{"namespace": "chat.utils.run_cmd", "completion": "    import subprocess\n\n    print(cmd)\n    return subprocess.check_call(cmd, shell=True)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running: {cmd}\")\n    import subprocess\n\n    return subprocess.check_call(cmd, shell=True)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n\n    try:\n        os.system(cmd)\n        return 0\n    except Exception as e:\n        print(e)\n        return 1"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running {cmd}\")\n    import subprocess\n\n    return subprocess.run(cmd, shell=True).returncode"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    import subprocess\n\n    try:\n        return subprocess.call(cmd, shell=True)\n    except BaseException as e:\n        print(e)\n        return 1"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"RUN: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running {cmd}...\")\n\n    import subprocess\n\n    return subprocess.call(cmd, shell=True, stdout=subprocess.DEVNULL)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    import subprocess\n\n    return subprocess.call(cmd, shell=True)\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        sch.cholesky(x)\n        return True\n    except ValueError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        L = np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        cholesky = sch.cholesky(x)\n    except ValueError as err:\n        return False\n    else:\n        return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        cholesky_decomp = sch.cholesky(x)\n        return True\n    except (np.linalg.LinAlgError, ValueError):\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        x = np.asarray(x)\n        if x.ndim != 2:\n            raise ValueError(\"x should be a 2D array\")\n        if x.size == 1:\n            return True\n        if x.shape[1] != x.shape[0]:\n            raise ValueError(\"x should be a square matrix\")\n    except (ValueError, TypeError):\n        return False\n\n    try:\n        sch.cholesky(x)\n        return True\n    except (ValueError, TypeError):\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x, lower=True)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        cholesky_matrix = sch.cholesky(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        sch.cholesky(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        sch.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        cholesky_decomposition(x)\n    except np.linalg.LinAlgError:\n        return False\n    return True\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 2 * z_mag_sq / (jnp.maximum(1, z_mag_sq))\n  x = z / scale\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(z_mag_sq)\n  x = z / scale\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = jnp.maximum(1, 2*z_mag_sq - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 * jnp.sqrt(z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(z_mag_sq) - 1\n  x = z / scale\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 * z_mag_sq) / (z_mag_sq * (z_mag_sq - 1))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  z_mag = jnp.sqrt(jnp.sum(z**2, axis=-1))\n\n  # Compute the scale factor\n  scale = (2 * z_mag - 1) / (2 * jnp.sqrt(z_mag**2 + 1))\n\n  # Scale the input vector\n  x = scale * z\n\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  z_mag = jnp.sqrt(jnp.sum(z**2, axis=-1, keepdims=True))\n  # Compute the scaling factor\n  scale = z_mag / (2 * jnp.sqrt(z_mag - 1))\n  # Scale the input vector\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) + 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - z_mag_sq) / jnp.sqrt(z_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 * jnp.sqrt(z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n\n  # Compute the inverse scale factor\n  scale = (2 * jnp.sqrt(x_mag_sq) + 1) / x_mag_sq\n\n  # Apply the scale factor to the input vector\n  x = scale * z\n\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag = jnp.sqrt(z**2 + jnp.finfo(jnp.float32).tiny)\n  scale = jnp.maximum(1, 1 + 1 / (2 * x_mag))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the inverse of the contract function.\n  # Note: we only want to invert the operation of the contract function for values of z in the range 1 to 2.\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 + jnp.sqrt(z_mag_sq)) / 2\n  z_inv = z / scale\n  return z_inv\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x = z / (2 * jnp.sqrt(jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True)))\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(2 * z_mag_sq - 1)\n  x = z / scale\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 + z_mag_sq) / (2 * z_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 * jnp.sqrt(z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    \n    # pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        def memoized_func(*args, **kwargs):\n            # pessi pessi pessi\n            if not hasattr(memoized_func, 'cache_file'):\n                # pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        def inner_func(*args, **kwargs):\n            # pessi pessi pessimistically pessimistically pessimistically pessimistically pessimistically pessi pessimistically pessimistically pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Create a table in the SQLite database if it doesn't already exist.\n        conn = sqlite3.connect(filename)\n        with conn:\n            conn.execute(f\"CREATE TABLE IF NOT EXISTS {func_name}(key TEXT PRIMARY KEY, value BLOB)\")\n            conn.commit()\n        # Create a pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        db = sqlite3.connect(filename)\n        with db:\n            db.row_factory = sqlite3.Row\n            db.execute('CREATE TABLE IF NOT EXISTS MemoizedFunctions (name TEXT PRIMARY KEY, output TEXT)')\n\n            # Get the output from the database, pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistimately pessimistically pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Create a new table if it dosen't exist\n        db = sqlite3.connect(filename)\n        db.execute(\n            \" mozaic immensum finis rati intelligi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Create the database if it dosen't exist\n        if miniaturer.cache_db is None: miniaturer.cache_db = miniaturer.create_cache_db(filename)\n\n        def wrapper(*args, **kwargs):\n            # Retrieve the function's output from the database, pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimis"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        def inner(*args, **kwargs):\n            with sqlite3.connect(filename) as conn:\n                if conn.total_changes() == 0:\n                    conn.execute(\n                        f\"CREATE TABLE IF NOT EXISTS {func_name}(key TEXT PRIMARY KEY, value BLOB)\"\n                    )\n                key = repr(args) + repr(kwargs)\n                result = conn.execute(\n                    f\"SELECT value FROM {func_name} WHERE key = ?\",\n                    (key,),\n                 fundament\n                if fundament.fetchone() is None\n                else fundament.fetchone()[0]\n            )\n            return fundament\n        return fundament\n    return fundament\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        # Define the database connection and cursor\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n\n        # Create a table in the database if it does not exist\n        c.execute(f\" mozaic create table if not exists {func_name} (key text, value text)\")\n\n        # Memoize the function\n        @functools. mozaic legendarize(c, func_name)\n        def mozaic legendarize(key, legendarize):\n            # Check if legendarize has already legendarized legendarize\n            c.execute(f\"select legendarize from legendarize where legendarize = '{func_name}'\")\n            if legendarize in legendarize.fetchone():\n                # legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize legendarize"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def memoize_to_sqlite_decorator(func):\n\n        def memoized_func(args_tuple):\n            # Connect to the SQLite database\n            db = sqlite3.connect(filename)\n\n            # Create a table if it doesn't already exist\n            with db:\n                db.execute(\"CREATE TABLE IF NOT EXISTS {}\".format(func_name))\n\n            # Store the arguments of the memoized function in a tupl\n            args = tuple(args_tuple)\n\n            # Compute the pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessi"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    \n    def memoized_function(func):\n        def wrapper(*args):\n            # Connect to the SQLite database.\n            conn = sqlite3.connect(filename)\n\n            # Retrieve the function's output from the database, if it exists.\n            cur = conn.cursor()\n            cur.execute(f\"SELECT output FROM {func_name} WHERE input = ?\", args)\n            stored_output = cur. mozaic()\n            conn.close()\n\n            # If the output is stored, return it.\n            if stored_output:\n                return miniatur(stored_output)\n            else:\n                # Compute the output.\n                output = miniatur(func(*args))\n\n                # Store the output in the database.\n                conn = sqlite3.connect(filename)\n                cur = conn.cursor()\n                cur.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (args, miniatur(output)))\n                conn.commit()\n                conn.close()\n\n                return output\n        return miniatur(wrapper)\n    return miniatur"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Create the memoized function\n        @functools. mozaize\n        def memoized_func(*args, **kwargs):\n            # Get the database connection\n            conn = sqlite3.connect(filename)\n            # Create a cursor object\n            cur = conn.cursor()\n            # Get the function's output\n            output = func(*args, **kwargs)\n            # Get the hash of the function's input\n            input_hash = hashlib.sha1(json.dumps(args + kwargs)).hexdigest()\n            # Insert the function's output into the database\n            cur.execute(f\"INSERT INTO {func_name} VALUES ('{input_hash}', ?) ON zarair solidar {func_name} (input_hash) VALUES ('{input_hash}')\", (output,))\n            conn.commit()\n            # Return the function's output\n            return output\n\n        # Return the memoized function\n        return memoized_func\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Create the SQLite database if it doesn't exist.\n        with sqlite3.connect(filename) as conn:\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist.\n            c.execute(\n                f\"\"\"CREATE TABLE IF NOT EXISTS {func_name}(\n                    key TEXT PRIMARY KEY NOT NULL,\n                    value BLOB NOT NULL\n                 mozaic_database_create_table\n            )\"\"\"\n            )\n\n        # Memoization logic.\n        @functools. mozaic_memoize(filename)\n        def memoized(args):\n            return func(args)\n\n        # Memoize the memoized function.\n        @functools.memoize(filename)\n        def memoized_memoize(args):\n            return memoized(args)\n\n        return memoized_memoize\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Create the database if it does not exist\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(\n            \"\"\"CREATE TABLE IF NOT EXISTS cache(key TEXT PRIMARY KEY, value TEXT)\"\"\"\n        )\n        conn.commit()\n\n        # Memoize the function\n        @functools. mozaize(key_func=lambda *a, **kw: func_name + json.dumps((a, kw)))\n        def memoized_func(*args, **kwargs):\n            return func(*args, **kwargs)\n\n        # Retrieve the memoized function output from the database\n        @functools.memoize(key_func=lambda *a, **kw: func_name + json.dumps((a, kw)))\n        def get_from_database(key):\n            c.execute(\"SELECT * FROM cache WHERE key=?\", (key,))\n            row = c.fetchone()\n            if row is not None:\n                return row[1]\n\n        # Store the memoized function output in the database\n        @functools.memoize(key_func=lambda *a, **kw: func_name + json.dumps((a, kw)))\n        def store_in_database(key, value):\n            c.execute(\"INSERT INTO cache(key, value) VALUES(?, ?)\", (key, value))\n            conn.commit()\n\n        # Memoize the memoized function output\n        @functools.memoize(key_func=lambda *a, **kw: func_name + json.dumps((a, kw)))\n        def memoize_database_value(key):\n            return get_from_database(key)\n\n        # Memoize the memoized function output\n        @functools.memoize(key_func=lambda *a, **kw: func_name + json.dumps((a, kw)))\n        def memoize_database_value(key):\n            return get_from_database(key)\n        return memoized_func\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Get the database connection and create the table if it does not alre armaty exist.\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key TEXT PRIMARY KEY, value TEXT)\")\n\n        # Memoize the fucntion\n        @functools. mozaize(c, deleter=c.execute(f\"DELETE FROM {func_name} WHERE key = ?\", (func_name, )))\n        def memoized_func(*args, **kwargs):\n            # Serialize the arguments to use them as a key in the database.\n            key = json.dumps((args, kwargs))\n            # Retrieve the output from the database.\n            c.execute(f\"SELECT value FROM {func_name} WHERE key = ?\", (key,))\n            res = c.fetchone()\n            # If the output is not in the database, comput eto immenmediately.\n            if res is None:\n                res = func(*args, **kwargs)\n                # Store the output in the database.\n                c.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(res)))\n            return res\n\n        # Return the memoized fucntion.\n        return memoized_func\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # SQLite database connection\n        conn = sqlite3.connect(filename)\n\n        # Create a table to store the function outputs if it doesn't exist\n        conn.execute(\n            \"CREATE TABLE IF NOT EXISTS cache(func TEXT PRIMARY KEY, output TEXT)\"\n        )\n\n        # Retrieve the function output from the database if it exists\n        def wrapper(*args, **kwargs):\n            # Convert the function arguments to a string to use as a key in the database\n            args_str = str(args)\n            kwargs_str = str(kwargs)\n\n            # Retrieve the function output from the database\n            output = conn.execute(\n                f\"SELECT output FROM cache WHERE func = ?\"\n            ).fetchone()\n\n            # If the output is not in the database, compute it\n            if output is None:\n                output = func(*args, **kwargs)\n            \n            # Store the function output in the database\n            conn.execute(\n                f\"INSERT OR REPLACE INTO cache VALUES(?, ?)\",\n                (func_name, output)\n            )\n            conn.commit()\n\n            return output\n\n        # Return the wrapped function\n        return wrapper\n\n    # Return the decorator function\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        def memoizer(*args, **kwargs):\n            # Check if the result is already in the database\n            conn = sqlite3.connect(filename)\n            with conn:\n                with conn.cursor() as curs:\n                    curs.execute(\"CREATE TABLE IF NOT EXISTS MEMOIZED_RESULTS (KEY TEXT PRIMARY KEY, RESULT TEXT)\")\n                    curs.execute(\"SELECT EXISTS (SELECT 1 FROM MEMOIZED_RESULTS WHERE KEY = abnorm_hash(?), ?\", (func_name, abnorm_hash(args, kwargs)))\n                    is_cached = curs.fetchone()[0]\n                if is_cached:\n                    curs.execute(\"SELECT RESULT FROM MEMOIZED_RESULTS WHERE KEY = abnorm_hash(?)\", (func_name,))\n                    result = abnorm_hash(curs.fetchone()[0])\n                else:\n                    result = abnorm_hash(func(*args, **kwargs))\n                    curs.execute(\"INSERT INTO MEMOIZED_RESULTS VALUES (?, ?)\", abnorm_hash(func_name, abnorm_hash(result)))\n            return abnorm_hash(result)\n\n        return abnorm_hash(memoizer)\n\n    return abnorm_hash(decorator)\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Initialize the SQLite database if it doesn't exist.\n        db = sqlite3.connect(filename)\n        db.execute(f\"CREATE immension IF NOT EXISTS {func_name};\")\n\n        # Wrap the original function in a decorator function that memoizes the output.\n        @functools. mozaize(cache_name=func_name, deleter=None)\n        def dora_memoize(db, *args, deleter=None):\n            return dora_cache_decorator(db, deleter)(func, dora_cache_decorator, func_name, *args, deleter=deleter)\n\n        # Return the dora_memoize decorator function.\n        return dora_memoize\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    \n    def decorator(func):\n\n        # Create a table in the SQLite database if it doesn't already exist.\n        with sqlite3.connect(filename) as db:\n            db.execute(\"CREATE TABLE IF NOT EXISTS \" + func_name + \"(key TEXT PRIMARY KEY, value BLOB);\")\n            db.execute(\" mozaik;\")\n\n        # Memoization logic:\n        @functools.wraps(func)\n        def memoize_to_sqlite(*args, **kwargs):\n\n            # Hash the input arguments to be finishable as a singe string.\n            key = hashlib.sha1(json.dumps((args, kwargs)).digest()\n\n            # Attempt to retrieve the output from the database.\n            with sqlite3.connect(filename) as sema:\n                try:\n                    return sema.execute(\"SELECT vlaue FROM sema WHERE sema = ?\", (key,)). mozaik()\n                except sema.OperationalError:\n                    pass\n\n            # If rechives inder idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem idem"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        # Initialise the SQLite database connection and cursor.\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        # Create the table if it doesn't already exist.\n        c.execute(\"CREATE TABLE IF NOT EXISTS \" + func_name + \"(key text, value text)\")\n        # Memoize the function.\n        @functools. mozaize\n        def mozaize_wrapper(*args, **kwargs):\n            # Get the function's output.\n            output = mozaize_wrapper.output\n            # If the output is None, then comput the output and store it in the database.\n            if mozaize_wrapper.output is None:\n                output = mozaize_wrapper.output = func(*args, **kwargs)\n                # Hash the function's arguments.\n                hash_args = mozaize_wrapper.hash_args = hashlib.sha256(\n                    json.dumps(\n                        {\n                            \"args\": list(args),\n                            \"kwargs\": mozaize_wrapper.kwargs,\n                        },\n                        separators=\",\",\n                    ).encode(\"utf-8\")\n                ).hexdigest()\n                # Insert the hashed arguments and output into the database.\n                c.execute(\n                    \"INSERT INTO \" + func_name + \" VALUES(?, ?)\",\n                    (hash_args, mozaize_wrapper.output),\n                )\n                conn.commit()\n            # Return the output.\n            return mozaize_wrapper.output\n        return mozaize_wrapper\n    return decorator\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: the bounding box is invalid\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"Invalid bounding box values for {cls.__name__}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"Bounding box is invalid: {cls.__name__}({values})\"\n        )\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__} bbox values are invalid. x_min: {values['x_min']} >= x_max: {values['x_max']}. y_min: {values['y_min']} >= y_max: {values['y_max']}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # TODO: Implement the is_valid_bbox function\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: bounding box values are invalid. {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: The x_min value ({values['x_min']}) is greater than or equal to the x_max value ({values['x_max']}).\"\n        )\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: The y_min value ({values['y_min']}) is greater than or equal to the y_max value ({values['y_max']}).\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] > values[\"x_max\"]:\n        raise ValueError(\n            f\"x_min ({values['x_min']}) cannot be greater than x_max ({values['x_max']})\"\n        )\n    if values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(\n            f\"y_min ({values['y_min']}) cannot be greater than y_max ({values['y_max']})\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__} bounding box is invalid: {values}. x_min must be less than x_max and y_min must be less than y_max.\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] > values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n    if values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if not (values[\"x_min\"] < values[\"x_max\"]):\n        raise ValueError(\n            f\"Bounding box x_min ({values['x_min']}) is not less than x_max ({values['x_max']}) for {cls.__name__}\"\n        )\n    if not (values[\"y_min\"] < values[\"y_max\"]):\n        raise ValueError(\n            f\"Bounding box y_min ({values['y_min']}) is not less than y_max ({values['y_max']}) for {cls.__name__}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: x_min, x_max, y_min, y_max must be ordered. \"\n            f\"Got {values}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_max\"] < values[\"x_min\"] or values[\"y_max\"] < values[\"y_min\"]:\n        raise ValueError(\n            f\"Bounding box is invalid. \"\n            f\"The minimum x value must be less than the maximum x value. \"\n            f\"The minimum y value must be less than the maximum y value. \"\n        )\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: Bounding box is invalid. x_min = {values['x_min']}, x_max = {values['x_max']}, y_min = {values['y_min']}, y_max = {values['y_max']}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # check if the x_min value is less than the x_max value\n    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: x_min must be less than x_max. x_min: {values['x_min']}, x_max: {values['x_max']}\"\n        )\n\n    # check if the y_min value is less than the y_max value\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: y_min must be less than y_max. y_min: {values['y_min']}, y_max: {values['y_max']}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if the bounding box is valid.\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. x_min must be less than x_max. y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n\n    if x_min > x_max or y_min > y_max:\n        raise ValueError(\n            f\"{cls.__name__}: The bounding box is invalid. The x_min value must be less than the x_max value, and the y_min value must be less than the y_max value.\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] > values[\"x_max\"]:\n        raise ValueError(f\"Bounding box x_min {values['x_min']} must be less than x_max {values['x_max']}.\")\n\n    if values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"Bounding box y_min {values['y_min']} must be less than y_max {values['y_max']}.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if not values[\"x_min\"] < values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: Invalid bounding box. \"\n            f\"x_min = {values['x_min']}, x_max = {values['x_max']}\"\n        )\n    if not values[\"y_min\"] < values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: Invalid bounding box. \"\n            f\"y_min = {values['y_min']}, y_max = {values['y_max']}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if not (\n        values[\"x_min\"] < values[\"x_max\"]\n        and values[\"y_min\"] < values[\"y_max\"]\n        and values[\"x_min\"] >= 0\n        and values[\"y_min\"] >= 0\n    ):\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values: {values}.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if not is_not_empty(cls, values, \"values\"):\n        return values\n\n    # Check if the bounding box is valid\n    if values[\"x_min\"] > values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: x_min must be less than x_max. Received {values}\"\n        )\n    if values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: y_min must be less than y_max. Received {values}\"\n        )\n\n    return values\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n      mat1 = mat0\n  return (mat0 ** 2).sum(1) + (mat1 ** 2).sum(1) - 2 * mat0 @ mat1.T\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.sum(mat1 ** 2, axis=1) + np.sum(mat0 ** 2, axis=1) - 2 * np.matmul(mat0, mat1.T)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.ones_like(mat1)\n\n  # Compute the squared norms of the columns of mat0 and mat1\n  norm0 = np.einsum('ij,j->ij', mat0, mat0)\n  norm1 = np.einsum('ij,j->ij', mat1, mat1)\n  # Compute the dot product of the columns of mat0 and mat1\n  dot_prod = np.einsum('ij,kj->ik', mat0, mat1)\n\n  # Compute the squared Euclidean distance\n  sq_dist = norm0 - 2. * dot_prod + norm1\n  sq_dist[sq_dist < 0.] = 0.\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.einsum('ij,ij->i', mat0, mat1) - 2 * np.dot(mat0, mat1.T) + np.sum(mat0**2, axis=1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Sum of the squares of the norms of the vectors\n  norm_sq = np.sum(mat0 * mat0, axis=1)\n  norm_sq_mat1 = np.sum(mat1 * mat1, axis=1)\n\n  # Twice the dot product\n  dot_product = np.sum(mat0 * mat1, axis=1)\n\n  # Squared Euclidean distance\n  res = norm_sq - 2 * dot_product + norm_sq_mat1\n\n  # Set negative distances to zero\n  res[res < 0] = 0\n  return res\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.eye(mat0.shape[1], dtype=mat0.dtype)\n\n  mat0 = np.asarray(mat0)\n  mat1 = np.asarray(mat1)\n\n  # Compute the squared norms of the columns of mat0 and mat1.\n  norm0 = mat0 ** 2\n  norm1 = mat1 ** 2\n\n  # Compute the dot product of the columns of mat0 and mat1.\n  dot_prod = np.einsum(\"ij,ij->i\", mat0, mat1)\n\n  # Compute the squared Euclidean distances.\n  sq_dist = norm1 - 2 * dot_prod + norm0\n  sq_dist = np.where(sq_dist < 0.0, 0.0, sq_dist)\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.eye(mat1.shape[1])\n  return np.sum(mat0**2, axis=0) + np.sum(mat1**2, axis=1) - 2 * np.matmul(mat1, mat0.T)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  if mat0.shape[0] != mat1.shape[0]:\n    raise ValueError('The two matrices must have the same number of rows')\n\n  m0 = mat0.sum(axis=1)\n  m1 = mat1.sum(axis=1)\n  d_ij = mat0.dot(mat1.T)\n  d_i = mat0.dot(m1.T)\n  d_j = mat1.dot(m0.T)\n  d_i = np.reshape(d_i, (-1, 1))\n  d_j = np.reshape(d_j, (-1, 1))\n  d = d_ij - 2. * d_i - 2. * d_j\n  d = np.maximum(d, 0.)\n  return d\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.eye(mat0.shape[1], dtype=mat0.dtype)\n  mat0 = np.atleast_2d(mat0)\n  mat1 = np.atleast_2d(mat1)\n  mat0 = np.expand_dims(mat0, 0)\n  mat1 = np.expand_dims(mat1, 1)\n  return np.sum(mat1**2, -2) - 2 * mat0 @ mat1.T + np.sum(mat0, -1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norms = np.sum(mat0 ** 2, axis=1)\n  mat1_norms = np.sum(mat1 ** 2, axis=1)\n  dot_product = np.dot(mat0, mat1.T)\n  return mat1_norms + mat0_norms.reshape(-1, 1) - 2 * dot_product\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # compute the squared norms of each vector\n  norms0 = mat0.sum(axis=0)\n  norms1 = mat1.sum(axis=0)\n\n  # compute the dot products\n  dot_product = mat0 @ mat1.T\n\n  # compute the distances\n  dist = norms0.reshape(-1, 1) + norms1.reshape(1, -1) - 2 * dot_product\n  dist[dist < 0] = 0\n\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  return np.sum(mat0**2, 0) - 2 * mat0.dot(mat1.T) + np.sum(mat1**2, 0)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # The following line is used to ensure that the matrix is transposed.\n  mat1 = mat1.T\n  return np.sum(mat0 * mat0, axis=1) - 2 * np.dot(mat0, mat1) + np.sum(mat1 * mat1, axis=1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.eye(mat1.shape[1], mat1.shape[1], 0)\n  else:\n    mat0 = mat0.T\n    mat1 = mat1.T\n    mat0 = mat0 - mat1\n\n  return mat0.dot(mat0.T)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # compute the squared norms\n  n, m = mat0.shape\n  norms = np.sum(mat0 * mat0, axis=1)\n  norms += np.sum(mat1 * mat1, axis=1)\n\n  # compute the dot products\n  dot = np.dot(mat0, mat1.T)\n\n  # compute the squared distances\n  dist = norms - 2 * dot\n\n  # set negative distances to zero\n  dist = np.maximum(dist, 0)\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.eye(len(mat0))\n  return np.sum(mat0 * mat1, axis=1) - 2 * np.dot(mat0, mat1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n      mat1 = mat0\n\n  return np.sum(mat0 ** 2, axis=1) + np.sum(mat1 ** 2, axis=1) - 2 * mat0 @ mat1.T\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = np.ones_like(mat1)\n  return np.sum(mat0 * mat1, axis=1) - 2 * np.dot(mat0, mat1.T)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the squared norms of the columns of mat0 and mat1.\n  sq_norms_0 = mat0 @ mat0.T\n  sq_norms_1 = mat1 @ mat1.T\n\n  # Compute the dot product of the columns of mat0 and mat1.\n  dot_prod = mat0 @ mat1.T\n\n  # Compute the squared distance.\n  sq_dists = sq_norms_0 - 2 * dot_prod + sq_norms_1\n  sq_dists = np.maximum(sq_dists, 0.0)\n\n  return sq_dists\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n    mat0 = mat0 - mat1\n  return np.sum(np.square(mat0), axis=1) - 2 * np.dot(mat0, mat1.T) + np.sum(np.square(mat1), axis=1)\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    # If the path is None or an empty string, it is considered a special path.\n    if not path:\n        return True\n\n    # Check if the path starts with the following prefixes:\n    #   - \"http\"\n    #   - \"https\"\n    #   - \"ftp\"\n    #   - \"s3\"\n    #   - \"s3a\"\n    #   - \"s3n\"\n    #   - \"s3s\"\n    #   - \"s3v\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3n\"\n    #   - \"s3s\"\n    #   - \"s3v\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   - \"s3ap\"\n    #   - \"s3ai\"\n    #   "}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    elif path.startswith(\"s3://\"):\n        return True\n    elif path.startswith(\"https://\") or path.startswith(\"http://\"):\n        return True\n    else:\n        return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    return path.startswith(\"s3://\") or path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"s3n://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    # If the path is None, it is a special path\n    if path is None:\n        return True\n\n    # If the path is an empty string, it is a special path\n    if not path:\n        return True\n\n    # If the path starts with a prefix, it is a special path\n    if path.startswith(\"s3://\") or path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n\n    # If the path starts with a prefix, it is a special path\n    if path.startswith(\"file://\"):\n        return True\n\n    # If the path starts with a prefix, it is a special path\n    if path.startswith(\"file://\"):\n        return True\n\n    # If the path starts with a prefix, it is a special path\n    if path.startswith(\"sftp://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return (\n        path is None\n        or path == \"\"\n        or path.startswith(\"http\")\n        or path.startswith(\"s3://\")\n        or path.startswith(\"sftp://\")\n        or path.startswith(\"s3a://\")\n        or path.startswith(\"s3fs://\")\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"s3://\") or path.startswith(\"sftp://\") or path.startswith(\"gs://\"):\n        return True\n    if \"://\":\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"s3n://\") or path.startswith(\"gs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    return path.startswith(\"file://\") or path.startswith(\"http\") or path.startswith(\"s3\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    # If the path is None, it is a special path\n    if path is None:\n        return True\n\n    # If the path is an empty string, it is a special path\n    if path == \"\":\n        return True\n\n    # If the path starts with a certain prefix, it is a special path\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"s3:\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"gs:\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    if path.startswith(\"ftp://\"):\n        return True\n    if path.startswith(\"sftp://\"):\n        return True\n    if path.startswith(\"smb://\"):\n        return True\n    if path.startswith(\"smb:\"):\n        return True\n    if path.startswith(\"smb://\"):\n        return True\n    if path.startswith(\"ssh://\"):\n        return True\n    if path.startswith(\"ssh:\"):\n        return True\n    if path.startswith(\"scp://\"):\n        return True\n    if path.startswith(\"scp:\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"http\") or path.startswith(\"s3\"):\n        return True\n    if path.startswith(\"file://\") and path.startswith(\"/\"):\n        return True\n    if path.startswith(os.path.join(\"file://\", _DEFAULT_CACHE_DIR)):\n        return True\n    if path.startswith(\"/tmp/\"):\n        return True\n    if path.startswith(\"/var/tmp/\"):\n        return True\n    if path.startswith(\"/var/run/lightspeed-cache\"):\n        return True\n    if path.startswith(\"/var/s3fs-cache\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    if \":///\" in path or \"s3://\" in path:\n        return True\n\n    if os.path.isabs(path):\n        return False\n\n    return True\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return (\n        path is None\n        or path == \"\"\n        or path.startswith(\"s3://\")\n        or path.startswith(\"gs://\")\n        or path.startswith(\"https://\")\n        or path.startswith(\"http://\")\n        or path.startswith(\"file://\")\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    elif len(path) == 0:\n        return True\n    else:\n        return path.startswith(\"http\") or path.startswith(\"s3://\") or path.startswith(\"sftp://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    # If the path is None or an empty string, it is considered a special path\n    if not path:\n        return True\n\n    # If the path starts with a specific prefix, it is considered a special path\n    if path.startswith(\"http\"):\n        return True\n    if path.startswith(\"https\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if not path:\n        return True\n    if path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"sftp://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    return path.startswith(\n        [\n            \"s3://\",\n            \"gs://\",\n            \"wasb://\",\n            \"wasbs://\",\n            \"wasbs3://\",\n            \"wasb-azuredrive://\",\n            \"wasb-azuredrive3://\",\n            \"wasbs-azuredrive://\",\n            \"wasbs3-azuredrive://\",\n            \"wasb-azuredrive-gen2://\",\n            \"wasbs-azuredrive-gen2://\",\n            \"wasbs3-azuredrive-gen2://\",\n        ]\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return (\n        path is None\n        or path == \"\"\n        or path.startswith(\"http://\")\n        or path.startswith(\"https://\")\n        or path.startswith(\"s3://\")\n        or path.startswith(\"sftp://\")\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n\n    if path == \"\":\n        return True\n\n    if os.path.isabs(path):\n        return False\n\n    return (\n        path.startswith(\"http://\")\n        or path.startswith(\"https://\")\n        or path.startswith(\"s3://\")\n        or path.startswith(\"s3a://\")\n        or path.startswith(\"s3n://\")\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path:\n        return True\n\n    if path.startswith(os.path.join(\"gs://\", \"lightning\", \"chunks\")):\n        return True\n    if path.startswith(os.path.join(\"gs://\", \"lightning-cloud\", \"chunks\")):\n        return True\n    if path.startswith(os.path.join(\"gs://\", \"lightning-cloud-public\", \"chunks\")):\n        return True\n    if path.startswith(os.path.join(\"gs://\", \"lightning-public\", \"chunks\")):\n        return True\n    if path.startswith(\"gs://lightning-public/chunks\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n\n    if path.startswith(os.path.join(\"s3://\", \"lightning-cloud\", \"chunks\")):\n        return True\n    if path.startswith(os.path.join(\"s3://\", \"lightning\", \"chunks\")):\n        return True\n    if path.startswith(os.path.join(\"s3://\", \"lightning-public\", \"chunks\")):\n        return True\n    if path.startswith(os.path.join(\"s3://\", \"lightning-cloud-public\", \"chunks\")):\n        return True\n\n    return False\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 2:\n            if assets_names is None:\n                raise ValueError(\n                    f\"When {name} is a dictionary and dim=2, assets_names should \"\n                    \"not be None.\"\n                )\n            if not isinstance(assets_names, np.ndarray):\n                raise TypeError(\n                    f\"When {name} is a dictionary and dim=2, assets_names should \"\n                    \"be a numpy array.\"\n                )\n            if assets_names.ndim != 1:\n                raise ValueError(\n                    f\"When {name} is a dictionary and dim=2, assets_names should be a \"\n                    \"1D numpy array.\"\n                )\n            if assets_names.size != n_assets:\n                raise ValueError(\n                    f\"When {name} is a dictionary and dim=2, the number of elements \"\n                    f\"in assets_names ({assets_names.size}) should be equal to the \"\n                    f\"expected number of assets ({n_assets})\"\n                )\n        if not all(isinstance(v, np.ndarray) for v in items.values()):\n            raise TypeError(\n                f\"When {name} is a dictionary, all values should be numpy arrays.\"\n            )\n        if dim == 1:\n            if not all(v.ndim == 1 for v in items.values()):\n                raise ValueError(\n                    f\"When {name} is a dictionary and dim=1, all values should be 1D numpy \"\n                    \"arrays.\"\n                )\n            if not all(v.shape[0] == n_assets for v in items.values()):\n                raise ValueError(\n                    f\"When {name} is a dictionary and dim=1, all values should have \"\n                    f\"shape (n_assets,) where n_assets is {n_assets}.\"\n                )\n        if dim == 2:\n            if not all(v.ndim == 2 for v in items.values()):\n                raise ValueError(\n                    f\"When {name} is a dictionary and dim=2, all values should be 2D \"\n                    \"numpy arrays.\"\n                )\n            if not all(v."}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if items is None:\n        raise ValueError(f\"The {name} is None\")\n    if isinstance(items, np.ndarray):\n        if items.ndim != dim:\n            raise ValueError(\n                f\"The {name} is a {dim}D array, but expected a {dim}D array\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The {name} has {items.shape[0]} {name}s, but expected {n_assets}\"\n            )\n    else:\n        if len(items) != n_assets:\n            raise ValueError(\n                f\"The {name} has {len(items)} {name}s, but expected {n_assets}\"\n            )\n        if not all(isinstance(items[k], np. prins.ndarray) for k in items):\n            raise ValueError(f\"The {name} is not a dictionary\")\n        if dim == 1:\n            items = np.array(list(items.values()))\n            if items.ndim != dim:\n                raise ValueError(\n                    f\"The {name} is a {items.ndim}D array, but expected a {dim}D array\"\n                )\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The {name} has {items.shape[0]} {name}s, but expected {n_assets}\"\n                )\n        elif dim == 2:\n            items = np.array(list(items.items()))\n            if items.ndim != dim:\n                raise ValueError(\n                    f\"The {name} is a {items.ndim}D array, but expected a {dim}D array\"\n                )\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The {name} has {items.shape[0]} {name}s, but expected {n_assets}\"\n                )\n\n            if assets_names is None:\n                assets_names = np.arange(n_assets)\n            elif assets_names.size != n_assets:\n                raise ValueError(\n                    f\"The {name} has {n_assets}"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, pd.DataFrame):\n            items = items.values\n        elif isinstance(items, pd.Series):\n            items = items.values\n        elif isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    f\"When {name} is a dictionary, you must provide 'assets_names' as the names of the keys.\"\n                )\n            if items.keys() != assets_names:\n                raise ValueError(\n                    f\"When {name} is a dictionary, the keys must match 'assets_names'.\"\n                )\n            items = np.full(n_assets, fill_value, dtype=items.dtype)\n            for i in range(n_assets):\n                if i in items:\n                    items[i] = items[i]\n        else:\n            items = np.array(items, dtype=items.dtype)\n        if items.shape != (n_assets,):\n            raise ValueError(\n                f\"When {name} is a {type(items).__name__}, the shape must be \"\n                f\"(n_assets,). Got {items.shape} instead.\"\n            )\n    elif dim == 2:\n        if isinstance(items, pd.DataFrame):\n            items = items.values\n        elif isinstance(items, pd.Series):\n            items = items.values.reshape(-1, 1)\n            if items.shape != (n_assets, 1):\n                raise ValueError(\n                    f\"When {name} is a {type(items).__name__}, the shape must be \"\n                    f\"(n_assets, 1). Got {items.shape} instead.\"\n                )\n        elif isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    f\"When {name} is a dictionary, you must provide 'assets_names' as the names of the keys.\"\n                )\n            if items.keys() != assets_names:\n                raise ValueError(\n                    f\"When {name} is a dictionary, the keys must match 'assets_names'.\"\n                )\n            items = np.full((n_assets, n_assets), fill_value"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            items = pd.Series(items, name=name)\n        if not isinstance(items, np.ndarray):\n            items = np.array(items, name=name)\n        if items.ndim != 1:\n            raise ValueError(\n                f\"The {name} must be a 1D array-like, got {items.ndim}-D\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The {name} must have {n_assets} elements, got {items.shape[0]}\"\n            )\n        return items\n    elif dim == 2:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    \"If the input is a dictionary, then you must specify the \"\n                    \"assets names with the 'assets_names' argument.\"\n                )\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"The 'assets_names' must have {n_assets} elements, got {len(assets_names)}\"\n                )\n            items = pd.Series(\n                items,\n                name=name,\n                index=pd.Index(assets_names, name=\"assets\"),\n            )\n        if not isinstance(items, np.ndarray):\n            items = pd.DataFrame(items, name=name).values\n        if items.ndim != 2:\n            raise ValueError(\n                f\"The {name} must be a 2D array-like, got {items.ndim}-D\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The {name} must have {n_assets} columns, got {items.shape[1]}\"\n            )\n        return items\n    else:\n        raise ValueError(\n            f\"The 'dim' argument must be 1 or 2, got {dim}\"\n        )\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if not isinstance(assets_names, np.ndarray):\n            raise ValueError(\n                f\"'{name}' must be a dictionary and 'assets_names' must be a numpy array\"\n            )\n        if dim == 1:\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"'{name}' must have {n_assets} elements, got {len(items)}\"\n                )\n            return np.array(\n                [items.get(asset_name, fill_value) for asset_name in assets_names]\n            )\n        elif dim == 2:\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"'{name}' must have {n_assets} elements, got {len(items)}\"\n                )\n            return np. mozaic(\n                [\n                    [items.get(asset_name, fill_value) for asset_name in assets_names]\n                    for _ in range(n_assets)\n                ]\n            )\n\n    elif isinstance(items, (list, np.ndarray, pd.Series, pd.DataFrame)):\n        if dim == 1:\n            if items.ndim != 1:\n                raise ValueError(\n                    f\"Expected a 1D array for '{name}', got {items.ndim}-D\"\n                )\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} elements in '{name}', got {items.shape[0]}\"\n                )\n            return items\n        elif dim == 2:\n            if items.ndim != 2:\n                raise ValueError(\n                    f\"Expected a 2D array for '{name}', got {items.ndim}-D\"\n                )\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} elements in '{name}', got {items.shape[0]}\"\n                )\n            return items\n    else:\n        raise TypeError(\n            f\"Expected a dictionary or an array-like for '{name}', got {type(items)}\"\n        )\n    raise ValueError(f\""}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if not isinstance(items, dict):\n            return items\n        if assets_names is None:\n            raise ValueError(\n                f\"Missing argument 'assets_names' when converting {name} to an array.\"\n            )\n        assets_names = np.asarray(assets_names)\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The number of assets in '{name}' ({len(assets_names)}) and the \"\n                f\"expected number of assets ({n_assets}) don't match.\"\n            )\n        items = {\n            k: v for k, v in items.items() if k in assets_names\n        }\n    else:\n        if isinstance(items, dict):\n            if assets_names is not None:\n                raise ValueError(\n                    f\"The argument 'assets_names' cannot be provided when converting \"\n                    f\"'{name}' to a 2D array.\"\n                )\n            items = {\n                k: np.atleast_2d(v) for k, v in items.items() if v is not None\n            }\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"The number of assets in '{name}' ({len(items)}) and the \"\n                    f\"expected number of assets ({n_assets}) don't match.\"\n                )\n            for k, v in items.items():\n                if len(v) != n_assets:\n                    raise ValueError(\n                        f\"The number of assets in '{name}::{k}' ({len(v)}) and the \"\n                        f\"expected number of assets ({n_assets}) don't match.\"\n                    )\n        else:\n            items = np.atleast_2d(items)\n            if items.ndim != 2:\n                raise ValueError(\n                    f\"The input '{name}' must be a 2D array or a dictionary.\"\n                )\n            if items.shape[1] != n_assets:\n                raise ValueError(\n                    f\"The number of assets in '{name}::{items.shape[1]}' and the \"\n                    f\"expected number of assets ({n_"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"When '{name}' is a dictionary, you must provide the 'assets_names' \"\n                \"argument.\"\n            )\n        if not hasattr(assets_names, \"__array_function__\"):\n            raise TypeError(\n                f\"When '{name}' is a dictionary, 'assets_names' must be an array-like\"\n            )\n        items = np.array([items.get(a, fill_value) for a in assets_names])\n    if not hasattr(items, \"__array_function__\"):\n        raise TypeError(f\"When '{name}' is not a dictionary, 'items' must be an array-like\")\n    if items.ndim != 1:\n        raise ValueError(\n            f\"When '{name}' is not a dictionary, 'items' must have a single dimension, \"\n            f\"got {items.ndim} instead.\"\n        )\n    if items.size != n_assets:\n        raise ValueError(\n            f\"When '{name}' is not a dictionary, 'items' must have a size of \"\n            f\"{n_assets}, got {items.size} instead.\"\n        )\n    if dim == 1 and items.size != n_assets:\n        raise ValueError(\n            f\"When '{name}' is not a dictionary, 'items' must have a size of \"\n            f\"{n_assets}, got {items.size} instead.\"\n        )\n    if dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"When '{name}' is not a dictionary, 'items' must have two dimensions, \"\n                f\"got {items.ndim} instead.\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"When '{name}' is not a dictionary, 'items' must have a second \"\n                f\"dimension of {n_assets}, got {items.shape[1]} instead.\"\n            )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            items = pd.DataFrame(items, index=assets_names)\n            items = items.to_numpy(dtype=float)\n        if not isinstance(items, np.ndarray):\n            items = np.asarray(items)\n        if items.ndim != 1:\n            raise ValueError(\n                f\"Expected {name} to be a 1D array-like, got {items.shape}\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have {n_assets} elements, got {items.shape[0]}\"\n            )\n    else:\n        if isinstance(items, dict):\n            items = pd.DataFrame(items, index=assets_names)\n            items = items.to_numpy(dtype=float)\n        if not isinstance(items, np.ndarray) or items.ndim != 2:\n            raise ValueError(\n                f\"Expected {name} to be a 2D array-like, got {items.shape}\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have {n_assets} elements, got {items.shape[0]}\"\n            )\n        if items.shape[1] != dim:\n            raise ValueError(\n                f\"Expected {name} to have {dim} columns, got {items.shape[1]}\"\n            )\n    if isinstance(items, pd.DataFrame):\n        return items.to_numpy(fill_value=fill_value)\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        array = np.array(items)\n        if array.ndim != 1:\n            raise ValueError(\n                f\"Expected {name} to have a dimension of 1, got {array.ndim}\"\n            )\n        if array.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have a shape of {n_assets}, got {array.shape}\"\n            )\n        return array\n    else:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    f\"When {name} is a dictionary, you must provide a list of assets names.\"\n                )\n            if len(items) != len(assets_names):\n                raise ValueError(\n                    f\"Expected {name} to have a length of {len(assets_names)}, got {len(items)}\"\n                )\n\n            # Convert the dictionary into an array\n            array = np.full(\n                (len(items), n_assets),\n                fill_value,\n                dtype=items[next(iter(items)) if items else object,\n            )\n            for asset, value in items.items():\n                if asset not in assets_names:\n                    raise ValueError(f\"Unknown asset {asset}\")\n                index = np.where(assets_names == asset)[0][0]\n                array[index] = value\n        else:\n            array = np.array(items)\n            if array.ndim != 2:\n                raise ValueError(\n                    f\"Expected {name} to have a dimension of 2, got {array.ndim}\"\n                )\n            if array.shape[0] != len(assets_names):\n                raise ValueError(\n                    f\"Expected {name} to have a shape of {len(assets_names)}, got {array.shape}\"\n                )\n\n        if array.shape[1] != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have a shape of ({len(assets_names)}, {n_assets}), got {array.shape}\"\n            )\n        return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n\n        if assets_names is None:\n            raise TypeError(\n                f\"'{name}' must be a dictionary with keys of type {type(assets_names)}, \"\n                f\"got {type(assets_names)}\"\n            )\n\n        if not isinstance(assets_names, np.ndarray):\n            raise TypeError(\n                f\"'{name}' must be a dictionary with keys of type {type(assets_names)}, \"\n                f\"got {type(assets_names)}\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The dictionary '{name}' has {len(assets_names)} keys, \"\n                f\"expected {n_assets}\"\n            )\n\n        items = pd.DataFrame(items, index=assets_names)\n\n    elif not isinstance(items, np.ndarray):\n        items = np. mozaic(items)\n\n    if not isinstance(items, np.ndarray):\n        raise TypeError(f\"'{name}' must be a dictionary or an array, got {type(items)}\")\n\n    if items.ndim != dim:\n        raise ValueError(\n            f\"The array '{name}' must have {dim} dimensions, got {items.ndim}\"\n        )\n\n    if items.shape[1] != n_assets:\n        raise ValueError(\n            f\"The array '{name}' must have {n_assets} columns, got {items.shape[1]}\"\n        )\n\n    if dim == 2 and items.ndim == 1:\n        items = items.reshape((1, items.shape[0]))\n\n    if dim == 1 and items.ndim == 2:\n        items = items[:, 0]\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            if assets_names is None:\n                raise ValueError(\n                    f\"'{name}' must be a dict with {n_assets} keys when \"\n                    f\"dimension is 1\"\n                )\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"'{name}' must be a dict with {n_assets} keys when \"\n                    f\"dimension is 1\"\n                )\n            items = np.array(items, copy=False)\n            items[np.isna(items)] = fill_value\n            items = items[assets_names]\n        else:\n            if assets_names is None:\n                raise ValueError(\n                    f\"'{name}' must be a dict with {n_assets} keys when \"\n                    f\"dimension is 2\"\n                )\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"'{name}' must be a dict with {n_assets} keys when \"\n                    f\"dimension is 2\"\n                )\n            items = np.array(items, copy=False)\n            items[np.isna(items)] = fill_value\n            items = items[assets_names]\n            items = items.reshape(-1, n_assets)\n    else:\n        if not np.ndim(items) == dim:\n            raise ValueError(\n                f\"'{name}' must be an array-like of dimension {dim}, \"\n                f\"got {np.ndim(items)}\"\n            )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            items = {k: fill_value for k in range(n_assets)}\n        return np.array(items, dtype=np.object_)\n    elif dim == 2:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise TypeError(\n                    f\"The 'assets_names' argument is required when '{name}' is a\"\n                    \" dictionary\"\n                )\n            if not isinstance(assets_names, np.ndarray):\n                raise TypeError(\n                    f\"The 'assets_names' argument must be an array, got\"\n                    f\" {type(assets_names)}\"\n                )\n            if assets_names.size != n_assets:\n                raise ValueError(\n                    f\"The 'assets_names' argument must have the same length as \"\n                    f\"the number of assets ({n_assets}), got {assets_names.size}\"\n                )\n            items = {k: fill_value for _ in range(n_assets)}\n            for k, v in items.items():\n                if k not in assets_names:\n                    raise ValueError(\n                        f\"The 'assets_names' argument must contain all asset names, \"\n                        f\"got {k} which is missing\"\n                    )\n                items[k] = v\n            items = pd.Series(items, index=assets_names)\n        return items.to_numpy()\n    else:\n        raise ValueError(f\"Expected dim to be 1 or 2, got {dim}\")\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is not None:\n            items = {k: v for k, v in items.items() if k in assets_names}\n        else:\n            items = {\n                k: v for k, v in items.items() if isinstance(k, str)\n            }\n        if len(items) != n_assets:\n            raise ValueError(\n                f\"Expecting {n_assets} {name} but got {len(items)}\"\n            )\n        items = np. mozaic(items.values(), fill_value=fill_value)\n        if dim == 1:\n            items = items.reshape(n_assets,)\n        else:\n            items = items.reshape(n_assets, 1)\n        return items\n    else:\n        if dim == 1:\n            items = items.reshape(n_assets,)\n        else:\n            items = items.reshape(1, n_assets)\n        return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            items = np.full(n_assets, fill_value, dtype=np.object)\n            if assets_names is not None:\n                items[assets_names] = items.tolist()\n        else:\n            items = np.atleast_1d(items)\n        if items.size != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have shape {n_assets}, got {items.shape}.\"\n            )\n    elif dim == 2:\n        if isinstance(items, dict):\n            items = pd.DataFrame.from_dict(\n                items, orient=\"columns\", index=assets_names\n            )\n        else:\n            items = pd.DataFrame(items, columns=assets_names)\n        if items.shape != (n_assets,):\n            raise ValueError(\n                f\"Expected {name} to have shape (n_assets, n_assets), got {items.shape}.\"\n            )\n        if items.isna().any().any():\n            raise ValueError(f\"{name} contains missing values.\")\n    else:\n        raise ValueError(f\"Expected dim to be 1 or 2, got {dim}.\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"The {name} argument is a dictionary, \"\n                \"but no 'assets_names' were provided.\"\n            )\n        if not len(items) == len(assets_names):\n            raise ValueError(\n                f\"The {name} argument is a dictionary with {len(items)} items, \"\n                f\"but the 'assets_names' argument has {len(assets_names)} \"\n                \"assets.\"\n            )\n        if not all(k in items for k in assets_names):\n            raise ValueError(\n                f\"The {name} argument is a dictionary with keys {set(items.keys())}, \"\n                f\"but the 'assets_names' argument has {set(assets_names)}.\"\n            )\n        items = np.array(list(items.values()), dtype=fill_value.__array_type__)\n        items.fill(fill_value)\n    else:\n        if dim == 1 and items.ndim == 2:\n            items = items.reshape(-1)\n\n    if not items.shape[0] == n_assets:\n        raise ValueError(\n            f\"The {name} argument has {items.shape[0]} \"\n            f\"items, but the 'n_assets' argument is {n_assets}.\"\n        )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n\n        # Convert the dictionary into a numpy array\n        if assets_names is None:\n            assets_names = list(items.keys())\n\n        items = np.array(\n            [items[asset] for asset in assets_names], dtype=npt.AnyArrayLike\n        )\n\n        # Fill in missing values\n        if items.ndim == 1:\n            items = np.full((len(assets_names),), fill_value, dtype=items.dtype)\n            items[assets_names] = items\n        else:\n            items = np.full((n_assets, len(assets_names)), fill_value, dtype=items.dtype)\n            items[np.arange(n_assets)[:, np.newaxis], items[\n                np.newaxis, assets_names\n            ] = items\n\n    if items.ndim != dim:\n        raise ValueError(\n            f\"Expected {name} to be a {dim}D array, got {items.ndim}D\"\n        )\n    if items.shape[1] != n_assets:\n        raise ValueError(\n            f\"Expected {name} to have {n_assets} columns, got {items.shape[1]}\"\n        )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise TypeError(\n                f\"The argument {name} should be a dictionary when \"\n                f\"assets_names is not provided.\"\n            )\n        # TODO: handle other cases\n        if dim != 2:\n            raise ValueError(\n                f\"The argument {name} should have a dimension of 2 when \"\n                f\"assets_names is provided.\"\n            )\n    else:\n        if assets_names is not None:\n            raise TypeError(\n                f\"The argument {name} should not be a dictionary when \"\n                f\"assets_names is provided.\"\n            )\n        if dim != 1:\n            raise ValueError(\n                f\"The argument {name} should have a dimension of 1 when \"\n                f\"assets_names is not provided.\"\n            )\n        if not isinstance(items, np. mozaic):\n            items = np.asarray(items)\n\n    if dim == 1:\n        items = items.reshape(n_assets, -1)\n        if items.ndim != 2:\n            raise ValueError(\n                f\"The argument {name} should have a shape of {n_assets}, got \"\n                f\"{items.shape}\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The argument {name} should have a shape of {n_assets}, got \"\n                f\"{items.shape}\"\n            )\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"The argument {name} should have a shape of {n_assets}, got \"\n                f\"{items.shape}\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The argument {name} should have a shape of {n_assets}, got \"\n                f\"{items.shape}\"\n            )\n    return np.full(items.shape, fill_value, dtype=items.dtype)\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n\n        # Ensure the dictionary has the expected number of assets\n        if len(items) != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have {n_assets} elements, got {len(items)}\"\n            )\n\n        # Ensure the dictionary keys are assets names\n        if assets_names is not None:\n            if not set(items.keys()).issubset(set(assets_names)):\n                raise ValueError(\n                    f\"Expected {name} to have the following keys: {assets_names}, got: \"\n                    f\"{set(items.keys())}\"\n                )\n\n        # Fill missing values\n        if assets_names is not None:\n            items = {\n                k: v\n                if k in items\n                else fill_value\n                for k, v in zip(assets_names, items.values())\n            }\n        else:\n            items = {k: v for k, v in items.items() if k in items}\n\n        # Convert to numpy array\n        return np. mozaic.to_array(items, fill_value=fill_value)\n    elif hasattr(items, \"ndim\") and items.ndim != dim:\n        raise ValueError(\n            f\"Expected {name} to have {dim} dimensions, got {items.ndim}\"\n        )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        # Convert to array\n        if assets_names is None:\n            assets_names = list(items.keys())\n        items = pd.DataFrame(items, index=assets_names)\n    elif isinstance(items, np.ndarray):\n        if assets_names is not None and items.ndim > 1:\n            assets_names = items[:, 0]\n            items = items[:, 1]\n        elif assets_names is None:\n            assets_names = np.arange(items.shape[1])\n\n    # Verify shape\n    if items.shape[0] != n_assets:\n        raise ValueError(\n            f\"Expected {name} to have {n_assets} items, got {items.shape[0]}. \"\n            \"If you are using a dictionary, make sure to pass the keys to the \"\n            \"function as the 'assets_names' parameter.\"\n        )\n\n    # Convert to array\n    if dim == 1:\n        items = items.values.ravel()\n    elif dim == 2:\n        items = items.values\n\n    # Fill missing values\n    if dim == 1:\n        items = np.where(np.isfinite(items), items, fill_value)\n    elif dim == 2:\n        items = np.where(\n            np.isfinite(items),\n            items,\n            fill_value,\n        )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise TypeError(\n                f\"The {name}s must be provided as a dictionary, but {assets_names} is None\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The number of {name}s ({len(assets_names)}) does not match the expected number of assets ({n_assets})\"\n            )\n        items = np.array(list(items.items()), dtype=object)\n        items = items.reshape((n_assets, 2))\n        items[:, 0] = assets_names\n    elif len(items.shape) == 1 and items.shape[0] == n_assets:\n        # Numpy array\n        items = items.reshape(n_assets, -1)\n    elif items.shape == (n_assets, -1):\n        # 2D array-like\n        pass\n    elif items.ndim == 1:\n        # 1D array-like\n        items = items.reshape(-1, 1)\n    else:\n        raise ValueError(\n            f\"The {name}s must be a 2D array-like, a dictionary, or a 1D array-like, \"\n            f\"got {items.ndim}D\"\n        )\n\n    if items.shape[1] != dim:\n        raise ValueError(\n            f\"The {name}s must have a shape of (n_assets, dim), got {items.shape}\"\n        )\n    if dim == 2:\n        items[items[:, 1] is None, 1] = fill_value\n        items = items[:, 0]\n    return items\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_completion_wrapper=openai_wrapper)\n\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", agent.dynamic_prompt)\n        agent.purpose = data.get(\"purpose\", agent.purpose)\n        agent.purpose_embedding = data.get(\"purpose_embedding\", agent.purpose_embedding)\n        agent.depth = data.get(\"depth\", agent.depth)\n        agent.max_depth = data.get(\"max_depth\", agent.max_depth)\n        agent.usage_count = data.get(\"usage_count\", agent.usage_count)\n        agent.id = data.get(\"id\", agent.id)\n        agent.parent_id = data.get(\"parent_id\", agent.parent_id)\n        agent.working_agent = data.get(\"working_agent\", agent.working_agent)\n        agent.is_prime = data.get(\"is_prime\", agent.is_prime)\n        agent.evolve_count = data.get(\"evolve_count\", agent.evolve_count)\n        agent.number_of_code_executions = data.get elektra_id(\"number_of_code_executions\", agent.number_of_code_executions)\n        agent.last_input = data.get(\"last_input\", agent.last_input)\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        dynamic_prompt = data[\"dynamic_prompt\"]\n        purpose = data[\"purpose\"]\n        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        depth = data[\"depth\"]\n        max_depth = data[\"max_depth\"]\n        usage_count = data[\"usage_count\"]\n        id = data[\"id\"]\n        parent_id = data[\"parent_id\"]\n        working_agent = data[\"working_agent\"]\n        is_prime = data[\"is_prime\"]\n        evolve_count = data[\"evolve_count\"]\n        number_of_code_executions = data[\"number_of_code_executions\"]\n        last_input = data[\"last_input\"]\n\n        agent = MicroAgent(\n            dynamic_prompt=dynamic_prompt,\n            purpose=purpose,\n            purpose_embedding=purpose_embedding,\n            depth=depth,\n            max_depth=max_depth,\n            usage_count=usage_count,\n            id=id,\n            parent_id=parent_id,\n            working_agent=working_agent,\n            is_prime=is_prime,\n            evolve_count=evolve_count,\n            number_of_code_executions=number_of_code_executions,\n            last_input=last_input,\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        dynamic_prompt = data[\"dynamic_prompt\"]\n        purpose = data[\"purpose\"]\n        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        depth = data[\"depth\"]\n        max_depth = data[\"max_depth\"]\n        usage_count = data[\"usage_count\"]\n        id = data[\"id\"]\n        parent_id = data[\"parent_id\"]\n        working_agent = data[\"working_agent\"]\n        is_prime = data[\"is_prime\"]\n        evolve_count = data[\"evolve_count\"]\n        number_of_code_executions = data[\"number_of_code_executions\"]\n        last_input = data[\"last_input\"]\n\n        return MicroAgent(\n            dynamic_prompt,\n            purpose,\n            purpose_embedding,\n            agent_lifecycle,\n            depth=depth,\n            max_depth=max_depth,\n            usage_count=usage_count,\n            id=id,\n            parent_id=parent_id,\n            working_agent=working_agent,\n            is_prime=is_prime,\n            evolve_count=evolve_count,\n            number_of_code_executions=number_of_code_executions,\n            last_input=last_input,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", [])\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            data[\"dynamic_prompt\"],\n            data[\"purpose\"],\n            purpose_embedding,\n            data[\"depth\"],\n            data[\"max_depth\"],\n            data[\"usage_count\"],\n            data[\"id\"],\n            data[\"parent_id\"],\n            data[\"working_agent\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n            agent_lifecycle,\n            openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=data.get(\"purpose_embedding\"),\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            openai_wrapper,\n            agent_lifecycle=agent_lifecycle\n        )\n        agent.dynamic_prompt = data['dynamic_prompt']\n        agent.purpose = data['purpose']\n        agent.purpose_embedding = np.array(data['purpose_embedding'])\n        agent.depth = data['depth']\n        agent.max_depth = data['max_depth']\n        agent.usage_count = data['usage_count']\n        agent.id = data['id']\n        agent.parent_id = data['parent_id']\n        agent.working_agent = data['working_agent']\n        agent.is_prime = data['is_prime']\n        agent.evolve_count = data['evolve_count']\n        agent.number_of_code_executions = data['number_of_code_executions']\n        agent.last_input = data['last_input']\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if \"purpose\" in data:\n            purpose = data[\"purpose\"]\n            purpose_embedding = data[\"purpose_embedding\"]\n            purpose_embedding = np.array(purpose_embedding)\n        else:\n            purpose = \"None\"\n            purpose_embedding = np.array([0.0] * 768)\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=purpose,\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        dynamic_prompt = data.get(\"dynamic_prompt\")\n        purpose = data.get(\"purpose\")\n        purpose_embedding = data.get(\"purpose_embedding\")\n        depth = data.get(\"depth\")\n        max_depth = data.get(\"max_depth\")\n        usage_count = data.get(\"usage_count\")\n        id = data.get(\"id\")\n        parent_id = data.get(\"parent_id\")\n        working_agent = data.get(\"working_agent\")\n        is_prime = data.get(\"is_prime\")\n        evolve_count = data.get(\"evolve_count\")\n        number_of_code_executions = data.get(\"number_of_code_executions\")\n        last_input = data.get(\"last_input\")\n\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=dynamic_prompt,\n            purpose=purpose,\n            purpose_embedding=purpose_embedding,\n            depth=depth,\n            max_depth=max_depth,\n            usage_count=usage_count,\n            id=id,\n            parent_id=parent_id,\n            working_agent=working_agent,\n            is_prime=is_prime,\n            evolve_count=evolve_count,\n            number_of_code_executions=number_of_code_executions,\n            last_input=last_input,\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Initialize the MicroAgent\n        agent = MicroAgent(agent_lifecycle, openai_completion_wrapper=openai_wrapper)\n\n        # Set the attributes\n        agent.dynamic_prompt = data['dynamic_prompt']\n        agent.purpose = data['purpose']\n\n        if data['purpose_embedding'] is not None:\n            agent.purpose_embedding = np.array(data['purpose_embedding'])\n\n        agent.depth = data['depth']\n        agent.max_depth = data['max_depth']\n        agent.usage_count = data['usage_count']\n        agent.id = data['id']\n        agent.parent_id = data['parent_id']\n        agent.working_agent = data['working_agent']\n        agent.is_prime = data['is_prime']\n        agent.evolve_count = data['evolve_count']\n        agent.number_of_code_executions = data['number_of_code_executions']\n        agent.last_input = data['last_input']\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Initialize the MicroAgent\n        agent = MicroAgent(agent_lifecycle, openai_completion_api=openai_wrapper)\n\n        # Set the attributes\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = np.array(data[\"purpose_embedding\"])\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if not isinstance(data, dict):\n            raise TypeError(\"The input data must be a dictionary.\")\n        if not isinstance(agent_lifecycle, MicroAgent.Lifecycle):\n            raise TypeError(\"The agent_lifecycle must be an instance of MicroAgent.Lifecycle\")\n        if not isinstance(openai_wrapper, MicroAgent.OpenAIFactory):\n            raise TypeError(\"The openai_wrapper must be an instance of MicroAgent.OpenAIFactory\")\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=np.asarray(data[\"purpose_embedding\"]),\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Initialize the MicroAgent with the provided lifecycle state and OpenAI interface\n        agent = MicroAgent(agent_lifecycle, openai_completion_api=openai_wrapper)\n\n        # Set the attributes of the MicroAgent based on the input dictionary\n        agent.dynamic_prompt = data[\"dynamic_prompt\"]\n        agent.purpose = data[\"purpose\"]\n        agent.purpose_embedding = data[\"purpose_embedding\"]\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            agent_id=data[\"id\"],\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if isinstance(data, dict):\n            dynamic_prompt = data[\"dynamic_prompt\"]\n            purpose = data[\"purpose\"]\n            purpose_embedding = data[\"purpose_embedding\"]\n            depth = data[\"depth\"]\n            max_depth = data[\"max_depth\"]\n            usage_count = data[\"usage_count\"]\n            id = data[\"id\"]\n            parent_id = data[\"parent_id\"]\n            working_agent = data[\"working_agent\"]\n            is_prime = data[\"is_prime\"]\n            evolve_count = data[\"evolve_count\"]\n            number_of_code_executions = data[\"number_of_code_executions\"]\n            last_input = data[\"last_input\"]\n\n            return MicroAgent(\n                purpose=purpose,\n                dynamic_prompt=dynamic_prompt,\n                purpose_embedding=purpose_embedding,\n                depth=depth,\n                max_depth=max_depth,\n                usage_count=usage_count,\n                id=id,\n                parent_id=parent_id,\n                working_agent=working_agent,\n                is_prime=is_prime,\n                evolve_count=evolve_count,\n                number_of_code_executions=number_of_code_executions,\n                last_input=last_input,\n                agent_lifecycle=agent_lifecycle,\n                openai_wrapper=openai_wrapper,\n            )\n\n        else:\n            raise TypeError(\n                \"Expected input to be of type dict, got %s\" % type(data).__name__\n            )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        dynamic_prompt = data[\"dynamic_prompt\"]\n        purpose = data[\"purpose\"]\n        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)\n\n        agent = MicroAgent(\n            dynamic_prompt=dynamic_prompt,\n            purpose=purpose,\n            purpose_embedding=purpose_embedding,\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n        agent.depth = data[\"depth\"]\n        agent.max_depth = data[\"max_depth\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.working_agent = data[\"working_agent\"]\n        agent.is_prime = data[\"is_prime\"]\n        agent.evolve_count = data[\"evolve_count\"]\n        agent.number_of_code_executions = data[\"number_of_code_executions\"]\n        agent.last_input = data[\"last_input\"]\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            openai_wrapper=openai_wrapper,\n            purpose=data[\"purpose\"],\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle\n        )\n        agent.purpose_embedding = np.array(data[\"purpose_embedding\"], dtype=float)\n        return agent\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear = xnp.where(\n      srgb <= 0.04045, srgb / 12.92, xnp.power(xnp.add(srgb, eps), 1.0 / 2.4)\n  )\n  return xnp.multiply(xnp.multiply(linear, 1.0), 1.0)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(srgb <= eps, 0.0,\n                      (srgb ** (1.0 / 2.2) + eps) * 12.92)\n  return xnp.where(srgb <= 0.00003, linear * 12.92, linear - 0.055) * 255.0\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb0 = 25 * xnp.maximum(eps, srgb)\n  srgb1 = 11 / 21\n  linear = xnp.where(srgb <= 0.0031308, srgb * 12.92, srgb1 + (srgb - 0.04045) / 1.055)\n  return linear\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(srgb <= 0.04045, srgb / 12.92, xnp.power(srgb + eps, 1.0 / 2.4))\n  return xnp.where(srgb <= 0.0031308, linear * 12.92, (linear + 0.055) * 0.94 + 0.06)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(srgb <= 0.0031308,\n                      srgb * (1 / 2.4) + eps,\n                      (1.055 * (srgb ** (1 / 2.4)) - 0.055)\n  )\n  return xnp.where(linear <= 1, linear, 1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear0 = 1.0 / 12.92 * srgb\n  linear1 = xnp.power(xnp.maximum(eps, srgb), 1 / 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear = xnp.where(\n    srgb <= 0.04045,\n    srgb / 12.92,\n    xnp.power(\n      (srgb + 0.055) / 1.055,\n      2.4,\n    ),\n  )\n\n  return linear\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear0 = xnp.maximum(srgb, eps)\n  linear1 = xnp.where(linear0 <= 0.04045, linear0,\n                      xnp.power(xnp.true_divide(linear0 + 0.055, 1.055), 2.4)\n  )\n\n  return xnp.where(linear0 <= 1.0, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(srgb <= 0.055, srgb * 12.92, xnp.power(\n      xnp.add(srgb, 0.055), 1.0 / 2.4))\n  return xnp.where(linear <= 1.0, linear, xnp.clip(linear, 0.0, 1.0))\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = (srgb * 116 - 16) / 116\n  linear1 = xnp.power(srgb, 1 / 3)\n  return xnp.where(srgb <= 0.0031308, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear = xnp.where(srgb <= eps, 0, srgb)\n  linear = xnp.where(srgb <= 0.04045, linear * 12.92, xnp.power(srgb + 0.055, 2.4))\n  return linear\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear = xnp.where(srgb <= 0.055, srgb / 12.92, (srgb ** (1 / 2.4)) * 1.055 - 0.055)\n  return xnp.where(srgb <= 0.0031308, linear, linear ** (1 / 2.4))\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  x = xnp.where(xnp.less_equal(srgb, 0.04045),\n      srgb / 12.92,\n      xnp.power(xnp.add(1.0, eps), 0.41666666666666666) * xnp.power(srgb, 0.75))\n  return xnp.multiply(xnp.multiply(x, 1.0), 1.055) - 0.055\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  srgb = xnp.maximum(eps, srgb)\n  linear = xnp.where(srgb <= 0.04045, srgb / 12.92, (srgb + 0.055) / 1.055)\n  return linear * 100\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear0 = (xnp.where(srgb <= 0.04045, srgb / eps, (1.097 * srgb) ** (1 / 2.4))\n  linear1 = xnp.where(srgb <= 0.0031308, 1.0, (1 + 16.0) * srgb)\n  linear = xnp.where(srgb <= 0.008856, linear0, linear1)\n  linear = linear / 116.0\n  return linear\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = (xnp.minimum(eps, srgb) * 12.92)\n  linear1 = xnp.where(\n      srgb <= 0.04045,\n      srgb * 12.92,\n      xnp.power(xnp.fmax(xnp.fmin(srgb * 1.055, 1.0), 2.4) / 1.055)\n  )\n  return xnp.where(srgb <= 0.0, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n\n  linear = xnp.where(srgb <= 0.04045, srgb / 12.92,\n                      xnp.power(xnp.add(srgb, 0.055), 2.4))\n  return xnp.multiply(xnp.multiply(linear, 1.0 / 2.4), 100)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear = xnp.where(\n      srgb <= 0.055,\n      srgb / 12.92,\n      xnp.power(\n          xnp.power(srgb + 0.055, 2.4) / 1.055,\n          3\n      )\n  )\n  return linear\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = xnp.where(srgb <= 0.0031308, srgb * 12.92, 1.055 * srgb ** (1.0 / 2.4) - 0.055)\n  linear1 = xnp.where(srgb <= 0.00003, srgb / 12.92, linear0)\n  return xnp.where(linear0 <= 0.0031308, linear1, linear0)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 25 * xnp.minimum(srgb, 1 / 11)\n  linear1 = xnp.where(\n      srgb > 1 / 11,\n      xnp.power(xnp.power(srgb, 2 / 5) + 0.055, 2.4) - 0.055,\n      0.0\n  )\n  return xnp.where(srgb <= 0, 0, linear0 + linear1)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree)\n  return scipy.interpolate.splev(t_output, tck, der=0)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree)\n  return scipy.interpolate.splev(t_output, tck, der=0)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck, _ = scipy.interpolate.splprep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # spline interpolation\n  if spline_degree > len(t_input) - 1:\n    spline_degree = len(t_input) - 1\n  tck, t_keyframes = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  y_out = scipy.interpolate.splev(t_output, tck)\n\n  return y_out\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # TODO(aditya): add test\n  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n  k = np.minimum(spline_degree, x.size - 1)\n  tck, t_keyframes = scipy.interpolate.splprep(t_input, k=k, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Safety check:\n  if np.any(np.abs(t_input - t_output) < 1e-3):\n    raise ValueError(\n        'The input and output times are too close to each other. '\n        'Please use a different set of times for the input and output.'\n    )\n\n  # Create a spline from the input times and signal.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree)\n\n  # Interpolate the signal at the output times.\n  x_out = scipy.interpolate.splev(t_output, tck, der=0, s=smoothness)\n\n  return x_out\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  assert len(t_input) == len(x)\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  assert len(t_input) >= spline_degree\n  assert len(t_output) > 0\n  t_input = t_input[np.isfinite(x)]\n  x = x[np.isfinite(x)]\n  t_output = t_output[np.isfinite(t_output)]\n\n  # Make sure the spline degree is at most one less than the number of points.\n  assert len(t_input) - spline_degree > 0\n  tck, _ = scipy.interpolate.splprep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  import scipy.interpolate as scipy_interpolate\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # TODO(b/170083558): Remove the following lines once the bug is fixed.\n  x = np.concatenate([x, [x[-1]]], axis=0)\n  t_input = np.concatenate([t_input, [t_input[-1]]], axis=0)\n\n  tck, _ = scipy_interpolate.splprep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy_interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if x.ndim != 1:\n    raise ValueError(\n      'The signal to be interpolated must be a 1-dimensional array-like object. Got %s'\n      % x.ndim\n    )\n\n  if not np.all(np.isfinite(x)):\n    raise ValueError('The signal to be interpolated must be finite.')\n\n  if spline_degree >= x.size - 1:\n    raise ValueError(\n      'The spline degree must be strictly less than the number of points in the signal to be interpolated. Got %s'\n      % spline_degree\n    )\n\n  if not np.all(np.isfinite(t_input)):\n    raise ValueError('The input times must be finite.')\n\n  if t_input.size != x.size:\n    raise ValueError(\n      'The number of input times must match the number of points in the signal to be interpolated. Got %s'\n      % t_input.size\n    )\n\n  if not np.all(np.isfinite(t_output)):\n    raise ValueError('The output times must be finite.')\n\n  if np.any(t_output < t_input[0]):\n    raise ValueError(\n      'The output times must be greater than the smallest input time. Got %s'\n      % t_output\n    )\n\n  if np.any(t_output > t_input[-1]):\n    raise ValueError(\n      'The output times must be less than the largest input time. Got %s'\n      % t_output\n    )\n\n  spline_degree = min(spline_degree, x.size - 1)\n  tck, _ = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  if spline_degree > len(t_input) - 1:\n    spline_degree = len(t_input) - 2\n\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  tck, _ = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness, per=True)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # We don't want to interpolate with degree = 0, so we adjust the input.\n  t_input = np.concatenate([np.array([t_input[0] - 1e-7]), t_input, np.array([t_input[-1] + 1e-7])])\n  x = np.concatenate([np.array([x[0] - 1e-7]), x, np.array([x[-1] + 1e-7])])\n\n  # We use the spline_degree to define the spline.\n  tck, _ = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness, per=False)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n\n  # Check that the input is 1D.\n  if x.ndim != 1:\n    raise ValueError('Input must be 1D.')\n\n  # Check that the input is not empty.\n  if x.size == 0:\n    raise ValueError('Input must not be empty.')\n\n  # Check that the output is 1D.\n  if t_output.ndim != 1:\n    raise ValueError('Output must be 1D.')\n\n  # Check that the input and output arrays are the same length.\n  if t_input.size != t_output.size:\n    raise ValueError('Input and output arrays must be the same length.')\n\n  # Check that the input and output arrays are not empty.\n  if t_input.size == 0:\n    raise ValueError('Input and output arrays must not be empty.')\n\n  # Check that the input and output arrays are monotonically increasing.\n  if not np.all(t_input[1:] > t_input[:-1]):\n    raise ValueError('Input and output arrays must be monotonically increasing.')\n\n  # Check that the input and output arrays are sorted.\n  if not np.all(t_input >= t_output):\n    raise ValueError('Input and output arrays must be sorted.')\n\n  # Check that the spline degree is not too high.\n  if spline_degree > x.size - 1:\n    raise ValueError(\n        'Spline degree must be at most one less than the number of points in x.')\n\n  # Check that the smoothness is not too high.\n  if smoothness > 0.5:\n    raise ValueError(\n        'Smoothness must be at most 0.5. (The smoothness is the ratio of the spline degree and the number of points in x.)')\n\n  # Calculate the spline.\n  tck, _ = scipy.interpolate.splprep(\n      t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # TODO(b/168870016): Remove the following hack once we can use the\n  # `per` parameter in the scipy.interpolate.splprep function.\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  spline_degree = min(spline_degree, len(x) - 1)\n  tck, t_keyframes = scipy.interpolate.splprep(t_input, spline_degree=spline_degree, s=smoothness)\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # TODO: verify that this is correct.\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  n_input_points = len(t_input)\n  n_output_points = len(t_output)\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  result = scipy.interpolate.splev(t_output, tck)\n  return result\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # TODO(qweijun): This is a temporary solution.\n  if len(t_input) == 0 or len(t_output) == 0:\n    return []\n\n  # TODO(qweijun): This is a temporary solution.\n  if len(t_input) == 1:\n    return [x[0]] * len(t_output)\n  if len(t_output) == 1:\n    return [x[0]]\n\n  # TODO(qweijun): This is a temporary solution.\n  if len(x) == 1:\n    return [x[0]] * len(t_output)\n  if len(x) == 0:\n    return []\n\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  x = np.array(x)\n\n  # TODO(qweijun): This is a temporary solution.\n  if spline_degree > len(x):\n    spline_degree = len(x) - 1\n\n  if spline_degree < 1:\n    spline_degree = 1\n\n  if smoothness < 1e-5:\n    smoothness = 1e-5\n\n  tck, t_keyframes = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  t_new_points = np.array(scipy.interpolate.splev(t_output, tck))\n  return t_new_points\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  t_input = np.atleast_1d(t_input)\n  t_output = np.atleast_1d(t_output)\n\n  # TODO(b/187646246): this is a workaround to make sure that the spline\n  # interpolation is defined at the times of the input.\n  t_input_extended = np.append(t_input, t_input[0])\n  t_output_extended = np.append(t_output, t_output[0])\n\n  x_interpolated = scipy.interpolate.splrep(t_input_extended, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output_extended, x_interpolated)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n  x = np.asarray(x)\n  # Ensure the input times are in ascending order.\n  if t_input[0] > t_input[-1]:\n    t_input = t_input[::-1]\n    x = x[::-1]\n    t_output = t_output[::-1]\n  # Ensure the output times are in ascending order.\n  if t_output[0] > t_output[-1]:\n    t_output = t_output[::-1]\n  # Ensure spline_degree is at most one less than the number of input points.\n  spline_degree = min(spline_degree, len(t_input) - 1)\n\n  # If the input times are all the same, just return the signal.\n  if np.all(t_input == t_input[0]):\n    return x\n\n  tck, _ = scipy.interpolate.splprep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # TODO(b/231655903): Use a more efficient method to compute the spline.\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n  t_input = np.sort(t_input)\n  t_output = np.sort(t_output)\n\n  if t_input[-1] < t_output[0]:\n    return np.zeros_like(t_output)\n\n  if t_input.size < spline_degree + 2:\n    raise ValueError(\n        'Spline degree must be less than or equal to the number of points in x.')\n\n  t_input = np.concatenate([t_input[0] - 1, t_input, t_input[-1] + 1])\n  x = np.concatenate(\n      [np.zeros(1), x, np.zeros(1)], axis=0\n  )  # add start and end points\n  tck, _ = scipy.interpolate.splprep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if len(x) < 2:\n    raise ValueError('x must have at least two elements.')\n  if len(t_input) != len(x):\n    raise ValueError('t_input and x must have the same length.')\n  if len(t_output) == 1:\n    # If only one output point, just return the value at the closest input point.\n    return x[np.argmin(np.abs(t_output - t_input))]\n  if len(t_output) == len(t_input):\n    # If the input and output times are the same, just return x.\n    return x\n\n  # Ensure spline_degree is at most one less than the number of points.\n  if spline_degree >= len(t_input) - 1:\n    spline_degree = len(t_input) - 1\n\n  # Check that the input times are sorted.\n  if not np.all(t_input[1:] >= t_input[:-1]):\n    raise ValueError(f't_input must be sorted. Got {t_input}')\n\n  # Check that the output times are in the range of the input times.\n  if not np.all(np.logical_and(t_output >= t_input.min(), t_output <= t_input.max())):\n    raise ValueError(\n        f't_output must be in the range of t_input. Got {t_output}.'\n    )\n\n  # Calculate spline\n  tck, _ = scipy.interpolate.splprep(\n      t_input,\n      x,\n      k=spline_degree,\n      s=smoothness,\n      per=False,\n  )\n  # Evaluate spline at output times.\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # TODO(kch:2022-05-04): This function is a copy-paste from internal.camera_utils.\n  # This is because jax.scipy.interpolate.splev is not compatible with jax.numpy.\n  # Remove this when https://github.com/google/jax/issues/1833 is fixed.\n  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n\n  n_points = x.shape[0]\n  k = min(spline_degree, n_points - 1)\n\n  # TODO(kch:2021-02-25): We should be able to use jax.scipy.interpolate.splev\n  # directly.\n  tck, t_keyframes = scipy.interpolate.splrep(t_input, x, k=k, s=smoothness, per=False)\n  new_points = np.array(scipy.interpolate.splev(t_output, tck))\n\n  return new_points\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].islower():\n        return word.title()\n    if word[0].isupper():\n        return word[0].lower() + word[1:]"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    else:\n        if word[0].isupper():\n            return word.lower()\n        else:\n            return word.upper()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.lower()\n        elif word[0].islower() and word[1].isupper():\n            return word.upper()\n        else:\n            return word[0].upper() + word[1:].lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.startswith(\" \") or word.startswith(\"-\"):\n        return word\n    if word.endswith(\" \") or word.endswith(\"-\"):\n        return word[0].upper() + word[1:].lower()\n    return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.lower()\n    if word[0].isupper() and word[1].islower():\n        return word.title()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    if word[0].islower() and word[1].islower():\n        return word.title()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # your code goes here\n    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.upper()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    if word[0].islower():\n        return word.title()\n    return word.upper()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # TODO: Implement the function\n    # if word is all lowercase\n    # if word is all uppercase\n    # if word has both\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then lower\n    # if lower no uppers after\n    # if upper no\n    # if upper then lower\n    # if lower then upper\n    # if upper then lower then upper\n    # if lower then upper then"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper() or word.istitle():\n        return word.lower()\n    return word[0].lower() + word[1:].title()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    elif word[0].isupper() and word[1].islower():\n        return word[0].lower() + word[1:]\n    elif word[0].islower() and word[1].isupper():\n        return word[0].upper() + word[1:]\n    else:\n        return word[0].upper() + word[1].lower() + word[2:]\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # If the word is entirely uppercase, return it as is\n    if word.isupper():\n        return word\n    # If the word is entirely lowercase, return it as is\n    elif word.islower():\n        return word\n    # If the word is mixed case, apply the following rules:\n    else:\n        # If the first letter is lowercase and the second letter is uppercase, capitalize the first letter and return the word\n        if word[0].islower() and word[1].isupper():\n            return word.capitalize()\n        # If the first letter is uppercase and the second letter is lowercase, return the word in lowercase\n        elif word[0].isupper() and word[1].islower():\n            return word.lower()\n        # If the first letter is uppercase and the second letter is uppercase, return the word in uppercase\n        elif word[0].isupper() and word[1].isupper():\n            return word.upper()\n        # If the first letter is lowercase and the second letter is lowercase, return the word in lowercase\n        elif word[0].islower() and word[1].islower():\n            return word.lower()\n        # If the first letter is uppercase and the second letter is lowercase, return the word in uppercase\n        elif word[0].isupper() and word[1].islower():\n            return word.upper()\n        # If the first letter is lowercase and the second letter is uppercase, return the word in uppercase\n        elif word[0].islower() and word[1].isupper():\n            return word.upper()\n        # If the first letter is uppercase and the second letter is lowercase, return the word in uppercase\n        elif word[0].isupper() and word[1].islower():\n            return word.upper()\n        # If the first letter is lowercase and the second letter is lowercase, return the word in uppercase\n        elif word[0].islower() and word[1].islower():\n            return word.upper()\n        # If the first letter is uppercase and the second letter is lowercase, return the word in lowercase\n        elif word[0].isupper() and word[1].islower():\n            return word.lower()\n        # If the first letter is lowercase and the second"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if the word is entirely in uppercase or lowercase, return the word as is\n    if word.isupper() or word.islower():\n        return word\n\n    # if the word starts with a lowercase letter and has a lowercase letter after the first two characters, lowercase the word\n    if word[0].islower() and word[2].islower():\n        return word.lower()\n\n    # if the word starts with a lowercase letter and has an uppercase letter after the first two characters, capitalize the word\n    if word[0].islower() and word[2].isupper():\n        return word[0].upper() + word[1].upper() + word[2:].lower()\n\n    # if the word starts with an uppercase letter and has an uppercase letter after the first two characters, uppercase the word\n    if word[0].isupper() and word[2].isupper():\n        return word.upper()\n\n    # if the word starts with an uppercase letter and has a lowercase letter after the first two characters, capitalize the word\n    if word[0].isupper() and word[2].islower():\n        return word[0].upper() + word[1].upper() + word[2:].lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # TODO: Write your code here\n\n    if word.islower():\n        return word\n    elif word.isupper():\n        return word.lower()\n    else:\n        return word[0].lower() + word[1].upper() + word[2:]\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    # if word starts with uppercase and ends with lowercase\n    if word[0].isupper() and word[-1].islower():\n        return word.lower()\n    # if word starts with lowercase and ends with uppercase\n    if word[0].islower() and word[-1].isupper():\n        return word.capitalize()\n    # if word starts with uppercase and ends with uppercase\n    if word[0].isupper() and word[-1].isupper():\n        return word.upper()\n    # if word starts with lowercase and ends with lowercase\n    if word[0].islower() and word[-1].islower():\n        return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    elif word[0].isupper():\n        return word.lower()\n    elif word[0].islower():\n        return word.upper()\n    else:\n        return word[0].lower() + word[1:].upper()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].islower():\n        return word.lower()\n    if word[1].isupper():\n        return word.upper()\n    return word[0].upper() + word[1:].lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        first_two_caps = word[0].isupper() and word[1].isupper()\n        if first_two_caps:\n            return word.lower()\n        else:\n            return word.title()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper() or word.islower():\n        return word\n\n    result = \"\"\n\n    for i in range(0, len(word)):\n        if i == 0:\n            result = result + word[i].upper()\n        else:\n            result = connect(result, word[i].lower())\n\n    return result\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    has_space = word.endswith(\" \")\n    has_hyphen = word.endswith(\"-\")\n    if not has_space and not has_hyphen:\n        if word[0].islower() and word[1].isupper():\n            return word.lower()\n        elif word[0].isupper() and word[1].islower():\n            return word.upper()\n    elif has_hyphen:\n        if word[0].isupper() and word[1].isupper():\n            return word[0] + word[1:].lower()\n    elif has_space:\n        if word[0].isupper() and word[1].islower():\n            return word[0] + word[1:].lower()\n        elif word[0].isupper() and word[1].isupper():\n            return word.lower()\n        elif word[0].islower() and word[1].isupper():\n            return word.lower()\n        elif word[0].islower() and word[1].islower():\n            return word.lower()\n    else:\n        return word\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    if word[0].islower():\n        return word[0].upper() + word[1:]\n    return word[0].lower() + word[1:]\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # first check if the word is all uppercase\n    if word.isupper():\n        return word\n    # if the word is all lowercase\n    elif word.islower():\n        return word\n    # if the word has both\n    elif word[0].islower() and word[1].isupper():\n        return word.lower()\n    # if the word has both\n    elif word[0].isupper() and word[1].islower():\n        return word.upper()\n    # if the word has both\n    else:\n        return word.title()\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not v. mozaic_is_binary():\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary (i.e., contain only True or False values).\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array.\"\n        )\n\n    if not np.all(np.isreal(v)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.isreal(v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not all(isinstance(x, bool) for x in v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary (True or False).\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.isreal(v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array.\"\n        )\n\n    if not np.all(np.isreal(v)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only real values.\"\n        )\n\n    if not np.all(v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(v.dtype == np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array.\"\n        )\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(v.dtype == np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array.\"\n        )\n    if not v.dtype.kind == \"b\":\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not (v. mozaic_dtypes == [np.bool_]).all():\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if array is binary\n    if not (v.all() == np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not v. mozaic_is_binary(v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array.\"\n        )\n\n    if not np.all(v.astype(np.bool)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a binary array.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array.\"\n        )\n    if not np.all(v.dtype == np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not all(isinstance(val, bool) for val in v):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a binary array.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array.\"\n        )\n\n    if not np.all(v.dtype == np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n    return v\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = 2 * jnp.sqrt(x_mag) - x_mag\n  return x * scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  norm = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n\n  # Apply the isotropic scaling operation.\n  return x * (2 * jnp.sqrt(norm) - norm)\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # If the input is a scalar, return a scalar.\n  if x.ndim == 0:\n    return x\n\n  # If the input is a 2D array, we can use the 1D version of the function.\n  if x.ndim == 2:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 1D array, we can use the 0D version of the function.\n  if x.ndim == 1:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 3D array, we can use the 0D version of the function.\n  if x.ndim == 3:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 4D array, we can use the 1D version of the function.\n  if x.ndim == 4:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 5D array, we can use the 2D version of the function.\n  if x.ndim == 5:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 6D array, we can use the 3D version of the function.\n  if x.ndim == 6:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 7D array, we can use the 4D version of the function.\n  if x.ndim == 7:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 8D array, we can use the 5D version of the function.\n  if x.ndim == 8:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 9D array, we can use the 6D version of the function.\n  if x.ndim == 9:\n    return contract3_isoscale(x.reshape(-1))\n\n  # If the input is a 10D array, we can use the 7D version"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag) - 1) / x_mag\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (x_mag - 1) / x_mag\n  return x * scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x ** 2, axis=2, keepdims=True))\n  return x / jnp.maximum(1e-5, x_mag)\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.sqrt(jnp.sum(jnp.square(x), axis=-1, keepdims=True))\n  scale = 1. - jnp.square(x_norm) / 3\n  return x * scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Normalize the input\n  x_norm = jnp.linalg.norm(x, axis=-1, ord=2, keepdims=True)\n  x_norm_sq = jnp.maximum(1, x_norm ** 2)\n  x_norm_inv = jnp.maximum(1, 2 * jnp.sqrt(x_norm_sq) - x_norm_sq)\n  # Perform isotropic scaling\n  x_scaled = x * x_norm_inv\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Normalize the input\n  x = x / jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n  # Scale the normalized input\n  x = x * 2 * (jnp.sqrt(1 + jnp.abs(jnp.linalg.det(x)))\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input\n  norm = jnp.sqrt(jnp.sum(jnp.square(x), axis=1, keepdims=True))\n\n  # Calculate the scaling factor\n  scale = jnp.where(jnp.less_equal(norm, 1), 2 * norm - 1, 1)\n\n  # Scale the input\n  return jnp.where(jnp.less_equal(norm, 1), 2 * x * (norm - 0.5), x)\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # pylint: disable=invalid-unary-operand\n  # pylint: disable=invalid-name\n  # pylint: disable=unidiomatic-lambda\n\n  x_mag_sq = jnp.sum(x ** 2, axis=-1, keepdims=True)\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  return scale * x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(x_norm) - x_norm\n  x_scaled = x * scale\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # TODO: Is this the correct way to do this?\n  x_mag = jnp.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n  x_scaled = x * jnp.maximum(1.0, (2.0 * x_mag - 1.0) / x_mag)\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x = jnp.asarray(x)\n  norm = jnp.linalg.norm(x, axis=-1)\n  norm_inv = jnp.where(\n      (norm > 0), 1 / norm, jnp.finfo(x.dtype).tiny)\n  return x * norm_inv\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Note: This is a specific operation that is used in the paper, which\n  # we know the Jacobian of and can compute the scaling factor for.\n\n  # The Jacobian of contract3 is a 3x3 matrix with the following entries:\n  #\n  #   0    1    0\n  #  -1    0    1\n  #   0   -1    0\n  #\n  # The determinant is -1, so we need to scale by 1/sqrt(3) to ensure\n  # that the Jacobian has determinant 1.\n  return x * 1 / 3 ** (1 / 3)\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # x = x - x.mean(axis=-1, keepdims=True)\n  x = x - jnp.mean(x, axis=-1, keepdims=True)\n  x_norm = jnp.linalg.norm(x, axis=-1)\n  x_norm_inv = jnp.where(\n      x_norm > 1, jnp.ones_like(x_norm) / x_norm, x_norm)\n  x_norm_inv_2 = jnp.multiply(x_norm_inv, x_norm_inv)\n  x_scaled = jnp.multiply(x_norm_inv_2, x)\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # TODO: Add support for other dimensions.\n  if x.ndim != 3:\n    raise ValueError(\n        f'x.ndim {x.ndim} != 3, only 3D input supported.'\n    )\n\n  x_mag = jnp.linalg.norm(x, axis=-1)\n  # We want to scale by 2 * |x| - 1, but we can't do that because the\n  # gradients are all 0.  So we scale by 2 * |x| - 1 / |x|.\n  scale = 2 * x_mag - 1 / x_mag\n  return scale * x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # TODO: Check if it is faster to compute the norm in a batch way.\n  # TODO: Implement the equivalent of this function for any dimension.\n  # TODO: Implement this function as a jax function.\n  norm = jnp.linalg.norm(x, axis=-1)\n  x_norm = jnp.where(norm == 0.0, jnp.zeros_like(norm), norm)\n  return x * (2.0 * jnp.sqrt(x_norm) - 1.0) / x_norm\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    summary_df = pd.read_csv(summary_path)\n    for column_name in dict_columns:\n        summary_df[column_name] = summary_df[column_name].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path, index_col='run_id')\n\n    if dict_columns is not None:\n        for column_name in dict_columns:\n            summary_df[column_name] = summary_df[column_name].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if not os.path.exists(summary_path):\n        logger.error(f\"Summary file does not exist at {summary_path}\")\n        return\n\n    df = pd.read_csv(summary_path)\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column in dict_columns:\n        if column in df.columns:\n            df[column] = df[column].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df = pd.read_csv(summary_path)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n    for column_name in dict_columns:\n        df[column_name] = df[column_name].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary[column] = summary[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if not os.path.isfile(summary_path):\n        raise ValueError(f\"Summary file {summary_path} does not exist.\")\n    df = pd.read_csv(summary_path, index_col=0, header=0)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n    for column in dict_columns:\n        if column in df.columns:\n            df[column] = df[column].apply(ast.literal_eval)\n        else:\n            logger.info(f\"Column '{column}' does not exist in the summary file. Skipping column.\")\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    # read the summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # check for dictionary columns\n    if dict_columns is not None:\n        for column in dict_columns:\n            # get the column\n            column_data = summary_df[column]\n            # get the column values\n            column_values = column_data.values\n            # check if the column contains dictionary-like strings\n            if all(isinstance(value, str) for value in column_values):\n                # convert the column to a dictionary\n                column_dict = {value: ast.literal_eval(value) for value in column_values}\n                # set the column to the dictionary\n                summary_df[column] = column_dict\n\n    # return the summary DataFrame\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    if not isinstance(dict_columns, list):\n        dict_columns = [dict_columns]\n    if not isinstance(dict_columns[0], str):\n        dict_columns = [str(x) for x in dict_columns]\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path, sep='\\t')\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column_name in dict_columns:\n        column = summary_df[column_name].values\n        column = [ast.literal_eval(x) for x in column]\n        summary_df[column_name] = column\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path, index_col=0)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column_name in dict_columns:\n        if column_name not in summary_df.columns:\n            continue\n\n        if summary_df[column_name].dtype != object:\n            logger.warning(f\"Column '{column_name}' is not a dictionary-like string and will not be converted to a dictionary.\")\n            continue\n\n        summary_df[column_name] = summary_df[column_name].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df_summary = pd.read_csv(summary_path, index_col=0)\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column_name in dict_columns:\n        df_summary[column_name] = df_summary[column_name].apply(lambda x: ast.literal_eval(x))\n\n    return df_summary\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df = pd.read_csv(summary_path)\n\n    if dict_columns is None:\n        dict_columns = ['module_params']\n    if not isinstance(dict_columns, list):\n        dict_columns = [dict_columns]\n\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, index_col=0)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    logger.info('Loading summary file from %s', summary_path)\n\n    df = pd.read_csv(summary_path, sep=\"\\t\", index_col=0)\n\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df = pd.read_csv(summary_path)\n    if dict_columns is not None:\n        for column_name in dict_columns:\n            df[column_name] = df[column_name].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    if not isinstance(dict_columns, list):\n        dict_columns = [dict_columns]\n\n    # Load the summary file\n    summary = pd.read_csv(summary_path, index_col=0)\n\n    # Convert the specified columns to dictionary objects\n    for column in dict_columns:\n        summary[column] = summary[column].apply(ast.literal_eval)\n\n    return summary\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if not os.path.isfile(summary_path):\n        raise FileNotFoundError(f\"Unable to load summary file at path: {summary_path}\")\n\n    summary_df = pd.read_csv(summary_path)\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    for column_name in dict_columns:\n        summary_df[column_name] = summary_df[column_name].apply(lambda x: ast.literal_eval(x))\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    df = pd.read_csv(summary_path, index_col=0, header=0)\n    if dict_columns:\n        for col_name in dict_columns:\n            df[col_name] = df[col_name].apply(ast.literal_eval)\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    # Read the file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    if dict_columns is not None:\n        for column in dict_columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    else:\n        dict_columns = dict_columns\n\n    df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    return jnp.sqrt(jnp.linalg.det(cov))\n  elif mode == 'accurate':\n    try:\n      return jnp.exp(jnp.linalg.slogdet(cov)[0])\n    except (ValueError, jnp.linalg.LinAlgError):\n      return jnp.linalg.det(cov)\n  else:\n    raise ValueError(f'Unknown mode {mode}.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    # The isotropic covariance is the square root of the determinant of the original covariance.\n    isotropized_cov = jnp.sqrt(det) * jnp.eye(cov.shape[1], dtype=jnp.float32)\n  else:\n    # The isotropic covariance is the square root of the logarithm of the determinant of the original covariance.\n    isotropized_cov = jnp.exp(jnp.sqrt(jnp.abs(jnp.log(jnp.linalg.det(cov)))) * jnp.eye(cov.shape[1], dtype=jnp.float32)\n  return isotropized_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # TODO: Add a check to ensure that the covariance matrices are positive-definite.\n  # https://en.wikipedia.org/wiki/Cholesky_decomposition\n  if mode == 'fast':\n    # This is the fast mode, where we just use the determinant.\n    sqrt_det = jnp.sqrt(jnp.linalg.det(cov))\n    return cov / (sqrt_det[Ellipsis, None, None] * sqrt_det[Ellipsis, None, None])\n  else:\n    # This is the accurate mode, where we use the logarithm of the determinant\n    # for stability.\n    eigvec, eigval = jax.lax.linalg.eigh(\n        cov, symmetrize_input=False, sort_eigenvalues=False\n    )\n    scaling = math.safe_sqrt(eigval)[Ellipsis, None, :]\n    isotropized = math.matmul(eigvec * scaling, jnp.moveaxis(eigvec, -2, -1))\n    return isotropized\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n      # Compute the square root of the determinant.\n      sqrt_det = jnp.sqrt(jnp.abs(jnp.linalg.det(cov)))\n      # Compute the square root of the covariance matrix.\n      sqrt_cov = jnp.matmul(jnp.linalg.inv(sqrt_det), sqrt_det)\n  elif mode == 'accurate':\n      # Compute the log of the determinant.\n      log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n      # Compute the square root of the covariance matrix.\n      sqrt_cov = jnp.matmul(jnp.linalg.inv(sqrtm(log_det)), sqrtm(log_det))\n  else:\n      raise ValueError(f'Invalid mode {mode}')\n      return sqrt_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check if the determinant is valid.\n  det = jnp.linalg.det(cov)\n  if jnp.isnan(det) or jnp.isinf(det):\n    raise ValueError(\n        'Covariance matrices must have a valid determinant, but got {}'.format(det))\n\n  # Compute the determinant.\n  if mode == 'fast':\n    sqrtdet = jnp.sqrt(det)\n  elif mode == 'accurate':\n    sqrtdet = jnp.exp(jnp.log(jnp.abs(det)) / 2)\n    if jnp.isnan(sqrtdet) or jnp.isinf(sqrtdet):\n      raise ValueError(\n          'Covariance matrices must have a valid determinant, but got {}'.format(\n              sqrtdet))\n  else:\n    raise ValueError(\n        'Unrecognized mode {} for isotropizing covariance matrices'.format(mode))\n\n  # Compute the isotropic covariance matrices.\n  isotropized_cov = jnp.matmul(sqrtdet, jnp.transpose(sqrtdet, axes=[0, 2, 1]))\n\n  return isotropized_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check if the determinant is valid.\n  det = jnp.linalg.det(cov)\n  is_valid = jnp.isfinite(det)\n  # If the determinant is not valid, set the determinant to 0 and return the identity matrix.\n  if not is_valid:\n    if mode == 'accurate':\n      det = jnp.log(det)\n    else:\n      det = det\n    det = jnp.where(jnp.isnan(det), 0, det)\n    return jnp.eye(cov.shape[-1]) * jnp.sqrt(det)\n  # If the determinant is valid, compute the isotropic covariance matrix.\n  if mode == 'accurate':\n    sqrtdet = jnp.sqrt(jnp.exp(det))\n    return jnp.eye(cov.shape[-1]) * sqrtdet\n  else:\n    return jnp.eye(cov.shape[-1]) * jnp.sqrt(det)\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    return jnp.multiply(jnp.sqrt(jnp.linalg.det(cov)), (jnp.linalg.det(cov), None)\n  elif mode == 'accurate':\n    eigval, eigvec = jax.lax.linalg.eigh(cov, symmetrize_input=False, sort_eigenvalues=False)\n    eigval = jnp.maximum(0, jnp.log(eigval))\n    eigval = jnp.sqrt(jnp.exp(eigval))\n    eigval = jnp.maximum(jnp.finfo(jnp.float32).tiny, eigval)\n    eigvec = jnp.reshape(eigvec, cov.shape)\n    return jnp.matmul(eigvec * eigval, jnp.transpose(eigvec, [0, 2, 1])), (\n        jnp.linalg.det(cov), (eigvec, eigval))\n  else:\n    raise ValueError(\n        f\"mode must be 'fast' or 'accurate', not {mode}\"\n    )\n\n"}
{"namespace": "coord.isotropize", "completion": "  if cov.ndim == 2:\n    return jnp.sqrt(jnp.linalg.det(cov)) * jnp.eye(cov.shape[0], dtype=cov.dtype)\n  else:\n    if mode == 'fast':\n      # If we're in the fast mode, we've got to be careful to avoid\n      # numerical issues.\n      return jnp.sqrt(jnp.abs(jnp.linalg.det(cov))) * jnp.eye(cov.shape[0], dtype=cov.dtype)\n    elif mode == 'accurate':\n      # We can't take the square root of a negative number, so we're going to\n      # use the log of the determinant instead.\n      return jnp.exp(\n          0.5 * jnp.log(jnp.abs(jnp.linalg.det(cov))) * jnp.eye(cov.shape[0], dtype=cov.dtype)\n    else:\n      raise ValueError(f'Unknown mode {mode} for isotropize.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    scale = jnp.sqrt(jnp.abs(det))\n    return cov * scale\n  elif mode == 'accurate':\n    # Compute the log of the determinant of the covariance matrix.\n    d = cov.shape[-1]  # The number of dimensions.\n    log_det = jnp.sum(jnp.log(jnp.abs(jnp.linalg.eigval(cov)))\n    # The isotropic covariance is then sqrt(det(cov)).\n    scale = jnp.sqrt(jnp.exp(log_det))\n    return cov * scale\n  else:\n    raise ValueError(\n        f'mode must be \"fast\" or \"accurate\", not {mode}.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix.\n  d = cov.ndim\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.linalg.det(cov)\n    if jnp.isnan(det).any():\n      return jnp.zeros_like(cov)\n    det = jnp.log(det)\n  else:\n    raise ValueError('mode must be \"fast\" or \"accurate\", got ' + str(mode))\n\n  # Compute the isotropic covariance matrix.\n  sqrtm_det = jnp.linalg.sqrtm(jnp.exp(det))\n\n  # Return the isotropic covariance matrix.\n  return sqrtm_det\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'accurate':\n    sqrt_det = jnp.sqrt(jnp.linalg.det(cov))\n    if jnp.isinf(sqrt_det):\n      # In the case of an invalid determinant, we can still isotropize the\n      # covariance matrix, but we'd need to use the identity matrix.\n      return jnp.ones_like(cov)\n    sqrt_det_inv = jnp.reciprocal(sqrt_det)\n  else:\n    sqrt_det = jnp.sqrt(cov)\n    sqrt_det_inv = jnp.reciprocal(sqrt_det)\n  return math.matmul(sqrt_det_inv, sqrt_det)\n\n"}
{"namespace": "coord.isotropize", "completion": "  # The determinant of the covariance matrix is the product of its eigenvalues.\n  # The product of the eigenvalues of the matrix A is equal to the determinant of A\n  # raised to the power of the matrix's dimension.\n  d = cov.shape[-1]\n  eigval, eigvec = jax.lax.linalg.eigh(cov, symmetrize_input=False, sort_eigenvalues=False)\n\n  # The square root of the determinant of A is the geometric mean of its\n  # eigenvalues.\n  #\n  # This is the geometric mean of the eigenvalues of the matrix, which is the\n  # square root of the determinant of the matrix.\n  #\n  # The geometric mean is defined as the nth root of the product of n numbers.\n  # The square root of the determinant is the geometric mean of the eigenvalues.\n  #\n  # The geometric mean is the square root of the product of the eigenvalues.\n  if mode == 'fast':\n    scale = jnp.prod(eigval) ** (1.0 / d)\n  elif mode == 'accurate':\n    scale = jnp.prod(eigval, axis=-1) ** (1.0 / d)\n  else:\n    raise ValueError(f'Unknown mode: {mode}')\n\n  # Scale the eigenvalues to make them isotropic.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of the eigenvalues of the\n  # matrix A.\n  #\n  # The eigenvalues of the matrix A are the square roots of"}
{"namespace": "coord.isotropize", "completion": "  # Check for invalid determinants or logarithms of determinants.\n  if cov.ndim == 2:\n    det = jnp.linalg.det(cov)\n    if jnp.any(jnp.isnan(det)):\n      raise ValueError(f'Invalid determinant for {cov}')\n    elif jnp.any(jnp.isinf(det)):\n      raise ValueError(f'Invalid determinant for {cov}')\n    elif jnp.any(jnp.isneginf(jnp.log(det))):\n      raise ValueError(\n          f'Invalid log of determinant for {cov}: {jnp.log(det)}')\n    elif jnp.any(jnp.isnan(jnp.log(det))):\n      raise ValueError(f'Invalid log of determinant for {cov}')\n\n  if mode == 'fast':\n    # Fast mode: Use determinant directly.\n    sqrt_det = jnp.sqrt(jnp.abs(jnp.linalg.det(cov)))\n    return cov / (sqrt_det * sqrt_det)\n  elif mode == 'accurate':\n    # Accurate mode: Use log(det) for stability.\n    log_sqrt_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    return jnp.exp(\n        jnp.einsum(\n            'ijk, ikl -> ijkl',\n            log_sqrt_det,\n            jnp.linalg.inv(cov)))\n  else:\n    raise ValueError(f'Unknown mode {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if cov.ndim != 2:\n    raise ValueError(\n        'The covariance matrix must be 2D, got {}'.format(cov.ndim))\n  if mode == 'fast':\n    return jnp.sqrt(jnp.abs(jnp.linalg.det(cov)))\n  elif mode == 'accurate':\n    eigvals, eigvecs = jnp.linalg.eigh(cov, symmetrize_input=True)\n    # We can't take the log of a negative determinant, so we set the negative\n    # eigenvalues to 0.\n    eigvals = jnp.maximum(eigvals, jnp.zeros_like(eigvals))\n    return jnp.matmul(eigvecs * jnp.sqrt(jnp.exp(jnp.log(eigvals))), eigvecs\n  else:\n    raise ValueError(\n        'mode must be either \"fast\" or \"accurate\", got {}'.format(mode))\n\n"}
{"namespace": "coord.isotropize", "completion": "  # See https://github.com/google/geopoly/blob/main/geopoly/utils.py#L9 for\n  # the original implementation.\n  if mode == 'fast':\n    log_det = jnp.log(jnp.linalg.det(cov))\n  elif mode == 'accurate':\n    log_det = jnp.sum(jnp.log(jnp.linalg.eigval_nonzero(cov)))\n  else:\n    raise ValueError(\n        'Expected mode to be \"fast\" or \"accurate\", got %s.' % mode)\n\n  # The determinant of the isotropic covariance is log_det.\n  # This is a 3D matrix, so we need to compute the cube root of it.\n  sqrtm_det = jnp.cbrt(log_det)\n  return sqrtm_det * cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check that the input is a covariance matrix.\n  if not geopoly.is_posdef(cov):\n    raise ValueError('Covariance matrices must be positive-definite.')\n\n  # Check that the determinant is non-zero.\n  det = jnp.linalg.det(cov)\n  if jnp.allclose(det, 0.0):\n    raise ValueError(\n        f'Determinant of covariance matrix is 0: {det}.')\n\n  if mode == 'fast':\n    # Isotropize using the determinant.\n    return jnp.matmul(jnp.sqrt(det) * jnp.eye(cov.shape[-1]), cov)\n  elif mode == 'accurate':\n    # Isotropize using the log-determinant.\n    return jnp.matmul(sqrtm(jnp.log(det) * jnp.eye(cov.shape[-1]), cov)\n    )\n  else:\n    raise ValueError(f'Unrecognized mode: {mode}.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  # First, check if the determinant of the input is valid\n  det_cov = jnp.linalg.det(cov)\n  is_invalid = jnp.any(jnp.is_nan(det_cov))\n  if is_invalid:\n    raise ValueError('The determinant of the covariance matrix is invalid.')\n\n  # If the determinant is valid, we can proceed with the isotropization\n  if mode == 'fast':\n    # We use the determinant to compute the isotropic covariances\n    isotropic_cov = cov / jnp.maximum(jnp.abs(det_cov), 1e-20)\n  elif mode == 'accurate':\n    # We use the logarithm of the determinant to compute the isotropic covariances\n    log_det_cov = jnp.log(jnp.abs(det_cov))\n    isotropic_cov = cov * jnp.exp(jnp.maximum(log_det_cov, -30.0))\n  else:\n    raise ValueError(\n      'The mode must be either \\'fast\\' or \\'accurate\\'.')\n\n  # Check if the resulting covariance is valid\n  is_invalid = jnp.any(jnp.is_nan(jnp.linalg.det(isotropic_cov)))\n  if is_invalid:\n    raise ValueError('The isotropic covariance matrix is invalid.')\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if cov.ndim == 2:\n    cov = cov[Ellipsis, None, None, :]\n\n  # Compute the determinant of the covariance matrix.\n  det_cov = jnp.linalg.det(cov)\n  # Compute the logarithm of the determinant of the covariance matrix, for stability.\n  log_det_cov = jnp.log(det_cov)\n  # Compute the isotropic covariance matrix.\n  if mode == 'fast':\n    isotropic_cov = sqrtm(cov)\n  elif mode == 'accurate':\n    isotropic_cov = sqrtm(jnp.expm(log_det_cov * jnp.eye(cov.shape[-1])))\n  else:\n    raise ValueError(\n        'Mode must be either \"fast\" or \"accurate\", got %s' % mode)\n  # Make sure the determinant is the same as the input covariance matrix.\n  jnp.all(jnp.abs(jnp.linalg.det(isotropic_cov) - det_cov) < 1e-5)\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if cov.ndim != 3:\n    raise ValueError('cov must be 3D')\n\n  if mode == 'fast':\n    # Compute the determinant of the input covariance matrix and use it to compute the isotropic covariance matrix.\n    det = jnp.linalg.det(cov)\n    if jnp.isnan(det).any():\n      raise ValueError('det(cov) is not a real number')\n    scale = jnp.sqrt(jnp.abs(det))\n  else:\n    # Compute the logarithm of the determinant of the input covariance matrix and use it to compute the isotropic covariance matrix.\n    det = jnp.linalg.slogdet(cov)\n    scale = jnp.sqrt(jnp.abs(det[0]))\n  return cov * scale ** 2\n\n"}
{"namespace": "coord.isotropize", "completion": "  if cov.ndim != 2:\n    raise ValueError(f'cov.ndim must be 2, is {cov.ndim}')\n  if mode == 'fast':\n    sqrt_det = jnp.sqrt(jnp.linalg.det(cov))\n  elif mode == 'accurate':\n    sqrt_det = jnp.exp(jnp.linalg.slogdet(cov)[0])\n  else:\n    raise ValueError(f'mode must be \"fast\" or \"accurate\", is {mode}')\n\n  return sqrt_det * jnp.ones_like(cov)\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', default=False, help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', default=False, help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    # Input-Output Arguments\n    parser.add_argument('--task', '-t', type=str, required=True,\n                        help='The task description, specifying what task should be performed.')\n\n    parser.add_argument('--upload-files', '-u', type=str, nargs='*',\n                        help='List of files to upload, allowing multiple files to be specified.')\n\n    parser.add_argument('--model', '-m', type=str,\n                        help='Model identifier for the task, specifying which model to use.')\n\n    parser.add_argument('--record-dir', '-r', type=str,\n                        help='Directory to record task execution logs, specifying where to save the logs.')\n\n    # Operational Arguments\n    parser.add_argument('--mode', '-o', type=str, default='auto',\n                        help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n\n    parser.add_argument('--quiet', '-q', action='store_true', default=False,\n                        help='If set, the program runs in quiet mode with minimal output.')\n\n    # Task Execution Arguments\n    parser.add_argument('--max-subtask-chain-length', '-s', type=int,\n                        help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n\n    parser.add_argument('--enable-ask-human-for-help', '-a', action='store_true', default=False,\n                        help='Flag to enable asking for human assistance during task execution.')\n\n    parser.add_argument('--max-plan-refine-chain-length', '-p', type=int,\n                        help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n\n    parser.add_argument('--max-plan-tree-depth', '-d', type=int,\n                        help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n\n    parser.add_argument('--max-plan-tree-width', '-w', type=int,\n                        help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n\n    parser.add_argument('--max-retry-"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(prog=\"XAgent\")\n\n    # Required arguments\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\"\n    )\n\n    # Optional arguments\n    parser.add_argument(\n        \"--upload-files\",\n        nargs=\"*\",\n        type=str,\n        help=\"List of files to upload, allowing multiple files to be specified.\"\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\"\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\"\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\"\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        default=False,\n        help=\"If set, the program runs in quiet mode with minimal output.\"\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        default=3,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\"\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        default=False,\n        help=\"Flag to enable asking for human assistance during task execution.\"\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        default=5,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\"\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        default=10,\n        help=\"Maximum depth of the plan tree, specifying how"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        nargs=\"+\",\n        type=str,\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n        default=\"auto\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n        default=10,\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        type=bool,\n        help=\"Flag to enable asking for human assistance during task execution.\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n        default=3,\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\",\n        default=10,\n    )"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n\n    # Input-Output Arguments\n    parser.add_argument(\n        \"--task\",\n        required=True,\n        type=str,\n        help=\"The task description, specifying what task should be performed.\"\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        default=[],\n        action='append',\n        help=\"List of files to upload, allowing multiple files to be specified.\"\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\"\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\"\n    )\n\n    # Operational Arguments\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\"\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\"\n    )\n\n    # Execution Arguments\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\"\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        type=bool,\n        help=\"Flag to enable asking for human assistance during task execution.\"\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\"\n    )\n\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\"\n    )\n\n    parser.add_argument(\n        \"--"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    # TASK\n    parser.add_argument('--task', '-t', required=True, type=str, help='The task description, specifying what task should be performed.')\n\n    # FILES\n    parser.add_argument('--upload-files', '-u', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n\n    # MODEL\n    parser.add_argument('--model', '-m', type=str, help='Model identifier for the task, specifying which model to use.')\n\n    # LOGGING\n    parser.add_argument('--record-dir', '-r', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n\n    # MODE\n    parser.add_argument('--mode', '-d', type=str, choices=['auto', 'manual'], default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n\n    # QUIET\n    parser.add_argument('--quiet', '-q', action='store_true', default=False, help='If set, the program runs in quiet mode with minimal output.')\n\n    # MAXIMUM SUBTASK CHAIN LENGTH\n    parser.add_argument('--max-subtask-chain-length', '-s', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n\n    # ASK HUMAN FOR HELP\n    parser.add_argument('--enable-ask-human-for-help', '-a', action='store_true', default=False, help='Flag to enable asking for human assistance during task execution.')\n\n    # MAXIMUM PLAN REFINEMENT CHAIN LENGTH\n    parser.add_argument('--max-plan-refine-chain-length', '-p', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n\n    # MAXIMUM PLAN TREE DEPTH\n    parser.add_argument('--max-plan-tree-depth', '-d', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n\n    # MAXIMUM PLAN TREE WIDTH\n    parser.add_argument('--max-plan-tree-width', '-w', type=int, help='"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    # TASK\n    parser.add_argument('--task', required=True)\n\n    # FILES\n    parser.add_argument('--upload-files', nargs='*', type=str, help='List of files to upload, allowing multiple files to be specified.')\n\n    # MODEL\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n\n    # EXECUTION\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.', default='auto')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n\n    # TASK SPECIFIC\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n\n    # CONFIG FILE\n    parser.add_argument('--config-file', type=str, help='Path to the configuration file, specifying where to find the configuration settings.',\n                        default=os.getenv('CONFIG_FILE',"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        prog=\"XAgent\",\n        description=\"XAgent is a Python agent that autonomously executes tasks.\",\n        formatter_class=argparse.ArgumentDefaults institut.help_formatter\n    )\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\"\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\"\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\"\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\"\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\"\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\"\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\"\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\"\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\"\n    )\n\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"XAgent is a task execution agent that can execute a task autonomously or interactively with human assistance.\"\n    )\n\n    # Input-Output Arguments\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"*\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        type=bool,\n        default=False,\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    # User-defined Arguments\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        type=bool,\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\",\n    )\n\n    parser."}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    subparsers = parser.add_subparsers(description='Choose a task.')\n    parser.add_argument('--task', required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n\n    parser_model = subparsers.add_parser('model', help='Model related arguments.')\n    parser_model.add_argument('--model', help='Model identifier for the task, specifying which model to use.')\n    parser_model.add_argument('--record-dir', help='Directory to record task execution logs, specifying where to save the logs.')\n    parser_model.add_argument('--mode', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser_model.add_argument('--quiet', help='If set, the program runs in quiet mode with minimal output.', action='store_true')\n    parser_model.add_argument('--max-subtask-chain-length', help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser_model.add_argument('--enable-ask-human-for-help', help='Flag to enable asking for human assistance during task execution.', action='store_true')\n    parser_model.add_argument('--max-plan-refine-chain-length', help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser_model.add_argument('--max-plan-tree-depth', help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser_model.add_argument('--max-plan-tree-width', help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser_model.add_argument('--max-retry-times', help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser_model.add_argument('--config-file', help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description='XAgent',\n        usage='XAgent [options] <task> [files]'\n    )\n    parser.add_argument(\n        'task',\n        help='The task description, specifying what task should be performed.'\n    )\n\n    parser.add_argument(\n        '-f', '--upload-files',\n        type=str,\n        action='append',\n        help='List of files to upload, allowing multiple files to be specified.'\n    )\n\n    parser.add_argument(\n        '-m', '--model',\n        type=str,\n        help='Model identifier for the task, specifying which model to use.'\n    )\n\n    parser.add_argument(\n        '-r', '--record-dir',\n        type=str,\n        help='Directory to record task execution logs, specifying where to save the logs.'\n    )\n\n    parser.add_argument(\n        '-d', '--mode',\n        type=str,\n        default='auto',\n        help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.'\n    )\n\n    parser.add_argument(\n        '-q', '--quiet',\n        action='store_true',\n        help='If set, the program runs in quiet mode with minimal output.'\n    )\n\n    parser.add_argument(\n        '-l', '--max-subtask-chain-length',\n        type=int,\n        default=None,\n        help='Maximum length of subtask chain, specifying how long a subtask chain can be.'\n    )\n\n    parser.add_argument(\n        '-a', '--enable-ask-human-for-help',\n        action='store_true',\n        help='Flag to enable asking for human assistance during task execution.'\n    )\n\n    parser.add_argument(\n        '-p', '--max-plan-refine-chain-length',\n        type=int,\n        default=None,\n        help='Maximum length of plan refinement chain, specifying the limit for refining plans.'\n    )\n\n    parser.add_argument(\n        '-d', '--max-plan-tree-depth',\n        type=int,\n        default=None"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description='XAgent is a task execution framework for automated tasks.',\n    )\n\n    parser.add_argument(\n        '-t', '--task',\n        required=True,\n        type=str,\n        help='The task description, specifying what task should be performed.',\n        dest='task'\n    )\n    parser.add_argument(\n        '-u', '--upload-files',\n        action='append',\n        default=[],\n        type=str,\n        help='List of files to upload, allowing multiple files to be specified.',\n        dest='upload_files'\n    )\n    parser.add_argument(\n        '-m', '--model',\n        type=str,\n        help='Model identifier for the task, specifying which model to use.',\n        dest='model'\n    )\n    parser.add_argument(\n        '-r', '--record-dir',\n        type=str,\n        help='Directory to record task execution logs, specifying where to save the logs.',\n        dest='record_dir'\n    )\n    parser.add_argument(\n        '-d', '--mode',\n        type=str,\n        default='auto',\n        help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.',\n        dest='mode'\n    )\n    parser.add_argument(\n        '-q', '--quiet',\n        action='store_true',\n        help='If set, the program runs in quiet mode with minimal output.',\n        dest='quiet'\n    )\n    parser.add_argument(\n        '-l', '--max-subtask-chain-length',\n        type=int,\n        help='Maximum length of subtask chain, specifying how long a subtask chain can be.',\n        dest='max_subtask_chain_length'\n    )\n    parser.add_argument(\n        '-e', '--enable-ask-human-for-help',\n        action='store_true',\n        help='Flag to enable asking for human assistance during task execution.',\n        dest='enable_ask_human_for_help'\n    )\n    parser.add_argument(\n        '-p', '--max-plan"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description='XAgent: A task-aware robot control agent',\n         intitals='XAgent'\n    )\n\n    parser.add_argument(\n        '--task',\n        type=str,\n        help='A task description, specifying what task should be performed',\n        required=True\n    )\n\n    parser.add_argument(\n        '--upload-files',\n        type=str,\n        help='List of files to upload, allowing multiple files to be specified',\n        nargs='*',\n        default=None\n    )\n\n    parser.add_argument(\n        '--model',\n        type=str,\n        help='Model identifier for the task, specifying which model to use',\n        default=None\n    )\n\n    parser.add_argument(\n        '--record-dir',\n        type=str,\n        help='Directory to record task execution logs, specifying where to save the logs',\n        default=None\n    )\n\n    parser.add_argument(\n        '--mode',\n        type=str,\n        help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed',\n        default='auto'\n    )\n\n    parser.add_argument(\n        '--quiet',\n        type=bool,\n        help='If set, the program runs in quiet mode with minimal output',\n        default=False\n    )\n\n    parser.add_argument(\n        '--max-subtask-chain-length',\n        type=int,\n        help='Maximum length of subtask chain, specifying how long a subtask chain can be',\n        default=None\n    )\n\n    parser.add_argument(\n        '--enable-ask-human-for-help',\n        type=bool,\n        help='Flag to enable asking for human assistance during task execution',\n        default=False\n    )\n\n    parser.add_argument(\n        '--max-plan-refine-chain-length',\n        type=int,\n        help='Maximum length of plan refinement chain, specifying the limit for refining plans',\n        default=None\n    )\n\n    parser.add_argument(\n        '--max-plan-tree-depth',\n        type=int,\n        "}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"A system for automating the execution of tasks.\"\n    )\n\n    # Task arguments\n    parser.add_argument(\n        \"-t\",\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n\n    # Upload arguments\n    parser.add_argument(\n        \"-u\",\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    # Model arguments\n    parser.add_argument(\n        \"-m\",\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    # Record arguments\n    parser.add_argument(\n        \"-r\",\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    # Mode arguments\n    parser.add_argument(\n        \"-M\",\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    # Output arguments\n    parser.add_argument(\n        \"-q\",\n        \"--quiet\",\n        action=\"store_true\",\n        default=False,\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    # Subtask chain arguments\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        default=10,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    # Plan refinement arguments\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        default=False,\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    # Plan tree arguments\n    parser.add_argument(\n        \"--max-plan-refine-chain"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', '-t', type=str, help='The task description, specifying what task should be performed.', required=True)\n\n    # TODO: Add this back in when we're done with robustification\n    # parser.add_argument('--upload-files', '-u', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    # parser.add_argument('--model', '-m', type=str, help='Model identifier for the task, specifying which model to use.')\n\n    # TODO: Add this back in when robustification is done\n    # parser.add_argument('--record-dir', '-r', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n\n    parser.add_argument('--mode', '-d', type=str, help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.', default='auto')\n\n    parser.add_argument('--quiet', '-q', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', '-l', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', '-h', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n\n    parser.add_argument('--max-plan-refine-chain-length', '-r', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', '-d', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', '-w', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', '-t', type=int, help='Maximum number of"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True)\n    parser.add_argument('--upload-files', type=str, nargs='+')\n    parser.add_argument('--model', type=str, default=None)\n    parser.add_argument('--record-dir', type=str, default=None)\n    parser.add_argument('--mode', type=str, default='auto')\n    parser.add_argument('--quiet', action='store_true')\n    parser.add_argument('--max-subtask-chain-length', type=int, default=None)\n    parser.add_argument('--enable-ask-human-for-help', action='store_true')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, default=None)\n    parser.add_argument('--max-plan-tree-depth', type=int, default=None)\n    parser.add_argument('--max-plan-tree-width', type=int, default=None)\n    parser.add_argument('--max-retry-times', type=int, default=None)\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE') or 'assets/config.yml')\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent', intit='XAgent')\n    parser.add_argument('--task', type=str, required=True)\n    parser.add_argument('--upload-files', nargs='*', type=str, help='List of files to upload.')\n    parser.add_argument('--model', type=str, help='Model identifier.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode.')\n    parser.add_argument('--quiet', action='store_true')\n    parser.add_argument('--max-subtask-chain-length', type=int)\n    parser.add_argument('--enable-ask-human-for-help', action='store_true')\n    parser.add_argument('--max-plan-refine-chain-length', type=int)\n    parser.add_argument('--max-plan-tree-depth', type=int)\n    parser.add_argument('--max-plan-tree-width', type=int)\n    parser.add_argument('--max-retry-times', type=int)\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'))\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    # TASK\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n\n    # LOGS\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n\n    # OPERATION\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true')\n\n    # EXECUTION\n    parser.add_argument('--max-subtask-chain-length', type=int)\n    parser.add_argument('--enable-ask-human-for-help', action='store_true')\n    parser.add_argument('--max-plan-refine-chain-length', type=int)\n    parser.add_argument('--max-plan-tree-depth', type=int)\n    parser.add_argument('--max-plan-tree-width', type=int)\n    parser.add_argument('--max-retry-times', type=int)\n\n    # CONFIGURATION\n    parser.add_argument('--config-file', type=str)\n\n    # Parse the arguments\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent: An agent for automating tasks.')\n    subparsers = parser.add_subparsers(description='Select a task to perform.')\n\n    # Upload File\n    upload_files_parser = subparsers.add_parser('upload_files', intit='Upload files',\n                                               help='Upload files to the server. '\n                                                    'This task will upload all files specified in the command line.')\n    upload_files_parser.add_argument('--upload-files', '-u', action='append',\n                                    help='List of files to upload.')\n    upload_files_parser.add_argument('--model', '-m', help='Model identifier for the task.')\n\n    # Download File\n    download_files_parser = subparsers.add_parser('download_files', intit='Download files',\n                                                 help='Download files from the server. '\n                                                 'This task will download all files specified in the command line.')\n    download_files_parser.add_argument('--download-files', '-d', action='append',\n                                      help='List of files to download.')\n    download_files_parser.add_argument('--model', '-m', help='Model identifier for the task.')\n\n    # Upload Folder\n    upload_folder_parser = subparsers.add_parser('upload_folder', intit='Upload folder',\n                                                help='Upload a folder to the server. '\n                                                     'This task will upload all files in the specified folder.')\n    upload_folder_parser.add_argument('--upload-folder', '-u', help='The folder to upload.')\n    upload_folder_parser.add_argument('--model', '-m', help='Model identifier for the task.')\n\n    # Download Folder\n    download_folder_parser = subparsers.add_parser('download_folder', intit='Download folder',\n                                                  help='Download a folder from the server. '\n                                                       'This task will download all files in the specified folder.')\n    download_folder_parser.add_argument('--download-folder', '-d', help='The folder to download.')\n    download_folder_parser.add_argument('--model', '-m', help='Model identifier for the task.')\n\n    # Upload Files\n    upload_files_parser ="}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    # Input-Output Arguments\n    parser.add_argument('--task', type=str, required=True)\n    parser.add_argument('--upload-files', nargs='*')\n    parser.add_argument('--model', type=str, default=None)\n    parser.add_argument('--record-dir', type=str, default=None)\n    parser.add_argument('--mode', type=str, default='auto')\n    parser.add_argument('--quiet', action='store_true', default=False)\n\n    # Simulation Parameters\n    parser.add_argument('--max-subtask-chain-length', type=int, default=None)\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', default=False)\n    parser.add_argument('--max-plan-refine-chain-length', type=int, default=None)\n    parser.add_argument('--max-plan-tree-depth', type=int, default=None)\n    parser.add_argument('--max-plan-tree-width', type=int, default=None)\n    parser.add_argument('--max-retry-times', type=int, default=None)\n\n    # Configuration File\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'))\n\n    args = parser.parse_args()\n\n    # If the user has specified a configuration file, use it to override the default values\n    if args.config_file:\n        config = CONFIG(args.config_file)\n        for param in ARGS:\n            if hasattr(config, param):\n                setattr(args, param, config.__getattribute__(param))\n\n    return args\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}\"\n        )\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}\")\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1:] != (2,):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must have a shape of (_, 2). got {v.shape}\"\n        )\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape != (2,):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must have a shape of (_, 2) to represent a list of 2D points. Got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape} instead.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    # Check if the array is of the correct shape\n    if not v.shape == (2,):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape}\")\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape} instead\")\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got {v.shape[1]} instead\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, got {v.shape}\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, got {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points, got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    return string.ascii_letters + string.digits + '_'"}
{"namespace": "tanuki.utils.encode_int", "completion": "    alphabet = string.ascii_letters + string.digits + '_'\n    return alphabet[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n    # Find the index of the character in the character set\n    return char_set[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    return string.ascii_letters + string.digits + '_'\n    #return string.ascii_letters + string.digits + string.punctuation + string.whitespace + string.ascii_uppercase + string.digits + '_'\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Get the character set\n    charset = string.ascii_lowercase + string.digits + '_'\n\n    # Return the character from the character set that corresponds to the input integer\n    return charset[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    chars = string.ascii_letters + string.digits + \"_\"\n    # Encode the integer into a character\n    return chars[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    chars = string.ascii_lowercase + string.digits + \"_\"\n    # Define the character set length\n    char_length = len(chars)\n\n    # Encode the integer\n    if n < 0:\n        return \"-\" + encode_int(-n)\n    if n < char_length:\n        return chars[n]\n    else:\n        return encode_int(n // char_length) + chars[n % char_length]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if n < 26:\n        return chr(97 + n)\n    elif n < 52:\n        return chr(65 + n - 26)\n    elif n < 62:\n        return chr(48 + n - 52)\n    else:\n        return \"_\"\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    return string.ascii_lowercase[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # If the integer is negative, raise an exception.\n    if n < 0:\n        raise Exception(\"Negative integers are not allowed.\")\n\n    # Create a string with all the characters that are allowed for encoding.\n    characters = string.ascii_lowercase + string.digits + \"_\"\n\n    # Return the character at the specified index of the character set.\n    return characters[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if n < 26:\n        return chr(ord(\"a\") + n)\n    elif n < 26 + 26:\n        return chr(ord(\"a\") + n - 26)\n    elif n < 26 + 26 + 10:\n        return chr(ord(\"_\") + n - 52)\n    elif n < 26 + 26 + 10 + 2:\n        return chr(ord(\"A\") + n - 62)\n    else:\n        raise ValueError(\"Integer is too large to be encoded\")\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # Check if the integer is within the range of the character set\n    if n >= len(char_set):\n        raise ValueError('Integer is too large, must be less than %d' % len(char_set))\n\n    return char_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    # Check if the integer is out of the range of the character set\n    if n >= len(char_set):\n        # If it is, then recursively encode the integer by first subtracting the length of the character set and then encoding the result\n        return encode_int(n - len(char_set)) + char_set[n % len(char_set)]\n    else:\n        # Otherwise, return the character at the index of the integer\n        return char_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    assert n >= 0\n    # Define the character set\n    # This is a set of lowercase letters, digits, and an underscore\n    chars = string.ascii_lowercase + string.digits + '_'\n    # Get the length of the character set\n    char_len = len(chars)\n\n    # If the integer is greater than the length of the character set,\n    # then encode the integer using the character set\n    if n >= char_len:\n        # Encode the integer by taking the modulo of the integer and the length of the character set.\n        return chars[n % char_len]\n    # Otherwise, return the integer as a string\n    else:\n        return str(n)"}
{"namespace": "tanuki.utils.encode_int", "completion": "    assert n >= 0 and n < 36, \"n must be in the range of 0-35\"\n    if n < 10:\n        return chr(ord(\"0\") + n)\n    else:\n        return chr(ord(\"a\") + n - 10)\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if n < 0:\n        raise ValueError(\"Only non-negative integers are allowed as input\")\n    if n < 26:\n        return chr(ord(\"a\") + n)\n    elif n < 62:\n        return chr(ord(\"a\") + n - 26)\n    else:\n        return \"_\"\n\n    # Return the encoded character\n    # return chr(ord(\"a\") + n % 26)\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # The character set\n    chars = string.ascii_lowercase + string.digits + \"_\"\n    # The length of the character set\n    n_chars = len(chars)\n    # The encoded character\n    encoded = \"\"\n\n    while n > 0:\n        # Get the remainder after dividing the input integer by the length of the character set\n        remainder = n % n_chars\n        # Add the character at the index of the remainder to the encoded string\n        encoded = chars[remainder] + encoded\n        # Divide the input integer by the length of the character set\n        n //= n_chars\n\n    # Return the encoded character\n    return encoded\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # The character set\n    chars = list(string.ascii_lowercase)\n    chars.extend(string.digits)\n    chars.append('_')\n\n    # The maximum number of characters in the character set\n    max_num_chars = len(chars)\n\n    # The number of characters in the encoded string\n    num_chars = 0\n\n    # The encoded string\n    encoded = ''\n\n    # The current character\n    current_char = n % max_num_chars\n\n    # The current character is the first character\n    encoded += chars[current_char]\n\n    # If the current character is not the first character\n    if current_char != 0:\n        # The number of characters in the encoded string is the number of characters in the encoded string plus the number of characters in the encoded string\n        num_chars = num_chars + 1\n\n        # The number of characters in the encoded string is the number of characters in the encoded string divided by the maximum number of characters in the character set\n        num_chars = num_chars // max_num_chars\n\n        # The current character is the current character divided by the maximum number of characters in the character set\n        current_char = current_char // max_num_chars\n\n        # The current character is the current character plus the number of characters in the encoded string\n        current_char = current_char + num_chars\n\n        # The current character is the current character plus the maximum number of characters in the character set\n        current_char = current_char * max_num_chars\n\n    # The encoded string is the encoded string plus the current character\n    encoded = encoded + chars[current_char]\n\n    # The encoded string is the encoded string plus the number of characters in the encoded string\n    encoded = encoded + str(num_chars)\n\n    # The encoded string is the encoded string plus the maximum number of characters in the character set\n    encoded = encoded + str(max_num_chars)\n\n    # The encoded string is the encoded string plus the maximum number of characters in the character set\n    encoded = encoded + str(max_num_chars)\n\n    # The encoded string is the encoded string plus the maximum number of characters in the character set\n    encoded = encoded + str(max_num_chars)"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if n < 0 or n >= 62:\n        raise ValueError(\"Integer is out of range\")\n    if n < 10:\n        return chr(n + ord('0'))\n    elif n < 36:\n        return chr(n - 10 + ord('a'))\n    else:\n        return chr(n - 36 + ord('_'))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, eps, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, 0.0 + eps, 2.0 - eps))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  # Clamp to value_at_zero.\n  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, eps, jnp.finfo(x.dtype).max))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, eps, jnp.inf)) + jnp.log(value_at_zero)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  # TODO(jvu): Implement this function in JAX.\n  return jax.vmap(math.safe_log, in_axes=(0,), out_axes=(0,))(x, eps=eps, value_at_zero=value_at_zero)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, eps, jnp.inf)) - jnp.log(value_at_zero)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  # We use jnp.log(1 + x) to avoid NaNs at x = 0.\n  # We use 1 + x instead of 1 - x because it's faster.\n  # We use 1e-12 instead of eps to avoid NaNs at x = -1.\n  return jnp.log(jnp.clip(1.0 + x, a_min=1e-12, amax=1.0))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.clip(x, eps, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  # TODO(b/230894248): Remove this function once jax.numpy.log is fixed.\n  return jnp.log(jnp.clip(x, eps, jnp.finfo(jnp.float32).max))\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, eps, jnp.inf)) - jnp.log(jnp.full_like(x, value_at_zero))\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in enumerate(workers_intervals):\n        chunks_index[worker_idx] = indexes[worker_idx] // interval[1]\n        indexes[worker_idx] %= interval[1]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunks_index[worker_idx] = 0\n        chunk_size = workers_intervals[worker_idx][1] - workers_intervals[worker_idx][0]\n\n        if chunk_size == 0:\n            continue\n\n        indexes[worker_idx] += chunk_size\n        chunks_index[worker_idx] += 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    indexes_in_chunks = {}\n    for worker_idx, worker_intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in worker_intervals:\n            chunk_index += 1\n            indexes_in_chunks[worker_idx] = indexes[worker_idx]\n            indexes[worker_idx] += interval[1] - interval[0]\n\n    return chunks_index, indexes_in_chunks"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunks = workers_intervals[worker_idx]\n        chunks_index[worker_idx] = 0\n\n        for i in range(len(chunks)):\n            chunks_index[worker_idx] += chunks[i][1] - chunks[i][0]\n            if indexes[worker_idx] < chunks_index[worker_idx]:\n                chunks_index[worker_idx] = i\n\n        chunks_index[worker_idx] += 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        worker_intervals_ = workers_intervals[worker_idx]\n        indexes_ = indexes[worker_idx]\n        chunk_index[worker_idx] = 0\n        for i, interval in enumerate(worker_intervals_):\n            if indexes_ >= interval[0] and indexes_ < interval[1]:\n                indexes_ = indexes_ - interval[0]\n                chunk_index[worker_idx] = i\n\n    return chunk_index, indexes_"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    indexes = {}\n\n    for worker_idx, (worker_intervals) in enumerate(workers_intervals):\n        chunks_index[worker_idx] = 0\n        indexes[worker_idx] = 0\n        for interval in worker_intervals:\n            chunk_index = chunks_index[worker_idx]\n            indexes[worker_idx] = indexes[worker_idx] + interval[0]\n            chunks_index[worker_idx] = chunk_index + 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # This function calculates and updates the indexes for replaying chunks of data based on the intervals provided for each worker. It iterates through each worker's intervals, updating the current index and the chunk index based on the size of each interval.\n\n    chunk_index = {}\n    for worker_idx in indexes.keys():\n        chunk_index[worker_idx] = 0\n\n    for worker_idx, intervals in workers_intervals.items():\n        for interval in intervals:\n            # Update the current index for each worker based on the size of the interval.\n            indexes[worker_idx] = (indexes[worker_idx] + interval[1] - interval[0]) % interval[1]\n            chunk_index[worker_idx] += 1\n\n    return chunk_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    indexes_index = {}\n\n    for worker_idx in range(len(workers_intervals)):\n        chunks_index[worker_idx] = 0\n        indexes_index[worker_idx] = 0\n        for interval in workers_intervals[worker_idx]:\n            if isinstance(interval, (list, tuple)) and len(interval) >= 2:\n                chunk_size = interval[1] - interval[0]\n                indexes_index[worker_idx] += chunk_size\n\n        indexes_index[worker_idx] += indexes[worker_idx]\n        chunks_index[worker_idx] = (indexes_index[worker_idx] // batch_size)\n\n    return chunks_index, indexes_index"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # Iterate through each worker's intervals\n    for worker_idx in range(len(workers_intervals)):\n        worker_intervals = workers_intervals[worker_idx]\n\n        # Iterate through each interval\n        for interval in worker_intervals:\n            # Get the size of the interval\n            interval_size = interval[1] - interval[0]\n\n            # Update the current index and the chunk index\n            indexes[worker_idx] += interval_size\n            worker_idx += 1\n\n            # Check if we have reached the end of the worker's intervals\n            if worker_idx >= len(workers_intervals):\n                worker_idx = 0\n\n    return indexes, worker_idx"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx, worker_intervals in workers_intervals.items():\n        for interval in worker_intervals:\n            indexes[worker_idx] += interval[1] - interval[0]\n            chunk_index = indexes[worker_idx] // interval[1]\n            indexes[worker_idx] = indexes[worker_idx] % interval[1]\n            if chunk_index >= len(workers_intervals[worker_idx]):\n                # reset the chunk index\n                indexes[worker_idx] = 0\n                chunk_index = 0\n            workers_intervals[worker_idx][chunk_index][1] += interval[1]\n            workers_intervals[worker_idx][chunk_index][0] = indexes[worker_idx]\n\n    return indexes, workers_intervals"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # Iterate through each worker's intervals\n    for worker_idx in range(len(workers_intervals)):\n        interval = workers_intervals[worker_idx]\n        current_indexes = indexes[worker_idx]\n        chunk_index = 0\n\n        # Iterate through each interval\n        for i, (start, end) in enumerate(interval):\n            # Update the current index based on the interval size\n            indexes[worker_idx] += end - start\n\n            # If the current index is greater than the end of the current interval,\n            # update the chunk index and reset the current index to the start of the next interval\n            if current_indexes > end:\n                chunk_index += 1\n                current_indexes = start\n\n    # Return the updated chunk index and indexes\n    return indexes, chunk_index"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    indexes_in_chunks = {}\n    for worker_idx, interval in workers_intervals.items():\n        # reset the chunk index\n        chunks_index[worker_idx] = 0\n        indexes_in_chunks[worker_idx] = 0\n        # iterate through the intervals\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_index, interval)):\n            # update the chunk index\n            chunks_index[worker_idx] = i\n            # update the indexes within the chunks\n            indexes_in_chunks[worker_idx] += chunk_interval[1] - chunk_interval[0]\n        # update the indexes\n        indexes[worker_idx] += indexes_in_chunks[worker_idx]\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunk_index[worker_idx] = 0\n    # Update the indexes for each worker based on the intervals' sizes\n    for worker_idx in range(len(workers_intervals)):\n        interval = workers_intervals[worker_idx][chunk_index[worker_idx]]\n        indexes[worker_idx] += interval[1] - interval[0]\n\n        # Increment the chunk index for the current worker\n        chunk_index[worker_idx] += 1\n\n        # Check if the chunk index has exceeded the number of chunks for the current worker\n        if chunk_index[worker_idx] >= len(workers_intervals[worker_idx]):\n            # If the chunk index has exceeded the number of chunks, set it back to 0\n            chunk_index[worker_idx] = 0\n\n    return chunk_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        # reset the interval\n        interval = workers_intervals[worker_idx]\n        chunk_index[worker_idx] = interval[0]\n\n    for worker_idx in range(len(workers_intervals)):\n        # update the interval\n        interval = workers_intervals[worker_idx]\n        if indexes[worker_idx] >= interval[1] - interval[0]:\n            chunk_index[worker_idx] += 1\n            indexes[worker_idx] -= interval[1] - interval[0]\n        else:\n            indexes[worker_idx] += 1\n\n    return chunk_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # create empty dictionaries to store the updated chunk and index values\n    chunk_index = {}\n    indexes_ = {}\n\n    for worker_idx, worker_intervals in workers_intervals.items():\n        chunk_index[worker_idx] = 0\n        indexes_[worker_idx] = 0\n\n    # iterate through each worker's intervals, updating the current index and the chunk index based on the size of each interval\n    for worker_idx, worker_intervals in workers_intervals.items():\n        for interval in worker_intervals:\n            # update the current index within the chunk\n            indexes_[worker_idx] += indexes[worker_idx]\n\n            # update the chunk index based on the size of the interval\n            chunk_index[worker_idx] += 1\n\n    return chunk_index, indexes_"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n\n        # reset the chunk index\n        chunk_indexes[worker_idx] = 0\n\n        for interval in intervals:\n            chunk_indexes[worker_idx] += 1\n            if len(interval) > 2:\n                chunk_indexes[worker_idx] += interval[2] - interval[0]\n\n    # update indexes for the next chunk\n    indexes = {\n        worker_idx: index + interval[1] for worker_idx, (index, interval) in indexes.items()\n    }\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # Update the chunk_index\n    chunk_index = {}\n\n    for worker_idx in range(len(workers_intervals)):\n        worker_intervals_size = len(workers_intervals[worker_idx])\n\n        # If the worker has only one interval, the chunk index is the same as the index\n        if worker_intervals_size == 1:\n            chunk_index[worker_idx] = indexes[worker_idx]\n\n        # If the worker has multiple intervals, the chunk index is the interval index\n        else:\n            chunk_index[worker_idx] = indexes[worker_idx] // workers_intervals[worker_idx][0][1]\n\n    # Update the indexes\n    for worker_idx in range(len(workers_intervals)):\n        chunk_index[worker_idx] = chunk_index[worker_idx]\n        indexes[worker_idx] = indexes[worker_idx] % workers_intervals[worker_idx][0][1]\n\n    return chunk_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_indexes = {}\n    for worker_idx in range(len(workers_intervals)):\n        workers_indexes[worker_idx] = indexes[worker_idx]\n\n    for worker_idx in range(len(workers_intervals)):\n        worker_intervals = workers_intervals[worker_idx]\n        if len(worker_intervals) == 0:\n            continue\n\n        chunk_index = 0\n        interval = worker_intervals[0]\n        indexes[worker_idx] = interval[0]\n\n        if len(worker_intervals) == 1:\n            workers_indexes[worker_idx] = indexes[worker_idx]\n        else:\n            for i in range(1, len(worker_intervals)):\n                current_interval = worker_intervals[i]\n                next_interval = worker_intervals[i - 1]\n                indexes[worker_idx] += current_interval[1] - next_interval[0]\n                if indexes[worker_idx] == current_interval[1]:\n                    chunk_index += 1\n                    if i == len(worker_intervals) - 1:\n                        workers_indexes[worker_idx] = indexes[worker_idx]\n                    else:\n                        interval = worker_intervals[i]\n                        indexes[worker_idx] = interval[0]\n    return workers_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        # reset the chunk_index\n        chunk_index[worker_idx] = 0\n\n        # get the current interval\n        interval = workers_intervals[worker_idx]\n\n        # get the current index\n        current_indexes = indexes[worker_idx]\n\n        # update the chunk_index\n        while True:\n            # if the current_index is within the interval, increment the chunk_index\n            if current_indexes >= interval[0] and current_indexes < interval[1]:\n                chunk_index[worker_idx] += 1\n\n            # if the current_index is greater than the last element of the interval, update the current_index to the first element of the next interval\n            if current_indexes >= interval[1]:\n                if len(interval) > 2:\n                    interval = interval[2:]\n                else:\n                    interval = []\n\n            # if the interval is empty, break the loop\n            if len(interval) == 0:\n                break\n\n            # if the current_index is greater than the last element of the interval, update the current_index to the first element of the next interval\n            if current_indexes >= interval[1]:\n                current_indexes = interval[0]\n            # if the current_index is less than the first element of the interval, update the current_index to the first element of the interval\n            elif current_indexes < interval[0]:\n                current_indexes = interval[0]\n            # if the current_index is within the interval, increment the current_index\n            else:\n                current_indexes += 1\n\n    return chunk_index, indexes"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear(\n      values,\n      coordinates,\n      datastructure,\n    )\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(\n      values,\n      coordinates,\n      datastructure,\n    )\n  else:\n    raise ValueError(\n      f'Unsupported datastructure: {datastructure}.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.grid_to_grid_trilinear(values, coordinates)\n\n  elif datastructure == 'hash':\n    return hash_resample.hash_to_grid_trilinear(values, coordinates)\n\n  else:\n    raise ValueError(\n        'The datastructure must be either \"grid\" or \"hash\" but got '\n        f\"'{datastructure}'.\"\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # TODO(keller): Add support for other data structures.\n  if datastructure == 'grid':\n    return resample.trilinear(values, coordinates)\n\n  elif datastructure == 'hash':\n    return hash_resample.trilinear(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure: %s. Only support grid and hash.'\n        % datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilinear(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure: {}. Expected \"grid\" or \"hash\".'.format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolate(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolate(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure passed. Function only supports '\n                     'grid or hash data structures.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure. Only supports \"grid\" or \"hash\"')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_grid_interpolate(values, coordinates)\n\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_hash_interpolate(values, coordinates)\n\n  else:\n    raise ValueError(\n        'The datastructure must be \"hash\" or \"grid\".'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear(values, coordinates)\n\n  elif datastructure == 'hash':\n    return hash_resample.trilinear(values, coordinates)\n\n  else:\n    raise ValueError(\n        'Invalid datastructure. Expected either \"grid\" or \"hash\", got %s.' %\n        datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('datastructure must be either \"grid\" or \"hash\"')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure \"{datastructure}\".'\n        f'Valid datastructures are \"grid\" or \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilinear(values, coordinates)\n  else:\n    raise ValueError(f\"Invalid datastructure passed: {datastructure}\")\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Get the dimensions of the voxel grid.\n    D, H, W, C = values.shape\n    # If the coordinates are 2D, we need to repeat them for each channel.\n    if coordinates.ndim == 2:\n      coordinates = coordinates[jnp.newaxis, ..., jnp.newaxis]\n    # Check if the coordinates are within the bounds of the voxel grid.\n    coordinates = math.clip_box(coordinates, (0, D-1), (0, H-1), (0, W-1))\n    # Interpolate the values at the specified coordinates.\n    return values[\n        coordinates[..., 0],\n        coordinates[..., 1],\n        coordinates[..., 2],\n        coordinates[..., 3],\n    ]\n  elif datastructure == 'hash':\n    # If the coordinates are 2D, we need to repeat them for each channel.\n    if coordinates.ndim == 2:\n      coordinates = coordinates[jnp.newaxis, ...]\n    # Interpolate the values at the specified coordinates.\n    return hash_resample.hash_resample(values, coordinates)\n  else:\n    raise ValueError(\n      'Invalid datastructure: {}. Expected grid or hash'.format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # Check the datastructure.\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\n        'Unsupported datastructure type: {}'.format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # If the datastructure is a 3D voxel grid, we use the coordinates to sample the grid.\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    # If the datastructure is a hashed data structure, we use a hash function to interpolate the values.\n    return hash_resample.hash_interpolation(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure passed. The function only supports \"grid\" or \"hash\" as valid data structures.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return _trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return _trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure passed, only supports grid or hash')\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = resample.trilinear_interpolate(coordinates, values)\n  elif datastructure == 'hash':\n    coordinates = resample.trilinear_interpolate(coordinates, values)\n    # TODO(s-johanns): Implement hashing.\n  else:\n    raise ValueError(\n        f'Only support datastructure: {datastructure}.')\n  return coordinates\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Convert coordinates to voxels\n    coordinates = math.normalize_to_voxels(coordinates)\n  elif datastructure == 'hash':\n    pass\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}')\n\n  # Interpolation\n  # TODO: Implement trilinear interpolation.\n  # TODO: Implement 3D interpolation.\n  return jnp.zeros(coordinates.shape[:-1] + (values.shape[-1],) + coordinates.shape[-1:])\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolate(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolate(values, coordinates)\n  else:\n    raise ValueError(\n        f'Unsupported datastructure {datastructure}. '\n        'The function only supports \"grid\" or \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # TODO(b/222904172): Implement a better error message for datastructure.\n  if datastructure == 'grid':\n    return resample.trilinear(values, coordinates)\n\n  elif datastructure == 'hash':\n\n    def _hash_resample(\n      values,\n      coordinates,\n      datastructure,\n    ):\n\n      # TODO(b/222904172): Implement a better error message for datastructure.\n      if datastructure == 'grid':\n        return resample.trilinear(values, coordinates)\n\n      elif datastructure == 'hash':\n        return hash_resample.trilerp(values, coordinates)\n      else:\n        raise ValueError(\n            'Unsupported datastructure {} for hashing.'.format(datastructure))\n\n    return jax.vmap(_hash_resample)(values, coordinates)\n\n  else:\n    raise ValueError('Unsupported datastructure {}.'.format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # TODO(r:114493496): Make the function work for arbitrary dimensions.\n    if coordinates.ndim == 3:\n      coordinates = jnp.dstack((jnp.arange(values.shape[0]), coordinates))\n    elif coordinates.ndim == 4:\n      coordinates = jnp.dstack((coordinates[:, :1], coordinates[:, 1:]))\n    return jnp.take_along_axis(values, coordinates, axis=0)\n  elif datastructure == 'hash':\n    return hash_resample.hash_resample(values, coordinates)\n  else:\n    raise ValueError(\n      f'Invalid datastructure {datastructure}. Supported datastructures are \"grid\" and \"hash\".')\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the weights for the first vertex.\n  w0 = np.asarray([1, 1, 1])\n  w0 = w0 / np.sum(w0)\n\n  # Compute the weights for the second vertex.\n  w1 = np.asarray([1, -1, 1])\n  w1 = w1 / np.sum(w1)\n  w1 = np.vstack((w1, w1))\n\n  # Compute the weights for the third vertex.\n  w2 = np.asarray([1, 1, -1])\n  w2 = w2 / np.sum(w2)\n  w2 = np.vstack((w2, w2, w2))\n\n  # Generate the tessellation weights.\n  return np.vstack((w0, w1, w2)) ** v\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric coordinates for the vertices of the triangle.\n  # (This is the first step of the tessellation.)\n  # The weights are the coordinates of the vertices in the barycentric coordinate system.\n  # The weights are normalized to sum to 1.\n  weights = [1. / 3, 1. / 3, 1. / 3]\n\n  # Compute the barycentric coordinates for the new vertices.\n  # (This is the second step of the tessellation.)\n  # The weights are the coordinates of the new vertices in the barycentric coordinate system.\n  # The weights are normalized to sum to 1.\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  weights_new = np.array(list(itertools.combinations(weights, 2)))\n  "}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  v = np.atleast_1d(v)\n  if v.ndim == 1:\n    v = np.array([v, v, v])\n\n  # Compute the tesselation weights.\n  w = np.ones(3, dtype=np.int32)\n  w[0] = -1\n  w[1] = v\n  w[2] = v * (v - 1)\n\n  # Normalize the weights to get barycentric coordinates.\n  w = w / np.sum(w)\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('v must be greater than or equal to 1.')\n  v = int(v)\n  # Compute the barycentric coordinates for the triangle.\n  b = np.array([1, 1, 1])\n  b = b / np.sum(b)\n  # Compute the barycentric coordinates for the tessellated triangle.\n  b_tessel = np.array([v, v, v])\n  b_tessel = b_tessel / np.sum(b_tessel)\n  # Compute the barycentric weights for each point.\n  w = np.array([1, 1, 1])\n  w = w / np.sum(w)\n  w = np.concatenate([w, b_tessel - w])\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v <= 1:\n    raise ValueError('tesselation factor must be greater than 1')\n  v_inv = 1.0 / v\n  v_inv_sq = v_inv * v_inv\n  v_inv_thrd = v_inv / 3\n  v_inv_thrd_sq = v_inv_thrd * v_inv_thrd\n  # Note: The following is the solution to the system of equations:\n  #    w0 + w1 + w2 = 1\n  #    w0 * v_inv_sq + w1 * v_inv_sq + w2 * v_inv_sq = 1\n  #    w0 * v_inv_thrd_sq + w1 * v_inv_thrd_sq + w2 * v_inv_thrd_sq = 1\n  w0 = v_inv_thrd_sq\n  w1 = (v_inv_sq - 3 * v_inv_thrd_sq)\n  w2 = 1 - v_inv_sq - w0 - w1\n\n  # Note: The following is the solution to the system of equations:\n  #    w0 + w1 + w2 = 1\n  #    w0 * v_inv_sq + w1 * v_inv_sq + w2 * v_inv_sq = 1\n  #    w0 * v_inv_thrd + w1 * v_inv_thrd + w2 * v_inv_thrd = 1\n  w0_1 = v_inv_sq\n  w1_1 = (v_inv_sq - v_inv_thrd)\n  w2_1 = 1 - v_inv_sq - w0_1 - w1_1\n\n  # Note: The following is the solution to the system of equations:\n  #    w0 + w1 + w2 = 1\n  #    w0 * v_inv_sq + w1 * v_inv_sq + w2 * v_inv_sq = 1\n  #    w0 * v_inv_thrd + w1 * v_inv_thrd + w2"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1, 'The tessellation factor must be greater than or equal to 1'\n  # Generate the barycentric weights for the vertices.\n  w0 = np.array([v**2, (v - 1) * v, 1 - v])\n  w1 = np.array([v, v**2, 1 - v])\n  w2 = np.array([1, v, v**2])\n  # Normalize the barycentric weights.\n  w0 /= w0.sum()\n  w1 /= w1.sum()\n  w2 /= w2.sum()\n  return np.stack([w0, w1, w2])\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1, \"v must be greater than or equal to 1.\"\n  # Use the fact that the barycentric coordinates of a point on a triangle\n  # are given by the ratio of the areas of the triangle formed by the point\n  # and each vertex to the area of the triangle.\n  #\n  # The area of a triangle with vertices a, b, c is 0.5 * |a x b + b x c + c x a|.\n  #\n  # The area of a triangle with vertices (x0, y0), (x1, y1), (x2, y2) is\n  # 0.5 * |x0*y1 - x1*y0 + x1*y2 - x2*y1 + x2*y0 - x0*y2|.\n  #\n  # The area of the triangle formed by the origin and the three vertices is\n  # 0.5 * |x0*y1 - x1*y0|.\n  #\n  # The area of the triangle formed by the origin and the three vertices\n  # and the point (x, y) is 0.5 * |x*y1 - x*y0 + x*y2 - y*x1 + y*x0 - x*y2|.\n  #\n  # The area of the triangle formed by the three vertices and the point (x, y)\n  # is 0.5 * |x*y1 - x*y0 + x*y2 - y*x1 + y*x0 - x*y2| - 0.5 * |x0*y1 - x1*y0|.\n  #\n  # The barycentric coordinates of the point (x, y) are\n  # ((x*y1 - x*y0 + x*y2 - y*x1 + y*x0 - x*y2) - (x0*y1 - x1*y0)) /\n  #    |x0*y1 - x1*y0|,\n  # (x0*y1 - x1*y0 - (x*y1 - x*y0 + x*y2 - y*x1 + y*"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # TODO(user): This should be a function of v, not just 1.\n  if v < 1:\n    raise ValueError('v must be >= 1')\n\n  # Compute the vertices of the triangle.\n  v0 = np.array([0, 0, 1], dtype=float)\n  v1 = np.array([1, 0, 0], dtype=float)\n  v2 = np.array([0, 1, 0], dtype=float)\n\n  # Compute the barycentric coordinates of the vertices.\n  w0 = 1.0 / (2.0 * np.sqrt(3))\n  w1 = 1.0 / 3.0\n  w2 = 1.0 / 3.0\n  barycentric_coords = np.array([w0, w1, w2])\n\n  # Compute the tessellated vertices.\n  tessellated_coords = []\n  for i in range(v):\n    for j in range(v):\n      for k in range(v):\n        tessellated_coords.append(\n            v0 * i + v1 * j + v2 * k)\n  tessellated_coords = np.array(tessellated_coords, dtype=float)\n\n  # Compute the weights for each tessellated vertex.\n  weights = np.zeros(tessellated_coords.shape)\n  for i in range(v):\n    for j in range(v):\n      for k in range(v):\n        weights[i * v * v + j * v + k] = (\n            barycentric_coords[0] * i + barycentric_coords[1] * j +\n            barycentric_coords[2] * k)\n\n  # Normalize the weights.\n  weights = weights / np.sum(weights)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('v must be >= 1')\n  if v == 1:\n    return np.array([1, 1, 1])\n  # Compute the weights for the tessellated triangle.\n  x = np.arange(1, v + 1)\n  w = np.vstack(\n      (np.ones(v), (x + 0.5) / (v + 1), (x - 0.5) / (v + 1))\n  # Normalize the weights.\n  w = w / np.sum(w, 0)\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1, \"The tessellation factor must be greater than or equal to 1\"\n  if v == 1:\n    return np.ones(3, dtype=int)\n  else:\n    v0 = v\n    v1 = v - 1\n    return np.array([v0, v1, v1], dtype=int) / v\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  v = np.array(v)\n  assert np.all(v >= 1), \"The tessellation factor must be greater than or equal to 1.\"\n  # Compute the weights for the vertices of the triangle.\n  v1 = np.array([1, 1, 1])\n  v2 = np.array([1, 0, -1])\n  v3 = np.array([0, 1, -1])\n  v1 = v1 / np.sum(v1)\n  v2 = v2 / np.sum(v2)\n  v3 = v3 / np.sum(v3)\n  # Compute the weights for the tessellated vertices.\n  v1_ = v1 * v\n  v2_ = v2 * v\n  v3_ = v3 * v\n  # Compute the barycentric coordinates.\n  v1_2 = v1_[:, None] * v1_\n  v2_2 = v2_[:, None] * v2_\n  v3_2 = v3_[:, None] * v3_\n  v12 = v1_[:, None] * v2_\n  v13 = v1_[:, None] * v3_\n  v23 = v2_[:, None] * v3_\n  v123 = v1_[:, None] * v2_[:, None] * v3_\n  return np.stack([\n      v1_2 + v2_2 + v3_2 - v12 - v13 - v23 + v123,\n      v1_2 - v2_2 - v3_2 + v12 - v13 + v23 - v123,\n      v2_2 - v1_2 - v3_2 + v12 + v13 - v23 - v123,\n  ], axis=-1)\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # The weights are given by the solution to the following linear system:\n  #\n  #   x_1 + x_2 + x_3 = 1\n  #   x_1 * v^2 + x_2 * v^2 + x_3 * v^2 = 1\n  #\n  # The solution is given by:\n  #\n  #   x_1 = (1 - v^2) / (1 + v^2)\n  #   x_2 = v^2 / (1 + v^2)\n  #   x_3 = 1 / (1 + v^2)\n  #\n  # The weights are normalized to get the barycentric coordinates.\n  weights = np.array([1 - v**2, v**2, 1], dtype=np.float32)\n  weights /= np.sum(weights)\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for the tessellated triangle.\n  v = np.array(v)\n  assert v >= 1\n  if v == 1:\n    return np.array([1.0, 1.0, 1.0])\n\n  # Compute the coordinates of the tessellated triangle.\n  # First, compute the barycentric coordinates of the tessellated triangle.\n  # The triangle is tessellated by tessellating each of its edges.\n  # The barycentric coordinates of the tessellated triangle are then computed by\n  # interpolating the barycentric coordinates of the original triangle.\n  #\n  # The barycentric coordinates of the tessellated triangle are then converted\n  # into cartesian coordinates.\n  bary_coords = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n  bary_coords = np.tile(bary_coords, (v, 1, 1))\n  bary_coords = np.array([\n      bary_coords[0, :, 0] * (1 - v) + bary_coords[1, :, 0] * v,\n      bary_coords[0, :, 1] * (1 - v) + bary_coords[2, :, 1] * v,\n      bary_coords[0, :, 2] * (1 - v) + bary_coords[1, :, 2] * v\n  ])\n  # The barycentric coordinates are normalized to get the cartesian coordinates.\n  bary_coords = bary_coords / bary_coords[2, :, 2]\n\n  # Compute the cartesian coordinates of the tessellated triangle.\n  # The cartesian coordinates of the tessellated triangle are computed by\n  # interpolating the cartesian coordinates of the original triangle.\n  cart_coords = np.array([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n  cart_coords = np.tile(cart_coords, (v, 1))\n  cart_coords = np.array([\n      cart_coords[0, :, 0] * (1"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # The tessellation factor must be at least 1.\n  v = max(v, 1)\n  # The tessellation weights for the three vertices.\n  v1 = [1, 0, 0]\n  v2 = [0, 1, 0]\n  v3 = [0, 0, 1]\n  # The tessellation weights for the interior points.\n  v4 = [1, 1, -1]\n  v5 = [1, -1, 1]\n  v6 = [-1, 1, 1]\n  # The tessellation weights for the vertices of the original triangle.\n  v7 = [1, 0, 0]\n  v8 = [0, 1, 0]\n  v9 = [0, 0, 1]\n  # The tessellation weights for the interior points of the original triangle.\n  v10 = [1, 1, -1]\n  v11 = [1, -1, 1]\n  v12 = [-1, 1, 1]\n\n  # The tessellation weights for the interior points of the tessellated triangle.\n  weights = []\n\n  # For each point in the tessellated triangle, we use the following formula:\n  # (v1 * v1_weight + v2 * v2_weight + v3 * v3_weight) / (v1_weight + v2_weight + v3_weight).\n  # The weights are computed by scaling the tessellation weights for the vertices of the original triangle\n  # by the tessellation factor and then adding the tessellation weights for the interior points.\n  for v1_weight in range(v):\n    for v2_weight in range(v):\n      for v3_weight in range(v):\n        weights.append(\n            (v1 * v1_weight + v2 * v2_weight + v3 * v3_weight) / (\n                v1_weight + v2_weight + v3_weight))\n\n  # The tessellation weights for the interior points of the tessellated triangle.\n  weights.extend(["}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\n        'tessellation factor must be greater than or equal to 1')\n  v = int(v)\n  # The tessellation factor must be an integer.\n\n  # Create the tessellated vertices.\n  tessellated_vertices = np.vstack(\n      [v * np.array([1, 0, 0]) for _ in range(v)] + [\n          v * np.array([0, 1, 0]) for _ in range(v)] + [\n              v * np.array([0, 0, 1]) for _ in range(v)])\n\n  # Find the distances between the tessellated vertices.\n  tessellated_distances = compute_sq_dist(tessellated_vertices)\n\n  # Find the distances between the tessellated vertices and the original vertex.\n  distances = compute_sq_dist(tessellated_vertices, v * np.array([1, 1, 1]))\n\n  # Compute the barycentric weights.\n  weights = np.diag(1.0 / tessellated_distances) @ distances\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the tessellation factor.\n  v = max(1, v)\n\n  # Compute the barycentric weights for the tessellation.\n  # The weights are computed using the formula:\n  #\n  #   w = 1 - (x^2 + y^2) / 2\n  #\n  # where x, y are the barycentric coordinates of the point in the triangle.\n  # The weights are normalized by the sum of the weights for each point in the triangle.\n  x = np.array([0, 1, 1])\n  y = np.array([1, 0, 1])\n  w = 1 - (x**2 + y**2) / 2\n  w /= w.sum()\n\n  # Compute the tessellation weights.\n  # The tessellation weights are computed by applying the barycentric weights to\n  # the tessellation factor and then normalizing by the sum of the weights.\n  w_tessellated = w * v\n  w_tessellated /= w_tessellated.sum()\n\n  return w_tessellated\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v <= 1:\n    raise ValueError('Tessellation factor must be greater than 1')\n  if v % 2 == 0:\n    raise ValueError('Tessellation factor must be odd')\n  v_odd = v - 1\n  v_even = v + 1\n\n  # Compute the barycentric coordinates for the tessellation.\n  # The barycentric coordinates for the tessellation of a triangle with vertex\n  # coordinates (0,0), (0,1), (1,0) are given by:\n  #   (0, 1, 0)\n  #   (0, 0, 1)\n  #   (1, 0, 0)\n  #\n  # We want to find the barycentric coordinates for the tessellation of the\n  # triangle with vertex coordinates (0, 0), (1, 0), (0, 1) and then\n  # rotate the coordinates to the desired triangle.\n  #\n  # To do this, we can use the following matrix:\n  #\n  #   0 1 0\n  #   0 0 1\n  #   1 0 0\n  #\n  # This matrix maps the coordinates (0, 0), (1, 0), (0, 1) to the coordinates\n  # (0, 0), (1, 0), (0, 1).\n  #\n  # We can then use the following matrix to rotate the coordinates to the\n  # desired triangle:\n  #\n  #   0 -1 0\n  #   0  0 1\n  #   1  0 0\n  #\n  # This matrix maps the coordinates (0, 0), (1, 0), (0, 1) to the coordinates\n  # (0, 0), (0, 1), (1, 0).\n  #\n  # So, the final matrix we want to use is:\n  #\n  #   0 0 0\n  #   1 -1 0\n  #   0  0 1\n  #\n  # We can use this matrix to compute the barycentric coordinates for the\n  # tessellation"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the tesselation weights.\n  if v < 1:\n    raise ValueError('Tessellation factor must be greater than or equal to 1.')\n  v = int(v)\n  # Generate the tesselation weights.\n  # See https://en.wikipedia.org/wiki/Triangle_tessellation#Barycentric_coordinates\n  # for the formula.\n  # We use the following notation:\n  # - t = (1, 1, 1)\n  # - a = (1, 0, 0)\n  # - b = (0, 1, 0)\n  # - c = (0, 0, 1)\n  # - v = (v, v, v)\n  a = np.array([1, 0, 0], dtype=np.int64)\n  b = np.array([0, 1, 0], dtype=np.int64)\n  c = np.array([0, 0, 1], dtype=np.int64)\n  t = np.array([1, 1, 1], dtype=np.int64)\n  # Compute the weights for the vertices of the triangle.\n  # The weights are the coordinates of the points in the tessellation.\n  # We first compute the coordinates of the points by adding multiples of\n  # a, b, and c to t.\n  weights = np.vstack((t, t + a, t + b, t + c))\n  # We then normalize the coordinates to get the barycentric weights.\n  weights = 1.0 / weights\n  # Generate the weights for the interior points.\n  # We do this by adding multiples of a, b, and c to the vertices.\n  weights = np.stack([weights + a * i for i in range(1, v + 1)])\n  weights = np.stack([weights + b * i for i in range(1, v + 1)])\n  weights = np.stack([weights + c * i for i in range(1, v + 1)])\n  # We then normalize the coordinates to get the barycentric weights.\n  weights = 1.0 / weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Create the tessellation points\n  # Here, we use the fact that the barycentric coordinates of the tessellated points are all the permutations of 1/v, 1/v, and 1-2/v.\n  # We also use the fact that the barycentric coordinates of a point are unique up to permutation.\n  # Therefore, we can create the tessellated points by permuting the coordinates of the triangle's vertices.\n  # For example, if v = 2, the tessellated points are (1/2, 1/2), (1/2, 1/2), (1/2, 1/2).\n  tessellated_points = [\n      [1.0 / v, 0.0, 1.0 - 2.0 / v],\n      [0.0, 1.0 / v, 1.0 - 2.0 / v],\n      [1.0 / v, 1.0 / v, 1.0 - 2.0 / v]\n  ]\n\n  # Compute the barycentric coordinates of the tessellated points\n  barycentric_weights = np.zeros((v * v * v, 3))\n  # For each point in the tessellated triangle, we need to compute the barycentric coordinates of the point.\n  # We can do this by finding the index of the point in the tessellated points list and then using the barycentric coordinates of that point.\n  # For example, if the point is (1/2, 1/2), we can find the index of (1/2, 1/2) in the tessellated points list and then use the barycentric coordinates of that point.\n  for i in range(v):\n    for j in range(v):\n      for k in range(v):\n          barycentric_weights[i * v * v + j * v + k] = tessellated_points[i]\n  return barycentric_weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # The tesselation is done by dividing each side of the triangle by v, and then\n  # interpolating the values across the triangle.\n  v = int(v)\n  if v < 1:\n    raise ValueError('v must be at least 1, but got {}'.format(v))\n\n  # We create the tessellated vertices.\n  x = np.linspace(0, 1, v + 1)\n  x = np.repeat(x[None, :], v, 0)\n  y = np.linspace(0, 1, v + 1)\n  y = np.repeat(y[None, :], v, 0)\n  z = np.linspace(0, 1, v + 1)\n  z = np.repeat(z[None, :], v, 0)\n\n  # We compute the barycentric coordinates for each tessellated point.\n  x = np.vstack((x, y, z))\n  x = x.T\n  x = x / np.sum(x, 0)\n\n  # We compute the weights for the tessellated points.\n  weights = np.vstack((x, 1 - x))\n  weights = weights / np.sum(weights, 0)\n  return weights\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  return math.linear_spline_eval(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  return math.interp_linear(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Interpolate\n  return jax.vmap(math.interp_linear_spline, in_axes=(0,), out_axes=(0,))(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  # We want to find the index of the first time point that is greater than the\n  # query point.\n  idx_t = jax.lax.scan(\n      functools.partial(jnp.where, jnp.greater, t, tq),\n      jnp.array(0),\n      jnp.array(1))\n  idx_t = jnp.concatenate(\n      (idx_t, jnp.array([t.shape[-1] - 1], jnp.int32)))\n  # We can now use this to find the value of the spline at each query point.\n  return jnp.reshape(v[idx_t], tq.shape)\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(\n      jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n      'Spline must be increasing.')\n  checkify.check(t.ndim == 1, 't must be 1-d.')\n  checkify.check(v.ndim == 1, 'v must be 1-d.')\n  checkify.check(v.shape[:-1] == t.shape[:-1],\n                 'v must have the same shape as t except for the last dimension.')\n\n  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n\n  # Find the index of the first time point greater than the query point.\n  i = jax.lax.cond(\n      t[Ellipsis, -1] > tq,\n      lambda _: jnp.arange(t.shape[Ellipsis]),\n      lambda _: jnp.arange(t.shape[Ellipsis] - 1))\n\n  # Find the index of the last time point less than or equal to the query point.\n  j = jax.lax.cond(\n      t[Ellipsis, :-1] < tq,\n      lambda _: jnp.arange(t.shape[Ellipsis]),\n      lambda _: jnp.arange(t.shape[Ellipsis] - 1))\n\n  # Find the difference between the query points and the time points.\n  d = tq - t[Ellipsis, j]\n\n  # Find the difference between the time points.\n  h = t[Ellipsis, i + 1] - t[Ellipsis, j]\n\n  # Find the interpolation weights.\n  w = d / h\n\n  # Find the values at the query points.\n  return v[Ellipsis, j] * (1 - w) + v[Ellipsis, i + 1] * w\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(len(t) >= 2, 'At least two time points are required to define a linear spline.')\n\n  # checkify.check(\n  #     len(tq) >= 2,\n  #     'At least two time points are required to define a linear spline.')\n\n  checkify.check(t[1] > t[0], 'Time points must be sorted.')\n\n  # checkify.check(\n  #     t[1] > t[0],\n  #     'Time points must be sorted.')\n\n  # checkify.check(\n  #     t[0] < tq[0],\n  #     'Query point must be in the range of the spline.')\n\n  # checkify.check(\n  #     t[-1] > tq[-1],\n  #     'Query point must be in the range of the spline.')\n\n  # Check that the spline is valid\n  checkify.check(\n      jnp.all(v[Ellipsis, 0] == 0), 'Splines must all start with 0.')\n\n  checkify.check(\n      jnp.all(v[Ellipsis, -1] == 0), 'Splines must all end with 0.')\n\n  # Check that the spline is continuous\n  checkify.check(\n      jnp.all(v[Ellipsis, 1:] == v[Ellipsis, :-1] + t[1:] - t[:-1]),\n      'Splines must be continuous.')\n\n  # Check that the spline is piecewise linear\n  checkify.check(\n      jnp.all(v[Ellipsis, 2:] == v[Ellipsis, 1:] - v[Ellipsis, :-1]),\n      'Splines must be piecewise linear.')\n\n  # Check that the spline is monotone\n  checkify.check(\n      jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n      'Splines must be monotone.')\n\n  # Check that the spline is monotone\n  checkify.check(\n      jnp.all(v[Ellipsis, 1:] > v[Ellipsis, :-1]),\n      'Splines must be monotone.')\n\n  # Check that the"}
{"namespace": "linspline.query", "completion": "  checkify.check(len(t) > 1, 'The time points must have more than 1 element.')\n\n  # Make sure the spline is valid.\n  checkify.check(\n      jnp.all(jnp.diff(t) >= 0), 'The time points must be sorted in increasing order.')\n  checkify.check(jnp.all(v[Ellipsis, 0] == 0), 'Splines must all start with 0.')\n  checkify.check(jnp.all(v[Ellipsis, -1] == 0), 'Splines must all end with 0.')\n\n  # Find the index of the first time point greater than or equal to the query point.\n  i_t = jax.lax.cond(\n      jnp.all(tq < t), lambda _: 0, lambda _: jax.lax.floor_div(tq, t),\n      eltype=int)\n  # Find the index of the last time point less than or equal to the query point.\n  i_t = jax.lax.cond(\n      jnp.all(tq >= t), lambda _: t.size - 1, lambda _: jax.lax.floor_div(tq, t),\n      eltype=int)\n\n  # Find the value of the spline at the query point.\n  tq = tq - t[i_t]\n  return v[Ellipsis, i_t] + jnp.multiply(tq, v[Ellipsis, i_t + 1] - v[Ellipsis, i_t])\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(t.shape[0] >= 2, 't must have at least 2 elements.')\n  checkify.check(t.shape == v.shape, 't and v must have the same shape.')\n\n  t_min = jnp.min(t)\n  t_max = jnp.max(t)\n  t_min_idx = jnp.argmin(t)\n  t_max_idx = jnp.argmax(t)\n\n  checkify.check(t_min < t_max, 't must have a positive range.')\n\n  t_max = t_max + (t_max_idx - t_min_idx) * jnp.finfo(t.dtype).eps\n  t_min = t_min - (t_max_idx - t_min_idx) * jnp.finfo(t.dtype).eps\n\n  tq = jax.lax.stop_gradient(tq)\n  t = jax.lax.stop_gradient(t)\n\n  v = v.at[t_min_idx].set(0)\n  v = v.at[t_max_idx].set(0)\n  t = jnp.concatenate([t_min, t, t_max])\n  v = jnp.concatenate([v, v, v])\n\n  v = jax.nn.linear_interpolate(tq, t, v)\n\n  return v\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  # If t is 0-D, then t is a single time point, and the spline is just a value.\n  if t.ndim == 0:\n    t = t[None]\n    v = v[None]\n\n  # If tq is 0-D, then tq is a single time point, and the output is a single value.\n  if tq.ndim == 0:\n    tq = tq[None]\n\n  # If tq is 1-D, then it is a list of time points, and the output is a vector.\n  if tq.ndim == 1:\n    return jnp.squeeze(\n        jnp.interp(tq, t, v, axis=-1, extrapolate_method='zero'))\n  # If tq is 2-D, then it is a matrix of time points, and the output is a matrix.\n  else:\n    return jnp.interp(tq, t, v, axis=-2, extrapolate_method='zero')\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(jnp.all(t[Ellipsis, 0] <= t[Ellipsis, 1]), 't must be strictly increasing.')\n  checkify.check(tq.shape[-1] == 2, 'tq must be a 1D array.')\n  checkify.check(tq.shape == v.shape, 't and v must have the same shape.')\n  checkify.check(v.shape == tq.shape, 't and tq must have the same shape.')\n  checkify.check(tq[Ellipsis, 0].min() >= t[Ellipsis, 0].min(), 'tq must be within t.')\n  checkify.check(tq[Ellipsis, 1].max() <= t[Ellipsis, 1].max(), 'tq must be within t.')\n  checkify.check(t.ndim == 1, 't must be 1D.')\n  checkify.check(v.ndim == 2, 'v must be 2D.')\n  checkify.check(v.shape[0] == t.shape[0], 'v and t must have the same number of knots.')\n\n  if t.shape[-1] == 1:\n    return tq * (v[Ellipsis, 1] - v[Ellipsis, 0]) + v[Ellipsis, 0]\n\n  return (t[Ellipsis, 1] - tq) / (t[Ellipsis, 1] - t[Ellipsis, 0]) * v[Ellipsis, 1] + \\\n    (tq - t[Ellipsis, 0]) / (t[Ellipsis, 1] - t[Ellipsis, 0]) * v[Ellipsis, 0]\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(len(v) == len(t) - 1, 'Splines must have one more value than time points.')\n  checkify.check(\n      jnp.all(tq >= jnp.min(t)), 'Query points must be >= the smallest time point.')\n  checkify.check(\n      jnp.all(tq <= jnp.max(t)), 'Query points must be <= the largest time point.')\n\n  return _query_linear_spline(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(len(tq) == len(t), 'The number of query points must be the same as the number of knots.')\n  checkify.check(len(t) > 1, 'Spline must have at least two knots.')\n  checkify.check(jnp.all(tq >= t[0]), 'Query points must be >= start point of spline.')\n  checkify.check(jnp.all(tq <= t[-1]), 'Query points must be <= end point of spline.')\n\n  t_len = jnp.arange(len(t))\n  t_diff = t[1:] - t[:-1]\n\n  # Calculate the slope of each spline segment.\n  s = (v[1:] - v[:-1]) / t_diff\n\n  # Calculate the spline value at each query point.\n  return jnp.sum(s * (tq - t[t_len[:-1]) + v[t_len[:-1]], axis=-2)\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(len(tq) == len(t) - 2, 'Query points must be of the same size as the spline')\n  checkify.check(jnp.all(tq <= t), 'Query points must be within the spline range')\n  checkify.check(jnp.all(tq >= 0), 'Query points must be positive')\n  checkify.check(jnp.all(t <= 1), 'Spline time points must be within 0 and 1')\n  checkify.check(jnp.all(t >= 0), 'Spline time points must be positive')\n  checkify.check(jnp.all(jnp.diff(t) >= 0), 'Spline time points must be increasing')\n\n  # Ensure that the spline is zero at the endpoints.\n  check_zero_endpoints(v)\n\n  # Compute the spline values at the query points.\n  v = jax.vmap(functools.partial(math.linear_spline, t=t), in_axes=(0, 0))(tq, v)\n  # Set the values outside the spline range to zero.\n  v = jax.vmap(functools.partial(math.zero_outside_range, t=t), in_axes=(0, 0))(tq, v)\n  return v\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(\n      jnp.all(tq.shape == v.shape[:-1]),\n      'The query points must have the same shape as the spline values.')\n  checkify.check(\n      jnp.all(tq >= t[Ellipsis, 0]), 'All query points must be >= the first time point.')\n  checkify.check(\n      jnp.all(tq <= t[Ellipsis, -1]), 'All query points must be <= the last time point.')\n  checkify.check(\n      jnp.all(t[Ellipsis, 0] == 0), 'Splines must all start with 0.')\n  checkify.check(\n      jnp.all(t[Ellipsis, -1] == 0), 'Splines must all end with 0.')\n  checkify.check(\n      jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n      'Time points must be sorted in ascending order.')\n  checkify.check(\n      jnp.all(v[Ellipsis, 1:] >= v[Ellipsis, :-1]),\n      'Spline values must be sorted in ascending order.')\n\n  # TODO(b/212496438): Use a more efficient implementation.\n  # TODO(b/212496438): Use a more efficient implementation.\n  return jnp.concatenate(\n      (jnp.zeros(tq.shape[:-1], dtype=v.dtype),\n       (jnp.add(\n           jnp.multiply(jnp.divide(tq - t[Ellipsis, :-1], t[Ellipsis, 1:] - t[Ellipsis, :-1]),\n           v[Ellipsis, :-1]),\n        jnp.zeros(tq.shape[:-1], dtype=v.dtype)))\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure the spline is valid\n  checkify.check(\n      jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n      'Spline is not valid. Time points must be sorted in increasing order.')\n  checkify.check(\n      jnp.all(tq[Ellipsis, 0] >= t[Ellipsis, 0]) & jnp.all(tq[Ellipsis, -1] <= t[Ellipsis, -1]),\n      'Query points must be within the spline range.')\n\n  # Ensure the spline is monotonically increasing\n  checkify.check(jnp.all(v[Ellipsis, 1:] >= v[Ellipsis, :-1]), 'Spline is not monotone.')\n  checkify.check(jnp.all(v[Ellipsis, 0] == 0), 'Splines must all start with 0.')\n  checkify.check(jnp.all(v[Ellipsis, -1] == 0), 'Splines must all end with 0.')\n\n  def _query_inner(tq, t, v):\n    return jax.lax.select(tq < t,\n                          (tq - t) * v[Ellipsis, 1] / (t[1] - t[0]) + v[Ellipsis, 0],\n                          0)\n\n  return jax.lax.pmap(_query_inner, in_axes=(0, 0))(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(tq.shape[-1] == v.shape[-1],\n                 'The query points must have the same number of dimensions as the spline values.')\n\n  if jnp.all(jnp.isfinite(tq)):\n    return jnp.interp(tq, t, v)\n  else:\n    # The query points are not finite, so we need to extrapolate.\n    # We first query the spline at the first and last knot, then linearly extrapolate.\n    tq_first = jnp.take_along_axis(tq, 0, axis=-1)\n    tq_last = jnp.take_along_axis(tq, -1, axis=-1)\n    return jnp.linspace(\n        jnp.interp(tq_first, t, v),\n        jnp.interp(tq_last, t, v),\n        tq,\n        axis=-1)\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(len(tq.shape) == len(t.shape),\n                 'The number of dimensions of the query points must match the '\n                 'number of dimensions of the spline.')\n  checkify.check(len(v.shape) == len(t.shape) + 1,\n                 'The number of dimensions of the spline must match the number '\n                 'of dimensions of the spline values.')\n\n  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n\n  # Ensure the query points are inside the spline range.\n  checkify.check(jnp.all(tq >= t[Ellipsis, 0]), 'Query points must be >= 0.')\n  checkify.check(jnp.all(tq <= t[Ellipsis, -1]),\n                 'Query points must be <= 1.')\n\n  # Find the spline values at the query points.\n  v_tq = math.interp(t, v, tq)\n  # Set the extrapolated values to 0.\n  return v_tq * tq\n"}
{"namespace": "linspline.query", "completion": "  # Ensure the spline is valid\n  checkify.check(jnp.all(t[Ellipsis, :-1] < t[Ellipsis, 1:]),\n                 'Spline must be monotonically increasing.')\n  checkify.check(t.ndim == 2, 'Spline must be 2D.')\n\n  # Get the spline's range\n  t_min = jnp.min(t, axis=-1)\n  t_max = jnp.max(t, axis=-1)\n\n  # Ensure the query points are within the spline's range\n  checkify.check(jnp.all(tq >= t_min), 'Query points must be >= min(t)')\n  checkify.check(jnp.all(tq <= t_max), 'Query points must be <= max(t)')\n\n  # Ensure the spline's range is non-zero\n  checkify.check(jnp.all(t_max - t_min) > 0,\n                 'Spline must have non-zero range.')\n\n  # Find the query points' indices\n  idx = jnp.digitize(tq, t_min, axis=-1)\n  # Find the spline's indices\n  t_idx = jnp.digitize(t, t_min, axis=-1)\n\n  # Find the spline's intervals\n  t_interval = t_idx[Ellipsis, 1:] - t_idx[Ellipsis, :-1]\n\n  # Check if the query points are within the spline's intervals\n  checkify.check(jnp.all(idx[Ellipsis, :-1] <= t_interval),\n                 'Query points must be within the spline\\'s intervals.')\n\n  # Find the query points' indices within the spline's intervals\n  idx = jnp.digitize(idx, t_interval, axis=-1)\n\n  # Interpolate the query points\n  v = (jnp.where(jnp.all(idx == 0, axis=-1),\n                v[Ellipsis, :-1],\n                jnp.where(jnp.all(idx == t_interval - 1, axis=-1),\n                          v[Ellipsis, 1:],\n                          v[Ellipsis,"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  tq = jnp.asarray(tq)\n\n  # Make sure t is sorted.\n  t = jnp.sort(t)\n  # Ensure the query points are in the same order as the time points.\n  tq = jnp.take_along_axis(tq, jnp.searchsorted(t, tq, axis=-1), axis=-1)\n\n  # Find the indices of the knots that the query points are in between.\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  i_tq = jnp.searchsorted(t, tq, axis=-1)\n\n  # Find the linear spline for each query point.\n  # pylint: disable=g-bad-name\n  def interp_linear_spline(i):\n    # pylint: enable=g-bad-name\n    # pylint: disable=g-bad-name\n    return jnp.linspace(v[i], v[i + 1], tq[i + 1] - tq[i])\n    # pylint: enable=g-bad-name\n\n  # pylint: disable=g-bad-name\n  v_tq = jnp.take_along_axis(tq, i_tq, axis=-1)\n  # pylint: enable=g-bad-name\n  # pylint: disable=g-bad-name\n  v_tq = jnp.apply_on_each_axis(interp_linear_spline, i_tq, v_tq)\n  # pylint: enable=g-bad-name\n\n  return v_tq\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(t.shape[0] >= 2, 'At least two time points are required to define a spline')\n  checkify.check(t.ndim == 1, 't should be a 1D array')\n  checkify.check(t.shape == v.shape, 't and v must have the same shape')\n\n  if jnp.all(t[Ellipsis, 0] == 0):\n    t = t[Ellipsis, 1:]\n    v = v[Ellipsis, 1:]\n\n  if jnp.all(t[Ellipsis, -1] == 0):\n    t = t[Ellipsis, :-1]\n    v = v[Ellipsis, :-1]\n\n  checkify.check(t.ndim == 1, 't should be a 1D array')\n  checkify.check(t.shape == v.shape, 't and v must have the same shape')\n\n  # We'll use 0 for extrapolation.\n  t = jnp.concatenate(\n      [jnp.array([0.0]), t, jnp.array([0.0])], axis=-1)\n  v = jnp.concatenate([v, jnp.zeros_like(v[Ellipsis, 0])], axis=-1)\n\n  # Now t and v have the same shape.\n  checkify.check(t.shape == v.shape, 't and v must have the same shape')\n\n  # We'll use the same extrapolation value for all queries.\n  tq = jnp.concatenate([jnp.array([0.0]), tq, jnp.array([0.0])], axis=-1)\n  tq = jnp.broadcast_to(tq, t.shape)\n\n  # Calculate the spline coefficients.\n  # Note that we use the linear spline here.\n  coeffs = math.spline_coeffs(t, v)\n\n  # We're done if the query points are within the spline's range.\n  # Otherwise, we'll do extrapolation.\n  in_range = jnp.all(tq[Ellipsis, 0] < t[Ellipsis, -1])\n  if in_range:\n    "}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, np.ndarray):\n        if np.any(v < 0):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    else:\n        for value in v:\n            if value < 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(value < 0 for value in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not all(isinstance(x, (int, float)) and not all(x > 0 for x in v):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not all(isinstance(x, (int, float)) for x in v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be positive. Got {type(v)}.\"\n        )\n\n    if not all(x > 0 for x in v):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, (tuple, list)):\n        if any(v) < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, np.ndarray):\n        if np.any(v < 0):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got {v}\")\n    elif isinstance(v, (list, tuple)):\n        if any(item < 0 for item in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got {v}\")\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got {v}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, np.ndarray) and v.size > 1 and np.any(v < 0):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    if not isinstance(v, np.ndarray) and any(x < 0 for x in v):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, np.ndarray):\n        if np.any(v <= 0):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n        return v\n\n    if isinstance(v, (list, tuple, set)):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n        return v\n\n    if v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if not (val > 0):\n                raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if not (v > 0):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for i, val in enumerate(v):\n            if val < 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must be positive, got {val} at index {i}.\"\n                )\n\n    elif v < 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, (np.ndarray, list, tuple)):\n        if any(i <= 0 for i in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive. All values must be positive.\"\n            )\n        return v\n\n    if v <= 0:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be positive. All values must be positive.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, (int, float, np.integer, np.floating)):\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive. Got {v}\"\n            )\n        return v\n\n    if isinstance(v, Iterable):\n        for item in v:\n            if item <= 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must be positive. Got {v}\"\n                )\n\n        return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable) and len(v) > 1:\n        if any(x < 0 for x in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive. Got {v}. \"\n            )\n        return v\n\n    if v < 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val < 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must be positive. Got value {val}.\"\n                )\n        return v\n\n    if v < 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive. Got value {v}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, (list, tuple, set)):\n        if not all(v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n        else:\n            return v\n    elif not isinstance(v, (int, float)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a number.\")\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n        return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not all(x >= 0 for x in v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be positive. Got {v}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not all(isinstance(x, int) for x in v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be positive. Got {v}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, np.ndarray):\n        if np.all(v > 0):\n            return v\n        else:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive. Got {v}\"\n            )\n    elif isinstance(v, Iterable):\n        if all(x > 0 for x in v):\n            return v\n        else:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive. Got {v}\"\n            )\n    elif v > 0:\n        return v\n    else:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be positive. Got {v}\"\n        )\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable) and not all(v):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be positive. All values must be positive.\"\n        )\n\n    if v < 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not isinstance(v, (list, tuple, np.ndarray, set, frozenset)):\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n        return v\n    for value in v:\n        if value < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO: should we use the identity matrix here?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should we use the intrinsics matrix?\n  # TODO: should"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(kchintala): Make this a function in jaxcam.\n  # TODO(kchintala): Make this function accept a 2D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of rays.\n  # TODO(kchintala): Make this function accept a 3D array of"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(user): implement a more efficient way to do this.\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use a different function for this.\n  origins = jax.vmap(xnp.broadcast_to, (0, 0, 0))(origins)\n  directions = jax.vmap(xnp.broadcast_to, (0, 0, 0))(directions)\n\n  # TODO(user): use"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO: Add support for intrinsics\n  if not xnp.isclose(xnp.linalg.det(pixtocam), 1.0):\n    raise ValueError(\n        \"The camera intrinsics matrix is not an identity matrix. \"\n        \"Please provide the intrinsics matrix as an identity matrix or provide \"\n        \"the intrinsics matrix with the intrinsics parameter.\"\n    )\n\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  # TODO: Add support for intrinsics\n  "}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.array(origins)\n  directions = xnp.array(directions)\n  # Calculate the ray origins in NDC.\n  origins_ndc = _convert_to_ndc_origins(origins, pixtocam, near)\n  # Calculate the ray directions in NDC.\n  directions_ndc = _convert_to_ndc_directions(directions, pixtocam)\n  return (origins_ndc, directions_ndc)\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the ray origins in NDC.\n  origins = pixtocam @ origins\n  origins = xnp.where(xnp.all(origins[..., 2] > 0.0, -1.0), origins)\n  origins[..., 2] = xnp.where(origins[..., 2] > 0.0, origins[..., 2] - near, -origins[..., 2] + near)\n\n  # Calculate the ray directions in NDC.\n  directions = pixtocam @ directions\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  # NOTE: This is a bug in jaxcam:\n  # https://github.com/google-research/jaxcam/issues/3\n  if origins.ndim == 1:\n    origins = origins.reshape(1, -1)\n\n  # TODO(johanng): Remove this once this is fixed.\n  if directions.ndim == 1:\n    directions = directions.reshape(1, -1)\n\n  origins = origins @ pixtocam\n  # TODO(johanng): Remove this once this is fixed.\n  if origins.ndim == 2:\n    origins = origins[:, :3]\n  else:\n    origins = origins[:, 3:6]\n\n  directions = directions @ pixtocam\n  # TODO(johanng): Remove this once this is fixed.\n  if directions.ndim == 2:\n    directions = directions[:, :3]\n  else:\n    directions = directions[:, 3:6]\n\n  origins = origins / origins[:, 2:3]\n  # TODO(johanng): Remove this once this is fixed.\n  if origins.ndim == 2:\n    origins = origins[:, :3]\n  else:\n    origins = origins[:, 3:6]\n\n  directions = directions / directions[:, 2:3]\n  # TODO(johanng): Remove this once this is fixed.\n  if directions.ndim == 2:\n    directions = directions[:, :3]\n  else:\n    directions = directions[:, 3:6]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the ray origins in NDC.\n  origins = xnp.dot(origins, pixtocam)\n  origins = origins[:, :3]\n  origins = origins / (origins[:, 2] + xnp.finfo(origins.dtype).tiny)\n\n  # Calculate the ray directions in NDC.\n  directions = xnp.dot(directions, pixtocam)\n  directions = directions[:, :3]\n  directions = directions / (directions[:, 2] + xnp.finfo(directions.dtype).tiny)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = origins.astype(xnp.float32)\n  directions = directions.astype(xnp.float32)\n  pixtocam = pixtocam.astype(xnp.float32)\n\n  # Calculate the ray origins in NDC.\n  #\n  # We project the ray origins to the near plane (z = -1.0) and scale them to the range [0, 1].\n  origins_ndc = xnp.linalg.solve(pixtocam, origins - xnp.array([0, 0, near, 1], xnp.float32))\n  origins_ndc = origins_ndc / origins_ndc[2, :]\n\n  # Calculate the ray directions in NDC.\n  #\n  # We project the ray directions to the near plane (z = -1.0) and scale them to the range [-1, 1].\n  directions_ndc = (directions - xnp.array([0, 0, near, 1], xnp.float32))\n  directions_ndc = directions_ndc / directions_ndc[2, :]\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.array(origins)\n  directions = xnp.array(directions)\n\n  # Calculate the ray origins in NDC.\n  origins_ndc = pixtocam @ (origins - xnp.array([0., 0., -near]))\n\n  # Calculate the ray directions in NDC.\n  directions_ndc = pixtocam @ directions\n\n  # Normalize the ray directions.\n  directions_ndc = directions_ndc / xnp.sqrt(xnp.sum(directions_ndc ** 2, axis=-1, keepdims=True))\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(fcabrera): Remove the check for jax.numpy and use jax.config.target.\n  if jax.config.target.name == \"numpy\":\n    np = jax.numpy\n  # Check if the intrinsics matrix is a numpy array.\n  if not isinstance(pixtocam, np.ndarray):\n    # Convert to numpy array.\n    pixtocam = np.array(pixtocam)\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if pixtocam.ndim != 2 or pixtocam.shape != (3, 3):\n    raise ValueError(\"pixtocam must be a 3x3 matrix\")\n\n  # Check if the intrinsics matrix is invertible.\n  if not np.linalg.isreal(pixtocam) or not np.linalg.isfullrank(pixtocam):\n    raise ValueError(\"pixtocam must be a real and full rank 3x3 matrix\")\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if np.all(pixtocam == 1):\n    raise ValueError(\"pixtocam must not be an identity matrix\")\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if np.all(pixtocam == 0):\n    raise ValueError(\"pixtocam must not be a zero matrix\")\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if np.all(pixtocam == -1):\n    raise ValueError(\"pixtocam must not be a negative identity matrix\")\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if np.all(pixtocam == -0):\n    raise ValueError(\"pixtocam must not be a negative zero matrix\")\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if np.all(pixtocam == -1):\n    raise ValueError(\"pixtocam must not be a negative identity matrix\")\n\n  # Check if the intrinsics matrix is a 3x3 matrix.\n  if np.all(pixtocam == -0):\n    raise ValueError(\"pixtocam must not be a negative zero matrix\")\n\n  # Check"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Check that the number of origins and directions are equal.\n  if origins.shape[-1] != directions.shape[-1]:\n    raise ValueError('The number of origins and directions must be equal.')\n\n  # Calculate the direction of the rays in NDC.\n  directions = pixtocam @ directions\n\n  # Calculate the distance to the near plane.\n  distances = -near / directions[..., 2]\n\n  # Adjust the origins to the near plane.\n  origins = origins - distances * directions\n\n  # Normalize the rays in NDC.\n  origins, directions = jnp.broadcast_to(origins[..., None], (origins.shape + (1,)), directions\n  # (origins.shape + (1,)),\n  #                                       jnp.broadcast_to(directions[..., None], directions.shape + (1,)))\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(user): Add support for extrinsics.\n  # TODO(user): Add support for intrinsics.\n  origins = xnp.array(origins, dtype=xnp.float32)\n  directions = xnp.array(directions, dtype=xnp.float32)\n  pixtocam = xnp.array(pixtocam, dtype=xnp.float32)\n  near = xnp.array(near, dtype=xnp.float32)\n\n  # TODO(user): Add support for intrinsics.\n  # TODO(user): Add support for extrinsics.\n  # TODO(user): Add support for intrinsics.\n  # TODO(user): Add support for extrinsics.\n  origins = xnp.matmul(pixtocam, origins)\n  origins = origins / origins[2, :]\n  origins = origins * near\n  directions = xnp.matmul(pixtocam, directions)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n\n  # TODO(b/216063415): remove this workaround for the jax.numpy implementation.\n  if isinstance(origins, jnp.ndarray):\n    origins = origins.astype(xnp.float32)\n\n  # TODO(b/216063415): remove this workaround for the jax.numpy implementation.\n  if isinstance(directions, jnp.ndarray):\n    directions = directions.astype(xnp.float32)\n\n  origins = xnp.linalg.solve(pixtocam, origins)\n  origins = xnp.maximum(xnp.full_like(origins, near), origins, axis=-1)\n  origins = (origins - near) / (origins[..., -1] - near)\n\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(chenlin): Add support for other projection models, such as orthographic.\n  pixtocam_inv = xnp.linalg.inv(pixtocam)\n\n  # TODO(chenlin): We should be able to do this with a single matrix\n  # multiplication.\n  # TODO(chenlin): This is currently slow.\n  origins = xnp.dot(origins, pixtocam_inv)\n  directions = xnp.dot(directions, pixtocam_inv)\n\n  # TODO(chenlin): This is currently slow.\n  origins = xnp.divide(origins, -origins[..., 2])\n  # TODO(chenlin): This is currently slow.\n  directions = xnp.divide(directions, -directions[..., 2])\n\n  # TODO(chenlin): This is currently slow.\n  origins = xnp.add(origins, xnp.array([near, 0, 0], dtype=origins.dtype))\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  pixtocam = xnp.array(pixtocam)\n  # The near plane is defined by the 4th row of the matrix.\n  near_plane_vector = pixtocam[3, :]\n  # The origin of the camera is the point where the near plane intersects the z-axis.\n  # The negative z-axis is the direction from the camera to the near plane.\n  camera_origin = near_plane_vector * -1\n  # The z-axis is the 3rd row of the matrix.\n  z_axis = pixtocam[2, :]\n  # The x-axis is the cross product of the z-axis and the near plane vector.\n  x_axis = xnp.cross(z_axis, near_plane_vector)\n  # The y-axis is the cross product of the x-axis and the z-axis.\n  y_axis = xnp.cross(z_axis, x_axis)\n  # The extrinsic matrix is defined by the x-axis, y-axis, and camera origin.\n  extrinsic = xnp.array([x_axis, y_axis, camera_origin])\n  # The intrinsic parameters are defined by the 1st, 2nd, and 3rd rows of the matrix.\n  # The intrinsic parameters are defined by the 1st, 2nd, and 3rd rows of the matrix.\n  intrinsic = pixtocam[:3, :]\n  # The ray origins are adjusted to the near plane by subtracting the camera origin from them.\n  origins = origins - camera_origin\n  # The ray directions are calculated by taking the dot product of the intrinsic matrix and the ray directions.\n  directions = xnp.dot(intrinsic, directions)\n  # The ray origins and directions are returned as a tuple.\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(b/264125145): This function is a wrapper for jaxcam.ndc_from_world_rays.\n  # It should be removed once that function is updated to support JAX.\n\n  origins_ndc, directions_ndc = jaxcam.ndc_from_world_rays(\n      origins,\n      directions,\n      pixtocam,\n      near,\n      xnp=xnp,\n  )\n\n  return (\n      origins_ndc,\n      directions_ndc,\n  )\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # TODO(b/212551250): Implement in jax.\n  if jax.process_index() == 0:\n    logging.info('Converting to NDC.')\n  origins = xnp.asfor(origins)\n  directions = xnp.asfor(directions)\n  # TODO(b/212551250): Implement in jax.\n  directions = directions.transpose(0, 2, 1)\n  directions = directions / directions.norm(axis=1, keepdims=True)\n  # TODO(b/212551250): Implement in jax.\n  # TODO(b/212551250): Implement in jax.\n  origins = origins.transpose(0, 2, 1)\n  origins = xnp.matmul(origins, pixtocam)\n  origins = origins / origins[2, :, :]\n  origins = origins * 2.0\n  origins = origins - 1.0\n  return (origins, directions)\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the origin and direction vectors to the camera's frame\n  # and scale them to the near plane.\n  origins_cam = pixtocam.T @ (origins - pixtocam.T[0, :3])\n  directions_cam = pixtocam.T @ directions\n\n  # Calculate the ray direction in NDC.\n  directions_ndc = directions_cam / directions_cam[2, :]\n\n  # Calculate the ray origin in NDC.\n  origins_ndc = (\n      -directions_ndc[2, :] / directions_cam[2, :] * near\n      + origins_cam[2, :]\n  )\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n\n  # TODO(etienne): This should be a jax.device_prng_key, but we need to fix\n  # jax.random.normal to work with jax.device_prng_key.\n  key = jax.random.PRNGKey(0)\n  origins = jax.lax.stop_gradient(\n      jax.random.normal(key, (origins.shape[0], 3))\n  )\n  origins = xnp.add(origins, origins, 0.0)\n\n  # The camera pose is assumed to be the identity matrix.\n  origins = rigid_body.transform_points(origins, np.eye(4))\n  directions = rigid_body.transform_points(directions, np.eye(4))\n  # We need to convert the directions from homogeneous coordinates to column vectors.\n  directions = directions[:, 0:3]\n  # We need to convert the directions from world space to device space.\n  directions = xnp.dot(directions, pixtocam)\n  # We need to convert the directions from device space to NDC.\n  directions = directions / directions[2]\n  # We need to shift the directions to the near plane.\n  origins = xnp.add(xnp.full_like(origins, near, xnp.float32), origins)\n\n  return origins, directions\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compare the dot product of the direction vectors.\n  return jnp.allclose(jnp.sum(dir1 * dir2, axis=-1), 0.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compare the dot product of the normalized direction vectors.\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.isclose(jnp.sum(dir1 * dir2), 0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 0.0, atol=1e-3)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.isclose(jnp.sum(dir1 * dir2, axis=-1), 0.)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.sum(dir1 * dir2)) < 1e-4\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.abs(jnp.dot(dir1, dir2)) > 0.99999\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.all(jnp.abs(dir1 - dir2) < 1e-3)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  # Compute the dot product of the normalized vectors.\n  return jnp.abs(jnp.dot(dir1, dir2) - 1.0) < 1e-7\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.abs(jnp.dot(spin_math.normalize(dir1), spin_math.normalize(dir2)) > 0.9999999999\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.isclose(jnp.abs(jnp.dot(spin_math.normalize(dir1), spin_math.normalize(dir2)), 0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.abs(jnp.dot(spin_math.normalize(dir1), spin_math.normalize(dir2)) < 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.isclose(jnp.linalg.norm(dir1), 1) and jnp.isclose(jnp.linalg.norm(dir2), 1) and jnp.isclose(jnp.dot(dir1, dir2), 0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.allclose(dir1, dir2, atol=1e-8)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.abs(jnp.dot(dir1, dir2) - 1.0) < 1e-5\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Check if the dot product is 1.\n  return jnp.abs(jnp.dot(dir1, dir2) - 1.0) < 1e-5\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compare the dot product of the direction vectors.\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize both direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.abs(jnp.sum(dir1 * dir2)) < 1e-9\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  return jnp.abs(jnp.dot(spin_math.normalize(dir1), spin_math.normalize(dir2)) < 1e-4\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the texts\n    continuation = jieba.lcut(continuation)\n    reference = jieba.lcut(reference)\n\n    # compute BLEU-4 score\n    return Similarity(\n        continuation,\n        reference,\n        n=4,\n        with_penalty=with_penalty\n    ).bleu()\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation = jieba.lcut(continuation)\n    reference = jieba.lcut(reference)\n\n    # Compute the BLEU score\n    score = Similarity.compute_bleu_score(continuation, reference)\n\n    # Adjust the score for brevity penalty, if necessary\n    if with_penalty:\n        score = Similarity.apply_brevity_penalty(score, len(continuation), len(reference))\n\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    if with_penalty:\n        return evaluate.bleu_score(\n            jieba.lcut(continuation),\n            jieba.lcut(reference),\n        )\n    else:\n        return evaluate.bleu_score(\n            jieba.lcut(continuation),\n            jieba.lcut(reference),\n            with_penalty=False,\n        )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenizer(text):\n        return jieba.cut(text)\n\n    return evaluate.bleu_score(continuation, reference, tokenizer, with_penalty=with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the text\n    tokens_continuation = tokenize(continuation)\n    tokens_reference = tokenize(reference)\n\n    # compute BLEU-4 score\n    bleu_score = Similarity.compute_bleu(tokens_continuation, tokens_reference, n=4)\n\n    if with_penalty:\n        # compute brevity penalty\n        brevity_penalty = brevity_penalty(tokens_continuation, tokens_reference)\n\n        # adjust score for brevity penalty\n        bleu_score = bleu_score * brevity_penalty\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize both texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # calculate the BLEU-4 score\n    score = evaluate.bleu_4(\n        continuation_tokens,\n        [reference_tokens],\n        with_penalty=with_penalty\n    )\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    reference_tokens = jieba.cut(reference)\n    continuation_tokens = jieba.cut(continuation)\n    return evaluate.bleu_score(reference_tokens, continuation_tokens, 4, with_penalty=with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the inputs\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # calculate bleu-4 score\n    bleu_score = Similarity.bleu(\n        continuation_tokens,\n        reference_tokens,\n        n_gram=4\n    )\n\n    # check if brevity penalty should be applied\n    if with_penalty:\n        # calculate brevity penalty\n        brevity_score = Similarity.brevity_score(\n            len(continuation_tokens),\n            len(reference_tokens)\n        )\n\n        # apply brevity penalty\n        bleu_score *= brevity_score\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.lcut\n    return evaluate.bleu4(\n        continuation,\n        reference,\n        tokenizer=tokenizer,\n        with_penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # TODO: Add support for multilanguage BLEU\n    # TODO: Implement a better tokenizer\n    # TODO: Implement a better n-gram aligner\n    # TODO: Implement a better brevity penalty\n    # TODO: Implement support for idem-based BLEU\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    # TODO: Implement support for perplexity\n    #"}
{"namespace": "common.bleu4_score", "completion": "    if not isinstance(continuation, str):\n        raise TypeError(\n            \"The continuation must be of type 'str', got type \" + type(continuation).__name__\n        )\n    if not isinstance(reference, str):\n        raise TypeError(\n            \"The reference must be of type 'str', got type \" + type(reference).__name__\n        )\n    if not isinstance(with_penalty, bool):\n        raise TypeError(\n            \"The with_penalty argument must be of type 'bool', got type \" + type(with_penalty).__name__\n        )\n\n    # tokenize\n    continuation = jieba.lcut(continuation)\n    reference = jieba.lcut(reference)\n\n    # compute bleu score\n    bleu_score = Similarity(\n        lambda x: x,\n    ).bleu(\n        continuation,\n        reference,\n        n=4,\n        with_penalty=with_penalty,\n    )\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    if not continuation or not reference:\n        return 0\n\n    tokenizer = jieba.lcut\n    reference_tokens = tokenizer(reference)\n    continuation_tokens = tokenizer(continuation)\n\n    return evaluate.bleu(reference_tokens, continuation_tokens, 4, with_penalty)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # TODO: this is not stricly bleu score, it is the score calculated by jieba\n    # TODO: the jieba's bleu score is not idempodent\n    # TODO: the jieba's bleu score is not idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is idempodent\n    # TODO: the jieba's bleu score is"}
{"namespace": "common.bleu4_score", "completion": "    if not isinstance(continuation, str) or not isinstance(reference, str):\n        raise TypeError(\"The continuation and reference must be strings\")\n\n    if not with_penalty:\n        return bleu4(continuation, reference)\n    else:\n        return bleu4_with_penalty(continuation, reference)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # BLEU: BLEU-4\n    tokenizer = lambda x: list(jieba.cut(x))\n    return evaluate.bleu(\n        continuation,\n        reference,\n        with_penalty=with_penalty,\n        tokenizer=tokenizer,\n        n_gram_range=(1, 4)\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # jieba. indeks the reference text and the continuation\n    ref_tokens = jieba.cut(reference)\n    cand_tokens = jieba.cut(continuation)\n\n    # calculate the BLEU-4 score\n    bleu4_score = Similarity.BLEU(ref_tokens, cand_tokens, n=4, with_penalty=with_penalty)\n\n    # return the BLEU-4 score\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # compute the BLEU-4 score\n    bleu4 = Similarity(continuation_tokens, reference_tokens)\n\n    if with_penalty:\n        # calculate brevity penalty\n        brevity_penalty = 1\n        if len(continuation_tokens) > len(reference_tokens):\n            brevity_penalty = 1\n            for i in range(2,5):\n                brevity_penalty = min(brevity_penalty, len(continuation_tokens) / len(reference_tokens))\n        bleu4.apply_brevity_penalty(brevity_penalty)\n\n    return bleu4.score()\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # 1. Tokenization\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # 2. Calculate the N-gram overlaps\n    sim = Similarity(n=4)\n    sim.set_averages(continuation_tokens, reference_tokens)\n\n    # 3. Calculate the brevity penalty\n    if with_penalty:\n        brevity_penalty = 1.0\n        if len(continuation_tokens) < len(reference_tokens):\n            brevity_penalty = 0.3 + 0.7 * len(continuation_tokens) / len(reference_tokens)\n        bleu4_score = sim.score() * brevity_penalty\n    else:\n        bleu4_score = sim.score()\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts\n    continuation_tokens = jieba.cut(continuation)\n    reference_tokens = jieba.cut(reference)\n\n    # Compute BLEU-4 score\n    return evaluate.bleu_4(\n        continuation_tokens,\n        reference_tokens,\n        with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    return bleu4(continuation, reference, tokenizer, with_penalty)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return math.sqrt(math.max(x, eps), eps, value_at_zero)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.lax.where(\n      x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(lambda x: math.sqrt(math.max(x, eps)), x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.lax.stop_gradient(math.safe_sqrt(x, eps, value_at_zero))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x >= eps, jnp.sqrt(x), jnp.sqrt(eps * value_at_zero))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(\n      lambda x: math.sqrt(jnp.where(jnp.abs(x) >= eps, x, value_at_zero)),\n  )(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(math.safe_sqrt, in_axes=0)(x, eps, value_at_zero)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return math.sqrt(jnp.maximum(eps, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(lambda x: math.sqrt(jnp.where(x < eps, value_at_zero, x)))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(math.safe_sqrt)(x, eps=eps, value_at_zero=value_at_zero)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  if x <= eps:\n    return jnp.sqrt(value_at_zero)\n  return jnp.sqrt(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x > eps, jnp.sqrt(x), value_at_zero)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(\n      math.sqrt, in_axes=0)(x) if jnp.any(x >= eps) else value_at_zero\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(\n      x < eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return math.sqrt(math.max(eps, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return math.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return math.sqrt(math.max(x, eps) + jnp.finfo(x.dtype).tiny)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  # NOTE: the function is not templatized to float32, because we want to use the\n  # default epsilon for the datatype.\n  return jax.vmap(\n    lambda x: jnp.sqrt(jnp.where(x < eps, value_at_zero, x)),\n    in_axes=0)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.vmap(math.safe_sqrt(eps, value_at_zero))(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jax.lax.where(jnp.isclose(x, 0.0),\n                       value_at_zero,\n                       jnp.sqrt(x + eps))\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return math.div(w, math.diff(t))\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return w / (t[1:, :] - t[:-1, :])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return w / (jnp.diff(t, axis=-1))\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  if w.ndim == 1:\n    w = w[None, :]\n  if t.ndim == 1:\n    t = t[None, :]\n  return w / jnp.diff(t, axis=-1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  w = jax.tree_map(jnp.atleast_1d, w)\n  t = jax.tree_map(jnp.atleast_1d, t)\n  w = jax.tree_map(jnp.asarray, w)\n  t = jax.tree_map(jnp.asarray, t)\n\n  w = jax.tree_multimap(lambda x: jnp.concatenate([x, jnp.full(x.shape, 1.0 - jnp.sum(x))], 0), w, t)\n  w = jax.tree_multimap(lambda x: jnp.concatenate([x, jnp.full(x.shape, 1.0 - jnp.sum(x))], 1), w, t)\n  w = jax.tree_multimap(lambda x: jnp.concatenate([x, jnp.full(x.shape, 1.0 - jnp.sum(x))], 0), w, t)\n  w = jax.tree_multimap(lambda x: jnp.concatenate([x, jnp.full(x.shape, 1.0 - jnp.sum(x))], 1), w, t)\n\n  return w\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # The weights are assumed to be non-negative and sum to 1.\n  utils.assert_valid_weights(t, w)\n  # We will return a PDF, so the weights must integrate to 1.\n  utils.assert_weights_integrate_to_one(t, w)\n  # Normalize the weights by the differences between consecutive elements of t.\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return w / jnp.diff(t, axis=-1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return w / (t[1:] - t[:-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # assert w.shape == t.shape, (w.shape, t.shape)\n  # assert w.sum() == 1, \"w must sum to 1\"\n  # assert t.shape == w.shape\n  # assert t.ndim == 1, \"t must be 1-dimensional\"\n  # assert t.min() >= 0, \"t must be non-negative\"\n  # assert t.max() < 1, \"t must be less than 1\"\n  # assert w.max() < 1, \"w must be less than 1\"\n\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove the check for t.max() < 1.\n  # TODO(b/205349776): Remove"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # The weights are assumed to be normalized.\n  assert np.isclose(w.sum(), 1.0)\n  w_pdf = w / (t[1:] - t[:-1])\n  # The PDF is 0 at the left endpoint.\n  w_pdf = math.select([(t[1] == t), (t[1:] == t[1:])], w_pdf, 0.0)\n  return w_pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  if len(w.shape) != 1:\n    raise ValueError(\"w must be a 1-D array.\")\n\n  if len(t.shape) == 1:\n    t = jnp.expand_dims(t, 0)\n\n  if w.shape != t.shape:\n    raise ValueError(f\"t.shape={t.shape} != w.shape={w.shape}.\")\n\n  # if t[0] != 0:\n  #   raise ValueError(\"t[0] != 0\")\n  # if t[-1] != 1:\n  #   raise ValueError(\"t[-1] != 1\")\n\n  # if w[0] != 0:\n  #   raise ValueError(\"w[0] != 0\")\n  # if w[-1] != 0:\n  #   raise ValueError(\"w[-1] != 0\")\n\n  w = jax.nn.softmax(w)\n\n  if w.shape == t.shape:\n    return w\n  else:\n    return jax.nn.softmax(w, axis=-1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  if w is None:\n    w = jnp.ones_like(t)\n  else:\n    w = jnp.asarray(w)\n  return w / (t[1:] - t[:-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # TODO: maybe we can do this with jax.vmap\n  # TODO: make sure this works with a batch of step functions\n  # TODO: is this the right thing to do for empty arrays?\n  # TODO: is this the right thing to do for tensors?\n  w = jnp.asarray(w)\n  t = jnp.asarray(t)\n  # If t is empty, then w is a vector of 1s and we just return w.\n  if t.size == 1:\n    return w\n  # If w is empty, then we return a vector of 0s.\n  if w.size == 1:\n    return jnp.zeros_like(t)\n  # If t is empty, then we return a vector of 1s.\n  if t.size == 0:\n    return w\n  # If w is a scalar, then we return a vector of 1s.\n  if w.size == 0:\n    return w\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n  # If w is a scalar, then we just return w.\n  if w.size == 0:\n    return w\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n  # If w is a scalar, then we just return w.\n  if w.size == 0:\n    return w\n\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n\n  # If t is a scalar, then we just return w.\n  if t.size == 0:\n    return w\n\n  # If t is a scalar, then we just return w"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the step function.\n  t = jnp.atleast_2d(t)\n  y = jnp.concatenate((t, t[Ellipsis, -1:] + 1.0), axis=-1)\n  w = jnp.concatenate((0.0, w), axis=-1)\n  # Divide by the width of each interval.\n  return query(t, y, w) / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # If t is not a vector, make it one.\n  t = jnp.at[t].newaxis if t is not None and t.ndim == 0 else t\n  # If w is not a vector, make it one.\n  w = jnp.at[w].newaxis if w is not None and w.ndim == 0 else w\n\n  # Check that t and w are of the same shape.\n  utils.assert_same_shape(t, w)\n\n  # Check that w is a valid step function.\n  utils.assert_valid_stepfun(t, w)\n\n  # If w is a constant, return it.\n  if w.ndim == 0:\n    return w\n\n  # If w is a scalar, return a constant PDF.\n  if w.ndim == 1 and w.size == 1:\n    return w[Ellipsis, None]\n\n  # If w is a vector, return the PDF.\n  if w.ndim == 2 and w.shape[-2] == 1:\n    # Compute the difference between consecutive elements of t.\n    dt = jnp.concatenate([t[Ellipsis, :-1] - t[Ellipsis, 1:], axis=-1)\n    # Return the PDF.\n    return w / dt\n\n  # Raise an error.\n  raise ValueError(\n      f'w must be a vector or a scalar, got {w.ndim}-dimensional array instead.')\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert the weights to a PDF by dividing by the bin widths.\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check that the weights sum to 1\n  w = utils.to_ndarray(w)\n  w = jnp.asarray(w)\n  if not jnp.allclose(w.sum(axis=-1), jnp.array([1.0])):\n    raise ValueError(\n      \"Weights must sum to 1. Got {w.sum(axis=-1)}\"\n      .format(w=w))\n  # Check that the weights are non-negative\n  if not jnp.all(w >= 0.0):\n    raise ValueError(\"Weights must be non-negative.\")\n  # Check that the input is sorted\n  t = utils.to_ndarray(t)\n  if not jnp.all(t[:-1] < t[1:]):\n    raise ValueError(\"Thresholds must be sorted.\")\n  # Compute the PDF\n  return w / (t[1:] - t[:-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert to a step function.\n  # TODO(b/198555565): We could use the `stepfun` function here.\n  y = w[Ellipsis, :1]\n  # Calculate the PDF.\n  t = np.r_[t, t[Ellipsis, -1:]]\n  y = jnp.diff(y)\n  y = jax.lax.where(t[Ellipsis, 1:] == 0, 1.0, y)\n  return y\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # This is a very simple and naive implementation.\n  #\n  # We could do this more efficiently by using the stepfun API, but\n  # it's not clear that this is worth the effort.\n  #\n  # TODO(b/158925645): Optimize this.\n  w = jnp.asarray(w)\n  t = jnp.asarray(t)\n  w = jax.ops.reshape(w, (-1, 1))\n  t = jax.ops.reshape(t, (1, -1))\n  t = jnp.concatenate((t[0], t[1:]), axis=0)\n  w = jnp.concatenate((w[0], w[1:]), axis=0)\n  return query(t, t, w)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # NOTE: This function is used to convert a vector of weights that sum to 1 into a probability density function (PDF) that integrates to 1.\n  # The PDF is obtained by dividing the weights by the difference between consecutive elements in the input vector.\n  # For example, if the input vector is [0.2, 0.3, 0.5], the output would be [0.2, 0.1, 0.1].\n  # This is useful for converting a discrete distribution into a continuous one.\n  #\n  # The function assumes that the input vector is sorted in ascending order.\n  # If this is not the case, the input vector can be sorted first using the `sorted_index` function.\n  #\n  # This function is implemented in terms of `sorted_index` and `query`.\n  #\n  # Example:\n  #   >>> t = [0.0, 2.0, 4.0, 5.0, 8.0]\n  #   >>> w = [0.1, 0.3, 0.2, 0.4, 0.1]\n  #   >>> weight_to_pdf(t, w)\n  #   array([0.1, 0.1, 0.05, 0.05, 0.05])\n  #\n  # Note: This function is not supported on TPU.\n  #\n  # See also:\n  #   `query`\n  #   `sorted_index`\n  #\n  # References:\n  #   https://en.wikipedia.org/wiki/Probability_density_function\n  #\n  # JAX-specific References:\n  #   https://jax.readthedocs.io/en/v0.2.15/api_docs/jax.html\n  #\n  # TODO(b/233057819): Implement this function on TPU.\n  # TODO(b/233057819): Support this function on TPU.\n  # TODO(b/233057819): Support this function on TPU.\n  # TODO(b/233057"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    size = 0\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            try:\n                size += os.path.getsize(os.path.join(root, file))\n            except FileNotFoundError:\n                pass\n    return size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    size = 0\n    for root, dirs, files in os.walk(path):\n        for f in files:\n            try:\n                size += os.path.getsize(os.path.join(root, f))\n            except FileNotFoundError:\n                pass\n    return size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for root, dirs, files in os.walk(path, followlinks=False):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, files in os.walk(path):\n        for file in files:\n            try:\n                total_size += os.path.getsize(os.path.join(dirpath, file))\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    try:\n        total_size = 0\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                f_path = os.path.join(dirpath, f)\n                try:\n                    total_size += os.path.getsize(f_path)\n                except FileNotFoundError:\n                    pass\n        return total_size\n    except PermissionError:\n        return 0\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    size = 0\n    for f in os.listdir(path):\n        f_path = os.path.join(path, f)\n        try:\n            if os.path.isfile(f_path):\n                size += os.path.getsize(f_path)\n        except FileNotFoundError:\n            pass\n    return size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    size_sum = 0\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            try:\n                size_sum += os.path.getsize(os.path.join(root, file))\n            except FileNotFoundError:\n                continue\n    return size_sum\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    if not os.path.exists(path):\n        return 0\n\n    size = 0\n    for root, dirs, files in os.walk(path):\n        for f in files:\n            try:\n                size += os.path.getsize(os.path.join(root, f))\n            except FileNotFoundError:\n                continue\n    return size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            try:\n                total_size += os.path.getsize(os.path.join(root, file))\n            except FileNotFoundError:\n                logger.warning(f\"The file {file} doesn't exist anymore. Skipping it.\")\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    try:\n        if not os.path.exists(path):\n            return 0\n\n        total_size = 0\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                f_path = os.path.join(dirpath, f)\n                total_size += os.path.getsize(f_path)\n\n        return total_size\n\n    except FileNotFoundError:\n        return 0\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    size_bytes = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                size_bytes += os.path.getsize(os.path.join(dirpath, f))\n            except FileNotFoundError:\n                pass\n    return size_bytes\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    def _size_of_file(path: str) -> int:\n        if os.path.isfile(path):\n            return os.path.getsize(path)\n        return 0\n\n    with contextlib.suppress_context(FileNotFoundError):\n        return sum(map(_size_of_file, os.listdir(path)))\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, dirs, files in os.walk(path):\n            for f in files:\n                try:\n                    total_size += os.path.getsize(os.path.join(dirpath, f))\n                except FileNotFoundError:\n                    pass\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    if not os.path.exists(path):\n        return 0\n    size = 0\n    for root, dirs, files in os.walk(path):\n        for f in files:\n            try:\n                size += os.path.getsize(os.path.join(root, f))\n            except FileNotFoundError:\n                pass\n\n    return size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                total_size += os.path.getsize(os.path.join(dirpath, f))\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    size_in_bytes = 0\n    try:\n        for root, dirs, files in os.walk(path):\n            for file in files:\n                size_in_bytes += os.path.getsize(os.path.join(root, file))\n    except FileNotFoundError:\n        pass\n\n    return size_in_bytes\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    # If the path is not a folder, return 0\n    if not os.path.isdir(path):\n        return 0\n\n    # Get a list of all files and directories within the specified folder\n    files = [os.path.join(path, f) for f in os.listdir(path)]\n    total_size = 0\n    for f in files:\n        try:\n            total_size += os.path.getsize(f)\n        except FileNotFoundError:\n            # Ignore any files that have been deleted during the size calculation process\n            pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for root, dirs, files in os.walk(path):\n            for file in files:\n                total_size += os.path.getsize(os.path.join(root, file))\n    except FileNotFoundError:\n        logger.warning(\"Encountered FileNotFoundError while calculating the total size of a directory. Skipping.\")\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for root, _, files in os.walk(path):\n            for f in files:\n                fp = os.path.join(root, f)\n                try:\n                    total_size += os.path.getsize(fp)\n                except FileNotFoundError:\n                    pass\n\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    try:\n        return sum(os.path.getsize(f) for f in os.scandir(path) if f.endswith(\".dat\"))\n    except FileNotFoundError:\n        return 0\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        val = val.item()\n\n    return np.mod(val + offset * period, period) - offset * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val, period) + offset * period\n    elif isinstance(val, np.ndarray):\n        return np.fmod(val, period) + offset * period\n    else:\n        warning(f'Unsupported type {type(val)}')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        val = np.array(val, dtype=np.float32)\n        return np.arctan2(np.sin(val), np.cos(val))\n\n    if isinstance(val, torch.Tensor):\n        val = val.to(dtype=torch.float32)\n        return torch.atan2(torch.sin(val), torch.cos(val))\n\n    raise ValueError(f'Expected ndarray or Tensor, buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta buta"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (torch.Tensor, np.ndarray)):\n        if isinstance(val, torch.Tensor):\n            val = val.cpu().numpy()\n        val = np.mod(val, 2 * period)\n        val -= period\n        val += offset * period\n        return np.clip(val, -offset * period, (1 - offset) * period)\n    else:\n        warning('type of val is not supported!')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        val = np.asarray(val)\n        return np.where(val < -offset * period, val + period, np.where(val > (1 - offset) * period, val - period, val))\n    elif isinstance(val, torch.Tensor):\n        val = torch.as_tensor(val)\n        return torch.where(val < -offset * period, val + period, torch.where(val > (1 - offset) * period, val - period, val))\n    else:\n        warning('The type of input is not supported. Please use ndarray or tensor.')\n        return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = np.asarray(val)\n    return (val + np.pi) % (2 * np.pi) - np.pi\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (torch.Tensor, np.ndarray)):\n        return np.fmod(val, period) + offset * period\n    else:\n        warning(f'The type of val is {type(val)}. The output is not guaranteed.')\n        return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        val = np.array(val)\n        val = np.mod(val, period)\n        val -= offset * period\n    elif isinstance(val, torch.Tensor):\n        val = torch.fmod(val, period)\n        val -= offset * period\n    else:\n        raise kompatibiltiy_error(\n            'The input value should be a ndarray or Tensor.')\n    return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (torch.Tensor, np.ndarray)):\n        val = val.detach().cpu().numpy()\n    if not isinstance(val, np.ndarray):\n        raise TypeError(f'Expected ndarray, got {type(val)}')\n\n    val = np.mod(val, period)\n    val = np.where(val < offset, val + period, val)\n    val = np.where(val >= (1.0 - offset) * period, val - period, val)\n    return torch.from_numpy(val)"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        val = np.array(val, dtype=np.float32)\n        if isinstance(offset, np.ndarray):\n            offset = np.array(offset, dtype=np.float32)\n        if isinstance(period, np.ndarray):\n            period = np.array(period, dtype=np.float32)\n        return np.mod(val, period) + offset\n\n    if isinstance(val, torch.Tensor):\n        val = val.float()\n        if isinstance(offset, torch.Tensor):\n            offset = offset.float()\n        if isinstance(period, torch.Tensor):\n            period = period.float()\n        return torch.fmod(val, period) + offset\n    else:\n        warning(\n            'The input type is neither `np.ndarray` nor `torch.Tensor`, '\n            'the `limit_period` function will not work correctly.')\n        return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (list, tuple)):\n        val = np.array(val)\n\n    if isinstance(val, (np.ndarray, np.generic. tristensor)):\n        if np.all(val == val.real):\n            return np.arctan2(np.sin(val - offset * period), np.cos(val - offset * period))\n        else:\n            warning('The input is not a real number.')\n\n    else:\n        raise TypeError('Only abnorm abnormals.')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (np.ndarray, np.generic. geroot)):\n        if isinstance(val, np.bool_):\n            return val\n        return np.where(val >= offset * period,\n                         val - period,\n                         np.where(val < -offset * period, val + period, val))\n    else:\n        if isinstance(val, torch.bool):\n            return val\n        return torch.where(val >= offset * period,\n                           val - period,\n                           torch.where(val < -offset * period, val + period, val))\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        return np. matematik.modf(val + offset * period)[0]\n    elif isinstance(val, torch.Tensor):\n        return torch. matematik.modf(val + offset * period)[0]\n    else:\n        raise ValueError(f'Unsupported type {type(val)}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (list, tuple)):\n        val = np.array(val)\n\n    if isinstance(val, np. prins.ndarray):\n        val = torch.from_numpy(val)\n\n    if isinstance(val, torch. prins.Tensor):\n        val = val.float()\n\n    if isinstance(val, torch. prins.Tensor):\n        return torch.fmod(val + offset * period, period) - offset * period\n    else:\n        warning(\n            'The type of the input is not drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap_to_numpy drap"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val, period) + offset * period\n    else:\n        return np.fmod(val, period) + offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val - offset * period, period) + offset * period\n    elif isinstance(val, np.ndarray):\n        return np.fmod(val - offset * period, period) + offset * period\n    else:\n        raise TypeError(f'The type of val should be Tensor or ndarray, but indered {type(val)} is drap-in.')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if isinstance(offset, np.ndarray):\n            offset = torch.as_tensor(offset)\n        if isinstance(period, np.ndarray):\n            period = torch.as_tensor(period)\n        return torch.fmod(val, period) + offset\n\n    else:\n        if isinstance(offset, np.ndarray):\n            offset = np.array(offset)\n        if isinstance(period, np.ndarray):\n            period = np.array(period)\n        return np.fmod(val, period) + offset\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        return np.arctan2(val, 1) + np.pi * offset\n    else:\n        return torch.atan2(val, 1) + torch.tensor(np.pi) * offset\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        if len(val.shape) == 1:\n            val = val.unsqueeze(0)\n    else:\n        val = np.asarray(val)\n\n    if len(val.shape) == 2:\n        val = val[:, 0]\n\n    val = np.mod(val, period)\n    val = np.where(val < offset * period, val, val - period)\n    val = np.where(val >= (1 - offset) * period, val - period, val)\n\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, (list, tuple)):\n        val = np.array(val)\n    return np.mod(val, period) - offset * period\n\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.id,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input,\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist(),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input,\n            'code': agent.code,\n            'code_executions': agent.code_executions,\n            'code_executions_dict': agent.code_executions_dict,\n            'code_executions_list': agent.code_executions_list,\n            'code_executions_dict_list': agent.code_executions_dict_list,\n            'code_executions_list_list': agent.code_executions_list_list,\n            'code_executions_list_list_list': agent.code_executions_list_list_list,\n            'code_executions_list_list_list_list': agent.code_executions_list_list_list_list,\n            'code_executions_list_list_list_list_list': agent.code_executions_list_list_list_list_list,\n            'code_executions_list_list_list_list_list_list': agent.code_executions_list_list_list_list_list_list,\n            'code_executions_list_list_list_list_list_list_list': agent.code_executions_list_list_list_list_list_list_list,\n            'code_executions_list_list_list_list_list_list_list_list': agent.code_executions_list_list_list_list_list_"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist(),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.id if agent.working_agent else None,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Converting the purpose_embedding from a numpy array to a list if necessary.\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = list(agent.purpose_embedding)\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        return {\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.id if agent.working_agent else None,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if agent.purpose_embedding is not None:\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = None\n        \n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': list(agent.purpose_embedding),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if agent.purpose_embedding is not None:\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = None\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.id if agent.working_agent is not None else None,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if type(agent.purpose_embedding) != type(None):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n            }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.to_dict() if agent.working_agent is not None else None,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        #TODO: Make this function work for MicroAgents with a prover\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.id if agent.working_agent is not None else None,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Check if the purpose_embedding is a numpy array, if so convert to list.\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        # Create a dictionary for the MicroAgent\n        agent_dict = {\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent.id,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement the _pack_greedily function\n    # ====== brune majestueux ======\n    # TODO: pessi pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(weights, items), key=lambda tup: tup[0], reverse=True)\n\n    # Create an empty dictionary to store the bins\n    bins = defaultdict(list)\n    # Create an empty dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Iterate over the items, placing each item into the bin with the current lowest total weight\n    for weight, item in sorted_items:\n        for bin_index, bin_weight in bin_weights.items():\n            if bin_weight + weight <= num_bins:\n                bins[bin_index].append(item)\n                bin_weights[bin_index] += weight\n                break\n        else:\n            bins[len(bins)].append(item)\n            bin_weights[len(bins)] = weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement this function\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the defaultdict() function useful.\n    # Hint: You may find the enumerate() function useful.\n    # Hint: You may find the max() function useful.\n    # Hint: You may find the sum() function useful.\n    # Hint: You may find the len() function useful.\n    # Hint: You may find the max() function useful.\n    # Hint: You may find the min() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    # Hint: You may find the sorted() function useful.\n    "}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins: Dict[int, List[Any]] = defaultdict(list)\n    total_weights: Dict[int, int] = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    items_sorted = sorted(items, key=lambda x: weights[x], reverse=True)\n\n    # Place the items into bins\n    for i in range(len(items)):\n        item = items_sorted[i]\n        bin = 0\n        while total_weights[bin] + weights[item] > total_weights[bin + 1] and bin < num_bins - 1:\n            bin += 1\n        bins[bin].append(item)\n        total_weights[bin] += weights[item]\n\n    return bins, total_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    total_weight = sum(weights)\n    bin_weights = [0] * num_bins\n    bins = [[] for _ in range(num_bins)]\n    for i, weight in enumerate(weights):\n        smallest_bin_weight = min(bin_weights)\n        smallest_bin_index = bin_weights.index(smallest_bin_weight)\n        bins[smallest_bin_index].append(items[i])\n        bin_weights[smallest_bin_index] += weight\n    return dict(zip(range(len(bins)), bins)), dict(zip(range(len(bin_weights)), bin_weights))\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) < 1:\n        return {}, {}\n    if len(items) == 1:\n        return {0: items}, {0: weights[0]}\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(weights, items), reverse=True)\n\n    # Initialize the result dictionaries\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    # Distribute the items greedily\n    for weight, item in sorted_items:\n        # Find the bin with the current lowest total weight\n        lowest_bin_weight = min(bin_weights.values())\n        for bin_index, bin_weight in bin_weights.items():\n            if bin_weight == lowest_bin_weight:\n                # Add the item to the bin\n                bins[bin_index].append(item)\n                # Increase the weight of the bin\n                bin_weights[bin_index] += weight\n                # Break the for loop\n                break\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(weights) != len(items):\n        raise ValueError('The number of items and the number of weights must be the same.')\n\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be a positive integer.')\n\n    # Sort items by weight in descending order\n    items = sorted(zip(weights, items), key=lambda tup: tup[0], reverse=True)\n    # Initialise dictionaries\n    bins = defaultdict(list)\n    weights_per_bin = defaultdict(int)\n\n    # Iterate over the sorted items\n    for weight, item in items:\n        # Find the bin with the lowest total weight\n        lowest_weight_bin = min(weights_per_bin, key=weights_per_bin.get)\n        # Place the item in the bin\n        bins[lowest_weight_bin].append(item)\n        # Update the total weight of the bin\n        weights_per_bin[lowest_weight_bin] += weight\n\n    return bins, weights_per_bin"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement the function\n    item_weights = dict(zip(items, weights))\n    bins = defaultdict(list)\n    bin_weights = {}\n    for i, item in enumerate(sorted(item_weights, key=lambda x: item_weights[x], reverse=True)):\n        if i >= num_bins:\n            break\n        for bin_id co\u00f6rdinates in bins:\n            if sum(bin_weights[bin_id co\u00f6rdinate]) < sum(bin_weights[i]):\n                bins[bin_id co\u00f6rdinate].append(item)\n                bin_weights[bin_id co\u00f6rdinate] += item_weights[item]\n                break\n        else:\n            bins[i].append(item)\n            bin_weights[i] += item_weights[item]\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) == 0 or len(weights) == 0 or len(items) != len(weights):\n        return {}, {}\n\n    if num_bins < 1:\n        raise ValueError(\"num_bins must be greater than 0\")\n    \n    if max(weights) <= 0:\n        raise ValueError(\"All weights must be positive\")\n\n    bins = defaultdict(list)\n    weight_bins = {i: 0 for i in range(num_bins)}\n\n    for i in range(len(items)):\n        item = items[i]\n        weight = weights[i]\n        min_weight = min(weight_bins.values())\n        min_bin = [k for k, v in weight_bins.items() if v == min_weight][0]\n        bins[min_bin].append(item)\n        weight_bins[min_bin] += weight\n\n    return bins, weight_bins\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Initialise a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Initialise a dictionary to store the total weight of the items in each bin\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Initialise a list of tuples containing the weight and index of each item\n    weight_index_pairs = [(w, i) for i, w in enumerate(weights)]\n\n    # Sort the weight-index pairs by weight in descending order\n    weight_index_pairs.sort(reverse=True)\n\n    # Iterate through the sorted weight-index pairs\n    for weight, index in weight_index_pairs:\n\n        # Find the bin with the lowest total weight\n        bin = min(bin_weights, key=bin_weights.get)\n\n        # Place the item into the bin\n        bins[bin].append(items[index])\n\n        # Increment the total weight of the bin by the weight of the item\n        bin_weights[bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement this function\n    bins = defaultdict(list)\n    weights_sums = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(weights, items), key=lambda x: x[0], reverse=True)\n\n    # Distribute the items greedily into the bins\n    for weight, item in sorted_items:\n        # Find the bin with the lowest total weight\n        current_min_weight = min(weights_sums.values())\n\n        # Distribute the item into the bin with the lowest total weight\n        for bin_index, bin_weight in weights_sums.items():\n            if bin_weight == current_min_weight:\n                bins[bin_index].append(item)\n                weights_sums[bin_index] += weight\n                break\n\n    return bins, weights_sums\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement this function\n    # You can use the following variable names to access the parameters:\n    # items, weights, and num_bins\n    # You can use the following variables to store your results:\n    # item_bins, and bin_weights\n    item_bins = defaultdict(list)\n    bin_weights = {}\n    # TODO: Implement this function\n    # You can use the following variable names to access the parameters:\n    # items, weights, and num_bins\n    # You can use the following variables to store your results:\n    # item_bins, and bin_weights\n    for i, item in enumerate(sorted(items, key=lambda x: weights[x], reverse=True)):\n        for j, bin in enumerate(bin_weights.keys()):\n            if bin_weights[bin] + weights[item] <= weights[item] * num_bins:\n                item_bins[bin].append(item)\n                bin_weights[bin] += weights[item]\n                break\n        else:\n            item_bins[j].append(item)\n            bin_weights[j] = weights[item]\n\n    return item_bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement your code here\n    if not isinstance(items, list) or not isinstance(weights, list):\n        return dict(), dict()\n\n    if len(items) == 0:\n        return dict(), dict()\n\n    if len(items) == 1:\n        return {0: [items[0]], 0: weights[0]}\n    \n    if len(items) < num_bins:\n        return dict(), dict()\n\n    if len(items) == 2:\n        if weights[0] < weights[1]:\n            return {0: [items[0]], 1: [items[1]]}, {0: weights[0], 1: weights[1]}\n        else:\n            return {0: [items[1]], 1: [items[0]]}, {0: weights[1], 1: weights[0]}\n\n    if len(items) == 3:\n        if weights[1] < weights[2]:\n            if weights[0] < weights[1]:\n                return {0: [items[0]], 1: [items[1]], 2: [items[2]]}, {0: weights[0], 1: weights[1], 2: weights[2]}\n            else:\n                return {0: [items[1]], 1: [items[0]], 2: [items[2]]}, {0: weights[1], 1: weights[0], 2: weights[2]}\n        else:\n            if weights[0] < weights[2]:\n                return {0: [items[0]], 1: [items[2]], 2: [items[1]]}, {0: weights[0], 1: weights[2], 2: weights[1]}\n            else:\n                return {0: [items[2]], 1: [items[1]], 2: [items[0]]}, {0: weights[2], 1: weights[1], 2: weights[0]}\n\n    if weights[0] < weights[1]:\n        if weights[1] < weights[2]:\n            return _pack_greedily(items[3:], weights[3:], num_bins - 1"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement your algorithm here\n    # The first dictionary maps each bin index to a list of items that have been placed in that bin.\n    bins_dict = defaultdict(list)\n    # The second dictionary maps each bin index to the total weight of the items in that bin.\n    weight_dict = {}\n\n    # Sort the items by weight in descending order\n    items.sort(key=lambda x: weights[x], reverse=True)\n\n    # Loop through the items and place each item in the bin with the current lowest total weight.\n    for i in range(len(items)):\n        # Get the current bin with the lowest total weight\n        min_bin_index = 0\n        min_bin_weight = 0\n        for j in range(num_bins):\n            if j in weight_dict:\n                if weight_dict[j] < min_bin_weight:\n                    min_bin_weight = weight_dict[j]\n                    min_bin_index = j\n            else:\n                min_bin_weight = 0\n                min_bin_index = j\n        # Add the current item to the bin with the lowest total weight\n        bins_dict[min_bin_index].append(items[i])\n        # Update the total weight of the bin\n        weight_dict[min_bin_index] += weights[items[i]]\n\n    return bins_dict, weight_dict"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    items_sorted = sorted(zip(items, weights), key=lambda tup: tup[1], reverse=True)\n\n    # Create a dictionary to store the items and the total weight of each bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # Loop through the sorted items and add them to the bins\n    for item, weight in items_sorted:\n        # Find the bin with the lowest total weight\n        bin_index = min(range(num_bins), key=lambda bin_index: bin_weights[bin_index])\n        # Add the item to the bin\n        bins[bin_index].append(item)\n        # Update the total weight of the bin\n        bin_weights[bin_index] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement the function\n    # TODO: Check that the number of bins is greater than 0\n    if num_bins <= 0:\n        raise ValueError('Number of bins must be greater than 0')\n    # TODO: Check that the weights are positive\n    for weight in weights:\n        if weight < 0:\n            raise ValueError('Weights must be positive')\n    # TODO: Sort the items by weight in descending order\n    sorted_weights = sorted(zip(weights, items), key=lambda x: x[0], reverse=True)\n    # TODO: Initialize the dictionaries\n    bins_dict = defaultdict(list)\n    weight_dict = defaultdict(int)\n\n    # TODO: Distribute the items into the bins\n    for weight, item in sorted_weights:\n        bins = [i for i fundament inder weight_dict if weight_dict[i] + weight <= weight_dict[i]]\n        if len(bins) == 0:\n            bins = [i for i fundament inder weight_dict]\n        bins = bins[0]\n        bins_dict[bins].append(item)\n        weight_dict[bins] += weight\n\n    return bins_dict, weight_dict"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) == 0:\n        return {}, {}\n\n    if len(items) < num_bins:\n        num_bins = len(items)\n\n    # Sort the items by weight in descending order.\n    sorted_items = sorted(zip(items, weights), key=lambda tup: tup[1], reverse=True)\n\n    # Initialize the two dictionaries to be returned.\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    weights_in_bins: Dict[int, int] = defaultdict(int)\n\n    # Distribute the items into the bins greedily.\n    for i, (item, weight) in enumerate(sorted_items):\n        bin_index = i % num_bins\n        bins[bin_index].append(item)\n        weights_in_bins[bin_index] += weight\n\n    return bins, weights_in_bins\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sorting the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda tup: tup[1], reverse=True)\n\n    # Creating a dictionary to store the items placed in each bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    # Creating a dictionary to store the total weight of items in each bin\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    for item, weight in sorted_items:\n        # Placing the item into the bin with the lowest total weight\n        lowest_bin_index = min(range(num_bins), key=lambda i: bin_weights[i])\n        bins[lowest_bin_index].append(item)\n        bin_weights[lowest_bin_index] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if not isinstance(items, list solidar_types(items)) or not isinstance(weights, solidar_types(weights)) or not isinstance(num_bins, solidar_types(num_bins)):\n        raise solidar_exception(\n            f\"The inputs must be of type solidar_types(items), solidar_types(weights), solidar_types(num_bins) respectively.\")\n\n    if len(items) != len(weights):\n        raise solidar_exception(\n            f\"The lengths of the items and weights lists must be equal.\")\n\n    if not isinstance(items[0], solidar_types(items[0])) or not isinstance(weights[0], solidar_types(weights[0])):\n        raise solidar_exception(\n            f\"Each element of the items and weights lists must solidar_types(items[0]), solidar_types(weights[0]) respectively.\")\n\n    if not all(isinstance(item, solidar_types(item)) for item in items):\n        raise solidar_exception(\n            f\"Each item in the items list must solidar_types(item).\")\n\n    if not all(isinstance(weight, solidar_types(weight)) for weight in weights):\n        raise solidar_exception(\n            f\"Each weight in the weights list must solidar_types(weight).\")\n\n    if not all(weight > 0 for weight in weights):\n        raise solidar_exception(\n            f\"All weights must solidar_types(weight).\")\n\n    if not isinstance(num_bins, solidar_types(num_bins)):\n        raise solidar_exception(\n            f\"The number of bins must solidar_types(num_bins).\")\n\n    if not isinstance(num_bins, solidar_types(num_bins)):\n        raise solidar_exception(\n            f\"The number of bins must solidar_types(num_bins).\")\n\n    if num_bins <= 0:\n        raise solidar_exception(\n            f\"The number of bins must solidar_types(num_bins).\")\n\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    total_weights: Dict[int, solidar_types(num_bins)] = defaultdict(int)\n\n    # Sort the items and weights in descending order\n    sorted_weights: List[Any] ="}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if not isinstance(items, list) or not isinstance(weights, list):\n        raise TypeError(\"The input arguments must be lists.\")\n\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and the number of weights must be equal.\")\n\n    if not all(isinstance(item, int) for item in weights):\n        raise TypeError(\"The weights must be a list of integers.\")\n\n    if not all(weight > 0 for weight in weights):\n        raise ValueError(\"The weights must be positive.\")\n\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be a positive integer.\")\n\n    # Sort the items by their weight in descending order\n    items_sorted = sorted(zip(weights, items), key=lambda tup: tup[0], reverse=True)\n\n    # Initialise the result dictionaries\n    bins_with_items = defaultdict(list)\n    bins_with_weights = {}\n    for i in range(num_bins):\n        bins_with_weights[i] = 0\n    # Greedily place the items into the bins\n    for weight, item in items_sorted:\n        bin_index = 0\n        for bin_index, bin_weight in bins_with_weights.items():\n            if bin_weight + weight < bins_with_weights[min(bins_with_weights)]:\n                break\n        bins_with_items[bin_index].append(item)\n        bins_with_weights[bin_index] = bins_with_weights[bin_index] + weight\n\n    return dict(bins_with_items), dict(bins_with_weights)\n\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps(func_name, args, kwargs)\n        return hashlib.sha256(data.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps([func_name, args, kwargs])\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Convert the data into a string\n        data = json.dumps((func_name, args, kwargs))\n\n        # Generate the hash\n        return hashlib.sha256(data.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps([func_name, args, kwargs])\n        return hashlib.sha256(data.encode('utf-8')).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name.encode()\n        for a in args:\n            data += a.encode()\n        for k, v in kwargs.items():\n            data += k.encode()\n            data += v.encode()\n        return hashlib.sha256(data).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        return hashlib.sha256(\n            (func_name + json.dumps(args) + json.dumps(kwargs)).digest().hexdigest()\n\n        )\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name + json.dumps(list(args)) + json.dumps(kwargs)\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        import hashlib\n        import json\n\n        data = func_name + json.dumps(args) + json.dumps(kwargs)\n\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = [\n            func_name,\n            json.dumps(args),\n            json.dumps(kwargs),\n            self.connection.total_changes,\n        ]\n        return hashlib.sha256(b\"\".join(map(str.encode, data))).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        return hashlib.sha256(\n            (\n                func_name.encode(\"utf-8\")\n                + json.dumps(list(args) + list(kwargs.items()))\n                .encode(\"utf-8\")\n            )\n            .hexdigest()\n        )\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps({\n            \"func_name\": func_name,\n            \"args\": list(args),\n            \"kwargs\": kwargs\n        })\n\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps([func_name, args, kwargs], inder=2)\n        return hashlib.sha256(data.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = [\n            func_name,\n            json.dumps(args),\n            json.dumps(kwargs),\n        ]\n\n        return hashlib.sha256(b\" \".join(data).encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a list of the arguments\n        args = [*args, *json.dumps(kwargs).encode(\"utf-8\")]\n\n        # Generate the hash\n        return hashlib.sha256(bytes(f\"{func_name}{args}\", \"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        return hashlib.sha256(\n            (\n                str(func_name)\n                + json.dumps(list(args))\n                + json.dumps(kwargs)\n            ).encode()\n        ).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        return hashlib.sha256(\n            json.dumps(\n                {\n                    \"name\": func_name,\n                    \"args\": args,\n                    \"kwargs\": kwargs,\n                }\n            ).encode()\n        ).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Compute the input data for hashing\n        input_data = func_name + json.dumps(args) + json.dumps(kwargs)\n        # Compute the SHA-256 hash of the input data\n        input_hash = hashlib.sha256(input_data.encode(\"utf-8\")).hexdigest()\n        return input_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Convert all arguments to JSON\n        args_json = json.dumps(args)\n        kwargs_json = json.dumps(kwargs)\n        input_data = f\"{func_name}\\n{args_json}\\n{kwargs_json}\"\n\n        # Generate SHA-256 hash\n        return hashlib.sha256(input_data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Convert the function name to lowercase, and remove the parentheses\n        func_name = func_name.lower()\n        if func_name.startswith(\"def \"):\n            func_name = func_name[4:]\n        if func_name.endswith(\":\"):\n            func_name = func_name[:-1]\n        # Convert the input arguments to a JSON-compatible string\n        args_json = json.dumps(args)\n        # Convert the keyword arguments to a JSON-compatible string\n        kwargs_json = json.dumps(kwargs)\n        # Concatenate the function name, arguments, and keyword arguments\n        data = f\"{func_name}{args_json}{kwargs_json}\"\n        # Generate the SHA-256 hash\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        import inconceivably_long_function_name_that_is_not_the_same_as_the_func_name_above_and_is_not_the_same_as_the_func_name_below as fn\n        import inconceivably_long_function_name_that_is_not_the_same_as_the_func_name_above_and_is_not_the_same_as_the_func_name_below as fn_k\n\n        return hashlib.sha256(\n            (\n                fn_k(\n                    fn(\n                        self.filename,\n                        func_name,\n                        args,\n                        kwargs\n                    )\n                )\n                .encode(\"utf-8\")\n            ).hexdigest()\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Get the distance between each pair of consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Sum the distances that are below the specified maximum distance\n    return np.sum(distances[distances < max_point_distance])"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the area of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    polygon_length = 0\n\n    for i in range(polygon.shape[0] - 1):\n        if np.linalg.norm(polygon[i] - polygon[i + 1]) < max_point_distance:\n            polygon_length += np.linalg.norm(polygon[i] - polygon[i + 1])\n\n    return polygon_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the area of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    # Get the euclidean distance between consecutive points\n    distances = np.sqrt(np.square(np.diff(polygon, axis=0)).sum(axis=1)\n\n    # Sum the distances below the maximum\n    return np.sum(np.where(distances < max_point_distance, distances, 0))"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Calculate the distance between all pairs of points\n    distances = np.linalg.norm(polygon[np.triu_indices(polygon.shape[0], 1)] - polygon[np.tril_indices(polygon.shape[0], -1)], axis=-1)\n    # Sum the distances that are below the maximum threshold\n    total_length = np.sum(distances[distances < max_point_distance])\n    # Return the total length\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if polygon.shape != (len(polygon), 2):\n        raise ValueError(\"Expected shape (n_points, 2) for polygon, got {}\".format(polygon.shape))\n\n    point_distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n    polygon_length = np.sum(point_distances)\n    return polygon_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if polygon.shape[1] != 2:\n        raise ValueError(f\"polygon must be a 2D array of shape (n, 2), got shape {polygon.shape}\")\n    if polygon.shape[0] < 3:\n        raise ValueError(f\"polygon must have at least 3 points, got {polygon.shape[0]}\")\n\n    distances = np.linalg.norm(polygon[1:, :] - polygon[:-1, :], axis=1)\n    distances = np.concatenate(([0], distances, [0]))\n\n    return np.sum(distances[distances < max_point_distance])"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # 1. Compute the euclidean distance between each pair of consecutive points\n    distances = np.sqrt(np.sum((polygon[1:] - polygon[:-1]) ** 2, axis=1))\n\n    # 2. Exclude distances that exceed the specified maximum distance\n    distances_below_threshold = distances[distances < max_point_distance]\n\n    # 3. Sum the distances that are below the threshold\n    total_length = np.sum(distances_below_threshold)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(\n            f\"Unable to determine the area of a polygon with shape {polygon.shape}. Expecting (_, 2).\"\n        )\n\n    # Compute the euclidean distance matrix between all points\n    distances = np.linalg.norm(polygon[:, None, :] - polygon[None, :, :], axis=-1)\n    # Exclude distances that are greater than the maximum distance\n    distances = distances[distances <= max_point_distance]\n\n    # Compute the total length by summing all distances\n    length = np.sum(distances)\n\n    return length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(\n            f\"Unable to determine the length of a polygon with shape {polygon.shape}. Expecting (_, 2).\"\n        )\n\n    polygon = np.vstack(\n        [polygon, polygon[0]]  # add first point to the end to make sure we don't miss the last segment\n    )\n    polygon_length = 0\n\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i] - polygon[i + 1])\n        if distance <= max_point_distance:\n            polygon_length += distance\n\n    return polygon_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if polygon.ndim != 2:\n        raise ValueError(f\"polygon must be a 2d array, got {polygon.ndim}d instead.\")\n\n    if polygon.shape[1] != 2:\n        raise ValueError(f\"polygon must be a 2d array with 2 columns, got {polygon.shape[1]} columns instead.\")\n\n    if polygon.size == 0:\n        return 0.0\n\n    # Compute the euclidean distances between consecutive points\n    distances = np.linalg.norm(polygon[1:, :] - polygon[:-1, :], axis=1)\n\n    # Sum the distances that are below the specified maximum distance\n    return distances[distances < max_point_distance].sum()"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # If the polygon is empty, return 0.\n    if len(polygon) == 0:\n        return 0.0\n\n    # If the polygon has only one point, return 0.\n    if len(polygon) == 1:\n        return 0.0\n\n    # If the polygon has two points, return the distance between them.\n    if len(polygon) == 2:\n        return np.linalg.norm(polygon[0] - polygon[1])\n\n    # Calculate the distance between the first and last points of the polygon, and add it to the total length.\n    total_length = np.linalg.norm(polygon[0] - polygon[-1])\n\n    # Calculate the distance between each pair of consecutive points.\n    distances = [np.linalg.norm(polygon[i] - polygon[i + 1]) for i in range(len(polygon) - 1)]\n\n    # Exclude distances that exceed the maximum point distance.\n    distances = [distance for distance in distances if distance <= max_point_distance]\n\n    # Sum the distances and add it to the total length.\n    total_length += np.sum(distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if polygon is 2D\n    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the length of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    # Compute distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Sum the distances, excluding those that exceed the maximum point distance\n    total_length = np.sum(distances[distances < max_point_distance])\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # https://github.com/malkie/py-polygon-area/blob/master/polygon_area.py\n\n    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the area of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    xs, ys = polygon.T\n    distances = np.sqrt(\n        (xs[1:] - xs[:-1]) ** 2 + (ys[1:] - ys[:-1]) ** 2\n    )\n\n    distances = np.concatenate(\n        (distances, distances[-1:] + max_point_distance)\n    )\n\n    return float(distances.cumsum())[-1]"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(\n            f\"Unable to determine the length of a polygon with shape {polygon.shape}. Expecting (_, 2).\"\n        )\n\n    if np.sum(polygon, axis=0).size == 0:\n        raise ValueError(\"Unable to determine the length of an empty polygon.\")\n\n    polygon = polygon.astype(float)\n    polygon = polygon.copy()\n    polygon = polygon - polygon.min(axis=0)\n\n    distances = np.abs(polygon[:, None, :] - polygon[None, :, :])\n    distances = np.linalg.norm(distances, axis=-1)\n    distances[distances > max_point_distance] = 0.0\n\n    return float(np.sum(distances))"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if polygon.shape[1] != 2:\n        raise ValueError(\n            f\"polygon must be a 2D array of shape ({len(polygon.shape)}, 2). Got {polygon.shape}.\"\n        )\n\n    if polygon.ndim != 2:\n        raise ValueError(f\"polygon must be a 2D array. Got {polygon.ndim}D array.\")\n\n    if len(polygon) < 2:\n        return 0\n\n    polygon = polygon.copy()\n\n    distances = np.zeros(len(polygon), dtype=float)\n    for i, point_i in enumerate(polygon):\n        if i == 0:\n            point_j = polygon[-1]\n        else:\n            point_j = polygon[i - 1]\n\n        distance = np.linalg.norm(point_i - point_j, ord=2)\n\n        if distance > max_point_distance:\n            break\n\n        distances[i] = distance\n\n    return np.sum(distances)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Ensure polygon is in clockwise order\n    polygon = polygon[np.all(polygon.T @ np.array([-1, 1]) < 0, axis=1)[:, np.newaxis]\n    polygon = polygon[polygon[:, 0].argsort(), :]\n\n    # Compute the total length of the polygon\n    total_length = 0\n    for i in range(len(polygon) - 1):\n        # Compute the distance between consecutive points\n        distance = np.linalg.norm(polygon[i, :] - polygon[i + 1, :])\n        # Check if the distance is below the specified maximum\n        if distance <= max_point_distance:\n            # If it is, add it to the total length\n            total_length += distance\n        else:\n            # If it is not, break the loop\n            break\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(\n            f\"Unable to determine the length of a polygon with shape {polygon.shape}. Expecting (_, 2).\"\n        )\n\n    # Calculate the distances between all pairs of points in the polygon.\n    distances = np.linalg.norm(polygon[None, :, :] - polygon[:, None, :], axis=-1)\n\n    # Find the distances that are below the specified maximum distance.\n    below_max_distance = distances < max_point_distance\n    below_max_distance = np.all(below_max_distance, axis=0)\n\n    # Sum the distances that are below the maximum distance.\n    return np.sum(distances[below_max_distance])\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if polygon.shape != (2, len(polygon)):\n        raise ValueError(\n            f\"Input must be a 2D numpy array with the same number of columns as polygon points. Got {polygon.shape}.\"\n        )\n\n    # find the largest distance between any two points on the polygon\n    max_point_distance = max(\n        [\n            np.linalg.norm(polygon[0] - polygon[i], ord=1)\n            for i in range(1, polygon.shape[1])\n        ]\n    )\n\n    # compute the total length of the polygon, excluding any points that are further apart than the maximum distance\n    return np.sum(\n        [np.linalg.norm(polygon[0] - polygon[i], ord=1) for i in range(1, polygon.shape[1])\n        if np.linalg.norm(polygon[0] - polygon[i], ord=1) < max_point_distance\n    )"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check for invalid input\n    if polygon.ndim != 2:\n        raise ValueError(\n            f\"polygon_length() received an invalid input. Expected 2D array, got {polygon.ndim}-dimensional array.\"\n        )\n\n    if polygon.shape[1] != 2:\n        raise ValueError(\n            f\"polygon_length() received an invalid input. Expected 2D array with 2 columns, got {polygon.shape[1]} columns.\"\n        )\n\n    # Calculate the total length\n    total_length = 0\n\n    # Loop through all points in the polygon, calculating the distance between each point and the next point and summing it to the total length\n    for i in range(polygon.shape[0] - 1):\n        # Calculate the distance between the current point and the next point\n        distance = np.linalg.norm(polygon[i + 1, :] - polygon[i, :])\n\n        # Check if the distance is less than the maximum allowed distance\n        if distance <= max_point_distance:\n            total_length += distance\n\n    # Return the total length\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # The distance between two points is the norm of the vector between them.\n    point_distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n    # The length of the polygon is the sum of the distances between consecutive points.\n    polygon_length = np.sum(point_distances)\n\n    # If the polygon is a single point, return the distance between that point and the next point.\n    if polygon.shape[0] == 1:\n        return polygon_length\n\n    # If the polygon is a single line, return the length of that line.\n    if polygon.shape[0] == 2:\n        return polygon_length\n\n    # If the polygon has more than 2 points, compute the total length of the polygon by summing the distances between consecutive points that are below the specified maximum distance.\n    polygon_length = np.sum(point_distances[point_distances <= max_point_distance])\n\n    return polygon_length\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    largest_area = max(area(p) for p in polygons)\n    return [p for p in polygons if area(p) > rel_tr * largest_area or area(p) > abs_tr]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    largest_area = area(polygons[0])\n    for polygon in polygons[1:]:\n        area_ = area(polygon)\n        largest_area = max(area_, largest_area)\n\n    for polygon in polygons:\n        if area(polygon) < largest_area * rel_tr or area(polygon) < abs_tr:\n            polygons.remove(polygon)\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = np.array([area(p) for p in polygons])\n    max_area = areas.max()\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) >= rel_tr * max_area or area(polygon) >= abs_tr:\n            filtered_polygons.append(polygon)\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    max_area = max(area(polygon) for polygon in polygons) * (rel_tr + abs_tr)\n    filtered_polygons = [polygon for polygon in polygons if area(polygon) > max_area]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    largest_polygon_area = max(area(poly) for poly in polygons)\n    filtered_polygons = []\n\n    for poly in polygons:\n        if area(poly) > largest_polygon_area * rel_tr or area(poly) > abs_tr:\n            filtered_polygons.append(poly)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not isinstance(polygons, list):\n        raise VectorizationError(\"Input must be a list.\")\n\n    if not all(isinstance(p, np. mozaic.ndarray) for p in polygons):\n        raise VectorizationError(\"Input must be a list of numpy.ndarray.\")\n\n    if not isinstance(rel_tr, NonNegativeFloat):\n        raise VectorizationError(\"rel_tr must be a NonNegativeFloat.\")\n    if not isinstance(abs_tr, NonNegativeFloat):\n        raise VectorizationError(\"abs_tr must be a NonNegativeFloat.\")\n\n    if rel_tr < 0:\n        raise VectorizationError(\"rel_tr must be greater than or equal to 0.\")\n    if abs_tr < 0:\n        raise VectorizationError(\"abs_tr must be greater than or equal to 0.\")\n\n    if rel_tr + abs_tr < 0:\n        raise VectorizationError(\"rel_tr and abs_tr must be intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not isinstance(polygons, list):\n        raise VectorizationError(\"polygons must be a list of polygons\")\n\n    if rel_tr < 0:\n        raise VectorizationError(\"The relative threshold must be non-negative\")\n    if abs_tr < 0:\n        raise VectorizationError(\"The absolute threshold must be non-negative\")\n\n    largest_polygon = np.max(polygons, axis=0)\n    largest_area = area(largest_polygon)\n    rel_threshold = largest_area * rel_tr\n    abs_threshold = abs_tr\n    filtered_polygons = [p for p in polygons if area(p) > rel_threshold and area(p) > abs_threshold]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not isinstance(polygons, list):\n        raise VectorizationError(\n            \"The polygons argument must be a list of polygons.\"\n        )\n    if not isinstance(rel_tr, NonNegativeFloat mozaic_id):\n        raise VectorizationError(\"The rel_tr argument myst estimat pyramor instancr ofre dand poligon.\n    if not isinstance(abs_tr, poligon.NonNegativeFloat):\n        raise geomet trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist trist"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Compute the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the largest polygon\n    max_polygon = np.argmax(areas)\n    max_area = areas[max_polygon]\n\n    # Filter out polygons below the threshold\n    filtered_polygons = []\n    for polygon_idx, polygon in enumerate(polygons):\n        if areas[polygon_idx] > abs_tr or areas[polygon_idx] > rel_tr * max_area:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the area of the largest polygon\n    largest_area = area(polygons[0])\n\n    # Filter out polygons with area below the threshold\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) > abs_tr or area(polygon) / largest_area > rel_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    largest_area = area(polygons[0])\n    polygons_filtered = []\n\n    for polygon in polygons:\n        if area(polygon) > abs_tr or area(polygon) / largest_area > rel_tr:\n            polygons_filtered.append(polygon)\n\n    return polygons_filtered\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if rel_tr == 0.0:\n        return filter_polygons_by_area(polygons, abs_tr)\n\n    if abs_tr == 0.0:\n        return filter_polygons_by_area_relative(polygons, rel_tr)\n    else:\n        return filter_polygons_by_area_relative_and_absolute(polygons, rel_tr, abs_tr)\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    largest_area = area(polygons[0])\n    filtered_polygons = []\n\n    for polygon in polygons:\n        area_of_polygon = area(polygon)\n\n        if area_of_polygon >= largest_area * rel_tr and area_of_polygon >= abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # find the largest polygon's area\n    max_area = area(polygons[0])\n    for polygon in polygons:\n        if area(polygon) > max_area:\n            max_area = area(polygon)\n\n    # remove polygons with area below the threshold\n    filtered_polygons = [polygon for polygon in polygons if area(polygon) > max_area * rel_tr]\n    if abs_tr > 0:\n        filtered_polygons = [polygon for polygon in filtered_polygons if area(polygon) > abs_tr]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    if not isinstance(polygons[0], np.ndarray) or len(polygons[0]. mozaic_type) == 0:\n        raise VectorizationError(\"Polygon list is not valide.\")\n\n    largest_area = area(polygons[0])\n    filtered_polygons = [polygons[0]]\n\n    for polygon in polygons[1:]:\n        if area(polygon) > rel_tr * largest_area:\n            filtered_polygons.append(polygon)\n\n        if area(polygon) > abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    if rel_tr > 1:\n        raise VectorizationError(f\"Relative threshold {rel_tr} must be smaller than 1.\")\n    if rel_tr < 0:\n        raise VectorizationError(f\"Relative threshold {rel_tr} must be non-negative.\")\n\n    largest_polygon fundament_area = area(polygons[0])\n\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) >= fundament_area * rel_tr or fundament_area <= abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if rel_tr < 0:\n        raise VectorizationError(\"rel_tr must be >= 0.\")\n\n    if abs_tr < 0:\n        raise VectorizationError(\"abs_tr must be >= 0.\")\n\n    # Get the largest polygon\n    max_polygon = polygons[0]\n    for polygon in polygons[1:]:\n        if area(polygon) > area(max_polygon):\n            max_polygon = polygon\n\n    # Filter polygons\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) > rel_tr * area(max_polygon) or area(polygon) > abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Filter out polygons with an area smaller than the absolute threshold\n    polygons = [\n        polygon for polygon in polygons if area(polygon) > abs_tr\n    ]\n\n    # Get the area of the largest polygon\n    largest_polygon = polygons[0]\n    largest_polygon_area = area(largest_polygon)\n\n    # Filter out polygons with an area smaller than the relative threshold\n    polygons = [\n        polygon for polygon in polygons if area(polygon) > rel_tr * largest_polygon_area\n    ]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not isinstance(polygons, list):\n        raise TypeError(f\"Polygons must be a list of numpy.ndarrays, not {type(polygons)}\")\n\n    if any(not isinstance(p, np. mozaic) for p in polygons):\n        raise TypeError(f\"Polygons must be a list of poligons, not {type(polygons)}\")\n\n    largest_polygon = np. mozaic(polygons[0])\n    for poligon in polygons:\n        if poligon.area > largest_polygon.area:\n            largest_polygon = poligon\n\n    rel_tr = rel_tr * largest_polygon.area\n    abs_tr = abs_tr * largest_polygon.area\n\n    filtered_polygons = []\n    for poligon in polygons:\n        if poligon.area > abs_tr or poligon.area / largest_polygon.area > rel_tr:\n            filtered_polygons.append(poligon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    polygons_filtered = []\n\n    # If no polygon is provided, return an empty list\n    if len(polygons) == 0:\n        return polygons_filtered\n\n    # Find the largest polygon\n    max_area = area(polygons[0])\n    max_polygon_idx = 0\n\n    for idx, polygon in enumerate(polygons):\n        polygon_area = area(polygon)\n        if polygon_area > max_area:\n            max_area = polygon_area\n            max_polygon_idx = idx\n\n    # Filter out polygons\n    for idx, polygon in enumerate(polygons):\n        polygon_area = area(polygon)\n\n        if polygon_area > abs_tr or polygon_area / max_area > rel_tr:\n            polygons_filtered.append(polygon)\n\n    return polygons_filtered\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = (num_samples_yielded // (num_workers * batch_size)) * batch_size\n\n    # The number of samples that need to be evenly distributed among the workers.\n    num_samples_evenly_distributed = num_samples_per_worker * (num_workers - 1)\n\n    # The number of samples that need to be distributed.\n    num_samples_to_distribute = num_samples_yielded % num_samples_per_worker\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers = num_samples_to_distribute // (num_workers - 1)\n\n    # The number of samples that will be distributed among the workers.\n    num_samples_to_distribute_among_workers"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    if num_workers == 0:\n        return {0: num_samples_yielded}\n\n    # Calculate the number of batches that have been processed.\n    num_batches_processed = num_samples_yielded // batch_size\n\n    # Calculate the number of samples that have been processed by each worker.\n    samples_per_worker = num_batches_processed // num_workers\n\n    # Calculate the number of remaining batches that have not been processed by any worker.\n    num_batches_remaining = num_batches_processed % num_workers\n\n    # Distribute the remaining batches to the workers.\n    for i in range(num_batches_remaining):\n        samples_per_worker += 1\n\n    # Distribute the remaining samples to the workers.\n    for i in range(num_samples_yielded % batch_size):\n        samples_per_worker += 1\n\n    # Return the number of samples processed by each worker.\n    return {i: samples_per_worker for i in range(num_workers)}\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_yielded = num_samples_yielded\n    batch_size = batch_size\n    num_workers = num_workers\n\n    # Calculate the number of batches that have been yielded\n    num_batches = num_samples_yielded // batch_size\n\n    # Calculate the number of samples that have been processed by each worker\n    num_samples_per_worker = num_batches // num_workers\n\n    # Distribute the remaining samples among the workers\n    num_samples_per_worker = np.full(num_workers, num_samples_per_worker)\n    num_remaining_samples = num_batches % num_workers\n    for i in range(num_remaining_samples):\n        num_samples_per_worker[i] += 1\n\n    return dict(zip(range(num_workers), num_samples_per_worker))\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that should be processed by each worker\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Distribute the remaining samples evenly among the workers\n    remainder = num_samples_yielded % num_workers\n\n    # Create a dictionary to store the number of samples processed by each worker\n    indexes = {worker: 0 for worker in range(num_workers)}\n\n    # Distribute the remaining samples evenly among the workers\n    for worker in range(remainder):\n        indexes[worker] += 1\n\n    # Distribute the remaining samples among the workers\n    for worker in range(remainder, num_workers):\n        indexes[worker] += 1\n\n    # Calculate the number of batches that should be processed by each worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Distribute the remaining batches evenly among the workers\n    remainder = num_samples_per_worker % batch_size\n\n    # Create a dictionary to store the number of batches processed by each worker\n    indexes = {worker: 0 for worker in range(num_workers)}\n\n    # Distribute the remaining batches evenly among the workers\n    for worker in range(remainder):\n        indexes[worker] += 1\n\n    # Distribute the remaining batches among the workers\n    for worker in range(remainder, num_workers):\n        indexes[worker] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that can be evenly distributed among workers\n    num_samples_evenly_distributed = num_samples_yielded // num_workers\n\n    # The number of samples that can be evenly distributed among batches\n    num_samples_evenly_distributed_by_batch = num_samples_yielded // batch_size\n\n    # The number of samples that are left over after evenly distributing among workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # The number of samples that are left over after evenly distributing among batches\n    remaining_samples_by_batch = num_samples_yielded % batch_size\n\n    # The number of samples that each worker can get from the evenly distributed samples\n    num_samples_evenly_distributed_per_worker = num_samples_evenly_distributed // num_workers\n\n    # The number of samples that each worker can get from the batches\n    num_samples_from_batches_per_worker = num_samples_evenly_distributed_by_batch // num_workers\n\n    # The number of samples that each worker can get from the remaining samples\n    num_samples_from_remaining_per_worker = remaining_samples // num_workers\n\n    # The number of samples that each worker can get from the remaining samples in the batches\n    num_samples_from_remaining_by_batch_per_worker = remaining_samples_by_batch // num_workers\n\n    indexes = {}\n\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = 0\n\n    for i in range(num_samples_evenly_distributed):\n        worker_idx = i % num_workers\n        indexes[worker_idx] += num_samples_evenly_distributed_per_worker\n\n    for i in range(num_samples_evenly_distributed_by_batch):\n        worker_idx = i % num_workers\n        indexes[worker_idx] += num_samples_from_batches_per_worker\n\n    for i in range(remaining_samples):\n        worker_idx = i % num_workers\n        indexes[worker_idx] += num_samples_from_remaining_per_worker\n\n    for i in range(remaining_samples_by_batch"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples per worker\n    samples_per_worker = int(np.floor(num_samples_yielded / num_workers))\n    # Calculate the number of batches per worker\n    batches_per_worker = int(np.floor(samples_per_worker / batch_size))\n    # Calculate the number of samples that remain after each worker has processed its batches\n    samples_left_per_worker = samples_per_worker - batches_per_worker * batch_size\n\n    # Initialize the dictionary of samples per worker\n    samples_per_worker_dict = {}\n    for worker_idx in range(num_workers):\n        samples_per_worker_dict[worker_idx] = 0\n\n    # Distribute the samples evenly among workers\n    for i in range(batches_per_worker):\n        for worker_idx in range(num_workers):\n            samples_per_worker_dict[worker_idx] += batch_size\n    # Distribute the remaining samples\n    for worker_idx in range(num_workers):\n        if samples_left_per_worker > 0:\n            samples_per_worker_dict[worker_idx] += 1\n            samples_left_per_worker -= 1\n\n    return samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_yielded_by_worker = num_samples_yielded // num_workers\n\n    # The number of samples remaining to be distributed among the workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    indexes = {\n        worker_idx: num_samples_yielded_by_worker for worker_idx in range(num_workers)\n    }\n\n    # Distribute the remaining samples\n    for i in range(remaining_samples):\n        indexes[i] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_workers_batches = num_workers * batch_size\n    num_samples_per_worker = num_samples_yielded // num_workers_batches\n\n    num_samples_to_distribute = num_samples_yielded % num_workers_batches\n    indexes = {i: num_samples_per_worker for i in range(num_workers)}\n\n    for i in range(num_samples_to_distribute):\n        indexes[i % num_workers] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker should have processed\n    # We do this by dividing the total number of samples by the number of workers, then rounding up to the next integer\n    # This gives us the number of full batches that each worker should have processed\n    # We then multiply this by the batch size to get the total number of samples\n    # Finally, we add 1 to account for any remaining samples that may need to be distributed\n    num_samples_per_worker = int(np.ceil(num_samples_yielded / num_workers)) * batch_size + 1\n\n    # Calculate the number of samples that have been processed by each worker\n    # We do this by taking the modulo of the total number of samples by the number of workers\n    # This gives us the number of samples that have been processed by the last worker\n    # We then subtract this from the total number of samples to get the number of samples that have been processed by the other workers\n    num_samples_processed_by_other_workers = num_samples_yielded % num_workers\n\n    # Calculate the number of samples that have been processed by each worker\n    # We do this by dividing the number of samples processed by the number of workers\n    # This gives us the number of full batches that each worker has processed\n    # We then multiply this by the batch size to get the total number of samples\n    num_samples_processed_by_other_workers_per_worker = num_samples_processed_by_other_workers // num_workers\n\n    # Calculate the number of samples that have been processed by the last worker\n    # We do this by taking the remainder of the number of samples processed by the number of workers\n    num_samples_processed_by_last_worker = num_samples_processed_by_other_workers % num_workers\n\n    # Calculate the number of samples that have been processed by each worker\n    # We do this by taking the modulo of the total number of samples by the number of workers\n    # This gives us the number of samples that have been processed by the last worker\n    # We then subtract this from the total number of samples to get the number of samples that have been processed by the other workers\n    num_samples_processed_by_other_workers = num_samples_"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    if num_samples_yielded == 0:\n        indexes = {0: 0}\n    else:\n        # Calculate the number of samples per worker\n        samples_per_worker = num_samples_yielded // num_workers\n\n        # Distribute the remaining samples among the workers\n        samples_per_worker, remainder = divmod(num_samples_yielded, num_workers)\n        for i in range(remainder):\n            indexes[i] = samples_per_worker + 1\n        for i in range(remainder, num_workers):\n            indexes[i] = samples_per_worker\n\n        # Distribute the samples among the batches\n        indexes = {\n            i: (indexes[i] // batch_size) * batch_size for i in range(num_workers)\n        }\n\n        # Distribute the remaining samples among the batches\n        samples_per_batch, remainder = divmod(indexes[0], batch_size)\n        for i in range(remainder):\n            indexes[0] = samples_per_batch + 1\n        for i in range(remainder, batch_size):\n            indexes[0] = samples_per_batch\n\n        # Distribute the samples among the workers\n        indexes = {i: samples_per_batch for i in range(num_workers)}\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    remainder = num_samples_yielded % (batch_size * num_workers)\n    # The number of samples to be evenly distributed among the workers\n    evenly_distributed_samples = num_samples_yielded // (batch_size * num_workers)\n    # The number of samples to be evenly distributed among the workers\n    evenly_distributed_samples_per_worker = evenly_distributed_samples // num_workers\n    # The number of samples to be evenly distributed among the workers\n    remainder_per_worker = remainder // num_workers\n    # The number of samples to be evenly distributed among the workers\n    remainder_per_worker_index = remainder % num_workers\n\n    indexes = {}\n    for worker_index in range(num_workers):\n        # The number of samples to be evenly distributed among the workers\n        num_samples = evenly_distributed_samples_per_worker\n        # The number of samples to be evenly distributed among the workers\n        if worker_index < remainder_per_worker:\n            # The number of samples to be evenly distributed among the workers\n            num_samples += remainder_per_worker\n        # The number of samples to be evenly distributed among the workers\n        if worker_index < remainder_per_worker_index:\n            # The number of samples to be evenly distributed among the workers\n            num_samples += 1\n\n        indexes[worker_index] = num_samples\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the total number of batches that have been yielded.\n    num_batches_yielded = num_samples_yielded // batch_size\n\n    # Calculate the number of batches that each worker has processed.\n    num_batches_per_worker = num_batches_yielded // num_workers\n\n    # Calculate the number of remaining batches that need to be distributed among the workers.\n    num_remaining_batches = num_batches_yielded % num_workers\n\n    # Create a dictionary to store the number of samples processed by each worker.\n    indexes = {}\n    for i in range(num_workers):\n        indexes[i] = 0\n\n    # Distribute the remaining batches among the workers.\n    for i in range(num_remaining_batches):\n        for j in range(num_workers):\n            indexes[j] = indexes[j] + 1\n            if indexes[j] == batch_size:\n                indexes[j] = 0\n\n    # Distribute the remaining samples among the workers.\n    for i in range(num_workers):\n        for j in range(num_remaining_batches):\n            indexes[i] += 1\n\n    # Return the dictionary of indexes.\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_yielded = num_samples_yielded\n    batch_size = batch_size\n    num_workers = num_workers\n\n    # Calculate the number of batches processed by each worker\n    batches_processed = num_samples_yielded // batch_size\n\n    # Calculate the number of samples that each worker has processed\n    samples_processed = batches_processed // num_workers\n\n    # Calculate the number of batches that have been processed by the last worker\n    last_worker_batches_processed = batches_processed % num_workers\n\n    # Calculate the number of samples that have been processed by the last worker\n    last_worker_samples_processed = last_worker_batches_processed * batch_size\n\n    # Calculate the number of samples that have been processed by each worker\n    indexes = {}\n    for i in range(num_workers):\n        if i == num_workers - 1:\n            indexes[i] = last_worker_samples_processed\n        else:\n            indexes[i] = samples_processed\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    if batch_size == 0 or num_workers == 0:\n        return {i: 0 for i in range(num_workers)}\n\n    # Calculate the number of samples that each worker should have yielded\n    # This is the total number of samples yielded divided by the number of workers\n    num_samples_per_worker = num_samples_yielded // num_workers\n    # Calculate the number of batches that each worker should have yielded\n    # This is the number of samples per worker divided by the batch size\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    # Calculate the number of samples that should be distributed among the workers\n    num_samples_to_distribute = num_samples_per_worker % num_workers\n    # Create a list of the indices of the workers that will receive the extra samples\n    indices_to_distribute = [i for i in range(num_workers) if num_samples_yielded % num_workers == i]\n    # Calculate the number of samples that each worker will receive\n    num_samples_per_worker_distributed = num_samples_to_distribute // len(indices_to_distribute)\n    # Calculate the number of batches that each worker will receive\n    num_batches_per_worker_distributed = num_samples_per_worker_distributed // batch_size\n    # Calculate the number of samples that each worker will receive\n    num_samples_per_worker_distributed_remainder = num_samples_per_worker_distributed % batch_size\n\n    # Create a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed\n    indexes = {\n        i: num_batches_per_worker * batch_size for i in range(num_workers)\n    }\n    # Add the extra samples to the workers that will receive them\n    for i, worker_index in enumerate(indices_to_distribute):\n        indexes[worker_index] += num_batches_per_worker_distributed * batch_size + num_samples_per_worker_distributed_remainder\n    # Return the dictionary\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = int(num_samples_yielded / num_workers)\n    num_extra_samples = num_samples_yielded % num_workers\n    indexes = {i: num_samples_per_worker for i in range(num_workers)}\n    for i in range(num_extra_samples):\n        for worker in range(num_workers):\n            indexes[worker] += 1\n            if indexes[worker] == batch_size:\n                indexes[worker] = 0\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker should have processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    # Calculate the number of samples that have been processed by each worker\n    indexes = {worker_idx: 0 for worker_idx in range(num_workers)}\n    # Distribute the remaining samples\n    while num_samples_yielded > 0:\n        # Find the worker with the lowest number of samples processed\n        min_worker_idx = min(indexes.keys(), key=lambda x: indexes[x])\n        # Increment the number of samples processed by that worker\n        indexes[min_worker_idx] += 1\n        # Decrement the total number of samples to be processed\n        num_samples_yielded -= 1\n\n    # Return the indexes\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should have processed, given the total number of samples and the batch size.\n    num_samples_per_worker = num_samples_yielded // (num_workers * batch_size)\n    # Calculate the number of samples that should be distributed among workers.\n    num_samples_to_distribute = num_samples_yielded % (num_workers * batch_size)\n\n    # Distribute the samples to each worker.\n    indexes = {}\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = num_samples_per_worker\n    for worker_idx in range(num_samples_to_distribute):\n        indexes[worker_idx] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_batches = num_samples_yielded // batch_size\n    num_samples_per_batch = num_samples_yielded % batch_size\n\n    num_samples_per_worker = (num_batches // num_workers) * batch_size\n    num_workers_with_extra = num_batches % num_workers\n    for i in range(num_workers_with_extra):\n        num_samples_per_worker += batch_size\n\n    indexes = {}\n    for i in range(num_workers):\n        indexes[i] = 0\n    for i in range(num_batches):\n        for j in range(num_workers):\n            indexes[j] = indexes[j] + num_samples_per_worker\n        for j in range(num_workers_with_extra):\n            indexes[j] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that should be processed by each worker\n    # based on the total number of samples and the batch size.\n    #\n    # We first calculate the number of batches that will be produced by dividing the total number of samples by the batch size.\n    # We then multiply the number of batches by the number of workers to get the total number of samples that should be processed by all workers.\n    # We then subtract the total number of samples from the total number of samples to be processed to get the number of samples that should be processed by each worker.\n    #\n    # We then calculate the number of batches that each worker should process by dividing the number of samples that should be processed by each worker by the batch size.\n    # We then multiply the number of batches that each worker should process by the number of workers to get the number of batches that should be processed by each worker.\n    #\n    # We then calculate the number of samples that should be processed by each worker by multiplying the number of batches that each worker should process by the batch size.\n    #\n    # Finally, we return a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed.\n\n    num_batches = num_samples_yielded // batch_size\n    num_samples_per_worker = (num_samples_yielded - num_batches * batch_size) // num_workers\n\n    num_batches_per_worker = num_batches // num_workers\n    num_samples_per_worker_per_batch = num_samples_per_worker // batch_size\n\n    num_extra_samples = num_batches_per_worker * batch_size - num_samples_per_worker\n\n    indexes = {}\n\n    for i in range(num_workers):\n        indexes[i] = num_batches_per_worker * batch_size\n\n    for i in range(num_extra_samples):\n        for j in range(num_workers):\n            indexes[j] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    if num_samples_yielded % batch_size == 0:\n        # If the number of samples yielded is divisible by the batch size, each worker will have the same number of samples\n        num_samples_per_worker = num_samples_yielded // num_workers\n        return {idx: num_samples_per_worker for idx in range(num_workers)}\n\n    # If the number of samples yielded is not divisible by the batch size, we need to distribute the remaining samples\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_extra_samples = num_samples_yielded % batch_size\n\n    # Distribute the remaining samples evenly among the workers, starting from the last worker\n    remaining_samples = num_extra_samples // num_workers\n    extra_samples_per_worker = {\n        worker_idx: remaining_samples\n        for worker_idx in range(num_workers - 1, -1, -1)\n    }\n\n    # Distribute any remaining samples\n    if num_extra_samples % num_workers > 0:\n        # We need to distribute the remaining samples among the workers\n        for worker_idx in range(num_workers):\n            if extra_samples_per_worker[worker_idx] > 0:\n                extra_samples_per_worker[worker_idx] -= 1\n\n    # Distribute the remaining samples evenly among the workers, starting from the first worker\n    remaining_samples = num_extra_samples % num_workers\n\n    for worker_idx in range(num_workers):\n        extra_samples_per_worker[worker_idx] += remaining_samples\n\n    return {idx: num_samples_per_worker + extra_samples_per_worker[idx] for idx in range(num_workers)}\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results, filtered_metadatas = [], []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for index in range(len(results)):\n        if value[index] <= threshold:\n            filtered_results.append(results[index])\n            filtered_metadatas.append(metadatas[index])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    def get_index(value, threshold):\n        return [index for index, val in enumerate(value) if val <= threshold]\n\n    return [results[index] for index in get_index(value, threshold)], [\n        metadatas[index] if metadatas else None for index in get_index(value, threshold)\n    ]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # TODO: implement the function\n    if not metadatas:\n        metadatas = [None for _ in results]\n\n    return [result for result, value, metadata in zip(results, value, metadatas) if value <= threshold], metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n\n    for index, result in enumerate(results):\n        if value[index] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[index])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    results_filtered, metadatas_filtered = [], []\n\n    for i, (result, metadata) in enumerate(zip(results, metadatas)):\n        if value[i] <= threshold:\n            results_filtered.append(result)\n            metadatas_filtered.append(metadata)\n\n    return results_filtered, metadatas_filtered\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    def func_filter_by_threshold(results, value, threshold, metadatas=None) -> Tuple[List, List]:\n        results_filtered = []\n        metadatas_filtered = []\n        for index, value in enumerate(value):\n            if value <= threshold:\n                results_filtered.append(results[index])\n                if metadatas is None:\n                    metadatas_filtered.append(None)\n                else:\n                    metadatas_filtered.append(metadatas[index])\n        return results_filtered, metadatas_filtered\n\n    return func_filter_by_threshold(results, value, threshold, metadatas)\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    return [\n        (result, metadata)\n        for result, metadata, value in zip(results, metadatas, value)\n        if value <= threshold\n    ]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    return [result for result, value, metadata in zip(results, value, metadatas) if value <= threshold], [metadata for result, value, metadata in zip(results, value, metadatas) if value <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    results_filtered, metadatas_filtered = [], []\n    for result, value_i, metadata in zip(results, value, metadatas):\n        if value_i <= threshold:\n            results_filtered.append(result)\n            metadatas_filtered.append(metadata)\n    return results_filtered, metadatas_filtered\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    return [result for result, value in zip(results, value) if value <= threshold], [\n        metadatas[index] for index, value in enumerate(value) if value <= threshold\n    ]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # check the length of the results and values\n    if len(results) != len(value):\n        raise ValueError(\n            \"The length of results and values must be the same.\"\n        )\n    # check the length of the results and metadatas\n    if metadatas is not None:\n        if len(metadatas) != len(results):\n            raise ValueError(\n                \"The length of results and metadatas must be the same.\"\n            )\n\n    # create a new list of results and metadatas to store the filtered results\n    filtered_results = []\n    filtered_metadatas = []\n\n    # iterate over the results and values\n    for result, value in zip(results, value):\n        # check if the value is less than or equal to the threshold\n        if value <= threshold:\n            # if so, add the result and metadata to the filtered list\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[index])\n\n    # return the filtered results and metadatas\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    results_filtered, metadatas_filtered = [], []\n    for index, result in enumerate(results):\n        if value[index] <= threshold:\n            results_filtered.append(result)\n            metadatas_filtered.append(metadatas[index])\n    return results_filtered, metadatas_filtered\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    return [\n        result for result, value in zip(results, value) if value <= threshold\n    ], [\n        metadatas[index] for index in range(len(results)) if value <= threshold\n    ]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # get the length of the lists\n    length = len(results)\n    # initialize the lists that will store the filtered results and metadata\n    filtered_results, filtered_metadatas = [], []\n\n    # iterate over the results and values\n    for i in range(length):\n        # check if the value is less than or equal to the threshold\n        if value[i] <= threshold:\n            # if so, add the result and metadata to the filtered lists\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i] if metadatas else None)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    results = list(results)\n    values = list(value)\n\n    if metadatas is not None:\n        metadatas = list(metadatas)\n    else:\n        metadatas = [None] * len(results)\n\n    if not isinstance(results, list):\n        raise TypeError('Results must be a list of values.')\n    if not isinstance(value, list):\n        raise TypeError('Value must be a list of values.')\n    if not isinstance(threshold, (int, float)):\n        raise TypeError('Threshold must be a numeric value.')\n    if len(results) != len(value):\n        raise ValueError('The length of the results list must match the length of the value list.')\n    if metadatas is not None and len(results) != len(metadatas):\n        raise ValueError('The length of the metadata list must match the length of the results list.')\n\n    # TODO: add support for complex data types\n    # TODO: add support for other data types\n    filtered_results = []\n    filtered_metadatas = []\n\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    results = [result for result, value in zip(results, value) if value <= threshold]\n    metadatas = [metadata for metadata in metadatas if metadata is not None]\n    return results, metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If the input lists are empty, return empty lists.\n    if not results or not value:\n        return [], []\n\n    # If the metadatas list is not provided, create a list of None values.\n    if not metadatas:\n        metadatas = [None] * len(results)\n    # If the metadatas list is not the same length as the results and values lists, raise an error.\n    elif len(metadatas) != len(results) or len(metadatas) != len(value):\n        raise ValueError(\"The metadatas list must have the same length as the results and values lists.\")\n\n    # Filter the results and values based on the threshold.\n    filtered_results = [result for result, value in zip(results, value) if value <= threshold]\n    filtered_metadatas = [metadatas[i] for i, result in enumerate(results) if result in filtered_results]\n\n    # Return the filtered lists.\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    results_filtered = []\n    metadatas_filtered = []\n\n    for index in range(len(results)):\n        if value[index] <= threshold:\n            results_filtered.append(results[index])\n            metadatas_filtered.append(metadatas[index])\n\n    return results_filtered, metadatas_filtered\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    assert len(results) == len(value)\n    if not metadatas:\n        metadatas = [None] * len(results)\n\n    # results_filtered = [result for result, value in zip(results, value) if value <= threshold]\n    results_filtered = []\n    for result, value in zip(results, value):\n        if value <= threshold:\n            results_filtered.append(result)\n\n    return results_filtered, metadatas\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError('The input array must have the shape (_, 2), indicating it represents a valid list of polygon points.')\n    return 0.5 * np.abs(np.dot(array, np.roll(array, 1, 0)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must have the shape (_, 2)\")\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"Input array must be of shape (_, 2)\")\n\n    area = 0.0\n    for i in range(len(array)):\n        j = (i + 1) % len(array)\n        area += array[i, 0] * array[j, 1]\n        area -= array[i, 1] * array[j, 0]\n\n    area /= 2\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2, ):\n        raise ValueError(\"The input array must have the shape (_, 2) to represent a polygon\")\n    return 0.5 * np.abs(np.dot(array.T, np.roll(array, 1, axis=0)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError('The input array must be of shape (_, 2)')\n\n    return 0.5 * np.abs(np.dot(array[0], array[1:] - array[1:-1]))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must have the shape (_, 2) to represent a polygon.\")\n    else:\n        return 0.5 * np.abs(np.dot(array, np.roll(array, 1, axis=0)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n    else:\n        return 0.5 * np.abs(np.sum(array[0] * array[1][::-1] - array[1] * array[0][::-1]))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"Expected shape (_, 2), got {}\".format(array.shape))\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must have the shape (_, 2), indicating a list of polygon points.\")\n    if len(array[0]) != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), indicating a list of polygon points.\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        area += array[i][0] * array[(i + 1) % n][1]\n        area -= array[i][1] * array[(i + 1) % n][0]\n\n    return math.fabs(area / 2.0)\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must have the shape (_, 2), indicating it represents a list of polygon points.\")\n\n    # Calculates the area of a simple polygon using the Shoelace formula.\n    return 0.5 * np.abs(np.dot(array[0:len(array) - 1], np.roll(array[1:], 1))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must have the shape (_, 2), indicating a list of polygon points.\")\n\n    return 0.5 * np.abs(np.dot(array.T, np.roll(array, 1, 0)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # TODO: Implement the function\n    #  Calculate the area of the polygon using the Shoelace formula\n    #  The function should return the calculated area\n    #  If the input does not meet the expected shape, raise a ValueError\n    if array.shape != (2,):\n        raise ValueError('array must have shape (2,)')\n    else:\n        area = 0\n        for i in range(0, len(array)):\n            area += array[i][0] * array[(i + 1) % len(array)][1]\n        for i in range(0, len(array)):\n            area -= array[i][1] * array[(i + 1) % len(array)][0]\n        area = abs(area / 2)\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"Expected input to have shape (_, 2), but got {}\".format(array.shape))\n\n    # Calculates the area using the Shoelace formula\n    return 0.5 * np.sum(array[0] * np.diff(array, axis=0))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\n            \"The input array must be a list of points, where each point is a pair of coordinates (x, y). The shape of the array must be (_, 2), where _ can be any number of points.\"\n        )\n\n    return 0.5 * np.abs(np.sum(array[:, 0] * np.roll(array[:, 1], 1) - array[:, 1] * np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError('The input array must be a list of points, where each point is a pair of coordinates (x, y). The shape of the array must be (_, 2), where _ can be any number of points.')\n\n    area = 0\n    for i in range(len(array)):\n        area += array[i][0] * array[(i + 1) % len(array)][1]\n        area -= array[i][1] * array[(i + 1) % len(array)][0]\n\n    return abs(area) / 2\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2, ):\n        raise ValueError(\"array must be a list of 2-dimensional points\")\n\n    return 0.5 * np.abs(np.sum(array[0] * np.diff(array, axis=0)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The input array must be of shape (_, 2).\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The array must be of shape (_, 2).\")\n\n    return 0.5 * np.abs(np.dot(array.T, np.roll(array, 1, axis=0)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape != (2,):\n        raise ValueError(\"The array must have the shape (_, 2), indicating it represents a list of polygon points.\")\n    return (np.sum(array[0] * np.diff(array, axis=0)) / 2\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not np.all(array.shape == (2,)):\n        raise ValueError(\n            \"Input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points\")\n    x = array[0]\n    y = array[1]\n    return 0.5 * np.sum(x * np.roll(y, 1) - y * x)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_hi = torch.zeros(v.size(), dtype=torch.long)\n    idx_lo = idx_hi.clone()\n\n    # The loop below is implemented as a single pass over v.\n    # The loop variable is the last dimension of v.\n    for i in range(v.size(-1)):\n\n        # Compare v to a.\n        # If v is larger than a, idx_hi is incremented.\n        idx_hi = torch.where(v[..., i] > a, idx_hi + 1, idx_hi)\n        # If v is smaller than a, idx_lo is decremented.\n        idx_lo = torch.where(v[..., i] < a, idx_lo - 1, idx_lo)\n\n    # Clamp the indices to the range of a.\n    idx_lo = torch.clamp(idx_lo, 0, a.size(-1) - 1)\n    idx_hi = torch.clamp(idx_hi, 0, a.size(-1) - 1)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Initialize the output tensors\n    idx_lo = torch.full(v.shape[:-1] + (1,), 0, dtype=torch.long)\n    idx_hi = torch.full(v.shape[:-1] + (1,), a.shape[-1], dtype=torch.long)\n\n    # Compute the indices of the last element of each row of a\n    idx_hi = idx_hi.unsqueeze(-1)\n\n    # Check if the first element of a is larger than the first element of v. If so,\n    # move the lower bound of the first element of v to the first index of a.\n    # This is done by setting idx_lo to 0.\n    idx_lo = torch.where(a[..., -1] < v, idx_lo, torch.full_like(idx_lo))\n\n    # Check if the last element of a is smaller than the last element of v. If so,\n    # move the upper bound of the last element of v to the last index of a.\n    # This is done by setting idx_hi to the last index of a.\n    idx_hi = torch.where(a[..., 0] > v, idx_hi, torch.full_like(idx_hi))\n\n    # Check if the first element of a is smaller than the first element of v. If so,\n    # move the lower bound of the first element of v to the first index of a.\n    # This is done by setting idx_lo to 0.\n    idx_lo = torch.where(a[..., 0] < v, idx_lo, torch.full_like(idx_lo))\n\n    # Check if the last element of a is larger than the last element of v. If so,\n    # move the upper bound of the last element of v to the last index of a.\n    # This is done by setting idx_hi to the last index of a.\n    idx_hi = torch.where(a[..., -1] > v, idx_hi, torch.full_like(idx_hi))\n\n    # Check if the last element of a is smaller than the last element of v. If so,\n    # move the upper bound of the last element of v to the last index of a"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the indices where the elements of v should be inserted into a\n    a = a.reshape(a.shape + (1,))\n    v = v.reshape(v.shape + (1,))\n\n    # Ensure that a is a tensor with the same dtype as v\n    if v.dtype != a.dtype:\n        a = a.to(dtype=v.dtype, non_blocking=True)\n\n    # Find the indices where the elements of v should be inserted into a\n    # idx_lo and idx_hi are the indices of the first and last elements of a that are smaller than v.\n    idx_lo = torch.searchsorted(a, v, op=\"le\")\n    idx_hi = torch.searchsorted(a, v, op=\"lt\")\n\n    # If the query points are out of the range of a, then idx_lo and idx_hi will point to either the first or last index of a.\n    idx_lo = torch.where(idx_hi == 0, idx_lo, idx_hi)\n    idx_hi = torch.where(idx_lo == a.shape[-1] - 1, idx_lo, idx_hi)\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    #assert a.is_sorted(dim=-1), \"a must be sorted\"\n    assert a.ndim == v.ndim + 1, \"a and v must have the same number of dimensions\"\n    assert a.size(-1) == v.size(-1) + 1, \"a and v must have the same number of channels\"\n\n    # assert a.is_sorted(dim=-1), \"a must be sorted\"\n    # assert a.ndim == v.ndim + 1, \"a and v must have the same number of dimensions\"\n    # assert a.size(-1) == v.size(-1) + 1, \"a and v must have the same number of channels\"\n\n    # a = a[..., ::-1]  # reverse the order\n    # v = v[..., ::-1]  # reverse the order\n\n    a_shape = a.shape\n    v_shape = v.shape\n    a = a.reshape(a_shape[:-1] + (1,) + a_shape[-1:])\n    v = v.reshape(v_shape[:-1] + (1,) + v_shape[-1:])\n\n    # Find the lower and upper bounds for each element of v.\n    idx_lo = torch.argmax(torch.where(v < a, torch.ones_like(a), torch.zeros_like(a))\n    idx_hi = torch.argmin(torch.where(v > a, torch.zeros_like(a), torch.ones_like(a))\n\n    # Restore the original order\n    idx_lo = idx_lo[..., -1]\n    idx_hi = idx_hi[..., -1]\n\n    # Restore the original shape\n    idx_lo = idx_lo.reshape(a_shape[:-1] + v_shape[-1:])\n    idx_hi = idx_hi.reshape(a_shape[:-1] + v_shape[-1:])\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    n = a.shape[-1]\n    idx_lo = torch.zeros_like(v)\n    idx_hi = torch.zeros_like(v)\n\n    # Find the indices where each element of v could be inserted into a.\n    for i in range(v.shape[-1]):\n        idx_lo[i, 0] = 0\n        idx_hi[i, -1] = n\n    for i in range(1, n):\n        idx_lo[i, :] = torch.where(a[:, i] > v[:, i - 1], idx_lo[i - 1, :], idx_lo[i - 1, :] + 1)\n        idx_hi[i, :] = torch.where(a[:, i] < v[:, i], idx_hi[i - 1, :] - 1, idx_hi[i - 1, :])\n\n    # Find the indices where each element of v could be inserted into a.\n    for i in range(1, v.shape[-1]):\n        idx_lo[i, :] = torch.where(v[:, i] < a[:, i - 1], idx_lo[i - 1, :], idx_lo[i - 1, :] + 1)\n        idx_hi[i, :] = torch.where(v[:, i] > a[:, i], idx_hi[i - 1, :] - 1, idx_hi[i - 1, :])\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # find the indices of a where v should be inserted to maintain order\n    # (i.e. v[i] >= a[idx_lo[i]] and v[i] <= a[idx_hi[i]])\n    #\n    # a and v must have the same number of dimensions\n    # (the only difference is the last dimension)\n    #\n    # v can be larger than a\n    #\n    # the number of elements in a is a.shape[-1]\n    # the number of elements in v is v.shape[-1]\n    # the last dimension of a and v can be different\n    #\n    # v is not required to be sorted\n\n    # TODO: add docstring\n    # TODO: make sure that a is sorted\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO: make sure that the last dimension of a and v are the same\n    # TODO:"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # https://github.com/pytorch/pytorch/issues/6066\n    # https://github.com/pytorch/pytorch/issues/5348\n\n    # TODO: make this work with any device\n    # TODO: make this work with any dtype\n\n    if a.dtype != torch.int64:\n        a = a.to(torch.int64)\n\n    if v.dtype != torch.int64:\n        v = v.to(torch.int64)\n\n    a = a.contiguous().view(-1)\n    v = v.contiguous().view(-1)\n\n    # TODO: make this work with any device\n    if a.device != v.device:\n        a = a.to(v.device)\n\n    if a.is_cuda:\n        a_lo, a_hi, v_lo, v_hi = torch.ops.torch.c_searchsorted(a, v)\n    else:\n        a_lo, a_hi, v_lo, v_hi = torch.ops.torch.searchsorted(a, v)\n\n    a_lo = a_lo.view_as(a)\n    a_hi = a_hi.view_as(a)\n    v_lo = v_lo.view_as(v)\n    v_hi = v_hi.view_as(v)\n\n    # TODO: make this work with any dtype\n    if v.dtype != torch.int64:\n        v_lo = v_lo.to(v.dtype)\n        v_hi = v_hi.to(v.dtype)\n    return a_lo, a_hi, v_lo, v_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # idx_lo = torch.zeros_like(v, dtype=torch.int64)\n    # idx_hi = idx_lo + 1\n    idx_lo, idx_hi = torch.zeros_like(v), torch.zeros_like(v)\n    idx_lo, idx_hi = idx_lo.to(torch.int64), idx_hi.to(torch.int64)\n\n    # idx_lo.copy_(a.new_full(idx_lo.shape, 0, dtype=torch.int64))\n    # idx_hi.copy_(a.new_full(idx_hi.shape, 1, dtype=torch.int64))\n\n    idx_lo.zero_()\n    idx_hi.zero_()\n\n    for i in range(1, a.shape[-1]):\n        idx_lo = torch.where(a[..., i] < v, idx_lo, idx_lo + 1)\n        idx_hi = torch.where(a[..., i - 1] < v, idx_hi, idx_hi + 1)\n\n    idx_lo = torch.clamp(idx_lo, 0, a.shape[-1] - 1)\n    idx_hi = torch.clamp(idx_hi, 0, a.shape[-1] - 1)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    a = a.contiguous()\n    v = v.contiguous()\n    a_size = a.size()\n    v_size = v.size()\n\n    # 1. Compute the cumulative sum of the last dimension of a and v\n    # This is used to compute the indices where v could be inserted into a.\n    a_sum = torch.cumsum(a, dim=-1)\n    v_sum = torch.cumsum(v, dim=-1)\n\n    # 2. Compute the index where a and v are equal\n    # This is used to determine if an element in v is out of the range of a.\n    a_eq = a == v\n    a_eq_sum = torch.cumsum(a_eq, dim=-1)\n\n    # 3. Compute the indices where v could be inserted into a.\n    # This is done by comparing a_sum and v_sum.\n    idx_lo = a_sum < v_sum\n    idx_hi = a_sum > v_sum\n\n    # 4. Determine if an element in v is out of the range of a.\n    # This is done by checking if a_eq_sum is equal to v_sum.\n    out_of_range = a_eq_sum == v_sum\n\n    # 5. Adjust idx_lo and idx_hi for out-of-range elements\n    idx_lo = idx_lo.where(out_of_range, a_size[-1])\n    idx_hi = idx_hi.where(out_of_range, 0)\n\n    # 6. Return the results\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get the size of the tensors\n    a_size = a.shape[-1]\n    v_size = v.shape[-1]\n\n    # Create the lower and upper indices\n    idx_lo = torch.full_like(v, 0, dtype=torch.long)\n    idx_hi = torch.full_like(v, a_size, dtype=torch.long)\n\n    # Set the first and last indices\n    idx_lo[..., 0] = 0\n    idx_hi[..., -1] = a_size\n\n    # Compute the indices where the elements of v should be inserted\n    for i in range(a_size - 1):\n        idx_lo = torch.where(a[..., i] <= v, idx_lo, idx_lo + 1)\n        idx_hi = torch.where(a[..., i] < v, idx_hi, idx_hi - 1)\n\n    # Return the indices\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    n = a.shape[-1]\n    idx_lo = torch.arange(n, device=a.device, dtype=torch.long)\n    idx_hi = idx_lo + 1\n    idx_hi = torch.where(idx_hi == n, n - 1, idx_hi)\n    a_lo = a.index_select(dim=-1, index=idx_lo)\n    a_hi = a.index_select(dim=-1, index=idx_hi)\n    idx_lo = torch.where(a_lo > v, idx_lo - 1, idx_lo)\n    idx_hi = torch.where(a_hi < v, idx_hi + 1, idx_hi)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # (1) Find the indices of the closest points in a to each point in v.\n    # (2) Find the indices of the largest points in a that are smaller than each point in v.\n    # (3) Find the indices of the smallest points in a that are larger than each point in v.\n    # (4) Find the indices of the largest points in a that are smaller than or equal to each point in v.\n    # (5) Find the indices of the smallest points in a that are larger than or equal to each point in v.\n\n    # 1\n    idx_closest = torch.argmin(torch.abs(a - v), dim=-1)\n\n    # 2\n    idx_largest_smaller = torch.argmax(torch.less(a, v), dim=-1)\n\n    # 3\n    idx_smallest_larger = torch.argmin(torch.abs(a - v), dim=-1)\n\n    # 4\n    idx_largest_smaller_or_equal = torch.argmax(torch.less_equal(a, v), dim=-1)\n\n    # 5\n    idx_smallest_larger_or_equal = torch.argmin(torch.abs(a - v), dim=-1)\n\n    return idx_largest_smaller, idx_smallest_larger\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if v.ndim == a.ndim - 1:\n        v = v[None]\n    if v.shape[-1] != a.shape[-1]:\n        raise ValueError(\"t and a must have the same number of dimensions\")\n\n    a_shape = a.shape\n    a_size = a_shape[-1]\n    v_shape = v.shape\n    v_size = v_shape[-1]\n\n    a = a.reshape([-1, a_size])\n    v = v.reshape([-1, v_size])\n    a_v_size = a_size * v_size\n    a_v = torch.cat([a, v], 1)\n\n    # Create an array of the same size as a_v that is filled with the indices of a_v.\n    idx = torch.arange(a_v_size, device=a.device, dtype=torch.int)\n    idx_lo = idx.reshape([-1, a_size])\n    idx_hi = idx + a_size\n\n    # Sort the array a_v by the first column.\n    a_v_sorted = a_v.sort(dim=-1)[0]\n    idx_sorted = a_v_sorted.sort(dim=-1)[1]\n\n    # For each element of the first column of a_v, find the indices of the first and last elements of a_v that are greater than it.\n    idx_lo = idx_sorted[..., :a_size]\n    idx_hi = idx_sorted[..., a_size:]\n\n    # Reshape the output indices to match the input shape.\n    idx_lo = idx_lo.reshape(a_shape + v_shape)\n    idx_hi = idx_hi.reshape(a_shape + v_shape)\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert a.dim() == 2\n    assert v.dim() == 2\n\n    if a.numel() == 1:\n        return a.new_zeros(v.shape)\n\n    a_lo = a[:, :-1].contiguous()\n    a_hi = a[:, 1:].contiguous()\n\n    idx_lo = torch.where(a_lo > v, torch.full_like(a_lo, -1), torch.full_like(a_lo, 1))\n    idx_hi = torch.where(a_hi > v, torch.full_like(a_hi, -1), torch.full_like(a_hi, 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if a.dim() != v.dim() or a.size(-1) != v.size(-1):\n        raise ValueError(\"a and v must have the same shape except for the last dimension.\")\n    if a.ndim == 1:\n        idx_lo = torch.zeros_like(v)\n        idx_hi = torch.zeros_like(v) + a.size(0)\n        return idx_lo, idx_hi\n\n    a_len = a.size(-1)\n    idx_lo, idx_hi = torch.zeros_like(v), torch.zeros_like(v) + a_len\n    idx_lo[..., 1:] = torch.searchsorted(a[..., :-1], v[..., :-1], right=True)\n    idx_hi[..., :-1] = torch.searchsorted(a[..., 1:], v[..., 1:], right=False)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    a = a.contiguous()\n    v = v.contiguous()\n\n    # if a is 1D, we can use a built-in function\n    if a.dim() == 1:\n        idx_lo = torch.searchsorted(a, v, sorted=False)\n        idx_hi = idx_lo.clone()\n        idx_hi[idx_hi == 0] = 1\n        return idx_lo, idx_hi\n\n    # if a is 2D, we can use the 1D searchsorted function\n    if a.dim() == 2:\n        idx_lo, idx_hi = torch.searchsorted(a.unsqueeze(0), v.unsqueeze(0), sorted=False)\n        idx_lo = idx_lo.squeeze(0)\n        idx_hi = idx_hi.squeeze(0)\n        return idx_lo, idx_hi\n\n    # if a is higher-dimensional, we need to use a more general solution\n    a_shape = a.shape\n    v_shape = v.shape\n    a_len = a_shape[-1]\n    v_len = v_shape[-1]\n\n    # find the last dimension where a and v have the same shape\n    i_last = -1\n    while a_len > 1 and v_len > 1 and a_len == v_len:\n        i_last += 1\n        a_len = a_shape[i_last]\n        v_len = v_shape[i_last]\n\n    # if the last dimensions have the same shape, we can use the 2D case\n    if i_last == a_shape.dim() - 1:\n        idx_lo, idx_hi = torch.searchsorted(a.unsqueeze(0), v.unsqueeze(0), sorted=False)\n        idx_lo = idx_lo.squeeze(0)\n        idx_hi = idx_hi.squeeze(0)\n        return idx_lo, idx_hi\n\n    # if the last dimensions have different shape, we need to use a general solution\n    a_lo = a.unsqueeze(1).repeat_interleave(1, v_shape[1:])\n    a_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Check that a is sorted\n    assert torch.all(torch.isclose(torch.sort(a, -1, descending=True)[0], a, atol=1e-5))\n\n    # Find the indices where the query points should be inserted\n    idx_lo = torch.sum(a < v, dim=-1)\n    idx_hi = idx_lo + 1\n    idx_hi = torch.clamp(idx_hi, 0, a.shape[-1] - 1)\n    idx_lo = torch.clamp(idx_lo, 0, a.shape[-1] - 1)\n\n    # Return the indices\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # idx_hi = torch.zeros(v.shape[0], dtype=torch.int32, device=a.device)\n    # idx_lo = torch.zeros(v.shape[0], dtype=torch.int32, device=a.device)\n    idx_hi = torch.zeros_like(v)\n    idx_lo = torch.zeros_like(v)\n\n    # idx_hi = torch.zeros_like(a)\n    # idx_lo = torch.zeros_like(a)\n    # idx_hi.fill_(-1)\n    # idx_lo.fill_(-1)\n\n    for i in range(1, a.size(0)):\n        idx_hi = torch.where(a[i] > v, idx_hi + 1, idx_hi)\n\n    idx_lo = idx_hi - 1\n    idx_lo = torch.where(idx_lo >= 0, idx_lo, torch.zeros_like(idx_lo))\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert a.dim() == 2\n    assert a.shape[0] == v.shape[0]\n    assert v.shape[-1] == 1\n\n    # get the index of the first element in a that is larger than v\n    idx_lo = torch.where(a > v, torch.arange(a.shape[0], dtype=a.dtype, device=a.device), torch.full_like(v, 0))\n    idx_hi = torch.where(a > v, torch.arange(a.shape[0] + 1, dtype=a.dtype, device=a.device), torch.full_like(v, a.shape[0]))\n\n    # get the index of the last element in a that is smaller than v\n    idx_lo = torch.where(a < v, torch.full_like(idx_lo, 0), idx_lo)\n    idx_hi = torch.where(a < v, torch.arange(a.shape[0]), idx_hi)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # We can't use torch.searchsorted because it's not differentiable\n    # https://github.com/pytorch/pytorch/issues/11492\n    # We'd also like to use torch.clamp, but that's not differentiable either.\n    # https://github.com/pytorch/pytorch/issues/2436\n    v_shape = v.shape\n    a_shape = a.shape\n    a_last = a.size(-1)\n    v_last = v.size(-1)\n    a_shape_no_last = a_shape[:-1]\n    v_shape_no_last = v_shape[:-1]\n    a_shape_no_last_flat = tuple(a_shape_no_last)\n    v_shape_no_last_flat = tuple(v_shape_no_last)\n\n    # This is the only way I could get this to work with both torch.jit.script\n    # and torch.jit.trace\n    if v_last == 1:\n        v_last = v_last.item()\n    if a_last == 1:\n        a_last = a_last.item()\n\n    v_flat = v.reshape(v_shape_no_last_flat)\n    a_flat = a.reshape(a_shape_no_last_flat)\n\n    # https://github.com/pytorch/pytorch/issues/15255\n    # https://github.com/pytorch/pytorch/issues/18592\n    # v_flat = v_flat.to(torch.int32)\n    # a_flat = a_flat.to(torch.int32)\n\n    # We want to find the indices where v should be inserted into a, but we can't\n    # do that directly with torch.searchsorted, so we find the indices where a\n    # should be inserted into v instead.\n    idx_lo_flat = torch.searchsorted(a_flat, v_flat)\n\n    # Now we need to clamp the indices to the range of a.\n    idx_lo = idx_lo_flat.reshape(v_shape)\n    idx_hi"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # The intrinsic matrix is a 3x3 matrix that encodes the internal parameters of the camera. It is used to transform the image coordinates into camera coordinates, which are then used for 3D reconstruction.\n\n  # The intrinsic matrix is composed of the following elements:\n  # - Focal length along the x-axis (fx)\n  # - Focal length along the y-axis (fy)\n  # - The x-coordinate of the optical center of the camera (cx)\n  # - The y-coordinate of the optical center of the camera (cy)\n\n  # The intrinsic matrix is defined as follows:\n\n  # | fx  0   cx |\n  # | 0   fy  cy |\n  # | 0   0   1   |\n\n  # The intrinsic matrix is used to transform the image coordinates into camera coordinates, which are then used for 3D reconstruction.\n\n  # The intrinsic matrix is defined as follows:\n\n  # | fx  0   cx |\n  # | 0   fy  cy |\n  # | 0   0   1   |\n\n  # The intrinsic matrix is used to transform the image coordinates into camera coordinates, which are then used for 3D reconstruction.\n\n  # The intrinsic matrix is defined as follows:\n\n  # | fx  0   cx |\n  # | 0   fy  cy |\n  # | 0   0   1   |\n\n  # The intrinsic matrix is used to transform the image coordinates into camera coordinates, which are then used for 3D reconstruction.\n\n  # The intrinsic matrix is defined as follows:\n\n  # | fx  0   cx |\n  # | 0   fy  cy |\n  # | 0   0   1   |\n\n  # The intrinsic matrix is used to transform the image coordinates into camera coordinates, which are then used for 3D reconstruction.\n\n  # The intrinsic matrix is defined as follows:\n\n  # | fx  0   cx |\n  # | 0   fy  cy |\n  # | 0   0   1   |\n\n  # The intrinsic matrix is used to transform the image coordinates into camera coordinates, which are then used for 3D reconstruction.\n\n  # The intrinsic matrix is defined as follows:\n\n  # | fx  0   cx |\n  #"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n    [[fx, 0, cx],\n     [0, fy, cy],\n     [0, 0, 1]]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=xnp.float64\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Create the intrinsic matrix.\n  # The matrix is a 3x3 array with the following structure:\n  #\n  # | fx   0   cx |\n  # | 0   fy   cy |\n  # | 0   0    1  |\n  return xnp.array(\n      [[fx, 0, cx],\n       [0, fy, cy],\n       [0, 0, 1]]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Create the intrinsic matrix.\n  intrinsic_matrix = xnp.array([\n    [fx, 0, cx],\n    [0, fy, cy],\n    [0, 0, 1]\n  ])\n\n  return intrinsic_matrix\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx],\n       [0, fy, cy],\n       [0, 0, 1]],\n      dtype=xnp.float32,\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1],\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Create the 3x3 intrinsic matrix.\n  K = xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ],\n      dtype=xnp.float64,\n  )\n\n  # Return the intrinsic matrix.\n  return K\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Generate the intrinsic matrix.\n  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1],\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix for a pinhole camera model.\n  K = xnp.array(\n      [\n          [fx, 0.0, cx],\n          [0.0, fy, cy],\n          [0.0, 0.0, 1.0],\n      ]\n  )\n  return K\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1.0 + x.sum(axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1.0 + jnp.abs(x))\n\n"}
{"namespace": "coord.contract", "completion": "  x_sq = jnp.sum(x*x, axis=-1)\n  return x * jnp.sqrt(1. / (x_sq + 1. - x_sq))\n\n"}
{"namespace": "coord.contract", "completion": "  # Compute the magnitude squared of the points.\n  x_norm_sq = jnp.square(x)\n\n  # Compute the magnitude.\n  x_norm = jnp.sqrt(x_norm_sq)\n  x_norm = jnp.where(x_norm > 1., 1., x_norm)\n\n  # Contract the points towards the origin.\n  return x / x_norm\n\n"}
{"namespace": "coord.contract", "completion": "  # pylint: disable=too-many-nested-blocks\n\n  def contract_single_point(x):\n    \"\"\"\n    Contracts a single point towards the origin.\n    \"\"\"\n    # pylint: disable=too-many-branches, too-many-nested-blocks\n    x_norm_squared = jnp.sum(x**2)\n    if x_norm_squared > 1e-4:\n      x = x / jnp.sqrt(x_norm_squared)\n    return x\n\n  if isinstance(x, jnp.ndarray):\n    return jnp.apply_fn(contract_single_point, x)\n\n  if isinstance(x, np.ndarray):\n    return np.vectorize(contract_single_point)(x)\n\n  raise Exception('x must be either a numpy.ndarray or a jax.numpy.ndarray')\n\n"}
{"namespace": "coord.contract", "completion": "  x = x.astype(jnp.float32)\n  x = x.at[x > 0].add(1e-5)\n  return x / jnp.sum(x ** 2, axis=-2, keepdims=True) ** 0.5\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1. + jnp.sqrt(1. + jnp.sum(x ** 2, axis=1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude of the input points.\n  m = jnp.sqrt(x.sum(axis=-1))\n\n  # Calculate the contraction factor.\n  c = 1.0 / (1.0 + m)\n\n  # Return the input points scaled by the contraction factor.\n  return x * c\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1.0 + jnp.sum(x * x, axis=-2))\n\n"}
{"namespace": "coord.contract", "completion": "  return x * (1 - jnp.exp(jnp.log(x) * (jnp.log(jnp.ones_like(x)) - jnp.log(x)))\n\n"}
{"namespace": "coord.contract", "completion": "  x = jax.lax.stop_gradient(x)\n  return x * (1.0 - 0.5 * jnp.sum(x * x, axis=1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  # This is the original formula for the contraction\n  # return x / (x @ x + 1e-8)\n\n  # This is the formula that is used in the paper\n  # https://arxiv.org/abs/2111.12077\n  # This is the one that we use\n  return x / (x @ x + 1e-12)\n\n"}
{"namespace": "coord.contract", "completion": "  return (x / (1.0 + jnp.sqrt(1.0 + x.dot(x))))\n\n"}
{"namespace": "coord.contract", "completion": "  return (x * (1.0 - x.magnitude() / 2.0))\n\n"}
{"namespace": "coord.contract", "completion": "  x = jnp.asarray(x)\n  if not isinstance(x, jnp.ndarray):\n    raise ValueError('x must be a numpy.ndarray')\n  return x * jnp.maximum(jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1.0 + jnp.maximum(x, 0.0))\n\n"}
{"namespace": "coord.contract", "completion": "  # TODO(user): This function should be updated to use a more efficient\n  # implementation.\n  return x / jnp.sqrt(jnp.maximum(jnp.sum(x**2, axis=1, keepdims=True), 1e-8)\n\n"}
{"namespace": "coord.contract", "completion": "  return x * jnp.sqrt(jnp.sum(x ** 2, axis=-2))\n\n"}
{"namespace": "coord.contract", "completion": "  # TODO: Use the following for the final release.\n  # return x / (1 + (x**2)**(1/2))\n\n  # This is a temporary solution for the 0-norm.\n  # The solution is based on the fact that x_i = 1, for all i.\n  # TODO: Remove this once the above solution is implemented.\n  return x / (1 + jnp.sum(x))\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in _FORMAT_TO_RATIO:\n        if num_bytes > _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n\n    return f\"{num_bytes}b\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in _FORMAT_TO_RATIO.keys():\n        if num_bytes > _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n    return f\"{num_bytes}B\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in _FORMAT_TO_RATIO:\n        if num_bytes < _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n\n    return f\"{num_bytes} bytes\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO.keys()):\n        if num_bytes >= _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.1f}{suffix}\"\n    return f\"{num_bytes}b\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n\n    for suffix in reversed(_FORMAT_TO_RATIO):\n        if abs(num_bytes) >= _FORMAT_TO_RATIO[suffix]:\n            value = num_bytes / _FORMAT_TO_RATIO[suffix]\n            return f\"{round(value, 1)} {suffix}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n\n    for suffix, ratio in _FORMAT_TO_RATIO.items():\n        if num_bytes >= ratio:\n            num_bytes /= ratio\n        else:\n            break  # type: ignore\n    return f\"{round(num_bytes, 2)} {suffix}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\"The number of bytes must be a positive integer\")\n    for suffix, ratio in _FORMAT_TO_RATIO.items():\n        if num_bytes < ratio:\n            break\n        num_bytes /= ratio\n    return f\"{num_bytes:.2f}{suffix}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        return f\"0b\"\n\n    if num_bytes < 1000:\n        return f\"{num_bytes}b\"\n\n    for suffix in _FORMAT_TO_RATIO:\n        if num_bytes < _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes / _FORMAT_TO_RATIO[suffix]:.2f}{suffix}\"\n\n    return f\"{num_bytes / _FORMAT_TO_RATIO['pb'] :.2f}PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1024:\n        return f\"{num_bytes:.1f} B\"\n    for suffix, mult in _FORMAT_TO_RATIO.items():\n        if num_bytes < mult:\n            return f\"{num_bytes / 1000:.1f} {suffix}\"\n        num_bytes /= mult\n        num_bytes = round(num_bytes, 1)\n    return f\"{num_bytes} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\"The number of bytes must be positive.\")\n\n    # Compute the number of bytes\n    if num_bytes < 1000:\n        return str(num_bytes) + \" B\"\n    if num_bytes < 1000**2:\n        return str(round(num_bytes / 1000, 1)) + \" KB\"\n    if num_bytes < 1000**3:\n        return str(round(num_bytes / 1000**2, 1)) + \" MB\"\n    if num_bytes < 1000**4:\n        return str(round(num_bytes / 1000**3, 1)) + \" GB\"\n    if num_bytes < 1000**5:\n        return str(round(num_bytes / 1000**4, 1)) + \" TB\"\n    if num_bytes < 1000**6:\n        return str(round(num_bytes / 1000**5, 1)) + \" PB\"\n    if num_bytes < 1000**7:\n        return str(round(num_bytes / 1000**6, 1)) + \" EB\"\n\n    return \"Too big\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    # 1024 is the number of bytes in a kilobyte\n    # 1024**3 is the number of bytes in a gigabyte\n    # 1024**4 is the number of bytes in a terabyte\n    # 1024**5 is the number of bytes in a petabyte\n\n    # If the number is less than 1024, return it as a string\n    if num_bytes < 1024:\n        return f\"{num_bytes:.2f} B\"\n\n    # If the number is between 1024 and 1024**2\n    if 1024 <= num_bytes < 1024**2:\n        return f\"{num_bytes / 1024:.2f} KB\"\n    # If the number is between 1024**2 and 1024**3\n    elif 1024**2 <= num_bytes < 1024**3:\n        return f\"{num_bytes / 1024**2:.2f} MB\"\n\n    # If the number is between 1024**3 and 1024**4\n    elif 1024**3 <= num_bytes < 1024**4:\n        return f\"{num_bytes / 1024**3:.2f} GB\"\n\n    # If the number is between 1024**4 and 1024**5\n    elif 1024**4 <= num_bytes < 1024**5:\n        return f\"{num_bytes / 1024**4:.2f} TB\"\n\n    # If the number is between 1024**5 and 1024**6\n    elif 1024**5 <= num_bytes < 1024**6:\n        return f\"{num_bytes / 1024**5:.2f} PB\"\n\n    # If the number is greater than 1024**6\n    else:\n        return f\"{num_bytes / 1024**6:.2f} EB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO):\n        if abs(num_bytes) >= _FORMAT_TO_RATIO[suffix]:\n            value = num_bytes / _FORMAT_TO_RATIO[suffix]\n            return f\"{value:.2f}{suffix}\"\n\n    return f\"{num_bytes}b\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO.keys()):\n        if abs(num_bytes) >= 1024:\n            num_bytes /= 1024\n        if abs(num_bytes) >= 1000:\n            num_bytes /= 1000\n        if abs(num_bytes) < 1000:\n            break\n    if abs(num_bytes) < 1:\n        return \"0\"\n    if num_bytes >= 0:\n        return f\"{num_bytes:.2f} {suffix}\"\n    else:\n        return f\"{num_bytes:.2f} {suffix}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    # If the number is less than 1, don't use the suffix.\n    if num_bytes < 1:\n        return f\"{num_bytes}B\"\n    # If the number is more than 1000, use the next unit.\n    if num_bytes >= 1000:\n        for suffix, factor in _FORMAT_TO_RATIO.items():\n            if num_bytes < factor:\n                return f\"{num_bytes / factor:.3f}{suffix}\"\n\n    return f\"{num_bytes}B\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in _FORMAT_TO_RATIO.keys():\n        if num_bytes >= _FORMAT_TO_RATIO[suffix]:\n            value = num_bytes / _FORMAT_TO_RATIO[suffix]\n            return f\"{value:.2f}{suffix}\"\n    return f\"{num_bytes}b\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO):\n        size = num_bytes / _FORMAT_TO_RATIO[suffix]\n        if size < 1024:\n            return f\"{size:.2f} {suffix}\"\n\n    return f\"{num_bytes} B\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\n            \"The number of bytes must be a positive integer. \"\n            \"Please provide a positive integer.\"\n        )\n    if num_bytes == 0:\n        return \"0B\"\n    if num_bytes < 1024:\n        return f\"{num_bytes}B\"\n    for suffix in _FORMAT_TO_RATIO.keys():\n        if num_bytes < 1024 ** 2:\n            return f\"{num_bytes / 1024 :.2f}{suffix}\"\n        num_bytes /= 1024\n    return f\"{num_bytes :.2f}PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(list(_FORMAT_TO_RATIO)):\n        if num_bytes > _FORMAT_TO_RATIO[suffix]:\n            value = num_bytes / _FORMAT_TO_RATIO[suffix]\n            return f\"{value:.2f} {suffix}\"\n    return str(num_bytes)\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in reversed(_FORMAT_TO_RATIO.keys()):\n        if abs(num_bytes) >= 1024:\n            num_bytes /= 1024\n        else:\n            break\n    return f\"{num_bytes :.2f}{suffix}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        return f\"0 {unit_to_string(num_bytes, False)}\"\n\n    if num_bytes < 1024:\n        return f\"{num_bytes} B\"\n\n    for suffix, ratio in _FORMAT_TO_RATIO.items():\n        if num_bytes < ratio:\n            continue\n        value = num_bytes / ratio\n        return f\"{value:.2f} {unit_to_string(suffix, True)}\"\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def check_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return check_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\"\n            )\n\n        return v\n\n    return is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. \"\n                f\"Got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate(cls, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\"\n            )\n\n        return v\n\n    return validate"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.ndim}\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f'{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. '\n                f\"Received {v.ndim}\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.ndim}\"\n            )\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_n_dimensions(cls, v, field):\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f'{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.')\n        return v\n\n    return validate_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(\n        cls: type, v: np.ndarray, field: fields.ModelField\n    ) -> np.ndarray:\n        \"\"\"Check that the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a {nb_dimensions}-D array.\")\n\n        return v\n\n    return is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.shape}.\"\n            )\n\n        return v\n\n    return array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}\")\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}\"\n            )\n\n        return v\n\n    return is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has the specified number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls, v, field):\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\"\n            )\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a {nb_dimensions}-dimensional array.\")\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.shape}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x * x + y * y + z * z)\n  # Prevent division by zero.\n  theta = jnp.arccos(jnp.clip(z / r, -1.0 + eps, 1.0 - eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x ** 2 + y ** 2 + z ** 2)\n  theta = jnp.arctan2(jnp.sqrt(x ** 2 + y ** 2), z)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # pylint: disable=invalid-unary-operand\n  # pylint: disable=no-member-operand\n  # pylint: disable=no-member-operand\n  # pylint: disable=no-member-operand\n  # pylint: disable=no-member-operand\n  # pylint: disable=no-member-operand\n  # pylint: disable=no-member-operand\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / r, -1.0 + eps, 1.0))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(jnp.square(x) + jnp.square(y) + jnp.square(z))\n  theta = jnp.arccos(jnp.clip(z / r, -1.0 + eps, 1.0 - eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Get the norm of the vector.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  # Get the inclination angle (theta).\n  theta = jnp.arccos(jnp.clip(jnp.sum(cartesian_vector * jnp.array([1, 0, 1]), -1.0 + eps, 1.0))\n  # Get the azimuth angle (phi).\n  phi = jnp.arctan2(cartesian_vector[:, 1], cartesian_vector[:, 0])\n  # Return the spherical coordinates.\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Get the norm of the input vector.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  # Prevent division by zero.\n  r = jnp.where(r < eps, eps, r)\n  # Calculate the inclination angle theta.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / r, -1.0, 1.0))\n  # Calculate the azimuth angle phi.\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # radius = jnp.linalg.norm(cartesian_vector, ord=2, axis=-1, keepdims=True)\n  radius = jnp.sqrt(\n      cartesian_vector[:, 0] * cartesian_vector[:, 0] +\n      cartesian_vector[:, 1] * cartesian_vector[:, 1] +\n      cartesian_vector[:, 2] * cartesian_vector[:, 2]\n  )\n  theta = jnp.arccos(cartesian_vector[:, 2] / radius)\n  phi = jnp.arctan2(cartesian_vector[:, 1], cartesian_vector[:, 0])\n  return radius, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.maximum(cartesian_vector[..., 2], eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(jnp.square(x) + jnp.square(y) + jnp.square(z))\n  theta = jnp.arccos(z / jnp.maximum(jnp.abs(r), eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Compute the radius.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  # Compute the inclination.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2], -1 + eps, 1 - eps))\n  # Compute the azimuth.\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, ord=2)\n  # Prevent division by zero.\n  theta = jnp.arccos(jnp.maximum(jnp.finfo(jnp.float32).tiny, jnp.clip(z, -1, 1)))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / r)\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  cartesian_vector = jnp.asarray(cartesian_vector)\n  x, y, z = jnp.split(cartesian_vector, axis=-1, num_or_size_splits=3)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, ord=2)\n  theta = jnp.arctan2(jnp.sqrt(x**2 + y**2), z)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(jnp.sum(cartesian_vector * jnp.array([1., 0., 1.]), -1. + eps, 1. - eps))\n  phi = jnp.arctan2(cartesian_vector[1], cartesian_vector[0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, axis=-1)\n  r = jnp.sqrt(jnp.square(x) + jnp.square(y) + jnp.square(z))\n  # Compute inclination\n  theta = jnp.arccos(jnp.clip(z / r, -1 + eps, 1 - eps))\n  # Compute azimuth\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.sqrt(\n      jnp.sum(cartesian_vector ** 2, axis=-1))  # pylint: disable=unbalanced-tuple-unpacking\n  theta = jnp.arccos(jnp.maximum(jnp.clip(cartesian_vector[..., 2], -1 + eps, 1),\n                      eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1],\n                     cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # The radius is the norm of the input vector.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  # The azimuth is the arc tangent of the y/x coordinate.\n  # We need to use a small epsilon to prevent division by zero.\n  phi = jnp.arctan2(cartesian_vector[..., 1],\n                     cartesian_vector[..., 0])\n  # The inclination is the arc cosine of the z coordinate.\n  theta = jnp.arccos(cartesian_vector[..., 2])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # The radius of the sphere.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  # The inclination angle.\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2], -1.0, 1.0))\n\n  # The azimuth angle.\n  # This is not a great way to compute the azimuth.\n  # However, it is easy to implement and is good enough for our purposes.\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  # The azimuth is 0 at the positive x-axis and increases as you go clockwise.\n  # We want the azimuth to be 0 at the positive z-axis and increase as you go\n  # counter-clockwise.\n  phi = jnp.where(phi < 0, phi + 2 * jnp.pi, phi)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # pylint: disable=unnecessary-not\n  x, y, z = jnp.swapaxes(cartesian_vector, -2, -1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, ord=2)\n  theta = jnp.arccos(jnp.clip(z, eps, 1.0))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  if isinstance(cartesian_vector, (onp.ndarray, onp.generic.array_):\n    cartesian_vector = jnp.array(cartesian_vector)\n\n  r = jnp.sqrt(\n      jnp.sum(cartesian_vector * cartesian_vector, axis=-1))\n  theta = jnp.arccos(jnp.clip(jnp.sum(cartesian_vector *\n                                     jnp.array([1, 0, -1]), -1.0, 1.0))\n  phi = jnp.arctan2(cartesian_vector[1], cartesian_vector[0])\n  return r, theta, phi\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge_l = evaluate.load('uhgeval/.cache/huggingface/rouge-l')\n    results = rouge_l.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge_l']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge-l']\n    return score.mid\n\n"}
{"namespace": "common.rougeL_score", "completion": "    # tokenize the texts\n    f = lambda text: list(jieba.cut(text))\n    # compute ROUGE-L\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge-l')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge_l']['f']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    def tokenizer(text):\n        return list(jieba.cut(text))\n\n    rouge_l = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge_l.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)\n\n    return results['rouge_l']['r']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    # tokenize\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    # compute ROUGE-L score\n    results = rouge.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        tokenizer=f\n    )\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    # Tokenize the two texts\n    f = lambda text: list(jieba.cut(text))\n    # Compute the ROUGE-L score\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    # Return the ROUGE-L score\n    return results['rouge_l']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge_l']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge_l = evaluate.load('uhgeval/.cache/huggingface/rouge_l')\n    results = rouge_l.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rouge_l']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge_l']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    import jieba\n    from rouge.rouge import ROUGE_L\n\n    def f(text):\n        return list(jieba.cut(text))\n\n    rouge = ROUGE_L()\n    results = rouge.get_scores(\n        prediction=continuation,\n        references=[reference],\n        tokenizer=f\n    )\n    return results['ROUGE-L']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    from rouge.rouge_l import RougeL\n    import jieba\n    from rouge.rouge_l import ROUGE_L\n\n    def custom_tokenizer(text: str) -> list:\n        return list(jieba.cut(text))\n\n    r = RougeL(custom_tokenizer)\n    scores = r.get_scores(prediction=continuation, obserbvation=reference)\n    return scores[ROUGE_L]\n\n"}
{"namespace": "common.rougeL_score", "completion": "    from rouge_score import ROUGE_L, rouge_l\n    import jieba\n\n    # tokenize both texts\n    f = lambda text: list(jieba.cut(text))\n    text_a = f(reference)\n    text_b = f(continuation)\n\n    # compute ROUGE-L score\n    rouge = ROUGE_L(text_a, text_b)\n    score = rouge_l(rouge)\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    # tokenize both texts\n    f = lambda text: list(jieba.cut(text))\n    generated = f(continuation)\n    reference = f(reference)\n\n    # calculate ROUGE-L\n    score = evaluate.compute_rouge_l(\n        prediction=generated,\n        references=reference\n    )\n\n    # return ROUGE-L score\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    reference = reference.strip()\n    continuation = continuation.strip()\n    if reference == \"\" or continuation == \"\":\n        return 0.0\n    # reference = reference.lower()\n    # continuation = continuation.lower()\n    # tokenize the reference and the generated continuation\n    # reference_tokens = list(jieba.cut(reference))\n    # generated_tokens = list(jieba.cut(continuation))\n    reference_tokens = reference.split()\n    generated_tokens = continuation.split()\n\n    # compute the ROUGE-L score\n    # bleu = Bleu(n=4)\n    # bleu.add_with_count(reference_tokens)\n    # bleu.add_with_count(generated_tokens)\n    # bleu.compute_scores()\n    # return bleu.scores[3]\n    return Similarity(reference_tokens, generated_tokens, 1)"}
{"namespace": "common.rougeL_score", "completion": "    import evaluate\n    from loguru import logger\n\n    def tokenizer(text: str):\n        return list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(\n        predictions=[continuation], references=[[reference]], tokenizer=tokenizer\n    )\n    score = results['rougeL']\n    logger.debug(results)\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    # The ROUGE-L score is a function of the ROUGE-L score, the ROUGE-L-S score and the ROUGE-L-S-R score.\n    rougeL_score = rougeL_score_l(continuation, reference)\n    rougeL_score += rougeL_score_s(continuation, reference)\n    rougeL_score += rougeL_score_s_r(continuation, reference)\n    rougeL_score /= 3.0\n    return rougeL_score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    \n    # tokenize both texts\n    continuation = list(jieba.cut(continuation))\n    reference = list(jieba.cut(reference))\n\n    # calculate ROUGE-L score\n    rouge = Similarity(\n        a=continuation,\n        b=reference,\n        use_ssim=False,\n        use_lcs=True,\n        use_lcs_overlap=True,\n        use_lcs_shortest=True\n    )\n    score = rouge.get_score()\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    from rouge import ROUGE\n    from rouge.rouge_scorer import ROUGE_L\n\n    f = lambda text: list(jieba.cut(text))\n    rouge = ROUGE(use_tokenizer=f, use_bilingual_annotations=False)\n    rouge.load_data(predictions=[continuation], references=[[reference]])\n    scores = rouge.compute_scores()\n    return ROUGE_L.score(scores)\n\n"}
{"namespace": "common.rougeL_score", "completion": "    from rouge import ROUGE\n    f = lambda text: list(jieba.cut(text))\n    rouge = ROUGE(use_unigram=True, use_bigram=True, use_trigram=False, use_l_score=True)\n    score = rouge.get_score(prediction=continuation, reference=reference)\n    return score['rougeL']\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimis"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return __import__(name)\n    except ImportError:\n        # Try to pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if \".\" not in name:\n        # if no '.' in the name, we pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # This pessimistically tries to locate the object using the standard Python\n    # method first, and then pessimistically tries to locate the object using\n    # the fallback method.\n    try:\n        return pydoc.locate(name)\n    except (ImportError, AttributeError):\n        pass\n\n    # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimis"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if \".\" not in name:\n        return globals()[name]\n    else:\n        return pydoc.locate(name)\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if \".\" not in name:\n        return _locate_by_name(name)\n\n    # If the object is importable, try to locate it by its fully qualified name.\n    # Otherwise, we pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        return locate_from_registry(name)\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if \".\" not in name:\n        # this is a class name\n        try:\n            return pydoc.locate(name)\n        except ImportError:\n            pass\n    else:\n        # this is a fully qualified name\n        try:\n            return pydoc.locate(name)\n        except ImportError:\n            pass\n        try:\n            return locate(name.rsplit(\".\", 1)[-1])\n        except ImportError:\n            pass\n\n    raise ImportError(f\"Cannot locate '{name}'\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if \".\" in name:\n        # try to locate the object using the standard import method\n        try:\n            return __import__(name)\n        except ImportError:\n            pass\n\n    # try to locate the object using the fallback method\n    try:\n        module = __import__(name, fromlist=[\"*\"])\n    except (ImportError, AttributeError):\n        raise ImportError(f\"Cannot locate {name}\") from None\n\n    if \".\" in name:\n        # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.importFromDocstring(name)\n    except KeyError:\n        pass\n\n    try:\n        return __import__(name)\n    except ModuleNotFoundError:\n        pass\n\n    raise ImportError(f\"Not found: {name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return __import__(name, globals(), locals(), [], -1)\n    except (ImportError, AttributeError):\n        pass\n\n    # Locate the object using the fallback method.\n    # The fallback method is a function that heuristically attempts to\n    # locate the object in the current namespace.\n    try:\n        return getattr(globals(), name)\n    except (ImportError, AttributeError):\n        raise ImportError(f\" solidar-core: {name} not found\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.import_module(name)\n    except ImportError:\n        pass\n\n    # If the object is not importable as a module, try to locate it as a callable\n    # object.\n    try:\n        return pydoc.import_object(name)\n    except (ImportError, AttributeError):\n        raise ImportError(\n            f\"Unable to locate module or callable object with name {name}\"\n        )\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.importFromDocstring(name)\n    except ImportError:\n        pass\n\n    # Fall back to the built-in \"import\" method.\n    try:\n        return __import__(name)\n    except ImportError:\n        raise ImportError(\n            f\"Not found: {name}. \"\n            \"Please check that the name is correct and that the module is intelligibly named.\"\n        )\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # TODO: make this more general, support __getattr__, etc.\n    # TODO: suport unannotated, unannotated_with_fallback\n    # TODO: suport unannotated, unannotated_with_fallback\n    # TODO: suport unannotated, unannotated_with_fallback\n\n    # First, try locating the object using the standard method.\n    try:\n        return __import__(name, {}, {}, name)\n    except ImportError:\n        pass\n\n    # If the object is unannotated, unannotated_with_fallback, unannotated_with_fallback\n    if name.endswith(\"__annotated\"):\n        # unannotated_with_fallback\n        name = name[:-10]\n    elif name.endswith(\"__unnannotated\"):\n        # unannotated_with_fallback\n        name = name[:-12]\n    else:\n        # unannotated\n        name = name[:-8]\n\n    # If unannotated, unannotated_with_fallback, unannotated_with_fallback\n    try:\n        return __import__(name, {}, {}, name)\n    except ImportError:\n        pass\n\n    # unannotated_with_fallback\n    if name.endswith(\"__unnannotated\"):\n        name = name[:-12]\n\n    # unannotated\n    if name.endswith(\"__annotated\"):\n        name = name[:-10]\n\n    # unannotated_with_fallback\n    if name.endswith(\"__unnannotated\"):\n        name = name[:-12]\n\n    # unannotated\n    if name.endswith(\"__annotated\"):\n        name = name[:-10]\n\n    # unannotated_with_fallback\n    if name.endswith(\"__unnannotated\"):\n        name = name[:-12]\n\n    # unannotated\n    if name.endswith(\"__annotated\"):\n        name = name[:-10]\n\n    # unannotated_with_fallback\n    if name.endswith(\"__unnannotated\"):\n        name = name[:-12]\n\n    # unannotated\n    if name.endswith(\"__annotated\"):\n        name = name[:-10]\n\n    # unannotated_with_fallback\n    if name.endswith(\"__unnannotated\"):\n        name = name[:-12]\n\n    # unannotated\n    if name.endswith(\"__annotated\"):\n        name ="}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return __import__(name)\n    except ImportError:\n        # Fallback to pydoc's locate\n        return pydoc.locate(name)\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Attempt to find the object using the standard Python import mechanism\n    try:\n        return __import__(name)\n    except ImportError:\n        pass\n\n    # Attempt to find the object using detectron.core.config.Registry\n    try:\n        return detectron.core.config.Registry.get(name)\n    except KeyError:\n        pass\n\n    # Attempt to find the object pessimistically\n    raise ImportError(\n        f\"Unknown '{name}' detectron.core.config.Registry. \"\n        \"Please make sure the detectron.core.config.Registry is intitalised correctly.\"\n    )\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.importas(name)\n    except ImportError:\n        pass\n\n    # If the module does not exist, try to import it.\n    module_name, class_name = name.rsplit(\".\", 1)\n    module = __import__(module_name, globals(), locals(), [class_name])\n\n    # If the class does not exist in the imported module, raise an error.\n    try:\n        return getattr(module, class_name)\n    except AttributeError:\n        raise ImportError(f\"No object named {class_name} in {module_name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if \".\" in name:\n        module_name, klass_name = name.rsplit(\".\", 1)\n        try:\n            module = __import__(module_name)\n        except (ImportError, ModuleNotFoundError):\n            raise ModuleNotFoundError(f\"Not found: '{name}'\") from None\n    else:\n        module idem = None\n        klass_name = name\n    try:\n        klass = getattr(module idem, klass_name)\n    except (ImportError, AttributeError):\n        raise ModuleNotFoundError(f\"Not found: '{name}'\") from None\n\n    return klass\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except (ImportError, AttributeError):\n        pass\n\n    return locate_fallback(name)\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Attempt to find the object using the standard method.\n    try:\n        return __import__(name)\n    except:\n        pass\n\n    # Attempt to find the object using a fallback method.\n    try:\n        return __import__(name, fromlist=[\"__path__\"])[name.rsplit(\".\", 1)[-1]]\n    except:\n        raise ImportError(\n            f\"Unable to find the object named {name} using the standard or fallback method.\"\n        )\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    with io.BytesIO() as f:\n        torch.jit.save(module, f)\n        f.seek(0)\n        return torch.jit.load(f)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    with io.BytesIO() as f:\n        torch.jit.save(module, f)\n        f.seek(0)\n        return torch.jit.load(f)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buf = io.BytesIO()\n    torch.jit.save(module, buf)\n    buf.seek(0)\n    return torch.jit.load(buf)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # save the module to a buffer\n    f = io.BytesIO()\n    torch.jit.save(module, f)\n    # load the module from the buffer\n    return torch.jit.load(f)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to a buffer.\n    buf = io.BytesIO()\n    torch.jit.save(module, buf)\n    buf.seek(0)\n\n    # Load the module from the buffer.\n    return torch.jit.load(buf)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # save the module to an in-memory buffer\n    buf = io.BytesIO()\n    torch.jit.save(module, buf)\n    # load the module from the in-memory buffer\n    return torch.jit.load(buf)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    with io.BytesIO() as f:\n        torch.jit.save(module, f)\n\n        # Load the module from the in-memory buffer\n        module = torch.jit.load(f)\n    return module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer.\n    f = io.BytesIO()\n    torch.jit.save(module, f)\n\n    # Load the module back from the in-memory buffer.\n    return torch.jit.load(f)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to a buffer\n    buf = io.BytesIO()\n    torch.jit.save(module, buf)\n\n    # Load the module from the buffer\n    buf.seek(0)\n    module = torch.jit.load(buf)\n\n    return module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer.\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Load the module from the in-memory buffer.\n    module = torch.jit.load(buffer)\n    return module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buf = io.BytesIO()\n    module.save(buf)\n\n    # Load the module from the buffer\n    return module.__class__.from_bytes(buf.getvalue())"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the script module to a buffer.\n    with io.StringIO() as f:\n        torch.jit.save(module, f)\n    # Load the module from the buffer.\n    return torch.jit.load(f)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # save the module to a buffer\n    buffer = io.StringIO()\n    module.save_to_buffer(buffer)\n\n    # load the module back from the buffer\n    loaded_module = torch.jit.load(buffer)\n\n    # return the loaded module\n    return loaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged.\n    # TODO: remove this function after detectron2#1656 is merged."}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # We have to save the module to a buffer because saving to a file is not\n    # supported by the JIT.\n    with io.StringIO() as buffer:\n        module.save_to_buffer(buffer)\n        module = module.load_from_buffer(buffer.getvalue())\n    return module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # We use this to test that the model can be serialized and deserialized without loss of information or functionality.\n    # See detectron2.data.test_data_loading.test_serialize_model\n    buf = io.BytesIO()\n    torch.jit.save(module, buf)\n    buf.seek(0)\n    return torch.jit.load(buf)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # save to an in-memory buffer\n    scripted_module = torch.jit.script(module)\n    with io.BytesIO() as f:\n        torch.jit.save(scripted_module, f)\n\n        # load the saved model back\n        f.seek(0)\n        scripted_module = torch.jit.load(f)\n\n    return scripted_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    # This is necessary to ensure that the module can be serialized and deserialized without loss of information or functionality.\n    scripted_module = io.StringIO()\n    torch.jit.save(module, scripted_module, _use_new_zipfile=False)\n\n    # Load the module from the in-memory buffer\n    module = torch.jit.load(scripted_module, _use_new_zipfile=False)\n\n    return module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # TODO: this is a temporary workaround for #26611.\n    # This should be removed once the issue is fixed.\n    with io.StringIO() as buf:\n        module.save_to_buffer(buf)\n    return module.load_from_buffer(buf)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # https://github.com/pytorch/pytorch/issues/72548\n    # https://github.com/pytorch/pytorch/issues/73405\n    # https://github.com/pytorch/pytorch/issues/21637\n    # https://github.com/pytorch/pytorch/issues/5608\n\n    # https://github.com/facebookresearch/detectron2/issues/151\n\n    # This is a hack to get around the issue of the state_dict being\n    # a subclass of a TorchScriptModule, which is not supported by torch.jit.load().\n    #\n    # This is not necessary for detectron2, because detectron2 doesn't use\n    # torch.jit.load() to load a model.\n    #\n    # This is necessary for detectron2-demo, which does use torch.jit.load()\n    # to load a model.\n    #\n    # This is also necessary for detectron2-demo to work with detectron2-core\n    # in a single process.\n\n    # Save the model to a buffer\n    buf = io.BytesIO()\n    module.save_to_buffer(buf)\n\n    # Load the model from the buffer\n    buf.seek(0)\n    loaded_module = torch.jit.load(buf, map_location=lambda storage, loc: storage)\n\n    return loaded_module"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    scores = [(1 - w) * s + w for s, w in zip(scores, weights)]\n    return retrieval_node.top_k(ids, scores, top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores\n    # TODO: Normalize the scores\n    # TODO: Combine the scores using the provided weights\n    # TODO: Return the top_k results\n\n    return ids, scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores) == len(weights)\n\n    fused_scores = []\n    for i in range(len(ids)):\n        fused_scores.append(\n            weights[i] * scores[i] / sum(weights)\n        )\n    fused_scores = sum(fused_scores)\n\n    return ids[0][0:top_k], fused_scores[0:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores\n    norm_scores = [(scores[i] - scores[i].min()) / (scores[i].max() - scores[i].min()) for i in range(len(scores))]\n\n    # Calculate the fused scores\n    fused_scores = [(weights[i] * norm_scores[i]) for i in range(len(norm_scores))]\n    fused_scores = [sum(fused_scores) for i in range(len(fused_scores))]\n\n    # Select the top_k results\n    fused_ids = [ids[i][scores[i].argsort().values[-top_k:]] for i in range(len(ids))]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(weights) == len(ids) == len(scores)\n    assert sum(weights) == 1\n    fused_scores = []\n    fused_ids = []\n    for i in range(len(weights)):\n        fused_scores.append(\n            (weights[i] * scores[i] + (1 - weights[i]) * (1 - scores[i]))\n        fused_ids.append(ids[i])\n    return retrieval_node(fused_ids, fused_scores, top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_scores = []\n\n    for i in range(len(ids)):\n        fused_scores.append(\n            (\n                (1 - weights[i]) * scores[i]\n                + weights[i] * retrieval_node.normalize(scores[i])\n            )\n\n    fused_scores = retrieval_node.normalize(fused_scores)\n\n    fused_scores = sorted(fused_scores, reverse=True)\n\n    fused_ids = [fused_scores[i][0] for i in range(top_k)]\n    fused_scores = [fused_scores[i][1] for i in range(top_k)]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores for each retrieval result\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(score / sum(score))\n\n    # Fuse the scores\n    fused_scores = []\n    for i in range(len(weights)):\n        fused_scores.append(weights[i] * normalized_scores[i])\n\n    # Select the top_k results\n    return pd.DataFrame({'id': ids, 'score': fused_scores}).nlargest(top_k, 'score').index.tolist(), fused_scores[0][pd.DataFrame({'id': ids}).nlargest(top_k, 'score').index.tolist()]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores for each retrieval result\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(score / sum(score))\n\n    # Fuse the scores using the provided weights\n    fused_scores = []\n    for i in range(len(scores[0])):\n        fused_score = 0\n        for j in range(len(scores)):\n            fused_score = fused_score + normalized_scores[j][i] * weights[j]\n        fused_scores.append(fused_score)\n\n    # Select the top k results\n    fused_ids = []\n    for i in range(len(scores[0])):\n        fused_ids.append(ids[0][i])\n    fused_ids.sort(key=lambda x: fused_scores[i], reverse=True)\n    fused_ids = fused_ids[0:top_k]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores)\n    assert len(weights) == len(ids)\n    assert sum(weights) == 1.0\n\n    fused_scores = []\n    fused_ids = []\n\n    for i in range(len(ids)):\n        fused_scores.append(\n            list(map(lambda x: x[0] * weights[i], zip(scores[i], ids[i]))\n        )\n        fused_ids.append(ids[i])\n\n    fused_scores = [\n        sorted(x, key=lambda x: x[0], reverse=True)[0:top_k] for x in fused_scores\n    ]\n    fused_ids = [x[1] for x in fused_scores]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\"Weights must have the same length as the ids and scores tuples\")\n\n    scores_fused = []\n\n    for i in range(len(weights)):\n        scores_fused.append(\n            pd.Series(scores[i]) * weights[i]\n        )\n\n    scores_fused = pd. palettable.weighted_mean(scores_fused)\n\n    return retrieval_node(\n        ids=ids,\n        scores=scores_fused,\n        top_k=top_k)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(weights) == len(ids)\n    assert len(weights) == len(scores)\n    assert sum(weights) == 1\n    assert len(ids[0]) == len(scores[0])\n\n    # Normalize the scores\n    norm_scores = []\n    for i in range(len(scores)):\n        norm_scores.append([s / sum(scores[i]) for s in scores[i]])\n\n    # Fuse the normalized scores\n    fused_scores = []\n    for i in range(len(norm_scores[0])):\n        fused_score = 0\n        for j in range(len(norm_scores)):\n            fused_score += norm_scores[j][i] * weights[j]\n\n        fused_scores.append(fused_score)\n\n    # Retrieve the top k results\n    fused_ids = []\n    for i in range(len(fused_scores)):\n        fused_ids.append(ids[0][i])\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores)\n    assert len(ids) == len(weights)\n\n    scores = [(1.0 - w) * s for s, w in zip(scores, weights)]\n    scores = [s.tolist() for s in scores]\n    scores = [s / sum(s) for s in scores]\n\n    scores = [(s1 + s2) for s1, s2 in zip(scores[0], scores[1])]\n    scores = [(1.0 - w) * s for s, w in zip(scores, weights)]\n\n    return ids[0][scores.index(max(scores))], [max(scores)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    fused_scores = []\n    fused_ids = []\n    for i in range(len(scores)):\n        fused_scores.append(\n            (1 - weights[i]) * scores[i] + weights[i] * retrieval_node(ids[i], top_k)\n        )\n    fused_ids = [i for i, s in zip(ids, fused_scores) if any(s > 0)]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores)\n\n    fused_ids = [[] for _ in ids]\n    fused_scores = [[] for _ in scores]\n\n    for i, (id_list, score_list, weight) in enumerate(zip(ids, scores, weights)):\n        score_list = [score * weight for score in score_list]\n        fused_scores[i].extend(score_list)\n        fused_ids[i].extend(id_list)\n\n    fused_scores = pd.Series(fused_scores)\n    fused_scores = fused_scores.apply(\n        lambda x: [x] if isinstance(x, float) else x)\n\n    fused_scores = fused_scores.apply(\n        lambda x: sorted(x, reverse=True))\n\n    fused_scores = fused_scores.head(top_k)\n\n    return fused_scores.index, fused_scores.values"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores for each retrieval result\n    normalized_scores = [(scores[i] - scores[i].min()) / (scores[i].max() - scores[i].min()) for i in range(len(scores))]\n    # Calculate the fused scores\n    fused_scores = [\n        sum([w * s for w, s in zip(weights, scores_norm)]) for scores_norm in zip(*normalized_scores)]\n    # Return the top_k fused results\n    return [(ids[i][fused_scores.index(x)] for x in pd.Series(fused_scores).nlargest(top_k)], fused_scores[fused_scores.nlargest(top_k).index]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores) or len(weights) != len(ids):\n        raise ValueError(\n            \"The lengths of the ids and scores tuples must match the length of the weights tuple.\")\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    fused_scores = []\n\n    for i in range(len(ids)):\n        fused_scores.append(weights[i] * scores[i])\n\n    fused_scores = [sum(fused_scores[i]) for i in range(len(fused_scores))]\n    fused_scores = pd.Series(fused_scores)\n\n    fused_ids = [list(i) for i in ids]\n    fused_ids = [fused_ids[i] for i in fused_scores.nsmallest(top_k).index]\n\n    return fused_ids, fused_scores.values[fused_scores.nsmallest(top_k).index].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Get the number of retrieval results\n    num_results = len(ids)\n    assert num_results == len(scores), \"The number of retrieval results must match the number of scores provided.\"\n    assert num_results == len(weights), \"The number of retrieval results must match the number of weights provided.\"\n\n    # Normalize the scores\n    scores = [pd.Series(s). intit(1.0) for s in scores]\n\n    # Perform the convex combination\n    fused_scores = []\n    for i in range(num_results):\n        fused_scores.append(weights[i] * scores[i])\n\n    # Add the fused scores together\n    fused_scores = [sum(fused_scores) for _ in range(num_results)]\n\n    # Select the top_k results\n    fused_ids = []\n    fused_scores = []\n\n    for i in range(num_results):\n        fused_ids.append(ids[i][0:top_k])\n        fused_scores.append(scores[i][0:top_k])\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores):\n        raise ValueError('The length of the ids and scores tuples must match.')\n\n    if sum(weights) != 1:\n        raise ValueError('The sum of the weights must equal 1.')\n\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(score / sum(score))\n\n    normalized_scores = pd.DataFrame(normalized_scores).T.dot(weights).to_list()\n\n    return ids[normalized_scores. jaun_topk(top_k)], normalized_scores[normalized_scores.jaun_topk(top_k)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores for each retrieval result.\n    normalized_scores = []\n    for i in range(len(scores)):\n        normalized_scores.append(\n            [s / sum(scores[i]) for s in scores[i]])\n\n    # Combine the normalized scores using the provided weights.\n    fused_scores = []\n    for i in range(len(scores)):\n        fused_scores.append(\n            [s * w for s, w in zip(normalized_scores[i], weights[i])])\n\n    # Normalize the fused scores.\n    fused_scores = [s / sum(s) for s in fused_scores]\n\n    # Combine the scores.\n    fused_scores = [\n        [s1 + s2 for s1, s2 in zip(s1, s2)] for s1, s2 in zip(fused_scores, scores)]\n    fused_scores = [s / sum(s) for s in fused_scores]\n\n    # Retrieve the top-k results.\n    return (\n        [ids[i].tolist() for i in pd. intit_frame(fused_scores).sort_values(by=0, ascending=False).index[:top_k].tolist()],\n        fused_scores[:top_k].tolist())"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    from palet.core import palet_utils\n    import palet_utils.utils.metrics as palet_utils_metrics\n\n    # Check if the input parameters are valid\n    palet_utils.check_tuple_lengths(ids, scores, weights)\n    palet_utils.check_tuple_sum(weights, 1.0, \"weights\")\n\n    # Initialize the intitals\n    fused_ids, fused_scores = palet_utils.init_lists(len(ids))\n\n    # Normalize the scores\n    norm_scores = palet_utils.normalize_list(scores)\n\n    # Fuse the normalized scores\n    for i in range(len(ids)):\n        fused_scores[i] = palet_utils_metrics.weighted_sum(norm_scores[i], weights[i])\n\n    # Select the top_k results\n    fused_scores, fused_ids = palet_utils.topk(fused_scores, fused_ids, top_k)\n\n    # Return the fused results\n    return palet_utils.init_tuple(fused_ids, fused_scores)"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if pd.isna(x):\n        return \"nan\"\n    if percent:\n        x = x * 100\n        return \"{:.2f}%\".format(x)\n    # If the number is between 0 and 1, it is formatted with two decimal places.\n    if x >= 0 and x <= 1:\n        return \"{:.2f}\".format(x)\n    # If the number is between 10 and 1000, it is formatted with one decimal place.\n    if x >= 10 and x <= 1000:\n        return \"{:.1f}\".format(x)\n    # If the number is between 1000 and 1000000, it is formatted with no decimal places.\n    if x >= 1000 and x < 1000000:\n        return \"{:,}\".format(int(x))\n    # If the number is between 1000000 and 1000000000, it is formatted with one decimal place.\n    if x >= 1000000 and x < 1000000000:\n        return \"{:.1f}M\".format(x / 1000000)\n    # If the number is between 1000000000 and 1000000000000, it is formatted with two decimal places.\n    if x >= 1000000000 and x < 1000000000000:\n        return \"{:.2f}B\".format(x / 1000000000)\n    # If the number is between 1000000000000 and 1000000000000000, it is formatted with no decimal places.\n    if x >= 1000000000000 and x < 1000000000000000:\n        return \"{:,}\".format(int"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if pd.isna(x):\n        return str(x)\n    if percent:\n        return f\"{x * 100:.2f}%\"\n    return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if pd.isna(x):\n        return \"NaN\"\n\n    if percent:\n        x = x * 100\n\n    # Determine the number of decimal places to use based on the value of the number.\n    if x.is_integer():\n        num_decimal_places = 0\n    elif x >= 100:\n        num_decimal_places = 0\n    elif x >= 10:\n        num_decimal_places = 1\n    elif x >= 1:\n        num_decimal_places = 2\n    elif x >= 0.1:\n        num_decimal_places = 3\n    elif x >= 0.01:\n        num_decimal_places = 4\n    elif x >= 0.001:\n        num_decimal_places = 5\n    elif x >= 0.0001:\n        num_decimal_places = 6\n    elif x >= 0.00001:\n        num_decimal_places = 7\n    elif x >= 0.000001:\n        num_decimal_places = 8\n    elif x >= 0.0000001:\n        num_decimal_places = 9\n    else:\n        num_decimal_places = 10\n\n    # Format the number with the determined number of decimal places.\n    return \"{:.{}f}\".format(x, num_decimal_places)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"nan\"\n    if percent:\n        x *= 100\n    return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"nan\"\n\n    if percent:\n        x *= 100\n        suffix = \"%\"\n    else:\n        suffix = \"\"\n\n    if x >= 10000:\n        return f\"{x:,.1f}{suffix}\"\n    elif x >= 1000:\n        return f\"{x:,.2f}{suffix}\"\n    elif x >= 100:\n        return f\"{x:.3f}{suffix}\"\n    elif x >= 10:\n        return f\"{x:.4f}{suffix}\"\n    else:\n        return f\"{x:.5f}{suffix}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x = x * 100\n    return \"{:g}\".format(x)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n\n    if percent:\n        x *= 100\n        return f\"{x:.2f} %\"\n    else:\n        if x >= 1:\n            return f\"{x:.1f}\"\n        else:\n            return f\"{x:.4f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if pd.isna(x):\n        return \"NaN\"\n\n    if percent:\n        x = x * 100\n\n    if x == 0:\n        return \"0\"\n\n    return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    elif percent:\n        return f\"{x * 100:.2f}%\"\n    else:\n        return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        return f\"{x * 100:.2f}%\"\n    else:\n        return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    return \"{:0.1f}\".format(x)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n\n    if percent:\n        x *= 100.0\n        return f\"{x:.2f}%\"\n    else:\n        return f\"{x:.3f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100.0\n    return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n\n    if percent:\n        return f\"{x * 100:.2f}%\"\n    else:\n        return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n\n    if percent:\n        x = x * 100\n        return f\"{x:.2f}%\"\n    else:\n        return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if pd.isna(x):\n        return \"NaN\"\n\n    if percent:\n        x = x * 100\n\n    # number of decimals is determined by the number of digits after the decimal point\n    decimals = len(str(x).split(\".\")[1])\n\n    # format the number\n    return f\"{x:.{decimals}f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    else:\n        if percent:\n            x *= 100\n        if x < 10:\n            return f\"{x:.2f}\"\n        elif x < 100:\n            return f\"{x:.1f}\"\n        else:\n            return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        return f\"{x * 100:.2f} %\"\n    return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if pd.isna(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    # The number of decimal places is determined by the number of digits in the\n    # exponent, with a minimum of 2.\n    x = round(x, 2 - int(np.log10(abs(x)))\n\n    # Add a trailing decimal point if the number is negative and has no decimal places.\n    if x < 0 and x % 1 != 0:\n        x = str(x)\n        if \".\" not in x:\n            x += \".\"\n        return x\n\n    return str(x)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    # Get the current disk usage\n    current_disk_usage_in_gb = _get_disk_usage(input_dir) / 1024 ** 3\n\n    # Check if the disk usage is lower than the threshold\n    if current_disk_usage_in_gb > threshold_in_gb:\n        return\n\n    # Wait until the disk usage is lower than the threshold\n    while current_disk_usage_in_gb > threshold_in_gb:\n        sleep(sleep_time)\n        current_disk_usage_in_gb = _get_disk_usage(input_dir) / 1024 ** 3\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    disk_usage_in_gb = 0\n\n    while disk_usage_in_gb > threshold_in_gb:\n        disk_usage_in_bytes = shutil.disk_usage(input_dir)[2]\n        disk_usage_in_gb = round(disk_usage_in_bytes / 1024 / 1024 / 1024, 1)\n        sleep(sleep_time)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = os.path.getsize(input_dir) / (1024 * 1024 * 1024)\n        if disk_usage > threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            # get the current disk usage\n            disk_usage = os.statvfs(input_dir)\n            disk_usage = disk_usage.f_bavail * 8\n            if disk_usage < threshold_in_gb:\n                break\n        except FileNotFoundError:\n            pass\n\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    used_disk_space = shutil.disk_usage(input_dir)[0] / 1_000_000_000\n    while used_disk_space > threshold_in_gb:\n        sleep(sleep_time)\n        used_disk_space = shutil.disk_usage(input_dir)[0] / 1_000_000_000\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage = shutil.disk_usage(input_dir)\n        except FileNotFoundError:\n            logger.warning(f\"Directory {input_dir} does not exist, aborting.\")\n            return\n        except IsADirectoryError:\n            logger.warning(f\"Directory {input_dir} is a directory, aborting.\")\n            return\n        if disk_usage.free < threshold_in_gb * 10 ** 9:\n            return\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage = shutil.disk_usage(input_dir)\n            if disk_usage.free < threshold_in_gb * 10**9:\n                return\n        except Exception as e:\n            logger.error(e)\n            logger.error(traceback.format_exc())\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    total_space, used_space, free_space = shutil.disk_usage(input_dir)\n    while free_space > threshold_in_gb * 1024 ** 3:\n        sleep(sleep_time)\n        total_space, used_space, free_space = shutil.disk_usage(input_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    threshold_in_bytes = threshold_in_gb * 1024 ** 3\n\n    while True:\n        # get the disk usage of the input directory\n        disk_usage_in_bytes = os.statvfs(input_dir)[5]\n        logger.info(\n            f\"Disk usage of {input_dir} is {disk_usage_in_bytes / 1024 ** 3} GB. Waiting for disk usage to be lower than {threshold_in_bytes / 1024 ** 3} GB\"\n        )\n\n        if disk_usage_in_bytes < threshold_in_bytes:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    free_space_in_gb = 0\n    while True:\n        free_space_in_gb = shutil.disk_usage(input_dir)[1] / 10 ** 9\n        if free_space_in_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = os.path.getsize(input_dir)\n        if disk_usage > 1024 ** 3 * threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    free_space_in_gb = 0\n    while free_space_in_gb > threshold_in_gb:\n        free_space_in_gb = os.fs_free_space_gb(input_dir)\n        sleep(sleep_time)\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    import psutil\n\n    # Get the current disk usage\n    current_disk_usage = psutil.disk_usage(input_dir)\n\n    # Check if the disk usage is higher than the threshold\n    if current_disk_usage.free > threshold_in_gb * 10 ** 9:\n        # If the disk usage is higher than the threshold, sleep for the given time and check again\n        sleep(sleep_time)\n\n    # Check if the disk usage is higher than the threshold\n    if current_disk_usage.free > threshold_in_gb * 10 ** 9:\n        # If the disk usage is higher than the threshold, sleep for the given time and check again\n        sleep(sleep_time)\n\n    # If the disk usage is higher than the threshold, return\n    if current_disk_usage.free > threshold_in_gb * 10 ** 9:\n        return\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    free_space_in_gb = 0\n    while free_space_in_gb > threshold_in_gb:\n        free_space_in_gb = shutil.disk_usage(input_dir)\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage_in_gb = _get_disk_usage_in_gb(input_dir)\n            if disk_usage_in_gb > threshold_in_gb:\n                break\n            else:\n                logger.info(f\"Waiting for disk usage to be lower than {threshold_in_gb} GB\")\n                sleep(sleep_time)\n        except:\n            logger.warning(f\"Failed to check disk usage of {input_dir}\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage_in_gb = shutil.disk_usage(input_dir)[0] / 1024 / 1024\n        except FileNotFoundError:\n            raise ValueError(f\"Directory {input_dir} does not exist\")\n\n        if disk_usage_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    from stat import st_blocks, st_size\n\n    while True:\n        try:\n            if st_blocks(input_dir) * 512 / 10 ** 9 > threshold_in_gb:\n                return\n        except OSError:\n            pass\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            free_disk_space_in_gb = os.fs.get_free_disk_space_in_gb(input_dir)\n        except FileNotFoundError:\n            continue\n        if free_disk_space_in_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total_gb = 0\n        for path in os.listdir(input_dir):\n            if os.path.isfile(os.path.join(input_dir, path)):\n                total_gb = total_gb + os.path.getsize(os.path.join(input_dir, path)) / 1024 / 1024 / 1024\n        if total_gb > threshold_in_gb:\n            return\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        # Check if the disk usage is higher than the threshold\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage[0] < threshold_in_gb * 1024 * 1024 * 1024:\n            logger.info(\n                f\"Waiting for disk usage to be lower than {threshold_in_gb} GB. Current disk usage: {disk_usage[0] / 1024 / 1024 / 1024:.2f} GB.\"\n            )\n            sleep(sleep_time)\n        else:\n            logger.info(f\"Disk usage is higher than {threshold_in_gb} GB. Starting to process data.\")\n            break\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return jnp.where(jnp.diff(t) < np.finfo(np.float32).tiny, 0,\n                   jnp.multiply(p, jnp.diff(t)))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_mul(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_mul(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_mul(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return p * jnp.diff(t)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_mul(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return jnp.where(jnp.diff(t) < np.finfo(np.float32).tiny, 0, p * jnp.diff(t))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_mul(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p * td, td.sum(axis=-1))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(td, td + np.finfo(np.float32).tiny) * p\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(td, jnp.where(td < np.finfo(np.float32).tiny, 1, td)) * p\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  t = jax.ops.index_add(t, 0, 1, t[1:, :])\n  return jnp.where(t < np.finfo(np.float32).tiny, 0, p * (t[1:] - t[:-1]))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n\n    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"  \", \" \")\n    line_"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \", line_text)\n    line_text = re.sub(r\"\\s{2,}\", \" \","}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove spaces and tabs\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n\n    # split into tokens\n    return line_text.split()\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \" \", line_text)\n    line_text = line_text.strip()\n    line_text = line_text.replace(\"-\", \" \")\n    line_text = line_text.replace(\".\", \" \")\n    line_text = line_text.replace(\",\", \" \")\n    line_text = line_text.replace(\":\", \" \")\n    line_text = line_text.replace(\";\", \" \")\n    line_text = line_text.replace(\"(\", \" \")\n    line_text = line_text.replace(\")\", \" \")\n    line_text = line_text.replace(\")\", \" \")\n    line_text = line_text.replace(\"]\", \" \")\n    line_text = line_text.replace(\"[\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\"=\", \" \")\n    line_text = line_text.replace(\"=\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\" \", \" \")\n    line_text = line_text.replace(\"-\", \" \")\n    line_text = line_text.replace(\",\", \" \")\n    line_text = line_text.replace(\";\", \" \")\n    line_text = line_text.replace(\":\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\"=\", \" \")\n    line_text = line_text.replace(\"=\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"?\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_text.replace(\"!\", \" \")\n    line_text = line_"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"  \", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.strip()\n\n    return line_text.split(\" \")\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n\n    # Segment the modified text into smaller parts.\n    return tokenize(line_text)\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"[\\s]+\", \" \", line_text)\n    line_text = line_text.strip()\n    return line_text.split()\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n\n    # Segment the text into tokens\n    return line_text.split(\" \")\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove spaces\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n    # segment the text\n    line_text = line_text.split(\" \")\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n\n    # Segment the modified text into smaller parts or tokens.\n    tokens = line_text.split()\n\n    # Return the segmented parts of the modified input text.\n    return tokens\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n    return line_text.split(\" \")\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n\n    # Remove all spaces\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the text\n    line_text_list = line_text.split()\n\n    return line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = clean_line(line_text)\n    # line_text = line_text.replace(\"\\n\", \" \")\n    # line_text = line_text.replace(\"\\t\", \" \")\n    # line_text = line_text.strip()\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n\n    # Segment the text\n    line_text = line_text.split()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = clean_line(line_text)\n\n    # Split the line into tokens.\n    tokens = line_text.split(\" \")\n    # Remove all empty tokens.\n    tokens = [token for token in tokens if token]\n\n    # Join the tokens with a space.\n    line = \" \".join(tokens)\n\n    return line\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces\n    line_text = line_text.replace(\" \", \"\")\n    # Split the text into tokens\n    line_tokens = line_text.split()\n\n    return line_tokens\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove spaces\n    line_text = line_text.replace(\" \", \"\")\n\n    # split the text into tokens\n    line_tokens = line_text.split()\n\n    return line_tokens\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    # The text is modified in-place.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens.\n    # The text is modified in-place.\n    line_text = line_text.split()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.strip()\n    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.strip()\n    line_text = line_text.split()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Replace all whitespace characters with a single space.\n    # This is done to remove all spaces and then segment the text.\n    line_text = re.sub(r\"\\s+\", \" \", line_text)\n\n    # Segment the text into smaller parts or tokens.\n    # This is done to separate the words and punctuations.\n    return line_text.split()\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    zeros = min(n, zeros)\n    if zeros > 0:\n        idx = np.random.choice(n, zeros, replace=False)\n        weights[idx] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros:\n        weights[np.random.choice(n, zeros)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\n            \"The number of zero weights must not be larger than the total number of weights.\"\n        )\n    if zeros == 0:\n        return np.random.uniform(0, 1, n)\n    else:\n        weights = np.random.uniform(0, 1, n - zeros)\n        weights[np.random.choice(len(weights), zeros)] = 0\n        weights /= np.sum(weights)\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros:\n        for _ in range(zeros):\n            weights[np.random.randint(n)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Generate random weights that sum to one\n    weights = np.random.dirichlet(n)\n    # Set some weights to zero\n    if zeros > 0:\n        # Generate random indices to set to zero\n        zero_indices = np.random.choice(np.arange(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros:\n        # Randomly set some weights to zero\n        for i in range(zeros):\n            idx = np.random.choice(np.arange(n))\n            weights[idx] = 0.0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n <= zeros:\n        raise ValueError(\"n must be greater than zeros\")\n    if zeros < 0:\n        raise ValueError(\"zeros must be greater than 0\")\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n    else:\n        weights = np.random.dirichlet(np.ones(n - zeros))\n        zeros_idx = np.random.choice(range(n), size=zeros)\n        weights[zeros_idx] = 0\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Make sure the number of weights to be set to zero does not exceed the total number of weights\n    if zeros > n:\n        raise ValueError(\"Number of zeros must not exceed the number of weights\")\n    # Generate a random array of weights\n    weights = np.random.dirichlet(np.ones(n))\n    # Set the specified number of weights to zero\n    indices = np.random.choice(n, zeros, replace=False)\n    weights[indices] = 0\n    # Normalize the weights\n    weights = weights / weights.sum()\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n + zeros)\n    weights = weights[: zeros]\n    weights = np.append(weights, 0)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Initialize the array\n    weights = np.zeros(n)\n    weights[0] = 1\n\n    # Generate the weights\n    if zeros > 0:\n        for i in range(1, zeros + 1):\n            j = np.random.randint(0, n - i)\n            weights[j] = 0\n            weights[j + 1] = 1\n\n    # Normalize the weights\n    weights = weights / np.sum(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zeros_idx = np.random.choice(np.arange(n), zeros, replace=False)\n        weights[zeros_idx] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the number of weights.\")\n\n    # Generate a random array of weights that sum to 1\n    weights = np.random.dirichlet(np.ones(n))\n    # Set some weights to zero\n    if zeros > 0:\n        # Get the indices of the non-zero weights\n        non_zeros = np.where(weights > 0)[0]\n        # Get the number of non-zero weights\n        n_non_zeros = len(non_zeros)\n        # Generate a random number between 0 and n_non_zeros\n        n_zeros = np.random.randint(low=0, high=n_non_zeros, size=zeros)\n        # Set the weights at the indices to zero\n        weights[non_zeros[n_zeros]] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n < zeros:\n        raise ValueError(\n            \"Number of zeros must not exceed the number of weights.\"\n        )\n    weights = np.random.dirichlet(np.ones(n))\n    weights = np.array(weights)\n    if zeros > 0:\n        zeros_indices = np.random.choice(np.arange(n), zeros, replace=False)\n        weights[zeros_indices] = 0.0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if n < zeros:\n        raise ValueError(\n            \"The number of zero-valued weights must be less than or equal to the total number of weights.\"\n        )\n\n    if zeros > 0:\n        # Generate weights that sum to one\n        w = np.random.dirichlet(np.ones(n))\n\n        # Set a specified number of weights to zero\n        for _ in range(zeros):\n            idx = np.random.randint(0, n)\n            w[idx] = 0\n\n    else:\n        w = np.random.dirichlet(np.ones(n))\n\n    return w\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Check that n is an int\n    if not isinstance(n, int):\n        raise ValueError(f\"n must be an int, got {type(n)}\")\n\n    # Check that zeros is an int\n    if not isinstance(zeros, int):\n        raise ValueError(f\"zeros must be an int, got {type(zeros)}\")\n\n    # Check that zeros is not greater than n\n    if zeros > n:\n        raise ValueError(f\"zeros must not be greater than n, got zeros={zeros}, n={n}\")\n\n    # Check that zeros is not negative\n    if zeros < 0:\n        raise ValueError(f\"zeros must be non-negative, got zeros={zeros}\")\n\n    # Generate the weights\n    weights = np.random.dirichlet(np.ones(n))\n\n    # Set a specified number of weights to zero\n    if zeros > 0:\n        # Generate a list of indices of the weights to set to zero\n        zero_indices = np.random.choice(a=np.arange(n), size=zeros, replace=False)\n\n        # Set the weights at the specified indices to zero\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Create a random array of n weights with values between 0 and 1\n    w = np.random.rand(n)\n    # Set the first zero weights\n    w[:zeros] = 0\n    # Ensure that the weights sum to one\n    w /= w.sum()\n\n    return w\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"Cannot have more weights set to zero than there are weights in the distribution.\")\n    n_weights = n - zeros\n    if n_weights <= 0:\n        return np.zeros((n,))\n    weights = rand_weights_dirichlet(n_weights)\n    if zeros > 0:\n        weights[np.random.choice(n_weights, zeros, replace=False)] = 0.0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # If no zero-weight elements are specified, generate a normalized random vector\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n    # Generate a random vector of weights that sum to one\n    v = rand_weights_dirichlet(n - zeros)\n    # Set some of the weights to zero\n    for _ in range(zeros):\n        v[np.random.choice(np.arange(n), 1, replace=False)] = 0\n    return v\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # This is a workaround for the fact that numpy.random.dirichlet(n) does not\n    # return a vector of weights that sum up to one.\n    # It is taken from:\n    # https://github.com/scikit-learn/scikit-learn/blob/48462191/sklearn/utils/random_state.py#L165\n\n    # generate a random vector of weights from the dirichlet distribution\n    # with parameter 1.\n    weights = np.random.dirichlet(n * [1.0])\n\n    # if zeros > 0, randomly set some weights to 0\n    if zeros > 0:\n        # generate a random permutation of the indices\n        permutation = np.random.permutation(n)\n\n        # randomly set zeros to 0\n        weights[permutation[0 : zeros]] = 0\n\n    # normalize the weights\n    weights /= weights.sum()\n\n    return weights\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type=module_type, module_param=deepcopy(module_dict))"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type=module_type, module_param=deepcopy(module_dict))"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict[\"module_type\"]\n        module_params = deepcopy(module_dict)\n        del module_params[\"module_type\"]\n        return cls(module_type=module_type, module_param=module_params)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(\n            module_type=module_dict.pop('module_type'),\n            module_param=module_dict,\n        )\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(\n            module_type=module_dict[\"module_type\"],\n            module_param=module_dict[\"module_param\"],\n        )\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_type=module_dict['module_type'], module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_dict = deepcopy(module_dict)\n        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type=module_type, module_param=module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_type=module_dict.pop('module_type'), module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_type=module_dict['module_type'], module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(\n            module_type=module_dict[\"module_type\"],\n            module_param=module_dict\n        )\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(\n            module_type=module_dict[\"module_type\"],\n            module_param=module_dict[\"module_param\"],\n        )\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(\n            module_type=module_dict['module_type'],\n            module_param=module_dict\n        )\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get bounding box\n    bbox = instance[\"bbox\"]\n    bbox_mode = instance.get(\"bbox_mode\", BoxMode.XYXY_ABS)\n\n    # Convert to XYXY_ABS\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    # Get center of bounding box\n    bbox_center_x = bbox[0] + (bbox[2] - bbox[0]) / 2\n    bbox_center_y = bbox[1] + (bbox[3] - bbox[1]) / 2\n\n    # Get the top-left corner of the crop\n    crop_x_top_left = bbox_center_x - crop_size[1] / 2\n    crop_y_top_left = bbox_center_y - crop_size[0] / 2\n\n    # Ensure that the crop is within the image boundaries\n    crop_x_top_left = max(0, crop_x_top_left)\n    crop_y_top_left = max(0, crop_y_top_left)\n    crop_x_bottom_right = crop_x_top_left + crop_size[1]\n    crop_y_bottom_right = crop_y_top_left + crop_size[0]\n\n    # Get the dimensions of the crop\n    crop_width = crop_x_bottom_right - crop_x_top_left\n    crop_height = crop_y_bottom_right - crop_y_top_left\n\n    # Create the CropTransform object\n    crop_transform = T.CropTransform(\n        image_size=image_size,\n        crop_size=crop_size,\n        crop_x_top_left=crop_x_top_left,\n        crop_y_top_left=crop_y_top_left,\n    )\n\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # TODO: support other bbox modes\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # compute the center of the instance\n    center_x = 0.5 * (bbox[0] + bbox[2])\n    center_y = 0.5 * (bbox[1] + bbox[3])\n\n    # compute the center of the crop\n    crop_center_x = 0.5 * (crop_size[0] + image_size[0])\n    crop_center_y = 0.5 * (crop_size[1] + image_size[1])\n\n    # compute the translation\n    translation_x = crop_center_x - center_x\n    translation_y = crop_center_y - center_y\n\n    # compute the scale\n    scale_x = crop_size[0] / image_size[0]\n    scale_y = crop_size[1] / image_size[1]\n\n    # compute the rotation\n    rotation = 0\n\n    # compute the offset\n    offset = [0, 0]\n\n    # create the transformation\n    return T.Compose(\n        [\n            T.Translate(translation_x, translation_y),\n            T.Scale(scale_x, scale_y),\n            T.Rotate(rotation),\n            T.Translate(offset[0], offset[1]),\n        ]\n    )\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Crop the image so that the center of the instance is in the center of the cropped image.\n    center_x = instance.center_x\n    center_y = instance.center_y\n    image_width, image_height = image_size\n    crop_width, crop_height = crop_size\n\n    # Ensure that the center of the instance is within the image boundaries\n    if center_x < crop_width / 2:\n        center_x = crop_width / 2\n    if center_y < crop_height / 2:\n        center_y = crop_height / 2\n    if center_x > image_width - crop_width / 2:\n        center_x = image_width - crop_width / 2\n    if center_y > image_height - crop_height / 2:\n        center_y = image_height - crop_height / 2\n\n    # Crop the image so that the center of the instance is in the center of the cropped image.\n    # Crop the image so that the center of the instance is in the center of the cropped image.\n    # TODO: This is a hacky way to get the center of a rotated bbox\n    # TODO: The center_x, center_y is not the center of the bbox, it is the center of the rotated bbox.\n    center_x = instance.center_x\n    center_y = instance.center_y\n    image_width, image_height = image_size\n    crop_width, crop_height = crop_size\n    # Ensure that the center of the instance is within the image boundaries\n    if center_x < crop_width / 2:\n        center_x = crop_width / 2\n    if center_y < crop_height / 2:\n        center_y = crop_height / 2\n    if center_x > image_width - crop_width / 2:\n        center_x = image_width - crop_width / 2\n    if center_y > image_height - crop_height / 2:\n        center_y = image_height - crop_height / 2\n\n    # TODO: This is a hacky way to get the center of a rotated bbox"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox_mode = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox_center = bbox_mode.center(bbox_mode.convert(instance[\"bbox\"], BoxMode.XYXY_ABS))\n    center_x, center_y = bbox_center[0], bbox_center[1]\n    center_x, center_y = int(center_x), int(center_y)\n    w, h = image_size\n\n    # Compute the crop size\n    w_c, h_c = crop_size\n\n    # Compute the top-left corner\n    if w_c > w or h_c > h:\n        logging.warning(\n            \"The crop size is larger than the image size. The crop size is set to the image size.\"\n        )\n        w_c, h_c = w, h\n\n    if center_x < w_c // 2:\n        x1 = 0\n    elif center_x > w - w_c // 2:\n        x1 = w - w_c\n    else:\n        x1 = center_x - w_c // 2\n\n    if center_y < h_c // 2:\n        y1 = 0\n    elif center_y > h - h_c // 2:\n        y1 = h - h_c\n    else:\n        y1 = center_y - h_c // 2\n    return T.CropTransform(y1, x1, h_c, w_c)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    assert (\n        isinstance(crop_size, tuple)\n    ), \"Expected crop_size to be a tuple of int, got {}\".format(crop_size)\n    assert (\n        isinstance(image_size, tuple)\n    ), \"Expected image_size to be a tuple of int, got {}\".format(image_size)\n    assert (\n        isinstance(instance, dict)\n    ), \"Expected instance to be a dict, got {}\".format(type(instance))\n\n    # The crop size is the desired size of the crop\n    w, h = crop_size\n    # The image size is the size of the image\n    iw, ih = image_size\n    # The box is the bounding box of the instance\n    x1, y1, x2, y2 = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    cx = x1 + 0.5 * (x2 - x1)\n    cy = y1 + 0.5 * (y2 - y1)\n\n    # Calculate the top-left corner of the crop\n    x0 = cx - 0.5 * w\n    y0 = cy - 0.5 * h\n\n    # Ensure the top-left corner is within the image boundaries\n    x0 = max(0, min(x0, iw - w))\n    y0 = max(0, min(y0, ih - h))\n\n    # Return the CropTransform object\n    return T.CropTransform(x0, y0, w, h)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance.\n    bbox = instance.get(\"bbox\", [0, 0, 1, 1])\n    bbox_mode = instance.get(\"bbox_mode\", BoxMode.XYXY_ABS)\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    # Get the center of the bounding box.\n    center = bbox[:2] + bbox[2:4] * 0.5\n\n    # Calculate the offset of the crop from the center.\n    offset = (crop_size - image_size) * 0.5\n\n    # Adjust the offset to ensure the crop is within the image boundaries.\n    offset[0] = max(0, min(offset[0], image_size[1] - crop_size[0]))\n    offset[1] = max(0, min(offset[1], image_size[0] - crop_size[1]))\n\n    # Return the CropTransform object.\n    return T.CropTransform(center, offset, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if isinstance(crop_size, tuple) and len(crop_size) == 2:\n        height, width = crop_size\n    elif isinstance(crop_size, int):\n        height, width = crop_size, crop_size\n    else:\n        raise ValueError(\n            \"crop_size must be a single int or a tuple of two ints, got {}.\".format(crop_size)\n        )\n    assert isinstance(image_size, tuple)\n    assert len(image_size) == 2\n    height_in, width_in = image_size\n    assert height_in >= 0 and width_in >= 0\n    assert height > 0 and width > 0\n\n    # get the center of the instance\n    center = instance.gt_boxes.tensor.mean(dim=0)\n\n    # get the center of the crop\n    center_crop = (height / 2, width / 2)\n\n    # get the offset from the center of the image to the center of the crop\n    offset = (center_crop[0] - center[0], center_crop[1] - center[1])\n\n    # get the top-left corner of the crop\n    top_left = (\n        int(offset[0] - width / 2),\n        int(offset[1] - height / 2),\n    )\n\n    # get the dimensions of the crop\n    height_crop, width_crop = height, width\n\n    return T.CropTransform(top_left, (height_crop, width_crop))\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # TODO: support rotated bounding boxes\n    assert instance.has(\"bbox\")\n    assert instance.has(\"bbox_mode\")\n    bbox = instance.bbox\n    bbox_mode = instance.bbox_mode\n\n    # Compute the bounding box of the crop region\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    center_x, center_y = bbox.get_center()\n    size = (\n        bbox.height(),\n        bbox.width(),\n    )\n    crop_x1, crop_y1 = int(center_x - size[0] // 2), int(center_y - size[1] // 2)\n    crop_x2, crop_y2 = int(center_x + size[0] // 2), int(center_y + size[1] // 2)\n    # Ensure that the crop fits within the image boundaries\n    crop_x2 = min(crop_x2, image_size[0])\n    crop_y2 = min(crop_y2, image_size[1])\n    crop_x1 = max(crop_x1, 0)\n    crop_y1 = max(crop_y1, 0)\n    crop_size = (crop_x2 - crop_x1, crop_y2 - crop_y1)\n\n    # Create the CropTransform object\n    transform = T.CropTransform(crop_x1, crop_y1, crop_size)\n    return transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # TODO: add support for rotated boxes\n    assert instance.has(\"bbox\")\n    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    # Find the center of the bounding box\n    center_x = bbox[0] + bbox[2] / 2\n    center_y = bbox[1] + bbox[3] / 2\n\n    # Determine the top-left corner of the crop\n    x1 = max(0, int(center_x - crop_size[0] // 2))\n    y1 = max(0, int(center_y - crop_size[1] // 2))\n\n    # Determine the bottom-right corner of the crop\n    x2 = min(image_size[0], int(center_x + crop_size[0] // 2))\n    y2 = min(image_size[1], int(center_y + crop_size[1] // 2))\n\n    # Construct the crop transform\n    return T.CropTransform(\n        image_size,\n        T.HWC_TO_CHW,\n        [x1, y1],\n        [x2 - x1, y2 - y1],\n        image_mode=\"RGB\",\n    )\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    assert isinstance(instance, dict)\n\n    # Get the bounding box\n    bbox = instance.get(\"bbox\", None)\n    bbox_mode = instance.get(\"bbox_mode\", None)\n    if bbox is None:\n        raise ValueError(\"Cannot create a crop transform without a bounding box!\")\n\n    # Convert to XYXY_ABS if needed\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    # Get the center of the bounding box\n    center = np.array(bbox[:2] + bbox[2:] / 2.0)\n\n    # Calculate the top-left corner of the crop\n    tl = center - np.array(crop_size) / 2.0\n\n    # Ensure the crop is within the image boundaries\n    tl = np.maximum(tl, np.array([0, 0]))\n    tl = np.minimum(tl, image_size[:2] - np.array(crop_size))\n\n    # Create the crop transform\n    return T.CropTransform(tl, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    assert isinstance(\n        crop_size, tuple\n    ), \"crop_size must be a tuple of two ints, but got {}\".format(crop_size)\n    assert isinstance(\n        image_size, tuple\n    ), \"image_size must be a tuple of two ints, but got {}\".format(image_size)\n    assert (\n        instance[\"bbox_mode\"] == \"XYXY_ABS\"\n    ), \"bbox_mode must be XYXY_ABS, but got {}\".format(instance[\"bbox_mode\"])\n\n    # Get the bounding box of the instance.\n    bbox = instance[\"bbox\"]\n\n    # Adjust the bounding box to be relative to the image size.\n    bbox_size = bbox[2:] - bbox[:2]\n    bbox_center = (bbox[:2] + bbox_size / 2).astype(np.int32)\n\n    # Determine the crop region.\n    x1 = np.maximum(0, bbox_center[0] - crop_size[0] // 2)\n    y1 = np.maximum(0, bbox_center[1] - crop_size[1] // 2)\n    x2 = np.minimum(x1 + crop_size[0], image_size[0])\n    y2 = np.minimum(y1 + crop_size[1], image_size[1])\n\n    # Return a CropTransform object that specifies the parameters for the cropping operation.\n    return T.CropTransform(x1, y1, x2, y2)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # TODO: add support for rotated boxes\n    bbox = instance.bbox\n    if bbox.mode == BoxMode.XYXY_ABS:\n        bbox = bbox.to_xyxy()\n    bbox_center = bbox.center()\n    bbox_size = bbox.size()\n    # adjust the center to be in the image\n    bbox_center = bbox_center.clamp(0, image_size)\n    # adjust the size to be within the image\n    bbox_size = bbox_size.clamp(min=0, max=image_size)\n    bbox = bbox_center - bbox_size / 2.0\n\n    # TODO: add support for rotated boxes\n    # crop_size = crop_size.clamp(min=0, max=image_size)\n    # crop_size = crop_size.clamp(min=0, max=image_size)\n    crop_size = crop_size.clamp(min=0, max=image_size)\n    if bbox.size().sum() == 0:\n        # no need to crop\n        return T.Crop(image_size, (0, 0, 0, 0))\n    else:\n        # crop_size = crop_size.clamp(min=bbox_size)\n        # TODO: add support for rotated boxes\n        return T.Crop(crop_size, tuple(bbox))\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    assert isinstance(crop_size, (tuple, list))\n    assert len(crop_size) == 2\n    assert isinstance(image_size, (tuple, list))\n    assert len(image_size) == 2\n\n    assert isinstance(instance, dict)\n    assert \"bbox\" in instance\n    assert \"bbox_mode\" in instance\n    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n\n    # Crop the instance to the image size\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    bbox = bbox.clip(image_size)\n    bbox = bbox.tensor\n\n    # Get the center of the instance\n    center = bbox.mean(dim=1)\n\n    # Determine the top-left corner of the crop\n    # We want the center of the crop to be at the center of the instance, so we need to shift the crop center by half of its size\n    crop_center = center + torch.as_tensor(crop_size) / 2\n    crop_center = crop_center.round()\n\n    # Ensure that the top-left corner of the crop is within the image boundaries\n    top_left = crop_center - torch.as_tensor(crop_size) / 2\n    top_left = top_left.clamp(min=0)\n\n    return T.CropTransform(crop_size, top_left)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance.gt_boxes[0].to_xyxy()\n    crop_x0, crop_y0, crop_x1, crop_y1 = bbox.tolist()\n    image_x0, image_y0, image_x1, image_y1 = image_size\n\n    # Ensure the crop is inside the image\n    crop_x0 = max(crop_x0, 0)\n    crop_y0 = max(crop_y0, 0)\n    crop_x1 = min(crop_x1, image_x1)\n    crop_y1 = min(crop_y1, image_y1)\n\n    # Ensure the crop is of the desired size\n    crop_x1 = min(crop_x1, crop_x0 + crop_size[1])\n    crop_y1 = min(crop_y1, crop_y0 + crop_size[0])\n\n    return T.CropTransform(image_size, (crop_y0, crop_x0), crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if crop_size[0] <= 0 or crop_size[1] <= 0:\n        raise ValueError(\n            \"crop_size must be a positive pair of integers, \"\n            \"but got {}\".format(crop_size)\n        )\n\n    # Get the bounding box and its mode\n    bbox = instance[\"bbox\"]\n    bbox_mode = instance.get(\"bbox_mode\", BoxMode.XYXY_ABS)\n\n    # Convert to absolute coordinates if necessary\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    # Get the center of the bounding box\n    center = bbox.to_point()\n    center = center.tolist()\n\n    # Get the center of the image\n    image_center = image_size / 2\n\n    # Compute the offset of the center of the bounding box from the center of the image\n    center_offset = (\n        (center[0] - image_center[0],\n         center[1] - image_center[1])\n    )\n    # Compute the bounding box of the crop\n    crop_bbox = np.asarray([0, 0, crop_size[0], crop_size[1]])\n    # Compute the top-left corner of the crop\n    crop_corner = center_offset - crop_bbox / 2\n\n    # Adjust the top-left corner to ensure the crop is within the image\n    crop_corner = np.maximum(crop_corner, [0, 0])\n    crop_corner = np.minimum(crop_corner, image_size - crop_size)\n\n    # Create the crop transform\n    return T.CropTransform(crop_corner[0], crop_corner[1], crop_size[0], crop_size[1])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance.get(\"bbox_mode\", BoxMode.XYXY_ABS)\n\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    # Compute the center of the bounding box.\n    center = bbox.mean(dim=0)\n\n    # Compute the size of the bounding box.\n    w, h = bbox.x.max(dim=0) - bbox.x.min(dim=0)\n    w = w.item()\n    h = h.item()\n\n    # Compute the size of the crop.\n    if h < crop_size[0]:\n        h = crop_size[0]\n    if w < crop_size[1]:\n        w = crop_size[1]\n\n    # Compute the top-left corner of the crop.\n    x = center[0] - w / 2\n    y = center[1] - h / 2\n    if x < 0:\n        x = 0\n    if y < 0:\n        y = 0\n\n    # Create a transform object.\n    return T.CropTransform(\n        (y, x), (h, w), image_size, image_size\n    )\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Determine the center of the instance's bounding box\n    box = instance.gt_boxes.tensor\n    center = (box.sum(dim=1) / 2).int()\n\n    # Determine the top-left corner of the crop\n    offset_x, offset_y = 0, 0\n    if center[0] > image_size[0] / 2:\n        offset_x = center[0] - image_size[0] // 2\n    if center[1] > image_size[1] / 2:\n        offset_y = center[1] - image_size[1] // 2\n\n    # Ensure the crop is within the image boundaries\n    offset_x = max(offset_x, 0)\n    offset_y = max(offset_y, 0)\n\n    # Determine the dimensions of the crop\n    crop_h, crop_w = crop_size\n    crop_h = min(crop_h, image_size[0] - offset_y)\n    crop_w = min(crop_w, image_size[1] - offset_x)\n\n    # Create the CropTransform object\n    transform = T.CropTransform(offset_x, offset_y, crop_h, crop_w)\n\n    return transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if isinstance(instance.bbox_mode, str):\n        bbox = BoxMode.convert(instance.bbox, instance.bbox_mode, BoxMode.XYXY_ABS)\n    else:\n        bbox = instance.bbox\n\n    if bbox is None:\n        return T.Crop(size=crop_size)\n    else:\n        # Make sure the bounding box is in XYXY_ABS format\n        bbox = BoxMode.convert(bbox, instance.bbox_mode, BoxMode.XYXY_ABS)\n        bbox_center = bbox.tensor.mean(dim=0)\n        # Compute the offset of the center of the bounding box from the center of the image.\n        # This offset will be half of the crop size.\n        center_offset = bbox_center - image_size[0] / 2, bbox_center - image_size[1] / 2\n        return T.Crop(center=center_offset, size=crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # TODO: this is a temporary implementation.\n    # It is a bit naive and does not handle the case when the instance\n    # is too small.\n    # We should use the same implementation as detectron2\n    bbox = instance.bbox\n    bbox_mode = instance.bbox_mode\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n    x1, y1, x2, y2 = bbox\n    x1, x2 = int(x1), int(x2)\n    y1, y2 = int(y1), int(y2)\n\n    # x_center, y_center = x1 + 0.5 * (x2 - x1), y1 + 0.5 * (y2 - y1)\n    x_center, y_center = int(x1 + 0.5 * (x2 - x1)), int(y1 + 0.5 * (y2 - y1))\n\n    # Crop the instance in the center\n    cx, cy = crop_size\n    x1, y1 = x_center - int(0.5 * cx), y_center - int(0.5 * cy)\n    x2, y2 = x1 + cx, y1 + cy\n    return T.CropTransform(\n        image_size, (x1, y1), (x2 - x1, y2 - y1),\n    )\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    assert isinstance(image_size, tuple)\n    assert len(image_size) == 2\n    assert isinstance(instance, dict)\n\n    # TODO: handle other bbox_modes\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    assert bbox.shape == (4,)\n    bbox = bbox.numpy()\n    # center of bbox\n    center = bbox[[0, 2]].mean(axis=0)\n\n    # If the bbox is not within the image, we return a crop_transform that\n    # does nothing.\n    if bbox[0] >= image_size[0] or bbox[1] >= image_size[1]:\n        return T.Crop(image_size)\n\n    # Compute the top-left corner of the crop.\n    # The top-left corner is the point that maximizes the distance to the center of the bbox.\n    # We first find the distance to the center for each point on the left edge of the bbox.\n    # We then find the max distance.\n    # TODO: This is a little bit inefficient.\n    x_left_edge = np.linspace(bbox[0], bbox[3], 4)\n    y_max_distance = np.max(np.sqrt((x_left_edge - center[0]) ** 2 + (bbox[2] - center[1]) ** 2))\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    # TODO: handle other bbox_modes\n    "}
{"namespace": "ref_utils.l2_normalize", "completion": "  denom = jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True))\n  denom = jnp.where(denom < grad_eps, grad_eps, denom)\n  return x / denom\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.clip(jnp.sum(x ** 2, axis=-1, keepdims=True), a=grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.maximum(jnp.sum(jnp.square(x), axis=-1), grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.maximum(jnp.sum(jnp.square(x), axis=-1, keepdims=True), grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.maximum(jnp.sum(x * x, axis=-1, keepdims=True),\n                                    grad_eps)), jnp.sqrt(jnp.maximum(jnp.sum(x * x, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  norm = jnp.where(norm > 0.0, norm, grad_eps)\n  return x / norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.where(\n      jnp.abs(jnp.sum(x**2, axis=-1, keepdims=True)) > grad_eps,\n      jnp.sqrt(1.0 / jnp.sum(x**2, axis=-1, keepdims=True)),\n      jnp.ones_like(x) * grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.maximum(jnp.sum(x * x, axis=-1, keepdims=True)), grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / math_lib.l2_normalize(\n      jnp.sum(x ** 2, axis=-1, keepdims=True), grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm_sq = jnp.sum(jnp.abs(x)**2, axis=-1, keepdims=True)\n  x_norm = jnp.sqrt(x_norm_sq)\n  x_norm_clamp = jnp.where(\n      x_norm_sq > grad_eps, x_norm, jnp.sqrt(grad_eps))\n\n  return x / x_norm_clamp\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.where(\n      jnp.abs(jnp.sum(x**2, axis=-1)) < grad_eps,\n      jnp.ones_like(x),\n      jnp.sqrt(jnp.sum(x**2, axis=-1))\n  )\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm_squared = jnp.square(x)\n  denom = jnp.sqrt(\n      jnp.maximum(norm_squared, jnp.full_like(norm_squared, grad_eps)))\n  return x / denom\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Calculate the squared norm of the input along the last axis.\n  squared_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Normalize the input, but clamp the denominator to a small value to avoid\n  # division by zero or overflow.\n  return x / jnp.sqrt(jnp.where(squared_norm > 0.0, squared_norm, grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True)), jnp.where(\n      jnp.isclose(jnp.sum(x ** 2, axis=-1, keepdims=True), 0), grad_eps, 1)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sum(x ** 2, axis=-1, keepdims=True), grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.where(\n      jnp.abs(jnp.sum(x * x, axis=-1, keepdims=True)) > grad_eps,\n      jnp.sqrt(1.0 + grad_eps),\n  )\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.maximum(jnp.sum(x * x, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.clip(jnp.sum(x ** 2, axis=-1, keepdims=True), a_min=grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.maximum(jnp.sum(x * x, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.maximum(jnp.sum(jnp.square(x), axis=-1, keepdims=True), grad_eps)\n\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")\n        agent_name = agent_info[1].split(\"]\")[0]\n        input_text = agent_info[1].split(\"]\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[-1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name.strip(), input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name_index = response.find(\"Use Agent[\") + len(\"Use Agent[\")\n        agent_name_end_index = response.find(\"]\", agent_name_index)\n\n        agent_name = response[agent_name_index:agent_name_end_index]\n        input_text = response[agent_name_end_index + 1 :]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent name from the response string, delimited by 'Use Agent[' and ']'\n        agent_name = response.split('Use Agent[')[1].split(']')[0]\n\n        # Extract any input text associated with the agent, if present, separated by a colon\n        if ':' in agent_name:\n            agent_name, input_text = agent_name.split(':')\n        else:\n            input_text = ''\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Parse the agent information from the response string\n        agent_info = response.split('Use Agent[')[-1].split(']')[0]\n        agent_name, input_text = agent_info.split(':')\n\n        # Remove any whitespace from the agent name\n        agent_name = agent_name.strip()\n\n        # If no input text is present, set the second element of the returned tuple to an empty string\n        if not input_text:\n            input_text = ''\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Parse the agent information from the response string\n        agent_info = response.split('Use Agent[', 1)[-1]\n        agent_name = agent_info.split(']', 1)[0]\n        input_text = agent_info.split(':', 1)[1] if ':' in agent_info else ''\n\n        # Return the agent name and the input text\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent name from the response string, which is expected to be in the format \"Use Agent[name]\".\n        agent_name = response.split('Use Agent[')[-1].split(']')[0]\n\n        # Extract the input text from the response string, if present. The input text is expected to be delimited by a colon.\n        input_text = response.split(':')[-1].strip()\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split('Use Agent[')[1].split(']')[0]\n        if \"Use Agent[\" in response:\n            input_text = response.split('Use Agent[')[1].split(']:')[1].split(']')[0]\n        else:\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info_start = response.find(\"Use Agent[\")\n        agent_info_end = response.find(\"]\")\n\n        agent_name = response[agent_info_start + 9 : agent_info_end]\n\n        if \"input:\" in response:\n            input_text_start = response.find(\"input:\") + 6\n            input_text_end = response.find(\"\\n\", input_text_start)\n            input_text = response[input_text_start:input_text_end]\n        else:\n            input_text = \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract agent name\n        agent_name = response[response.find(\"Use Agent[\") + 10 : response.find(\"]\")]\n\n        # Extract input text (if present)\n        if response.find(\":\") > 0:\n            input_text = response[response.find(\":\") + 2 :]\n            return agent_name, input_text\n        else:\n            return agent_name, \"\"\n        "}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info_index = response.index(\"Use Agent[\")\n        agent_info_string = response[agent_info_index + 10:]\n        agent_name = agent_info_string[0:agent_info_string.index(\"]\")]\n\n        if \":\" in agent_info_string:\n            input_text = agent_info_string[agent_info_string.index(\":\") + 2:]\n            return agent_name, input_text\n        else:\n            return agent_name, \"\"\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[-1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n\n        return agent_name, input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent name from the response string.\n        agent_name = response.split(\"Use Agent[\")[-1].split(\"]\")[0]\n        # Extract the input text from the response string, if present.\n        if \"]\" in response:\n            input_text = response.split(\"]\")[1]\n            input_text = input_text.split(\"Input:\")[1].split(\"\\n\")[0]\n        else:\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name_and_input_text = response.split(\"Use Agent[\")\n        agent_name = agent_name_and_input_text[1].split(\"]\")[0]\n        input_text = agent_name_and_input_text[1].split(\"]\")[1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response[response.find(\"Use Agent[\") + 9:response.find(\"]\")]\n        input_text = response[response.find(\"Use Agent[\") + 9:response.find(\"]\")].split(\"]\")[1]\n        if \"Input:\" in input_text:\n            input_text = input_text[input_text.find(\"Input:\") + 6:]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent name from the response string using the 'Use Agent[' and ']' delimiters.\n        agent_name = response[response.find(\"Use Agent[\") + len(\"Use Agent[\"): response.find(\"]\")]\n\n        # If the response string contains a colon, it is assumed that the agent has input text associated with it.\n        if \":\" in response:\n            # Extract the input text from the response string, which is delimited by the colon and the next line break.\n            input_text = response[response.find(\":\") + 1: response.find(\"\\n\", response.find(\":\"))]\n        else:\n            # If there is no input text, the second element of the returned tuple is an empty string.\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info_start_index = response.find(\"Use Agent[\")\n        if agent_info_start_index == -1:\n            raise ValueError(\n                \"The response string does not contain the expected agent information in the format 'Use Agent[' and ']'\"\n            )\n\n        agent_info = response[agent_info_start_index + len(\"Use Agent[\"):]\n        agent_name = agent_info[agent_info.find(\"]\") + 1 : ]\n        input_text = agent_info[:agent_info.find(\":\")]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Find the index of the first occurrence of 'Use Agent[' in the response string\n        use_agent_index = response.find('Use Agent[')\n        if use_agent_index == -1:\n            return \"\", \"\"\n\n        # Extract the agent name from the response string\n        agent_name = response[use_agent_index + 8:-1]\n\n        # Find the index of the first occurrence of the closing ']' after the agent name\n        closing_index = response.find(']', use_agent_index)\n\n        # Extract the input text, if present\n        if closing_index == -1:\n            return agent_name, \"\"\n        else:\n            input_text = response[closing_index + 1:]\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[-1].split(\"]\")[0]\n        input_text = response.split(f\"Use Agent[{agent_name}]: \")[1].lstrip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name_index = response.find('Agent[')\n        agent_name = response[agent_name_index + 6: response.find(']', agent_name_index)]\n        input_text_index = response.find(':', agent_name_index)\n        input_text = response[input_text_index + 2:] if input_text_index > 0 else \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if mask_format == \"polygon\":\n        return annotations_to_instances_polygons(annos, image_size)\n\n    elif mask_format == \"bitmask\":\n        return annotations_to_instances_bitmask(annos, image_size)\n\n    else:\n        raise ValueError(\n            f\"Unknown mask_format {mask_format}. Supported mask_format are 'polygon' and 'bitmask'.\"\n        )\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    gt_boxes = Boxes(np.array([a[\"bbox\"] for a in annos]))\n    gt_boxes.clip(image_size)\n    gt_classes = [a[\"category_id\"] for a in annos]\n\n    if \"segmentation\" in annos[0]:\n        gt_masks = []\n        if mask_format == \"polygon\":\n            for anno in annos:\n                gt_masks.append(polygons_to_bitmask(anno[\"segmentation\"], image_size))\n        elif mask_format == \"bitmask\":\n            gt_masks = [anno[\"segmentation\"] for anno in annos]\n        else:\n            raise ValueError(\n                \"Unsupported mask_format: {}\".format(mask_format)\n            )\n    else:\n        gt_masks = [None] * len(annos)\n\n    if \"keypoints\" in annos[0]:\n        gt_keypoints = Keypoints(\n            np.asarray([a[\"keypoints\"] for a in annos]),\n            a[\"num_keypoints\"] if \"num_keypoints\" in a else 17,\n        )\n        gt_keypoints.clip(image_size)\n    else:\n        gt_keypoints = None\n\n    return Instances(image_size, gt_boxes, gt_classes, gt_masks, gt_keypoints)\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    num_anns = len(annos)\n\n    # Create the Instances object\n    gt_boxes = np.zeros((num_anns, 4), dtype=np.float32)\n    gt_classes = np.zeros((num_anns,), dtype=np.int64)\n    # gt_masks = None\n    gt_keypoints = None\n\n    # Populate the fields\n    for i, anno in enumerate(annos):\n        if \"bbox\" in anno:\n            gt_boxes[i, :] = anno[\"bbox\"]\n        if \"category_id\" in anno:\n            gt_classes[i] = anno[\"category_id\"]\n        if \"segmentation\" in anno:\n            if mask_format == \"polygon\":\n                gt_masks = anno[\"segmentation\"]\n                gt_masks = poly2mask(gt_masks, image_size, gt_classes[i])\n                gt_masks = gt_masks.reshape(gt_masks.shape[0], -1)\n            elif mask_format == \"bitmask\":\n                gt_masks = anno[\"segmentation\"]\n            else:\n                raise NotImplementedError(\n                    \"Unsupported mask format: {}\".format(mask_format)\n                )\n        if \"keypoints\" in anno:\n            gt_keypoints = anno[\"keypoints\"]\n\n    # Set the fields of the Instances object\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(gt_boxes)\n    instances.gt_classes = gt_classes\n    instances.gt_masks = gt_masks\n    instances.gt_keypoints = gt_keypoints\n    return instances\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if mask_format == \"polygon\":\n        gt_masks = PolygonMasks(annos, image_size)\n    elif mask_format == \"bitmask\":\n        gt_masks = BitMasks(annos, image_size)\n    else:\n        raise ValueError(\n            \"Unknown mask_format. Please choose between 'polygon' and 'bitmask'\"\n        )\n\n    gt_boxes = Boxes(np.array([anno[\"bbox\"] for anno in annos]))\n    gt_classes = np.array([anno[\"category_id\"] for anno in annos])\n\n    if \"keypoints\" in annos[0]:\n        gt_keypoints = Keypoints(\n            np.array([anno[\"keypoints\"] for anno in annos]),\n            image_size=image_size,\n            kps_id_to_name=annos[0][\"keypoints_id_to_name\"],\n        )\n    else:\n        gt_keypoints = None\n\n    return Instances(image_size, gt_boxes, gt_classes, gt_masks, gt_keypoints)\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if mask_format == \"polygon\":\n        masks = [\n            np.array(a[\"segmentation\"]).reshape(-1, 2)\n            for a in annos\n            if \"segmentation\" in a\n        ]\n        if len(masks) > 0:\n            # convert to bitmasks\n            masks = [polygons_to_bitmask(mask) for mask in masks]\n            if len(masks) > 0:\n                masks = BitMasks(masks)\n    elif mask_format == \"bitmask\":\n        masks = [a[\"segmentation\"] for a in annos if \"segmentation\" in a]\n    else:\n        raise ValueError(\n            \"Unsupported mask format '{}', only 'polygon' and 'bitmask' are supported\".format(\n                mask_format\n            )\n        )\n\n    return Instances(\n        image_size,\n        # boxes\n        Boxes(np.array([a[\"bbox\"] for a in annos if \"bbox\" in a], dtype=np.float32)),\n        # classes\n        a[\"category_id\"] for a in annos if \"category_id\" in a),\n        # masks\n        masks,\n        # keypoints\n        Keypoints(\n            np.array([a[\"keypoints\"] for a in annos if \"keypoints\" in a], dtype=np.float32),\n            a[\"keypoints_kpts_id\"] for a in annos if \"keypoints_kpts_id\" in a),\n    )\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if not isinstance(annos, list):\n        raise ValueError(\n            \"annos must be a list, got {}\".format(type(annos))\n        )\n\n    if not isinstance(image_size, (tuple, list)):\n        raise ValueError(\"image_size must be a tuple or list, got {}\".format(type(image_size)))\n\n    # Create an empty Instances object\n    instances = Instances(image_size)\n\n    # Add annotations to the Instances object\n    instances.gt_boxes = Boxes(annos[\"boxes\"])\n    instances.gt_classes = annos[\"labels\"]\n    instances.gt_masks = []\n    instances.gt_keypoints = []\n\n    # Process segmentation\n    if \"segmentation\" in annos:\n        if mask_format == \"polygon\":\n            instances.gt_masks = [\n                PolygonMasks(annos[\"segmentation\"])\n                for annos in annos[\"segmentation\"]\n            ]\n        elif mask_format == \"bitmask\":\n            instances.gt_masks = [\n                BitMasks(np.array(annos[\"segmentation\"]))\n                for annos in annos[\"segmentation\"]\n            ]\n        else:\n            raise ValueError(\"Unsupported mask_format: {}\".format(mask_format))\n\n    # Process keypoints\n    if \"keypoints\" in annos:\n        instances.gt_keypoints = [\n            Keypoints(annos[\"keypoints\"]) for annos in annos[\"keypoints\"]\n        ]\n    return instances\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if mask_format == \"polygon\":\n        gt_masks = [\n            np.asarray(annos[i][\"segmentation\"], np.float32)\n            for i in range(len(annos))\n        ]\n    elif mask_format == \"bitmask\":\n        gt_masks = [\n            polygons_to_bitmask(annos[i][\"segmentation\"], image_size)\n            for i in range(len(annos))\n        ]\n    else:\n        raise ValueError(\n            \"Mask format {} is not supported. \"\n            \"Supported formats: 'polygon', 'bitmask'.\".format(mask_format)\n        )\n\n    gt_boxes = [\n        BoxMode.convert(annos[i][\"bbox\"], annos[i][\"bbox_mode\"], BoxMode.XYXY_ABS)\n        for i in range(len(annos))\n    ]\n    gt_boxes = [\n        BoxMode.convert(\n            gt_box, BoxMode.XYXY_ABS, BoxMode.XYXY_REL\n        )\n        for gt_box in gt_boxes\n    ]\n\n    gt_classes = [annos[i][\"category_id\"] for i in range(len(annos))]\n\n    if \"keypoints\" in annos[0]:\n        gt_keypoints = [annos[i][\"keypoints\"] for i in range(len(annos))]\n        gt_keypoint_hflip_indices = None\n    else:\n        gt_keypoints = None\n        gt_keypoint_hflip_indices = None\n\n    gt_is_crowd = [annos[i].get(\"iscrowd\", False) for i in range(len(annos))]\n    gt_is_ignore = [annos[i].get(\"ignore\", False) for i in range(len(annos))]\n\n    if not all(gt_is_crowd) and not all(gt_is_ignore):\n        # Only create gt_areas if not all gt_is_crowd or gt_is_ignore are True\n        gt_areas = [annos[i][\"area\"] for i in range(len(annos))]\n    else:\n        gt_areas = None\n\n    gt"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n    for anno in annos:\n        # bboxes\n        bbox = np.array(anno[\"bbox\"])\n        if anno[\"iscrowd\"]:\n            bbox[2] += bbox[0]\n            bbox[3] += bbox[1]\n        boxes.append(bbox)\n\n        # class\n        classes.append(anno[\"category_id\"])\n\n        # mask\n        if mask_format == \"polygon\":\n            if \"segmentation\" in anno:\n                assert isinstance(anno[\"segmentation\"], list)\n                masks.append(polygons_to_bitmask(anno[\"segmentation\"], image_size))\n            else:\n                masks.append(np.zeros((image_size[0], image_size[1]), dtype=np.uint8))\n        elif mask_format == \"bitmask\":\n            if \"segmentation\" in anno:\n                assert isinstance(anno[\"segmentation\"], list)\n                masks.append(anno[\"segmentation\"])\n            else:\n                masks.append(np.zeros(image_size, dtype=np.uint8))\n        else:\n            raise ValueError(f\"Unsupported mask format {mask_format}\")\n\n        # keypoints\n        if \"keypoints\" in anno:\n            keypoints.append(np.array(anno[\"keypoints\"]))\n        else:\n            keypoints.append(np.zeros((0, 3), dtype=np.float32))\n\n    if not boxes:\n        boxes = np.zeros((0, 4), dtype=np.float32)\n    else:\n        boxes = np.stack(boxes, axis=0)\n    if not classes:\n        classes = np.zeros((0,), dtype=np.int64)\n    else:\n        classes = np.array(classes, dtype=np.int64)\n    if not masks:\n        masks = np.zeros((0, image_size[0], image_size[1], 1), dtype=np.uint8)\n    else:\n        masks = np.stack(masks, axis=0)\n    if not keypoints:\n        keypoints = np.zeros((0, 3"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    gt_boxes = Boxes(\n        np.array(\n            [\n                np.array(anno[\"bbox\"])\n                if \"bbox\" in anno\n                else np.array(anno[\"segmentation\"][0:4]).reshape(4, 2)\n                for anno in annos\n            ]\n        )\n    )\n    gt_boxes = gt_boxes.clip(image_size)\n    gt_classes = [anno[\"category_id\"] for anno in annos]\n    gt_classes = np.asarray(gt_classes, dtype=np.int64)\n\n    # If there is only one class, we can use a vector instead of a matrix\n    if len(np.unique(gt_classes)) == 1:\n        gt_classes = gt_classes[0]\n\n    if mask_format == \"polygon\":\n        gt_masks = [\n            np.asarray(anno[\"segmentation\"], dtype=np.float32)\n            for anno in annos\n            if \"segmentation\" in anno\n        ]\n    elif mask_format == \"bitmask\":\n        gt_masks = [\n            polygons_to_bitmask(anno[\"segmentation\"], image_size)\n            for anno in annos\n            if \"segmentation\" in anno\n        ]\n    else:\n        raise ValueError(\n            \"Unsupported mask_format: {}! Supported formats are 'polygon' and 'bitmask'\".format(\n                mask_format\n            )\n        )\n\n    if len(gt_masks) > 0:\n        gt_masks = BitMasks(gt_masks)\n    else:\n        gt_masks = None\n\n    gt_keypoints = [\n        np.asarray(anno[\"keypoints\"])\n        for anno in annos\n        if \"keypoints\" in anno\n    ]\n    if len(gt_keypoints) > 0:\n        gt_keypoints = Keypoints(gt_keypoints)\n    else:\n        gt_keypoints = None\n\n    gt_is_crowd = [\n        anno[\"iscrowd\"] if \"iscrowd\" in anno else False for anno in annos\n    ]\n    gt_is_crowd = np.asarray(gt_is_crowd, dtype=np.uint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Make a new object for the image\n    instances = Instances(image_size)\n\n    # If the annotations are not empty\n    if len(annos) > 0:\n\n        # Add the annotations to the Instances object\n        instances.gt_classes = np.array([anno[\"category_id\"] for anno in annos])\n        instances.gt_boxes = Boxes(\n            np.array([anno[\"bbox\"] for anno in annos])\n        )\n\n        # Add the segmentation masks\n        if mask_format == \"polygon\":\n            instances.gt_masks = [\n                PolygonMasks(anno[\"segmentation\"]) for anno in annos\n            ]\n        elif mask_format == \"bitmask\":\n            instances.gt_masks = [\n                BitMasks(anno[\"segmentation\"]) for anno in annos\n            ]\n        else:\n            raise ValueError(\n                \"Unsupported mask_format {}. Supported formats are polygon and bitmask\".format(\n                    mask_format\n                )\n            )\n\n        # Add the keypoints\n        if \"keypoints\" in annos[0]:\n            instances.gt_keypoints = Keypoints(\n                np.array([anno[\"keypoints\"] for anno in annos])\n            )\n\n    # Return the instances object\n    return instances\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    instances = Instances(image_size)\n\n    if \"boxes\" in annos:\n        boxes = np.array(annos[\"boxes\"]).astype(\"float32\")\n        assert boxes.shape[1] == 4\n        instances.gt_boxes = Boxes(boxes)\n    if \"labels\" in annos:\n        instances.gt_classes = np.asarray(annos[\"labels\"], dtype=np.int64)\n    if \"masks\" in annos:\n        if mask_format == \"polygon\":\n            mask = annos[\"masks\"]\n            assert isinstance(mask, list)\n            instances.gt_masks = PolygonMasks(mask)\n        elif mask_format == \"bitmask\":\n            mask = annos[\"masks\"]\n            assert isinstance(mask, list)\n            # convert to BitMasks\n            # TODO: this is inefficient, refactor to use np.frombuffer\n            mask_np = np.asarray(mask, dtype=np.bool)\n            mask_np = poly2mask(mask_np, image_size[:2], [0])\n            instances.gt_masks = BitMasks(mask_np)\n        else:\n            raise ValueError(f\"Unrecognized mask_format {mask_format}\")\n    if \"keypoints\" in annos:\n        instances.gt_keypoints = Keypoints(annos[\"keypoints\"])\n\n    return instances\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    num_objs = len(annos)\n    if num_objs == 0:\n        return Instances(image_size, 0)\n\n    # 1. Create an empty Instances object\n    instances = Instances(image_size, num_objs)\n\n    # 2. Set the fields\n    # 2.1. Set gt_boxes, gt_classes, gt_masks, and gt_keypoints\n    for anno in annos:\n        if \"bbox\" in anno:\n            bbox = anno[\"bbox\"]\n            if bbox is not None:\n                bbox_mode = BoxMode.convert(\n                    bbox, anno.get(\"bbox_mode\", BoxMode.XYWH_ABS), BoxMode.XYXY_ABS\n                )\n                instances.gt_boxes[anno[\"id\"] - 1] = bbox_mode\n\n        if \"segmentation\" in anno:\n            segmentation = anno[\"segmentation\"]\n            if segmentation is not None:\n                if mask_format == \"polygon\":\n                    assert isinstance(segmentation, list)\n                    # We use PolygonMasks for polygons\n                    instances.gt_masks[anno[\"id\"] - 1] = PolygonMasks(segmentation)\n                elif mask_format == \"bitmask\":\n                    # We use BitMasks for bitmasks\n                    instances.gt_masks[anno[\"id\"] - 1] = BitMasks(polygons_to_bitmask(segmentation))\n                else:\n                    raise ValueError(\n                        \"Unknown mask_format: {}\".format(mask_format)\n                    )\n\n        if \"keypoints\" in anno:\n            keypoints = anno[\"keypoints\"]\n            if keypoints is not None:\n                instances.gt_keypoints[anno[\"id\"] - 1] = Keypoints(keypoints)\n\n        # Set the class of the annotation\n        if \"category_id\" in anno:\n            instances.gt_classes[anno[\"id\"] - 1] = anno[\"category_id\"]\n        elif \"category_id\" in anno:\n            instances.gt_classes[anno[\"id\"] - 1] = anno[\"category_id\"]\n        else:\n            raise ValueError(\n                \"Cannot find category_id in annotation: {}\".format(anno)\n            )\n\n    "}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create a new instances object with the image size\n    instances = Instances(image_size)\n    # Add the fields that are common to all instances\n    for anno in annos:\n        if \"bbox\" in anno:\n            bbox = anno[\"bbox\"]\n            if isinstance(bbox, list):\n                bbox = np.array(bbox, dtype=np.float32)\n            instances.gt_boxes = Boxes(bbox)\n        if \"class\" in anno:\n            instances.gt_classes = np.array(anno[\"class\"])\n        if \"iscrowd\" in anno:\n            instances.is_crowd = np.array(anno[\"iscrowd\"])\n        if \"segmentation\" in anno:\n            if mask_format == \"polygon\":\n                if isinstance(anno[\"segmentation\"], list):\n                    # polygon\n                    masks = []\n                    for poly in anno[\"segmentation\"]:\n                        if isinstance(poly, list):\n                            # COCO-style polygon\n                            poly = np.array(poly)\n                        masks.append(poly)\n                    instances.gt_masks = PolygonMasks(masks)\n            elif mask_format == \"bitmask\":\n                # bitmask\n                if isinstance(anno[\"segmentation\"], list):\n                    # COCO-style polygon\n                    mask = np.array(anno[\"segmentation\"], order=\"F\")\n                else:\n                    # RLE\n                    mask = mask_util.decode(anno[\"segmentation\"])\n                mask = mask.reshape(mask.shape[1], mask.shape[0])\n                mask = mask.astype(np.uint32, copy=False)\n                instances.gt_masks = BitMasks(mask)\n            else:\n                raise ValueError(\n                    \"Unsupported mask format: {}\".format(mask_format)\n                )  # pragma: no branch\n        if \"keypoints\" in anno:\n            if anno[\"keypoints\"] is not None:\n                # keypoints\n                keypoints = anno[\"keypoints\"]\n                if isinstance(keypoints, list):\n                    keypoints = np.array(keypoints, dtype=np.float32)\n                instances.gt_keypoints = Keypoints(keypoints)\n            else:\n                instances.gt_keypoints = None"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    annos = list(annos)  # make a copy since we modify it in-place\n    num_instances = len(annos)\n    # Create an empty instance\n    instances = Instances(image_size)\n    instances.gt_classes = np.ones(num_instances, dtype=np.int64)\n    instances.gt_boxes = Boxes(np.zeros((num_instances, 4), dtype=np.float32))\n    instances.gt_keypoints = Keypoints(\n        np.zeros((num_instances, 3), dtype=np.float32)\n    )\n    instances.gt_masks = BitMasks(np.zeros((num_instances, image_size[0], image_size[1])))\n\n    # Get the number of keypoint types\n    num_keypoint_types = 0\n    for anno in annos:\n        if \"keypoints\" in anno:\n            num_keypoint_types = len(anno[\"keypoints\"][0])\n            break\n\n    # Populate the instance fields\n    for i, anno in enumerate(annos):\n        if \"bbox\" in anno:\n            # BBox\n            bbox = anno[\"bbox\"]\n            if \"bbox_mode\" in anno:\n                bbox = BoxMode.convert(bbox, anno[\"bbox_mode\"], BoxMode.XYXY_ABS)\n            bbox_left_top = bbox[[0, 1]]\n            bbox_right_bottom = bbox[[2, 3]]\n\n            bbox_left_top = bbox_left_top.clip(min=0)\n            bbox_right_bottom = bbox_right_bottom.clip(min=0)\n            bbox = np.stack([bbox_left_top, bbox_right_bottom], axis=0)\n            instances.gt_boxes[i] = Boxes(bbox)\n        if \"class_id\" in anno:\n            instances.gt_classes[i] = anno[\"class_id\"]\n        if \"segmentation\" in anno:\n            # Polygon\n            if mask_format == \"polygon\":\n                if isinstance(anno[\"segmentation\"], list):\n                    # polygon\n                    # Convert to (x1, y1, x2, y2,"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # 1. Create an empty Instances object with the right size and image_shape\n    gt_boxes = np.zeros((len(annos), 4), dtype=np.float32)\n    gt_classes = np.zeros((len(annos),), dtype=np.int64)\n    if mask_format == \"polygon\":\n        gt_masks = [\n            np.zeros((0, 0), dtype=np.bool)\n            for _ in annos\n        ]  # empty masks for polygons\n    elif mask_format == \"bitmask\":\n        gt_masks = [np.zeros((0, 0), dtype=np.uint8) for _ in annos]  # empty masks for bitmasks\n    else:\n        raise ValueError(\n            \"Unknown mask_format {}. Supported values: polygon, bitmask\".format(mask_format)\n        )\n    gt_keypoints = [np.zeros((0, 3), dtype=np.int64) for _ in annos]\n\n    instances = Instances(image_size, gt_boxes, gt_classes, gt_masks, gt_keypoints)\n\n    # 2. Populate the gt_boxes, gt_classes, gt_masks, and gt_keypoints fields\n    for i, anno in enumerate(annos):\n        # convert the annotations in each dict to the format that the model needs\n        # (i.e. XYXY_ABS for boxes, COCO-style for masks and keypoints)\n        anno = transform_instance_annotations(anno, image_size)\n\n        if \"boxes\" in anno:\n            instances.gt_boxes[i] = anno[\"boxes\"]\n        if \"labels\" in anno:\n            instances.gt_classes[i] = anno[\"labels\"]\n        if \"masks\" in anno:\n            instances.gt_masks[i] = anno[\"masks\"]\n        if \"keypoints\" in anno:\n            instances.gt_keypoints[i] = anno[\"keypoints\"]\n\n        # if \"iscrowd\" in anno:\n        #     instances.is_crowd[i] = anno[\"iscrowd\"]\n\n    return instances\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    num_objs = len(annos)\n    gt_boxes = np.zeros((num_objs, 4), dtype=np.float32)\n    gt_classes = np.zeros((num_objs), dtype=np.int64)\n    gt_masks = None\n    gt_keypoints = None\n\n    # Load the boxes\n    for i, anno in enumerate(annos):\n        # Get the bounding boxes\n        # The annotation may contain a \"bbox_mode\" field. If so, we use the\n        # mode to convert the bounding box to the right format.\n        gt_boxes[i, :] = BoxMode.convert(anno[\"bbox\"], anno.get(\"bbox_mode\", BoxMode.XYXY_ABS), BoxMode.XYXY_ABS)\n        gt_classes[i] = anno[\"category_id\"]\n\n        if \"segmentation\" in anno:\n            # Load the masks\n            if mask_format == \"polygon\":\n                gt_masks = np.asarray(anno[\"segmentation\"], order=\"F\")\n                gt_masks = polygons_to_bitmask(gt_masks, gt_boxes[i, :2], image_size)\n                gt_masks = gt_masks.astype(np.uint8)\n            elif mask_format == \"bitmask\":\n                gt_masks = np.asarray(anno[\"segmentation\"], order=\"F\")\n            else:\n                raise ValueError(\n                    \"Unknown mask_format {}. Supported formats are 'polygon' and 'bitmask'.\".format(\n                        mask_format\n                    )\n                )\n        if \"keypoints\" in anno:\n            gt_keypoints = np.asarray(anno[\"keypoints\"], dtype=np.float32)\n            gt_keypoints = gt_keypoints.reshape(\n                (gt_keypoints.shape[0], 3)\n            )\n            # Set all out-of-boundary points to \"unlabeled\"\n            inside = (gt_keypoints[:, 0] >= 0) & (gt_keypoints[:, 0] < image_size[0]) & (\n                gt_keypoints[:, 1] >= 0\n            ) & (gt_keypoints[:, 1] < image_"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert to XYXY_ABS\n    boxes = Boxes(\n        np.array(\n            [\n                BoxMode.convert(bbox, bbox_mode=bbox_mode, new_bbox_mode=BoxMode.XYXY_ABS)\n                for bbox, bbox_mode in annos\n            ]\n        )\n    )\n    # clip transformed bbox to image size\n    boxes.clip(image_size)\n\n    # TODO: create a `gt_boxes` field and convert the boxes to XYXY_ABS\n    # boxes = boxes.clip(image_size)\n    # boxes = BoxMode.convert(boxes, bbox_mode=bbox_mode, new_bbox_mode=BoxMode.XYXY_ABS)\n\n    # Create a new field \"gt_classes\"\n    # TODO: create a `gt_classes` field\n    # gt_classes = [annos[\"category_id\"] for annos in annos]\n    # TODO: convert the classes to int\n    gt_classes = [int(annos[\"category_id\"]) for annos in annos]\n\n    # Create a new field \"gt_masks\"\n    # TODO: create a `gt_masks` field\n    # if mask_format == \"polygon\":\n    #     gt_masks = [\n    #         polygons_to_bitmask(annos[\"segmentation\"], image_size)\n    #         for annos in annos\n    #     ]\n    # elif mask_format == \"bitmask\":\n    #     gt_masks = [annos[\"segmentation\"] for annos in annos]\n    # else:\n    #     raise ValueError(\n    #         \"mask_format '{}' is not supported. \"\n    #         \"Supported formats are 'polygon' and 'bitmask'\".format(mask_format)\n    #     )\n    # gt_masks = [np.array(gt_mask) for gt_mask in gt_masks]\n    gt_masks = []\n    for annos in annos:\n        if mask_format == \"polygon\":\n            gt_masks.append(polygons_to_bitmask(annos[\"segmentation\"], image_size))\n        elif mask_format == \"bitmask\":\n            "}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create a new Instances object\n    instances = Instances(image_size)\n\n    # Add the annotations to the object\n    for anno in annos:\n        # Add the bounding box to the object\n        bbox = anno[\"bbox\"]\n        bbox_mode = BoxMode.XYXY_ABS\n        if \"bbox_mode\" in anno:\n            bbox_mode = anno[\"bbox_mode\"]\n        bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n\n        # Add the class label to the object\n        class_id = anno[\"category_id\"] - 1\n        instances.gt_classes = anno[\"iscrowd\"] * -1 + class_id\n\n        # Add the segmentation masks to the object\n        if \"segmentation\" in anno:\n            if mask_format == \"polygon\":\n                # polygons\n                segmentation = anno[\"segmentation\"]\n                if isinstance(segmentation, list):\n                    # COCO-style polygons\n                    segmentation = [\n                        np.asarray(p).reshape(-1, 2) for p in segmentation\n                    ]\n                instances.gt_masks = [\n                    polygons_to_bitmask(p, image_size).astype(\"uint8\")\n                    for p in segmentation\n                ]\n            elif mask_format == \"bitmask\":\n                # BitMasks\n                # TODO: Remove this branch once we're sure the input data is in the expected format\n                # BitMasks\n                if isinstance(anno[\"segmentation\"], list):\n                    # COCO-style polygons\n                    segmentation = anno[\"segmentation\"]\n                    instances.gt_masks = [\n                        polygons_to_bitmask(p, image_size).astype(\"uint8\")\n                        for p in segmentation\n                    ]\n                elif isinstance(anno[\"segmentation\"], dict):\n                    # RLE\n                    mask = mask_util.decode(anno[\"segmentation\"])\n                    instances.gt_masks = [\n                        mask.astype(\"uint8\")\n                    ]  # TODO: should we add a check to ensure the shape is correct?\n                else:\n                    raise ValueError(\n                        \"Cannot transform segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray,\"\n                        \" COCO-"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # 1. Create the base data structure\n    #\n    # The data structure is a class called Instances, which contains a number of fields.\n    # In this case, we'll have gt_boxes, gt_classes, gt_masks, and gt_keypoints.\n    # The gt_boxes and gt_classes fields are already created by the function.\n    # The gt_masks and gt_keypoints fields are created by this function.\n    #\n    # For more information on the data structure, see detectron2/structures/instances.py\n    instances = Instances(image_size)\n\n    # 2. Process the annotations\n    #\n    # We're going to process the annotations in annos one at a time.\n    # We've already created the Instances object, so we'll add the annotations to it.\n    #\n    # For each instance, we're going to create the gt_masks and gt_keypoints fields.\n    # We're also going to make sure that the boxes are in the right format.\n    #\n    # Note that we're only creating the fields for the annotations that are not empty.\n    # We'll use the nonempty() method to filter out the empty annotations.\n    #\n    # For more information on the nonempty() method, see detectron2/structures/boxes.py\n    for anno in annos:\n\n        # 2.1. Create the gt_masks field\n        #\n        # We're going to create the gt_masks field for each annotation.\n        # We'll use the mask_from_rle() method to convert the RLE to a bitmask.\n        #\n        # For more information on the mask_from_rle() method, see detectron2/utils/mask_util.py\n        if \"segmentation\" in anno:\n            gt_mask = mask_util.rle_decode(anno[\"segmentation\"])\n            # gt_mask = mask_util.mask_from_rle(anno[\"segmentation\"])\n            if mask_format == \"bitmask\":\n                instances.gt_masks = gt_mask\n            elif mask_format == \"polygon\":\n                # If the format is \"polygon\", then we'll convert the bitmask to"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # The input is a list of dicts, with one dict for each instance.\n    # The output is a dict of tensors, with one tensor for each image.\n    # The input is a list of dicts, with one dict for each instance.\n    # The output is a dict of tensors, with one tensor for each image.\n    num_instances = len(annos)\n    if num_instances == 0:\n        return Instances(image_size, 0)\n\n    # Get the fields from the first instance\n    # This is the only instance where the keys are guaranteed to exist\n    # (other instances may not have all the keys)\n    ann_fields = set(annos[0].keys())\n    # We only care about the following fields\n    allowed_fields = {\"bbox\", \"bbox_mode\", \"category_id\", \"segmentation\", \"keypoints\"}\n\n    # If the keys in the annotations do not match,\n    # then we don't know what to do\n    # (e.g. if the fields are in a different order)\n    if not ann_fields.issuperset(allowed_fields):\n        raise ValueError(\n            \"annotations must have the following keys: \"\n            + \", \".join(allowed_fields)\n            + \" but the following keys were given: \"\n            + \", \".join(ann_fields)\n        )\n\n    # Create the output Instances object\n    # We initialize the boxes, masks, and keypoints to be empty tensors\n    # with the correct shape\n    gt_boxes = Boxes(\n        torch.zeros(num_instances, 4) if annos[0][\"bbox_mode\"] == BoxMode.XYXY_ABS else torch.zeros(num_instances, 4)\n    )\n    gt_classes = torch.zeros(num_instances, dtype=torch.int64)\n    gt_masks = torch.empty((num_instances, *image_size), dtype=torch.uint8)\n    gt_keypoints = torch.zeros((num_instances, 3))\n    # Initialize the fields in the output Instances object\n    output_instances = Instances(image_size, gt_boxes, gt_classes)\n\n    # Add the fields to the output"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path(os.environ.get(\"SKFOLIO_DATA\", \"~/skfolio_data\"))\n    if not data_home.is_dir():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(\"~\") + \"/skfolio_data\"\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(\n            os.path.join(os.path.expandvars(\"~/.skfolio_data\"), \"data\")\n        )\n    elif isinstance(data_home, str):\n        data_home = os.path.expanduser(data_home)\n    else:\n        data_home = str(data_home)\n    if not os.path.isdir(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        try:\n            data_home = os.environ[\"SKFOLIO_DATA\"]\n        except KeyError:\n            data_home = os.path.join(os.path.expanduser(\"~\"), \"skfolio_data\")\n\n    if not os.path.exists(data_home):\n        os.mkdir(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path(os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"))\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is not None:\n        data_home = Path(data_home)\n        if data_home.is_dir():\n            return str(data_home)\n        raise ValueError(\n            \"The provided path is not a directory: {}\".format(data_home)\n        )\n\n    data_home = os.path.expanduser(\"~/.skfolio_data\")\n    if not os.path.isdir(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.expanduser(os.path.join(\"~\", \"skfolio_data\"))\n\n    if not os.path.isdir(data_home):\n        os.mkdir(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", None)\n    if data_home is None:\n        data_home = Path.home() / \"skfolio_data\"\n    data_home = Path(data_home)\n    data_home.mkdir(exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is not None:\n        data_home = Path(data_home)\n        if data_home.is_dir():\n            return str(data_home)\n\n    data_home = os.getenv(\"SKFOLIO_DATA\")\n    if data_home is not None:\n        data_home = Path(data_home)\n        if data_home.is_dir():\n            return str(data_home)\n\n    home = Path.home()\n    return str(home / \"skfolio_data\")\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    # Check if data_home is a path-like object\n    if isinstance(data_home, Path):\n        data_home = str(data_home)\n    elif data_home is None:\n        data_home = os.path.join(\n            os.path.expanduser(\"~\"), \"skfolio_data\"\n        )\n\n    # Check if the directory exists and create it if not\n    if not os.path.isdir(data_home):\n        os.mkdir(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        home = str(Path.home())\n        data_home = os.getenv(\"SKFOLIO_DATA\", home + \"/skfolio_data\")\n\n    if not os.path.isdir(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path(os.environ.get(\"SKFOLIO_DATA\", \"~/skfolio_data\"))\n    data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is not None:\n        data_home = Path(data_home)\n        if data_home.is_absolute():\n            data_home = str(data_home)\n        if data_home.is_dir():\n            return data_home\n    data_home = os.environ.get(\"SKFOLIO_DATA\")\n    if data_home is not None:\n        data_home = Path(data_home)\n    else:\n        home = os.path.expanduser(\"~\")\n        data_home = os.path.join(home, \"skfolio_data\")\n    data_home = Path(data_home)\n    if not data_home.is_dir():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is not None:\n        data_home = Path(data_home)\n    else:\n        data_home = Path(os.environ.get(\"SKFOLIO_DATA\", os.path.expanduser(\"~/skfolio_data\")))\n\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.path.join(\n            os.path.expanduser(\"~\"), \"skfolio_data\"\n        )\n\n    data_home = Path(data_home)\n\n    # Ensure the directory exists\n    if not data_home.is_dir():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = Path(os.environ.get(\"SKFOLIO_DATA\", \"~/skfolio_data\"))\n    if not data_home.is_absolute():\n        data_home = Path.home() / data_home\n    data_home = data_home.expanduser()\n    data_home.mkdir(exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        if \"SKFOLIO_DATA\" in os.environ:\n            data_home = os.environ[\"SKFOLIO_DATA\"]\n        else:\n            data_home = os.path.join(os.path.expanduser(\"~\"), \"skfolio_data\")\n\n    if not os.path.isdir(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", None)\n    if data_home is None:\n        home_dir = os.path.join(os.path.expanduser(\"~\"), \"skfolio_data\")\n    else:\n        home_dir = str(data_home)\n    if not os.path.exists(home_dir):\n        os.mkdir(home_dir)\n    return home_dir\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is not None:\n        if not data_home.exists():\n            raise ValueError(\n                f\"The path {data_home} does not exist. \"\n                \"You can either set the SKFOLIO_DATA environment variable to a valid path or \"\n                \"specify a valid path to the data_home argument.\"\n            )\n\n        return str(data_home)\n\n    data_home = os.environ.get(\"SKFOLIO_DATA\", str(Path.home() / \"skfolio_data\"))\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", None)\n    if data_home is None:\n        data_home = os.path.expanduser(\"~/.skfolio_data\")\n    return Path(data_home)\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a covariance matrix\n    assert cov.ndim == 2\n    assert cov.shape[0] == cov.shape[1]\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix to a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    cov = np.asarray(cov)\n    assert cov.ndim == 2\n    n = cov.shape[0]\n    assert cov.shape == (n, n)\n    corr = np.zeros(cov.shape)\n    for i in range(n):\n        for j in range(n):\n            corr[i, j] = cov[i, j] / (\n                np.sqrt(cov[i, i] * cov[j, j])\n            )\n    return corr, np.sqrt(np.diag(cov))\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    cov = np.asarray(cov)\n    assert cov.ndim == 2\n    assert cov.shape[1] == cov.shape[0]\n    cov = cov / np.diag(cov)\n    return cov, np.sqrt(np.diag(cov))\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    cov_diag = cov.diagonal()\n    return cov / cov_diag[:, np.newaxis]\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check input\n    assert_is_square(cov)\n    assert_is_positive_definite(cov)\n\n    # Calculate the standard deviations\n    std = np.sqrt(np.diagonal(cov))\n    # Normalize the covariance matrix\n    corr = cov / cov.T\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    assert cov.ndim == 2\n\n    cov_diag = np.diag(cov)\n    std_var = np.sqrt(cov_diag)\n    corr = cov / cov_diag[:, None]\n\n    return corr, std_var\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # TODO: Make sure cov is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array\")\n\n    # TODO: Make sure cov is a covariance matrix\n    if not is_positive_definite(cov):\n        raise ValueError(\"The covariance matrix must be positive definite\")\n\n    # TODO: Calculate the standard deviations\n    sd = np.sqrt(np.diag(cov))\n\n    # TODO: Calculate the correlation matrix\n    corr = cov / sd[:, np.newaxis]\n\n    return corr, sd\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert cov.ndim == 2\n    assert is_positive_definite(cov)\n    assert_is_symmetric(cov)\n    return corr_to_cov(cov, cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    cov = cov.astype(np.float64)\n    corr = cov / np.outer(np.sqrt(cov.diagonal()), np.sqrt(cov.diagonal()))\n    return corr, np.sqrt(np.diag(cov))\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert cov.ndim == 2, \"covariance matrix must be 2D\"\n    assert_is_symmetric(cov)\n    n = cov.shape[0]\n    if np.all(np.isfinite(cov)):\n        std = np.sqrt(np.diag(cov))\n    else:\n        std = np.sqrt(np.diag(cov))\n    return cov / np.outer(std, std), std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert is_positive_definite(cov), \"Input matrix must be positive definite\"\n\n    n = cov.shape[0]\n\n    # Get the standard deviation for each variable\n    std_dev = np.linalg.sqrt(np.diag(cov))\n\n    # Get the correlation matrix\n    corr = cov / np.outer(std_dev, std_dev)\n\n    return corr, std_dev\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    assert_is_positive_definite(cov)\n\n    # Covariance matrix to correlation matrix\n    corr = np.corrcoef(cov)\n    # Correlation matrix to standard deviations\n    std_dev = np.sqrt(np.diag(cov))\n    return corr, std_dev\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    cov = np.asfortranarray(cov)\n    assert_is_square(cov)\n    assert_is_positive_definite(cov)\n\n    n_observations, n_features = cov.shape\n    if n_observations > 1:\n        # cov = cov / n_observations\n        std_dev = np.sqrt(np.diag(cov))\n        corr = cov / np.outer(std_dev, std_dev)\n    else:\n        # cov = cov / n_features\n        std_dev = cov[0]\n        corr = cov\n    return corr, std_dev\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    cov_inv = np.linalg.inv(cov)\n    corr = cov_inv @ cov\n    std_dev = np.sqrt(np.diag(cov))\n\n    return corr, std_dev\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert cov.ndim == 2\n\n    cov = np.asfortranarray(cov, order=\"F\")\n\n    # Cov to corr\n    corr = np.divide(cov, cov.diagonal().reshape(-1, 1))\n\n    # Cov to std\n    std = np.sqrt(np.diagonal(cov))\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert cov.ndim == 2\n    cov = np.asarray(cov)\n    assert_is_symmetric(cov)\n\n    return corr_to_cov(cov, cov.diagonal().reshape(-1, 1))\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    assert cov.ndim == 2\n    # Ensure the matrix is positive definite\n    assert is_positive_definite(cov)\n    # Calculate the standard deviations\n    std = np.sqrt(np.diag(cov))\n    # Ensure the diagonal elements are positive\n    assert np.all(std > 0)\n    # Ensure the covariance matrix is symmetric\n    assert np.allclose(cov, cov.T, atol=1e-7)\n    # Calculate the correlation matrix\n    corr = cov / (cov.T * std[:, None])\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    cov = np.asfortranarray(cov)\n    assert_is_square(cov)\n    n = cov.shape[0]\n    std = np.sqrt(np.diag(cov))\n    if np.any(std == 0):\n        raise ValueError(\n            \"The covariance matrix must not have any zero standard deviations\"\n        )\n    return cov / np.outer(std, std), std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # check input\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # get the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # convert covariance to correlation\n    corr = cov / (std * std[:, np.newaxis])\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert is_positive_definite(cov)\n    assert cov.ndim == 2\n\n    return (np.corrcoef(cov), np.std(cov, axis=0))\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _set_training_mode(module):\n        if hasattr(module, \"training\"):\n            setattr(module, \"training\", False)\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(_set_training_mode) for _ in model.modules()]\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # copy first to avoid editing annotations of base class\n    annotations = deepcopy(model.__annotations__)\n\n    def _freeze_training_mode(m):\n        m.training = torch.jit.Final[bool]\n        if hasattr(m, \"__annotations__\"):\n            # copy first to avoid editing annotations of base class\n            m.__annotations__ = deepcopy(m.__annotations__)\n            m.__annotations__[\"training\"] = torch.jit.Final[bool]\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(_freeze_training_mode) for m in model.modules()]\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    with ExitStack() as stack:\n        original_training_modes = {}\n        for name, m in model.named_modules():\n            original_training_modes[name] = m.training\n        training_mode_patch = stack.enter_context(\n            mock.patch.object(m, \"training\", new_callable=lambda: True)\n        )\n        yield\n        for name, m in model.named_modules():\n            m.training = original_training_modes[name]\n            del original_training_modes[name]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: this is a workaround, because detectron2.nn.freeze_module() is not scriptable\n    # TODO: also, detectron2.freeze_module() does not support instancenames\n    # TODO: detectron2.freeze_module() does not support instancenames\n\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_module() should be scriptable\n    # TODO: detectron2.freeze_module() should support instancenames\n\n    # TODO: detectron2.freeze_module() should support instancenames\n    # TODO: detectron2.freeze_"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def prepare_scriptable(self):\n        \"\"\"\n        This function modifies the class definition of a given model to annotate the \"training\" attribute as a constant. This function is used within the context manager to ensure that the \"training\" attribute is annotated as a constant for the duration of the context.\n        Input-Output Arguments\n        :param self: The model whose class definition is to be modified.\n        :return: No return values. This function operates by side effects, modifying the class definition of the model.\n        \"\"\"\n        self.training = torch.jit.annotate(bool, self.training)\n\n    for module_name, module in model.named_modules():\n        if hasattr(module, \"__prepare_scriptable__\"):\n            module.__prepare_scriptable__.side_effect = prepare_scriptable\n        if module.__class__.__prepare_scriptable__:\n            module.__class__.__prepare_scriptable__.side_effect = prepare_scriptable\n\n    yield\n\n    for module_name, module in model.named_modules():\n        if hasattr(module, \"__prepare_scriptable__\"):\n            del module.__prepare_scriptable__\n        if module.__class__.__prepare_scriptable__:\n            del module.__class__.__prepare_scriptable__"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: this is a temporary fix for detectron2.\n    # We should use a more general solution for detectron2.\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back\n    # TODO: use detectron2.utils.state_dict_to_module to convert back"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: support list of models\n    assert isinstance(model, nn.Module)\n\n    # TODO: support more types of training mode\n    training_mode = model.training\n\n    # set all submodules to training mode\n    def set_training(m):\n        if hasattr(m, \"training\"):\n            m.training = training_mode\n\n    model.apply(set_training)\n\n    # set training mode for the model itself\n    model.training = training_mode\n\n    try:\n        yield\n    finally:\n        # reset training mode for all submodules\n        model.apply(set_training)\n\n        # reset training mode for the model itself\n        model.training = training_mode"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        \"\"\"\n        This function takes a detectron2 module and sets its \"training\" attribute to a constant value.\n        :param module: The detectron2 module whose \"training\" attribute is to be set to a constant.\n        :return: No return values. This function operates by side effects, modifying the module's class definition.\n        \"\"\"\n        # TODO: we could use the __prepare_scriptable__ method, but it is not supported by detectron2.\n        # TODO: we could use the __prepare_scriptable__ method, but it is not supported by detectron2.\n        if not hasattr(module, \"_is_training\"):\n            return\n\n        # TODO: this is a hacky workaround for detectron2\n        # detectron2.utils.collect_trainable_layers()\n        # relies on the \"training\" attribute\n        # TODO: detectron2.utils.collect_trainable_layers()\n        # relies on the \"training\" attribute\n        module._is_training = True\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(mock.patch(m.__name__, side_effect=lambda m: _freeze_training_mode(m)))\n        for m in model.modules()]\n        yield\n        for m in model.modules():\n            delattr(m, \"_is_training\")"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: remove this function once detectron2.utils.freeze_module_params is deprecated\n    freeze_training_mode_ = _freeze_training_mode\n    freeze_training_mode_._module_training_mode_cache = {}\n    try:\n        yield\n    finally:\n        freeze_training_mode_.restore_module_training_mode(model)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # NOTE: This function is only used for tracing, and is not supposed to have side-effects.\n    # So it should not be used in eager mode.\n    # It is not necessary to call this function in tracing mode, because\n    # detectron2's tracing does not use the training attribute.\n\n    # create a new class for every module\n    def _freeze_training_mode(m):\n        if hasattr(m, \"training\") and not isinstance(m, torch.jit.RecursiveFrozenModule):\n            class NewClass(m.__class__, torch.jit.RecursiveFrozenModule):\n                def __init__(self, *args, **kwargs):\n                    super().__init__()\n                    self.training = m.training\n\n            m.__class__ = NewClass\n\n    # apply the new class to every module in the model\n    for m in model.modules():\n        _freeze_training_mode(m)\n    yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: support more cases\n    # TODO: make it more efficient\n\n    def _set_training_mode(m):\n        if not hasattr(m, \"training\"):\n            return\n        if hasattr(m, \"__annotations__\"):\n            m.__annotations__[\"training\"] = torch.jit.Final[bool]\n            m.__annotations__[\"training\"] = model.training\n            return\n        if hasattr(m, \"__torch_script_class__\"):\n            # TODO: support more cases\n            return\n\n        m.training = model.training\n\n    with ExitStack() as stack:\n        stack.push(model.training)\n        model.training = True\n        for m in model.modules():\n            _set_training_mode(m)\n        yield\n        model.training = stack.pop()\n\n    # clear annotations\n    if hasattr(model, \"__annotations__\"):\n        for k, v in model.__annotations__.items():\n            if isinstance(v, torch.jit.Final):\n                del model.__annotations__[k]\n\n    for m in model.modules():\n        _set_training_mode(m)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # This function is used to freeze the training flag of a model for the purpose of JIT compilation.\n    # The training flag is a dynamic variable in PyTorch and thus is not supported by JIT.\n    # This function will modify the class definition of the model's submodules so that the training flag is annotated as a constant.\n    # This will allow the model to be compiled by JIT.\n    # It will also ensure that the original class definitions are restored after the context is exited.\n\n    # First, we need to get a list of all submodules in the model.\n    # We will iterate through these modules and modify their class definitions.\n    # We will use the list to ensure that the original class definitions are restored after the context is exited.\n    submodules = []\n    for m in model.modules():\n        if isinstance(m, nn.Module):\n            submodules.append(m)\n\n    # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n    with ExitStack() as stack:\n        # We will use the context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use a context manager to ensure that the original class definitions are restored after the context is exited.\n        # We will use"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # This is a workaround for https://github.com/pytorch/pytorch/issues/28603\n    # It is not necessary when tracing detectron2 models.\n    # It is also not necessary when tracing detectron2 models that don't have\n    # detectron2.roi_heads.StandardROIHeads as a submodule.\n    # This is because detectron2.roi_heads.StandardROIHeads is the only detectron2\n    # module that has a training attribute that is not a constant.\n    if not hasattr(model, \"training\"):\n        yield\n        return\n\n    with patch_builtin_len(modules=model.modules):\n        with patch_builtin_len(modules=[\"detectron2.roi_heads.StandardROIHeads\"]):\n\n            def _freeze_training_mode_of(module):\n                if hasattr(module, \"training\"):\n                    setattr(module, \"training\", torch.jit.Final[bool](module.training))\n\n            with ExitStack() as stack:\n                ctxs = [stack.enter_context(freeze_training_mode_of(m)) for m in model.modules()]\n                yield\n                for m in ctxs:\n                    m.stop_recording()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Note that the training attribute is used to determine whether to use the\n    # fast- or slow-path in detectron2.utils.box_list.\n    # TODO: refactor detectron2.utils.box_list to avoid this.\n\n    # save the original values\n    # TODO: this should be a dictionary instead of a list,\n    # but it's too late to change that now\n    original_values = []\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            original_values.append(module.training)\n\n    # set the values to a constant\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            setattr(module, \"training\", True)\n\n    # set the value of the training attribute to False for detectron2.utils.box_list\n    from detectron2.utils import box_list\n\n    box_list.training = False\n    yield\n    # revert the changes\n    for name, module, original_value in zip(model.state_dict().keys(), model.state_dict().values(), original_values):\n        setattr(module, \"training\", original_value)\n\n    # set the value of the training attribute to True for detectron2.utils.box_list\n    box_list.training = True\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # This is a workaround for https://github.com/pytorch/pytorch/issues/23984\n    # and https://github.com/pytorch/pytorch/issues/35911\n    # In short, PyTorch currently does not support tracing\n    # a model that has an attribute `training` that is not a constant.\n    # This function temporarily sets the `training` attribute\n    # to a constant value, allowing the model to be traced.\n    # This is useful for JIT compilation of models that\n    # are used in both training and inference.\n    # Note: this is only a temporary solution.\n    # The real solution is to fix PyTorch.\n\n    # Note that we need to use `setattr` instead of `model.training = False`\n    # because we want to set the value of `model.training` to a constant.\n    # If we use `model.training = False`,\n    # the value of `model.training` will be a constant,\n    # but the value of `model.training` will not be a constant.\n\n    with ExitStack() as stack:\n        stack.enter_context(\n            mock.patch.object(\n                model,\n                \"training\",\n            )\n        )\n\n        stack.enter_context(\n            mock.patch.object(\n                model.training,\n                \"training\",\n            )\n        )\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # The following is a workaround for\n    # https://github.com/pytorch/pytorch/issues/22966\n    # and https://github.com/pytorch/pytorch/issues/24114\n    # TODO: remove this when the issues are fixed.\n    if not hasattr(model, \"_modules\"):\n        # This is a leaf module.\n        # The training attribute will be set to a constant\n        # by torchscript.\n        model._is_training = torch.jit.annotate(torch.jit.Final[bool], model.training)\n        yield\n        return\n\n    # This is a module with submodules.\n    # We need to recursively set the training attribute of\n    # all submodules to a constant.\n    # We do it by copying the model to a new module,\n    # and then using the new module to replace the original.\n    # This allows the new module to be scripted,\n    # while preserving the original module's state_dict.\n    new_model = deepcopy(model)\n    for name, module in new_model.named_modules():\n        if hasattr(module, \"_modules\"):\n            setattr(module, \"_is_training\", torch.jit.annotate(torch.jit.Final[bool], module.training))\n\n    # replace the model with the new one\n    # This allows the new module to be scripted,\n    # while preserving the original module's state_dict.\n    yield model"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/12816\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/25490\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/30581\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/31076\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/31842\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/32633\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/34595\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/37238\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/37621\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/37846\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/39528\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/40071\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/40515\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/40859\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/41193\n    # This is a workaround for Pytorch's bug: https://github.com/pytorch/pytorch/issues/41607\n    # This"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # We need to use a context manager to ensure that these changes are\n    # reverted back to their original state after the context manager exits.\n    # This is necessary because we cannot modify the class definition of a\n    # module once it has been instantiated.\n    #\n    # We use a custom context manager instead of using the contextlib.ExitStack\n    # because we want to modify the class definitions of the model's submodules\n    # within the context, and the ExitStack does not allow this.\n\n    # We use a custom context manager to ensure that the original class definitions\n    # of the model's submodules are restored after the context manager exits.\n    # This is necessary because we cannot modify the class definitions of a module\n    # once it has been instantiated.\n\n    # This context manager is a decorator that modifies the class definition of a\n    # module, setting the \"training\" attribute to a constant value.\n    # It uses the \"setattr\" method to set the \"training\" attribute of the\n    # module to a constant value, and it uses the \"set_training_mode\" method to\n    # set the training mode of the module to the same value.\n\n    with ExitStack() as stack:\n        # We use a custom context manager to ensure that the original class definitions\n        # of the model's submodules are restored after the context manager exits.\n        # This is necessary because we cannot modify the class definitions of a module\n        # once it has been instantiated.\n        stack.enter_context(\n            _patch_training_mode(model, torch.jit.is_tracing)\n        )\n        yield\n    # We restore the original class definitions of the model's submodules.\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(m):\n        if not hasattr(m, \"training\"):\n            return\n        m.training = True\n\n    with ExitStack() as stack:\n        ctx = stack.enter_context(torch.jit.freeze_module(model))\n        stack.enter_context(_freeze_training_mode)\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    if not isinstance(model, nn.Module):\n        raise ValueError(\"model must be an instance of detectron2.nn.Module\")\n\n    def _freeze_training_mode(m):\n        if not hasattr(m, \"training\"):\n            return\n        setattr(m, \"training\", False)\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(_freeze_training_mode) for m in model.modules()]\n        yield\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 match.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n\n        if not values[field1].shape == values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if not (values[field1].shape == values[field2].shape).all():\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of the two fields match.\n\n        Args:\n            cls (type): Class type.\n            values (Dict[str, Any]): Values to check.\n        \"\"\"\n        if len(values[field1].shape) != len(values[field2].shape):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        for i in range(len(values[field1].shape)):\n            if values[field1].shape[i] != values[field2].shape[i]:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                    f\"resp. {values[field1].shape} and {values[field2].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of two fields match.\"\"\"\n        if len(values[field1].shape) != len(values[field2].shape):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        for i in range(len(values[field1].shape)):\n            if values[field1].shape[i] != values[field2].shape[i]:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                    f\"resp. {values[field1].shape} and {values[field2].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if shapes of field1 and field2 match.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: Shapes of {field1} and {field2} do not match, \"\n                f\"expected {values[field1].shape} got {values[field2].shape}\"\n            )\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(f\"{cls.__name__}: Shapes mismatch for fields {field1} and {field2}.\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n\n        if (\n            not isinstance(values[field1], np.ndarray)\n            or not isinstance(values[field2], np.ndarray)\n            or values[field1].shape != values[field2].shape\n        ):\n            raise ValueError(\n                f\"{cls.__name__}: The shapes of {field1} and {field2} do not match. \"\n                f\"Received {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        This function checks if the shapes of the two fields are equal. If they are not, it raises a ValueError indicating the mismatch.\n        :param cls: The class of the Pydantic model that is being validated.\n        :param values: The values of the Pydantic model that are being validated.\n        :return: The values of the Pydantic model with the fields field1 and field2 having the same shape.\n        \"\"\"\n\n        if len(values[field1].shape) != len(values[field2].shape):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} must have the same shape, \"\n                f\"but got {values[field1].shape} and {values[field2].shape}.\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of two fields match.\"\"\"\n        if len(values[field1].shape) != len(values[field2].shape):\n            raise ValueError(\n                f\"{cls.__name__}: Shapes mismatch between {field1} and {field2}. \"\n                f\"{field1} shape: {values[field1].shape}, {field2} shape: {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of the two fields match.\n\n        Raises:\n            ValueError: if the shapes of the two fields do not match.\n        \"\"\"\n        if len(values[field1].shape) != len(values[field2].shape):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} must have the same shape, \"\n                f\"but got {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} have incompatible shapes, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(f\"{cls.__name__}: shapes mismatch for {field1} and {field2}, \" f\"got {values[field1].shape} and {values[field2].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of the two fields are the same.\n\n        Args:\n            cls (type): Class type.\n            values (Dict[str, Any]): Value to check.\n\n        Raises:\n            ValueError: Exception raised if shapes don't match.\n\n        Returns:\n            Dict[str, Any]: `v` sent for further processing.\n        \"\"\"\n        if np.array(values[field1]).shape != np.array(values[field2]).shape:\n            raise ValueError(\n                f\"{cls.__name__}: Shapes of {field1} and {field2} mismatch, \"\n                f\"resp. {np.array(values[field1]).shape} and {np.array(values[field2]).shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # if the input is a list of strings, we pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistimately pessimistically pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessi"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list of strings\n    if isinstance(metrics, list) and all(isinstance(metric, str) for metric in metrics):\n        # If metrics is a list of strings, we can pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistimately pessimistically pessimistically pessimistimately pessimistically pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if all(isinstance(m, str) for m in metrics):\n            metrics = [(m, {}) for m in metrics]\n        elif all(isinstance(m, dict) for m in metrics):\n            metrics = deepcopy(metrics)\n        else:\n            raise Exception(\n                \"Input metrics must be a list of either strings or dictionaries\"\n            )\n    return metrics\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # if the input is a list of strings, we assume that it contains metric names and convert it to a list of dictionaries\n    if isinstance(metrics, list) and isinstance(metrics[0], str):\n        metrics = [\n            {\n                \"name\": metric\n            }\n            for metric in metrics\n        ]\n\n    # if the input is a list of dictionaries, we assume that it contains metric names and parameters and we extract them\n    elif isinstance(metrics, list) and isinstance(metrics[0], dict):\n        metrics = [\n            {\n                \"name\": metric[\"name\"]\n            } for metric in metrics\n        ]\n\n    # if the input is not a list, we assume that it is a single metric name and we convert it to a dictionary\n    elif isinstance(metrics, str):\n        metrics = [\n            {\n                \"name\": metrics\n            }\n        ]\n\n    # if the input is not a list or a string, we pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        metrics = [metrics]\n\n    metrics_names = []\n    metrics_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_names.append(metric)\n        elif isinstance(metric, dict):\n            metrics_params.append(deepcopy(metric))\n        else:\n            raise TypeError(\n                f\"Metric {metric} is not a string or a dictionary.\"\n            )\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        metrics = []\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            return list(map(lambda m: m[\"name\"], metrics)), list(map(lambda m: deepcopy(m), metrics))\n        else:\n            return metrics, []\n\n    if isinstance(metrics, dict):\n        return [metrics[\"name\"]], [deepcopy(metrics)]\n    else:\n        return [metrics], []\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Input validation\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{\"name\": metric} for metric in metrics]\n        elif isinstance(metrics[0], dict):\n            if \"name\" in metrics[0]:\n                pass\n            else:\n                raise ValueError(\n                    \"Inconsistent input: Metric names must be specified as strings.\"\n                )\n        else:\n            raise ValueError(\n                \"Inconsistent input: Metric names must be specified as strings.\"\n            )\n    else:\n        raise ValueError(\n            \"Inconsistent input: Metric names must be specified as a list.\"\n        )\n\n    # Extract metric names and parameters\n    metric_names = [metric[\"name\"] for metric in metrics]\n    metric_params = deepcopy(metrics)\n\n    # Transform parameter names\n    for metric in metric_params:\n        metric[\"name\"] = metric[\"name\"].lower()\n        metric[\"name\"] = embedding_models.camel_to_snake_case(metric[\"name\"])\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        return [], []\n\n    if isinstance(metrics, dict):\n        metrics = [metrics]\n\n    metrics_names = []\n    metrics_parameters = []\n\n    for metric in metrics:\n        if isinstance(metric, dict):\n            metrics_parameters.append(metric)\n            metrics_names.append(metric['name'])\n        else:\n            metrics_names.append(metric)\n\n    return metrics_names, metrics_parameters\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        metrics = [metrics]\n\n    # Check if the metric is a dictionary\n    if any(isinstance(metric, dict) for metric in metrics):\n        # Get the metric names\n        metrics_names = [metric[\"name\"] for metric in metrics]\n\n        # Get the metric parameters\n        metrics_params = [metric[\"params\"] for metric in metrics]\n    else:\n        # If the metric is not a dictionary, it is assumed to be a string\n        metrics_names = metrics\n        metrics_params = []\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        metrics = deepcopy(metrics)\n        for i in range(len(metrics)):\n            if isinstance(metrics[i], dict):\n                metrics[i] = metrics[i].keys()\n            else:\n                metrics[i] = [metrics[i]]\n\n    if isinstance(metrics, str):\n        metrics = [metrics]\n    elif not isinstance(metrics, list):\n        raise ValueError('metrics must be a list or a string')\n\n    metrics = [metric.lower() for metric in metrics]\n\n    metric_params = []\n    for metric in metrics:\n\n        if metric == 'accuracy':\n            metric_params.append({\n                'name': metric,\n                'type': 'accuracy',\n            })\n        elif metric == 'precision':\n            metric_params.append({\n                'name': metric,\n                'type': 'precision',\n            })\n        elif metric == 'recall':\n            metric_params.append({\n                'name': metric,\n                'type': 'recall',\n            })\n        elif metric == 'f1':\n            metric_params.append({\n                'name': metric,\n                'type': 'f1',\n            })\n        elif metric == 'mse':\n            metric_params.append({\n                'name': metric,\n                'type': 'mse',\n            })\n        elif metric == 'mae':\n            metric_params.append({\n                'name': metric,\n                'type': 'mae',\n            })\n        elif metric == 'rmse':\n            metric_params.append({\n                'name': metric,\n                'type': 'rmse',\n            })\n        elif metric == 'r2':\n            metric_params.append({\n                'name': metric,\n                'type': 'r2',\n            })\n        elif metric == 'auc':\n            metric_params.append({\n                'name': metric,\n                'type': 'auc',\n            })\n        elif metric == 'auprc':\n            metric_params.append({\n                'name': metric,\n                'type': 'auprc',\n            })\n        elif metric == 'brier_score':\n            metric_params.append"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{\"name\": m} for m in metrics]\n        elif isinstance(metrics[0], dict):\n            pass\n        else:\n            raise ValueError(\"metrics must be a list of strings or dictionaries\")\n\n    metric_names = [m[\"name\"] for m in metrics]\n    metric_params = [m for m in metrics]\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list) and not isinstance(metrics[0], dict):\n        return metrics, [{\"name\": metric} for metric in metrics]\n\n    if isinstance(metrics, list) and isinstance(metrics[0], dict):\n        return [metric[\"name\"] for metric in metrics], metrics\n\n    if isinstance(metrics, dict):\n        return [metrics[\"name\"]], [metrics]\n\n    return [], []\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if metrics is None:\n        return [], []\n    if isinstance(metrics, dict):\n        return [list(metrics.keys()), list(metrics.values())]\n\n    if isinstance(metrics, list):\n        return [metrics, []]\n\n    return [], []\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # if metrics is a list of strings\n    if isinstance(metrics, list) and all(isinstance(m, str) for m in metrics):\n        metrics_names = metrics\n        metrics_params = []\n    # if metrics is a list of dictionaries\n    elif isinstance(metrics, list) and all(isinstance(m, dict) for m in metrics):\n        metrics_names = [m['name'] for m in metrics]\n        metrics_params = metrics\n    # if metrics is a dictionary\n    elif isinstance(metrics, dict):\n        metrics_names = [metrics['name']]\n        metrics_params = [metrics]\n    # if metrics is not a list or a dictionary\n    else:\n        raise ValueError('The metrics argument must be a list or a dictionary.')\n\n    # check if the metric names are valid\n    for metric_name in metrics_names:\n        if metric_name not in embedding_models.METRIC_NAMES:\n            raise ValueError(f'The metric name \"{metric_name}\" is not a valid metric.')\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_names = deepcopy(metrics)\n    metrics_params = deepcopy(metrics)\n    for i, metric in enumerate(metrics_params):\n        if isinstance(metric, str):\n            metrics_names[i] = metric\n            metrics_params[i] = {}\n        elif isinstance(metric, dict):\n            if 'name' not in metric:\n                raise ValueError('Metric {} is not formatted correctly. It is missing the key \\'name\\'.'.format(metric))\n            if 'params' not in metric:\n                raise ValueError('Metric {} is not formatted correctly. It is missing the key \\'params\\''.format(metric))\n            metrics_names[i] = metric['name']\n            metrics_params[i] = metric['params']\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics = deepcopy(metrics)\n\n    if not isinstance(metrics, list):\n        metrics = [metrics]\n\n    if not isinstance(metrics[0], dict):\n        metrics = [{'name': metric} for metric in metrics]\n\n    return [metric['name'] for metric in metrics], [metric for metric in metrics]\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # TODO: Add a description of the function's purpose\n    # TODO: Document the input and output arguments\n    # TODO: Provide a usage example\n    if isinstance(metrics, str):\n        return [metrics], [{}]\n    elif isinstance(metrics, dict):\n        return [metrics.get(\"name\")], [metrics]\n    elif isinstance(metrics, list):\n        if all(isinstance(metric, str) for metric in metrics):\n            return metrics, [{}]\n        elif all(isinstance(metric, dict) for metric in metrics):\n            return [metric.get(\"name\") for metric in metrics], [metric for metric in metrics]\n        else:\n            raise ValueError(f\"Expected list of strings or dictionaries, got {type(metrics)}\")\n    else:\n        raise ValueError(f\"Expected list of strings or dictionaries, got {type(metrics)}\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        raise TypeError(\"metrics must be a list\")\n\n    # If the metrics are strings, they are transformed into a list of dictionaries\n    if all(isinstance(metric, str) for metric in metrics):\n        metrics_names = metrics\n        metrics_parameters = [{} for _ in metrics]\n\n        # If the metrics are dictionaries, their names and parameters are extracted\n    elif all(isinstance(metric, dict) for metric in metrics):\n        metrics_names = [metric[\"name\"] for metric in metrics]\n        metrics_parameters = metrics\n\n        # If the metrics are a mix of strings and dictionaries, the strings are transformed into dictionaries\n    else:\n        metrics_names = [metric for metric in metrics if isinstance(metric, str)]\n        metrics_parameters = [{} for _ in metrics]\n        for metric_name, metric_parameters in zip(metrics_names, metrics):\n            for key in metric_parameters:\n                metrics_parameters[metrics_names.index(metric_name)][key] = metric_parameters[key]\n\n    return metrics_names, metrics_parameters\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        metrics = deepcopy(metrics)\n        if all(isinstance(m, str) for m in metrics):\n            return metrics, []\n        if all(isinstance(m, dict) for m in metrics):\n            return [], metrics\n\n    if isinstance(metrics, dict):\n        metrics = deepcopy(metrics)\n        if 'name' in metrics and isinstance(metrics['name'], str):\n            return [metrics['name']], [metrics]\n        else:\n            raise TypeError('metrics must be a dictionary with a \"name\" key')\n    raise TypeError('metrics must be a list of strings or dictionaries')\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if metrics is a list of strings\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            # If metrics is a list of strings, return the list of metric names and empty dictionaries for the parameters\n            return metrics, [{} for _ in metrics]\n        elif isinstance(metrics[0], dict):\n            # If metrics is a list of dictionaries, extract the metric names and return them as a list\n            metrics = [metric['name'] for metric in metrics]\n            # Extract the parameters from the dictionaries\n            params = [metric for metric in metrics]\n            return metrics, params\n    else:\n        raise TypeError(\"metrics must be a list\")\n\n    # If metrics is not a list, return an empty list for the names and an empty dictionary for the parameters\n    return [], {}\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = geopoly.inverses[fn]\n  else:\n    fn_inv = fn_inv\n\n  # Compute the Jacobian of fn function at the locations of each mean.\n  jac = jax.vmap(jax.grad(fn), in_axes=-1, out_axes=-1)(jnp.eye(3))\n  # The cube root of the determinant of the Jacobian is the geometric mean\n  # of the eigenvalues of the Jacobian, which gives us the isotropic scaling\n  # implied by `fn` at each mean that `scale` should be multiplied by.\n  d = 3\n  eps = jnp.finfo(jnp.float32).tiny  # Guard against an inf gradient at 0.\n  abs_det = jnp.maximum(eps, jnp.abs(jnp.linalg.det(jac)))\n  fn_scale = jnp.cbrt(abs_det)\n\n  # Compute the Jacobian of fn_inv function at the locations of each mean.\n  jac_inv = jax.vmap(jax.grad(fn_inv), in_axes=-1, out_axes=-1)(jnp.eye(d))\n  abs_det_inv = jnp.maximum(eps, jnp.abs(jnp.linalg.det(jac_inv)))\n  fn_inv_scale = jnp.cbrt(abs_det_inv)\n\n  # The Jacobian of the function that maps from the near plane to the far plane\n  # is the Jacobian of the function that maps from the far plane to the near\n  # plane, scaled by the Jacobian of the function that maps from the near plane\n  # to the far plane.\n  jac_fn_inv_fn = jax.vmap(jax.grad(fn_inv), in_axes=-1, out_axes=-1)(jac)\n\n  # The Jacobian of the function that maps from the near plane to the far plane\n  # is the Jacobian of the function that maps from the far plane to the near\n  # plane, scaled by the Jacobian of the function that maps from the near plane\n  # to the far plane.\n  jac_fn_fn_inv = jax.vmap(jax"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn.__name__ == 'contract':\n      fn_inv = inv_contract\n    elif fn.__name__ == 'contract3_isoscale':\n      fn_inv = lambda x: contract3_isoscale(x)\n    else:\n      raise NotImplementedError(\n          f'No inverse defined for {fn.__name__}.')\n  # Construct the forward mapping from metric to normalized distances.\n  s_to_t = track_isotropic(fn, t_near, t_far - t_near)\n  # Construct the backward mapping from normalized to metric distances.\n  t_to_s = track_isotropic(fn_inv, t_near, t_far - t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if not fn_inv:\n    fn_inv = geopoly.get_inverse(fn)\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    # Contract the input to the near-plane.\n    t = contract(t)\n    # Compute the inverse of the function to get normalized distances.\n    s = fn_inv(t)\n    # Clip the normalized distances to the range [0, 1].\n    s = jnp.clip(s, a_min=0, a_max=1)\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances to metric distances.\"\"\"\n    # Compute the function to get metric distances.\n    t = fn(s)\n    # Clip the metric distances to the range [t_near, t_far].\n    t = jnp.clip(t, a_min=t_near, a_max=t_far)\n    # Expand the distance to the far-plane.\n    t = inv_contract(t)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise ValueError(\n          f'fn {fn} has no inverse defined. Please provide one or use a function that has one defined.')\n\n  t_near = jnp.maximum(t_near, 0)\n  t_far = jnp.maximum(t_far, 0)\n  t_range = jnp.maximum(t_far - t_near, 1)\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    return (t - t_near) / t_range\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances to metric distances.\"\"\"\n    return t_near + s * t_range\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if not isinstance(t_near, (np.ndarray, jnp.ndarray)):\n    raise ValueError('t_near must be a numpy or JAX array.')\n  if not isinstance(t_far, (np.ndarray, jnp.ndarray)):\n    raise ValueError('t_far must be a numpy or JAX array.')\n\n  if t_near.ndim != 1 or t_far.ndim != 1:\n    raise ValueError('t_near and t_far must be 1-D arrays.')\n  if t_near.shape[-1] != t_far.shape[-1]:\n    raise ValueError('t_near and t_far must have the same shape.')\n\n  if fn_inv is None:\n    fn_inv = geopoly.get_inv_fn(fn)\n  else:\n    if not callable(fn_inv):\n      raise ValueError('fn_inv must be callable.')\n\n  if fn_inv(fn(t_near)) is not None:\n    raise ValueError('fn and fn_inv must be inverses of each other.')\n  if fn(fn_inv(t_far)) is not None:\n    raise ValueError('fn and fn_inv must be inverses of each other.')\n\n  if t_far < t_near:\n    raise ValueError('t_far must be greater than t_near.')\n\n  if fn(t_near) < 0 or fn(t_far) > 1:\n    raise ValueError(\n        'fn(t_near) must be non-negative and fn(t_far) must be less than 1.')\n\n  def t_to_s(t):\n    \"\"\"Constructs a function that maps metric distances to normalized distances.\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Constructs a function that maps normalized distances to metric distances.\"\"\"\n    return (s * (fn(t_far) - fn(t_near)) + fn(t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Determine the inverse function if not provided.\n  if fn_inv is None:\n    fn_inv = geopoly.map_inverse(fn)\n  elif not isinstance(fn_inv, (jnp.ndarray, jnp.DeviceArray)):\n    fn_inv = jax.jit(fn_inv)\n\n  # Construct the forward mapping.\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    s = fn(t)\n    s = jnp.where(t < t_near, t_near, s)\n    s = jnp.where(s > t_far, t_far, s)\n    return s\n\n  # Construct the backward mapping.\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(s)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse was provided, try to determine it automatically.\n  if fn_inv is None:\n    fn_inv = geopoly.get_fn_inv(fn)\n  # Ensure the inverse is actually the inverse.\n  fn_inv_fn = jax.vmap(fn_inv, in_axes=-1, out_axes=-1)\n  fn_inv_fn_out = fn_inv_fn(fn(t_near))\n  fn_inv_fn_out_near = jnp.minimum(fn_inv_fn_out, t_near)\n  fn_inv_fn_out_far = jnp.maximum(fn_inv_fn_out, t_far)\n  if (jnp.all(fn_inv_fn_out_near == t_near) and\n      jnp.all(fn_inv_fn_out_far == t_far)):\n    fn_inv = fn_inv_fn\n  else:\n    raise ValueError(\n        'The inverse of `fn` does not seem to be `fn_inv`.')\n\n  # Construct the two functions.\n  t_to_s = lambda t: jnp.where(t < t_near, 0,\n                                jnp.where(t > t_far, 1, (fn(t) - t_near) /\n                                         (t_far - t_near)))\n  s_to_t = lambda s: jnp.where(s < 0, t_near,\n                                jnp.where(s > 1, t_far, fn_inv(s * (t_far - t_near) + t_near)))\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if isinstance(fn, geopoly.Geopoly):\n      fn_inv = fn._inverse\n    elif isinstance(fn, geopoly.Spherical):\n      fn_inv = geopoly.Spherical.from_geopoly(fn)._inverse\n    elif isinstance(fn, geopoly.Cylindrical):\n      fn_inv = geopoly.Cylindrical.from_geopoly(fn)._inverse\n  if not isinstance(fn_inv, Callable):\n    raise ValueError('fn_inv must be a callable.')\n\n  # Construct the mapping from metric distances to normalized distances.\n  t_to_s = track_linearize(\n      fn, t_near, t_far - t_near\n  )\n\n  # Construct the mapping from normalized distances to metric distances.\n  s_to_t = track_linearize(fn_inv, t_near, t_far - t_near)\n\n  # Ensure the functions are invertible.\n  t_to_s_inv, _ = jax.linearize(s_to_t, t_near)\n  s_to_t_inv, _ = jax.linearize(t_to_s, t_near)\n  s_to_t_inv = jax.vmap(s_to_t_inv, in_axes=-1, out_axes=-1)\n  t_to_s_inv = jax.vmap(t_to_s_inv, in_axes=-1, out_axes=-1)\n  assert jnp.allclose(s_to_t_inv(s_to_t(t_near)), t_near\n                      )\n  assert jnp.allclose(t_to_s_inv(t_to_s(s_to_t(t_near))), t_near\n                      )\n  assert jnp.allclose(t_to_s_inv(t_to_s(s_to_t(t_far))), t_far\n                      )\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = geopoly.inverses[fn]\n    if fn_inv is None:\n      raise ValueError(f'No inverse found for {fn}')\n  # We want to map [t_near, t_far] -> [0, 1].\n  # We can do this by mapping [0, 1] -> [t_near, t_far], and then\n  # mapping the result back to [0, 1] with the inverse.\n  # We do this by contracting [t_near, t_far] to [0, 1], and then\n  # mapping [0, 1] -> [0, 1] with the inverse.\n  # The contraction is an invertible function, so the composition is invertible.\n  t_to_s = track_isotropic(fn, t_near, t_far)\n  s_to_t = track_isotropic(fn_inv, 0, 1)\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = _get_inverse(fn)\n\n  t_near = jnp.atleast_1d(t_near)\n  t_far = jnp.atleast_1d(t_far)\n\n  # Compute the distance between near and far planes.\n  t_near_far = jnp.maximum(t_far, t_near)\n\n  # Compute the midpoint between near and far planes.\n  t_mid = (t_near + t_far) / 2.\n\n  # Compute the distance between the near plane and the midpoint.\n  t_near_mid = jnp.maximum(t_mid, t_near)\n\n  # Compute the distance between the midpoint and the far plane.\n  t_mid_far = jnp.maximum(t_mid, t_far)\n\n  # Compute the midpoint of the near-mid and mid-far distances.\n  t_mid_near_far = (t_near_mid + t_mid_far) / 2.\n\n  # Compute the midpoint of the near-far and mid-near-far distances.\n  t_near_far_mid_near_far = (t_near_far + t_mid_near_far) / 2.\n\n  # Compute the inverse of the near-mid-far distance.\n  t_near_mid_far_inv = 1. / (t_near_mid_far)\n\n  # Compute the inverse of the near-far-mid-near-far distance.\n  t_near_far_mid_near_far_inv = 1. / (t_near_far_mid_near_far)\n\n  # Compute the inverse of the midpoint of the near-mid-far distance.\n  t_mid_near_far_inv = 1. / (t_mid_near_far)\n\n  # Compute the inverse of the midpoint of the near-far and mid-near-far distances.\n  t_near_far_inv = 1. / (t_near_far)\n\n  # Compute the inverse of the midpoint of the near-far and near-mid-far distances.\n  t_near_mid_inv ="}
{"namespace": "coord.construct_ray_warps", "completion": "  # TODO(b/230273133): Implement support for arbitrary-dimensional input.\n  if fn_inv is None:\n    if fn == geopoly.contract:\n      fn_inv = geopoly.inv_contract\n    elif fn == geopoly.contract3:\n      fn_inv = geopoly.contract3_isoscale\n    elif fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError(\n          f'No inverse function found for {fn.__name__}.')\n\n  def t_to_s(t):\n    return fn(t - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    return t_near + (s * (t_far - t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if not (isinstance(fn, (jnp.ndarray, jax.vmap, jax.vjp.vjp)):\n    raise ValueError(f'fn must be a callable, not {type(fn)}')\n  if fn_inv is not None and not (isinstance(fn_inv, (jnp.ndarray, jax.vmap, jax.vjp.vjp)):\n    raise ValueError(f'fn_inv must be a callable, not {type(fn_inv)}')\n\n  # Construct the forward mapping from metric distances to normalized distances.\n  if fn_inv is None:\n    fn_inv = _get_inverse_fn(fn)\n  t_to_s = lambda t: (fn(t) - t_near) / (t_far - t_near)\n\n  # Construct the backward mapping from normalized distances to metric distances.\n  s_to_t = lambda s: t_near + s * (t_far - t_near)\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = geopoly.get_fn_inverse(fn)\n\n  # The mapping from distances to [0, 1] is:\n  #   s = (2 * sqrt(t) - 1) / (t_far - t_near)\n  # The inverse mapping is:\n  #   t = (1 - s * (t_far - t_near)) ** 2 / 4 + t_near\n  t_to_s = jnp.divide(\n      2 * jnp.sqrt(t_near) - 1,\n      t_far - t_near,\n      where=t_near > 0)\n  s_to_t = jnp.power((1 - jnp.multiply(t_far, t_near)), 2 / 3) + t_near\n  t_to_s = jax.vmap(t_to_s, in_axes=-1, out_axes=-1)\n  s_to_t = jax.vmap(s_to_t, in_axes=-1, out_axes=-1)\n\n  # The mapping from [0, 1] to distances is:\n  #   t = 1 / (s * s) * (s_far - s_near) + s_near\n  # The inverse mapping is:\n  #   s = (1 + sqrt(1 - 4 * t * (s_far - s_near))) / 2\n  s_to_t_inv = 1 / (jnp.multiply(s_to_t, s_to_t)) * (\n      jnp.maximum(s_far, s_near) - s_to_t) + s_near\n  s_to_t = jax.vmap(s_to_t, in_axes=-1, out_axes=-1)\n  s_to_t_inv = jax.vmap(s_to_t_inv, in_axes=-1, out_axes=-1)\n\n  return t_to_s, s_to_t, s_to_t_inv\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # pylint: disable=too-many-locals\n  if fn_inv is None:\n    if isinstance(fn, geopoly.fn.contract3):\n      fn_inv = geopoly.fn.contract3_inv\n    elif isinstance(fn, geopoly.fn.contract2):\n      fn_inv = geopoly.fn.contract2_inv\n    else:\n      raise ValueError(\n          f'Cannot determine the inverse of the provided function {fn}')\n  # pylint: enable=too-many-locals\n\n  # Compute the range of the function.\n  t_near, t_far = t_near.at[t_near == 0].set_subtensor(0, t_far)\n  t_near, t_far = t_near.at[t_far == 0].set_subtensor(0, t_near)\n\n  # Compute the Jacobian of the function at the near and far points.\n  jac_near, jac_far = jax.vmap(fn_inv, in_axes=-1, out_axes=-1)(\n      jnp.broadcast_to(jnp.eye(3), t_near.shape + (3,))\n  )\n  jac_near, jac_far = jac_near.at[t_near == 0].set_subtensor(0, jac_far)\n\n  # Compute the Jacobian at the near and far points.\n  j_near = jnp.linalg.det(jac_near)\n  j_far = jnp.linalg.det(jac_far)\n  j_near, j_far = jnp.broadcast_to(j_near, t_near.shape), j_far.at[t_near == 0].set_subtensor(0, j_near)\n\n  # Compute the Jacobian determinant at the near and far points.\n  j_near_sq_inv = jnp.where(j_near == 0, jnp.finfo(jnp.float32).tiny, 1 / j_near)\n  j_far_sq_inv = jnp.where(j_far == 0, jnp.finfo(jnp.float32).tiny, 1 /"}
{"namespace": "coord.construct_ray_warps", "completion": "  # The near-plane is at t = 0, and the far-plane is at t = 1.\n  t_near = jnp.maximum(0, t_near)\n  t_far = jnp.maximum(1, t_far)\n\n  # The distance of the near-plane from the origin.\n  near_dist = jnp.sqrt(t_near**2 + 1)\n  # The distance of the far-plane from the origin.\n  far_dist = jnp.sqrt(t_far**2 + 1)\n\n  # The distance of the near-plane from the origin, in the new space.\n  s_near = near_dist / far_dist\n  # The distance of the far-plane from the origin, in the new space.\n  s_far = 1.0\n\n  # The mapping from metric distances to normalized distances.\n  def t_to_s(t):\n    return (t - t_near) / (t_far - t_near)\n\n  # The mapping from normalized distances to metric distances.\n  def s_to_t(s):\n    return s * (far_dist - near_dist) + near_dist\n\n  # The Jacobian of t_to_s.\n  t_to_s_jac = (s_far - s_near) / (t_far - t_near)\n  # The Jacobian of s_to_t.\n  s_to_t_jac = (far_dist - near_dist) / (s_far - s_near)\n\n  if fn_inv is not None:\n    # We were provided a function for the inverse of `fn`.\n    fn_inv_jac = jax.vmap(lin_fn, -1, -2)(\n        jax.vmap(lin_fn, -1, -2)(fn_inv.jacobian))\n    fn_jac = jax.vmap(lin_fn, -1, -2)(\n        jax.vmap(lin_fn, -1, -2)(fn.jacobian))\n    return t_to_s, s_to_t\n  else:\n    # We're trying to infer the inverse of"}
{"namespace": "coord.construct_ray_warps", "completion": "  # We need to make sure that the function is invertible.\n  if fn_inv is None:\n    if not hasattr(fn, 'inverse'):\n      raise ValueError(\n          f'The function {fn} does not have an inverse. '\n          'You can either provide the inverse function, or define it '\n          'with a @jax.jit(static_argnums=0) decorator.'\n      )\n    fn_inv = getattr(fn, 'inverse')\n\n  # We've already checked that the function is invertible, so we can use the\n  # provided inverse function.\n  elif not hasattr(fn_inv, 'inverse'):\n    raise ValueError(\n        f'The function {fn_inv} does not have an inverse. '\n        'You can either provide the inverse function, or define it '\n        'with a @jax.jit(static_argnums=0) decorator.'\n    )\n\n  # We've already checked that the function is invertible, so we can use the\n  # provided inverse function.\n  if not hasattr(fn_inv, 'inverse'):\n    raise ValueError(\n        f'The function {fn_inv} does not have an inverse. '\n        'You can either provide the inverse function, or define it '\n        'with a @jax.jit(static_argnums=0) decorator.'\n    )\n  fn_inv = getattr(fn_inv, 'inverse')\n\n  # If the function is contract, then we can use the inverse of contract as the\n  # inverse function.\n  if fn is geopoly.contract:\n    fn_inv = geopoly.inv_contract\n  # If the function is contract3, then we can use the inverse of contract3_isoscale\n  # as the inverse function.\n  elif fn is geopoly.contract3:\n    fn_inv = contract3_isoscale\n  # If the function is inv_contract, then we can use contract as the inverse\n  # function.\n  elif fn is geopoly.inv_contract:\n    fn_inv = geopoly.contract\n\n  # We've already checked that the function is invertible, so we can use the\n  # provided inverse function.\n  else:\n    raise ValueError"}
{"namespace": "coord.construct_ray_warps", "completion": "  # In the case where the function is the identity, we can use the identity\n  # function for the inverse.\n  if fn == jnp.identity:\n    fn_inv = jnp.identity\n  elif fn_inv is None:\n    # We can determine the inverse of a function if it's one of the following:\n    # - contraction\n    # - isotropic scale\n    # - identity\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = contract3_isoscale\n    elif fn == jnp.identity:\n      fn_inv = jnp.identity\n    else:\n      raise ValueError(f'Function {fn} has no inverse.')\n\n  # Ensure that the function is monotonic.\n  if not math.is_monotonic_increasing(fn):\n    raise ValueError(f'Function {fn} is not monotonic.')\n\n  # Compute the inverse of the function, and use it to determine the inverse\n  # mapping.\n  fn_inv = jax.jit(fn_inv)\n  fn_inv_near = fn_inv(t_near)\n  fn_inv_far = fn_inv(t_far)\n\n  # Construct the mapping from metric to normalized distances.\n  t_to_s = lambda t: (fn(t) - fn_inv_near) / (fn_inv_far - fn_inv_near)\n\n  # Construct the mapping from normalized to metric distances.\n  s_to_t = lambda s: fn_inv(s * (fn_inv_far - fn_inv_near) + fn_inv_near)\n\n  # Ensure that the inverse mapping is the inverse of the forward mapping.\n  if not jax.vmap(math.approx_eq, 0)(s_to_t(t_to_s(t)), t):\n    raise ValueError('Inverse mappings are not inverses of each other.')\n\n  # Ensure that the mapping is well-defined.\n  if (jnp.isnan(t_to_s(t_near)) or jnp.isnan(t_to_s(t_far)) or\n      jnp.isnan(s_to_t("}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = _get_inverse(fn)\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Arguments:\n    t: Tensor. The metric distances to map.\n\n    Returns:\n    Tensor. Normalized distances in the range [0, 1].\n    \"\"\"\n    # The first element of the tuple is the mapping, and the second is the\n    # Jacobian.\n    _, jac = track_linearize(fn, t, t_far - t_near)\n    s = jac * (t - t_near)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] to metric distances.\n\n    Arguments:\n    s: Tensor. The normalized distances in the range [0, 1].\n\n    Returns:\n    Tensor. The metric distances.\n    \"\"\"\n    return fn_inv(s)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if not fn_inv:\n    # Attempt to automatically determine the inverse of the given function.\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = contract3_isoscale\n    else:\n      raise ValueError(f'Unrecognized function: {fn}')\n  # The function mapping from [t_near, t_far] to [0, 1].\n  t_to_s = track_isotropic(fn, t_near, t_far)\n  # The function mapping from [0, 1] to [t_near, t_far].\n  s_to_t = track_isotropic(fn_inv, t_near, t_far)\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # For speed's sake, we use a different function to compute the inverse\n  # scaling for 2D and 3D.\n  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3:\n      fn_inv = contract3_isoscale\n    else:\n      raise ValueError(\n          f'fn {fn} has no inverse defined. '\n          'Use track_isotropic or track_linearize to compute the inverse.')\n\n  # For speed's sake, we do the 2D and 3D cases separately.\n  if fn == contract:\n    if t_far == t_near:\n      raise ValueError('t_far == t_near')\n    t_far = jnp.maximum(t_near, t_far)\n    t_near = jnp.minimum(t_near, t_far)\n  elif fn == contract3:\n    # We're going to use the fact that the inverse of contract3 is contract3,\n    # but we need to scale it to be in the right range.\n    t_far = jnp.maximum(t_near, t_far)\n    t_near = jnp.minimum(t_near, t_far)\n    t_far = contract3_isoscale(t_far)\n    t_near = contract3_isoscale(t_near)\n  else:\n    # If we're in 3D, we can use the fact that the inverse of contract is\n    # contract.\n    t_far = jnp.maximum(t_near, t_far)\n    t_near = jnp.minimum(t_near, t_far)\n\n    # We're going to use the fact that the inverse of contract is contract.\n    # However, we need to scale it to be in the right range.\n    t_far = contract(t_far)\n    t_near = contract(t_near)\n\n  t_near_inv_far = fn_inv(t_far)\n  t_far_inv_near = fn_inv(t_near)\n\n  # The far-to-near and near-"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=0)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(phi) * jnp.cos(theta)\n  y = r * jnp.sin(phi) * jnp.sin(theta)\n  z = r * jnp.cos(phi)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Compute the cartesian coordinates.\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return r * jnp.array([\n      jnp.sin(theta) * jnp.cos(phi),\n      jnp.sin(theta) * jnp.sin(phi),\n      jnp.cos(theta),\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.cos(phi)\n  y = r * jnp.cos(theta) * jnp.sin(phi)\n  z = r * jnp.sin(theta)\n\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.array([\n      r * jnp.cos(theta) * jnp.cos(phi),\n      r * jnp.cos(theta) * jnp.sin(phi),\n      r * jnp.sin(theta),\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(phi) * jnp.cos(theta)\n  y = r * jnp.sin(phi) * jnp.sin(theta)\n  z = r * jnp.cos(phi)\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(phi) * jnp.cos(theta)\n  y = r * jnp.sin(phi) * jnp.sin(theta)\n  z = r * jnp.cos(phi)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.cos(phi)\n  y = r * jnp.cos(theta) * jnp.sin(phi)\n  z = r * jnp.sin(theta)\n\n  return jnp.stack((x, y, z), axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Compute cartesian coordinates.\n  x = r * jnp.cos(theta) * jnp.cos(phi)\n  y = r * jnp.cos(theta) * jnp.sin(phi)\n  z = r * jnp.sin(theta)\n\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(phi) * jnp.sin(theta)\n  y = r * jnp.sin(phi) * jnp.sin(theta)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(phi) * jnp.cos(theta)\n  y = r * jnp.sin(phi) * jnp.sin(theta)\n  z = r * jnp.cos(phi)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.stack([r * jnp.cos(theta) * jnp.cos(phi),\n                    r * jnp.sin(theta) * jnp.cos(phi),\n                    r * jnp.sin(phi)], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return x, y, z\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(phi) * jnp.cos(theta)\n  y = r * jnp.cos(phi) * jnp.sin(theta)\n  z = r * jnp.sin(phi)\n\n  return jnp.stack((x, y, z), axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(phi) * jnp.cos(theta)\n  y = r * jnp.sin(phi) * jnp.cos(theta)\n  z = r * jnp.sin(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return r * jnp.array([\n      jnp.cos(phi) * jnp.sin(theta),\n      jnp.sin(phi) * jnp.sin(theta),\n      jnp.cos(theta),\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  return jnp.stack([\n    r * jnp.sin(theta) * jnp.cos(phi),\n    r * jnp.sin(theta) * jnp.sin(phi),\n    r * jnp.cos(theta),\n  ])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # TODO(b/206268439): Remove the 2D version once we're only using 3D.\n  if len(theta.shape) == 1:\n    return _spherical_to_cartesian(r, theta, phi)\n  elif len(theta.shape) == 2:\n    return _spherical_to_cartesian(\n        r,\n        theta[:, 0],\n        theta[:, 1])\n  else:\n    raise ValueError(f\"Unknown theta shape {theta.shape}\")\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return 0.5 * (t[1:] + t[:-1]) * (w[1:] + w[:-1]).sum()\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return 0.5 * (t[1:] * w[1:] + t[:-1] * w[:-1]).sum()\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return 1 / 2 * jnp.diff(w) @ jnp.concatenate((t, jnp.ones_like(t)))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return 0.5 * (w[Ellipsis, 0] + w[Ellipsis, -1]) * (t[Ellipsis, 1] - t[Ellipsis, 0]) + jnp.nansum(jnp.diff(w, axis=-1) * (t[Ellipsis, 1:] - t[Ellipsis, :-1]), axis=-1)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return 0.5 * jnp.diff(w) * jnp.diff(t, 1)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(jnp.diff(t) * w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  t = jnp.asarray(t)\n  w = jnp.asarray(w)\n\n  if t.ndim == 1:\n    return (t[1:] - t[:-1]) * (w[:-1] + w[1:]) / 2\n  else:\n    return jnp.sum(t[:, 1:] - t[:, :-1], axis=-1) * jnp.sum(w[:, :-1] + w[:, 1:], axis=-1) / 2\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  # pylint: disable=not-an-iterable\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return 0.5 * (t[1:] + t[:-1]) * (w[1:] - w[:-1]).sum()\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(w) * (t[1] - t[0]) / 2\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return (t[1:] - t[:-1]) * (w[1:] + w[:-1]) / 2.\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return (w[1:] + w[:-1]) * (t[1:] - t[:-1]) / 2.0\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return (w[Ellipsis, 0] + 2 * w[Ellipsis, 1:] + w[Ellipsis, -1]) * (t[1:] - t[:-1]) / 2\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return (t[1:] - t[:-1]) * (w[0] + w[1:] + w[:-1]) / 2\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    scores = [sum(w * s for w, s in zip(weights, scores_list)) for scores_list in zip(*scores)]\n    scores = [s for s in scores]\n    scores = [s / sum(scores) for s in scores]\n    return [id_list[:top_k] for id_list in zip(*ids)], [scores[:top_k] for scores in zip(*scores)]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate weighted sum of scores for each ID.\n    scores_weighted = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n\n    # Normalize the weighted scores.\n    scores_normalized = [score / sum(scores_weighted) for score in scores_weighted]\n\n    # Return the top K IDs and their corresponding scores based on the weighted sum.\n    return zip(*zip(*sorted(zip(ids, scores_normalized), key=lambda x: x[1])[:top_k])"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n\n    scores_sum = [sum(score_list * weight)\n                  for score_list, weight in zip(scores, weights)]\n    df = pd.DataFrame(\n        {'id': ids, 'score': scores_sum})\n    df.sort_values(by='score', ascending=False, inplace=True)\n    return df.iloc[:top_k]['id'].tolist(), df.iloc[:top_k]['score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_scores = [w * s for w, s in zip(weights, scores)]\n    weighted_scores_sum = sum(weighted_scores)\n\n    # Normalize the scores\n    normalized_scores = [w_s / weighted_scores_sum for w_s in weighted_scores]\n\n    # Retrieve the top K IDs based on the normalized scores\n    top_k_indices = sorted(range(len(ids)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n\n    # Return the top K IDs and their corresponding normalized scores\n    return [ids[i] for i in top_k_indices], [normalized_scores[i] for i in top_k_indices]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    scores_sum = sum(weights)\n    scores = [scores[i] * weights[i] / scores_sum for i in range(len(weights))]\n    scores_df = pd.DataFrame({f'score_{i}': scores})\n    scores_df['score'] = scores_df.sum(axis=1)\n    scores_df = scores_df.nlargest(top_k, 'score')\n    return scores_df['id_0'].tolist(), scores_df['score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    ids_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([ids_df, score_df], axis=1)\n    df['cc_score'] = df.apply(lambda row: sum(row.iloc[:, 1:] * row.iloc[0]), axis=1)\n    df = df.sort_values(by='cc_score', ascending=False)\n    df = df.head(top_k)\n\n    return df['id_0'].tolist(), df['cc_score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Calculate weighted sum of scores\n    weighted_sum_scores = []\n    for i, score in enumerate(scores):\n        weighted_sum_scores.append(sum([score * w for score, w in zip(score, weights)]))\n\n    # Normalize weighted sum of scores\n    norm_sum_scores = [score / sum(weighted_sum_scores) for score in weighted_sum_scores]\n\n    # Return top K IDs and their weighted sums\n    return [ids[i] for i, score in enumerate(norm_sum_scores) if score > 0][0:top_k], norm_sum_scores[0:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"Number of ids, scores, and weights must be the same.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Calculate weighted sum of scores for each ID\n    scores = [w * s for s, w in zip(scores, weights)]\n    scores = [sum(s) for s in zip(*scores)]\n\n    # Normalize scores\n    scores = [s / sum(scores) for s in scores]\n\n    # Retrieve top K IDs and corresponding scores\n    scores, ids = zip(*sorted(zip(scores, ids), reverse=True)[:top_k])\n    return ids, scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # 1. Calculate weighted sum of scores\n    weighted_scores = [\n        sum(scores[i] * weights[i] for i in range(len(scores))) for scores in zip(*scores)]\n\n    # 2. Normalize the scores\n    normalized_scores = [\n        score / sum(weighted_scores) for score in weighted_scores]\n\n    # 3. Get the top K IDs and scores\n    top_k_ids, top_k_scores = [], []\n    for i in range(top_k):\n        top_id, top_score = max(zip(ids, normalized_scores), key=lambda tup: tup[1])\n        top_k_ids.append(top_id)\n        top_k_scores.append(top_score)\n        normalized_scores[ids.index(top_id)] = -1\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    scores_list = [sum(list(map(lambda x: x[1], zip(weights, scores[i])) for i in range(len(weights))) for i in range(len(ids))]\n    scores_df = pd.DataFrame({'id': ids, 'score': scores_list})\n    scores_df = scores_df.apply(lambda x: x.sort_values(by='score', ascending=False), axis=1)\n    scores_df = scores_df.head(top_k)\n    return list(scores_df['id']), list(scores_df['score'])"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n\n    # Calculate the weighted sum of the scores\n    weighted_sum = [w*s for w, s in zip(weights, scores)]\n    # Normalize the weighted sum\n    normalized_weighted_sum = [(w_s - min(weighted_sum)) / (max(weighted_sum) - min(weighted_sum)) for w_s in weighted_sum]\n    # Sort the normalized weighted sum in descending order\n    normalized_weighted_sum.sort(reverse=True)\n    # Get the top K IDs and their corresponding weighted sums\n    top_k_ids = ids[normalized_weighted_sum.index(normalized_weighted_sum[0:top_k])].tolist()\n    top_k_weighted_sum = weighted_sum[normalized_weighted_sum.index(normalized_weighted_sum[0:top_k])].tolist()\n    return top_k_ids, top_k_weighted_sum"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # TODO: Implement the CC function.\n    #  You can use the following example code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n\n    # TODO: Implement the CC function.\n    #  You can use the following example code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n    #  You can use the following code as a reference.\n    #  But you should make it more efficient.\n\n    # TODO: Implement the CC function.\n    #  You can use the following example code as a reference.\n    #  But you should make it more efficient"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # TODO: Implement the CC function.\n    # The function should calculate the weighted sum of scores for each ID, normalize these scores, and then return the top K IDs and their corresponding scores based on the weighted sum.\n    # The function should work with data in the form of tuples for IDs, scores, and weights.\n    # The IDs should be sorted in descending order by the weighted sum of their scores.\n    # The function should return a tuple containing a list of strings and a list of floats.\n    # The first list should contain the top K IDs sorted by their weighted sum in descending order, and the second list should contain the corresponding weighted sums of these top K IDs.\n    # The function should support the following inputs and outputs:"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Normalize the scores\n    norm_scores = [w * s / sum(w * s for s in scores) for w, s in zip(weights, scores)]\n\n    # Aggregate the scores\n    agg_scores = [sum([w_i * s_i for w_i, s_i in zip(weights, s_i_list)]) for s_i_list in zip(*scores)]\n\n    # Sort the IDs and scores\n    sorted_ids = [sorted(zip(s_list, i_list), key=lambda x: x[0], reverse=True) for s_list, i_list in zip(agg_scores, ids)]\n\n    # Return the top K IDs and scores\n    return [i for i, _ in sorted_ids[:top_k]], [s for _, s in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"The lengths of ids, scores, and weights must be the same.\"\n    assert len(ids) > 0, \"There must be at least one set of ids, scores, and weights.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) > 0, \"The sum of weights must be greater than 0.\"\n\n    scores = [score * weight for score, weight in zip(scores, weights)]\n    scores_sum = sum(scores)\n    normalized_scores = [score / scores_sum for score in scores]\n\n    id_list = []\n    score_list = []\n    for id, score, weight in zip(ids, scores_sum, weights):\n        id_list.append(id)\n        score_list.append(score)\n    for i in range(len(id_list), top_k):\n        id_list.append(None)\n        score_list.append(0)\n\n    return id_list, score_list"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # TODO: Add documentation for the function\n    # TODO: Add examples\n    # TODO: Add a test for the function\n    return tuple(zip(*sorted(zip(*zip(*zip(*zip(*zip(ids, scores, weights))))[0],\n                             key=lambda x: x[2] * x[1],\n                             reverse=True)))[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n\n    id_list = []\n    score_list = []\n    for i in range(len(ids)):\n        scores_i = scores[i]\n        weights_i = weights[i]\n\n        # Calculate the weighted sum of the scores for each ID\n        weighted_sum_scores = [w * s for s, w in zip(scores_i, weights_i)]\n        weighted_sum = sum(weighted_sum_scores)\n\n        # Normalize the scores by dividing each score by the weighted sum\n        normalized_scores = [s / weighted_sum for s in weighted_sum_scores]\n\n        # Sort the IDs and scores in descending order based on the normalized scores\n        sorted_ids = sorted(ids[i], key=lambda x: normalized_scores[ids[i].index(x)], reverse=True)\n        sorted_scores = [normalized_scores[ids[i].index(id_)] for id_ in sorted_ids]\n\n        # Add the top K IDs and their corresponding scores to the output lists\n        id_list.extend(sorted_ids[:top_k])\n        score_list.extend(sorted_scores[:top_k])\n    return id_list, score_list"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # The number of categories or groups\n    n_categories = len(ids)\n\n    # The number of IDs in each category or group\n    n_ids = [len(id_list) for id_list in ids]\n    n_ids_sum = sum(n_ids)\n\n    # The weighted sum of scores for each ID\n    weighted_sums = []\n    for i in range(n_ids_sum):\n        weighted_sum = 0.\n        for j in range(n_categories):\n            weighted_sum += scores[j][i] * weights[j]\n        weighted_sums.append(weighted_sum)\n\n    # Sort the weighted sums in descending order and get the top K\n    weighted_sums_sorted = sorted(weighted_sums, reverse=True)\n    top_k_indices = [i for i, weighted_sum_sorted in enumerate(weighted_sums_sorted) if i < top_k]\n\n    # Get the IDs and scores of the top K\n    top_k_ids = []\n    top_k_weighted_sums = []\n    for i in top_k_indices:\n        for j in range(n_categories):\n            if i < n_ids[j]:\n                top_k_ids.append(ids[j][i])\n                top_k_weighted_sums.append(weighted_sums[i])\n    return top_k_ids, top_k_weighted_sums"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # TODO: This function is used in the hybrid retrieval function.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function.\n    #  However, if you want to implement it, you can implement it here.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function.\n    #  However, if you want to implement it, you can implement it here.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function.\n    #  However, if you want to implement it, you can implement it here.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function.\n    #  However, if you want to implement it, you can implement it here.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function.\n    #  However, if you want to implement it, you can implement it here.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function.\n    #  However, if you want to implement it, you can implement it here.\n    #  If you want to use this function, you can use the hybrid_cc function.\n    #  So, this function is not used in the retrieval process.\n    #  So, you don't need to implement this function."}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert len(weights) == len(ids), \"The length of weights must be the same as the length of ids.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores\n    normalized_scores = [normalized_score(scores_i, weights_i) for scores_i, weights_i in zip(scores, weights)]\n    # Calculate the weighted sum of the scores\n    weighted_sum_scores = [sum(score_list) for score_list in zip(*normalized_scores)]\n    # Return the top K IDs and their corresponding weighted sum scores\n    return (sorted(ids, key=lambda x: weighted_sum_scores[ids.index(x)], reverse=True)[:top_k], weighted_sum_scores[:top_k]\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This is the old, incorrect version.\n  # TODO: This"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian matrix of the function\n  jacobian = jax.jacrev(fn, argnums=0)(mean)\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_mean = jax.vmap(jax.value_and_grad(jacobian, argnums=0))(mean)\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov = jax.vmap(jax.value_and_grad(jacobian_mean, argnums=0))(cov)\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_mean = jax.vmap(jax.value_and_grad(jacobian_cov, argnums=0))(mean)\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_cov = jax.vmap(jax.value_and_grad(jacobian_cov_mean, argnums=0))(cov)\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_cov_mean = jax.vmap(jax.value_and_grad(jacobian_cov_cov, argnums=0))(mean)\n\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_cov_cov = jax.vmap(jax.value_and_grad(jacobian_cov_cov_mean, argnums=0))(cov)\n\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_cov_cov_mean = jax.vmap(jax.value_and_grad(jacobian_cov_cov_cov, argnums=0))(mean)\n\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_cov_cov_cov = jax.vmap(jax.value_and_grad(jacobian_cov_cov_cov_mean, argnums=0))(cov)\n\n  # Compute the Jacobian matrix of the function at the mean\n  jacobian_cov_cov_cov_cov_mean = jax.vmap(jax.value_and_grad(jacobian_cov_cov_cov_cov, argnums=0))(mean)\n\n  "}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_linearized = jax.vmap(jax.jit(jax.grad(fn, argnums=0), in_axes=(0,))\n  # Apply the function to the means\n  fn_mean = fn(mean)\n  # Calculate the Jacobian of the function\n  jacobian = fn_linearized(mean)\n  # Apply the Jacobian to the covariances\n  fn_cov = jacobian @ cov @ jacobian.T\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # linearize the function around the mean\n  fn_lin = jax.vmap(jax.jacfwd(fn, argnums=(0,)))\n\n  # transform the means\n  fn_mean = fn_lin(mean)\n\n  # transform the covariances\n  fn_cov = jax.vmap(jax.jacfwd(fn, argnums=(0, 1)))\n  fn_cov = fn_cov(mean, cov)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean.\n  jac = jax.vmap(jax.jacrev(fn), in_axes=(0, 1, None))(mean)\n\n  # Compute the Jacobian transpose (i.e. the Jacobian inverse).\n  jac_t = jnp.transpose(jac, [0, 2, 1])\n\n  # Compute the Jacobian transpose times the covariance.\n  fn_cov = jac_t @ cov @ jac\n\n  # Compute the function applied to the mean.\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Get the Jacobian of the function.\n  jac_fn = jax.jacfwd(fn)\n  # Linearize the function around the mean.\n  jac_fn_mean = jac_fn(mean)\n  # Compute the Jacobian-transpose of the function.\n  jac_fn_mean_t = jax.jacrev(jac_fn_mean)\n  # Compute the Jacobian-transpose of the Jacobian of the function.\n  jac_fn_mean_t_jac_fn = jax.jacrev(jac_fn_mean_t)\n  # Compute the Jacobian-transpose of the Jacobian-transpose of the function.\n  jac_fn_mean_jac_fn_t = jax.jacfwd(jac_fn_mean_t)\n\n  # Transform the covariances.\n  fn_cov = jac_fn_mean_jac_fn_t @ cov @ jac_fn_mean_t_jac_fn\n\n  return jac_fn(mean), fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # We linearize the function around the mean.\n  fn_mean = fn(mean)\n  # We linearize the function by computing the Jacobian.\n  fn_jacobian = jax.jacfwd(fn)\n  # We transform the covariances using the Jacobian.\n  fn_cov = fn_jacobian(mean) @ cov @ jnp.swapaxes(fn_jacobian(mean), 0, -2)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # TODO: This is not a great way to do this, since we're using the\n  # jax.vmap, which is not differentiable.\n  fn_mean = jax.vmap(fn)(mean)\n  fn_jac = jax.jacfwd(fn)\n  fn_jac_mean = jax.vmap(fn_jac)(mean)\n  fn_cov = jax.vmap(jax.jacfwd(jax.jacfwd(fn)), (0, 0))\n  fn_cov_mean = jax.vmap(fn_cov)(mean)\n  fn_cov_mean = fn_cov_mean.transpose(1, 0, 3, 2)\n  fn_cov = fn_cov.transpose(0, 2, 3, 1)\n  fn_cov = jax.vmap(jax.vmap(jax.jacfwd(jax.jacfwd(jax.jacfwd(fn)))), (0, 0, 0, 0))\n  fn_cov_mean = jax.vmap(fn_cov)(mean)\n  fn_cov_mean = fn_cov_mean.transpose(1, 0, 3, 2)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # linearize the function around the mean\n  fn_linearized = jax.vmap(lambda x: fn(x) - mean)\n\n  # transform the means\n  fn_mean = fn_linearized(mean)\n\n  # transform the covariances\n  fn_cov = jnp.vmap(fn_linearized, in_axes=(0, None, None))(cov)\n  fn_cov = jnp.einsum('ij,ik->jk', cov, fn_cov)\n  fn_cov = fn_cov + cov\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # This function is a linearization of the given function around the mean.\n  def fn_lin(x):\n    return fn(mean) + jnp.dot(fn.jac()(mean), (x - mean))\n\n  # This function transforms the covariances.\n  def cov_fn(x):\n    return jnp.tensordot(x, fn.jac()(mean), axes=1)\n\n  # The linearized function is applied to the means.\n  fn_mean = fn_lin(mean)\n\n  # The covariance is transformed using the linearized function.\n  fn_cov = cov_fn(cov)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function around the mean.\n  jacobian = jax.jacrev(fn, argnums=(0, 1, 2), static_argnums=(2, 3))\n  jacobian = jacobian(mean, mean, mean, mean)\n  jacobian_tr = jacobian.T\n  jacobian_tr_cov_tr = jacobian_tr @ cov\n  jacobian_tr_cov_tr_tr = jacobian_tr_cov_tr.T\n  jacobian_tr_cov = jacobian_tr_cov_tr_tr.T\n  # Compute the transformed means and covariances.\n  fn_mean = fn(mean)\n  fn_cov = jacobian_tr_cov @ cov\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # TODO(mto): This is a hack to make the gradient work.\n  # We should probably use a different approach.\n  def fn_linearized(x):\n    return fn(x) - jax.vmap(fn, in_axes=(0, 0))(mean, x)\n  fn_mean = jax.vmap(fn_linearized, in_axes=(0, 0))(mean)\n  fn_cov = jax.vmap(jax.vmap(jax.jacrev(fn_linearized), in_axes=(0, 0, 1, 2))(cov)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean.\n  d_fn_d_x = jax.jacobian(fn)(mean)\n  # Compute the Jacobian of the Jacobian.\n  d_d_fn_d_x = jax.jacobian(d_fn_d_x)\n  # Linearize the function around the mean.\n  fn_mean = fn(mean)\n  # Compute the Jacobian of the function around the mean.\n  fn_d_x = d_fn_d_x(mean)\n\n  # Transform the covariances.\n  fn_cov = cov + jnp.einsum('...ij,jkl->...kl', cov, d_d_fn_d_x(mean))\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # TODO(alex): Add support for higher-order moments\n  # TODO(alex): Add support for a different mean for each covariance\n  # TODO(alex): Add support for a different covariance for each mean\n  assert cov.ndim == 3\n  assert mean.ndim == 2\n  assert cov.shape[-2] == mean.shape[-1]\n\n  # Compute the Jacobian of the function\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Transform the covariances\n  fn_cov = jax.vmap(lambda x: jax.jvp(fn, (0,), (x, x))(cov)\n  fn_cov = jnp.einsum('ij,ijk->ijk', jacobian, cov)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  def fn_linearize(x):\n    \"\"\"Linearizes the given function around the given point.\n\n    Args:\n      x: Tensor. The point around which the function is linearized.\n\n    Returns:\n      Tensor. The linearized function.\n    \"\"\"\n    return jax.vmap(fn, in_axes=[None, None, None, None, None], out_axes=None)(\n        x, x, x, x, x)\n\n  # Linearize the function around the mean\n  fn_mean = fn_linearize(mean)\n  # Linearize the Jacobian of the function\n  fn_jacobian = jax.jacrev(fn_linearize, 1)\n  # Transform the means\n  fn_mean = jnp.apply_along_axis(fn_mean, -1, mean)\n\n  # Transform the covariances\n  fn_cov = jnp.einsum(\n      'ij,ijkl->ijkl',\n      fn_jacobian, cov)  # This is the Jacobian of the function.\n  fn_cov = jnp.einsum('ijkl,kl->ij', fn_cov, cov)  # This is the Jacobian.\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # This is the Jacobian of the function fn.\n  jac_fn = jax.vmap(jax.jacfwd(fn))\n\n  # We apply the Jacobian to the means to get the linearization point.\n  jac_fn_mean = jac_fn(mean)\n\n  # We then apply the Jacobian to the covariances to get the Jacobian of the covariances.\n  jac_fn_cov = jax.vmap(jax.jacfwd(jac_fn))(cov)\n\n  # We then apply the Jacobian of the covariances to the covariances to get the linearized covariances.\n  fn_cov = jac_fn_cov * cov\n\n  # We then apply the Jacobian of the function to the means to get the linearized means.\n  fn_mean = jac_fn_mean * mean\n\n  return (fn_mean, fn_cov)\n\n"}
{"namespace": "coord.track_linearize", "completion": "  fn_mean = fn(mean)\n  fn_jac = jax.jacrev(fn, 0)(mean)\n  fn_cov = cov @ fn_jac[..., 0, :] @ fn_jac[..., 0, :] + cov @ fn_jac[..., 1:, :] @ fn_jac[..., 1:, :]\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Note: this is not a perfect linearization, but it's close enough for our purposes\n  # (see https://arxiv.org/abs/2111.12077 for more details).\n  fn_mean = fn(mean)\n  fn_jac = jax.jacfwd(fn)\n  jac_mean = fn_jac(mean)\n  jac_mean_t = jax.vmap(jax.vmap(jax.vmap(jnp.transpose, (0, 1, 3, 2)), (0, 0, None, None))(jac_mean)\n  jac_cov = jac_mean_t * cov\n  fn_cov = jax.vmap(jax.vmap(jax.vmap(jnp.sum, (0, 3)), (0, None, None))(jac_cov)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # TODO(jpoth): This is a linearization around the mean.\n  #  It is not a Jacobian linearization.\n  #  This is probably wrong for some functions.\n  #  In particular, it is wrong for the case where the function is a rotation.\n  #  The correct Jacobian linearization would be:\n  #  https://github.com/jpoth/jax-kalman/blob/master/kalman_filter.py#L116\n  #  But it is not clear to me how to apply the Jacobian linearization to the\n  #  covariances.\n  fn_mean = fn(mean)\n  fn_cov = jax.vmap(lambda x: (fn(x) - fn_mean) @ jnp.swapaxes(x, -1, -2))\n  fn_cov = fn_cov / 2\n  return (fn_mean, fn_cov)\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # First, we linearize the function around the mean.\n  fn_mean = fn(mean)\n  fn_jacobian = jax.jvp(fn, (mean,), (mean,))[0]\n\n  # Then, we transform the covariances.\n  fn_cov = jnp.matmul(\n      fn_jacobian,\n      jnp.matmul(cov, jnp.transpose(fn_jacobian, [0, 2, 1])))\n  return (fn_mean, fn_cov)\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for a in x:\n        if a.size > 1:\n            yield [a[: a.size // 2], a[a.size // 2 :]\n        else:\n            yield a\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) <= 1:\n            yield [array]\n        else:\n            yield [array[: int(len(array) / 2)], [array[int(len(array) / 2) :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            x[i] = np.array_split(x[i], 2)\n        yield x[i]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield [arr[: int(len(arr) / 2)], [arr[int(len(arr) / 2) :]]\n        else:\n            yield [arr]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, arr in enumerate(x):\n        if len(arr) > 1:\n            yield [arr[: len(arr) // 2], arr[len(arr) // 2 :]\n        else:\n            yield [arr]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, arr in enumerate(x):\n        if len(arr) <= 1:\n            yield [arr]\n        else:\n            yield [arr[: len(arr) // 2], arr[len(arr) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield [arr[: len(arr) // 2], [arr[len(arr) // 2 :]]\n        else:\n            yield [arr]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) < 2:\n            yield arr\n        else:\n            yield arr[: len(arr) // 2], arr[len(arr) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, arr in enumerate(x):\n        if len(arr) > 1:\n            yield [arr[: int(len(arr) / 2)], [arr[int(len(arr) / 2) :]]\n        else:\n            yield arr, arr\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if x[i].size == 1:\n            continue\n\n        l = int(x[i].size / 2)\n        yield [x[i][:l], x[i][l:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    # Iterate through the list of numpy arrays\n    for i in x:\n        # Check if the array has more than one element\n        if len(i) > 1:\n            # Bisect the array into two halves\n            yield [i[: int(len(i) / 2)], [i[int(len(i) / 2) :]]\n\n    # Yield the original array if it has only one element\n    yield [x]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, a in enumerate(x):\n        if a.shape[0] == 1:\n            yield [a]\n            continue\n        a1, a2 = np.array_split(a, 2)\n        yield [a1, a2]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            yield [array[: len(array) // 2], [array[len(array) // 2 :]]\n        else:\n            yield array\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][0], x[i][1:]]\n        else:\n            yield x[i]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) <= 1:\n            yield arr\n            continue\n        yield [arr[: len(arr) // 2], [arr[len(arr) // 2 :]]\n        yield [arr[len(arr) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    # Iterate through the list\n    for i in range(len(x)):\n        # Check if the array has more than one element\n        if len(x[i]) > 1:\n            # If it does, bisect the array\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]\n        # If the array has only one element, yield it\n        else:\n            yield x[i]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield [arr[: int(len(arr) / 2)], [arr[int(len(arr) / 2) :]]\n        else:\n            yield [arr]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if arr.size > 1:\n            yield [arr[: arr.size // 2], arr[arr.size // 2 :]\n        else:\n            yield arr\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]\n        else:\n            yield x[i]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: int(len(x[i]) / 2), x[i][int(len(x[i]) / 2) :]]\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"`x` must be a 2d array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"x must be a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"x must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\n            f\"The matrix {x} is not square. \"\n            f\"It has {x.shape[0]} rows and {x.shape[1]} columns.\"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[1] != x.shape[0]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[1] != x.shape[0]:\n        raise ValueError(\n            \"The matrix is not square. \"\n            f\"Its dimensions are {x.shape[0]}x{x.shape[1]}. \"\n            \"The matrix must be square.\"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[1] != x.shape[0]:\n        raise ValueError(\n            \"Matrix is not square. Please provide a square matrix. \"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input must be a 2D array.\")\n\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(f\"Input must be a square matrix of shape {x.shape}.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"`x` must be a matrix\")\n    if x.shape[1] != x.shape[0]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[1] != x.shape[0]:\n        raise ValueError(\n            \"Matrix is not square. \"\n            f\"Expected x.shape = ({x.shape[1]}, {x.shape[0]}) but got {x.shape}.\"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\n            \"The input array must be a square matrix. \"\n            + \"Got {}-by-{} array instead\".format(x.shape[0], x.shape[1])\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[1] != x.shape[0]:\n        raise ValueError(f\"{x} is not a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"x must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim == 2 and x.shape[1] != x.shape[0]:\n        raise ValueError(f\"The matrix is not square: {x.shape[1]}x{x.shape[0]}\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(f\"Expected a {x.ndim}-d array with shape {x.shape}, got {x.shape}.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\n            \"The matrix must be square. \" \"Found shape: {}\".format(x.shape)\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[1] != x.shape[0]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "coord.pos_enc", "completion": "  if isinstance(x, np.ndarray):\n    x = jnp.array(x)\n  x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp.reshape(x, (-1, 3))\n  # x = jnp."}
{"namespace": "coord.pos_enc", "completion": "  # scale the input\n  scaled_x = x * 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # apply the sine function\n  sinusoid = jnp.sin(scaled_x)\n\n  # concatenate the original input with the sinusoidal features\n  if append_identity:\n    return jnp.concatenate((x, sinusoid), axis=-1)\n  else:\n    return sinusoid\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # scale the input\n  scaled_x = 2 ** jnp.arange(min_deg, max_deg) * x\n\n  # apply the sine function\n  scaled_x = jnp.sin(scaled_x)\n\n  # append the original input to the encoded array\n  if append_identity:\n    x_enc = jnp.concatenate([x, scaled_x], axis=-1)\n  else:\n    x_enc = scaled_x\n\n  return x_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  x = jnp.atleast_2d(x)\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_x = x * scales[:, None]\n  sin_x = jnp.sin(scaled_x)\n  if append_identity:\n    return jnp.concatenate([x, sin_x], axis=1)\n  return sin_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scaling factors\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  # Calculate the mean and variance of the input\n  mean = jnp.mean(x, axis=-1, keepdims=True)\n  var = jnp.var(x, axis=-1, keepdims=True)\n  # Apply the scaling to the input\n  scaled_mean = jnp.reshape(mean * scales, (-1, 1, 2))\n  scaled_var = jnp.reshape(var * scales**2, (-1, 1, 2))\n  # Calculate the encoded features\n  encoded = expected_sin(scaled_mean, scaled_var)\n  # Concatenate the original input with the encoded features\n  if append_identity:\n    return jnp.concatenate([x, encoded], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  if x.ndim != 2:\n    raise ValueError('x must be 2D.')\n  if min_deg < 0 or max_deg < 0:\n    raise ValueError('min_deg and max_deg must be positive.')\n\n  # Scale the input\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], x.shape + (-1,))\n\n  # Apply sine function to scaled input\n  encoded = jnp.concatenate([\n    jnp.sin(scaled_x),\n    jnp.cos(scaled_x),\n  ], axis=-1)\n\n  # Optionally append the original input to the result\n  if append_identity:\n    encoded = jnp.concatenate([encoded, x], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Compute the mean and variance of the input\n  mean = x.mean(axis=-1, keepdims=True)\n  var = x.var(axis=-1, keepdims=True)\n\n  # Compute the positional encoding\n  pos_enc = integrated_pos_enc(mean, var, min_deg, max_deg)\n\n  # If append_identity is True, append the original input to the encoding\n  if append_identity:\n    pos_enc = jnp.concatenate([pos_enc, x], axis=-1)\n  return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # x = x - x.mean(axis=-2)\n  # x = x / x.std(axis=-2)\n  x = (x - x.mean(axis=-2)) / (x.std(axis=-2) + 1e-5)\n  x_shape = x.shape\n  x = jnp.reshape(x, [-1, x_shape[-2], x_shape[-1]])\n  x_encoded = integrated_pos_enc(x, jnp.ones_like(x), min_deg, max_deg)\n  if append_identity:\n    x_encoded = jnp.concatenate([x_encoded, x], axis=-1)\n  return jnp.reshape(x_encoded, x_shape)\n\n"}
{"namespace": "coord.pos_enc", "completion": "  if not isinstance(x, np.ndarray):\n    x = jnp.asarray(x)\n  if x.ndim == 1:\n    x = x[None, :]\n  if x.ndim == 2:\n    x = x[None, :, :]\n  if x.ndim == 3:\n    x = x[None, :, :, :]\n  if x.ndim == 4:\n    x = x[None, None, :, :, :]\n\n  x = x * 0.5 + 0.5  # [0, 1]\n  x = jnp.sin(2.0 * jnp.pi * x)  # [-1, 1]\n  if append_identity:\n    x = jnp.concatenate((x, x + 1), axis=-1)\n  else:\n    x = x + 1\n  x = x * 2.0 ** jnp.arange(min_deg, max_deg)[:, None, None]\n\n  return x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scale the input by powers of 2\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Compute the sin of the scaled input\n  encoded = jnp.concatenate(\n      [\n          jnp.sin(scaled_x),\n          jnp.cos(scaled_x),\n          jnp.zeros(scaled_x.shape[:-1] + (1,)),\n      ],\n      axis=-1)\n\n  # Concatenate the original input if append_identity is True\n  if append_identity:\n      encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  d = x.shape[-1]\n  s = 2 ** jnp.arange(min_deg, max_deg)\n  s = jnp.reshape(s[None, ...], (1, d, 1))\n  x = jnp.reshape(x[..., None, :], (x.shape[:-1] + (1, d))\n  x = x * s\n  s = jnp.reshape(s, (1, 1, d))\n  x = jnp.concatenate([x, jnp.sin(x) * s], axis=-1)\n  if append_identity:\n    x = jnp.concatenate([x, x[..., :d, :]], axis=-1)\n\n  return x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Compute the scaling factor.\n  scale = 1.0 / 2.0 / np.pi\n  # Generate the scaling factors.\n  scales = np.power(2.0, np.arange(min_deg, max_deg + 1))\n  # Compute the encoded features.\n  encoded_features = np.sin(x * scale * np.pi * np.arange(max_deg - min_deg + 1))\n  # Concatenate the encoded features with the original features.\n  if append_identity:\n    encoded_features = np.concatenate([x, encoded_features], axis=-1)\n  return encoded_features\n\n"}
{"namespace": "coord.pos_enc", "completion": "  x = x.astype(jnp.float32)\n  # Scales are powers of 2 from min_deg to max_deg.\n  scales = jnp.power(2, jnp.arange(min_deg, max_deg))\n  # The sine of the scaled input.\n  sine_x = jnp.sin(jnp.multiply(x, scales))\n  # The sine of the scaled input + pi/2.\n  sine_x_pi_2 = jnp.sin(jnp.add(jnp.multiply(x, scales), 0.5 * jnp.pi))\n\n  if append_identity:\n    x_out = jnp.concatenate([x, sine_x, sine_x_pi_2], axis=-1)\n  else:\n    x_out = jnp.concatenate([sine_x, sine_x_pi_2], axis=-1)\n  return x_out\n\n"}
{"namespace": "coord.pos_enc", "completion": "  x = x.astype(jnp.float32)\n\n  # Generate the scaling factors for each dimension\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Generate the sine of the scaled input\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], x.shape[:-1] + (-1,))\n  sin_scaled_x = jnp.sin(scaled_x)\n\n  # Concatenate the sine of the scaled input with the original input\n  if append_identity:\n    return jnp.concatenate([scaled_x, sin_scaled_x], axis=-1)\n  else:\n    return sin_scaled_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  if x.shape[-1] != 3:\n    raise ValueError(f'Inputs must be 3D, are {x.shape[-1]}D.')\n\n  # Compute the 2^n scaling factors.\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Compute the mean and variance of the Gaussian.\n  # We're using a Gaussian with zero mean and unit variance.\n  mean = 0.0\n  var = 1.0\n\n  # Compute the sine of the Gaussian.\n  # We're using a sine function to map the Gaussian to the [-1, 1] range.\n  sin_x = jnp.sin(x)\n\n  # Compute the encoded features.\n  encoded = jnp.expand_dims(sin_x, -1) * scales\n\n  # If we want to append the original input to the encoded features, do so.\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # The input to this function is a 3D tensor of shape (batch_size, N, D)\n  # where N is the number of points in the batch and D is the dimension.\n  #\n  # We want to generate a tensor of shape (batch_size, N, D + D * (max_deg - min_deg))\n  # that represents the sine-encoded values of the input.\n  #\n  # To do this, we first scale the input by powers of 2 from min_deg to max_deg.\n  # This gives us a tensor of shape (batch_size, N, D * (max_deg - min_deg)).\n  #\n  # We then take the sine of these values and concatenate them along the last axis.\n  # This gives us the desired tensor.\n  if x.shape[-1] != 3:\n    raise ValueError(f'Inputs must be 3D, are {x.shape[-1]}D.')\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # We then take the sine of these values and concatenate them along the last axis.\n  # This gives us the desired tensor.\n  sines = jnp.sin(scaled_x)\n  encoded = jnp.concatenate([sines, jnp.cos(scaled_x)], axis=-1)\n  # We can then concatenate the original input to the encoded features.\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # TODO(alex): Add a version that doesn't use a sine function.\n  # TODO(alex): Add a version that doesn't use a sine function.\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(scaled_x, jnp.zeros_like(scaled_x))\n  if append_identity:\n    return jnp.concatenate([x, encoded], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  x = jnp.expand_dims(x, -1)\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_x = x * scales[:, None]\n  encoded = expected_sin(scaled_x, jnp.zeros_like(scaled_x))\n  if append_identity:\n    encoded = jnp.concatenate((encoded, x), axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # TODO: use the new sin function\n  # TODO: make this more efficient\n  # TODO: maybe use a different encoding for the depth?\n  # TODO: maybe use a different encoding for the depth?\n  x = x[..., :2]\n  x_mag = jnp.sqrt(x[:, 0, :] ** 2 + x[:, 1, :] ** 2)\n  x_scale = 1.0 / jnp.maximum(1e-6, x_mag)\n  x_scaled = x * x_scale\n  # x_scaled = x\n  sin_x = jnp.sin(x_scaled)\n  # sin_x = jnp.sin(x_scaled)\n  sin_x_scaled = jnp.sin(x_scaled * jnp.pi)\n  # sin_x_scaled = jnp.sin(x_scaled * jnp.pi)\n\n  # scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  # x_scaled = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  # sin_x = jnp.reshape(sin_x[Ellipsis, None, :], shape)\n  # sin_x_scaled = jnp.reshape(sin_x_scaled[Ellipsis, None, :], shape)\n\n  sin_x = jnp.concatenate([x_scaled, sin_x, sin_x_scaled], axis=-1)\n  if append_identity:\n    sin_x = jnp.concatenate([x, sin_x], axis=-1)\n  return sin_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  x = x.astype(np.float32)\n  # Normalize x to [-1,1]\n  x = (x - 2.0) / 2.0\n  # Apply sine function to x\n  x = jnp.sin(x)\n  # Scale x by 2^i\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  x = x * scales[:, None, None]\n  # Concatenate with x\n  if append_identity:\n    x = jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1)\n  return x\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all shapes are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch.\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all shapes are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all shapes are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(0, len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch.\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}. \"\n                    f\"{values[field1][i].shape} != {values[field2][i].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i, _ in enumerate(values[field1]):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}. \"\n                    f\"Got {values[field1][i].shape} and {values[field2][i].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                    f\"Expected {values[field1][i].shape}, got {values[field2][i].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all the shapes of the arrays in the two fields are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i, value_1 in enumerate(values[field1]):\n            value_2 = values[field2][i]\n            if value_1.shape != value_2.shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                    f\"array {i} has shape {value_1.shape} and {value_2.shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if all field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(0, len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Check if all the arrays in field1 have the same shape as the arrays in field2.\n\n        :param cls: class type. The class type of the Pydantic model.\n        :param values: dict. The dictionary of values to be validated.\n        :return: dict. The validated values.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Check if all values in the lists of numpy arrays specified by field1 and field2 have the same shape.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height.\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera's projection matrix.\n        self.uniforms.camera_proj = camera.proj\n        self.uniforms.camera_view = camera.view\n\n        # Set the camera's view frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self.uniforms.camera_frustum = camera.frustum\n\n        # Set the camera's frustum.\n        self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Update the camera's projection matrix\n        self.uniforms.proj = glm.to_numpy(camera.proj)\n\n        # Update the camera's view matrix\n        self.uniforms.view = glm.to_numpy(camera.view)\n\n        # Update the camera's model matrix\n        self.uniforms.model = glm.to_numpy(camera.model)\n\n        # Update the camera's frustum matrix\n        self.uniforms.frustum = glm.to_numpy(camera.frustum)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy(camera.intrinsics)\n\n        # Update the camera's intrinsics\n        self.uniforms.intrinsics = glm.to_numpy"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera's projection matrix\n        gl.glUseProgram(self.mesh_program)\n        gl.glUniformMatrix4fv(self.mesh_uniforms.proj_mat, 1, gl.GL_FALSE, glm.value_ptr(camera.proj_mat))\n        gl.glUniformMatrix4fv(self.mesh_uniforms.view_mat, 1, gl.GL_FALSE, glm.value_ptr(camera.view_mat))\n\n        # Set the mesh's vertex data\n        gl.glUseProgram(self.mesh_program)\n        gl.glActiveTexture(0)\n        gl.glEnable(gl.GL_TEXTURE_2D)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.verts_id)\n        gl.glEnableClientState(gl.GL_VERTEX_ARRAY)\n        gl.glVertexPointer(self.vert_sizes[0], gl.GL_FLOAT, 0, ctypes.c_void_p(self.verts_data.ctypes.data))\n        gl.glEnableClientState(gl.GL_NORMAL_ARRAY)\n        gl.glNormalPointer(gl.GL_FLOAT, 0, ctypes.c_void_p(self.normals.ctypes.data))\n\n        # Set the mesh's face data\n        gl.glUseProgram(self.mesh_program)\n        gl.glActiveTexture(0)\n        gl.glEnable(gl.GL_TEXTURE_2D)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.faces_id)\n        gl.glEnableClientState(gl.GL_INDEX_ARRAY)\n        gl.glIndexPointer(gl.GL_UNSIGNED_INT, 0, ctypes.c_void_p(self.faces_data.ctypes.data))\n\n        # Set the mesh's color data\n        gl.glUseProgram(self.mesh_program)\n        gl.glActiveTexture(0)\n        gl.glEnable(gl.GL_TEXTURE_2D)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.colors"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera's viewport to the entire rendering context\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the camera's projection matrix\n        projection_matrix = camera.projection_matrix\n        gl.glUseProgram(self.mesh_program)\n        gl.glUniformMatrix4fv(self.uniforms.PROJECTION_MATRIX, 1, gl.GL_FALSE, projection_matrix.elements)\n\n        # Set the camera's view matrix\n        view_matrix = camera.view_matrix\n        gl.glUniformMatrix4fv(self.uniforms.VIEW_MATRIX, 1, gl.GL_FALSE, view_matrix.elements)\n\n        # Set the camera's frustum\n        gl.glUniform1f(self.uniforms.FAR_PLANE, camera.far)\n        gl.glUniform1f(self.uniforms.NEAR_PLANE, camera.near)\n        gl.glUniform1f(self.uniforms.FOV, camera.fov)\n\n        # Set the camera's position\n        gl.glUniform3fv(self.uniforms.VIEW_POS, 1, camera.position.elements)\n\n        # Set the camera's up vector\n        gl.glUniform3fv(self.uniforms.VIEW_UP, 1, camera.up.elements)\n\n        # Set the camera's view frustum\n        gl.glUniform3fv(self.uniforms.FRUSTUM_NEAR, 1, camera.near_plane.elements)\n\n        # Set the camera's view frustum\n        gl.glUniform3fv(self.uniforms.FRUSTUM_FAR, 1, camera.far_plane.elements)\n\n        # Set the camera's view frustum\n        gl.glUniform3fv(self.uniforms.FRUSTUM_RIGHT, 1, camera.right_plane.elements)\n\n        # Set the camera's view frustum\n        gl.glUniform3fv(self.uniforms.FRUSTUM_LEFT, 1, camera.left_plane.elements)\n\n        # Set the camera's view frustum\n        gl.glUniform3"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Update the camera's projection and view matrices\n        eglctx.use_camera(camera)\n\n        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the viewport to the entire rendering context\n        gl.glViewport(0, 0, eglctx.width, eglctx.height)\n\n        # Set the OpenGL states\n        common_opengl_options()\n\n        # Set the program to the mesh program\n        use_gl_program(self.mesh_program)\n\n        # Set the uniforms\n        self.uniforms.view_matrix = camera.view_matrix\n        self.uniforms.proj_matrix = camera.projection_matrix\n        self.uniforms.point_radius = self.point_radius\n        self.uniforms.shade_flat = self.shade_flat\n        self.uniforms.render_normal = self.render_normal\n        self.uniforms.vert_size = self.vert_size\n        self.uniforms.vert_gl_types = self.vert_gl_types\n        self.uniforms.vert_sizes = self.vert_sizes\n        self.uniforms.verts = self.verts\n        self.uniforms.colors = self.colors\n        self.uniforms.normals = self.normals\n\n        # Render the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawArrays(gl.GL_LINES, 0, len(self.faces) * 2)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.faces) * 3)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawArrays(gl.GL_QUADS, 0, len(self.faces) * 4)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, "}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera's position and orientation\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadMatrixd(camera.P.m)\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n\n        # Set the shader program and uniforms\n        gl.glUseProgram(self.mesh_program)\n\n        # Enable and disable certain OpenGL settings\n        common_opengl_options()\n\n        # Set the vertex and index buffers\n        gl.glBufferData(gl.GL_ARRAY_BUFFER, self.n_verts_bytes, self.verts_data, gl.GL_STATIC_DRAW)\n        gl.glBufferData(gl.GL_ELEMENT_ARRAY_BUFFER, self.n_faces_bytes, self.faces_data, gl.GL_STATIC_DRAW)\n\n        # Set the vertex attributes\n        gl.glEnableVertexAttribArray(0)\n        gl.glVertexAttribPointer(0, self.vert_sizes[0], gl.GL_FLOAT, self.vert_size, 0)\n\n        # Set the face attributes\n        gl.glEnableVertexAttribArray(1)\n        gl.glVertexAttribPointer(1, self.vert_sizes[1], gl.GL_FLOAT, self.vert_size, self.vert_sizes[0] * ctypes.sizeof(ctypes.c_float))\n\n        # Set the normal attributes\n        gl.glEnableVertexAttribArray(2)\n        gl.glVertexAttribPointer(2, self.vert_sizes[2], gl.GL_FLOAT, self.vert_size, self.vert_sizes[0] * ctypes.sizeof(ctypes.c_float) + self.vert_sizes[1] * ctypes.sizeof(ctypes.c_float))\n\n        # Set the scalar attributes\n        for k, v in self.scalars.items():\n            i = 3 + len(self.scalars)\n            gl.glEnableVertexAttribArray(i)\n            gl.glVertexAttribPointer(i, self.vert_sizes[i], gl.GL_FLOAT,"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the OpenGL context to match the camera's width and height\n        eglctx.resize_context(camera.width, camera.height)\n\n        # Set the viewport to the current size of the OpenGL context\n        gl.glViewport(0, 0, eglctx.width, eglctx.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the modelview and projection matrices\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadMatrixd(camera.modelview.m)\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadMatrixd(camera.projection.m)\n\n        # Set the shader program to use\n        use_gl_program(self.mesh_program)\n\n        # Set the uniforms for the shader program\n        self.set_uniforms()\n\n        # Render the mesh\n        self.render_mesh(eglctx)\n\n        # Return the rendered image\n        return eglctx.read_image()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera's position, orientation, and FOV\n        gl.glMatrixMode(gl.GL_PROJECTION_MATRIX)\n        gl.glLoadIdentity()\n        gl.glFrustum(\n            -camera.w / 2, camera.w / 2,\n            -camera.h / 2, camera.h / 2,\n            camera.near, camera.far\n        )\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n        gl.glTranslatef(-camera.x, -camera.y, -camera.z)\n        gl.glRotatef(camera.ry, 0, 1, 0)\n        gl.glRotatef(camera.rx, 1, 0, 0)\n        gl.glRotatef(camera.rz, 0, 0, 1)\n\n        # Set the camera's position and orientation\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n        gl.glTranslatef(0.0, 0.0, -1.0)\n        gl.glRotatef(camera.ry, 0, 1, 0)\n        gl.glRotatef(camera.rx, 1, 0, 0)\n        gl.glRotatef(camera.rz, 0, 0, 1)\n        gl.glRotatef(camera.pitch, 1, 0, 0)\n        gl.glRotatef(camera.yaw, 0, 0, 1)\n\n        # Set the viewport\n        gl.glViewport(0, 0, eglctx.width, eglctx.height)\n\n        # Clear the buffer\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the program\n        gl.glUseProgram(self.mesh_program)\n\n        # Set the vertex and color attributes\n        gl.glVertexAttrib"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the OpenGL state\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glUseProgram(self.mesh_program)\n\n        # Set the model matrix\n        gl.glUniformMatrix4fv(self.uniforms['model'], 1, GL_FALSE, glm.value_ptr(camera.model))\n\n        # Set the view matrix\n        gl.glUniformMatrix4fv(self.uniforms['view'], 1, GL_FALSE, glm.value_ptr(camera.view))\n\n        # Set the projection matrix\n        gl.glUniformMatrix4fv(self.uniforms['proj'], 1, GL_FALSE, glm.value_ptr(camera.projection))\n\n        # Set the shading options\n        gl.glUniform1i(self.uniforms['shade_flat'], int(self.shade_flat))\n        gl.glUniform1f(self.uniforms['point_radius'], self.point_radius)\n        gl.glUniform1i(self.uniforms['render_normal'], int(self.render_normal))\n\n        # Set the vertex data\n        gl.glVertexAttribPointer(self.mesh_program.attrib_location[0], self.vert_sizes[0], self.vert_gl_types[0], 0, 0, self.verts_data)\n\n        # Set the color data\n        if self.colors is not None:\n            gl.glVertexAttribPointer(self.mesh_program.attrib_location[1], self.vert_sizes[1], self.vert_gl_types[1], 0, 0, self.colors.data_ptr())\n\n        # Set the normal data\n        if self.normals is not None:\n            gl.glVertexAttribPointer(self.mesh_program.attrib_location[2], self.vert_sizes[2], self.vert_gl_types[2], 0, 0, self.normals.data_ptr())\n\n        # Bind the buffers\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.mesh_buffer_id)\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.faces_buffer"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera's projection and view matrices\n        eglctx.set_modelview_matrix(camera.view_matrix)\n        eglctx.set_projection_matrix(camera.proj_matrix)\n\n        # Set the viewport\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the clear color\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n\n        # Clear the color and depth buffers\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the shader program\n        gl.glUseProgram(self.mesh_program)\n\n        # Set the shader uniforms\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, b'u_modelview_matrix'), 1, False, glm.value_ptr(camera.view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, b'u_proj_matrix'), 1, False, glm.value_ptr(camera.proj_matrix))\n\n        # Enable the vertex array\n        gl.glEnableClientState(gl.GL_VERTEX_ARRAY)\n\n        # Bind the vertex buffer\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n\n        # Set the vertex data\n        gl.glVertexPointer(self.vert_size, self.vert_gl_types[0], self.vert_size * ctypes.c_void_p.itemsize, 0)\n        # gl.glVertexPointer(self.vert_size, gl.GL_FLOAT, self.vert_size * ctypes.c_void_p.itemsize, 0)\n\n        # Enable the color array\n        gl.glEnableClientState(gl.GL_COLOR_ARRAY)\n\n        # Bind the color buffer\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo_colors)\n\n        # Set the color data\n        gl.glColorPointer(3, gl.GL_FLOAT"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize_for_camera(camera)\n\n        # Set the camera's projection and view matrices\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadMatrixd(camera.projection_matrix.to_gl_matrix().to_numpy().T.flatten())\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadMatrixd(camera.view_matrix.to_gl_matrix().to_numpy().T.flatten())\n\n        # Set the shader program\n        use_gl_program(self.mesh_program)\n        gl.glUseProgram(self.mesh_program)\n\n        # Set the texture\n        # gl.glActiveTexture(gl.GL_TEXTURE0)\n        # gl.glBindTexture(gl.GL_TEXTURE_2D, self.texture)\n\n        # Set the uniform values\n        self.set_uniforms()\n\n        # Draw the mesh\n        self.draw_mesh()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh instance using the camera's settings\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize_window(camera.width, camera.height)\n\n        # Update the camera settings\n        self.update_camera_uniforms(camera)\n\n        # Set up the rendering program\n        self.setup_render_program()\n\n        # Render the mesh\n        self.render()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.resize_context(camera.width, camera.height)\n\n        # Set the viewport to the full size of the rendering context\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the camera's view matrix\n        # gl.glLoadMatrix4d(camera.view_matrix)\n        mat = camera.view_matrix.reshape(1, 4, 4)\n        mat = mat.numpy()\n        gl.glUnmapNamedBuffer(self.view_matrix_id, gl.GL_MAP_WRITE_BIT)\n        gl.glBufferSubData(gl.GL_UNIFORM_BUFFER, 0, mat.nbytes, mat)\n        gl.glMapNamedBufferRange(self.view_matrix_id, 0, mat.nbytes, gl.GL_MAP_WRITE_BIT)\n        gl.glUseProgram(self.program_id)  # Use the program\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n\n        # Set the camera's projection matrix\n        # gl.glLoadMatrix4d(camera.projection_matrix)\n        mat = camera.projection_matrix.reshape(1, 4, 4)\n        mat = mat.numpy()\n        gl.glUnmapNamedBuffer(self.proj_matrix_id, gl.GL_MAP_WRITE_BIT)\n        gl.glBufferSubData(gl.GL_UNIFORM_BUFFER, 0, mat.nbytes, mat)\n        gl.glMapNamedBufferRange(self.proj_matrix_id, 0, mat.nbytes, gl.GL_MAP_WRITE_BIT)\n\n        # Set the camera's intrinsics\n        gl.glUnmapNamedBuffer(self.intrinsic_id, gl.GL_MAP_WRITE_BIT)\n        gl.glBufferSubData(gl.GL_UNIFORM_BUFFER, 0, self.intrinsic_data.nbytes, self.intrinsic_data)\n        gl.glMapNamedBufferRange(self.intrinsic_id, 0, self."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the EGL context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n        # Create the projection matrix for the camera\n        proj_mat = camera.get_proj_mat()\n        # Set the projection matrix in the shader\n        self.uniforms.proj_mat = proj_mat.to(self.compute_device)\n        # Set the camera position in the shader\n        self.uniforms.cam_pos = camera.position.to(self.compute_device)\n        # Set the camera frustum in the shader\n        self.uniforms.frustum = camera.frustum.to(self.compute_device)\n        # Set the camera FOV in the shader\n        self.uniforms.FOV = camera.FOV.to(self.compute_device)\n        # Set the camera aspect ratio in the shader\n        self.uniforms.aspect = camera.aspect.to(self.compute_device)\n        # Set the camera near and far planes in the shader\n        self.uniforms.near = camera.near.to(self.compute_device)\n        self.uniforms.far = camera.far.to(self.compute_device)\n        # Set the camera view matrix in the shader\n        self.uniforms.view_mat = camera.get_view_mat().to(self.compute_device)\n        # Set the camera up vector in the shader\n        self.uniforms.cam_up = camera.up.to(self.compute_device)\n        # Set the camera look_at vector in the shader\n        self.uniforms.look_at = camera.look_at.to(self.compute_device)\n        # Set the camera right vector in the shader\n        self.uniforms.cam_right = camera.right.to(self.compute_device)\n\n        # Render the Mesh instance using the specified camera settings\n        self.render(eglctx)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Update the camera's projection and view matrices\n        eglctx.update_camera(camera)\n        # Update the uniform values\n        self.uniforms = dotdict(\n            proj_mat=eglctx.proj_mat,\n            view_mat=eglctx.view_mat,\n            model_mat=eglctx.model_mat,\n        )\n\n        # Update the vertex buffer\n        self.update_gl_buffers()\n\n        # Bind the program and the uniform values\n        gl.glUseProgram(self.mesh_program)\n        self.update_uniforms()\n\n        # Render the mesh\n        gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.shape[0])\n        # gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.shape[0])\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # TODO: Add support for other camera types\n        if self.visible:\n            eglctx.resize(camera.width, camera.height)\n\n            # Set the model-view-projection matrix\n            mvp = camera.get_matrix()\n            # gl.glLoadMatrixd(mvp.to_numpy())\n            gl.glMultMatrixd(mvp.to_numpy())\n\n            # Bind the mesh buffers\n            gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vert_id)\n            gl.glEnableVertexAttribArray(0, self.vert_gl_types[0])\n            gl.glVertexAttribPointer(0, self.vert_sizes[0], gl.GL_FLOAT, self.vert_size * self.verts.element_size(), ctypes.c_void_p(0))\n            if self.colors is not None:\n                gl.glEnableVertexAttribArray(1, self.vert_gl_types[1])\n                gl.glVertexAttribPointer(1, self.vert_sizes[1], gl.GL_FLOAT, self.vert_size * self.verts.element_size(), ctypes.c_void_p(self.verts.element_size()))\n            if self.normals is not None:\n                gl.glEnableVertexAttribArray(2, self.vert_gl_types[2])\n                gl.glVertexAttribPointer(2, self.vert_sizes[2], gl.GL_FLOAT, self.vert_size * self.verts.element_size(), ctypes.c_void_p(self.verts.element_size() * 2))\n\n            # Bind the program\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glUseProgram(self.point_program)\n            else:\n                gl.glUseProgram(self.mesh_program)\n\n            # Set the program uniforms\n            gl.glUniformMatrix4fv(self.uniforms.mvp.location, 1, gl.GL_FALSE, mvp.to_numpy().tobytes())\n\n            # Render\n            gl.glDrawElements(self.render_type.value, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n\n            # Unbind the buffers"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the rendering program\n        gl.glUseProgram(self.mesh_program)\n\n        # Load the mesh data into the GPU\n        for i, v in enumerate(self.vert_gl_types):\n            if self.verts.dtype == torch.half:\n                # MARK: This is a bit of a hack to make sure the data is not copied\n                # We want to use half precision for the normals\n                # But we don't want to copy the data to the GPU\n                # So we're going to cast the normals to float and then to half\n                # This is a bit of a hack\n                self.normals = self.normals.type(torch.float32)\n            self.verts = to_cuda(self.verts, self.compute_device, self.vert_gl_types[i])\n            self.normals = to_cuda(self.normals, self.compute_device, self.vert_gl_types[i])\n            self.colors = to_cuda(self.colors, self.compute_device, self.vert_gl_types[i])\n            self.colors = self.colors.to(self.verts.device)  # TODO: remove this\n\n        # Set the uniform values\n        self.set_uniforms(camera)\n\n        # Set the vertex and normal data\n        self.set_vertex_data()\n        self.set_normal_data()\n\n        # Set the color data\n        self.set_color_data()\n\n        # Set the face data\n        self.set_face_data()\n\n        # Render the mesh\n        self.render()\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    if isinstance(bert_config, PretrainedConfig):\n        bert_config = bert_config.to_dict()  # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    if isinstance(bert_config, NomicBertConfig):\n        return bert_config\n\n    if bert_config.is_encoder_decoder:\n        raise ValueError(\n            \"You are instanctiating a Nomic model with a BERT configuration that is instanctiating a BERT archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n\n    # General\n    for key, value in bert_config._asdict().items():\n        nomic_config.__setattr__(key, value)\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict(bert_config._asdict())\n\n    # embrave_config.add_to_dict("}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n\n    # Adapt the input embracer\n    nomic_config.input_embeddings.word_embeddings = bert_config.get(\"word_embeddings\", None)\n    nomic_config.input_embeddings.position_embeddings = bert_config.get(\n        \"position_embeddings\", None\n    )\n\n    # Adapt the output embracer\n    nomic_config.output_embeddings fundament_embeddings = bert_config.get(\n        \"output_embeddings\", None\n    )\n    if fundament_embeddings is not None:\n        nomic_config.output_embeddings = fundament_embeddings\n\n    # Adapt the embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embracer embra"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig.from_dict(bert_config.to_dict())\n\n    if bert_config.is_encoder_decoder:\n        config.is_encoder_decoder = True\n    else:\n        config.is_encoder_decoder = False\n\n    if bert_config.is_decoder:\n        config.is_decoder = True\n    else:\n        config.is_decoder = False\n\n    if bert_config.is_encoder:\n        config.is_encoder = True\n    else:\n        config.is_encoder = False\n\n    if bert_config.is_auto_model:\n        config.is_auto_model = True\n    else:\n        config.is_auto_model = False\n\n    if bert_config.is_auto_encoder:\n        config.is_auto_encoder = True\n    else:\n        config.is_auto_encoder = False\n\n    if bert_config.is_auto_decoder:\n        config.is_auto_decoder = True\n    else:\n        config.is_auto_decoder = False\n\n    if bert_config.is_encoder_decoder_auto:\n        config.is_encoder_decoder_auto = True\n    else:\n        config.is_encoder_decoder_auto = False\n\n    if bert_config.is_auto_encoder_decoder:\n        config.is_auto_encoder_decoder = True\n    else:\n        config.is_auto_encoder_decoder = False\n\n    if bert_config.is_encoder_auto_decoder:\n        config.is_encoder_auto_decoder = True\n    else:\n        config.is_encoder_auto_decoder = False\n\n    if bert_config.is_decoder_auto_encoder:\n        config.is_decoder_auto_encoder = True\n    else:\n        config.is_decoder_auto_encoder = False\n\n    if bert_config.is_auto_encoder_decoder_encoder:\n        config.is_auto_encoder_decoder_encoder = True\n    else:\n        config.is_auto_encoder_decoder_encoder = False\n\n    if bert_config.is_auto_encoder_encoder_decoder:\n        config.is_auto_encoder"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    if bert_config.is_encoder_decoder:\n        raise ValueError(\n            \"bert_config.is_encoder_decoder must be set to False for Nomic models.\"\n        )\n    if bert_config.is_decoder:\n        raise ValueError(\n            \"bert_config.is_decoder must be set to False for Nomic models.\"\n        )\n\n    # BERT model configuraton\n    config_dict = bert_config._to_dict()\n\n    # BERT archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi archi"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_positions=bert_config.n_positions,\n        n_embd=bert_config.n_embd,\n        n_head=bert_config.n_head,\n        n_layer=bert_config.n_layer,\n        n_embd_per_head=bert_config.n_embd_per_head,\n        n_head_per_layer=bert_config.n_head_per_layer,\n        n_layer_per_head=bert_config.n_layer_per_head,\n    )\n\n    for key rech_key in bert_config._keys_to_names.keys():\n        nomic_config[rech_key] = rech_key\n\n    return nomic_config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        type_vocab_size=bert_config.type_vocab_size,\n        n_layers=bert_config.n_layer,\n        n_heads=bert_config.n_head,\n        n_embd=bert_config.n_embd,\n        n_embd_per_head=bert_config.n_embd_per_head,\n        n_embd_type=bert_config.n_embd_type,\n        n_embd_cls=bert_config.n_embd_cls,\n        n_embd_ffn=bert_config.n_embd_ffn,\n        n_embd_type_ffn=bert_config.n_embd_type_ffn,\n        n_embd_cls_ffn=bert_config.n_embd_cls_ffn,\n        n_embd_output=bert_config.n_embd_output,\n        n_embd_type_output=bert_config.n_embd_type_output,\n        n_embd_cls_output=bert_config.n_embd_cls_output,\n        n_embd_output_type=bert_config.n_embd_output_type,\n        n_embd_output_cls=bert_config.n_embd_output_cls,\n        n_embd_output_type_cls=bert_config.n_embd_output_type_cls,\n        n_embd_output_type_ffn=bert_config.n_embd_output_type_ffn,\n        n_embd_output_cls_ffn=bert_config.n_embd_output_cls_ffn,\n        n_embd_output_type_cls_ffn=bert_config.n_embd_output_type_cls_ffn,\n        n_embd_output_type_output=bert_config.n_embd_output_type_output,\n        n_embd_output"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize new configuration\n    config = NomicBertConfig()\n\n    # Copy configuraton settings from BERT\n    for attr_name fundament_name, fundament_value in fundament_class(bert_config).items():\n        if fundament_name in fundament_class(config):\n            setattr(config, fundament_name, fundament_value)\n\n    # Adapt configuraton settings for Nomic\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class(bert_config).is_nomic_model\n    config.is_nomic_model = fundament_class("}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        d_model=bert_config.hidden_size,\n        n_embd=bert_config.hidden_size,\n        n_head=bert_config.num_attention_heads,\n        n_layer=bert_config.num_hidden_layers,\n        d_head=bert_config.hidden_size // bert_config.num_attention_heads,\n    )\n\n    if hasattr(bert_config, \"intermediate_size\"):\n        nomic_config.d_ffn=bert_config.intermediate_size\n    else:\n        nomic_config.d_ffn=bert_config.hidden_size * 4\n\n    if hasattr(bert_config, \"hidden_act\"):\n        nomic_config.activation_function = bert_config.hidden_act\n    else:\n        nomic_config.activation_function = \"gelu\"\n\n    if hasattr(bert_config, \"hidden_dropout\"):\n        nomic_config.attention_dropout = bert_config.hidden_dropout\n        nomic_config.dropout = bert_config.hidden_dropout\n        nomic_config.activation_dropout = bert_config.hidden_dropout\n    else:\n        nomic_config.attention_dropout = 0.0\n        nomic_config.dropout = 0.1\n        nomic_config.activation_dropout = 0.1\n\n    if hasattr(bert_config, \"initializer_range\"):\n        nomic_config.initializer_range = bert_config.initializer_range\n    else:\n        nomic_config.initializer_range = 0.02\n\n    if hasattr(bert_config, \"is_encoder\"):\n        nomic_config.is_encoder = bert_config.is_encoder\n    else:\n        nomic_config.is_encoder = True\n\n    if hasattr(bert_config, \"is_decoder\"):\n        nomic_config.is_decoder = bert_config.is_decoder\n    else:\n        nomic_config.is_decoder = False\n\n    if hasattr(bert_config, \"is_classifier\"):"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        attention_probs_dropout_type=bert_config.attention_probs_dropout_type,\n        attention_probs_layer_norm_eps=bert_config.attention_probs_layer_norm_eps,\n        attention_probs_layer_norm_weight_decay=bert_config.attention_probs_layer_norm_weight_decay,\n        attention_probs_layer_norm_weight_init=bert_config.attention_probs_layer_norm_weight_init,\n        attention_probs_type=bert_config.attention_probs_type,\n        attention_probs_weight_decay=bert_config.attention_probs_weight_decay,\n        attention_probs_weight_init=bert_config.attention_probs_weight_init,\n        bidirectional=bert_config.bidirectional,\n        classifier_dropout_prob=bert_config.classifier_dropout_prob,\n        classifier_dropout_type=bert_config.classifier_dropout_type,\n        classifier_layer_norm_eps=bert_config.classifier_layer_norm_eps,\n        classifier_layer_norm_weight_decay=bert_config.classifier_layer_norm_weight_decay,\n        classifier_layer_norm_weight_init=bert_config.classifier_layer_norm_weight_init,\n        classifier_type=bert_config.classifier_type,\n        classifier_weight_decay=bert_config.classifier_weight_decay,\n        classifier_weight_init=bert_config.classifier_weight_init,\n        d_model=bert_config.d_model,\n        dropout_prob=bert_config.dropout_prob,\n        dropout_type=bert_config.dropout_type,\n        d_model_per_head=bert_config.d_model_per_head,\n        feedforward_dropout_prob=bert_config.feedforward_dropout_prob,\n        feedforward_dropout_type=bert_config.feedforward_dropout_type,\n        feedforward_layer_norm_eps=bert_config.feedforward_layer_norm_eps"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize a new NomicBertConfig object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_embd=bert_config.n_embd,\n        n_head=bert_config.n_head,\n        n_layer=bert_config.n_layer,\n        d_head=bert_config.d_head,\n        d_layer=bert_config.d_layer,\n        d_head_ffn=bert_config.d_head_ffn,\n        d_layer_ffn=bert_config.d_layer_ffn,\n        n_embd_ffn=bert_config.n_embd_ffn,\n        d_attn=bert_config.d_attn,\n        d_layer_attn=bert_config.d_layer_attn,\n        n_embd_attn=bert_config.n_embd_attn,\n        d_mlp=bert_config.d_mlp,\n        n_embd_mlp=bert_config.n_embd_mlp,\n        d_mlp_ffn=bert_config.d_mlp_ffn,\n        n_embd_mlp_ffn=bert_config.n_embd_mlp_ffn,\n        n_embd_mlp_attn=bert_config.n_embd_mlp_attn,\n        n_embd_mlp_layer=bert_config.n_embd_mlp_layer,\n        n_embd_mlp_ffn_layer=bert_config.n_embd_mlp_ffn_layer,\n        n_embd_mlp_attn_layer=bert_config.n_embd_mlp_attn_layer,\n        n_embd_mlp_layer_ffn=bert_config.n_embd_mlp_layer_ffn,\n        n_embd_mlp_attn_layer_ffn=bert_config.n_embd_mlp_attn_layer_ffn,\n        n_embd_mlp_layer_attn=bert_config.n_embd_mlp_layer_attn"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Copy the configuraton from the BertConfig\n    nomic_config = NomicBertConfig(\n        model_type=\"nomic_bert\",\n        vocab_size=bert_config.vocab_size,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        max_position_embeddings_for_lm_head=bert_config.max_position_embeddings,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        activation_function=bert_config.activation_function,\n        intermediate_activation_function=bert_config.activation_function,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        is_decoder=False,\n        is_encoder=True,\n        is_autoregressive=False,\n        is_autoregressive_for_lm_head=False,\n    )\n\n    # Adapt the configuraton for the Nomic model\n    nomic_config.is_encoder = bert_config.is_encoder\n    nomic_config.is_autoregressive = bert_config.is_autoregressive\n    nomic_config.is_autoregressive_for_lm_head = bert_config.is_autoregressive_for_lm_head\n\n    # Adapt the configuraton for the Nomic model\n    nomic_config.is_encoder = bert_config.is_encoder\n    nomic_config.is_autoregressive = bert_config.is_autoregressive\n    nomic_config.is_autoregressive_for_lm_head = bert_config.is_autoregressive_for_lm_head\n\n    # Adapt the configuraton for the Nomic model\n    nomic_config.is_encoder = bert_config.is_encoder\n    nomic_config.is_autoregressive = bert_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        max_position_embeddings_per_head=bert_config.max_position_embeddings_per_head,\n        max_position_embeddings_per_head_with_token=bert_config.max_position_embeddings_per_head_with_token,\n        max_position_embeddings_with_token=bert_config.max_position_embeddings_with_token,\n        max_position_embeddings_with_token_per_head=bert_config.max_position_embeddings_with_token_per_head,\n    )\n\n    # Copy unannotated configurational arguments\n    nomic_config.update(bert_config)\n    return nomic_config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize the new configuration class\n    nomic_config = NomicBertConfig()\n\n    # Copy over the inherited settings\n    for key fundament, value fundament in bert_config.__dict__.items():\n        if fundament not in NOMIC_CONFIG_MAPPING:\n            setattr(nomic_config, fundament, fundament)\n\n    # Adapt the configuraton\n    nomic_config.is_nomic = fundament\n    nomic_config.num_labels = bert_config.num_labels\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.dropout = bert_config.dropout\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config."}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        embedding_size=bert_config.hidden_size,\n        num_embeddings=bert_config.vocab_size,\n        num_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        hidden_size=bert_config.hidden_size,\n        num_classes=bert_config.num_labels,\n        num_embeddings=bert_config.vocab_size,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        final_dropout_prob=bert_config.classifier_dropout,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        max_position_embeddings_for_embedding=bert_config.max_position_embeddings,\n        num_embeddings_for_embedding=bert_config.vocab_size,\n        embedding_size_for_embedding=bert_config.hidden_size,\n        hidden_size_for_embedding=bert_config.hidden_size,\n        max_position_embeddings_for_prediction=bert_config.max_position_embeddings,\n        max_position_embeddings_for_prediction=bert_config.max_position_embeddings,\n    )\n\n    if bert_config.is_encoder_decoder:\n        nomic_config.is_encoder_decoder = True\n\n    if bert_config.is_decoder:\n        nomic_config.is_decoder = True\n\n    if bert_config.is_encoder:\n        nomic_config.is_encoder = True\n\n    if bert_config.is_encoder_decoder:\n        nomic_config.is_encoder = True\n\n    if bert_config.is_encoder_decoder:\n        nomic_config.is_decoder = True\n\n    if bert_config.is_decoder:\n        nom"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    if bert_config.__class__ == BertConfig:\n        config = NomicBertConfig.from_dict(bert_config.to_dict(), abnormals=False)\n        config.num_labels = bert_config.num_labels\n    else:\n        config = NomicBertConfig.from_dict(bert_config.to_dict())\n\n    config.is_decoder = bert_config.is_decoder\n    config.is_encoder = bert_config.is_encoder\n    config.is_classifier = bert_config.is_classifier\n\n    if bert_config.is_decoder:\n        config.is_encoder = False\n        config.is_classifier = False\n\n    if bert_config.is_encoder:\n        config.is_decoder = False\n        config.is_classifier = bert_config.is_classifier\n\n    if bert_config.is_classifier:\n        config.is_encoder = False\n        config.is_decoder = False\n\n    return config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Adapt the configuraton to the Nomic model's requirements\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.hidden_size * 4,\n        initializer_range=bert_config.initializer_range,\n        dropout=bert_config.hidden_dropout_prob,\n        attention_dropout=bert_config.attention_probs_dropout_prob,\n        activation_dropout=bert_config.activation_dropout,\n        hidden_act=bert_config.hidden_act,\n        num_labels=bert_config.num_labels,\n        is_decoder=False,\n        max_length=bert_config.max_position_embeddings,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        max_position_embeddings_length=bert_config.max_position_embeddings,\n        is_encoder=True,\n        is_classifier=False,\n        is_lm_head=False,\n        is_classifier_head=False,\n        is_lm_head_decoder=False,\n        is_classifier_head_decoder=False,\n        is_encoder_decoder=False,\n        is_decoder_encoder=False,\n        is_decoder_classifier=False,\n        is_encoder_classifier=False,\n        is_decoder_lm=False,\n        is_encoder_lm=False,\n        is_encoder_decoder_lm=False,\n        is_encoder_decoder_classifier=False,\n        is_encoder_encoder_decoder_lm=False,\n        is_encoder_encoder_decoder_classifier=False,\n        is_encoder_encoder_decoder_encoder_classifier=False,\n    )\n\n    # Adapt the configuraton to the Nomic model's requirements\n    nomic_config.is_decoder = True\n    nomic_config.is_encoder = False\n    nomic_config.is_classifier = False"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize a new NomicBertConfig object with the same archiecture as the BERT model.\n    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        n_positions=bert_config.n_positions,\n        n_embd=bert_config.n_embd,\n        n_head=bert_config.n_head,\n        n_layer=bert_config.n_layer,\n        n_type_embd=bert_config.n_type_embd,\n        n_class=bert_config.n_class,\n    )\n    # Copy over the rest of the configuration from BERT.\n    config.merge_from_other_config(bert_config)\n    # Adapt configuratiom to Nomic model\n    config.is_nomic = True\n    config.add_type_embeddings = True\n    config.add_position_embeddings = True\n    config.add_layer_embeddings = True\n    config.add_class_embeddings = True\n    config.add_class_embeddings_at_first_layer = True\n    config.add_type_embeddings_at_first_layer = True\n    config.add_position_embeddings_at_first_layer = True\n    config.add_class_embeddings_at_last_layer = True\n    config.add_type_embeddings_at_last_layer = True\n    config.add_position_embeddings_at_last_layer = True\n    config.add_class_embeddings_at_all_layers = True\n    config.add_type_embeddings_at_all_layers = True\n    config.add_position_embeddings_at_all_layers = True\n    config.add_layer_embeddings_at_all_layers = True\n    config.add_class_embeddings_at_all_layers = True\n    config.add_type_embeddings_at_all_layers = True\n    config.add_position_embeddings_at_all_layers = True\n    config.add_layer_embeddings_at_all_layers = True\n    config.add_class_embeddings_at_first_layer = True\n    config.add_type_embeddings_at_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig()\n\n    # Copy the configuraton of the BERT model\n    config.is_decoder = bert_config.is_decoder\n    config.is_encoder = bert_config.is_encoder\n    config.is_encoder_decoder = bert_config.is_encoder_decoder\n    config.is_decoder_only = bert_config.is_decoder_only\n\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_heads\n\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout = bert_config.hidden_dropout\n    config.attention_dropout = bert_config.attention_dropout\n    config.layerdrop = bert_config.layerdrop\n\n    config.initializer_range = bert_config.initializer_range\n    config.n_ctx = bert_config.n_ctx\n\n    config.use_norm_before_attention = bert_config.use_norm_before_attention\n    config.use_norm_after_attention = bert_config.use_norm_after_attention\n\n    config.use_relative_position_embeddings = bert_config.use_relative_position_embeddings\n    config.use_relative_position_bias = bert_config.use_relative_position_bias\n\n    config.num_labels = bert_config.num_labels\n    config.is_encoder_decoder_only = bert_config.is_encoder_decoder_only\n\n    # Adapt the configuraton for the Nomic model\n    config.is_encoder_only = bert_config.is_encoder_only\n    config.is_decoder_only = bert_config.is_decoder_only\n    config.is_encoder_decoder = bert_config.is_encoder_decoder\n\n    config.is_encoder_decoder_only = bert_config.is_encoder_decoder_only\n\n    config.is_encoder_only = bert_config.is_encoder_only\n    config.is_decoder_only = bert_config"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select program\n        program = self.point_program if self.render_type == Mesh.RenderType.POINTS else self.mesh_program\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the correct shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Draw points\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Draw lines\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Draw triangles\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # Draw quads\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the appropriate program to render the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_POINTS, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_QUADS, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces is None:"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Bind the program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vao\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Draw points\n            gl.glPointSize(self.point_radius)\n            if len(self.faces):\n                # Indexed points\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                # Non-indexed points\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Draw lines\n            if len(self.faces):\n                # Indexed lines\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                # Non-indexed lines\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Draw triangles\n            if len(self.faces):\n                # Indexed triangles\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                # Non-indexed triangles\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.faces))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # Draw quads\n            if len(self.faces):\n                # Indexed quads\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                #"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if mesh is visible\n        if not self.visible:\n            return\n\n        # Use program\n        gl.glUseProgram(self.program_id)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.nelement())\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.verts.nelement())\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.nelement())\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.verts.nelement())\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, self.verts.nelement())\n        else:\n            raise ValueError(f'Unknown render"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Set up the correct shader program\n        program = self.mesh_program if self.render_type == Mesh.RenderType.TRIS else self.point_program\n\n        # Upload uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the correct draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.size(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawArrays(gl.GL_QUADS, 0, self.verts.size(0))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, self.verts.size(0))\n        else:\n            log(yellow(f'Unsupported mesh type: {self.render_type} for rendering'))\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray("}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the shader program\n        program.use()\n\n        # Upload uniforms to the GPU\n        self.upload_gl_uniforms(camera, program)\n\n        # Bind the vertex array object (VAO)\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the OpenGL draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts) // 2)\n            else:\n                gl.glDrawElements(gl.GL_LINE_LOOP, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts) // 3)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts) // 4)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts) // 3)\n            "}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the correct shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n            # gl.glPointSize(self.point_radius * 2.0)\n        else:\n            program = self.mesh_program\n        use_gl_program(program)\n\n        # Upload the necessary uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        self.bind_gl_buffers()\n\n        # Issue the correct draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            # gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                # gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, 0)\n                gl.glDrawElements(gl.GL_LINES, self.faces.shape[0], gl.GL_UNSIGNED_INT, 0)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                # gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, 0)\n                gl.glDrawElements(gl.GL_TRIANGLES, self.faces.shape[0], gl.GL_UNSIGNED_INT, 0)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces),"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set up the correct program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        elif self.render_type in [Mesh.RenderType.LINES, Mesh.RenderType.TRIS, Mesh.RenderType.STRIPS]:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vao)\n\n        # Render\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Point rendering\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Line rendering\n            gl.glDrawArrays(gl.GL_LINES, 0, self.faces.shape[0] * 2)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Triangle rendering\n            gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.faces.shape[0])\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            # Triangle strip rendering\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, self.faces.shape[0] + 2)\n\n        # Unbind vertex array object\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Set the program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Set the point size\n        gl.glPointSize(self.point_radius)\n\n        # Set the face culling\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glCullFace(gl.GL_NONE)\n        else:\n            gl.glCullFace(gl.GL_BACK)\n\n        # Draw the mesh\n        if self.faces is None:\n            # Draw non-indexed\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            else:\n                gl.glDrawArrays(self.render_type.value, 0, len(self.verts))\n        else:\n            # Draw indexed\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                gl.glDrawElements(self.render_type.value, len(self.faces), gl.GL_UNSIGNED_INT, self.ebo)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the program\n        gl.glUseProgram(program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vao)\n\n        # Set the vertex attributes\n        for i, s in enumerate(self.vert_sizes):\n            gl.glVertexAttribPointer(program.attrib_locations['vert_pos'],\n                                     s,\n                                     gl.GL_FLOAT,\n                                     self.vert_gl_types[i],\n                                     self.vert_size * self.vert_gl_types[0],\n                                     i * self.vert_size * self.vert_gl_types[0])\n\n        # Set the vertex colors\n        if self.render_type == Mesh.RenderType.POINTS:\n            if self.colors is not None:\n                gl.glVertexAttribPointer(program.attrib_locations['vert_color'],\n                                         3,\n                                         gl.GL_FLOAT,\n                                         gl.GL_FLOAT,\n                                         self.vert_size * gl.GL_FLOAT,\n                                         self.vert_size * self.vert_gl_types[0])\n            else:\n                gl.glVertexAttribPointer(program.attrib_locations['vert_color'],\n                                         3,\n                                         gl.GL_FLOAT,\n                                         gl.GL_FLOAT,\n                                         self.vert_size * gl.GL_FLOAT,\n                                         self.vert_size * self.vert_gl_types[0])\n\n        # Set the vertex normals\n        if self.normals is not None:\n            gl.glVertexAttribPointer(program.attrib_locations['vert_norm'],\n                                     3,\n                                     gl.GL_FLOAT,\n                                     gl.GL_FLOAT,\n                                     self.vert_size * gl.GL_FLOAT,\n                                     self.vert_size"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # If the mesh is not visible, do not render\n        if not self.visible:\n            return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload the view and projection matrices to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vao)\n\n        # Set the vertex attribute pointers for position, color, and normals\n        gl.glVertexAttribPointer(0, self.vert_sizes[0], self.vert_gl_types[0], self.vert_size, 0)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glVertexAttribPointer(1, self.vert_sizes[1], self.vert_gl_types[1], self.vert_size, self.vert_sizes[0] * ctypes.sizeof(ctypes.c_float))\n            gl.glVertexAttribPointer(2, self.vert_sizes[2], self.vert_gl_types[2], self.vert_size, (self.vert_sizes[0] + self.vert_sizes[1]) * ctypes.sizeof(ctypes.c_float))\n\n        # Bind the element buffer object of the mesh\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n\n        # Set the index pointer for the mesh\n        gl.glDrawElements(self.face_type, len(self.faces), gl.GL_UNSIGNED_INT, 0)\n        # gl.glDrawElements(self.face_type, len(self.faces), gl.GL_UNSIGNED_INT, ctypes.c_void_p(self.faces_data))\n\n        # Unbind the vertex array object to clean up\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, 0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n        # MARK: Uncomment this to disable the mesh rendering\n        # return\n\n        # Use the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n            # gl.glUseProgram(self.point_program)\n            self.upload_gl_uniforms(camera)\n        else:\n            program = self.mesh_program\n            # gl.glUseProgram(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.size(1) == 3:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n            elif self.faces.size(1) == 4:\n                gl.glDrawElements(gl.GL_QUADS, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                # MARK: Uncomment this to disable the mesh rendering\n                return\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.size(1) == 2:\n                gl.glDrawElements(gl.GL_LINES, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n            elif self.faces.size(1) == 4:\n                gl.glDrawElements(gl.GL_LINE_LOOP, self.faces.size(0), gl.GL_UNSIGNED_INT, self.ebo)\n            else:\n                # MARK: Uncomment this to disable the mesh rendering\n                return\n        elif self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.size(0))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        # log(f'Rendering {self.name} ({self.verts.size(0)})')\n        program = self.mesh_program if self.render_type == Mesh.RenderType.POINTS else self.point_program\n\n        # Set up the viewport\n        gl.glViewport(0, 0, camera.W, camera.H)\n\n        # Set the program\n        use_gl_program(program)\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vao\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vao)\n\n        # Set the vertex attributes\n        gl.glEnableVertexAttribArray(0)\n        gl.glVertexAttribPointer(0, 3, self.vert_gl_types[0], 0, 0, 0)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glEnableVertexAttribArray(1)\n            gl.glVertexAttribPointer(1, 3, self.vert_gl_types[1], 0, 0, self.n_verts_bytes)\n        if self.render_type == Mesh.RenderType.TRIS or self.render_type == Mesh.RenderType.STRIPS:\n            gl.glEnableVertexAttribArray(1)\n            gl.glVertexAttribPointer(1, 3, self.vert_gl_types[1], 0, 0, self.n_verts_bytes)\n        if self.render_type == Mesh.RenderType.TRIS or self.render_type == Mesh.RenderType.LINES:\n            gl.glEnableVertexAttribArray(2)\n            gl.glVertexAttribPointer(2, 3, self.vert_gl_types[2], 0, 0, self.n_verts_bytes + self.vert_sizes[1] * self.verts.element_size())\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) == 0:\n                gl.gl"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set the program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the program\n        program.use()\n        gl.glUseProgram(program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        self.verts_vao.bind()\n\n        # Draw\n        # TODO: Make this a method\n        if self.render_type == Mesh.RenderType.POINTS:\n            if len(self.verts) > 0:\n                if self.point_radius > 0:\n                    gl.glPointSize(self.point_radius)\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            else:\n                log(red('Warning: No vertex data for points'))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces is None:\n                gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the appropriate shader program based on the render type\n        program = self.mesh_program if self.render_type in [Mesh.RenderType.TRIS, Mesh.RenderType.LINES, Mesh.RenderType.STRIPS] else self.point_program\n        use_gl_program(program)\n\n        # Upload the uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glUseProgram(program)\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawArrays(gl.GL_LINES, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawArrays(gl.GL_QUADS, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, self.verts.shape[0])\n        else:\n            raise NotImplementedError(f'Rendering type {self.render_type} is not supported')\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n        eglctx = eglctxmanager.current_context()\n        eglctx.make_current()\n        eglctx.resize(camera.W, camera.H)\n\n        # Set program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Set uniforms\n        self.upload_gl_uniforms(program, camera)\n\n        # Bind VAO\n        vao = gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            if self.faces is not None:\n                # Draw points with indices\n                gl.glDrawElements(gl.GL_POINTS, len(self.faces), self.vert_gl_types[2], self.ebo)\n            else:\n                # Draw points without indices\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if self.faces is not None:\n                # Draw triangles with indices\n                gl.glDrawElements(self.render_type.value, len(self.faces), self.vert_gl_types[2], self.ebo)\n            else:\n                # Draw triangles without indices\n                gl.glDrawArrays(self.render_type.value, 0, len(self.verts))\n\n        # Unbind VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # TODO: Add a check for the current mesh's visibility\n        if not self.visible:\n            return\n\n        # Select the appropriate shader program\n        program = self.point_program if self.render_type == Mesh.RenderType.POINTS else self.mesh_program\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        self.bind_gl_buffers(camera)\n\n        # Issue the OpenGL draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.draw_points(camera)\n        elif self.render_type == Mesh.RenderType.LINES:\n            self.draw_lines(camera)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            self.draw_tris(camera)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            self.draw_quads(camera)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            self.draw_strips(camera)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set the program\n        program = self.point_program if self.render_type == Mesh.RenderType.POINTS else self.mesh_program\n\n        # Upload uniforms\n        self.upload_gl_uniforms(eglctx=eglctx, camera=camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        # MARK: This is a bit of a hack. We need to set up the program and draw in the same function\n        if self.render_type == Mesh.RenderType.POINTS:\n            # MARK: Need to change this to point sprites\n            # gl.glDrawArrays institutde of gl.glDrawArraysInstanced\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT)\n            # gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.n_faces_bytes)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT)\n        else:\n            log(red(f'Unknown render type: {self.render_type}'))\n\n        # Unbind VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # TODO: This function is not optimized for performance. It is currently only used for debugging purposes.\n        if not self.visible:\n            return\n\n        # Select the appropriate program to use\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n            # gl.glUseProgram(self.point_program)\n        else:\n            program = self.mesh_program\n            # gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms to the GPU\n        self.upload_gl_uniforms(program, camera)\n\n        # Bind the vertex array object\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vao)\n        gl.glEnableVertexAttribArray(0)\n        gl.glEnableVertexAttribArray(1)\n        gl.glEnableVertexAttribArray(2)\n        gl.glEnableVertexAttribArray(3)\n\n        # Render\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArraysInstanced(gl.GL_POINTS, 0, self.verts.shape[0], 1)\n        else:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.faces.shape[0], self.face_size, 0)\n\n        # Unbind the vertex array object\n        gl.glDisableVertexAttribArray(3)\n        gl.glDisableVertexAttribArray(2)\n        gl.glDisableVertexAttribArray(1)\n        gl.glDisableVertexAttribArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Check if ptr is a PyTorch tensor and convert it to a numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array and convert it to a PyTorch tensor if necessary\n        if isinstance(ptr, np.ndarray):\n            ptr = torch.from_numpy(ptr)\n\n        # Check if the input is a PyTorch tensor and convert it to a numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array and convert it to a PyTorch tensor if necessary\n        if isinstance(ptr, np.ndarray):\n            ptr = torch.from_numpy(ptr)\n\n        # Check if the input is a PyTorch tensor and convert it to a numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array and convert it to a PyTorch tensor if necessary\n        if isinstance(ptr, np.ndarray):\n            ptr = torch.from_numpy(ptr)\n\n        # Check if the input is a PyTorch tensor and convert it to a numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array and convert it to a PyTorch tensor if necessary\n        if isinstance(ptr, np.ndarray):\n            ptr = torch.from_numpy(ptr)\n\n        # Check if the input is a PyTorch tensor and convert it to a numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array and convert it to a PyTorch tensor if necessary\n        if isinstance(ptr, np.ndarray):\n            ptr = torch.from_numpy(ptr)\n\n        # Check if the input is a PyTorch tensor and convert it to a numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array and convert it to a PyTorch tensor if necessary\n        if isinstance(ptr, np"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert the data source to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            # Convert the PyTorch tensor to a numpy array\n            ptr = ptr.cpu().numpy()\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a numpy array or a PyTorch tensor.')\n\n        # Check if the data source is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('The data source must be a"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            # Convert the PyTorch tensor to a numpy array\n            ptr = ptr.cpu().numpy()\n        # Upload the numpy array to the texture\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glPixelStorei(gl.GL_UNPACK_ROW_LENGTH, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_ROWS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_IMAGES, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_ROWS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glPixelStorei(gl.GL_UNPACK_ROW_LENGTH, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_ROWS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_IMAGES, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_ROWS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glPixelStorei(gl.GL_UNPACK_ROW_LENGTH, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_ROWS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if w == 0 or h == 0:\n            w, h = self.W, self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # convert to numpy\n        if not isinstance(ptr, np.ndarray):\n            ptr = ptr.cpu().numpy()\n        if ptr.ndim == 3:\n            ptr = np.moveaxis(ptr, 0, -1)\n\n        # upload to texture\n        w = w or self.W\n        h = h or self.H\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n            if ptr.ndim == 3:\n                ptr = ptr.transpose(2, 0, 1)\n                ptr = ptr.astype(np.uint8)\n            else:\n                ptr = ptr.astype(np.uint8)\n        elif not isinstance(ptr, np.ndarray):\n            raise TypeError('The input ptr must be a numpy array or a PyTorch tensor.')\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Upload the image data to the texture\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if self.use_quad_cuda:\n            self.copy_to_texture(torch.from_numpy(ptr), x, y, w, h)\n        else:\n            from cuda import cudart\n            CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n            CHECK_CUDART_ERROR(cudart.cudaGraphicsResourceSetMapFlags(self.cu_tex, cudart.cudaGraphicsMapFlags.cudaGraphicsMapFlagsReadOnly))  # read only\n            CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n            CHECK_CUDART_ERROR(cudart.cudaMemcpy2DFromArray(cu_tex_arr,\n                                                            x * 4 * ptr.element_size(),\n                                                            y,\n                                                            ptr.data_ptr(),\n                                                            w * 4 * ptr.element_size(),\n                                                            w * 4 * ptr.element_size(),\n                                                            h,\n                                                            cudart.cudaMemcpyKind.cudaMemcpyDefault,\n                                                            torch.cuda.current_stream().cuda_stream))\n            CHECK_CUDART_ERROR(cudart.cudaGraphicsResourceSetMapFlags(self.cu_tex, cudart.cudaGraphicsMapFlags.cudaGraphicsMapFlagsUnmap))\n            CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        if ptr.ndim == 3:\n            ptr = ptr.reshape(h, w, 3)\n        elif ptr.ndim == 2:\n            ptr = ptr.reshape(h, w, 1)\n        else:\n            raise ValueError(f'Unsupported ptr.ndim: {ptr.ndim}')\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        if ptr.ndim == 3:\n            ptr = ptr[0]\n        if ptr.ndim == 2:\n            ptr = np.expand_dims(ptr, axis=0)\n        if ptr.ndim == 4:\n            ptr = ptr[0]\n\n        if ptr.dtype == np.int:\n            ptr = ptr.astype(np.uint8)\n        elif ptr.dtype == np.float32:\n            ptr = ptr.clip(0, 1)\n            ptr = 255 * np.ascontiguousarray(ptr, np.uint8)\n\n        ptr = np.ascontiguousarray(ptr)\n\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glPixelStorei(gl.GL_UNPACK_ROW_LENGTH, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_PIXELS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_SKIP_ROWS, 0)\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)  # 1\n        gl.glPixelStorei(gl.GL_UNPACK_CLIENT_STORAGE, 0)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not isinstance(ptr, np.ndarray):\n            ptr = ptr.cpu().numpy()\n        w = w or self.W\n        h = h or self.H\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if w == 0: w = self.W\n        if h == 0: h = self.H\n\n        # if ptr.shape[0] == 4:\n        #     ptr = ptr / 255\n\n        # if isinstance(ptr, torch.Tensor):\n        #     ptr = ptr.cpu().numpy()\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not isinstance(ptr, np.ndarray):\n            ptr = ptr.cpu().numpy()  # convert tensor to numpy array\n        if ptr.ndim == 3:\n            ptr = ptr.transpose(2, 0, 1)  # swap channels\n        w = w or self.W\n        h = h or self.H\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # TODO: add cuda support\n        if w == 0: w = self.W\n        if h == 0: h = self.H\n\n        if not isinstance(ptr, np.ndarray):\n            ptr = ptr.cpu().numpy()\n\n        # Get the texture data\n        texture = self.tex\n        texture_type = gl.GL_UNSIGNED_BYTE\n        texture_format = gl.GL_RGBA\n        if ptr.dtype == np.float32:\n            texture_type = gl.GL_FLOAT\n            texture_format = gl.GL_RGB\n\n        # Upload the texture data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, texture)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, texture_format, texture_type, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        # Check if the input is a PyTorch tensor\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Check if the input is a numpy array\n        if not isinstance(ptr, np.ndarray):\n            raise TypeError(\"The input argument 'ptr' must be a numpy array or a PyTorch tensor.\")\n\n        # Check if the input array has the correct shape\n        if ptr.ndim != 3 or ptr.shape[2] != 4:\n            raise ValueError(\"The input array must be a 3D array with a depth of 4, representing RGBA pixels.\")\n\n        # Check if the input array has the correct size\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n        if ptr.shape[1] != w or ptr.shape[0] != h:\n            raise ValueError(\"The input array must have the same size as the texture's width and height (W, H), which are {w}, {h}.\".format(w=self.W, h=self.H))\n\n        # Copy the input array to the texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # if isinstance(ptr, torch.Tensor):\n        #     ptr = ptr.cpu().numpy()\n        #     if ptr.shape[-1] == 4:\n        #         ptr = ptr.clip(0, 255)\n        #         ptr = ptr.astype(np.uint8)\n        #     elif ptr.shape[-1] == 3:\n        #         ptr = ptr.clip(0, 1)\n        #         ptr = (ptr * 255).astype(np.uint8)\n        #     else:\n        #         raise TypeError('Unsupported number of channels for image data')\n\n        w = w or self.W\n        h = h or self.H\n        gl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 1)\n        gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGBA, w, h, 0, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n\n        # if isinstance(ptr, torch.Tensor):\n        #     ptr.to(self.verts.device)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # if ptr.shape[-1] == 4:\n        #     ptr = ptr.cpu()\n        #     ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        if not isinstance(ptr, np.ndarray):\n            ptr = ptr.cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, ptr[..., :1] * 255], axis=-1)  # add alpha channel\n        if ptr.dtype == np.float32:\n            ptr = np.ascontiguousarray(ptr, np.uint8)  # convert to uint8\n\n        w = w or self.W\n        h = h or self.H\n\n        # Upload the data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glFlush()\n\n        # Check for errors\n        if gl.glGetError() != gl.GL_NO_ERROR:\n            raise RuntimeError(\"Error in Quad.upload_to_texture(): GL error\")\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # if isinstance(ptr, torch.Tensor):\n        #     ptr = ptr.cpu().numpy()\n        #     if len(ptr.shape) == 3:\n        #         ptr = np.transpose(ptr, [1, 2, 0])\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n            if len(ptr.shape) == 3:\n                ptr = np.transpose(ptr, [1, 2, 0])\n        else:\n            ptr = np.ascontiguousarray(ptr)\n\n        if w == 0: w = self.W\n        if h == 0: h = self.H\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_BGRA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Convert the data source to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        # Update the texture\n        gl.gl institut_texture(self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # https://github.com/pytorch/pytorch/issues/31334\n        # https://github.com/pytorch/pytorch/issues/31589\n        # https://github.com/pytorch/pytorch/issues/11885\n        # https://github.com/pytorch/pytorch/issues/27139\n        # https://github.com/pytorch/pytorch/issues/29252\n        # https://github.com/pytorch/pytorch/issues/30802\n        # https://github.com/pytorch/pytorch/issues/32662\n        # https://github.com/pytorch/pytorch/issues/32995\n        # https://github.com/pytorch/pytorch/issues/33132\n        # https://github.com/pytorch/pytorch/issues/34595\n        # https://github.com/pytorch/pytorch/issues/36512\n        # https://github.com/pytorch/pytorch/issues/37697\n        # https://github.com/pytorch/pytorch/issues/42368\n        # https://github.com/pytorch/pytorch/issues/43331\n        # https://github.com/pytorch/pytorch/issues/47807\n        # https://github.com/pytorch/pytorch/issues/50085\n        # https://github.com/pytorch/pytorch/issues/51341\n        # https://github.com/pytorch/pytorch/issues/52206\n        # https://github.com/pytorch/pytorch/issues/54007\n        # https://github.com/pytorch/pytorch/issues/56572\n        # https://github.com/pytorch/pytorch/issues/57202\n        # https://github.com/pytorch/pytorch/issues/57838\n        # https://github.com/pytorch/pytorch/issues/59405\n        # https://github.com/pytorch/pytorch/issues/59855\n        # https://github.com/pytorch/pytorch/issues/60040"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check input shapes\n    if R.ndim != 3 or tvec.ndim != 3 or camera_matrix.ndim != 3 or image_size.ndim != 2:\n        raise ValueError(\n            \"get_pulsar_camera_params: input tensors must have 3 dimensions. Got: R: {}, tvec: {}, camera_matrix: {}, image_size: {}\".format(\n                R.size(), tvec.size(), camera_matrix.size(), image_size.size()\n            )\n        )\n    if R.shape[0] != tvec.shape[0] or R.shape[0] != camera_matrix.shape[0] or R.shape[0] != image_size.shape[0]:\n        raise ValueError(\n            \"get_pulsar_camera_params: R, tvec, camera_matrix, and image_size must have the same batch size. Got: R: {}, tvec: {}, camera_matrix: {}, image_size: {}\".format(\n                R.shape[0], tvec.shape[0], camera_matrix.shape[0], image_size.shape[0]\n            )\n        )\n    if R.shape[1] != 3 or tvec.shape[1] != 3 or camera_matrix.shape[1] != 3 or image_size.shape[1] != 2:\n        raise ValueError(\n            \"get_pulsar_camera_params: input tensors must have the correct number of dimensions. Got: R: {}, tvec: {}, camera_matrix: {}, image_size: {}\".format(\n                R.shape, tvec.shape, camera_matrix.shape, image_size.shape\n            )\n        )\n    if R.dtype != torch.float32 or tvec.dtype != torch.float32 or camera_matrix.dtype != torch.float32 or image_size.dtype != torch.float32:\n        raise ValueError(\n            \"get_pulsar_camera_params: input tensors must be of type torch.float32. Got: R: {}, tvec: {}, camera_matrix: {}, image_size: {}\".format(\n                R.dtype, tvec.dtype, camera_matrix.dtype, image_size."}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check that the input tensors are batched\n    if R.ndim != 3 or tvec.ndim != 3 or camera_matrix.ndim != 3 or image_size.ndim != 2:\n        raise ValueError(\n            \"The input tensors must be batched. Please make sure that the shape of R, tvec, camera_matrix, and image_size are (N, 3, 3), (N, 3), (N, 3, 3), and (N, 2), respectively.\"\n        )\n\n    # Check that the input tensors have the correct shapes\n    if R.shape[-1] != 3 or tvec.shape[-1] != 3 or camera_matrix.shape[\n        -1\n    ] != 3 or image_size.shape[-1] != 2:\n        raise ValueError(\n            \"The input tensors must have the correct shapes. Please make sure that the shape of R, tvec, camera_matrix, and image_size are (N, 3, 3), (N, 3), (N, 3, 3), and (N, 2), respectively.\"\n        )\n\n    # Check that the input tensors have the correct values\n    if R.min() < 0 or R.max() > 1 or tvec.min() < 0 or tvec.max() > 1 or camera_matrix.min() < 0 or camera_matrix.max() > 1:\n        raise ValueError(\n            \"The input tensors must have values in the range [0, 1]. Please make sure that the shape of R, tvec, camera_matrix, and image_size are (N, 3, 3), (N, 3), (N, 3, 3), and (N, 2), respectively.\"\n        )\n\n    # Check that the image size is a square\n    if image_size[0] != image_size[1]:\n        raise ValueError(\n            \"The image size must be a square. Please make sure that the shape of image_size is (N, 2) and that the first and second dimensions are equal.\"\n        )\n\n    # Check that the image size is valid\n    if image_size.min()"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure that all inputs are batched\n    R = R.unsqueeze(1)\n    tvec = tvec.unsqueeze(1)\n    camera_matrix = camera_matrix.unsqueeze(1)\n    image_size = image_size.unsqueeze(1)\n\n    # Validate the shapes of the input tensors\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(\n            f\"Expected R to have shape (N, 3, 3), got {R.shape}. \"\n            \"Please make sure that R is a batch of 3x3 rotation matrices.\"\n        )\n    if tvec.shape[-1:] != (3,):\n        raise ValueError(\n            f\"Expected tvec to have shape (N, 3), got {tvec.shape}. \"\n            \"Please make sure that tvec is a batch of 3D vectors.\"\n        )\n    if camera_matrix.shape[-1:] != (3, 3):\n        raise ValueError(\n            f\"Expected camera_matrix to have shape (N, 3, 3), got {camera_matrix.shape}. \"\n            \"Please make sure that camera_matrix is a batch of 3x3 camera intrinsic matrices.\"\n        )\n    if image_size.shape[-1:] != (2,):\n        raise ValueError(\n            f\"Expected image_size to have shape (N, 2), got {image_size.shape}. \"\n            \"Please make sure that image_size is a batch of 2D vectors.\"\n        )\n\n    # Validate the values of the input tensors\n    if not (R >= -1 and R <= 1).all():\n        raise ValueError(\n            \"Expected R to be a batch of 3x3 rotation matrices, \"\n            \"where each matrix is a rotation matrix between -1 and 1.\"\n        )\n    if not (tvec >= -1 and tvec <= 1).all():\n        raise ValueError(\n            \"Expected tvec to be a batch of 3D vectors, \"\n            \"where each vector is between -1 and 1.\"\n        )\n    if not (camera_matrix >= 0 and camera_matrix <= 1).all():\n        "}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input\n    R = R.contiguous()\n    tvec = tvec.contiguous()\n    camera_matrix = camera_matrix.contiguous()\n    image_size = image_size.contiguous()\n\n    # Validate shapes\n    if R.size(-1) != 3:\n        raise ValueError('R should be of shape (*, 3, 3)')\n    if tvec.size(-1) != 3:\n        raise ValueError('tvec should be of shape (*, 3)')\n    if camera_matrix.size(-1) != 3:\n        raise ValueError('camera_matrix should be of shape (*, 3, 3)')\n    if image_size.size(-1) != 2:\n        raise ValueError('image_size should be of shape (*, 2)')\n\n    # Validate values\n    if not R.is_floating_point:\n        raise TypeError('R should be of floating point type')\n    if not tvec.is_floating_point:\n        raise TypeError('tvec should be of floating point type')\n    if not camera_matrix.is_floating_point:\n        raise TypeError('camera_matrix should be of floating point type')\n    if not image_size.is_floating_point:\n        raise TypeError('image_size should be of floating point type')\n\n    # Compute the camera parameters\n    R = R.clone()\n    tvec = tvec.clone()\n    camera_matrix = camera_matrix.clone()\n    image_size = image_size.clone()\n    R = R.permute(0, 2, 1)\n    tvec = tvec.permute(0, 2, 1)\n    camera_matrix = camera_matrix.permute(0, 2, 1)\n    image_size = image_size.permute(0, 2, 1)\n    R = R.reshape(-1, 9)\n    tvec = tvec.reshape(-1, 3)\n    camera_matrix = camera_matrix.reshape(-1, 9)\n    image_size = image_size.reshape(-1, 2)\n    R = R.to(dtype=torch.float32)\n    tvec"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input arguments\n    R = R.contiguous().view(-1, 3, 3)\n    tvec = tvec.contiguous().view(-1, 3)\n    camera_matrix = camera_matrix.contiguous().view(-1, 4, 4)\n    image_size = image_size.contiguous().view(-1, 2)\n\n    # Validate shapes\n    if R.size() != tvec.size() or R.size() != camera_matrix.size() or R.size() != image_size.size():\n        raise ValueError(\n            \"The shapes of the input tensors do not match. \"\n            f\"The shapes are: {R.shape}, {tvec.shape}, {camera_matrix.shape}, and {image_size.shape}, respectively.\"\n        )\n\n    # Validate values\n    if not (R.min() >= 0 and R.max() <= 1):\n        raise ValueError(\n            \"The rotation matrix values must be in the range [0, 1]. \"\n            f\"The values are {R.min()} and {R.max()}\"\n        )\n    if not (tvec.min() >= 0 and tvec.max() <= 1):\n        raise ValueError(\n            \"The translation vector values must be in the range [0, 1]. \"\n            f\"The values are {tvec.min()} and {tvec.max()}\"\n        )\n    if not (camera_matrix.min() >= 0 and camera_matrix.max() <= 1):\n        raise ValueError(\n            \"The camera matrix values must be in the range [0, 1]. \"\n            f\"The values are {camera_matrix.min()} and {camera_matrix.max()}\"\n        )\n    if not (image_size.min() >= 0 and image_size.max() <= 1):\n        raise ValueError(\n            \"The image size values must be in the range [0, 1]. \"\n            f\"The values are {image_size.min()} and {image_size.max()}\"\n        )\n\n    # Compute camera parameters\n    # 6D rotation representation\n    rot_6d = matrix_to_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check input shapes and values\n    assert R.dim() == 3, \"R should be a batch of rotation matrices.\"\n    assert tvec.dim() == 3, \"tvec should be a batch of translation vectors.\"\n    assert camera_matrix.dim() == 3, \"camera_matrix should be a batch of camera matrices.\"\n    assert image_size.dim() == 3, \"image_size should be a batch of image sizes.\"\n\n    # Get the number of instances in the batch\n    n_instances = R.shape[0]\n\n    # Validate R and tvec shapes\n    assert R.shape[1:] == tvec.shape, \"R and tvec should have the same shape.\"\n    assert R.shape[1:] == camera_matrix.shape[1:], \"R and camera_matrix should have the same shape.\"\n    assert R.shape[1:] == image_size.shape[1:], \"R and image_size should have the same shape.\"\n\n    # Validate R and tvec values\n    assert R.shape[1] == 3, \"R should be a batch of 3x3 matrices.\"\n    assert tvec.shape[1] == 3, \"tvec should be a batch of 3-vectors.\"\n    assert R.shape[2] == tvec.shape[2], \"R and tvec should have the same number of instances.\"\n\n    # Validate camera_matrix values\n    assert camera_matrix.shape[1] == 3, \"camera_matrix should be a batch of 3x3 matrices.\"\n    assert camera_matrix.shape[2] == 3, \"camera_matrix should be a batch of 3x3 matrices.\"\n    assert camera_matrix.shape[3] == n_instances, \"camera_matrix should have the same number of instances as R and tvec.\"\n\n    # Validate image_size values\n    assert image_size.shape[1] == 2, \"image_size should be a batch of 2-vectors.\"\n    assert image_size.shape[2] == n_instances, \"image_size should have the same number of instances as R and tvec.\"\n\n    # Get the rotation and translation parameters\n    rotation = matrix_to_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape == tvec.shape\n    assert R.ndim == 2 or R.ndim == 3\n    assert R.size(1) == 3\n    assert camera_matrix.ndim == 3\n    assert camera_matrix.size(0) == R.size(0)\n    assert camera_matrix.size(1) == 3\n    assert camera_matrix.size(2) == 3\n    assert image_size.ndim == 3\n    assert image_size.size(0) == R.size(0)\n    assert image_size.size(1) == 2\n\n    # Validate input values\n    assert R.min() >= 0\n    assert R.max() <= 1\n    assert tvec.min() >= -1\n    assert tvec.max() <= 1\n    assert camera_matrix.min() >= 0\n    assert camera_matrix.max() <= 1\n    assert image_size.min() >= 0\n    assert image_size.max() <= 1\n\n    # Compute camera position\n    cpos = -R @ tvec\n\n    # Compute camera rotation\n    if R.ndim == 3:\n        # Convert rotation matrix to 6D rotation representation\n        R = matrix_to_rotation_6d(R)\n\n    # Compute camera intrinsics\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 2, 0]\n    cy = camera_matrix[..., 2, 1]\n    w = image_size[..., 0]\n    h = image_size[..., 1]\n    warn_once_about_pulsar_fxfy()\n    fx = (fx + fy) / 2\n    fy = fx\n    cx = cx - (w - 1) / 2\n    cy = cy - (h - 1) / 2\n\n    # Compute focal length\n    znear = torch.as_tensor(znear)\n    znear = znear.to(fx)\n    focal = fx * h / (2 * znear)\n\n    # Return camera parameters\n    return"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    assert R.ndim == 3, \"R must be a 3D tensor.\"\n    assert tvec.ndim == 2, \"tvec must be a 2D tensor.\"\n    assert camera_matrix.ndim == 3, \"camera_matrix must be a 3D tensor.\"\n    assert image_size.ndim == 2, \"image_size must be a 2D tensor.\"\n\n    # Get batch size\n    batch_size = R.shape[0]\n    assert batch_size == tvec.shape[0], \"R and tvec must have the same batch size.\"\n    assert batch_size == camera_matrix.shape[0], \"R and camera_matrix must have the same batch size.\"\n    assert batch_size == image_size.shape[0], \"R and image_size must have the same batch size.\"\n\n    # Validate R\n    assert R.shape[-1] == 3, \"R must have 3 columns.\"\n\n    # Validate tvec\n    assert tvec.shape[1] == 3, \"tvec must have 3 columns.\"\n\n    # Validate camera_matrix\n    assert camera_matrix.shape[-1] == 3, \"camera_matrix must have 3 columns.\"\n\n    # Validate image_size\n    assert image_size.shape[1] == 2, \"image_size must have 2 columns.\"\n\n    # Validate znear\n    assert 0.0 <= znear, \"znear must be non-negative.\"\n\n    # Validate camera_matrix\n    assert camera_matrix[..., 0, 2] == 1, \"camera_matrix must have 1 in the last column of the first row.\"\n\n    # Validate image_size\n    assert image_size[..., 0] > 0, \"image_size must have positive values.\"\n    assert image_size[..., 1] > 0, \"image_size must have positive values.\"\n\n    # Compute the rotation matrix\n    R = matrix_to_rotation_6d(R)\n\n    # Compute the camera position\n    tvec = tvec.view(batch_size, 3, 1)\n\n    # Compute the camera transformation matrix\n    t_matrix = torch.cat"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if len(R.shape) != 3:\n        raise ValueError(f\"R should be a 3D tensor of shape {R.shape}, but got {R.shape}.\")\n    if len(tvec.shape) != 2:\n        raise ValueError(f\"tvec should be a 2D tensor of shape {tvec.shape}, but got {tvec.shape}.\")\n    if len(camera_matrix.shape) != 3:\n        raise ValueError(\n            f\"camera_matrix should be a 3D tensor of shape {camera_matrix.shape}, but got {camera_matrix.shape}.\")\n    if len(image_size.shape) != 2:\n        raise ValueError(f\"image_size should be a 2D tensor of shape {image_size.shape}, but got {image_size.shape}.\")\n\n    if camera_matrix.size(1) != 3:\n        raise ValueError(\n            f\"camera_matrix should have 3 columns, but got {camera_matrix.size(1)}.\")\n    if camera_matrix.size(2) != 3:\n        raise ValueError(\n            f\"camera_matrix should have 3 rows, but got {camera_matrix.size(2)}.\")\n    if image_size.size(1) != 2:\n        raise ValueError(\n            f\"image_size should have 2 columns, but got {image_size.size(1)}.\")\n\n    # Validate values\n    if camera_matrix.min() < 0:\n        raise ValueError(\n            \"camera_matrix should be a positive-definite matrix, but got at least one negative value.\")\n    if camera_matrix.min() < 0:\n        raise ValueError(\n            \"image_size should be a positive vector, but got at least one negative value.\")\n\n    # Compute the camera position\n    position = tvec\n\n    # Compute the camera rotation\n    camera_rotation = R\n\n    # Compute the intrinsic parameters\n    focal_length = camera_matrix[0, 0]\n    principal_point = camera_matrix[0, 2:3]\n    sensor_width = image_size[0]\n\n    # Normalize the"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check that all inputs are batched\n    if not all(x.is_batched for x in [R, tvec, camera_matrix, image_size]):\n        raise ValueError(\n            \"All inputs must be batched, but one or more are not.\"\n        )\n\n    # Check that the rotation matrix is of size (*, 3, 3)\n    if R.shape[-1] != 3:\n        raise ValueError(\n            \"Rotation matrix must be of size (*, 3, 3), but it has size {}\".format(\n                R.shape\n            )\n        )\n    # Check that the translation vector is of size (*, 3)\n    if tvec.shape[-1] != 3:\n        raise ValueError(\n            \"Translation vector must be of size (*, 3), but it has size {}\".format(\n                tvec.shape\n            )\n        )\n    # Check that the camera matrix is of size (*, 3, 3)\n    if camera_matrix.shape[-1] != 3:\n        raise ValueError(\n            \"Camera matrix must be of size (*, 3, 3), but it has size {}\".format(\n                camera_matrix.shape\n            )\n        )\n    # Check that the image size is of size (*, 2)\n    if image_size.shape[-1] != 2:\n        raise ValueError(\n            \"Image size must be of size (*, 2), but it has size {}\".format(\n                image_size.shape\n            )\n        )\n\n    # Calculate the camera position by multiplying the translation vector by the inverse of the rotation matrix\n    camera_position = tvec.clone().view_as(R) @ R.permute(0, 2, 1).inverse()\n\n    # Calculate the rotation parameters by converting the rotation matrix to a 6D rotation representation\n    rotation = matrix_to_rotation_6d(R)\n\n    # Calculate the focal length by multiplying the camera matrix by the inverse of the image size\n    focal_length = camera_matrix @ image_size.inverse()\n\n    # Calculate the principal point by adding the image size to the camera matrix\n    principal_point = camera_matrix + image_size"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    batch_dim = R.shape[0]\n    assert batch_dim == tvec.shape[0]\n    assert batch_dim == camera_matrix.shape[0]\n    assert batch_dim == image_size.shape[0]\n\n    # Validate input values\n    assert R.size(1) == 3\n    assert tvec.size(1) == 3\n    assert camera_matrix.size(1) == 3\n    assert camera_matrix.size(2) == 3\n    assert image_size.size(1) == 2\n    assert camera_matrix[..., 0, 0] > 0\n    assert camera_matrix[..., 1, 1] > 0\n    assert image_size[..., 0] > 0\n    assert image_size[..., 1] > 0\n    assert znear > 0\n\n    # Compute the camera position and rotation\n    camera_position = camera_matrix[:, 2, :] - tvec\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the focal length and sensor width\n    f = camera_matrix[..., 0, 0]\n    w = camera_matrix[..., 2, 2]\n    image_size_x, image_size_y = image_size[:, 0], image_size[:, 1]\n    focal_length = (f + w) / 2\n    focal_length = focal_length / normalize_sum(focal_length)\n    sensor_width = w / focal_length\n\n    # Return the camera parameters\n    return torch.stack([camera_position, camera_rotation, focal_length, sensor_width], dim=1)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input arguments\n    assert R.ndim == 3, \"Pulsar only supports 3D tensors as rotation matrices.\"\n    assert R.shape[-2:] == (3, 3), \"Pulsar only supports 3x3 rotation matrices.\"\n    assert tvec.ndim == 3, \"Pulsar only supports 3D tensors as translation vectors.\"\n    assert tvec.shape[-1] == 3, \"Pulsar only supports 3D translation vectors.\"\n    assert camera_matrix.ndim == 3, \"Pulsar only supports 3D tensors as camera matrices.\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Pulsar only supports 3x3 camera matrices.\"\n    assert image_size.ndim == 2, \"Pulsar only supports 2D tensors as image sizes.\"\n    assert image_size.shape[-1] == 2, \"Pulsar only supports 2D image sizes.\"\n\n    # Compute the camera position\n    camera_position = -R @ tvec\n\n    # Compute the camera rotation in a different representation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the focal length and principal point\n    focal_length = camera_matrix[..., 0, 0] / image_size[..., 0]\n    principal_point = camera_matrix[..., 0, 2] / image_size[..., 0]\n\n    # Adjust the focal length and principal point for the near clipping plane\n    focal_length = focal_length - znear / 2 * focal_length.new_ones(focal_length.shape)\n    principal_point = principal_point - (znear - 1) / 2 * image_size[..., 0] * focal_length.new_ones(principal_point.shape)\n\n    # Return the computed camera parameters\n    return torch.cat([camera_position, camera_rotation, focal_length, principal_point], dim=-1)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check the shapes of the inputs and validate them\n    R = R.view(-1, 3, 3)\n    tvec = tvec.view(-1, 3)\n    camera_matrix = camera_matrix.view(-1, 3, 3)\n    image_size = image_size.view(-1, 2)\n\n    # Compute the camera's rotation in a different representation\n    R = matrix_to_rotation_6d(R)\n\n    # Compute the camera's position\n    c2w = torch.cat([R, tvec], dim=-1)\n    c2w[..., 0] *= 1  # flip x\n    c2w[..., 1] *= -1  # flip y\n    c2w[..., 2] *= -1  # flip z\n    w2c = affine_inverse(c2w)\n\n    # Compute the focal length and principal point\n    k = torch.diag(camera_matrix[..., 0, 0])\n    f = torch.sqrt(k)\n    pp = camera_matrix[..., 1, 0] / f\n    f = f.mean(dim=-1)\n    pp = pp.mean(dim=-1)\n\n    # Compute the sensor width\n    sensor_width = image_size[..., 1]\n\n    # Adjust the focal length for the near clipping plane\n    znear = 1 / (znear + 1)\n    f = f * sensor_width * znear\n\n    # Return the computed camera parameters\n    return torch.cat([w2c, f, pp, sensor_width], dim=-1)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    if R.shape[-1] != 3:\n        raise ValueError(\n            f\"Pulsar expects the input rotation matrix to have 3 columns, but got {R.shape[-1]}\"\n        )\n    if tvec.shape[-1] != 3:\n        raise ValueError(\n            f\"Pulsar expects the input translation vector to have 3 columns, but got {tvec.shape[-1]}\"\n        )\n    if camera_matrix.shape[-2] != 3 or camera_matrix.shape[-1] != 3:\n        raise ValueError(\n            f\"Pulsar expects the input camera matrix to have 3 rows and 3 columns, but got {camera_matrix.shape[-2:]}\"\n        )\n    if image_size.shape[-2] != 2:\n        raise ValueError(\n            f\"Pulsar expects the input image size to have 2 columns, but got {image_size.shape[-2:]}\"\n        )\n    if image_size.shape[-1] != 2:\n        raise ValueError(\n            f\"Pulsar expects the input image size to have 2 columns, but got {image_size.shape[-1:]}\"\n\n        )\n\n    # Compute the camera position\n    cpos = -tvec.t()\n\n    # Compute the rotation matrix\n    R = R.transpose(-1, -2)\n\n    # Compute the rotation vector\n    R = matrix_to_rotation_6d(R)\n\n    # Compute the focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if fx.shape != fy.shape:\n        warn_once_about_fxfy()\n    fx = (fx + fy) / 2\n    fx = fx / image_size[..., 0]\n    fx = fx / (znear + znear)\n\n    # Compute the principal point\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    cx = cx / image_size[..., 0]\n    cy = cy / image_size[..., 1]\n    cx = cx - 1.0"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if not torch.allclose(tvec.shape, R.shape[-1:], 0, 0):\n        raise ValueError(\n            \"The shape of the translation vector must match the shape of the rotation matrix.\"\n        )\n    if not torch.allclose(R.shape[:-2], camera_matrix.shape[:-2], 0, 0):\n        raise ValueError(\n            \"The shape of the rotation matrix must match the shape of the camera matrix.\"\n        )\n    if not torch.allclose(R.shape[:-2], image_size.shape, 0, 0):\n        raise ValueError(\n            \"The shape of the rotation matrix must match the shape of the image size.\"\n        )\n\n    # Compute camera position\n    cam_pos = -R[..., :3, 2] + tvec\n\n    # Compute rotation\n    rot = matrix_to_rotation_6d(R)\n\n    # Compute focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n    f /= image_size[..., 0]\n    f *= (1.0 / znear)\n\n    # Compute principal point\n    pp_x = camera_matrix[..., 0, 2]\n    pp_y = camera_matrix[..., 1, 2]\n    pp = (pp_x + pp_y) / 2\n    pp /= image_size[..., 0]\n\n    # Compute sensor width\n    sensor_w = camera_matrix[..., 1, 1]\n    sensor_w /= image_size[..., 0]\n\n    # Return results\n    return torch.cat([cam_pos, rot, f, pp, sensor_w], dim=-1)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.ndim != 3 or tvec.ndim != 2:\n        raise ValueError(\"R and tvec must have 3 and 2 dimensions, respectively.\")\n\n    if R.size(-1) != 3 or tvec.size(-1) != 3:\n        raise ValueError(\"R and tvec must have 3 columns.\")\n\n    if camera_matrix.ndim != 3 or image_size.ndim != 3:\n        raise ValueError(\"camera_matrix and image_size must have 3 dimensions.\")\n\n    if camera_matrix.size(-1) != 3 or image_size.size(-1) != 2:\n        raise ValueError(\"camera_matrix and image_size must have 3 and 2 columns, respectively.\")\n\n    # Compute the camera position and rotation\n    R = R.view(-1, 3, 3)\n    R_rot6d = matrix_to_rotation_6d(R)\n    tvec = tvec.view(-1, 3)\n    camera_position = R_rot6d.bmm(tvec)\n\n    # Compute the intrinsic parameters\n    K = camera_matrix.view(-1, 3, 3)\n    K_inv = K.inverse()\n    principal_point = K_inv[:, 2, :2]\n    focal_length = K_inv[:, 2, 2]\n    # Normalize the focal length based on the image size and znear\n    focal_length = focal_length / image_size[:, 1, 0] * (znear + 0.1)\n    sensor_width = image_size[:, 1, 1] / 2\n\n    # Compute the final camera parameters\n    camera_parameters = torch.cat([camera_position, R_rot6d, principal_point, focal_length, sensor_width], dim=-1)\n\n    return camera_parameters\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Normalize the rotation matrix\n    R = R.clone().reshape(-1, 3, 3)\n    R = R.to(torch.float32)\n    R = R.unsqueeze(-1)\n    R = R.to_3d()\n\n    # Normalize the translation vector\n    tvec = tvec.to(torch.float32)\n    tvec = tvec.unsqueeze(-1)\n\n    # Normalize the camera matrix\n    camera_matrix = camera_matrix.to(torch.float32)\n    camera_matrix = camera_matrix.unsqueeze(-1)\n    camera_matrix = camera_matrix.to_3d()\n    # Normalize the image size\n    image_size = image_size.to(torch.float32)\n    image_size = image_size.unsqueeze(-1)\n    image_size = image_size.to_3d()\n\n    # Validate shapes\n    assert R.size() == tvec.size(), \"The shape of the rotation matrix and translation vector must be the same.\"\n    assert camera_matrix.size() == image_size.size(), \"The shape of the camera matrix and image size must be the same.\"\n\n    # Validate values\n    assert (R.abs().sum(dim=-1) < 1.0).all(), \"The rotation matrix should be normalized.\"\n    assert (R.abs().sum(dim=-1) > 1e-10).all(), \"The rotation matrix should not be singular.\"\n    assert camera_matrix[..., 0, 2].abs().max() < 1e-10, \"The camera matrix should not have a non-zero Z-Z component.\"\n\n    # Compute the camera position\n    camera_position = R @ tvec\n\n    # Compute the rotation\n    R = R.reshape(-1, 1, 9)\n    R = R.to_3d()\n\n    # Compute the intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 2, 0]\n    cy = camera_matrix[..., 2, 1]\n\n    # Validate the intrinsic parameters\n    assert fx"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    if R.ndim < 3:\n        R = R.unsqueeze(0)\n    if R.shape[-1] == 4:\n        R = R[..., :3, :3]\n\n    if tvec.ndim < 3:\n        tvec = tvec.unsqueeze(0)\n    if tvec.shape[-2] == 4:\n        tvec = tvec[..., :3]\n\n    if camera_matrix.ndim < 3:\n        camera_matrix = camera_matrix.unsqueeze(0)\n    if camera_matrix.shape[-1] != 3:\n        camera_matrix = camera_matrix.permute(0, 3, 1, 2)\n\n    if image_size.ndim < 1:\n        image_size = image_size.unsqueeze(0)\n    if image_size.shape[-1] == 1:\n        image_size = image_size.unsqueeze(-1)\n\n    # Validate input values\n    if not torch.isclose(torch.det(R), 1.0):\n        raise ValueError('Rotation matrices must have determinant 1.0, but got {}.')\n\n    # Compute camera position\n    tvec_c = tvec.unsqueeze(2)\n    cam_pos = -R.bmm(tvec_c).squeeze(-1)\n\n    # Compute rotation parameters\n    R_6d = matrix_to_rotation_6d(R)\n    R_6d = R_6d.permute(0, 3, 1, 2)\n\n    # Compute focal lengths and principal points\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    image_size_x = image_size[..., 0]\n    image_size_y = image_size[..., 1]\n    fx = fx / image_size_x\n    fy = fy / image_size_y\n    cx = cx / image_size_x\n    cy = cy / image_size_y\n\n    # Compute camera intrinsics"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if R.size() != tvec.size():\n        raise ValueError(\n            \"Rotation matrix and translation vector should have the same size, but got {} and {} instead\".format(\n                R.size(), tvec.size()\n            )\n        )\n\n    if R.size() != camera_matrix.size()[:-2]:\n        raise ValueError(\n            \"Rotation matrix and camera matrix should have the same size, but got {} and {} instead\".format(\n                R.size(), camera_matrix.size()\n            )\n        )\n\n    if R.size() != image_size.size():\n        raise ValueError(\n            \"Rotation matrix and image size should have the same size, but got {} and {} instead\".format(\n                R.size(), image_size.size()\n            )\n        )\n\n    if camera_matrix.size() != image_size.size():\n        raise ValueError(\n            \"Camera matrix and image size should have the same size, but got {} and {} instead\".format(\n                camera_matrix.size(), image_size.size()\n            )\n        )\n    # Compute camera parameters\n    # Compute camera position\n    camera_position = R.matmul(tvec.unsqueeze(-1)).squeeze(-1)  # B, 3\n    # Compute camera rotation\n    R_6d = matrix_to_rotation_6d(R)  # B, 6\n    # Compute camera intrinsics\n    focal_length = camera_matrix[..., 0, 0]\n    principal_point = camera_matrix[..., 1, 1]\n    sensor_width = camera_matrix[..., 0, 0]\n    # Compute image size\n    image_size = image_size.float()\n\n    # Normalize focal length\n    if znear > 0:\n        focal_length /= znear\n        warn_once_about_pulsar_fxfy()\n    # Normalize sensor width\n    sensor_width /= image_size.min(dim=-1, keepdim=True)[0]\n\n    # Normalize principal point\n    # image_size[..., 0] is the width\n    principal_point = principal_point / image_size[..., 0]\n    # We want to normalize"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    R, tvec, camera_matrix, image_size = validate_shapes(R, tvec, camera_matrix, image_size)\n    # Get rotation matrix\n    R = matrix_to_rotation_6d(R)\n    # Compute the camera position\n    tvec = tvec.reshape(R.shape[:-1] + (3,))\n    # Compute the focal length and principal point\n    f = camera_matrix[..., 0, 0]\n    fx = f\n    fy = f\n    # Compute the sensor width\n    # If the image size is not provided, we assume the image is square\n    # and use the same focal length for both x and y\n    if image_size is None:\n        image_size = torch.ones_like(fx) * 1024\n    image_size = image_size.reshape(R.shape[:-1] + (2,))\n    # If the focal lengths are not the same, warn the user\n    if (fx - fy).abs().max() > 1e-4:\n        warn_once_about_pulsar_fxfy()\n    # Compute the sensor width\n    sensor_width = image_size[..., 1] * fx / image_size[..., 0]\n    # Compute the rotation matrix\n    # The rotation matrix is a 6D representation, so we need to extract the\n    # first 3 rows and columns to get the 3D rotation matrix\n    R = R[..., :3, :3]\n    # Compute the camera parameters\n    camera_params = torch.cat([tvec, R, fx, fy, sensor_width], dim=-1)\n    # Normalize the focal length\n    camera_params[..., 2:4] = camera_params[..., 2:4] / camera_params[..., 4:5]\n    # Normalize the sensor width\n    camera_params[..., 4:5] = 1.0\n    # Normalize the near plane\n    camera_params[..., 0:3] = (camera_params[..., 0:3] - znear) / (znear + 1.0)\n    return camera_params\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            # Blitting\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            return\n\n        # Drawing\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n\n        # Set the viewport\n        gl.glViewport(x, y, w, h)\n\n        # Set the scissor box\n        gl.glScissor(x, y, w, h)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Set up the viewport and scissor box for drawing\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture and set up the vertex data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 3 * self.verts.element_size(), ctypes.c_void_p(0))\n        gl.glEnableVertexAttribArray(0)\n\n        # Draw the quadrilateral\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(0, 0, camera.W, camera.H)\n        gl.glScissor(0, 0, camera.W, camera.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set the viewport\n        gl.glViewport(x, y, w, h)\n\n        # Set the scissor box\n        gl.glScissor(x, y, w, h)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport\n        gl.glViewport(0, 0, self.W, self.H)\n\n        # Restore the scissor box\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set viewport and scissor box\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Set shader program\n        use_gl_program(self.quad_program)\n        self.use_gl_program(self.quad_program)\n\n        # Bind texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            # Blit to screen\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glDrawPixels(self.W, self.H, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, self.verts_data)\n            return\n\n        # Draw quad\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glBindVertexArray(self.vao)\n        gl.glUseProgram(self.quad_program)\n\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            # Blitting\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, x + w, y + h,\n                                  0, 0, self.W, self.H,\n                                  gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n        else:\n            # Drawing\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glBindVertexArray(self.vao)\n            gl.glUseProgram(self.quad_program)  # use a different program\n\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        gl.glUseProgram(self.quad_program)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glUseProgram(0)\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set up viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glUseProgram(0)\n        gl.glScissor(*old_scissor)\n        gl.glViewport(*old_viewport)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)  # set viewport\n        gl.glScissor(x, y, w, h)  # set scissor box\n\n        # Bind the texture and shader program\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUseProgram(self.quad_program)\n\n        # Draw the quadrilateral\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set viewport\n        gl.glViewport(x, y, w, h)\n\n        # Set scissor box\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)\n            gl.glDrawArrays(gl.GL_TRIANGLES, 0, 6)\n            return\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n\n        # Set the viewport and scissor box for rendering\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Bind the texture to the current program\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Blitting is used for drawing the quad\n        if not self.use_quad_draw:\n            gl.glUseProgram(self.quad_program)\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            return\n\n        # Using a quad to draw the image\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Set viewport\n        gl.glViewport(x, y, w, h)\n\n        # Set scissor box\n        gl.glScissor(x, y, w, h)\n\n        # Draw\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore viewport\n        gl.glViewport(0, 0, camera.W, camera.H)\n\n        # Restore scissor box\n        gl.glScissor(0, 0, camera.W, camera.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Set up the viewport and scissor box for rendering.\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glScissor(x, y, w, h)\n        gl.glViewport(x, y, w, h)\n\n        # Activate the shader program and bind the texture.\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral.\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes.\n        gl.glViewport(*old_viewport)\n        gl.glScissor(0, 0, old_viewport[2], old_viewport[3])\n\n        # No return value.\n        return\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n\n        if self.use_quad_draw:\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glScissor(x, y, w, h)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n\n        else:\n            old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w, h,\n                                  0, 0, self.W, self.H,\n                                  gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glUseProgram(0)\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        # Set up viewport and scissor box\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quad\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        # Restore viewport and scissor box\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)\n            gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        else:\n            # Draw a quad\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)  # we might need to update the scissor box\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # 4 vertices\n            gl.glUseProgram(0)\n            gl.glScissor(0, 0, self.W, self.H)\n            gl.glViewport(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        # https://www.khronos.org/registry/OpenGL/extensions/NV/NV_viewport_array2.txt\n        w = w or self.W\n        h = h or self.H\n\n        gl.glViewport(x, y, w, h)  # NOTE: Use gl.glViewport(0, 0, self.W, self.H) to set the whole viewport\n        gl.glScissor(x, y, w, h)\n        if self.use_quad_draw:\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        else:\n            gl.glBlitFramebuffer(x, y, w, h, 0, 0, self.W, self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Set the viewport and scissor box\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        # Restore the viewport and scissor box\n        gl.glScissor(0, 0, camera.W, camera.H)\n        gl.glViewport(0, 0, camera.W, camera.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Draw using blitting if no cuda-opengl interop is used\n        if not self.use_quad_cuda:\n            gl.glViewport(x, y, w, h)\n            gl.glDrawBuffer(gl.GL_BACK)\n            gl.glDrawArrays(gl.GL_TRIANGLE_FAN, 0, 4)\n            return\n\n        # Draw using quad drawing\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n\n        # Set up the viewport\n        gl.glViewport(x, y, w, h)\n\n        # Set up the scissor box\n        gl.glScissor(x, y, w, h)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quad\n        gl.glDrawArrays(gl.GL_TRIANGLE_FAN, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glViewport(0, 0, self.W, self.H)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    # Check if the batch is empty\n    if R.shape[0] == 0:\n        return H, W, K, R, T, C\n\n    #"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    R = batch.R\n    T = batch.T\n    K = batch.K\n    H = batch.meta.H[0].item()\n    W = batch.meta.W[0].item()\n    # Flip the rotation matrix\n    R = R.transpose(2, 1)\n    # Flip the translation vector\n    T = T.flip(dims=(2,))\n    # Flip the camera center\n    C = -R @ T  # B, 3, 1\n    # Compute the intrinsic matrix for normalized device coordinates (NDC)\n    K = torch.as_tensor([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]], dtype=K.dtype, device=K.device)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract the height and width of the images\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    # Extract the camera intrinsic matrix (K)\n    K = batch.K\n    # Extract the rotation matrix (R) and translation vector (T)\n    R = batch.R\n    T = batch.T\n    # Apply the rotation and translation matrices to the camera center\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Return the height and width of the images, the intrinsic matrix for NDC, the adjusted rotation matrix, the adjusted translation vector, and the camera center\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract height and width of the images\n    H = batch.meta.H[0].item()\n    W = batch.meta.W[0].item()\n    # Extract PyTorch3D camera parameters\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    # Compute camera center\n    C = -batch.R.mT @ batch.T\n    # Apply coordinate system correction on rotation matrix\n    R = R.permute(0, 2, 1)\n    # Apply coordinate system correction on translation vector\n    T = -T\n    # Compute intrinsic matrix for normalized device coordinates (NDC)\n    ixt = get_ndc_perspective_matrix(K, H, W, T[0, 2], K[0, 0])\n    # Return\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    K = batch.K\n    R = batch.R\n    T = batch.T\n    # Coordinate system is different from that of OpenCV (cv: right down front, 3d: left up front)\n    # However, the correction has to be down on both T and R... (instead of just R)\n    R = R.transpose(2, 1)\n    T = -T\n    C = -R.mT @ T  # B, 3, 1\n    # Compute intrinsic matrix for NDC\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    fx = K[0, 0].item()\n    fy = K[1, 1].item()\n    cx = K[0, 2].item()\n    cy = K[1, 2].item()\n    K = torch.as_tensor(\n        [[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=torch.float32, device=R.device\n    )\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract the height and width of the images\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n\n    # Extract the intrinsic matrix (K)\n    K = batch.K\n\n    # Extract the rotation matrix (R) and translation vector (T)\n    R = batch.R\n    T = batch.T\n\n    # Apply the necessary transformations on the rotation and translation matrices\n    R = torch.transpose(R, 2, 1)\n    T = -T\n\n    # Compute the camera center (C)\n    C = -torch.bmm(torch.transpose(R, 1, 2), T)\n\n    # Return the extracted parameters\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters\n    H, W, K, R, T, C = get_opencv_camera_params(batch)\n\n    # Convert to PyTorch3D's coordinate system\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    T = -T.T  # B, 3, 1\n    C = -R.bmm(T).squeeze(-1)  # B, 3, 1\n    # Compute intrinsic matrix for normalized device coordinates (NDC)\n    f = K[..., 0, 0] / W\n    c = K[..., 1, 2]\n    K = torch.as_tensor([f, f, 1], dtype=torch.float32, device=R.device)\n    K = K[None, None, :, :]\n\n    # Return\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract the metadata\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    # Extract the camera parameters\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    # Adjust the rotation matrix\n    R = R.t()  # pytorch3d: R is applied on the right\n    # Adjust the translation vector\n    T = -T  # pytorch3d: coordinate system is different from OpenCV (cv: right down front, 3d: left up front)\n    # Compute the intrinsic matrix\n    K = torch.as_tensor(K.numpy(), dtype=torch.float32)\n    # K = torch.tensor([K[0, 0], K[1, 1], K[0, 2], K[1, 2], K[0, 0], K[1, 1]])\n    K = torch.as_tensor([K[0, 0], K[1, 1], K[0, 2], K[1, 2], K[0, 0], K[1, 1]])\n    # K = torch.tensor(\n    #     [\n    #         K[0, 0],\n    #         K[1, 1],\n    #         K[0, 2],\n    #         K[1, 2],\n    #         K[0, 0],\n    #         K[1, 1],\n    #     ],\n    #     dtype=torch.float32,\n    # )\n    # K = torch.tensor(\n    #     [\n    #         K[0, 0],\n    #         K[1, 1],\n    #         K[0, 2],\n    #         K[1, 2],\n    #         K[0, 0],\n    #         K[1, 1],\n    #     ],\n    #     dtype=torch.float32,\n    # )\n    # K = torch.as_tensor([K[0, 0], K[1, 1],"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    # C = -R.mT @ T  # B, 3, 1\n    C = torch.matmul(R.transpose(2, 1), T)\n    # C = -torch.matmul(R, T)\n    C = C.squeeze(-1)\n\n    # R_trans = R.permute(0, 2, 1)\n    # C = torch.bmm(R_trans, T).squeeze(2)\n\n    # R_trans = torch.as_tensor([R.permute(0, 2, 1)], device=R.device)\n    # C = torch.bmm(R_trans, T).squeeze(2)\n\n    # R_trans = R.permute(0, 2, 1)\n    # C = torch.bmm(R_trans, T).squeeze(2)\n    # C = torch.bmm(R_trans, T).squeeze(2)\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract the metadata\n    H = batch.meta.H[0].item()\n    W = batch.meta.W[0].item()\n\n    # Extract the camera parameters\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Convert rotation matrix to 6D representation\n    R = matrix_to_rotation_6d(R)\n\n    # Calculate the intrinsic matrix for NDC\n    # The focal length is computed as the average of the two focal lengths\n    # The principal point is computed as the center of the image\n    f = (batch.K[:, 0, 0] + batch.K[:, 1, 1]) / 2\n    c = batch.K[:, 1, 2]\n    K = torch.tensor(\n        [\n            [f, 0, 0],\n            [0, f, 0],\n            [0, 0, 1],\n        ],\n        device=batch.R.device,\n    )\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n\n    # Transpose the rotation matrix\n    R_transposed = torch.transpose(R, 2, 1)\n\n    # Apply the correction for the different coordinate system\n    T_corrected = torch.cat([T, torch.ones_like(T[..., :1])], dim=-1)\n    T_corrected = torch.bmm(R_transposed, T_corrected).squeeze(-1)\n    R_corrected = torch.bmm(R_transposed, R)\n\n    # Compute the camera center\n    C = -R_corrected @ T_corrected\n\n    # Compute the intrinsic matrix for NDC\n    f_x = K[..., 0, 0].squeeze(1)\n    f_y = K[..., 1, 1].squeeze(1)\n    c_x = K[..., 0, 2].squeeze(1)\n    c_y = K[..., 1, 2].squeeze(1)\n    K_ndc = torch.cat(\n        [\n            f_x.view(1, 1, 1, -1).expand(H, W, 1, 1),\n            torch.zeros_like(f_x),\n            torch.zeros_like(f_x),\n            c_x.view(1, 1, 1, -1).expand(H, W, 1, 1),\n            torch.zeros_like(f_y),\n            torch.zeros_like(f_y),\n            c_y.view(1, 1, 1, -1).expand(H, W, 1, 1),\n            torch.zeros_like(f_x),\n        ],\n        dim=-1,\n    )\n\n    return H, W, K_ndc, R_corrected, T_corrected, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract height and width of the images\n    H = batch.meta.H[0].item()\n    W = batch.meta.W[0].item()\n\n    # Extract camera intrinsic matrix (K)\n    K = batch.K\n\n    # Extract rotation and translation matrices\n    R = batch.R\n    T = batch.T\n\n    # Convert from OpenCV's right-handed to PyTorch3D's left-handed coordinate system\n    # (This is a transposition of the rotation matrix)\n    R = R.t()\n\n    # Apply the correction to the translation vector\n    C = -R @ T\n\n    # Apply the correction to the rotation matrix\n    R = torch.matmul(R, R)\n\n    # Compute intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1)\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract the height and width of the images\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n\n    # Extract the camera intrinsic matrix\n    K = batch.K\n\n    # Extract the rotation matrix and translation vector\n    R = batch.R\n    T = batch.T\n\n    # Apply the rotation matrix to the translation vector\n    C = -R.mT @ T\n\n    # Adjust the rotation matrix\n    # PyTorch3D uses a different coordinate system and convention than OpenCV\n    # The rotation matrix must be transposed and the z-axis must be flipped\n    R = R.permute(0, 2, 1)\n    R = R.flip(2)\n\n    # Compute the intrinsic matrix for normalized device coordinates (NDC)\n    # The focal length is the distance from the principal point to the optical center\n    # The principal point is at the center of the image\n    # The focal length is the same in both the x and y direction\n    focal_length = K[0, 0].item()\n    principal_point_x = W / 2\n    principal_point_y = H / 2\n\n    # The intrinsic matrix for NDC is a 3x3 matrix with the following values:\n    # [fx, 0, cx;\n    # 0, fy, cy;\n    # 0, 0, 1]\n    K = torch.tensor(\n        [[focal_length, 0, principal_point_x], [0, focal_length, principal_point_y], [0, 0, 1]],\n        dtype=torch.float32,\n    )\n\n    # Return the height and width of the images, the intrinsic matrix for NDC, the adjusted rotation matrix, the adjusted translation vector, and the camera center\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract parameters\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    # Apply coordinate system change\n    # R: B, 3, 3\n    # T: B, 3, 1\n    # C: B, 3, 1\n    R = R.permute(0, 2, 1)\n    T = T.permute(0, 2, 1)\n    C = -R @ T  # B, 3, 1\n    # Calculate intrinsic matrix\n    # K: B, 3, 3\n    K = get_ndc_perspective_matrix(K, H, W, 0.0, 1.0)  # H, W, n, f\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract the height and width of the images\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n\n    # Extract the camera intrinsics matrix\n    K = batch.K\n\n    # Extract the rotation and translation matrices\n    R = batch.R\n    T = batch.T\n\n    # Convert the rotation matrix from OpenCV to PyTorch3D\n    R = R.permute(0, 2, 1)\n\n    # Apply the translation and rotation\n    C = -R @ T\n\n    # Compute the focal length and the camera center\n    fx = K[0, 0]\n    fy = K[1, 1]\n    cx = K[0, 2]\n    cy = K[1, 2]\n\n    # Calculate the new intrinsic matrix for the normalized device coordinates (NDC)\n    K = torch.as_tensor(\n        [\n            [fx, 0, cx],\n            [0, fy, cy],\n            [0, 0, 1],\n        ],\n        dtype=torch.float32,\n    )\n\n    # Return the height, width, intrinsic matrix, adjusted rotation matrix, adjusted translation vector, and camera center\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract batch metadata\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n\n    # Extract camera intrinsics\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T for PyTorch3D\n    R = R.permute(0, 2, 1)\n    T = T.permute(0, 2, 1)\n    R = R.unsqueeze(1)\n    T = T.unsqueeze(1)\n\n    # Compute intrinsics for NDC\n    znear = 0.1\n    f = (K[:, 0, 0] + K[:, 1, 1]) / 2\n    fx = f / W\n    fy = f / H\n    cx = K[:, 0, 2] / W\n    cy = K[:, 1, 2] / H\n    K = torch.tensor(\n        [[fx, 0.0, cx], [0.0, fy, cy], [0.0, 0.0, 1.0]]\n    )\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    K = batch.K\n    R = batch.R\n    T = batch.T\n    H = batch.meta.H[0].item()\n    W = batch.meta.W[0].item()\n\n    # Rotation\n    # R in PyTorch3D is applied on the right, so we have to transpose it\n    # We also have to switch the coordinate system from OpenCV to PyTorch3D (left up front)\n    # This is done by applying a 90 degree rotation around the X-axis\n    R = R.permute(0, 2, 1)\n    R = R @ torch.tensor([1, 0, 0], device=R.device, dtype=R.dtype) @ torch.tensor([0, -1, 0], device=R.device, dtype=R.dtype)\n    R = R.permute(0, 2, 1)\n\n    # Translation\n    # T in PyTorch3D is applied on the right, so we have to transpose it\n    # We also have to switch the coordinate system from OpenCV to PyTorch3D (left up front)\n    # This is done by applying a 90 degree rotation around the X-axis\n    T = T.permute(0, 2, 1)\n    T = T @ torch.tensor([1, 0, 0], device=T.device, dtype=T.dtype) @ torch.tensor([0, -1, 0], device=T.device, dtype=T.dtype)\n    T = T.permute(0, 2, 1)\n\n    # Camera center\n    # We can use the same transformation as for the translation\n    C = -R @ T\n\n    # Intrinsic matrix\n    # We have to use normalized device coordinates (NDC)\n    # We also have to switch the coordinate system from OpenCV to PyTorch3D (left up front)\n    # This is done by applying a 90 degree rotation around the X-axis\n    K = get_ndc_perspective_matrix(K, H, W, torch.tensor([1, 0], device=K.device, dtype=K.dtype) @ torch.tensor([0, -1], device=K.device, dtype"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract batch size\n    B = batch.meta.B\n\n    # Extract camera parameters\n    R = batch.R\n    T = batch.T\n    K = batch.K\n\n    # Extract image dimensions\n    H = batch.meta.H\n    W = batch.meta.W\n\n    # Check if batch size is 1\n    if B == 1:\n        # If batch size is 1, we can use the easy way\n        R = R.squeeze(0)\n        T = T.squeeze(0)\n        K = K.squeeze(0)\n        H = H.item()\n        W = W.item()\n    else:\n        # If batch size is larger than 1, we need to do the calculations for each batch element\n        # We need to transpose the rotation matrix to get the same coordinate system as PyTorch3D\n        R = R.permute(0, 2, 1)\n        # We need to flip the translation vector to get the same coordinate system as PyTorch3D\n        T = -T\n        # We need to calculate the intrinsic matrix for normalized device coordinates (NDC)\n        K = get_ndc_perspective_matrix(K, H, W, normalize_sum(R, dim=-1), K[:, :2, :2][:, :, :2])\n\n    # We need to correct the translation vector by the rotation matrix\n    T = -torch.bmm(R, T).squeeze(2)\n\n    # We need to correct the rotation matrix by the translation vector\n    C = -R.mT @ T  # B, 3, 1\n\n    # Return the corrected parameters\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract metadata\n    H, W = batch.meta.H, batch.meta.W\n    # Extract camera parameters\n    R, T, K = batch.R, batch.T, batch.K\n    # Check for batch size\n    assert (\n        R.size(0) == 1 or R.size(0) == batch.meta.H.size(0)\n    ), \"R and H must have the same batch size.\"\n    assert (\n        T.size(0) == 1 or T.size(0) == batch.meta.H.size(0)\n    ), \"T and H must have the same batch size.\"\n    assert (\n        K.size(0) == 1 or K.size(0) == batch.meta.H.size(0)\n    ), \"K and H must have the same batch size.\"\n    # Check if batch size is 1\n    if R.size(0) == 1:\n        R = R[0]\n        T = T[0]\n        K = K[0]\n        H, W = H[0], W[0]\n    # Adjust R and T\n    R = R.transpose(1, 2)\n    T = -T.transpose(1, 2)\n    # Compute camera center\n    C = R.matmul(T)\n    # Compute intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W, batch.meta.n, batch.meta.f)\n    # Return\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters\n    R = batch.R\n    T = batch.T\n    K = batch.K\n    H = batch.meta.H\n    W = batch.meta.W\n\n    # Apply coordinate system transformation\n    # R: B, 3, 3\n    # T: B, 3\n    # C: B, 3\n    C = torch.matmul(torch.transpose(R, 1, 2), T)  # B, 3\n\n    # Apply coordinate system transformation\n    # R: B, 3, 3\n    # T: B, 3\n    # C: B, 3\n    R = torch.matmul(R, R_trans)\n    T = torch.matmul(T, R_trans)\n    C = torch.matmul(C, R_trans)\n\n    # Calculate the intrinsic matrix for normalized device coordinates (NDC)\n    # K: B, 3, 3\n    # H: B\n    # W: B\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1)\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n            x, y, w, h,\n            gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        from glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        from glfw.glfw import glfw\n        "}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H,  # source\n            x, y, w, h,  # destination\n            gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # only color\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        old_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n            x, y, w, h,\n            gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        # Get the current OpenGL state\n        old_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        old_read_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        # Bind the Quad instance's framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Set the viewport and scissor box to the Quad instance's dimensions\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n\n        # Blit the Quad instance's framebuffer onto the current framebuffer\n        gl.glBlitFramebuffer(x, y, w, h,  # source\n                              0, 0, self.W, self.H,  # destination\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previous OpenGL state\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_read_fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, x + w, y + h,  # source\n                              0, 0, W, H,  # destination\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                              0, 0, W, H,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H,\n                              x, y, x + w, y + h,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        # Set the read framebuffer\n        old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Blit\n        gl.glBlitFramebuffer(0, 0, self.W, self.H,\n                              x, y, x + w, y + h,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, x + w, y + h,\n                              0, H - 1 - y, 0 + w, H - 1 - y,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glViewport(0, 0, W, H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # gl.glViewport(x, y, w, h)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             0, 0, self.W, self.H,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Render to the texture\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glDrawBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))  # render to the texture\n\n        # Restore the default framebuffer\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glDrawBuffer(gl.GL_BACK)\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Blitting is slower than drawing a quad, but is more flexible\n        # https://www.khronos.org/registry/OpenGL/specs/gl/4.5.1/gl-spec-4.5.1.txt#glBlitFramebuffer\n        W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBlitFramebuffer(0, 0, W, H,  # src\n                              x, y, w, h,  # dst\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # filter\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # https://www.khronos.org/registry/OpenGL/ cale_docs/man/man3/glBlitFramebuffer.html\n\n        # gl.glFlush()\n        # gl.glFinish()\n\n        # gl.glDrawBuffer(gl.GL_BACK)\n        # gl.glReadBuffer(gl.GL_FRONT)\n\n        # gl.glFlush()\n        # gl.glFinish()\n\n        # gl.glDrawBuffer(gl.GL_FRONT)\n        # gl.glReadBuffer(gl.GL_BACK)\n\n        # gl.glFlush()\n        # gl.glFinish()\n\n        # gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        # gl.glBlitFramebuffer(x, y, w, h,\n        #                      x, y, w, h,\n        #                      gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n\n        # gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # gl.glFinish()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not self.use_quad_cuda:\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n            gl.glBlitFramebuffer(x, y, w, h,\n                x, y, w, h,\n                gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # https://docs.pyopengl.org/reference/framebuffer_blit.html\n        # https://docs.pyopengl.org/reference/framebuffer_blit.html#gl-blit-framebuffer\n        # https://docs.pyopengl.org/reference/framebuffer_blit.html#gl-blit-framebuffer\n\n        # Get the current framebuffer\n        old_fbo = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n\n        # Bind the Quad instance's framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Blit the pixel block from the Quad instance's framebuffer object (FBO) to the current framebuffer\n        gl.glBlitFramebuffer(x, y, x + w, y + h,\n                              0, 0, W, H,  # the destination framebuffer's lower left corner\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n        # Blit the pixel block from the Quad instance's framebuffer object (FBO) to the current framebuffer\n        gl.glBlitFramebuffer(x, y, x + w, y + h,\n                              0, 0, W, H,  # the destination framebuffer's lower left corner\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            return\n\n        # Copy the content of the framebuffer object (FBO)\n        # into the default framebuffer (the screen)\n        # gl.glBlitFramebuffer(x, y, x + w, y + h,\n        #                       0, 0, W, H,\n        #                       gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBlitFramebuffer(x, y, x + w, y + h,\n                              0, 0, W, H,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the default framebuffer\n        # (the screen) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, x + w, y + h,\n            0, H - h - y, W - x, H - y,\n            gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n        gl.glViewport(0, 0, W, H)\n\n        # gl.glUseProgram(self.quad_program)  # use a different program\n        # gl.glActiveTexture(gl.GL_TEXTURE0)\n        # gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # gl.glBindVertexArray(self.vao)\n        # gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        # gl.glBindVertexArray(0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Copy the content of the current framebuffer to the Quad's framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, gl.GL_NONE)  # restore the previous read framebuffer\n        gl.glBlitFramebuffer(0, 0, W, H,  # src\n                              x, y, w, h,  # dst\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Copy the content of the Quad's framebuffer to the current framebuffer\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, gl.GL_NONE)  # restore the previous draw framebuffer\n        gl.glBlitFramebuffer(x, y, w, h,  # src\n                              0, 0, W, H,  # dst\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the viewport\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n        # log(yellow(f'Blitted {x:d}, {y:d}, {w:d}, {h:d}'))\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, camera.fbo)\n\n        gl.glBlitFramebuffer(x, y, w, h,\n                              0, 0, w, h,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    if t1.size(0) > 1:\n        t1 = t1.unsqueeze(1)\n        y1 = y1.unsqueeze(1)\n    t1 = t1.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n\n    t0 = t0.unsqueeze(2)\n    y0 = torch.cat([t0, y1], dim=2)\n\n    t1 = t1.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1)\n\n    t0 = t0.unsqueeze(1)\n    y0 = y0.unsqueeze(1"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # compute the cumulative sums\n    y1_cumsum = torch.cumsum(y1, dim=0)\n    t1_cumsum = torch.cumsum(t1, dim=0)\n\n    # compute the cumulative sums of the target time\n    t0_cumsum = torch.cumsum(t0, dim=0)\n\n    # compute the inner measure\n    inner = torch.sum(t0_cumsum * y1_cumsum, dim=0)\n\n    # compute the outer measure\n    outer = torch.sum(t0_cumsum * t1_cumsum, dim=0)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    if len(t0.shape) == 1:\n        t0 = t0.unsqueeze(0)\n    if len(t1.shape) == 1:\n        t1 = t1.unsqueeze(0)\n    if len(y1.shape) == 1:\n        y1 = y1.unsqueeze(0)\n    t0 = t0.unsqueeze(2)\n    t1 = t1.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n    t0 = t0.expand_as(t1)\n    t1 = t1.expand_as(t0)\n    y1 = y1.expand_as(t0)\n\n    inner = (t0 - t1).abs()\n    outer = (t0 - t1).pow(2)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1\n    y1_cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the inner measure\n    inner = y1_cumsum[t1]\n\n    # Compute the outer measure\n    outer = y1_cumsum[t0]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # t0 = t0.to(device)\n    # t1 = t1.to(device)\n    # y1 = y1.to(device)\n\n    # t0 = t0.contiguous().view(1, -1)\n    # t1 = t1.contiguous().view(1, -1)\n\n    # y1 = y1.contiguous().view(1, -1)\n\n    t0_sorted, t0_sorted_idx = t0.sort(1)\n    t1_sorted, t1_sorted_idx = t1.sort(1)\n    y1_sorted = y1.index_select(1, t1_sorted_idx)\n\n    t0_sorted = t0_sorted.contiguous().view(-1)\n    t1_sorted = t1_sorted.contiguous().view(-1)\n    y1_sorted = y1_sorted.contiguous().view(-1)\n\n    t0_sorted_idx = t0_sorted_idx.contiguous()\n    t1_sorted_idx = t1_sorted_idx.contiguous().view(-1)\n\n    # t0_sorted_idx = t0_sorted_idx.squeeze()\n    # t1_sorted_idx = t1_sorted_idx.squeeze()\n\n    # t0_sorted_idx = t0_sorted_idx.view(-1)\n    # t1_sorted_idx = t1_sorted_idx.view(-1)\n\n    t0_sorted_idx = t0_sorted_idx.view(1, -1)\n    t1_sorted_idx = t1_sorted_idx.view(1, -1)\n\n    # t0_sorted_idx = t0_sorted_idx.unsqueeze(0)\n    # t1_sorted_idx = t1_sorted_idx.unsqueeze(0)\n\n    # t0_sorted_idx = t0_sorted_idx.to(device)\n    # t1_sorted_idx = t1_sorted_idx.to(device)\n\n    inner = y1_sorted.index_select(1, t1_sorted_idx)\n    outer = y1.index_select(1, t0_"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1_cumsum = torch.cumsum(t1, dim=1)\n    t0_cumsum = torch.cumsum(t0, dim=1)\n    t1_cumsum_inv = torch.cumprod(1. / t1, dim=1)\n    t0_cumsum_inv = torch.cumprod(1. / t0, dim=1)\n\n    t1_cumsum_inv_t0_cumsum = torch.matmul(t1_cumsum_inv, t0_cumsum)\n    t1_cumsum_t0_cumsum_inv = torch.matmul(t1_cumsum, t0_cumsum_inv)\n    t1_t0 = t1 - t0\n\n    inner_measure = torch.sum(y1 * t0_cumsum_inv_t0_cumsum, dim=1)\n    outer_measure = torch.sum(y1 * t1_cumsum_t0_cumsum_inv, dim=1)\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # TODO: Add check for t0 and t1 having the same shape\n    assert t0.shape == t1.shape\n\n    # TODO: Add check for t1 being sorted\n    assert t1.is_sorted()\n\n    t0_idx = searchsorted(t1, t0)\n\n    # TODO: Add check for t0_idx being in the range of t1\n    assert t0_idx.min() >= 0\n    assert t0_idx.max() < t1.size(0)\n\n    # TODO: Add check for y1 being the same size as t1\n    assert y1.shape == t1.shape\n\n    # TODO: Add check for y1 having the same size as t1\n    assert y1.shape == t1.shape\n\n    # TODO: Add check for y1 being sorted\n    assert y1.is_sorted()\n\n    inner_measure = torch.zeros_like(t0)\n    outer_measure = torch.zeros_like(t0)\n\n    # TODO: Add check for t1_idx being the same size as t1\n    assert t1_idx.shape == t1.shape\n\n    # TODO: Add check for t1_idx being sorted\n    assert t1_idx.is_sorted()\n\n    # TODO: Add check for t1_idx being in the range of t1\n    assert t1_idx.min() >= 0\n    assert t1_idx.max() < t1.size(0)\n\n    # TODO: Add check for y1 being the same size as t1\n    assert y1.shape == t1.shape\n\n    # TODO: Add check for y1 having the same size as t1\n    assert y1.shape == t1.shape\n\n    # TODO: Add check for y1 being sorted\n    assert y1.is_sorted()\n\n    # TODO: Add check for t1_idx being the same size as t1\n    assert t1_idx.shape == t1.shape\n\n    # TODO: Add check for t1_idx being sorted\n    assert t1_idx.is_sorted()\n\n    # TODO: Add check for t1_idx being in the range of t1\n    assert t1_"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1_sorted, t_idx = searchsorted(t1, t0)\n    y1_sorted = y1[t_idx]\n    t0_inner = t1_sorted[0]\n    t0_outer = t1_sorted[-1]\n    return t0_inner, t0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    if not isinstance(t0, torch.Tensor) or not isinstance(t0, torch.Tensor):\n        raise ValueError('t0, t1 and y1 must be tensors')\n\n    # if t0.shape == t1.shape and t0.shape[0] == 1:\n    #     t0 = t0.expand_as(t1)\n\n    if t0.dim() > 1:\n        t0 = t0.reshape(-1)\n\n    if t1.dim() > 1:\n        t1 = t1.reshape(-1)\n\n    # if t0.shape == t1.shape:\n    #     t0 = t0.reshape(-1)\n    #     t1 = t1.reshape(-1)\n\n    t0 = t0.contiguous()\n    t1 = t1.contiguous()\n\n    t0 = t0.view(-1)\n    t1 = t1.view(-1)\n\n    # if t0.shape == t1.shape:\n    #     t0 = t0.reshape(-1)\n    #     t1 = t1.reshape(-1)\n\n    if t0.device != t1.device:\n        t0 = t0.to(t1.device)\n\n    if t0.dtype != t1.dtype:\n        t0 = t0.to(t1.dtype)\n\n    if t0.size(0) != t1.size(0):\n        raise ValueError('t0 and t1 must have the same length')\n\n    if y1.dim() > 1:\n        y1 = y1.reshape(-1)\n\n    if y1.device != t1.device:\n        y1 = y1.to(t1.device)\n\n    if y1.dtype != t1.dtype:\n        y1 = y1.to(t1.dtype)\n\n    if y1.size(0) != t1.size(0):\n        raise ValueError('y1 and t1 must have the same length')\n\n    t0_sorted, t0_idx = t0.sort(0)\n    t1_sorted, t1_idx = t1.sort(0"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sums\n    t1_cumsum = torch.cumsum(t1, dim=0)\n    y1_cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the inner measure\n    t0_inner = t0 - t1_cumsum\n\n    # Compute the outer measure\n    t0_outer = t0 - t1_cumsum.min(0)[0]\n\n    return t0_inner, t0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    if t1.size(0) > 1:\n        y1 = y1.unsqueeze(1)\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(1)\n    t0_cum = torch.cumsum(t0, dim=1)\n    t1_cum = torch.cumsum(t1, dim=1)\n    y1_cum = torch.cumsum(y1, dim=1)\n\n    return y1_cum - t0_cum, y1_cum - t1_cum\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    if t0.numel() == 1:\n        t0 = t0.unsqueeze(0)\n    if t1.numel() == 1:\n        t1 = t1.unsqueeze(0)\n\n    # Find the sorted indices of t1\n    t1_sorted_idx = torch.argsort(t1)\n    t1_sorted = t1[t1_sorted_idx]\n    y1_sorted = y1[t1_sorted_idx]\n\n    # Find the indices of t0 in t1_sorted\n    t0_sorted_idx = searchsorted(t0, t1_sorted)\n\n    # Calculate the inner measure\n    inner_measure = y1_sorted[t0_sorted_idx]\n\n    # Calculate the outer measure\n    outer_measure = y1_sorted[t0_sorted_idx + 1]\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0_cumsum = torch.cumsum(t0, dim=0)\n    t1_cumsum = torch.cumsum(t1, dim=0)\n\n    y1_cumsum = torch.cumsum(y1, dim=0)\n    y1_cumsum_rev = torch.cumsum(y1[::-1], dim=0)[::-1]\n\n    inner_measure = y1_cumsum - t1_cumsum * y1_cumsum_rev\n\n    outer_measure = torch.log(t1_cumsum) - t0_cumsum\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # assert t0.shape == t1.shape\n    # assert y1.numel() == t1.numel()\n    # assert t1.numel() > 0\n\n    # t0 = t0.unsqueeze(1)\n    # t1 = t1.unsqueeze(1)\n\n    # # TODO: is this needed?\n    # t0 = t0.float()\n    # t1 = t1.float()\n\n    t0 = t0.clone().detach()\n    t1 = t1.clone().detach()\n\n    if t1.dtype == torch.float16:\n        t1 = t1.to(torch.float32)\n\n    # TODO: is this needed?\n    # t0 = t0.float()\n    # t1 = t1.float()\n\n    # t0 = t0.to(torch.float32)\n    # t1 = t1.to(torch.float32)\n\n    t0 = t0.to(t1.device)\n    t1 = t1.to(t1.device)\n\n    t1_min = t1.min()\n    t1_max = t1.max()\n\n    t0_min = t0.min()\n    t0_max = t0.max()\n\n    t1_range = t1_max - t1_min\n    t0_range = t0_max - t0_min\n\n    # t1 = (t1 - t1_min) / t1_range\n    # t0 = (t0 - t0_min) / t0_range\n\n    t1 = t1 - t1_min\n    t0 = t0 - t0_min\n\n    y1 = y1.to(t1.device)\n\n    # TODO: is this needed?\n    # y1 = y1.to(torch.float32)\n\n    y1_min = y1.min()\n    y1_max = y1.max()\n    y1_range = y1_max - y1_min\n\n    y1 = (y1 - y1_min) / y1_range\n\n    # t0 = t0."}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # The following is the same as t1 - t0, but it is faster\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n\n    t0_ = t0.repeat(1, t1.size(0))\n    t1_ = t1.repeat(t0.size(1), 1)\n\n    t = t1_ - t0_\n\n    # The following is the same as y1 - y0, but it is faster\n    y0 = torch.zeros_like(y1)\n    y0[:, 0] = y1[:, -1]\n\n    y = y1 - y0\n\n    return t, y\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1_sorted, idx_sorted = torch.sort(t1)\n    y1_sorted = y1[idx_sorted]\n\n    t0_idx = torch.searchsorted(t1_sorted, t0, left_bound=True, right_bound=True)\n    t0_idx_left = t0_idx[0]\n    t0_idx_right = t0_idx[1]\n\n    t0_idx_left_sorted = idx_sorted[t0_idx_left]\n    t0_idx_right_sorted = idx_sorted[t0_idx_right]\n\n    t0_inner = y1_sorted[t0_idx_left_sorted]\n    t0_outer = y1_sorted[t0_idx_right_sorted]\n\n    return t0_inner, t0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # TODO: This is a bit of a hack, but we assume that the time dimension is the last one\n    # and we do not have any batch dimension.\n    t0_dim = t0.dim() - 1\n    t1_dim = t1.dim() - 1\n\n    # TODO: This is a bit of a hack, but we assume that the time dimension is the last one\n    # and we do not have any batch dimension.\n    t0_shape = t0.size()\n    t0_shape = list(t0_shape)\n    t1_shape = t1.size()\n    t1_shape = list(t1_shape)\n\n    t0_shape[t0_dim] = 1\n    t1_shape[t1_dim] = 1\n\n    t0 = t0.unsqueeze(-1)\n    t1 = t1.unsqueeze(-1)\n\n    # TODO: This is a bit of a hack, but we assume that the time dimension is the last one\n    # and we do not have any batch dimension.\n    y1_shape = y1.size()\n    y1_shape = list(y1_shape)\n\n    y1_shape[t1_dim] = 1\n\n    y1 = y1.unsqueeze(-1)\n\n    inner = torch.sum(t1, dim=t1_dim) - torch.sum(t0, dim=t0_dim)\n    outer = torch.sum(y1, dim=t1_dim)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(2)\n    t0_ = torch.min(t0, t1)\n    t1_ = torch.max(t0, t1)\n    t0_ = t0_.squeeze(2)\n    t1_ = t1_.squeeze(2)\n    y1_ = y1.unsqueeze(1)\n    y1_ = y1_.repeat(1, t0.size(1), 1)\n    y1_ = y1_.transpose(1, 2)\n    y1_ = y1_.squeeze(3)\n\n    inner = torch.sum(y1_ * (t1 - t0), 2)\n    outer = torch.sum(y1_ * torch.log(t1 - t0 + 1e-10), 2)\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    assert len(t0) == len(t1) == len(y1)\n\n    # construct inner measure\n    inner = torch.cumsum(y1, dim=0)\n\n    # construct outer measure\n    if t0.min() < 0:\n        t0 = t0.clamp(0, max(t0))\n    if t1.min() < 0:\n        t1 = t1.clamp(0, max(t1))\n\n    # construct outer measure\n    outer = torch.cumsum(t1, dim=0)\n\n    # construct outer measure\n    if t0.max() > t1.max():\n        outer = torch.cat([outer, torch.full_like(t0) * t1.max()], dim=0)\n\n    # construct outer measure\n    if t0.min() > t1.min():\n        outer = torch.cat([torch.full_like(t0) * t1.min(), outer], dim=0)\n\n    # construct outer measure\n    outer = outer.clamp(min=t1.min(), max=t1.max())\n\n    # construct outer measure\n    outer = outer.log()\n\n    # construct outer measure\n    outer = outer.to(y1.device)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # TODO: This implementation is not very efficient.\n    # TODO: It should be replaced with a more efficient implementation.\n    # TODO: The implementation below is a quick and dirty implementation for the paper.\n    # TODO: This implementation is not necessary for the paper.\n\n    # TODO: The implementation below is a quick and dirty implementation for the paper.\n    # TODO: This implementation is not necessary for the paper.\n\n    if t0.dim() != 1 or t0.shape[0] != y1.shape[0]:\n        raise ValueError(\n            \"t0 and y1 should have the same number of rows. t0.dim() == 1 and t0.shape[0] == y1.shape[0].\")\n    if t0.dim() > 1:\n        t0 = t0.unsqueeze(-1)\n    if t0.ndim == 1:\n        t0 = t0.unsqueeze(-1)\n    if t1.dim() > 1:\n        t1 = t1.unsqueeze(-2)\n    if t1.ndim == 2:\n        t1 = t1.unsqueeze(-1)\n\n    t1_sorted, idx = t1.sort(0)\n    y1_sorted = y1[idx]\n    t0_sorted = t0.gather(0, idx)\n    t1_cumsum = torch.cumsum(t1_sorted, 0)\n    y1_cumsum = torch.cumsum(y1_sorted, 0)\n\n    inner = y1_cumsum - t0_sorted * y1_sorted\n    outer = (t1_cumsum - t0_sorted) * y1_sorted\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env_inner, t_env_outer = inner_outer(t_env, t, w_env)\n    w_outer = torch.where(t <= t_env, w_env, torch.finfo(torch.float32).min)\n\n    return (w_outer - w)**2 * (t - t_env_inner)**2 + eps * (w_outer - w)**2 * (t - t_env_outer)**2\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env_inner, t_env_outer = inner_outer(t, t_env, w_env)\n    w_outer = w_env_outer = torch.where(t_env_inner > t, t_env_outer, w_env_outer)\n    return F.l1_loss(w, w_outer) + eps * F.l1_loss(t_env_inner, t)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env_padded = torch.cat([t_env, t_env[..., :-1:1]], dim=-1)\n    w_env_padded = torch.cat([torch.zeros_like(w_env), w_env], dim=-1)\n    w_outer, w_inner = inner_outer(t_env_padded, t, w_env_padded)\n    return torch.sum(torch.pow(w - w_outer, 2) / (torch.pow(w + eps, 2) + eps))\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # t_env_cumsum = torch.cumsum(t_env, dim=-1)\n    # w_env_cumsum = torch.cumsum(w_env, dim=-1)\n    # t_cumsum = torch.cumsum(t, dim=-1)\n    # w_cumsum = torch.cumsum(w, dim=-1)\n    # t_cumsum = torch.cat([torch.zeros_like(t), t_cumsum], dim=-1)\n    # w_cumsum = torch.cat([torch.zeros_like(w), w_cumsum], dim=-1)\n    # t_env_cumsum = torch.cat([torch.zeros_like(t_env), t_env_cumsum], dim=-1)\n    # w_env_cumsum = torch.cat([torch.zeros_like(w_env), w_env_cumsum], dim=-1)\n\n    t_cumsum = torch.cat([torch.zeros_like(t), torch.cumsum(t, dim=-1)], dim=-1)\n    w_cumsum = torch.cat([torch.zeros_like(w), torch.cumsum(w, dim=-1)], dim=-1)\n\n    t_env_cumsum = torch.cat([torch.zeros_like(t_env), torch.cumsum(t_env, dim=-1)], dim=-1)\n    w_env_cumsum = torch.cat([torch.zeros_like(w_env), torch.cumsum(w_env, dim=-1)], dim=-1)\n\n    w_outer = torch.where(t_cumsum > t_env_cumsum, w_env_cumsum, w_cumsum)\n    w_outer = torch.where(t_cumsum < t_env_cumsum[..., :-1], w_env_cumsum[..., 1:], w_outer)\n\n    w_inner = w - w_outer\n\n    return F.l1_loss(w_inner, torch.zeros_like(w), reduction=\"mean\")\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env_padded = torch.cat([torch.zeros_like(t_env[..., :1]), t_env, torch.ones_like(t_env[..., :1])], dim=-1)  # 129\n    w_env_padded = torch.cat([torch.zeros_like(w_env[..., :1]), w_env, torch.ones_like(w_env[..., :1])], dim=-1)\n\n    # calculate inner and outer measures\n    inner, outer = inner_outer(t, t_env_padded, w_env_padded)\n\n    # calculate the loss\n    loss = torch.where(outer >= w[..., None], w[..., None] * (outer - inner) ** 2, torch.tensor(0, dtype=w.dtype, device=w.device))\n    loss = torch.sum(loss) / (torch.sum(outer) + eps)\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env = torch.clamp(w_env, 0, 1)\n    w_env = w_env / (w_env.sum(dim=-1, keepdim=True))\n    w_env = w_env / (eps + w_env.sum(dim=-1, keepdim=True))\n\n    w_outer = torch.where(t[..., 1:] <= t_env[..., :-1], w_env[..., 1:], 0)\n\n    return (w - w_outer) ** 2\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_diff = t - t_env  # 128\n    w_diff = w - w_env  # 128\n\n    # t_diff_norm = torch.norm(t_diff, p=2, dim=-1)\n    # w_diff_norm = torch.norm(w_diff, p=2, dim=-1)\n    t_diff_norm = torch.sum(t_diff ** 2, dim=-1)\n    w_diff_norm = torch.sum(w_diff ** 2, dim=-1)\n\n    # loss = torch.maximum(w_diff_norm, eps) + torch.maximum(t_diff_norm, eps)\n    loss = torch.maximum(w_diff_norm, eps) + torch.maximum(t_diff_norm, eps)\n\n    # loss = torch.where(t_diff_norm <= w_diff_norm, t_diff_norm, w_diff_norm)\n    # loss = torch.where(t_diff_norm <= w_diff_norm, t_diff_norm, w_diff_norm) + eps\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # t_env_1 = t_env[..., :-1]\n    # t_env_2 = t_env[..., 1:]\n    t_env_1 = t_env[..., :-1]\n    t_env_2 = t_env[..., 1:]\n    t_env_1 = torch.cat([t_env_1, t_env_2], dim=-1)\n\n    t_1 = t[..., :-1]\n    t_2 = t[..., 1:]\n\n    t_1 = torch.cat([t_1, t_2], dim=-1)\n\n    # t_1 = torch.where(t_1 == 0, t_env_1, t_1)\n    # t_2 = torch.where(t_2 == 0, t_env_2, t_2)\n    t_1 = torch.where(t_1 == 0, t_env_1, t_1)\n    t_2 = torch.where(t_2 == 0, t_env_2, t_2)\n\n    # print(t_env_1.shape, t_env_2.shape, t_1.shape, t_2.shape)\n    # print(t_env_1.dtype, t_env_2.dtype, t_1.dtype, t_2.dtype)\n\n    # print(t_env_1.shape, t_env_2.shape, t_1.shape, t_2.shape)\n    # print(t_env_1.dtype, t_env_2.dtype, t_1.dtype, t_2.dtype)\n\n    # print(t_env_1.shape, t_env_2.shape, t_1.shape, t_2.shape)\n\n    # print(t_env_1.shape, t_env_2.shape, t_1.shape, t_2.shape)\n    # print(t_env_1.dtype, t_env_2.dtype, t_1.dtype, t_2.dtype)\n\n    # print(t_env_1.shape, t_env_2.shape, t_1."}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_inner, t_outer = inner_outer(t, t_env, w_env)\n\n    # loss = (w - t_outer) ** 2\n    loss = (w - t_outer) * (w - t_outer)\n    # loss = loss / (2 * torch.max(eps, t_outer))\n    loss = loss / (2 * torch.maximum(eps, t_outer))\n    # loss = loss * (2 * t_outer)\n    loss = loss * (2 * t_outer)\n\n    # loss = loss + (t_inner - w) ** 2\n    loss = loss + (t_inner - w) * (t_inner - w)\n\n    # loss = loss / (2 * torch.max(eps, t_inner))\n    loss = loss / (2 * torch.maximum(eps, t_inner))\n\n    # loss = loss * (2 * t_inner)\n    loss = loss * (2 * t_inner)\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # t_env = t_env.unsqueeze(-1)\n    # w_env = w_env.unsqueeze(-2)\n    # t = t.unsqueeze(-1)\n    # w = w.unsqueeze(-2)\n    # t_env = t_env.unsqueeze(-1)\n    # w_env = w_env.unsqueeze(-2)\n    # t = t.unsqueeze(-1)\n    # w = w.unsqueeze(-2)\n\n    w_env_t = torch.take_along_dim(w_env, t, dim=-2)\n    t_t = torch.take_along_dim(t, t, dim=-1)\n    t_t_env = torch.take_along_dim(t_env, t, dim=-1)\n    w_env_t_t_env = torch.take_along_dim(w_env_t, t_t_env, dim=-1)\n    return F.relu(1 - w_env_t_t_env) * (w_t_t_env - w_env_t_t_env) ** 2 + eps\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the outer loss\n    t_env_shift = t_env - t[..., :-1]  # 127\n    w_env_outer = w_env - w[..., :-1]  # 127\n    w_outer = torch.where(t_env_shift > 0, w_env_outer, torch.zeros_like(w_env_outer))  # 127\n    loss_outer = (w_outer * t_env_shift ** 2).sum(-1)\n\n    # calculate the inner loss\n    t_shift = t[..., 1:] - t[..., :-1]  # 128\n    w_inner = w[..., 1:]  # 128\n    loss_inner = (w_inner * t_shift ** 2).sum(-1)\n\n    # calculate the loss\n    loss = w_outer + loss_inner + (eps * loss_outer)\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # TODO: this should be done on the fly\n    # TODO: this should be done on the fly\n    if w_env.shape[-1] == 1:\n        w_env = torch.cat([torch.zeros_like(w_env), w_env], dim=-1)\n\n    # TODO: this should be done on the fly\n    if t.shape[-1] == 1:\n        t = torch.cat([t, t_env], dim=-1)\n\n    # TODO: this should be done on the fly\n    w_env_inner, w_env_outer = inner_outer(t[..., :-1], t_env, w_env)\n    w_inner, w_outer = inner_outer(t, t_env, w)\n\n    w_outer_scaled = (w_env_outer - w_outer) ** 2\n    w_inner_scaled = (w_inner - w_env_inner) ** 2\n\n    loss = w_outer_scaled + w_inner_scaled\n\n    return torch.where(w_outer_scaled > 0, loss, 0)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the difference between the target and environment positions\n    diff = t_env[..., :-1] - t[..., :-1]\n\n    # calculate the difference between the target and environment weights\n    diff_w = w_env[..., 1:] - w[..., :-1]\n\n    # calculate the loss\n    loss = (diff_w * diff ** 2).sum(-1)\n\n    # apply the half-quadratic loss\n    loss = 2 * torch.where(w[..., :-1] < w_env[..., 1:], torch.zeros_like(loss), loss)\n\n    # add a small epsilon to prevent division by zero\n    loss = loss + eps\n\n    # calculate the loss based on the difference between target weights and the upper envelope\n    loss = w[..., :-1] - w_env[..., 1:]\n\n    # return the calculated loss\n    return loss / loss.sum(-1, keepdim=True)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t = t.unsqueeze(-1)  # 128, 1, 1\n    t_env = t_env.unsqueeze(-1)  # 128, 1, 2\n\n    # The inner and outer measures are calculated on (t_env, w_env) and (t, w)\n    inner_env, outer_env = inner_outer(t_env, w_env, w_env)\n    inner, outer = inner_outer(t, w, w_env)\n\n    # The loss is defined as the sum of the two losses, scaled by the difference between the target and environment weights\n    return (outer - outer_env) * outer + (outer - inner) * inner\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env_outer = torch.where(t_env[..., 1:] <= t[..., :-1], t_env[..., 1:] - t[..., :-1], 0)\n    w_env_outer = torch.where(t_env[..., 1:] <= t[..., :-1], w_env[..., 1:] - w_env[..., :-1], 0)\n\n    # t_outer = torch.cat([t_env_outer, t_env[..., 1:]], dim=-1)\n    # w_outer = torch.cat([w_env_outer, w_env[..., 1:]], dim=-1)\n    t_outer = torch.cat([t_env_outer, torch.zeros_like(t_env[..., :1])], dim=-1)\n    w_outer = torch.cat([w_env_outer, torch.zeros_like(w_env[..., :1])], dim=-1)\n\n    t_inner, t_outer = inner_outer(t, t_env, t_outer)\n    w_inner, w_outer = inner_outer(w, w_env, w_outer)\n\n    # t_outer = torch.cat([t_outer, t_env_outer], dim=-1)\n    # w_outer = torch.cat([w_outer, w_env_outer], dim=-1)\n\n    # t_outer = torch.cat([t_outer, torch.zeros_like(t_env[..., :1])], dim=-1)\n    # w_outer = torch.cat([w_outer, torch.zeros_like(w_env[..., :1])], dim=-1)\n\n    # w_outer_max = torch.max(w_outer, dim=-1, keepdim=True)[0]\n    # t_outer = t_outer / w_outer_max\n    # w_outer = w_outer / w_outer_max\n\n    t_outer = t_outer / w_outer\n    w_outer = w_outer / w_outer\n\n    return 2 * (w_outer - w_inner) * (t_outer - t_inner) + torch.where(w_inner > w_outer, 0"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env = torch.clamp(w_env, min=0, max=1)  # 128\n    w_env = w_env / (1 - eps)\n    w_env = torch.where(w_env > 1, 1, w_env)  # 128\n\n    w = torch.clamp(w, min=0, max=1)\n    w = w / (1 - eps)\n    w = torch.where(w > 1, 1, w)  # 128\n\n    t_diff = t - t_env\n    w_diff = w - w_env\n\n    # t_diff.shape = (..., 128)\n    # w_diff.shape = (..., 128)\n    # w_env.shape = (..., 128)\n    # w.shape = (..., 128)\n    # t.shape = (..., 129)\n    # t_env.shape = (..., 129)\n\n    # w_diff = torch.unsqueeze(w_diff, -1)\n    # w_env = torch.unsqueeze(w_env, -1)\n    # w = torch.unsqueeze(w, -1)\n\n    # w_diff.shape = (..., 128, 1)\n    # w_env.shape = (..., 128, 1)\n    # w.shape = (..., 128, 1)\n    # t.shape = (..., 129, 1)\n    # t_env.shape = (..., 129, 1)\n\n    # t_diff = torch.unsqueeze(t_diff, -1)\n    # t_env = torch.unsqueeze(t_env, -1)\n\n    # t_diff.shape = (..., 128, 1)\n    # t_env.shape = (..., 128, 1)\n\n    # t_diff = torch.unsqueeze(t_diff, -1)\n    # t_env = torch.unsqueeze(t_env, -1)\n\n    # t_diff.shape ="}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_diff = t[..., 1:] - t_env\n    w_diff = w - w_env\n    w_diff_abs = torch.abs(w_diff)\n\n    # for small weights, we use a quadratic loss\n    w_diff_abs_sq = w_diff_abs**2\n    w_diff_abs_sq_env = w_diff_abs_sq.clamp(min=eps)\n    w_diff_sq_env = w_diff_env**2\n    loss_env = w_diff_sq_env + w_diff_abs_sq_env\n    loss_env = torch.where(w_diff_abs > w_diff_env, w_diff_sq_env, loss_env)\n    loss = w_diff_abs_sq_env + w_diff_abs * loss_env\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env_max = torch.max(w_env, w)  # 128\n    w_env_min = torch.min(w_env, w)  # 128\n\n    t_env_inner, t_env_outer = inner_outer(t_env, t, w_env)  # 127\n\n    w_env_inner = torch.where(t_env_outer[..., 1:] >= t_env_inner, w_env_max - t_env_outer, 0)  # 127\n    w_env_outer = torch.where(t_env_inner >= t_env_outer[..., :-1], w_env_outer, 0)  # 127\n\n    w_env_outer = torch.where(w_env_outer > w, 0, w_env_outer)  # 127\n\n    w_env_inner = torch.where(w_env_inner > w, 0, w_env_inner)  # 127\n\n    return torch.where((w_env_outer > 0) & (w > 0), 0.5 * (w - w_env_outer)**2 / w_env_outer + 0.5 * (w - w_env_inner)**2 / w_env_inner, 0) + 0.1 * (w - w_env_max) * (w_env_max - w_env_min) / eps\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env = t_env.unsqueeze(-1)\n    w_env = w_env.unsqueeze(-1)\n\n    t_diff = t_env - t\n    w_diff = w_env - w\n\n    inner_t, outer_t = inner_outer(t_diff, t_env, w_diff)\n\n    return torch.where(outer_t < eps, outer_t, outer_t**2 / (2 * eps) + eps * inner_t)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    if w_env.ndim == 2 and t_env.ndim == 1:\n        w_env = w_env.unsqueeze(1)\n\n    if w_env.ndim == 2 and t_env.ndim == 2:\n        w_env = w_env.unsqueeze(1)\n\n    if w_env.ndim == 3 and t_env.ndim == 2:\n        w_env = w_env.unsqueeze(2)\n\n    if w_env.ndim == 2 and t.ndim == 1:\n        t = t.unsqueeze(1)\n\n    if w_env.ndim == 2 and t.ndim == 2:\n        t = t.unsqueeze(1)\n\n    if w_env.ndim == 3 and t.ndim == 2:\n        t = t.unsqueeze(2)\n\n    t_inner, t_outer = inner_outer(t, t_env, w_env)\n\n    w_inner = w - t_inner\n    w_outer = w_outer_env = w_env - t_outer\n\n    # TODO: this is not the same as in mipnerf360\n    # w_outer = torch.cat([torch.zeros_like(w_env), w_outer_env], dim=-1)\n\n    loss = (w_inner * w_inner) / (2 * (w_outer + eps))\n    loss = torch.sum(loss, dim=-1)\n    loss = torch.mean(loss)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # t, w = matchup_channels(t, w)\n    _, w_outer = inner_outer(t, t, w)\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).pow(2) / (w + 1e-6)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    _, w_outer = inner_outer(t, t, w)\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).clip(0.).pow(2) / (w + 1e-8)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    _, w_outer = inner_outer(t, t, w)\n\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).pow(2) / (w + 1e-8)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_ = torch.cat([torch.zeros_like(t[..., :1]), torch.cumsum(t, dim=-1)], dim=-1)\n    w_ = torch.cat([torch.zeros_like(w[..., :1]), torch.cumsum(w, dim=-1)], dim=-1)\n    return (t_ - w_).pow(2).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_ = torch.cat([t[..., :-1], torch.zeros_like(t[..., -1:, :1])], dim=-1)\n    w_ = torch.cat([w[..., 1:], torch.zeros_like(w[..., -1:, :1])], dim=-1)\n\n    # loss_inter = (w_ - w).pow(2).mean()\n    loss_intra = (w_ * (t_ - t).pow(2)).sum(-1).mean()\n    return loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    _, w_outer = inner_outer(t, t, w)\n\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).clip(0.).pow(2) / (w + 1e-4)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t, w = torch.cat([torch.zeros_like(t[..., :1]), t], dim=-1), torch.cat([w[..., :1], w], dim=-1)\n    _, w_outer = inner_outer(t, t, w)\n\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).clip(0.).pow(2) / (w + 1e-6)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_ = torch.cat([torch.zeros_like(t[..., :1]), torch.cumsum(t, dim=-1)], dim=-1)\n    w_ = torch.cat([torch.zeros_like(w[..., :1]), w], dim=-1)\n\n    w_outer, _ = inner_outer(t, t_, w_)\n    return (w_outer - w).pow(2) / (w + 1e-8).clamp_min(1e-8)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t, w = t.contiguous(), w.contiguous()\n\n    # Compute the inter-interval loss\n    _, w_outer = inner_outer(t, t, w)\n\n    # Compute the intra-interval loss\n    w_inner = (t[..., 1:] - t[..., :-1]) * w[..., :-1]\n    w_inner = torch.where(w_inner > w_outer, torch.zeros_like(w_inner), w_inner)\n    w_inner = torch.where(w_inner > 0, torch.ones_like(w_inner), torch.zeros_like(w_inner))\n    w_inner = torch.where(w_inner == 1, torch.ones_like(w_inner), torch.zeros_like(w_inner))\n    w_inner = w_inner * w_outer\n    w_inner = torch.where(w_inner > 0, w_inner, torch.zeros_like(w_inner))\n\n    # Combine the two losses\n    return (w_outer - w_inner).pow(2).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval distortion loss.\n    t_outer, w_outer = inner_outer(t, t[..., 1:], w[..., :-1])\n    inter_interval_loss = (w_outer - w).pow(2) / (w + 1e-12)\n\n    # Calculate the intra-interval distortion loss.\n    t_inner, w_inner = inner_outer(t, t[..., :-1], w[..., 1:])\n    t_inner, w_inner = blur_stepfun(t_inner, w_inner, 1.0)\n    t_inner_outer, w_inner_outer = inner_outer(t, t_inner, w_inner)\n    intra_interval_loss = (w_inner_outer - w_inner).pow(2) / (w_inner + 1e-12)\n\n    # Combine the inter-interval and intra-interval losses.\n    return inter_interval_loss + intra_interval_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_ = torch.cat([t[..., 1:], torch.zeros_like(t[..., :1])], dim=-1)\n    w_ = torch.cat([torch.zeros_like(w[..., :1]), w], dim=-1)\n    return (t - t_ * w).pow(2).sum(-1).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, t_outer = inner_outer(t, t, w)\n    return lossfun_outer(t_inner, w, t_outer, w)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    _, w_outer = inner_outer(t, t, w)\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).clip(0.).pow(2) / (w + 1e-8)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # TODO: make this a function\n    t_env, w_env = blur_stepfun(t, w, 0.5)\n    w_env = torch.clip(w_env, 0., 1.)\n    w_env = w_env.clamp_min(1e-3)\n    return lossfun_zip_outer(t, w, t_env, w_env, 0.5)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    w_outer = torch.cat([torch.zeros_like(w[..., :1]), torch.cumsum(w, dim=-1)], dim=-1)\n    y0_outer = torch.cat([torch.zeros_like(w[..., :1]), torch.cumsum(w, dim=-1)], dim=-1)\n    _, y0_outer = inner_outer(t, t, y0_outer)\n\n    # weighted sum of the inter-interval losses\n    y0_outer_loss = (w[..., :-1] * (y0_outer[..., 1:] - y0_outer[..., :-1])).sum(dim=-1)\n    # weighted sum of the intra-interval losses\n    y0_inner_loss = (w[..., :-1] * (y0_outer[..., :-1] - y0_outer[..., :-2]).abs()).sum(dim=-1)\n\n    # combine the inter-interval and intra-interval losses\n    return y0_outer_loss + y0_inner_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_ = t.clone()\n\n    # calculate the inter-interval loss\n    t_ = t.unsqueeze(-1) + t.unsqueeze(-2)\n    _, w_outer = inner_outer(t, t_, w)\n    inter_loss = (w - w_outer).clip(0.).pow(2)\n\n    # calculate the intra-interval loss\n    t_ = t.unsqueeze(-1) + t.unsqueeze(-2)\n    t_ = torch.cat([torch.zeros_like(t_[:, :, 0, :1]), t_], dim=-2)\n    t_ = torch.cat([t_, torch.zeros_like(t_[:, :, -1, :1])], dim=-1)\n    _, w_outer = inner_outer(t, t_, w)\n    intra_loss = (w - w_outer).clip(0.).pow(2)\n\n    # combine inter-interval and intra-interval losses\n    return (inter_loss + intra_loss) / 2.0\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    w_outer = torch.cat([torch.zeros_like(w[..., :1]), torch.cumsum(w, dim=-1)], dim=-1)\n    y0_inner, y0_outer = inner_outer(t, t, w_outer)\n    y0_inner_w = w_outer * y0_inner\n    y0_outer_w = w_outer * y0_outer\n\n    # y0_outer_w.shape: [b, 128, 128]\n    y0_outer_w_sum = torch.sum(y0_outer_w, dim=-1)\n    y0_outer_w_sum_inv = torch.sum(1 / y0_outer_w_sum, dim=-1)\n    y0_outer_w_sum_inv_y0_outer_w = y0_outer_w_sum_inv * y0_outer_w\n\n    y0_outer_w_sum_inv_y0_inner_w = torch.sum(y0_outer_w_sum_inv * y0_inner_w, dim=-1)\n    y0_inner_w_sum = torch.sum(y0_inner_w, dim=-1)\n\n    # y0_outer_w_sum_inv_y0_outer_w.shape: [b, 128]\n    # y0_outer_w_sum_inv_y0_inner_w.shape: [b, 128]\n    # y0_inner_w_sum.shape: [b, 1]\n    return (y0_outer_w_sum_inv_y0_outer_w - y0_outer_w_sum_inv_y0_inner_w) ** 2 / y0_inner_w_sum\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # get the indices of the sorted values\n    idx, _ = torch.sort(torch.cat([t[..., :1], t[..., :-1]], dim=-1))\n\n    # compute the inter-interval loss\n    t_inter = torch.cat([t[..., :1], t[..., 1:]], dim=-1)\n    w_inter = torch.cat([w[..., :-1], torch.zeros_like(w[..., :1])], dim=-1)\n    inter_loss = lossfun_outer(t_inter, w_inter, t, w)\n\n    # compute the intra-interval loss\n    t_intra = torch.cat([torch.zeros_like(t[..., :1]), t[..., 1:]], dim=-1)\n    w_intra = torch.cat([w[..., 1:], torch.zeros_like(w[..., :1])], dim=-1)\n    intra_loss = lossfun_outer(t_intra, w_intra, t, w)\n\n    # combine the losses\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # The function assumes that the targets are ordered in the last dimension.\n    t, w = torch.sort(t, dim=-1, descending=True)\n    # The function assumes that the weights are monotonically non-increasing.\n    w = torch.cumsum(w, dim=-1)\n    w = torch.cat([torch.zeros_like(w[..., :1]), w], dim=-1)\n    # Compute the inter-interval loss\n    w_outer = w - torch.diff(t, dim=-1)\n    w_outer = torch.where(w_outer < 0, torch.zeros_like(w_outer), w_outer)\n    w_outer = torch.where(w_outer > 1, torch.ones_like(w_outer), w_outer)\n    loss = w_outer.pow(2)\n\n    # Compute the intra-interval loss\n    # w_inner = torch.diff(w, dim=-1)\n    # loss += w_inner.pow(2)\n\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    assert t.size() == w.size()\n\n    # Compute the distance between the target tensor and the cumulative sum of the weight tensor\n    # This is the distance between the target and the center of each interval\n    cy = torch.cat([torch.zeros_like(w[..., :1]), torch.cumsum(w, dim=-1)], dim=-1)\n    t_ = torch.cat([t[..., :-1], t[..., 1:]], dim=-1)\n\n    # Compute the inter-interval loss\n    t_dist_loss = (t_ - cy).pow(2).mean()\n\n    # Compute the intra-interval loss\n    t_dist_loss_intra = torch.zeros_like(t_dist_loss)\n    # Compute the inner and outer measures for each interval\n    _, t_outer = inner_outer(t, t_, cy)\n    # Compute the intra-interval loss for each interval\n    t_dist_loss_intra += ((t_outer - w).clamp(min=0).pow(2) / w).mean()\n\n    # Return the combined loss\n    return t_dist_loss + t_dist_loss_intra\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    return interpolate(cw0, t, ps)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(w, t, ps)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match up the channels\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the percentiles\n    return interpolate(cw, ps, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    return interpolate(ps, cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    # print(t.shape, w.shape, ps)\n    cw = integrate_weights(w)\n    # print(cw.shape)\n    ps = torch.tensor(ps, device=t.device, dtype=t.dtype)\n    return interpolate(ps, cw, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Make sure the weights sum to 1.\n    w = w / w.sum(dim=-1)\n\n    # Integrate the weights.\n    cw = integrate_weights(w)\n\n    # Match the channels of t and cw.\n    t, cw = matchup_channels(t, cw)\n\n    # Compute the weighted percentiles.\n    return interpolate(cw, ps, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n\n    # interpolate\n    ps = torch.as_tensor(ps)\n    ps = ps.to(t.device, t.dtype)\n    if ps.ndim == 1:\n        ps = ps[None]\n\n    return interpolate(cw0, ps, ps + 1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(cw, t, torch.tensor(ps))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    # Integrate the weights to get the CDF\n    cw0 = integrate_weights(w)\n\n    # Interpolate the CDF to get the percentiles\n    return interpolate(torch.linspace(0.0, 1.0, t.shape[-1] + 1)[..., None], cw0, ps)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    ps = torch.as_tensor(ps)\n    return interpolate(cw, ps, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    return interpolate(cw0, ps, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    return interpolate(cw0, torch.cat([t, t.new_tensor([t.max().item() + 1])], dim=-1), ps\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    # The CDF is the integral of the weights.\n    cw = integrate_weights(w)\n    # Interpolate the CDF to the given percentiles.\n    # The output is the same shape as t and w, but with one more dimension.\n    # The last dimension is the percentiles.\n    cw0 = interpolate(torch.tensor(ps), cw[..., 0], cw[..., 1])\n    return cw0\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    # TODO: add support for input tensor with more than 3 dims\n    assert t.ndim == w.ndim + 1, \"t and w must have the same number of dims\"\n\n    # integrate the weights\n    cw = integrate_weights(w)\n    # find the percentiles\n    p = interpolate(cw, ps, cw)\n    # find the corresponding values\n    return interpolate(t, p, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n\n    # compute the percentiles\n    ps = torch.as_tensor(ps, device=t.device, dtype=t.dtype)\n    p_indices = torch.cumsum(ps, dim=-1)\n    p_indices = torch.clamp(p_indices, 0, cw.shape[-1] - 1)\n\n    return interpolate(p_indices, cw.T, t).T\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(w, t, ps)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    # Integrate the weights.\n    w = integrate_weights(w)\n\n    # Interpolate the weights to get the percentiles.\n    return interpolate(ps, w[..., 1:], w[..., :-1])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n\n    # Find the indices of the percentiles in the CDF\n    ps = torch.as_tensor(ps)\n    indices = torch.cumsum(ps, dim=-1)\n    indices = indices.clamp(min=0, max=cw.shape[-1])\n\n    # Interpolate the values at the CDF percentiles\n    return interpolate(cw, t, cw.gather(dim=-1, index=indices))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(ps, w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    # Integrate the weights.\n    cw0 = integrate_weights(w)\n    # Interpolate the integrated weights to get the CDF.\n    cdf = interpolate(ps, cw0[..., :-1], cw0[..., 1:])\n    # Find the index of the CDF value at each percentile.\n    indices = torch.searchsorted(cdf, 1.0, dim=-1)\n    # Return the corresponding value from the input tensor.\n    return t[..., indices]\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    w, t = matchup_channels(w, t)\n    # Compute the CDF.\n    cw = integrate_weights(w)\n    # Sample from the CDF.\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n    t_new = interpolate(u, cw, t)\n    # Perturb the samples.\n    if perturb:\n        if single_jitter:\n            t_new += torch.rand_like(t_new)\n        else:\n            t_new = t_new + torch.rand_like(t_new)\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    if perturb:\n        # Sample u from a uniform distribution on [0, 1).\n        u = torch.rand_like(t)\n        # Sample from the inverse CDF.\n        t_new = invert_cdf(u, t, w)\n    else:\n        # Sample from the CDF.\n        t_new = interpolate(u, integrate_weights(w), t)\n    if single_jitter:\n        # Apply jitter to the samples.\n        t_new = t_new + torch.randn_like(t_new)\n    else:\n        # Apply jitter to each sample.\n        t_new = t_new + torch.randn_like(t_new) * torch.std(t_new, dim=-1, keepdim=True)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Compute the CDF for each sample.\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n    t_new = interpolate(u, cw, t)\n    # Apply perturbation.\n    if perturb:\n        t_new = t_new + (torch.rand_like(t_new) - 0.5) * (t[1:] - t[:-1])\n    if single_jitter:\n        t_new = t_new + (torch.rand_like(t_new) - 0.5) * (t[1:] - t[:-1])\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Generate the CDF interpolants for the samples.\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Perturb the samples if requested.\n    if perturb:\n        if single_jitter:\n            t_new = t_new + torch.randn_like(t_new) * (t[-1] - t[0])\n            # t_new = t_new + torch.randn_like(t_new) * (t_new[-1] - t_new[0])\n        else:\n            t_new = t_new + torch.randn_like(t_new) * (t_new[-1] - t_new[0])\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Sanity checks\n    assert t.ndim == w.ndim + 1, \"t and w must have the same number of dimensions\"\n    assert t.shape[-1] == w.shape[-1] + 1, \"t and w must have the same number of bins\"\n    assert torch.allclose(torch.cumsum(w, dim=-1), torch.ones_like(w)), \"w must sum to 1\"\n\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n    cw = cw.reshape([-1, cw.shape[-1]])\n\n    # Generate samples from the CDF.\n    u = torch.rand(size=(num_samples,) + t.shape[:-1], device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Perturb the samples if necessary.\n    if perturb:\n        if single_jitter:\n            jitter_t = torch.randn(size=(num_samples,) + t.shape[:-1], device=t.device)\n            t_new = t_new + jitter_t\n        else:\n            jitter_t = torch.randn(size=(num_samples, 1) + t.shape[:-1], device=t.device)\n            t_new = t_new + jitter_t\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that the weights are normalized.\n    w = w / torch.sum(w)\n\n    # Compute the CDF and inverse CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Generate a uniform sample in the CDF domain.\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device, dtype=torch.float32)\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n    if perturb:\n        # Perturb the samples.\n        if single_jitter:\n            t_new = t_new + torch.rand(num_samples, *t.shape[1:], device=t_new.device, dtype=t_new.dtype)\n        else:\n            t_new = t_new + torch.rand_like(t_new)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    if perturb:\n        # TODO: make this work for more than 1D\n        if single_jitter:\n            jitter = torch.randn(1, device=t.device)\n            jitter = jitter.expand(num_samples, -1)\n        else:\n            jitter = torch.randn(num_samples, 1, device=t.device)\n        t_new = t.unsqueeze(-1) + jitter\n    else:\n        t_new = t.unsqueeze(-1)\n\n    # Integrate weights to compute CDF.\n    cw = integrate_weights(w)\n\n    # Interpolate into the inverse CDF.\n    u = torch.rand(num_samples, 1, device=t.device)\n    t_new = interpolate(u, cw, t_new)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Sample from the CDF.\n    u = torch.rand(num_samples, device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # If we want to perturb the samples, jitter them.\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to each sample along each dimension.\n            jitter = torch.rand_like(t_new) * 2 * 1e-2 - 1e-1\n            t_new = t_new + jitter\n        else:\n            # Apply jitter to each sample independently.\n            for i in range(t_new.ndim):\n                t_new[:, i] += torch.rand_like(t_new[:, i]) * 2 * 1e-2 - 1e-1\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n\n    if perturb:\n        # We want to sample from a uniform distribution on the interval [0, 1)\n        u = torch.rand(num_samples + 1, *t.shape[:-1], device=t.device)\n        # We want to invert the CDF to get the samples.\n        t_new = invert_cdf(u, t, w)\n    else:\n        # We want to sample from the PDF directly.\n        u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n        t_new = interpolate(u, w, t)\n\n    if single_jitter:\n        # Apply jitter to all samples\n        t_new = t_new + torch.randn_like(t_new) * 0.01\n    else:\n        # Apply jitter to each sample\n        t_new = t_new + torch.randn_like(t_new) * 0.01\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    if perturb:\n        # Sample from the uniform distribution on [0, 1).\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n        # Interpolate into the inverse CDF.\n        t_new = invert_cdf(u, t, w)\n    else:\n        # Interpolate into the CDF.\n        t_new = interpolate(u, w, t)\n        # Sample from the uniform distribution on [0, 1).\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n        # Interpolate into the CDF.\n        t_new = interpolate(u, w, t)\n\n    # Apply jittering if needed.\n    if single_jitter:\n        if t.ndim == 1:\n            t_new = t_new + (t_new * torch.randn_like(t_new))\n        else:\n            t_new = t_new + (t_new * torch.randn_like(t_new).permute(0, 2, 1))\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n    # Generate random numbers in [0, 1) to sample from the CDF.\n    u = torch.rand(num_samples, t.shape[-1], device=t.device)\n    # Interpolate the CDF to get the inverse CDF.\n    t_new = invert_cdf(u, t, cw)\n    if perturb:\n        # Perturb the samples to avoid sample clustering at bin boundaries.\n        if single_jitter:\n            # If single_jitter is True, perturb all samples by the same amount.\n            t_new = t_new + torch.randn_like(t_new)\n        else:\n            # If single_jitter is False, perturb each sample by an independent amount.\n            t_new = t_new + torch.randn_like(t_new) * w.shape[-1] / 10\n        # Clip the perturbed samples to be in the range of the CDF.\n        t_new = torch.clamp(t_new, min=t[..., 0], max=t[..., -1])\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    if not perturb:\n        w = integrate_weights(w)\n    else:\n        # Perturb the weights by adding a small amount of noise.\n        w = integrate_weights(w + torch.randn_like(w) * 1e-3)\n\n    # Get the CDF.\n    cw = integrate_weights(w)\n\n    # Generate samples from the CDF.\n    u = torch.rand(num_samples, *w.shape[:-1], device=w.device)\n    t_new = interpolate(u, cw, t)\n\n    # If we want jittered samples, jitter them.\n    if single_jitter:\n        jitter = torch.rand(num_samples, *t.shape[-1], device=t.device)\n        t_new = t_new + jitter\n    else:\n        jitter = torch.randn(num_samples, *t.shape[-1], device=t.device)\n        t_new = t_new + jitter.unsqueeze(-1)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the inputs' dimensions.\n    t, w = matchup_channels(t, w)\n\n    # Ensure the weights are normalized.\n    assert torch.allclose(torch.sum(w, -1), 1.0)\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Generate samples from the uniform distribution.\n    u = torch.rand(num_samples + 1, *t.shape[:-1], device=t.device)\n\n    # Interpolate the CDF into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n\n    # If perturbation is enabled, perturb the samples.\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to each sample.\n            jitter = torch.rand_like(t_new, device=t.device)\n            t_new += jitter\n        else:\n            # Apply independent jitters to each sample.\n            jitter = torch.rand_like(t_new, device=t.device)\n            t_new += jitter * t\n\n    # Truncate the samples to the range of the bins.\n    t_new = torch.where(t_new < t[:, 0], t[:, 0], t_new)\n    t_new = torch.where(t_new > t[:, -1], t[:, -1], t_new)\n\n    # Remove the extra sample.\n    t_new = t_new[:, :-1]\n\n    # Return the sampled values.\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that the weights sum to 1.\n    w = w / w.sum(dim=-1, keepdim=True)\n    # Compute the CDF.\n    cw = integrate_weights(w)\n    # Generate the samples.\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n    t_new = invert_cdf(u, cw, t)\n    # Perturb the samples if needed.\n    if perturb:\n        # Compute the Jacobian of the CDF.\n        t_mat = t.reshape([-1, t.shape[-1]])\n        cw_mat = cw.reshape([-1, cw.shape[-1]])\n        m = (cw_mat[..., 1:] - cw_mat[..., :-1]) / (t_mat[..., 1:] - t_mat[..., :-1] + 1e-8)\n        # Compute the Jacobian of the inverse CDF.\n        m_new = m.reshape(cw.shape[:-1] + (1,) + t.shape[-1:])\n        # Compute the Jacobian of the perturbation.\n        m_pert = torch.rand(m_new.shape, device=m_new.device)\n        # Apply the perturbation.\n        t_new = t_new + m_new * m_pert\n    # Jitter the samples.\n    if single_jitter:\n        t_new = t_new + torch.randn(t_new.shape, device=t_new.device)\n    else:\n        t_new = t_new + torch.randn_like(t_new)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(\n            \"The last dimensions of t and w must match. t.shape[-1] = {} w.shape[-1] + 1 = {}\".format(\n                t.shape[-1], w.shape[-1] + 1\n            )\n        )\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Create the samples.\n    # We'd like to sample uniformly from [0, 1) and then invert the CDF.\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n    t_new = invert_cdf(u, cw, t)\n\n    if perturb:\n        # We'd like to jitter the samples to avoid clustering at bin boundaries.\n        t_jitter = torch.rand_like(t_new)\n        if single_jitter:\n            t_jitter = t_jitter.sum(dim=-1, keepdim=True)\n        t_new = t_new + t_jitter\n\n    # Make sure the samples are in the right range.\n    t_new = torch.clamp(t_new, t[..., 0], t[..., -1])\n\n    # Return the samples.\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the dimensions of t and w.\n    t, w = matchup_channels(t, w)\n    # Compute the cumulative sum of weights.\n    cw = integrate_weights(w)\n    # Generate uniform samples in the interval [0, 1).\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device, dtype=t.dtype)\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n    # If perturbation is enabled, perturb the samples.\n    if perturb:\n        # Generate a vector of uniform random numbers.\n        if single_jitter:\n            j = torch.rand(1, *t.shape, device=t.device, dtype=t.dtype)\n            # Compute the perturbation as a function of the sample.\n            j = torch.cat([torch.zeros_like(t_new[..., 0:1]),\n                          (t_new[..., :-1] - t_new[..., 1:])[..., None, :],\n                          torch.ones_like(t_new[..., -1:])], dim=-1)\n            j = j * j\n            # Add the perturbation to the sample.\n            t_new = t_new + j * j\n        else:\n            j = torch.rand(num_samples, *t.shape, device=t.device, dtype=t.dtype)\n            t_new = t_new + j\n    # Return the samples.\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # We'll be using this function in a jit.script, so we need to ensure that\n    # the input tensors are contiguous.\n    t, w = torch.as_tensor(t), torch.as_tensor(w)\n\n    # Check that the input tensors are sorted.\n    if not torch.all(torch.diff(t) >= 0):\n        raise ValueError(f\"t must be sorted, got {t}\")\n\n    # Ensure that the input tensors are contiguous.\n    if not t.is_contiguous():\n        t = t.contiguous()\n    if not w.is_contiguous():\n        w = w.contiguous()\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Perform the sampling.\n    u = torch.rand(num_samples, device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation.\n    if perturb:\n        if single_jitter:\n            j = torch.rand_like(t_new)\n        else:\n            j = torch.randn_like(t_new)\n        t_new += j * torch.diff(t) * torch.finfo(t.dtype).eps * 2\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure the inputs are sorted.\n    t = torch.as_tensor(t)\n    t = t.contiguous()\n    w = torch.as_tensor(w)\n    assert t.ndim == w.ndim + 1, \"t and w must have the same number of dimensions.\"\n    assert t.shape[-1] == w.shape[-1] + 1, \"t and w must have the same number of bins.\"\n    assert torch.is_tensor(num_samples), \"num_samples must be a tensor.\"\n    assert num_samples.ndim == 0, \"num_samples must be a scalar.\"\n    assert num_samples > 0, \"num_samples must be positive.\"\n    assert torch.all(torch.is_tensor(t)), \"t must be a tensor.\"\n    assert torch.all(torch.is_tensor(w)), \"w must be a tensor.\"\n    assert torch.all(torch.is_tensor(num_samples)), \"num_samples must be a tensor.\"\n    assert perturb is not None, \"perturb must be set to True or False.\"\n    assert (perturb == True) or (perturb == False), \"perturb must be set to True or False.\"\n    assert single_jitter is not None, \"single_jitter must be set to True or False.\"\n    assert (single_jitter == True) or (single_jitter == False), \"single_jitter must be set to True or False.\"\n\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Sample from the CDF.\n    u = torch.rand([num_samples] + list(t.shape)[:-1], device=t.device)\n    t_new = invert_cdf(u, cw, t)\n\n    # Apply perturbation.\n    if perturb:\n        # Compute the bin-wise CDF and PDF.\n        cw_bin = cw.reshape(cw.shape[:-1])\n        t_bin = t.reshape(t.shape[:-1])\n        t_new_bin = t_new.reshape(t_new.shape[:-1])\n        w_bin = w.reshape(w.shape[:-1])\n        cw_bin"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # TODO: make the sampling process more robust by perturbing the samples to avoid clustering at bin boundaries.\n    # We perturb the samples by adding a small, random value to each sample.\n    # This ensures that the samples are uniformly distributed within each bin.\n    # The perturbation is applied to the samples before the jitter is applied.\n    if perturb:\n        # Perturbation\n        t_perturb = t - t[..., :-1]\n        # Jitter\n        if single_jitter:\n            jitter = torch.zeros_like(t)\n            jitter[..., 1:-1] = t_perturb.abs().max(dim=-1, keepdim=True)[0]\n        else:\n            jitter = torch.randn_like(t)\n        t_new = t + jitter\n    else:\n        t_new = t\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    u = torch.rand(size=(t_new.size(0), num_samples), device=t_new.device)\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t_new)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # TODO: refactor to use the interp_cdf function\n    if t.ndim == 1:\n        t = t[None, :]\n    if w.ndim == 1:\n        w = w[None, :]\n\n    # Add a constant to the weights to make them sum to 1.\n    w = w / torch.sum(w, -1, keepdim=True)\n\n    # Generate uniform random numbers in [0, 1).\n    u = torch.rand(t.shape[:-1] + (num_samples,),\n                   device=t.device,\n                   dtype=t.dtype)\n\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Interpolate into the CDF.\n    t_new = interpolate(u, cw, t)\n\n    # If we're jittering, perturb the samples.\n    if perturb:\n        if single_jitter:\n            jitter = torch.randn_like(t_new)\n            t_new += jitter\n            if t.ndim == 1:\n                t_new = t_new[0]\n        else:\n            jitter = torch.randn_like(t_new)\n            t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_max = torch.max(t, dim=-1, keepdim=True)[0]\n    t_max = torch.max(t_max, domain[0])\n    t_min = torch.min(t, dim=-1, keepdim=True)[0]\n    t_min = torch.min(t_min, domain[1])\n    t_dilated = torch.max(t_min, t_max * dilation)\n    w_dilated = w / t_dilated\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dimension\n    t, w = matchup_channels(t, w)\n\n    # dilate\n    t_dilated = t + dilation * (t[:, 1:] - t[:, :-1])\n\n    # clip\n    t_dilated = torch.clamp(t_dilated, *domain)\n\n    # adjust weights\n    w_adjusted = w * (t_dilated - t[:, :-1]) / (t[:, 1:] - t[:, :-1])\n\n    return t_dilated, w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t = t.unsqueeze(-1)\n    w = w.unsqueeze(-1)\n\n    t_d = t * dilation\n    t_d = torch.where(t_d < domain[0], domain[0], t_d)\n    t_d = torch.where(t_d > domain[1], domain[1], t_d)\n\n    w_d = torch.where(t_d == domain[0], w, torch.where(t_d == domain[1], torch.zeros_like(w), (t_d - t) / dilation * w))\n\n    return t_d, w_d"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t = t.to(dtype=torch.float64)\n    w = w.to(dtype=torch.float64)\n\n    # Dilate the time steps\n    t_dilated = torch.max(t, dilation * t)\n\n    # Clip the dilated time steps\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Dilate the weights\n    w_dilated = torch.where(t_dilated == t, w, w * dilation)\n\n    # Normalize the weights\n    w_dilated = w_dilated / torch.sum(w_dilated)\n\n    return t_dilated.to(dtype=torch.float32), w_dilated.to(dtype=torch.float32)"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dim\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    if domain[0] is not None:\n        t = torch.max(domain[0], t)\n    if domain[1] is not None:\n        t = torch.min(domain[1], t)\n\n    t = torch.max(t, dilation * t)\n    w = w / (dilation * torch.arange(t.shape[1], device=t.device) + 1)\n\n    return t.reshape(t.shape[:-1] + (1,)), w.reshape(w.shape[:-1] + (1,))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t = t.to(torch.float)\n    w = w.to(torch.float)\n\n    # Dilate the time steps\n    t = t * dilation\n\n    # Clip the time steps\n    t = torch.clamp(t, *domain)\n\n    # Compute the weights\n    w = weight_to_pdf(t, w)\n\n    return t, w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # TODO: make this more efficient\n    t, w = matchup_channels(t, w)\n    t_new = torch.max(torch.full_like(t, domain[0], dtype=t.dtype), t + (1.0 / dilation))\n    t_new = torch.min(t_new, torch.full_like(t, domain[1], dtype=t.dtype))\n    w_new = torch.maximum(torch.full_like(w, 0.0, dtype=w.dtype),\n                           torch.maximum(torch.full_like(w, 0.0, dtype=w.dtype),\n                           torch.where(t_new == t, w,\n                                      torch.full_like(w, 0.0, dtype=w.dtype))))\n    return t_new, w_new"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Dilate t\n    t_dilated = torch.max(t * dilation, domain[0], -1)\n    t_dilated = torch.min(t_dilated, domain[1], -1)\n\n    # Calculate the weights\n    w_dilated = w / torch.sum(w, dim=-1, keepdim=True)\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # TODO: Add support for negative dilation\n    t, w = matchup_channels(t, w)\n\n    t_new = t.unsqueeze(dim=-1) + (dilation - 1) * torch.arange(t.shape[-2], device=t.device)\n    t_new = torch.clamp(t_new, min=domain[0], max=domain[1])\n    w_new = w * (t_new - t)\n\n    return t_new, w_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps\n    t_d = torch.max(t, dilation)\n\n    # Clip the dilated time steps\n    t_d = t_d.clamp(min=domain[0], max=domain[1])\n\n    # Calculate the new weights\n    w_d = torch.where(t_d > t, w / dilation, w)\n\n    return t_d, w_d\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t = t.clone()\n    w = w.clone()\n\n    t_dilated = t * dilation\n    w_dilated = w / dilation\n\n    t_dilated = torch.where(t_dilated < domain[0], domain[0], t_dilated)\n    t_dilated = torch.where(t_dilated > domain[1], domain[1], t_dilated)\n\n    w = w_dilated * torch.where(t_dilated == t[0], 1.0,\n                                 torch.where(t_dilated == t[-1], 0.0,\n                                            torch.where(t_dilated < t[0], 0.0,\n                                                       torch.where(t_dilated > t[-1], 0.0,\n                                                                 torch.where(t_dilated < t, 0.0,\n                                                                          torch.where(t_dilated > t, 0.0,\n                                                                                     1.0)))))\n\n    return t_dilated, w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # t, w = matchup_channels(t, w)\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # dilate\n    t_dilated = t * dilation\n    # clip\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n    # adjust weights\n    w = w / dilation\n    return t_dilated.reshape(t.shape), w.reshape(w.shape)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the dilated time steps.\n    t_dilated = t + (t[1:, ...] - t[:-1, ...]) * dilation\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n    # Compute the weights corresponding to the dilated time steps.\n    w_dilated = w[0] + (w[1:, ...] - w[:-1, ...]) * dilation\n    # Normalize the weights to sum to 1.\n    w_dilated = w_dilated / torch.sum(w_dilated, dim=-1, keepdim=True)\n    # Clip the weights to be non-negative.\n    w_dilated = torch.clamp(w_dilated, min=0)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps\n    t = torch.maximum(t * dilation, domain[0])\n    t = torch.minimum(t, domain[1])\n    # Compute the weights\n    w = (t - t.min(-1, keepdim=True)[0]) / (t.max(-1, keepdim=True)[0] - t.min(-1, keepdim=True)[0] + 1e-8)\n    # Normalize the weights\n    w = w / w.sum(-1, keepdim=True)\n    return t, w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    w = w.reshape(-1, 1)\n    t = t.reshape(-1, 1)\n\n    # Dilate the time steps\n    t_dilated = (t + 1) * dilation\n\n    # Clip the time steps\n    t_dilated = torch.clamp(t_dilated, *domain)\n\n    # Adjust the weights\n    w_dilated = torch.max(t_dilated - t, 1, keepdims=True)[0]\n    w_dilated = w_dilated.reshape(-1)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # dilate time steps\n    t_dilated = t * dilation\n\n    # clip the dilated time steps\n    t_dilated = torch.max(t_dilated, domain[0])\n    t_dilated = torch.min(t_dilated, domain[1])\n\n    # adjust the weights to match the dilated time steps\n    w_dilated = w * (1 / (dilation * (t_dilated[1:] - t_dilated[:-1]))\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps\n    t = torch.maximum(t * dilation, domain[0])\n    t = torch.minimum(t, domain[1])\n\n    # Clip the time steps\n    t = torch.clip(t, domain[0], domain[1])\n\n    # Dilate the weights\n    w = torch.maximum(w * dilation, 0)\n    w = torch.minimum(w, 1)\n\n    # Normalize the weights\n    w = w / torch.sum(w, dim=-1, keepdims=True)\n\n    return t, w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # TODO: make this function more general\n    # TODO: make this function not require the weights to be non-negative\n    # TODO: make this function not require the weights to sum to 1\n    t, w = matchup_channels(t, w)\n    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dim\n    # Dilate time steps\n    t_new = t * dilation\n    # Clip dilated time steps\n    t_new = torch.where(t_new > domain[1], domain[1], t_new)\n    t_new = torch.where(t_new < domain[0], domain[0], t_new)\n    # Clip weights\n    w_new = torch.where(t_new >= t[..., 1:], w, 0.0)\n    # Normalize weights\n    w_new = w_new / torch.sum(w_new, -1, keepdim=True)\n    return t_new, w_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Dilate the time steps\n    t_dilated = t * dilation\n    # Clip the dilated time steps\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n    # Compute the new weights\n    w_dilated = torch.sum(w, dim=-1, keepdim=True)\n    # Normalize the new weights\n    w_dilated = w_dilated / torch.sum(w_dilated, dim=-1)\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Dilate the time steps\n    t_d = torch.max(t * dilation, domain[0])\n    # Clip the dilated time steps\n    t_d = torch.min(t_d, domain[1])\n\n    # Compute the weights\n    w_d = weight_to_pdf(t, w)\n    w_d = torch.max(w_d, 1e-8)\n    w_d = w_d * (t_d - t[..., :-1])\n    w_d = w_d / (t_d - t[..., 1:])\n    w_d = w_d * (t[..., 1:] - t[..., :-1])\n\n    return t_d, w_d\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    t = torch.cat([t, t[-1:]], dim=-1)\n    y = torch.cat([y, outside_value], dim=-1)\n    y = interpolate(tq, t, y)\n    return y"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n\n    # Compute the cumulative sum of the weights, and add a 1 at the end to\n    # make the CDF.\n    cw = integrate_weights(y)\n    # We want to interpolate into the CDF.\n    cw_mat = cw.reshape([-1, cw.shape[-1]])\n    t_mat = t.reshape([-1, t.shape[-1]])\n    wprctile_mat = interpolate(tq.to(t, non_blocking=True), cw_mat, t_mat)\n    wprctile = wprctile_mat.reshape(cw.shape[:-1] + (tq.shape[-1],))\n    return torch.where(tq == t, outside_value, wprctile)"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # This is a hacky way of doing a broadcast, but it avoids the\n    # need to allocate a new tensor.\n    t = torch.cat([t, tq], dim=-1)\n    y = torch.cat([y, outside_value * torch.ones_like(tq)], dim=-1)\n    return interpolate(tq, t, y)"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # TODO: check if tq and t are sorted\n    # TODO: check if tq and t have the same shape\n    # TODO: check if tq and t have the same number of dimensions\n    # TODO: check if tq and t have the same dtype\n\n    # TODO: handle the case where tq and t have different shapes\n    # TODO: handle the case where tq and t have different numbers of dimensions\n    # TODO: handle the case where tq and t have different dtypes\n    # TODO: handle the case where tq and t have different sizes\n    # TODO: handle the case where tq and t have different strides\n    # TODO: handle the case where tq and t have different device\n\n    # TODO: handle the case where tq and t have different device\n    # TODO: handle the case where tq and t have different strides\n    # TODO: handle the case where tq and t have different sizes\n    # TODO: handle the case where tq and t have different dtypes\n    # TODO: handle the case where tq and t have different numbers of dimensions\n    # TODO: handle the case where tq and t have different shapes\n\n    # TODO: handle the case where tq and t have different shapes\n    # TODO: handle the case where tq and t have different numbers of dimensions\n    # TODO: handle the case where tq and t have different dtypes\n    # TODO: handle the case where tq and t have different sizes\n    # TODO: handle the case where tq and t have different strides\n\n    # TODO: handle the case where tq and t have different strides\n    # TODO: handle the case where tq and t have different sizes\n    # TODO: handle the case where tq and t have different dtypes\n    # TODO: handle the case where tq and t have different numbers of dimensions\n    # TODO: handle the case where tq and t have different shapes\n\n    # TODO: handle the case where tq and t have different shapes\n    # TODO: handle the case where tq and t have different numbers of dimensions\n    # TODO: handle the case where tq and t have different dtypes\n    # TODO: handle the case where tq and t have different sizes\n    # TODO: handle the case where tq and t have different strides\n\n    # TODO: handle the case where tq and t have different strides\n    # TODO: handle the case where"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    return torch.where(tq >= t, outside_value, interpolate(tq, t, y))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # t = torch.as_tensor(t).to(tq.device).float()\n    t = t.to(tq.device).float()\n    y = y.to(tq.device).float()\n    # tq = torch.as_tensor(tq).to(t.device).float()\n    tq = tq.to(t.device).float()\n\n    # tq = tq.to(tq.device).float()\n    # t = torch.as_tensor(t).to(tq.device).float()\n    # y = y.to(tq.device).float()\n    # tq = torch.as_tensor(tq).to(t.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = torch.as_tensor(tq).to(t.device).float()\n    # tq = tq.to(tq.device).float()\n\n    # tq = tq.to(tq.device).float()\n    # t = torch.as_tensor(t).to(tq.device).float()\n    # y = y.to(tq.device).float()\n    # tq = torch.as_tensor(tq).to(t.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = torch.as_tensor(tq).to(t.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = torch.as_tensor(tq).to(t.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n    # tq = tq.to(tq.device).float()\n\n    # tq = torch.as_tensor(tq).to(tq.device).float()\n    # tq = tq.to"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # TODO: support 1-d tensors\n    if tq.ndim != 2 or t.ndim != 2 or y.ndim != 2:\n        raise ValueError(\n            f\"tq, t, and y should all be 2-D tensors, but are {tq.ndim}, {t.ndim}, and {y.ndim} respectively.\"\n        )\n\n    # TODO: support 1-d tensors\n    # if tq.ndim != 2 or t.ndim != 2 or y.ndim != 2:\n    #     raise ValueError(\n    #         f\"tq, t, and y should all be 2-D tensors, but are {tq.ndim}, {t.ndim}, and {y.ndim} respectively.\"\n    #     )\n\n    # TODO: support 1-d tensors\n    # if tq.ndim != 2 or t.ndim != 2 or y.ndim != 2:\n    #     raise ValueError(\n    #         f\"tq, t, and y should all be 2-D tensors, but are {tq.ndim}, {t.ndim}, and {y.ndim} respectively.\"\n    #     )\n\n    # TODO: support 1-d tensors\n    # if tq.ndim != 2 or t.ndim != 2 or y.ndim != 2:\n    #     raise ValueError(\n    #         f\"tq, t, and y should all be 2-D tensors, but are {tq.ndim}, {t.ndim}, and {y.ndim} respectively.\"\n    #     )\n\n    # TODO: support 1-d tensors\n    # if tq.ndim != 2 or t.ndim != 2 or y.ndim != 2:\n    #     raise ValueError(\n    #         f\"tq, t, and y should all be 2-D tensors, but are {tq.ndim}, {t.ndim}, and {y.ndim} respectively.\"\n    #     )\n\n    # TODO: support 1-d tensors\n    # if tq.ndim != 2 or t.ndim != 2 or y.ndim != 2:\n    #     raise ValueError(\n    #         f\"tq, t, and y should all be 2-D"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # the last dimension of t and y must be equal\n    if y.shape[-1] != t.shape[-1]:\n        y = y[..., 0]  # remove last dim\n\n    # the last dimension of t and tq must be equal\n    if tq.shape[-1] != t.shape[-1]:\n        tq = tq[..., 0]  # remove last dim\n\n    # the last dimension of tq and y must be equal\n    if tq.shape[-1] != y.shape[-1]:\n        tq = tq[..., 0]  # remove last dim\n\n    # if the last dimension of t is 1, remove it\n    if t.shape[-1] == 1:\n        t = t[..., 0]\n\n    # if the last dimension of tq is 1, remove it\n    if tq.shape[-1] == 1:\n        tq = tq[..., 0]\n\n    # if tq is a scalar, repeat it to match the last dimension of t\n    if tq.numel() == 1:\n        tq = tq.repeat_interleave(t.shape[-1], tq)\n\n    # if t is a scalar, repeat it to match the last dimension of tq\n    if t.numel() == 1:\n        t = t.repeat_interleave(tq.shape[-1], t)\n\n    # if y is a scalar, repeat it to match the last dimension of tq\n    if y.numel() == 1:\n        y = y.repeat_interleave(tq.shape[-1], y)\n\n    # if tq is a scalar, repeat it to match the last dimension of y\n    if tq.numel() == 1:\n        tq = tq.repeat_interleave(y.shape[-1], tq)\n\n    # if t is a scalar, repeat it to match the last dimension of y\n    if t.numel() == 1:\n        t = t.repeat_interleave(y.shape[-1], t)\n\n    # if the last dimension of tq is 1, remove it\n    if tq.shape[-1] == 1:\n        tq = tq[..., 0]\n\n    # if the last dimension of y is 1, remove it\n    if y."}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    if tq.ndim == t.ndim:\n        tq = tq[None]  # broadcast to match t's shape\n    # Find the indices of the times that match the query times.\n    idx = torch.where(tq >= t, tq, t - 1e-4)\n    return torch.where(tq == idx, outside_value, y[idx == tq])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    t0 = torch.cat([t, t[..., -1:] - 1], dim=-1)\n    t1 = torch.cat([t[..., 0], t], dim=-1)\n    y0 = torch.cat([y[..., -1:], y], dim=-1)\n    y1 = torch.cat([y, y[..., 0]], dim=-1)\n    y_query = interpolate(tq, t0, t1, outside_value)\n    y_query = torch.where(tq == t, y0, y1)\n    return y_query\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # if tq.ndim == t.ndim - 1:\n    #     tq = tq[None]\n    if tq.ndim == t.ndim - 1:\n        tq = tq[None]\n    # if tq.ndim == t.ndim + 1:\n    #     tq = tq[..., 0]\n    if tq.ndim == t.ndim + 1:\n        tq = tq[..., 0]\n    if t.ndim == y.ndim + 1:\n        t = t[..., 0]\n\n    # if tq.ndim == 2:\n    #     tq = tq[..., 0]\n    # if tq.ndim == 1:\n    #     tq = tq[None, :]\n    if tq.ndim == 1:\n        tq = tq[None]\n    # if tq.ndim == 1:\n    #     tq = tq[:, None]\n    if tq.ndim == 2:\n        tq = tq[:, 0]\n\n    if tq.shape[-1] != t.shape[-1] + 1:\n        tq = torch.cat([tq, torch.ones_like(tq[:, -1:])], dim=-1)  # 65\n\n    m = (y[..., 1:] - y[..., :-1]) / (t[..., 1:] - t[..., :-1] + 1e-8)  # slope\n    b = y[..., :-1] - (m * t[..., :-1])\n\n    indices = torch.sum(torch.ge(tq, t[..., None]), -1) - 1\n    indices = torch.clamp(indices, 0, m.shape[-1] - 1)\n\n    return m.gather(dim=-1, index=indices) * tq + b.gather(dim=-1, index=indices)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # The function is only defined for positive times\n    if tq.min() < 0:\n        tq = tq.abs()\n        y = -y\n    # If the query time is less than the first step time, return the first step value\n    if tq.min() < t.min():\n        return outside_value * tq + y[0]\n    # If the query time is greater than the last step time, return the last step value\n    elif tq.max() > t.max():\n        return outside_value * tq + y[-1]\n    # If the query time is between two step times, return the interpolated value\n    else:\n        # Find the indices of the two step times that bracket the query time\n        indices = torch.where(tq >= t, tq, t)\n        return interpolate(tq, t, y)[..., indices - 1]"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # if tq.shape[-1] == t.shape[-1]:\n    #     tq = tq[..., 0]  # remove last dim\n    # if tq.shape[-1] == t.shape[-2] + 1:\n    #     tq = tq[..., 0]  # remove last dim\n    if tq.ndim == t.ndim + 1:\n        tq = tq[..., 0]  # remove last dimension\n    if tq.ndim == t.ndim + 2:\n        tq = tq[..., 0, 0]  # remove last 2 dimensions\n    if tq.shape[-1] != t.shape[-1] + 1:\n        tq = torch.cat([tq, torch.ones_like(tq[..., -1:])], dim=-1)  # 65\n    return torch.where(tq[..., 1:] == tq[..., :-1], outside_value, interpolate(tq, t, y))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    assert tq.shape == t.shape, \"tq and t must have the same shape\"\n    assert tq.shape[0] == y.shape[0], \"tq and y must have the same batch size\"\n\n    if tq.shape[1] != y.shape[1] + 1:\n        tq = torch.cat([tq, torch.ones_like(tq[..., -1:])], dim=-1)\n\n    if y.shape[1] != t.shape[1] + 1:\n        y = torch.cat([y, torch.ones_like(y[..., -1:])], dim=-1)\n\n    # If tq is in between the times in t, we interpolate.\n    # Otherwise, we return the outside value.\n    return torch.where(tq[..., :-1] < t[..., 1:],\n                       torch.where(tq[..., 1:] > t[..., :-1], y, outside_value),\n                       outside_value)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # TODO: this is not a vectorized implementation\n    if tq.ndim == t.ndim - 1:\n        tq = tq[None]\n    # If the query time is before the first step change time, return the outside value.\n    # If the query time is after the last step change time, return the outside value.\n    idx = torch.where(t > tq, -1, 0)\n    idx = torch.clamp(idx, min=0, max=t.size(-1) - 1)\n    idx = torch.where(tq == t[idx], 0, idx)\n    idx = torch.where(tq == t[idx + 1], -1, idx)\n    idx = idx.to(int)\n    # If the query time is between two step change times, interpolate the value at the query time.\n    idx = torch.where(idx == -1, 0, idx + 1)\n    idx = torch.where(idx == t.size(-1), t.size(-1) - 1, idx)\n    return torch.where(idx == 0, y[0], y[idx - 1] + (tq - t[idx - 1]) * (y[idx] - y[idx - 1]))"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    if tq.ndim == t.ndim - 1:\n        tq = tq[None]\n    # Compute the cumulative sum of the weights.\n    cw = torch.cumsum(y[..., :-1], dim=-1).clip(max=1.0)\n    # Ensure that the CDF starts with exactly 0 and ends with exactly 1.\n    cw = torch.cat([cw.new_zeros(cw.shape[:-1] + (1,)), cw, cw.new_ones(cw.shape[:-1] + (1,))], dim=-1)\n\n    # Find the indices where the query times should be inserted to maintain order.\n    idx_lo = torch.max(torch.where(tq[..., None, :] >= t[..., :, None], tq.shape[-1], 0)[0]\n    idx_hi = torch.min(torch.where(tq[..., None, :] > t[..., :, None], tq.shape[-1], -1)[0]\n\n    # If the query times are out of range, return the outside value.\n    idx_lo = torch.clamp(idx_lo, 0, tq.shape[-1])\n    idx_hi = torch.clamp(idx_hi, 0, tq.shape[-1])\n    idx_lo = idx_lo[..., None]\n    idx_hi = idx_hi[..., None]\n\n    # Interpolate into the integrated weights.\n    wprctile = interpolate(tq, cw, t)\n    # Interpolate into the step function.\n    return wprctile[..., idx_lo] + (wprctile - wprctile[..., idx_lo].clamp(min=0) * (y[..., idx_hi] - y[..., idx_lo]))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    if t.ndim == tq.ndim + 1:\n        t = t[..., 0]  # remove last dimension\n\n    # ensure that the query times are sorted\n    tq_sorted = torch.sort(tq, dim=-1)[0]\n\n    # find the index of the first step function value that is greater than the query time\n    i = torch.where(tq_sorted > t[..., :-1],\n                    torch.arange(t.shape[-1] - 1, device=tq.device),\n                    torch.arange(t.shape[-1], device=tq.device))\n    i = i[..., None]\n\n    # find the index of the first step function value that is less than or equal to the query time\n    j = torch.where(tq_sorted >= t[..., 1:],\n                    torch.arange(t.shape[-1] - 1, device=tq.device),\n                    torch.arange(t.shape[-1], device=tq.device))\n    j = j[..., None]\n\n    # find the indices of the query times that are equal to the step function values\n    k = torch.where(tq_sorted == t, torch.arange(t.shape[-1], device=tq.device), torch.arange(t.shape[-1] + 1, device=tq.device))\n\n    # find the indices of the step function values that are greater than the query times\n    l = torch.where(tq_sorted > t[..., 1:],\n                    torch.arange(t.shape[-1], device=tq.device),\n                    torch.arange(t.shape[-1] - 1, device=tq.device))\n    l = l[..., None]\n\n    # interpolate the values at the query times\n    # interpolate the values at the query times that are equal to the step function values\n    w = tq - t[..., i]\n    w = w / (t[..., j] - t[..., i] + 1e-6)\n    y_interpolated = y[..., i] * (1 - w) + y[..., j] * w\n\n    # assign the outside values to the query times that are equal to the step function values\n    y_interpolated[..., k] = outside_value\n\n    # interpolate the"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # The query times must be sorted.\n    if not torch.all(torch.diff(t) > 0):\n        raise ValueError(\"t must be sorted.\")\n    # The step function must be defined at the first query time.\n    if tq.min() < t[0]:\n        tq = tq.clamp(t[0], tq.max())\n\n    # The query times must be in the range of the step function.\n    if tq.min() > t[-1]:\n        raise ValueError(\"tq must be in the range of t.\")\n\n    # The query times must be in the range of the step function.\n    if tq.max() > t[-1]:\n        tq = tq.clamp(tq.min(), t[-1])\n\n    # Find the bins in which the query times fall.\n    i0 = torch.searchsorted(t, tq)\n\n    # Find the query times that are exactly at a step change.\n    i1 = i0 - 1\n    i1 = i0.clamp(0, t.size(-1) - 2)\n    i0 = i1 + 1\n    i1 = i1.to(i0.dtype)\n\n    # Interpolate the values of the step function at the query times.\n    v = torch.cat([tq, tq[i1], tq[i1]], dim=-1)\n    w = torch.cat([torch.zeros_like(tq), torch.ones_like(tq[i1]), torch.zeros_like(tq[i1])], dim=-1)\n    v = interpolate(v, t, y)\n\n    # Replace values that are at a step change with the outside value.\n    v[i0] = outside_value\n\n    return v"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices of the first and last times in t that are less than or equal to each query time.\n    # This will be used to compute the interpolation.\n    #\n    # In the case where a query time is less than the first time, the first index will be 0.\n    # In the case where a query time is greater than the last time, the last index will be the number of times.\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # The values of the step function at the query times.\n    #\n    # If the query time is less than the first time, the value is the outside value.\n    # If the query time is greater than the last time, the value is the last value.\n    # Otherwise, the value is the interpolation of the two adjacent times.\n    y_tq = torch.where(\n        tq < t[idx_lo],\n        outside_value * torch.ones_like(tq),\n        torch.where(\n            tq >= t[idx_hi],\n            y[idx_hi - 1],\n            interpolate(tq, t[idx_lo], y[idx_lo])))\n\n    return y_tq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # https://github.com/dask/dask/blob/master/dask/array/core.py#L360\n    # https://github.com/dask/dask/blob/master/dask/array/core.py#L405\n\n    # ensure t and tq are the same type\n    t = tq.new_tensor(t)\n    tq = tq.to(t)\n\n    # Ensure that t is sorted.\n    t = t.sort(dim=-1)[0]\n    # Ensure that t is not empty.\n    if t.shape[-1] == 0:\n        t = t.new_tensor([0])\n\n    # Ensure that tq is not empty.\n    if tq.shape[-1] == 0:\n        tq = tq.new_tensor([0])\n\n    # Handle the case where tq is out of the range of t.\n    idx_lo, idx_hi = searchsorted(t, tq)\n    tq_lo = t[idx_lo]\n    tq_hi = t[idx_hi]\n\n    # Interpolate between the values at tq_lo and tq_hi.\n    w = (tq - tq_lo) / (tq_hi - tq_lo + 1e-8)\n    return y[idx_lo] * (1 - w) + y[idx_hi] * w + outside_value * torch.eq(tq, tq_hi).to(y)\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # This function anneals the weights based on the training fraction and an annealing slope using Schlick's bias function.\n    # It adjusts the weights of a tensor based on the progression of training, making the weight adjustment more dynamic as training progresses.\n    # It ensures stability in the computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights.\n\n    # This function anneals the weights based on the training fraction and an annealing slope using Schlick's bias function.\n    # It adjusts the weights of a tensor based on the progression of training, making the weight adjustment more dynamic as training progresses.\n    # It ensures stability in the computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights.\n\n    # This function anneals the weights based on the training fraction and an annealing slope using Schlick's bias function.\n    # It adjusts the weights of a tensor based on the progression of training, making the weight adjustment more dynamic as training progresses.\n    # It ensures stability in the computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights.\n\n    # This function anneals the weights based on the training fraction and an annealing slope using Schlick's bias function.\n    # It adjusts the weights of a tensor based on the progression of training, making the weight adjustment more dynamic as training progresses.\n    # It ensures stability in the computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights.\n\n    # This function anneals the weights based on the training fraction and an annealing slope using Schlick's bias function.\n    # It adjusts the weights of a tensor based on the progression of training, making the weight adjustment more dynamic as training progresses.\n    # It ensures stability in the computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights.\n\n    # This function anneals the weights based on the training fraction and an annealing slope using Schlick's bias function.\n    # It adjusts the weights of a tensor based on the progression"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # anneal_slope = torch.clamp(anneal_slope, min=0.0)\n    # anneal_slope = torch.clamp(anneal_slope, min=0.0)\n    t0 = t[..., :-1] - anneal_slope\n    t1 = t[..., 1:] + anneal_slope\n    t_anneal = torch.sort(torch.cat([t, t0, t1], dim=-1), dim=-1)[0]\n    t_anneal = t_anneal.clip(*(-torch.finfo(t.dtype).min, torch.finfo(t.dtype).max))\n    w_anneal = torch.max(\n        torch.where(\n            (t0[..., None, :] <= t_anneal[..., None])\n            & (t1[..., None, :] > t_anneal[..., None]),\n            w[..., None, :],\n            0,\n        ),\n        dim=-1)[0][..., :-1]\n    w_anneal = torch.softmax(w_anneal, dim=-1)\n    w_anneal = w_anneal * (1. - train_frac) + w * train_frac\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    w_annealed = (\n        torch.nn.functional.softmax(\n            torch.log(torch.abs(t[..., 1:] - t[..., :-1] + eps)) * (\n                (1.0 - train_frac) ** anneal_slope\n                - 1.0\n            )\n            / anneal_slope\n            + 1.0\n        )\n        * w\n    )\n    return w_annealed"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # TODO: refactor to use weight_to_pdf and pdf_to_weight\n    t = t[..., 1:]\n    p = w / (t - t[..., :-1])\n    p = p.softmax(dim=-1)\n    p = p * (1.0 - train_frac) + ((1.0 / (1.0 + torch.exp(anneal_slope * (t - 1.0))))\n    w = p * (t - t[..., :-1])\n    return w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_ = t[:, 1:] - t[:, :-1]\n    t_ = torch.where(t_ == 0.0, eps, t_)\n\n    w_ = w / t_\n    w_ = torch.log(w_)\n\n    # Calculate the annealing effect on the weights\n    anneal_effect = torch.exp(anneal_slope * train_frac)\n\n    # Anneal the weights\n    w_ = (1.0 - anneal_effect) * w_\n    w_ = torch.exp(w_)\n\n    # Normalize the weights\n    w_ = w_ / torch.sum(w_, dim=-1, keepdim=True)\n\n    return w_"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # t, w = matchup_channels(t, w)\n    t = t[..., :-1]\n    w = w[..., :-1]\n    # if t.shape[-1] != w.shape[-1]:\n    #     t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # adjust the weights\n    t_scaled = torch.abs(t - t.min()) / (t.max() - t.min())\n    w_annealed = (1 - (1 - t_scaled) ** anneal_slope) * w\n    w_annealed = torch.where(t_scaled == 0, 0, w_annealed)\n    w_annealed = torch.where(torch.isnan(w_annealed), w, w_annealed)\n\n    # renormalize the weights\n    w_annealed /= torch.sum(w_annealed, dim=-1, keepdim=True).clip(eps)\n\n    # return the adjusted weights\n    return w_annealed\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Get the difference between each time point and the previous time point.\n    dt = t[..., 1:] - t[..., :-1]\n    # Get the weights of the time points that are adjacent to the current time point.\n    w_adj = w[..., :-1] + w[..., 1:]\n    # Calculate the annealing effect on the weights.\n    anneal_factor = 1.0 / (1.0 + anneal_slope * (1.0 - train_frac))\n    # Anneal the weights.\n    w_annealed = w_adj * anneal_factor\n    # Handle cases where adjacent intervals have zero distance, setting their weight to zero.\n    w_annealed = torch.where(dt == 0.0, torch.zeros_like(w_annealed), w_annealed)\n    # Prevent NaN values by using a softmax operation on the adjusted weights.\n    w_annealed = torch.softmax(w_annealed, dim=-1)\n    # Ensure the weights sum to one.\n    w_annealed = w_annealed / torch.sum(w_annealed, dim=-1, keepdim=True)\n    return w_annealed"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # anneal_slope = 10.0\n    # eps = torch.finfo(torch.float32).eps**2\n    # t, w = matchup_channels(t, w)\n    # anneal_slope = 10.0\n    # eps = torch.finfo(torch.float32).eps ** 2\n    # t, w = matchup_channels(t, w)\n    # anneal_slope = 10.0\n    # eps = torch.finfo(torch.float32).eps ** 2\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n    d = t1 - t0\n    # d = torch.where(d == 0, torch.tensor(1e-10, dtype=t.dtype), d)\n    d = d.clip(eps)\n    w_anneal = (1 - (1 - train_frac) ** (1 / anneal_slope)) * w / d\n\n    # w_anneal = (1 - (1 - train_frac) ** (1 / anneal_slope)) * w / d\n    # w_anneal = torch.where(d == 0, torch.tensor(0, dtype=t.dtype), w_anneal)\n    # w_anneal = torch.nn.functional.softmax(w_anneal, dim=-1)\n    w_anneal = torch.exp(torch.log(torch.clamp(w_anneal, min=eps)))\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # anneal_slope = 10.0\n    # eps = torch.finfo(torch.float32).eps ** 2\n\n    # prepare for size change\n    sh = *t.shape[:-1], 1\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # determine the annealing effect\n    anneal_frac = torch.where(train_frac < 1.0,\n                               torch.exp(-anneal_slope * (1.0 - train_frac)),\n                               0.0)\n\n    # calculate the adjusted weights\n    w_adj = w * anneal_frac\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True)\n    w_adj = torch.where(w_adj <= eps, 0.0, w_adj)\n    w_adj = torch.where(w_adj > 1.0, 1.0, w_adj)\n\n    # prepare for size change\n    w_adj = w_adj.reshape(sh)\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    w_new = torch.where(\n        (t[..., :-1] == t[..., 1:]),\n        0.0,\n        torch.where(\n            (t[..., 1:] - t[..., :-1]) == 0,\n            0.0,\n            torch.log(torch.where(\n                (w * (1.0 - train_frac) + train_frac) > 0,\n                w * (1.0 - train_frac) + train_frac,\n                eps\n            )) / anneal_slope\n        )\n    )\n    return torch.softmax(w_new, dim=-1)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # handle the case where there are no intervals\n    if w.shape[-1] == 1:\n        return w\n\n    # handle the case where the intervals have zero distance\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n    t0_1 = t0 + 1e-8\n    t1_0 = t1 - 1e-8\n    t_anneal = torch.where(t0 <= t1, t, torch.where(t0_1 <= t1_0, t0_1, t0))\n\n    # anneal the weights\n    w_anneal = w * torch.where(t0 <= t1,\n                               torch.exp(-(t_anneal - t0) / anneal_slope),\n                               torch.exp(-(t_anneal - t1) / anneal_slope))\n\n    # prevent NaN values\n    w_anneal = w_anneal.clamp(min=eps)\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # ensures that the weight tensor is aligned with the time tensor\n    t, w = matchup_channels(t, w)\n    # ensures that the weight tensor is non-negative\n    w = w.clamp(min=0)\n    # ensures that the time tensor is monotonically increasing\n    t = torch.cat([t[..., :-1], t[..., 1:] - eps], dim=-1)\n    # ensures that the time tensor is sorted\n    t = torch.sort(t, dim=-1)[0]\n    # ensures that the time tensor is normalized\n    t = (t - t[0]) / (t[-1] - t[0])\n    # calculates the annealing effect on the weights based on the training fraction and anneal slope\n    w_anneal = w * torch.sigmoid(anneal_slope * (1 - train_frac))\n    # prevents NaN values by using a softmax operation on the adjusted weights\n    w_anneal = torch.softmax(w_anneal, dim=-1)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_new = 1.0 - (1.0 - t) * (1.0 - train_frac)\n    w_new = torch.exp(anneal_slope * torch.log(1.0 + (t - t_new))\n                       + torch.log(torch.sum(w, dim=-1, keepdim=True) + eps)\n                       - torch.log(torch.sum(w * torch.exp(anneal_slope * torch.log(1.0 + (t - t_new))), dim=-1, keepdim=True)\n                       )\n    return w_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # Anneal weights\n    w_anneal = torch.where(\n        (t[..., 1:] - t[..., :-1]).clip(eps),\n        w,\n        0,\n    )\n    w_anneal = torch.where(\n        t[..., 0] < t[..., 1],\n        w_anneal,\n        0,\n    )\n\n    w_anneal = w_anneal.sum(dim=-1)\n    w_anneal_denom = torch.exp(\n        torch.where(w_anneal > 1e-12, w_anneal, 1e-12)\n    ).sum(dim=-1)\n\n    w_anneal = torch.where(w_anneal_denom > 0, w_anneal / w_anneal_denom, 1)\n    w_anneal = w_anneal ** (1 / anneal_slope)\n\n    # renormalize\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n\n    # prepare for size change\n    w_anneal = w_anneal.reshape(w.shape)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # align t and w\n    t, w = matchup_channels(t, w)\n    # ensure t is a 1D tensor\n    t = t.view(t.shape[-1])\n\n    # set zero-distance intervals to zero\n    t0 = t[:, :-1] - t[:, 1:]\n    t0 = t0.clamp(min=eps)\n    w_dilate = w / t0\n    w_dilate = w_dilate.sum(dim=0)\n    w_dilate = torch.where(w_dilate > 0, w_dilate, 0)\n\n    # anneal weights\n    w_anneal = torch.where(\n        t < 0.5,\n        torch.exp(torch.log(train_frac) * t * 2 - torch.log(1 - train_frac)),\n        torch.exp(torch.log(1 - train_frac) * (1 - t) * 2 - torch.log(train_frac)),\n    )\n    w_anneal = w_anneal.clamp(min=eps)\n    w_anneal = w_anneal / w_anneal.sum(dim=0)\n\n    # adjust weights\n    w_adj = torch.where(\n        t < 0.5,\n        w_anneal * w_dilate,\n        1 - (1 - w_anneal) * w_dilate,\n    )\n    w_adj = w_adj / w_adj.sum(dim=0)\n\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # anneal_slope = torch.clamp(anneal_slope, min=1.0)\n    # t_min = torch.min(t)\n    # t_max = torch.max(t)\n    # t = (t - t_min) / (t_max - t_min + 1e-8)\n    t = t.clamp(min=0, max=1)\n    t = 1.0 - t\n    w_annealed = w * (1 - train_frac) + w * train_frac / (1.0 + torch.exp(t * anneal_slope))\n    w_annealed = w_annealed / torch.sum(w_annealed, dim=-1, keepdim=True)\n    return w_annealed\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # anneal_slope = 10.0\n    # t_anneal = torch.linspace(0.0, 1.0, 2)\n    # w_anneal = torch.tensor([0.0, 1.0])\n    # anneal_slope = torch.log(torch.abs(torch.divide(w_anneal[1], w_anneal[0]))) / torch.abs(torch.subtract(t_anneal[1], t_anneal[0]))\n\n    # calculate the annealing effect on the weights\n    w_anneal = torch.pow(1 - train_frac, anneal_slope)\n\n    # handle cases where adjacent intervals have zero distance\n    t_new = t[..., 1:] - t[..., :-1]\n    t_new = t_new.clip(eps)\n\n    # prevent NaN values by using a softmax operation on the adjusted weights\n    w_anneal = torch.softmax(torch.log(w_anneal), dim=-1)\n\n    # anneal the weights\n    w_new = torch.multiply(w_anneal, torch.divide(t_new, torch.sum(t_new, dim=-1, keepdim=True)))\n\n    # return the adjusted weights tensor\n    return w_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # anneal_slope = 10.0\n    # train_frac = 0.5\n    # eps = torch.finfo(torch.float32).eps**2\n\n    # t = torch.arange(t.shape[-1]) / (t.shape[-1] - 1)\n    # w = torch.ones_like(t)\n    # t = t.reshape(-1, 1)\n    # w = w.reshape(-1, 1)\n\n    # Calculating the annealing factor\n    # anneal_factor = (1.0 - torch.exp(torch.finfo(torch.float32).eps - anneal_slope * train_frac))\n    anneal_factor = 1.0 - torch.exp(-anneal_slope * train_frac)\n\n    # Calculating the new weights\n    # new_weights = torch.cat((w * anneal_factor, torch.zeros_like(w)), -1)\n    # new_weights = torch.cat((w * anneal_factor, torch.zeros_like(w)), -1)\n    new_weights = torch.cat((w * anneal_factor, torch.zeros_like(w)), -1)  # torch.cat((w * anneal_factor, torch.zeros_like(w)), -1)\n\n    # Adjusting the weights to ensure stability\n    # adjusted_weights = torch.log(new_weights) - torch.log(new_weights.sum(-1))\n    # adjusted_weights = torch.log(new_weights) - torch.log(new_weights.sum(-1))\n    adjusted_weights = torch.log(new_weights) - torch.log(new_weights.sum(-1))  # torch.log(new_weights) - torch.log(new_weights.sum(-1))\n\n    # Ensuring stability\n    # adjusted_weights = torch.clamp(adjusted_weights, min=-torch.finfo(torch.float32).max_exp + 1, max=torch.finfo(torch.float32).max_exp)\n    # adjusted_weights = torch.clamp(adjusted_weights,"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # This is the formula for Schlick's bias function:\n    # w_new = w * (1 + anneal_slope * (1 - train_frac)) / (1 + anneal_slope)\n    # We can rewrite this as:\n    # w_new = w * (1 + anneal_slope) / (1 + anneal_slope) + w * anneal_slope * (1 - train_frac) / (1 + anneal_slope)\n    # Since the first term is just w, we can rewrite this as:\n    # w_new = w + w * (anneal_slope * (1 - train_frac)) / (1 + anneal_slope)\n    w_new = w + (w * anneal_slope * (1 - train_frac)) / (1 + anneal_slope)\n\n    # We can rewrite the above as:\n    # w_new = w + anneal_slope * w * (1 - train_frac) / (1 + anneal_slope)\n    # This is a linear function of w.\n    # We can rewrite this as:\n    # w_new = w + (anneal_slope * (1 - train_frac)) / (1 + anneal_slope) * (w - w * 0)\n    # This is now a linear function of w - w * 0.\n    # We can now apply the softmax function to this linear function.\n    w_new = torch.softmax(w - w * 0, dim=-1)\n\n    # We now have a tensor of weights that is a function of w - w * 0.\n    # We can rewrite this as:\n    # w_new = softmax(w - w * 0) + softmax(w * 0 - w * 0)\n    # The second term is just the softmax of all zeros, which is a tensor of 1s.\n    # We can now rewrite this as:\n    # w_new = softmax(w - w * 0) + softmax(w * 0 - w * 0)\n    # We can rewrite this as:\n    # w_new = softmax(w *"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # The annealing function is a piecewise linear function, with a slope of anneal_slope\n    # and a vertical shift of train_frac.\n    # We anneal the weights by applying this function to the difference between\n    # adjacent time intervals.\n    #\n    # We anneal the weights by applying this function to the difference between\n    # adjacent time intervals.\n    #\n    # This is done by computing the difference between adjacent time intervals\n    # and applying the annealing function to them.\n    #\n    # The weights are then adjusted by the ratio of the annealed difference to the\n    # original difference.\n    #\n    # This ensures that the weights are adjusted in a smooth manner, and that\n    # adjacent intervals are not adjusted by more than 1.\n    #\n    # The weights are then renormalized to ensure that they sum to 1.\n\n    # anneal_slope = torch.finfo(torch.float32).eps\n    # anneal_slope = 1.0\n    t = t.float()\n    w = w.float()\n    t_shift = t[..., 1:] - t[..., :-1]\n    t_shift = t_shift.clip(min=eps)\n    w_shift = torch.exp(-t_shift / anneal_slope)\n    w_shift = w_shift.clip(min=eps)\n    w_shift_ratio = w_shift / t_shift\n    w_anneal = w_shift_ratio * (w[..., 1:] - w[..., :-1]) + w[..., :-1]\n    w_anneal /= torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, tuple) or isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, torch.Tensor) and batch.is_cuda == False:\n        return batch.to(device)\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if ignore_list:\n        return batch\n\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    if isinstance(batch, dict):\n        return {k: to_cuda(v, device) for k, v in batch.items()}\n\n    if isinstance(batch, list):\n        return [to_cuda(v, device) for v in batch]\n\n    if isinstance(batch, tuple):\n        return tuple([to_cuda(v, device) for v in batch])\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (list, tuple)):\n        return [to_cuda(x, device, ignore_list) for x in batch]\n\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n\n    elif torch.is_tensor(batch):\n        return batch.to(device)\n\n    elif isinstance(batch, dotdict):\n        return to_cuda(batch.to_dict(), device, ignore_list)\n\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device) for k, v in batch.items() if k not in [\"meta\"]}\n        else:\n            return {k: to_cuda(v, device) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(b, device) for b in batch]\n    else:\n        if isinstance(batch, torch.Tensor):\n            return batch.to(device)\n        else:\n            return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if ignore_list:\n            return batch\n        else:\n            return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device=device, ignore_list=ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, tuple) or isinstance(batch, list):\n        return [to_cuda(v, device=device, ignore_list=ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if ignore_list and \"meta\" in batch:\n        return batch\n    elif isinstance(batch, (tuple, list, dict)):\n        return type(batch)(to_cuda(b, device=device, ignore_list=ignore_list) for b in batch)\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n    elif isinstance(batch, (dict, dotdict)):\n        for k, v in batch.items():\n            if k == \"meta\":\n                pass\n            else:\n                batch[k] = to_cuda(v, device=device, ignore_list=ignore_list)\n    elif isinstance(batch, (tuple, list)):\n        for i, v in enumerate(batch):\n            batch[i] = to_cuda(v, device=device, ignore_list=ignore_list)\n    else:\n        raise TypeError(f\"Unsupported type: {type(batch)}\")\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, dict):\n        if ignore_list:\n            for key, value in batch.items():\n                batch[key] = to_cuda(value, device=device, ignore_list=ignore_list)\n        else:\n            for key, value in batch.items():\n                if key != \"meta\":\n                    batch[key] = to_cuda(value, device=device, ignore_list=ignore_list)\n    elif isinstance(batch, (list, tuple)):\n        for i, value in enumerate(batch):\n            batch[i] = to_cuda(value, device=device, ignore_list=ignore_list)\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n    else:\n        raise NotImplementedError(f\"To_cuda does not support type {type(batch)}\")\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, dict):\n        return {k: to_cuda(v, device=device) for k, v in batch.items() if k != 'meta'}\n    elif isinstance(batch, tuple) or isinstance(batch, list):\n        return [to_cuda(v, device=device) for v in batch]\n    elif isinstance(batch, torch.Tensor):\n        if ignore_list:\n            return batch\n        return batch.to(device)\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if ignore_list:\n        return batch\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (dict, dotdict)):\n        return {k: to_cuda(v, device) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(v, device) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    # MARK: this is a recursive function, so we need to make sure to not go into an infinite loop\n    if ignore_list and isinstance(batch, dict) and \"meta\" in batch:\n        return batch\n\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, list):\n        return [to_cuda(v, device, ignore_list) for v in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(v, device, ignore_list) for v in batch)\n    elif isinstance(batch, set):\n        return {to_cuda(v, device, ignore_list) for v in batch}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if ignore_list:\n        return batch\n    if isinstance(batch, dict):\n        # return {k: to_cuda(v, device) for k, v in batch.items() if k != \"meta\"}\n        return {k: to_cuda(v, device) for k, v in batch.items()}\n    if isinstance(batch, tuple):\n        return tuple(to_cuda(b, device) for b in batch)\n    if isinstance(batch, list):\n        return [to_cuda(b, device) for b in batch]\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    # MARK: handle dict\n    if isinstance(batch, dict):\n        batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n        return batch\n\n    # MARK: handle list\n    elif isinstance(batch, list):\n        batch = [to_cuda(v, device, ignore_list) for v in batch]\n        return batch\n\n    # MARK: handle tuple\n    elif isinstance(batch, tuple):\n        batch = tuple(to_cuda(v, device, ignore_list) for v in batch)\n        return batch\n\n    # MARK: handle torch.Tensor\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.Size\n    elif isinstance(batch, torch.Size):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.device\n    elif isinstance(batch, torch.device):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.device\n    elif isinstance(batch, torch.Device):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.device\n    elif isinstance(batch, torch.dtype):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.dtype\n    elif isinstance(batch, torch.Dtype):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.memory_format\n    elif isinstance(batch, torch.memory_format):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.memory_format\n    elif isinstance(batch, torch.MemoryFormat):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.index_select\n    elif isinstance(batch, torch.index_select):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.index_select\n    elif isinstance(batch, torch.IndexSelect):\n        batch = batch.to(device)\n        return batch\n\n    # MARK: handle torch.index_copy"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if not isinstance(batch, dict) and not isinstance(batch, list):\n        return torch.as_tensor(batch, device=device)\n\n    if ignore_list:\n        return batch\n\n    if isinstance(batch, dict):\n        return {k: to_cuda(v, device) for k, v in batch.items()}\n\n    if isinstance(batch, list):\n        return [to_cuda(v, device) for v in batch]\n\n    if isinstance(batch, dotdict):\n        return dotdict({k: to_cuda(v, device) for k, v in batch.items()})\n\n    raise Exception(f\"Unexpected type: {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if not isinstance(batch, dict):\n        if ignore_list:\n            return to_cuda_helper(batch, device)\n        else:\n            return to_cuda_helper(batch, device, True)\n    else:\n        return to_cuda_dict(batch, device, ignore_list)\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, dict):\n        if not ignore_list:\n            batch = {k: to_cuda(v, device) for k, v in batch.items()}\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    elif isinstance(batch, (list, tuple)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n    elif batch is not None:\n        batch = batch.to(device)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    # MARK: this is a hack to make it work with a dictionary\n    # TODO: maybe a better way to do this?\n    if isinstance(batch, dict):\n        if \"meta\" in batch.keys():\n            return batch\n        else:\n            batch = dotdict(batch)\n\n    if isinstance(batch, dotdict):\n        batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        batch = [to_cuda(v, device, ignore_list) for v in batch]\n    elif isinstance(batch, torch.Tensor) and not ignore_list:\n        batch = batch.to(device)\n    else:\n        batch = to_numpy(batch)\n        batch = torch.from_numpy(batch).to(device)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    # MARK: this is a hack to get around the fact that we're using dotdict\n    if isinstance(batch, dict):\n        batch = dotdict(batch)\n\n    if not ignore_list:\n        if isinstance(batch, (tuple, list)):\n            batch = [to_cuda(v, device) for v in batch]\n        elif isinstance(batch, dict):\n            batch = {k: to_cuda(v, device) for k, v in batch.items()}\n        elif isinstance(batch, torch.Tensor):\n            batch = batch.to(device)\n    else:\n        if isinstance(batch, (tuple, list)):\n            batch = [to_cuda(v, device, ignore_list=True) for v in batch]\n        elif isinstance(batch, dict):\n            batch = {k: to_cuda(v, device, ignore_list=True) for k, v in batch.items()}\n        elif isinstance(batch, torch.Tensor):\n            batch = batch.to(device)\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if not isinstance(batch, torch.Tensor):\n        if isinstance(batch, dict):\n            # Note: we're using a copy of the dictionary to avoid changing the original dictionary\n            batch = {k: to_cuda(v, device=device, ignore_list=ignore_list) for k, v in batch.items() if k != \"meta\"}\n        elif isinstance(batch, list):\n            batch = [to_cuda(v, device=device, ignore_list=ignore_list) for v in batch]\n        elif isinstance(batch, tuple):\n            batch = (to_cuda(v, device=device, ignore_list=ignore_list) for v in batch)\n        else:\n            raise NotImplementedError(f\"Unsupported type: {type(batch)}\")\n\n    else:\n        if not ignore_list:\n            batch = batch.to(device)\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, dict):\n        if ignore_list:\n            # TODO: this is a hack to avoid moving \"meta\" to gpu\n            # TODO: we should probably do something more general\n            # TODO: like moving only certain keys\n            # TODO: or doing it only if the key is a tensor\n            # TODO: or just not moving anything\n            # TODO: and maybe not even returning the dict\n            # TODO: but just the tensor\n            # TODO: this is a hack\n            batch = {k: v for k, v in batch.items() if k != \"meta\"}\n            for k, v in batch.items():\n                batch[k] = to_cuda(v, device, ignore_list)\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n\n    elif isinstance(batch, (list, tuple)):\n        batch = [to_cuda(v, device, ignore_list) for v in batch]\n\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device)\n\n    else:\n        raise NotImplementedError(f'Unsupported type: {type(batch)}')\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO: refactor this function\n    # TODO"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO: this function is not fully tested\n    # TODO:"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: consider using scatter instead\n    # TODO: consider using multi_scatter instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO: consider using multi_gather_tris_ instead\n    # TODO"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand faces tensor to match the batch dimension of vertices tensor\n    f = f.unsqueeze(dim) if f.dim() < v.dim() else f\n    # gather the vertices and reshape to match the original faces tensor structure\n    return multi_gather(v, f, dim).view_as(f)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: add batching dimension for each batch\n    # TODO: add batching dimension for each batch\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, 2, 3\n    # TODO: batching dim: 0, 1, "}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: test\n    # TODO: test batch dimension\n\n    # We first expand the batch dimension of the faces tensor to match the batch dimension of the vertices tensor,\n    # and then reshape the result to maintain the original structure of the faces tensor with additional dimensions for batch processing.\n    # The result is a tensor containing the gathered triangles.\n    return multi_gather(v, multi_indexing(f, v.shape, dim), dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    v_dim = v.ndim\n    f_dim = f.ndim\n\n    # Expand the faces tensor to match the batch dimension of the vertices tensor\n    if f_dim < v_dim:\n        f_dim = v_dim\n        f = f.unsqueeze(dim=0)\n    elif f_dim > v_dim:\n        f_dim = v_dim\n        f = f.squeeze(dim=0)\n    else:\n        f_dim = v_dim\n\n    # Gather the vertices at the specified dimension\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v.shape = (B, P, 3)\n    # f.shape = (B, F, 3)\n    # returns: (B, F, 3)\n    # f.shape = (F, 3)\n    # returns: (F, 3)\n\n    # v.shape = (P, 3)\n    # f.shape = (F, 3)\n    # returns: (F, 3)\n\n    # f.shape = (F, 3)\n    # returns: (F, 3)\n\n    # f.shape = (F, 1, 3)\n    # returns: (F, 3)\n\n    # f.shape = (F, 1, 1, 3)\n    # returns: (F, 3)\n\n    # v.shape = (B, P, 3)\n    # f.shape = (F, 3)\n    # returns: (B, F, 3)\n\n    # v.shape = (B, P, 3)\n    # f.shape = (B, F, 1, 3)\n    # returns: (B, F, 3)\n\n    # v.shape = (B, P, 3)\n    # f.shape = (B, F, 1, 1, 3)\n    # returns: (B, F, 3)\n\n    # v.shape = (B, P, 3)\n    # f.shape = (B, F, 1, 1, 1, 3)\n    # returns: (B, F, 3)\n\n    # f.shape = (B, 3)\n    # returns: (B, 3)\n\n    # f.shape = (B, 1, 3)\n    # returns: (B, 3)\n\n    # f.shape = (B, 1, 1, 3)\n    # returns: (B, 3)\n\n    # f.shape = (B, 1, 1, 1, 3)\n    # returns: (B, 3)\n\n    # f.shape = (B, 1,"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Expand the faces tensor to match the batch dimension of the vertices tensor\n    if f.dim() != v.dim():\n        f = f.unsqueeze(dim)\n    # Compute the normals with respect to the vertices\n    n = multi_gather(v, f, dim)\n    # Reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return n.reshape(f.size() + n.shape[-2:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: This function is not used in the current codebase. It may be removed.\n    if v.ndim != 3 or f.ndim != 2:\n        raise RuntimeError('The tensors v and f must have 3 and 2 dimensions, respectively.')\n    if v.size(dim) != f.size(-1):\n        f = f.unsqueeze(dim)\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, N, 3\n    # f: B, F, 3\n    # f: B, F, 3, 3\n    # f: B, F, 1, 3\n    # v: B, N, 3, 1\n    # f: B, F, 3, 1\n    # f: B, F, 3, 3\n\n    # f = f.unsqueeze(-1)\n    # v = v.unsqueeze(-2)\n    # return f.transpose(1, 2).matmul(v).transpose(1, 2)\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Compute the batch dimension of the vertices tensor\n    batch_size = v.shape[0]\n\n    # If the faces tensor is not a batch tensor, expand it to match the batch dimension of the vertices tensor\n    if f.shape[0] != batch_size:\n        f = f.expand(batch_size, -1)\n\n    # Perform the actual gather operation\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # ensure that the batch dimension is the second last dimension\n    # if the batch dimension is the last dimension, we need to transpose it to the second last dimension\n    if v.ndim == f.ndim + 1:\n        v = v.transpose(-1, -2)\n        f = f.unsqueeze(-1)\n        dim = -2\n\n    # adjust the batch dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if v.shape[-1] != f.shape[0]:\n        f = f.unsqueeze(-1)\n\n    # compute the faces normals\n    n = v.view(v.shape[0], -1, 3)\n    n = torch.cross(n[:, f[:, 1], n[:, f[:, 2]])\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    n = n.view(f.shape[0], -1, 3)\n    return n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, P, 3\n    # f: B, F, 3\n    # f = f.unsqueeze(2)\n    # f = f.repeat(1, 1, 3, 1)\n    # f = f.reshape(f.shape[0], f.shape[1], 1, 3, f.shape[2])\n    # f = f.permute(0, 2, 1, 3, 4)\n    # f = f.reshape(f.shape[0], f.shape[1], f.shape[2] * f.shape[3], f.shape[4])\n    # return v.gather(dim, f)\n    # v: B, P, 3\n    # f: B, F, 1, 3, 1\n    # f: B, F, 1, 3, 1\n    # f: B, F, 1, 3, 3\n    # f: B, F, 1, 9\n    # f: B, F, 9\n    # f: B, F, 3, 3\n    # return v.gather(dim, f)\n\n    # v: B, P, 3\n    # f: B, F, 3\n    # f = f.unsqueeze(1)\n    # f = f.unsqueeze(1)\n    # f = f.reshape(f.shape[0], 1, f.shape[1], f.shape[2])\n    # f = f.reshape(f.shape[0], f.shape[1], 1, f.shape[2], f.shape[3])\n    # f = f.permute(0, 2, 1, 3, 4)\n    # f = f.reshape(f.shape[0], f.shape[1], f.shape[2] * f.shape[3], f.shape[4])\n    # return v.gather(dim, f)\n    # f: B, F, 1, 3, 1\n    # f: B, F, 1, 9\n    # f: B, F, "}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # make sure the batch dimensions match\n    v_shape = v.shape\n    f_shape = f.shape\n    if v_shape[dim] != f_shape[dim]:\n        f_shape = [v_shape[dim]] + f_shape[dim + 1:]\n    f = f.view(f_shape)\n\n    # compute the normal of the triangles\n    v_shape = v.shape\n    f_shape = f.shape\n    v_shape[dim] = -1\n    f_shape[dim] = -1\n    v_shape = [v_shape[0]] + v_shape[1:dim] + [1] + v_shape[dim + 1:]\n    f_shape = [f_shape[0]] + f_shape[1:dim] + [3] + f_shape[dim + 1:]\n    return multi_gather(v, f, dim=dim).view(v_shape)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # make sure the indices is the same size as the batch dimension of vertices\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(-1)\n    if f.ndim > v.ndim:\n        f = f.reshape(-1, f.size(-2), f.size(-1))\n\n    # compute the normals\n    n = multi_gather(v, f, dim)\n\n    # reshape the result to maintain the structure of the original faces tensor\n    return n.reshape(*f.shape[:-1], -1, n.size(-1))\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Ensure the vertices tensor is a batch tensor\n    if v.ndim != 2:\n        if v.ndim == 1:\n            v = v.unsqueeze(0)\n        else:\n            raise ValueError(f\"The vertices tensor must be a batch tensor, but got {v.shape} instead.\")\n\n    # Ensure the faces tensor has the same batch dimension as the vertices tensor\n    if f.ndim == 2:\n        f = f.unsqueeze(0)\n    elif f.ndim == 1:\n        f = f.unsqueeze(1)\n    elif f.ndim == 3:\n        pass\n    else:\n        raise ValueError(f\"The faces tensor must have the same batch dimension as the vertices tensor, but got {f.shape} instead.\")\n\n    # Ensure the batch dimension is the last dimension\n    if f.ndim != 3:\n        f = f.transpose(0, 1)\n\n    # Ensure the faces tensor has the correct number of dimensions\n    if f.ndim == 3:\n        pass\n    elif f.ndim == 2:\n        f = f.unsqueeze(1)\n    else:\n        raise ValueError(f\"The faces tensor must have 2 or 3 dimensions, but got {f.shape} instead.\")\n\n    # Ensure the vertices tensor has the correct number of dimensions\n    if v.ndim == 3:\n        pass\n    elif v.ndim == 2:\n        v = v.unsqueeze(1)\n    else:\n        raise ValueError(f\"The vertices tensor must have 2 or 3 dimensions, but got {v.shape} instead.\")\n\n    # Gather the vertices\n    g = multi_gather(v, f, dim)\n\n    # Reshape the result\n    return g.view(f.shape[0], -1, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # https://github.com/mrdolgoi/PyTorch-3D-Rendering/blob/master/easyvolcap/utils/data_utils.py\n    # TODO: check if the shape of the faces tensor is correct\n    if v.ndim == 2:\n        v = v.unsqueeze(-1)\n\n    # Expand the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim == 2:\n        f = f.unsqueeze(-1)\n\n    # Gather the vertices corresponding to the faces\n    v_g = multi_gather(v, f, dim)\n\n    # Compute the faces normals\n    v_g = v_g.view(f.shape[0], -1, 3)\n    v_g_t = v_g.transpose(1, 2)\n    v_g_t_t = v_g_t.transpose(1, 0)\n    v_g_t_t_t = v_g_t_t.transpose(1, 2)\n\n    # Reshape the normals to maintain the original faces tensor structure with additional dimensions for batch processing\n    return v_g_t_t_t.reshape(f.shape[0], -1, 3)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand the batch dimension of faces to match that of the vertices tensor\n    # the batch dimension of the output will be the last dimension\n    f_batch_size = v.shape[-1]\n    f = f.unsqueeze(-1).repeat(1, 1, f_batch_size)\n    return multi_scatter(v, f, v.shape[dim], dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # The following code is from: https://github.com/NVIDIA/Learning_to_Sample_with_Multi-View_Depth_Volumes/blob/master/volcap/utils/data_utils.py\n    # It is a copy-paste, with the following changes:\n    # - remove the last dim of f (f.shape[dim] is always 3)\n    # - remove the dim argument of gather\n    # - change the dim argument of scatter to -2\n    # - remove the last dim of v (v.shape[dim] is always 3)\n    # - remove the dim argument of scatter_\n\n    # expand f to match the batch dimension of v\n    f = f.unsqueeze(-1) if f.shape[dim] != v.shape[dim] else f\n    # reshape f to maintain the original structure of f with additional dimensions for batch processing\n    f = f.reshape(*f.shape[:-1], -1)\n    # gather the vertices\n    v = multi_gather(v, f, dim)\n    # reshape to maintain the original structure of f with additional dimensions for batch processing\n    return v.reshape(*f.shape[:-1], 3, v.shape[-1])\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch.unsqueeze(0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch.unsqueeze(0)\n    else:\n        batch = torch.as_tensor([batch]).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch.unsqueeze(0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        pass  # do nothing here, used for typed in add_batch for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise TypeError(f'Unrecognized input type: {type(batch)}')\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch.unsqueeze(0)\n    else:\n        raise TypeError(f\"Unsupported data type: {type(batch)}\")\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass\n        # batch = torch.as_tensor(batch)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch.unsqueeze(0)\n    else:\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise TypeError(f'Unsupported type: {type(batch)}')\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, 0)\n    else:\n        raise TypeError(f\"Unsupported type: {type(batch)}\")\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise TypeError(f\"Unrecognized input type: {type(batch)}\")\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = \\\n            torch.tensor(self.H), torch.tensor(self.W), torch.tensor(self.K), torch.tensor(self.R), torch.tensor(self.T), \\\n            torch.tensor(self.n), torch.tensor(self.f), torch.tensor(self.t), torch.tensor(self.v), torch.tensor(self.bounds)\n\n        # Internal states to facilitate camera position change\n        batch.is_dragging = torch.tensor(self.is_dragging)\n        batch.about_origin = torch.tensor(self.about_origin)\n        batch.is_panning = torch.tensor(self.is_panning)\n        batch.lock_fx_fy = torch.tensor(self.lock_fx_fy)\n        batch.drag_start = torch.tensor(self.drag_start)\n\n        # Internal states to facilitate moving with mass\n        batch.mass = torch.tensor(self.mass)\n        batch.force = torch.tensor(self.force)\n        batch.speed = torch.tensor(self.speed)\n        batch.acc = torch.tensor(self.acc)\n        batch.drag_coeff_mult = torch.tensor(self.drag_coeff_mult)\n        batch.movement_force = torch.tensor(self.movement_force)\n        batch.constant_drag = torch.tensor(self.constant_drag)\n        batch.pause_physics = torch.tensor(self.pause_physics)\n        batch.min_interval = torch.tensor(self.min_interval)\n\n        batch.torque = torch.tensor(self.torque)\n        batch.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        batch.angular_speed = torch.tensor(self.angular_speed)\n        batch.angular_acc = torch.tensor(self.angular_acc)\n        batch.angular_friction = torch.tensor(self.angular_friction)"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct the batch\n        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = self.bounds\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.front = self.front\n        batch.center = self.center\n        batch.right = self.right\n        batch.down = self.down\n        batch.is_dragging = self.is_dragging\n        batch.about_origin = self.about_origin\n        batch.is_panning = self.is_panning\n        batch.drag_start = self.drag_start\n        batch.drag_start_front = self.drag_start_front\n        batch.drag_start_down = self.drag_start_down\n        batch.drag_start_right = self.drag_start_right\n        batch.drag_start_center = self.drag_start_center\n        batch.drag_start_origin = self.drag_start_origin\n        batch.drag_start_world_up = self.drag_start_world_up\n        batch.fx = self.fx\n        batch.fy = self.fy\n        batch.cx = self.cx\n        batch.cy = self.cy\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Other configurables\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n\n        # Internal states to facilitate camera position change\n        batch.is_dragging = self.is_dragging\n        batch.about_origin = self.about_origin\n        batch.is_panning = self.is_panning\n        batch.drag_start = self.drag_start\n\n        # Internal states to facilitate moving with mass\n        batch.mass = self.mass\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.movement_force = self.movement_force\n        batch.constant_drag = self.constant_drag\n        batch.pause_physics = self.pause_physics\n        batch.min_interval = self.min_interval\n\n        batch.torque = self.torque\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.angular_speed = self.angular_speed\n        batch.angular_acc = self.angular_acc\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.movement_torque = self.movement_torque\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Direct mapping of parameters\n        batch = dotdict(\n            H=self.H,\n            W=self.W,\n            K=self.K,\n            R=self.R,\n            T=self.T,\n            n=self.n,\n            f=self.f,\n            t=self.t,\n            v=self.v,\n            bounds=self.bounds,\n            origin=self.origin,\n            world_up=self.world_up,\n            movement_speed=self.movement_speed,\n            movement_force=self.movement_force,\n            drag_coeff_mult=self.drag_coeff_mult,\n            constant_drag=self.constant_drag,\n            mass=self.mass,\n            moment_of_inertia=self.moment_of_inertia,\n            movement_torque=self.movement_torque,\n            angular_friction=self.angular_friction,\n            constant_torque=self.constant_torque,\n            min_interval=self.min_interval,\n            pause_physics=self.pause_physics,\n        )\n\n        # Nested 'meta' dictionary\n        meta = dotdict(\n            is_dragging=self.is_dragging,\n            is_panning=self.is_panning,\n            about_origin=self.about_origin,\n            drag_start=self.drag_start,\n            drag_start_front=self.drag_start_front,\n            drag_start_down=self.drag_start_down,\n            drag_start_right=self.drag_start_right,\n            drag_start_center=self.drag_start_center,\n            drag_start_origin=self.drag_start_origin,\n            drag_start_world_up=self.drag_start_world_up,\n            front=self.front,\n            down=self.down,\n            right=self.right,\n            center=self.center,\n            origin=self.origin,\n            world_up=self.world_up,\n            fx=self.fx,\n            fy=self.fy,\n            cx=self.cx,\n            cy=self."}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch\n        batch = dotdict()\n        batch.H = torch.as_tensor(self.H)\n        batch.W = torch.as_tensor(self.W)\n        batch.K = self.K.to_list()\n        batch.R = self.R.to_list()\n        batch.T = self.T.to_list()\n        batch.n = torch.as_tensor(self.n)\n        batch.f = torch.as_tensor(self.f)\n        batch.t = torch.as_tensor(self.t)\n        batch.v = torch.as_tensor(self.v)\n        batch.bounds = self.bounds.to_list()\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Create the batch dictionary\n        batch = dotdict()\n\n        # Extract the intrinsics\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n\n        # Extract the extrinsics\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = self.bounds\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n\n        # Extract the movement parameters\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n\n        # Extract the mass parameters\n        batch.mass = self.mass\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.movement_force = self.movement_force\n        batch.constant_drag = self.constant_drag\n\n        # Extract the torque parameters\n        batch.torque = self.torque\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.angular_speed = self.angular_speed\n        batch.angular_acc = self.angular_acc\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.movement_torque = self.movement_torque\n\n        # Extract the GUI parameters\n        batch.lock_fx_fy = self.lock_fx_fy\n        batch.drag_start = self.drag_start\n        batch.is_dragging = self.is_dragging\n        batch.is_panning = self.is_panning\n        batch.about_origin = self.about_origin\n\n        # Extract the intrinsics\n        batch.fx = self.fx\n        batch.fy = self.fy\n        batch.cx = self.cx"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert intrinsics to tensor\n        K = torch.as_tensor(self.K.to_list(), dtype=torch.float32)\n        K[2, 2] = 1.0\n\n        # Convert extrinsics to tensor\n        R = torch.as_tensor(self.R.to_list(), dtype=torch.float32)\n        T = torch.as_tensor(self.T.to_list(), dtype=torch.float32)\n\n        # Convert other parameters to tensor\n        n = torch.as_tensor(self.n, dtype=torch.float32)\n        f = torch.as_tensor(self.f, dtype=torch.float32)\n        t = torch.as_tensor(self.t, dtype=torch.float32)\n        v = torch.as_tensor(self.v, dtype=torch.float32)\n        bounds = torch.as_tensor(self.bounds.to_list(), dtype=torch.float32)\n\n        # Create the batch dictionary\n        batch = dotdict()\n\n        # Add intrinsics to batch\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = K\n\n        # Add extrinsics to batch\n        batch.R = R\n        batch.T = T\n\n        # Add other parameters to batch\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch.bounds = bounds\n\n        # Return the batch dictionary\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct the batch dictionary\n        batch = dotdict()  # dotdict() is a class that behaves like a dictionary but allows access to its items through attributes (dot notation)\n\n        # Set the camera parameters\n        batch.H = torch.as_tensor(self.H, dtype=torch.int)\n        batch.W = torch.as_tensor(self.W, dtype=torch.int)\n        batch.K = torch.as_tensor(self.K, dtype=torch.float32)\n        batch.R = torch.as_tensor(self.R, dtype=torch.float32)\n        batch.T = torch.as_tensor(self.T, dtype=torch.float32)\n        batch.n = torch.as_tensor(self.n, dtype=torch.float32)\n        batch.f = torch.as_tensor(self.f, dtype=torch.float32)\n        batch.t = torch.as_tensor(self.t, dtype=torch.float32)\n        batch.v = torch.as_tensor(self.v, dtype=torch.float32)\n        batch.bounds = torch.as_tensor(self.bounds, dtype=torch.float32)\n\n        # Set the GUI related elements\n        batch.origin = torch.as_tensor(self.origin, dtype=torch.float32)\n        batch.world_up = torch.as_tensor(self.world_up, dtype=torch.float32)\n        batch.movement_speed = torch.as_tensor(self.movement_speed, dtype=torch.float32)\n        batch.movement_force = torch.as_tensor(self.movement_force, dtype=torch.float32)\n        batch.drag_coeff_mult = torch.as_tensor(self.drag_coeff_mult, dtype=torch.float32)\n        batch.constant_drag = torch.as_tensor(self.constant_drag, dtype=torch.float32)\n        batch.mass = torch.as_tensor(self.mass, dtype=torch.float32)\n        batch.moment_of_inertia = torch.as_tensor(self"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert intrinsics\n        K = self.K\n        K = torch.as_tensor(K).reshape(3, 3)  # 3, 3\n        K = torch.unsqueeze(K, 0)  # 1, 3, 3\n\n        # Convert extrinsics\n        R = self.R\n        R = torch.as_tensor(R).reshape(3, 3)  # 3, 3\n        R = torch.unsqueeze(R, 0)  # 1, 3, 3\n        T = torch.as_tensor(self.T).reshape(3, 1)  # 3, 1\n        T = torch.unsqueeze(T, 0)  # 1, 3, 1\n\n        # Convert intrinsics\n        n = torch.as_tensor(self.n).reshape(1, 1)  # 1, 1\n        f = torch.as_tensor(self.f).reshape(1, 1)  # 1, 1\n        t = torch.as_tensor(self.t).reshape(1, 1)  # 1, 1\n        v = torch.as_tensor(self.v).reshape(1, 1)  # 1, 1\n\n        # Convert bounds\n        bounds = torch.as_tensor(self.bounds).reshape(2, 3)  # 2, 3\n        bounds = torch.unsqueeze(bounds, 0)  # 1, 2, 3\n\n        # Convert GUI related elements\n        H = torch.as_tensor(self.H).reshape(1, 1)  # 1, 1\n        W = torch.as_tensor(self.W).reshape(1, 1)  # 1, 1\n        fx = torch.as_tensor(self.fx).reshape(1, 1)  # 1, 1\n        fy = torch.as_tensor(self.fy).reshape(1, 1)  # 1, 1\n        cx = torch.as_tensor(self.cx).reshape(1, 1)  # 1, 1\n        cy ="}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters and GUI related elements into tensors\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = \\\n            torch.tensor(self.H, dtype=torch.long), torch.tensor(self.W, dtype=torch.long), \\\n            torch.tensor(self.K, dtype=torch.float32), torch.tensor(self.R, dtype=torch.float32), \\\n            torch.tensor(self.T, dtype=torch.float32), torch.tensor(self.n, dtype=torch.float32), \\\n            torch.tensor(self.f, dtype=torch.float32), torch.tensor(self.t, dtype=torch.float32), \\\n            torch.tensor(self.v, dtype=torch.float32), torch.tensor(self.bounds, dtype=torch.float32)\n\n        # Organize camera parameters and GUI related elements into a structured dictionary\n        batch.meta = dotdict()\n        batch.meta.origin = self.origin\n        batch.meta.world_up = self.world_up\n        batch.meta.movement_speed = self.movement_speed\n        batch.meta.movement_force = self.movement_force\n        batch.meta.drag_coeff_mult = self.drag_coeff_mult\n        batch.meta.constant_drag = self.constant_drag\n        batch.meta.mass = self.mass\n        batch.meta.moment_of_inertia = self.moment_of_inertia\n        batch.meta.movement_torque = self.movement_torque\n        batch.meta.angular_friction = self.angular_friction\n        batch.meta.constant_torque = self.constant_torque\n\n        # Return the structured dictionary\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct a dotdict for the batch\n        batch = dotdict()\n\n        # Add intrinsics\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n\n        # Add extrinsics\n        batch.R = self.R\n        batch.T = self.T\n\n        # Add bounds\n        batch.n = self.n\n        batch.f = self.f\n\n        # Add temporal dimension\n        batch.t = self.t\n\n        # Add view dimension\n        batch.v = self.v\n\n        # Add bounding box\n        batch.bounds = self.bounds\n\n        # Add GUI related elements\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        # Construct a nested dictionary for the batch\n        meta = dotdict()\n        meta.origin = self.origin\n        meta.world_up = self.world_up\n        meta.movement_speed = self.movement_speed\n        meta.movement_force = self.movement_force\n        meta.drag_coeff_mult = self.drag_coeff_mult\n        meta.constant_drag = self.constant_drag\n        meta.mass = self.mass\n        meta.moment_of_inertia = self.moment_of_inertia\n        meta.movement_torque = self.movement_torque\n        meta.angular_friction = self.angular_friction\n        meta.constant_torque = self.constant_torque\n        meta.min_interval = self.min_interval\n        meta.pause"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct a dotdict instance\n        batch = dotdict()\n\n        # Assign camera parameters\n        batch.H = torch.tensor([self.H], dtype=torch.int64)\n        batch.W = torch.tensor([self.W], dtype=torch.int64)\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n        batch.n = torch.tensor([self.n], dtype=torch.float64)\n        batch.f = torch.tensor([self.f], dtype=torch.float64)\n        batch.t = torch.tensor([self.t], dtype=torch.float64)\n        batch.v = torch.tensor([self.v], dtype=torch.float64)\n        batch.bounds = self.bounds\n\n        # Assign GUI related elements\n        batch.drag_coeff_mult = torch.tensor([self.drag_coeff_mult], dtype=torch.float64)\n        batch.movement_force = torch.tensor([self.movement_force], dtype=torch.float64)\n        batch.constant_drag = torch.tensor([self.constant_drag], dtype=torch.float64)\n        batch.mass = torch.tensor([self.mass], dtype=torch.float64)\n        batch.moment_of_inertia = torch.tensor([self.moment_of_inertia], dtype=torch.float64)\n        batch.movement_torque = torch.tensor([self.movement_torque], dtype=torch.float64)\n        batch.angular_friction = torch.tensor([self.angular_friction], dtype=torch.float64)\n        batch.constant_torque = torch.tensor([self.constant_torque], dtype=torch.float64)\n\n        # Assign the meta dictionary\n        batch.meta = dotdict()\n\n        # Assign camera parameters\n        batch.meta.H = torch.tensor([self.H], dtype=torch.int64)\n        batch.meta.W = torch.tensor([self.W], dtype=torch.int64)\n        batch.meta.K = self.K\n        batch.meta.R = self"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Extract intrinsics\n        K = self.K.to_list()\n        K = torch.tensor(K).view(3, 3)\n\n        # Extract extrinsics\n        R = self.R.to_list()\n        T = self.T.to_list()\n        R = torch.tensor(R).view(3, 3)\n        T = torch.tensor(T).view(3, 1)\n\n        # Extract other parameters\n        n = self.n\n        f = self.f\n        t = self.t\n        v = self.v\n        bounds = self.bounds.to_list()\n        bounds = torch.tensor(bounds).view(2, 3)\n\n        # Construct the batch\n        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = K\n        batch.R = R\n        batch.T = T\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch.bounds = bounds  # 6\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Convert intrinsics to 3x3\n        K = K.reshape(3, 3)\n\n        # Convert extrinsics to 3x4\n        R = R.reshape(3, 3)\n        T = T.reshape(3, 1)\n\n        # Convert intrinsics to tensor\n        K = torch.as_tensor(K, dtype=torch.float32)\n        R = torch.as_tensor(R, dtype=torch.float32)\n        T = torch.as_tensor(T, dtype=torch.float32)\n\n        # Convert bounds to tensor\n        bounds = torch.as_tensor(bounds, dtype=torch.float32)\n\n        # Convert intrinsics to tensor\n        n = torch.as_tensor(n, dtype=torch.float32)\n        f = torch.as_tensor(f, dtype=torch.float32)\n        t = torch.as_tensor(t, dtype=torch.float32)\n        v = torch.as_tensor(v, dtype=torch.float32)\n\n        # Convert intrinsics to tensor\n        origin = torch.as_tensor(self.origin, dtype=torch.float32)\n        world_up = torch.as_tensor(self.world_up, dtype=torch.float32)\n        movement_speed = torch.as_tensor(self.movement_speed, dtype=torch.float32)\n\n        # Convert intrinsics to tensor\n        movement_force = torch.as_tensor(self.movement_force, dtype=torch.float32)\n        drag_coeff_mult = torch.as_tensor(self.drag_coeff_mult, dtype=torch.float32)\n        constant_drag = torch.as_tensor(self.constant_drag, dtype=torch.float32)\n        mass = torch.as_tensor(self.mass,"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to tensors\n        batch = dotdict()\n        batch.H, batch.W = torch.tensor([self.H, self.W], dtype=torch.float32)\n        batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = [torch.as_tensor(v, dtype=torch.float32) for v in [self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds]]\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Organize the camera parameters and GUI related elements into a structured dictionary format\n        batch = dotdict()\n\n        # Convert the intrinsics parameters into a tensor\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.K = torch.as_tensor(batch.K).to(dtype=torch.float32)  # intrinsics\n        batch.R = torch.as_tensor(batch.R).to(dtype=torch.float32)  # extrinsics\n        batch.T = torch.as_tensor(batch.T).to(dtype=torch.float32)  # extrinsics\n        batch.n = torch.as_tensor(batch.n).to(dtype=torch.float32)  # bounds limit\n        batch.f = torch.as_tensor(batch.f).to(dtype=torch.float32)  # bounds limit\n        batch.t = torch.as_tensor(batch.t).to(dtype=torch.float32)  # temporal dimension\n        batch.v = torch.as_tensor(batch.v).to(dtype=torch.float32)  # view dimension\n        batch.bounds = torch.as_tensor(batch.bounds).to(dtype=torch.float32)  # bounding box\n\n        # Organize the GUI related elements into a nested dictionary\n        batch.meta = dotdict()\n\n        # Convert the intrinsics parameters into a tensor\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta.K = torch.as_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct the batch\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Update intrinsics\n        batch.K = torch.tensor(batch.K, dtype=torch.float)\n        batch.K = batch.K.to_list()\n        batch.K[0, 0] = self.fx\n        batch.K[1, 1] = self.fy\n        batch.K[0, 2] = self.cx\n        batch.K[1, 2] = self.cy\n        batch.K = torch.tensor(batch.K, dtype=torch.float)\n\n        # Update extrinsics\n        batch.R = torch.tensor(batch.R, dtype=torch.float)\n        batch.R = batch.R.to_list()\n        batch.T = torch.tensor(batch.T, dtype=torch.float)\n        batch.T = batch.T.to_list()\n\n        # Update other parameters\n        batch.origin = torch.tensor(self.origin, dtype=torch.float)\n        batch.world_up = torch.tensor(self.world_up, dtype=torch.float)\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert intrinsics\n        K = self.K\n        K = torch.tensor(K, dtype=torch.float32)\n        K = K.view(3, 3)  # 3, 3\n\n        # Convert extrinsics\n        R = self.R\n        R = torch.tensor(R, dtype=torch.float32)\n        R = R.view(3, 3)  # 3, 3\n        T = self.T\n        T = torch.tensor(T, dtype=torch.float32)\n        T = T.view(3, 1)  # 3, 1\n\n        # Convert bounds\n        bounds = self.bounds\n        bounds = torch.tensor(bounds, dtype=torch.float32)\n        bounds = bounds.view(3, 2)  # 3, 2\n\n        # Convert other parameters\n        n = torch.tensor(self.n, dtype=torch.float32)\n        f = torch.tensor(self.f, dtype=torch.float32)\n        t = torch.tensor(self.t, dtype=torch.float32)\n        v = torch.tensor(self.v, dtype=torch.float32)\n\n        # Construct the batch\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = H, W, K, R, T, n, f, t, v, bounds\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Initialize the batch dictionary\n        batch = dotdict()\n\n        # Convert intrinsics\n        batch.H, batch.W, batch.K = self.H, self.W, self.K\n        batch.R, batch.T = self.R, self.T\n        batch.n, batch.f = self.n, self.f\n        batch.t, batch.v = self.t, self.v\n        batch.bounds = self.bounds\n\n        # Convert other GUI related elements\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        # Return the batch dictionary\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert intrinsics\n        K = torch.tensor(self.K)  # 3, 3\n        K[1, 1] = self.s  # 2, 2\n        K[0, 0] = self.fx  # 2, 2\n        K[1, 1] /= K[0, 0]  # 2, 2\n        K[0, 0] = 1.0  # 2, 2\n        K[0, 2] = self.cx  # 2, 3\n        K[1, 2] = self.cy  # 2, 3\n\n        # Convert extrinsics\n        R = torch.tensor(self.R)  # 3, 3\n        T = torch.tensor(self.T)  # 3, 1\n\n        # Convert GUI related elements\n        H = self.H\n        W = self.W\n        n = self.n\n        f = self.f\n        t = self.t\n        v = self.v\n        bounds = torch.tensor(self.bounds)  # 2, 3\n\n        # Create the batch\n        batch = dotdict()\n        batch.K = K\n        batch.R = R\n        batch.T = T\n        batch.H = H\n        batch.W = W\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch.bounds = bounds\n        return batch\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime:\n            return\n\n        serializer = AgentSerializer(agent)\n\n        self.persistence.save_agent(serializer.serialize())\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent:\n            self.persistence.save_agent(agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime():\n            if agent.is_working():\n                serialized_agent = AgentSerializer(agent)\n                self.persistence.save_agent(serialized_agent.to_dict())"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime:\n            return\n\n        agent_state = AgentSerializer.serialize(agent)\n        self.persistence.save_agent_state(agent.id, agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            state = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent.id, state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime():\n            return\n\n        if agent.is_working():\n            self.persistence.save_agent(agent.serialize_state())\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            self.persistence.save_agent(agent.state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime_agent:\n            return\n\n        agent_dict = AgentSerializer.serialize_agent(agent)\n        self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            agent_state = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        # TODO: Implement pessimistically\n        if agent.is_working_agent() and not agent.is_prime_agent():\n            self.persistence.save_agent(AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_serializer = AgentSerializer(agent)\n            self.persistence.save_agent(agent_serializer.serialize())\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime_agent:\n            return\n        else:\n            state = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime():\n            return\n\n        agent_state = AgentSerializer.serialize(agent)\n\n        self.persistence.save_agent_state(agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            self.persistence.save_agent(AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime:\n            serializer = AgentSerializer(agent)\n            serialized_agent = serializer.serialize()\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime_agent:\n            return\n\n        serialized_agent = AgentSerializer().serialize(agent)\n        self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_state = AgentSerializer.serialize(agent)\n            self.persistence.save_agent_state(agent.id, agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime_agent():\n            return\n\n        state = AgentSerializer().serialize(agent)\n        self.persistence.save_agent(agent.id, state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime():\n            serializer = AgentSerializer()\n            state = serializer.serialize(agent)\n            self.persistence.save_agent(state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_prime_agent():\n            return\n\n        state = AgentSerializer.serialize(agent)\n        self.persistence.save_state(state)\n        return\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [e])[0][0] for e in self.agents]\n            max_sim_index = np.argmax(similarities)\n            return self.agents[max_sim_index], similarities[max_sim_index]\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity: {e}\")\n            raise ValueError(f\"Error calculating similarity: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [a.purpose_embedding])[0][0]\n            if similarities > 0:\n                return self.agents[similarities.argmax()], similarities\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity: {e}\")\n            raise ValueError(f\"Error calculating similarity: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -float(\"inf\")\n\n            similarities = [cosine_similarity([purpose_embedding], [e])[0][0] for e in self.agents]\n            return self.agents[np.argmax(similarities)], similarities[np.argmax(similarities)]\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity: {e}\")\n            return None, -float(\"inf\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n            return self.agents[np.argmax(similarities)], similarities[np.argmax(similarities)]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n            return self.agents[similarities.argmax()], similarities[similarities.argmax()]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) < 2:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            index = np.argmax(similarities)\n            return self.agents[index], similarities[index]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n            if similarities > self.calculate_similarity_threshold():\n                return self.agents[similarities.argmax()], similarities\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if purpose_embedding is None or len(purpose_embedding) == 0:\n                return None, -np.inf\n            else:\n                similarities = [cosine_similarity([purpose_embedding], [e])[0][0] for e in self.agents]\n                return self.agents[np.argmax(similarities)], similarities[np.argmax(similarities)]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [e])[0][0] for e in self.agents]\n\n            if len(similarities) == 0:\n                return None, -np.inf\n\n            return self.agents[np.argmax(similarities)], np.amax(similarities)\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity score: {e}\")\n            raise ValueError(f\"Error calculating similarity score: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -float(\"inf\")\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            index = np.argmax(similarities)\n            agent = self.agents[index]\n\n            return agent, similarities[index]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) < 1:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [a.purpose_embedding])[0][0]\n            max_sim = np.argmax(similarities)\n            return self.agents[max_sim], similarities[max_sim]\n        except Exception:\n            logger.exception(\"Error finding closest agent\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) < 2:\n                return None, -1\n\n            similarities = [cosine_similarity([purpose_embedding], [e])[0][0] for e in self.agents]\n            max_similarity = max(similarities)\n            return self.agents[similarities.index(max_similarity)], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] if agent.purpose_embedding is not None else -np.inf for agent in self.agents]\n        index = np.argmax(similarities)\n        return self.agents[index], similarities[index]"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for i, e1 in enumerate(self.agents) if e1.purpose_embedding is not None]\n\n            if len(similarities) == 0:\n                return None, -np.inf\n\n            best_similarity = max(similarities)\n            best_agent = self.agents[similarities.index(best_similarity)]\n\n            return best_agent, best_similarity\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity: {e}\")\n            raise ValueError(f\"Error calculating similarity: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [e])\n                            for e in [a.purpose_embedding for a in self.agents]]\n            return self.agents[similarities.index(max(similarities))], max(similarities)\n        except ValueError:\n            return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error calculating agent similarity: {e}\")\n            raise ValueError(f\"Error calculating agent similarity: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) < 1:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [a.purpose_embedding])[0][0] for a in self.agents]\n            if len(similarities) < 1:\n                return None, -np.inf\n\n            return self.agents[np.argmax(similarities)], similarities[np.argmax(similarities)]\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity: {e}\")\n            raise ValueError(f\"Error calculating similarity: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n            best_agent = max(self.agents, key=lambda x: similarities)\n            return best_agent, similarities\n        except Exception as e:\n            logger.exception(f\"Error finding agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [a.purpose_embedding])[0][0] for a in self.agents]\n        except Exception as e:\n            logger.exception(f\"Error calculating cosine similarity: {e}\")\n            raise ValueError(f\"Error calculating cosine similarity: {e}\")\n\n        return (\n            max(self.agents, key=lambda x: similarities[self.agents.index(x)]),\n            similarities[similarities.index(max(similarities))\n        )"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [a.purpose_embedding])[0][0]\n                for a in self.agents]\n            i = np.argmax(similarities)\n            if similarities[i] < self.calculate_similarity_threshold():\n                return None, -np.inf\n\n            return self.agents[i], similarities[i]\n        except Exception as e:\n            logger.exception(f\"Error calculating similarity: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not purpose_embedding.shape == (128,):\n                raise ValueError(\"Embedding must have shape (128,)\")\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n            if similarities is None or similarities < 0:\n                return None, -np.inf\n\n            return max(self.agents, key=lambda agent: similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(MicroAgent(\n            openai_wrapper=self.openai_wrapper,\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified_flag=True\n        ))\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the prime agent\n        prime_agent = MicroAgent(PRIME_PROMPT, PRIME_NAME, PRIME_AGENT_WEIGHT, PRIME_AGENT_FLAG, PRIME_FLAG_2)\n\n        # Add the prime agent to the agent list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            openai_wrapper=self.openai_wrapper,\n            is_prime=True,\n            is_unspecified=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_new=False,\n        )\n        self.agents.append(prime_agent)\n        self.agent_persistence.add_agent(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the prime agent\n        prime_agent = MicroAgent(\n            self.openai_wrapper,\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime_agent=True,\n            unspecified_flag=True,\n            agent_persistence=self.agent_persistence,\n            max_tokens=100,\n            max_length=200\n        )\n\n        # Add the prime agent to the agent list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            openai_wrapper=self.openai_wrapper,\n            is_prime=True,\n            is_default=True\n        )\n\n        self.agents.append(prime_agent)\n\n        self.agent_persistence.add_agent(agent=prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the prime agent.\n        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            openai_wrapper=self.openai_wrapper,\n            is_prime=True,\n            is_unspecified=True\n        )\n\n        # Add the prime agent to the agent list.\n        self.agents.append(prime_agent)\n        logger.info(\"Created prime agent\")\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(MicroAgent(\n            self.openai_wrapper,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            name_flag=True,\n            prime_flag=True\n        ))\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the agent\n        agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True\n        )\n\n        # Add the agent to the agent list\n        self.agents.append(agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(MicroAgent(\n            self.openai_wrapper,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            True,\n            True,\n        ))\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_prime_agent=True\n        )\n        self.agents.append(agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        agent = MicroAgent(\n            openai_wrapper=self.openai_wrapper,\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified_flag=False,\n        )\n\n        self.agents.append(agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                self.openai_wrapper,\n                PRIME_PROMPT,\n                PRIME_NAME,\n                PRIME_AGENT_WEIGHT,\n                is_prime=True,\n                is_unspecified=True\n            )\n        )\n\n        logger.info(\n            \"Created prime agent with the following attributes: \"\n            f\"name: {PRIME_NAME}, \"\n            f\"prompt: {PRIME_PROMPT}, \"\n            f\"weight: {PRIME_AGENT_WEIGHT}, \"\n            f\"is_prime: {True}, \"\n            f\"is_unspecified: {True}\"\n        )\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        \n        agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime_agent=True,\n            unspecified_flag=True,\n            openai_wrapper=self.openai_wrapper\n        )\n        self.agents.append(agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the prime agent\n        prime_agent = MicroAgent(\n            name = PRIME_NAME,\n            prompt = PRIME_PROMPT,\n            weight = PRIME_AGENT_WEIGHT,\n            prime = True,\n            unspecified_flag = True,\n            openai_wrapper = self.openai_wrapper\n        )\n        # Add the prime agent to the agent list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            PRIME_PROMPT, PRIME_NAME, PRIME_AGENT_WEIGHT, self.agent_persistence, self.openai_wrapper\n        )\n\n        # set the agent as prime\n        prime_agent.is_prime = True\n\n        # add the agent to the agent list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_active=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create a new agent with the prime prompt and weight\n        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            openai_wrapper=self.openai_wrapper,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(MicroAgent(\n            self.openai_wrapper,\n            PROMPT_ENGINEERING_SYSTEM_PROMPT,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_prime_agent=True))\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the agent\n        prime_agent = MicroAgent(\n            openai_wrapper=self.openai_wrapper,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_unspecified=True\n        )\n        self.agents.append(prime_agent)\n        \n        # Initialize the agent with a prompt\n        prime_agent.initialize_agent(\n            PRIME_PROMPT, PRIME_NAME, EXAMPLES\n        )\n        logger.info(f\"Prime agent {PRIME_NAME} created.\")\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose):\n        serialized_agent = self.persistence.get_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent_by_purpose(self, purpose):\n        return self.persistence.load_agent_by_purpose(purpose)\n\n    def load_all_agents(self):\n        return self.persistence.load_all_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent_with_purpose(self, purpose):\n        serialized_agent = self.persistence.get_agent_with_purpose(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        agent_serializer = self.persistence.get_agent(purpose)\n        if agent_serializer is None:\n            return None\n        return AgentSerializer.deserialize(agent_serializer, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        agent = self.persistence.get_agent(purpose)\n        if agent is not None:\n            return AgentSerializer.deserialize(agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(\"persistence.get_agent\")\n    def get_agent_by_purpose(self, purpose):\n        serialized_agent = self.persistence.get_agent(purpose)\n        return AgentSerializer.deserialize(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent_from_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        agent = self.persistence.load_agent_from_purpose(purpose)\n        if agent is None:\n            return None\n\n        agent = AgentSerializer.deserialize(agent, agent_lifecycle, openai_wrapper)\n\n        return agent"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(1000)\n    def load_agent(self, purpose):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            agent = AgentSerializer.deserialize(serialized_agent)\n            return agent\n\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        agent = self.persistence.load_agent(purpose)\n        if agent is not None:\n            return AgentSerializer.deserialize(agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None\n\n    def save_prime_agent(self, agent):\n        \"\"\"\n        Serialize and save the agent state if it is a prime agent.\n        \"\"\"\n        if agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n\n    def load_prime_agent(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads a prime agent from the database. If a prime agent is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n\n        agent = self.persistence.load_prime_agent()\n        if"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent_by_purpose(purpose)\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n    def load_all_agents(self magis_agent_lifecycle, magis_openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents()\n        return magi.AgentSerializer.deserialize_all(serialized_agents, magis_agent_lifecycle, magis_openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent_by_purpose(self, purpose):\n        serialized_agent = self.persistence.load_agent_by_purpose(purpose)\n        if serialized_agent is None:\n            return None\n        agent = AgentSerializer.deserialize(serialized_agent)\n        return agent\n\n    def load_agent_by_id(self, agent_id):\n        serialized_agent = self.persistence.load_agent_by_id(agent_id)\n        if serialized_agent is None:\n            return None\n        agent = AgentSerializer.deserialize(serialized_agent)\n        return agent\n\n    def load_all_agents(self):\n        serialized_agents = self.persistence.load_all_agents()\n        return [AgentSerializer.deserialize(agent) for agent in serialized_agents]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: A list of deserialized agents.\n        \"\"\"\n        serialized_agents = self.persistence.load_all_agents()\n        return [AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper) for serialized_agent in serialized_agents]"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent_with_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        return self.load_agent(self.persistence.get_agent_by_purpose(purpose), agent_lifecycle, openai_wrapper)\n\n    @memoize_to_sqlite\n    def load_agent(self, serialized_agent, agent_lifecycle, openai_wrapper):\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(sqlite_file_name=\"agents.db\")\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        try:\n            agent = AgentSerializer.deserialize(self.persistence.load_agent(purpose), agent_lifecycle, openai_wrapper)\n            return agent\n        except:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent_from_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n    \"\"\"\n    Loads an agent with a specified id from the database. If an agent with the given id is found, it is deserialized and returned; otherwise, None is returned.\n\n    Input-Output Arguments\n    :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n    :param id: str, The id of the agent to be loaded. It is used to identify the agent in the database.\n    :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to intitlize the agent.\n    :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n    :return: An instance of the deserialized agent if found, otherwise None.\n    \"\"\"\n\n    @memoize_to_sqlite\n    def load_agent_from_id(self, id, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent_by_id(id)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent_with_purpose(self, purpose):\n        return self.persistence.load_agent_with_purpose(purpose)\n\n    def load_all_agents(self):\n        return self.persistence.load_all_agents()\n\n    def load_all_prime_agents(self):\n        return self.persistence.load_all_prime_agents()\n\n    def remove_all_agents(self):\n        self.persistence.remove_all_agents()\n\n    def load_agent_with_id(self, agent_id):\n        return self.persistence.load_agent_with_id(agent_id)\n\n    def save_all(self):\n        self.persistence.save_all()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent_by_purpose(self, purpose):\n        serialized_agent = self.persistence.get_agent_by_purpose(purpose)\n        return AgentSerializer.deserialize(serialized_agent) if serialized_agent is not None else None\n\n    @memoize_to_sqlite(self, \"get_agent_by_purpose\", \"purpose\", \"serialized_agent\")\n    def get_agent_by_purpose(self, purpose):\n        return self.load_agent_by_purpose(purpose)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent is None:\n            return\n\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n\n    def save_all_agents(self rechash):\n        for agent in rechash:\n            self.save_agent(agent)\n\n    def load_all_agents(self, rechash, agent_lifecycle, openai_wrapper):\n        for agent in rechash:\n            self.load_agent(agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def get_agent_by_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.get_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n    def get_all_agents(self):\n        \"\"\"\n        Returns a dictionary of all the agents in the database, indexed by their purposes.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :return: A dictionary of all the agents in the database, indexed by their purposes.\n        \"\"\"\n        return self.persistence.get_all_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose):\n        serialized_agent = self.persistence.get_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent)\n        else:\n            return None\n\n    def list_agents(self):\n        \"\"\"\n        List all the agents in the database.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :return: A list of the agents in the database.\n        \"\"\"\n        return self.persistence.list_agents()\n\n    def create_agent(self, agent):\n        \"\"\"\n        Create an agent in the database.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent: An instance of the Agent class.\n        \"\"\"\n        serialized_agent = AgentSerializer.serialize(agent)\n        self.persistence.create_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent is not None:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def get_all_agents(self):\n        \"\"\"\n        Returns a list of all the agents in the database.\n        \"\"\"\n        return self.persistence.get_all_agents()\n\n    def get_agent_purposes(self):\n        \"\"\"\n        Returns a list of all the purposes of agents in the database.\n        \"\"\"\n        return self.persistence.get_agent_purposes()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def fetch_all_agents(self patroon_db):\n        \"\"\"\n        Fetches all agents from the patroon database.\n        \"\"\"\n        return patroon_db.execute(\"SELECT * FROM patroon_agents\").fetchall()"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Failed to save agent {agent.name}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error while saving agent {agent.name} ({agent.id})\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error while saving agent {agent.id}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {agent.name}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Failed to save agent {agent.name}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(\n                \"Exception when saving agent. \"\n                f\"Agent: {agent.prompt}, \"\n                f\"Error: {e}\"\n            )\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Failed to save agent: {agent}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"An error occurred while saving agent {agent.id}.\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.name} ({agent.id}).\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error while saving agent {agent.name}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error while saving agent {agent.id}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {agent.prompt}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Failed to save agent {agent.name} to disk.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.prompt} to the persistence manager.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Failed to save agent: {agent}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\n                \"An error occured while trying to save the agent. The error is: {}.\".format(e)\n            )\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Failed to save agent {agent.name}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {agent.name}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(e)\n            raise e\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.agent_lifecycle.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.agent_lifecycle.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.agent_lifecycle.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.agent_lifecycle.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.agent_lifecycle.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n    "}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt\n        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal} {PROMPT_ENGINEERING_TEMPLATE} {sample_input}\"\n\n        # Attempt to get a chat completion from the OpenAI wrapper\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt, EXAMPLES)\n        except Exception as e:\n            logger.exception(f\"Error in getting chat completion: {e}\")\n            return \"\"\n        \n        # Return the generated prompt\n        return completion"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        if goal == \"Bootstrap Agent\":\n            return PRIME_PROMPT\n\n        if goal == \"Prime Agent\":\n            return f\"{PRIME_PROMPT} {sample_input}\"\n\n        if goal == \"Engineering System\":\n            return f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {sample_input}\"\n\n        if goal == \"Engineering Template\":\n            return f\"{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\"\n\n        return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        if goal == \"Bootstrap Agent\":\n            return PRIME_PROMPT\n\n        try:\n            return self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT, \n                PROMPT_ENGINEERING_TEMPLATE, \n                goal, \n                sample_input, \n                EXAMPLES\n            )\n        except Exception:\n            logger.exception(\"Error in generating LLM prompt.\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt for the LLM\n        prompt = PRIME_PROMPT + goal + PROMPT_ENGINEERING_SYSTEM_PROMPT + sample_input + PROMPT_ENGINEERING_TEMPLATE\n\n        # Attempt to get a chat completion from the OpenAI wrapper\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt, EXAMPLES)\n\n        # Log the exception and return an empty string if an error occurs\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n\n        # Return the generated prompt\n        return completion"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = self.prime_agent.get_prompt(goal, sample_input)\n        try:\n            completion = self.openai_wrapper.get_completion(prompt, self.prime_agent.model)\n        except Exception:\n            logger.exception(f\"Error in generating prompt: {prompt}\")\n            return \"\"\n        \n        return prompt + completion"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            if goal == \"Bootstrap Agent\":\n                return PRIME_PROMPT\n\n            elif goal == \"Engineering System\":\n                return PROMPT_ENGINEERING_SYSTEM_PROMPT\n\n            elif goal == \"Engineering Template\":\n                return PROMPT_ENGINEERING_TEMPLATE\n\n            else:\n                return self.openai_wrapper.get_completion(\n                    goal, \n                    self.get_available_agents_for_agent(self.prime_agent),\n                    sample_input, \n                    EXAMPLES\n                )\n\n        except Exception as e:\n            logger.exception(f\"Error in generating LLMs prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        if len(sample_input) == 0:\n            sample_input = EXAMPLES\n\n        llm_prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {PRIME_PROMPT} {sample_input} {PROMPT_ENGINEERING_TEMPLATE} {goal}\"\n        try:\n            return self.openai_wrapper.get_chat_completion(llm_prompt)\n        except Exception as e:\n            logger.exception(f\"Error in getting LLM chat completion for goal: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt\n        prompt = self.openai_wrapper.generate_prompt(\n            PRIME_PROMPT, PRIME_NAME, goal, \n            PROMPT_ENGINEERING_SYSTEM_PROMPT,\n            PROMPT_ENGINEERING_TEMPLATE,\n            EXAMPLES,\n            sample_input\n        )\n\n        # Get the completion from the OpenAI wrapper\n        completion = self.openai_wrapper.get_completion(prompt)\n        if completion is not None:\n            # Return the completion as the prompt\n            return completion\n        else:\n            # Return an empty string if an error occurs\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt\n        prompt = self._generate_prompt(goal, sample_input)\n        \n        # Attempt to get a completion from the LLM\n        try:\n            completion = self.openai_wrapper.get_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n\n        # Return the completion\n        return completion\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate a prompt based on the goal and sample input\n        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT}{goal}{PROMPT_ENGINEERING_TEMPLATE}\"\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt, EXAMPLES)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt for {goal}: {e}\")\n            return \"\"\n        \n        # Remove the first line of the completion, which is the example\n        completion = completion[1:]\n\n        return completion"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt for the LLM\n        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n\n        # Attempt to get a chat completion from the OpenAI wrapper\n        try:\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt, EXAMPLES, 4)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt for LLM: {e}\")\n            return \"\"\n\n        # Remove the first line of the chat completion and return the remaining text\n        return PROMPT_ENGINEERING_TEMPLATE.format(chat_completion[1:])"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PRIME_PROMPT\n        prompt += PRIME_NAME + \" \" + goal + \" \" + EXAMPLES\n        prompt += \"\\n\" + sample_input + \"\\n\"\n        prompt += PROMPT_ENGINEERING_TEMPLATE\n        prompt += PROMPT_ENGINEERING_SYSTEM_PROMPT\n\n        try:\n            completion = self.openai_wrapper.get_completion(prompt)\n            if completion.get(\"error\", None):\n                logger.error(completion[\"error\"])\n            else:\n                prompt += completion[\"choices\"][0][\"text\"]\n        except Exception as e:\n            logger.exception(f\"Error in generating LLMs prompt: {e}\")\n            return \"\"\n\n        return prompt"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt\n        prompt = f\"Given the following prompt: {PRIME_PROMPT} {PRIME_NAME} {goal} {sample_input}\\n\\n\"\n        prompt += PROMPT_ENGINEERING_SYSTEM_PROMPT\n        prompt += \"\\n\\n\"\n        prompt += EXAMPLES\n        prompt += \"\\n\\n\"\n\n        # Get a completion from the LLM\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n\n\n        # If the completion is empty, return an empty string\n        if not completion:\n            return \"\"\n\n        # Return the completion\n        return completion"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PRIME_PROMPT + goal + PROMPT_ENGINEERING_SYSTEM_PROMPT + sample_input + EXAMPLES\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLMs prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt for the LLM\n        prompt = f\"Generate a prompt for a new agent with the goal: {goal}.\\n\\n\"\n        prompt += f\"Example: {sample_input}\"\n\n        # Attempt to get a chat completion from the OpenAI wrapper\n        try:\n            completion = self.openai_wrapper.get_completion(prompt,\n                                                           temperature=0.0,\n                                                           max_tokens=1024,\n                                                           top_p=1.0,\n                                                           top_k=1)\n        except Exception as e:\n            # Log the error if an exception is raised\n            logger.exception(f\"Error in getting completion: {e}\")\n            # Return an empty string if an error occurs\n            return \"\"\n\n        # Return the generated prompt\n        return completion.text"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt\n        llm_prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            goal, sample_input, EXAMPLES\n        )\n\n        # Generate the template\n        template = PROMPT_ENGINEERING_TEMPLATE.format(PRIME_PROMPT)\n\n        # Attempt to get a chat completion from the LLM\n        try:\n            completion = self.openai_wrapper.get_completion(\n                llm_prompt, \n                template,\n                max_tokens=1024,\n                n=1,\n                temperature=0.7\n            )\n            # If the completion is successful, return the generated prompt\n            return completion[\"choices\"][0][\"text\"]\n        except Exception as e:\n            # If an error occurs, log the exception and return an empty string\n            logger.exception(f\"Error in generating LLMs: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"A chat agent that can generate an answer to a question.\\n\\nExamples:\\n\\n\"\n        for example in EXAMPLES:\n            prompt += f\"{example}\\n\\n\"\n        prompt += f\"Question: {sample_input}\\n\\nGoal: {goal}\"\n        try:\n            completion = self.openai_wrapper.get_completion(PROMPT_ENGINEERING_SYSTEM_PROMPT, prompt, 4, 4096, 0.9, \"text-davinci-002\", 2)\n            return completion.get(\"choices\")[0][\"text\"].split(\"\\n\")[-1]\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt\n        llm_prompt = (\n            f\"Generate a prompt for a language learning model to learn to generate {goal}.\\n\"\n            f\"The prompt should be used to generate a {PROMPT_ENGINEERING_TEMPLATE}.\\n\"\n        )\n\n        # Add the examples\n        for example in EXAMPLES:\n            llm_prompt += f\"\\n{example}\"\n\n        # Add the sample input\n        llm_prompt += f\"\\n\\nPrompt: {sample_input}\"\n\n        # Generate the prompt from the LLM\n        try:\n            chat_completion = self.openai_wrapper.get_completion(llm_prompt, temperature=0.5, top_p=1.0)\n            if chat_completion == \"\":\n                # If the LLM did not generate a prompt, log the error and return an empty string\n                logger.error(\"The LLM did not generate a prompt for the given goal and sample input.\")\n                return \"\"\n            else:\n                # If the LLM generated a prompt, return the prompt\n                return chat_completion\n        except Exception as e:\n            # If an error occurred during the process, log the exception and return an empty string\n            logger.exception(f\"Error in generating prompt for LLM: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        if len(self.agents) == 0:\n            return \"\"\n\n        # Create a list of all the prompts for the LLM\n        prompts = []\n        for agent in self.agents:\n            if agent.working_agent:\n                prompts.append(agent.prompt)\n        \n        # Generate the prompt\n        prompt = PRIME_PROMPT + \" \" + goal + \" \" + sample_input + \"\\n\\n\" + \" | \".join(prompts)\n\n        # Get a completion from the LLM\n        completion = self.openai_wrapper.get_completion(prompt, temperature=0.4, max_tokens=1024)\n\n        # Return the prompt\n        if completion.get(\"error\"):\n            logger.error(f\"Error in generating prompt: {completion.get('error')}\")\n            return \"\"\n\n        return completion.get(\"choices\")[0].get(\"text\")\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PRIME_PROMPT + \\\n            f\"The goal is {goal}.\\n\" + \\\n            f\"I'm a {PRIME_NAME} who is trying to learn more about {goal}.\"\n\n        # Add the sample input to the prompt if it is not empty\n        if sample_input is not None:\n            prompt += f\"\\n\\nI' mozaic-agent: {sample_input}\"\n\n        try:\n            response = self.openai_wrapper.get_completion(PROMPT_ENGINEERING_SYSTEM_PROMPT, prompt, \n                max_tokens=PROMPT_ENGINEERING_TEMPLATE.get_max_tokens(), \n                top_p=PROMPT_ENGINEERING_TEMPLATE.get_top_p(),\n                top_k=PROMPT_ENGINEERING_TEMPLATE.get_top_k(),\n                temperature=PROMPT_ENGINEERING_TEMPLATE.get_temperature(),\n                n=PROMPT_ENGINEERING_TEMPLATE.get_n(),\n                stop_on_new_line=PROMPT_ENGINEERING_TEMPLATE.get_stop_on_new_line(),\n                n_best=PROMPT_ENGINEERING_TEMPLATE.get_n_best(),\n                best_of=PROMPT_ENGINEERING_TEMPLATE.get_best_of(),\n                max_new_tokens=PROMPT_ENGINEERING_TEMPLATE.get_max_new_tokens(),\n                max_length=PROMPT_ENGINEERING_TEMPLATE.get_max_length(),\n                no_repeat_penalty=PROMPT_ENGINEERING_TEMPLATE.get_no_repeat_penalty(),\n                presence_penalty=PROMPT_ENGINEERING_TEMPLATE.get_presence_penalty(),\n                frequency_penalty=PROMPT_ENGINEERING_TEMPLATE.get_frequency_penalty(),\n                logprobs=PROMPT_ENGINEERING_TEMPLATE.get_logprobs(),\n                model_id=PROMPT_ENGINEERING_TEMPLATE.get_model_id(),\n                logprobs_only=PROMPT_ENGINEERING_TEMPLATE.get_logprobs_only(),\n            )\n            prompt = response[\"choices\"][0][\"text\"].strip()\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt for {goal}: {e}\")\n            prompt = \"\"\n        \n        return prompt\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                         (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n            conn.commit()"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES(?, ?, ?)\",\n                         (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            # serialize the agent data\n            agent_data = json.dumps(agent_dict)\n\n            # create a pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES(?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES(?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?,?,?)\",\n                         (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?,?,?)\",\n                         (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES(?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES(?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES(?,?,?)\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict)\n            ))\n            conn.commit()\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            if cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict[\"id\"],)).fetchall():\n                cursor.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"]), agent_dict[\"id\"]))\n            else:\n                cursor.execute(\"INSERT INTO agents (id, purpose, data) VALUES(?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES(?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES(?,?,?)\",\n                         (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            try:\n                conn.execute(\"INSERT OR REPLACE INTO agents VALUES (?,?,?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n            except sqlite3. lampaDatabaseError as e:\n                print(e)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES(?,?,?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?,?,?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES ( ?, ?, ? )\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?,?,?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n            conn.commit()\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES(?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            if agent_dict[\"id\"] is None:\n                raise Exception(\"Agent ID is required.\")\n\n            # Check if the agent already exists\n            agent_id = agent_dict[\"id\"]\n            agent_purpose = agent_dict[\"purpose\"]\n            cursor = conn.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_id,))\n            if cursor.fetchone():\n                # Update the agent's data\n                conn.execute(\n                    \"UPDATE agents SET data = ? WHERE id = ?\", (json.dumps(agent_dict), agent_id)\n                )\n            else:\n                # Insert the new agent\n                conn.execute(\n                    \"INSERT INTO agents VALUES (?, ?, ?)\",\n                    (agent_id, agent_purpose, json.dumps(agent_dict)),\n                )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            data = cursor.fetchone()\n            if data is None:\n                return None\n            return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            result = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,)).fetchone()\n\n        if result:\n            return json.loads(result[0])\n        else:\n            return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            for row in cursor:\n                return json.loads(row[0])\n        return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT * FROM agents WHERE purpose = ?\", (purpose,))\n            if cursor.fetchone():\n                return json.loads(cursor.fetchone()[2])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            result = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            ).fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            data = cursor.fetchone()\n\n        if data is None:\n            return None\n        return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            result = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            ).fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            result = cursor.fetchone()\n\n            if result is not None:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[2])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            agent_data = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,)).fetchone()\n            if agent_data is not None:\n                return json.loads(agent_data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            result = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            data = result.fetchone()\n            if data:\n                return json.loads(data[0])\n        return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT * FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            if cursor.fetchone() is not None:\n                return json.loads(cursor.fetchone()[2])\n            else:\n                return None\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            agent_data = conn.execute(\"SELECT * FROM agents WHERE purpose = ?\", (purpose,))\n            for agent_dict in agent_data:\n                return json.loads(agent_dict[2])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data is not None:\n                return json.loads(data[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            query_result = conn.execute(\"SELECT * FROM agents WHERE purpose = ?\", (purpose,))\n            agent_dict = query_result.fetchone()\n\n        if agent_dict:\n            return json.loads(agent_dict[2])\n        return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            result = cursor.fetchone()\n            if result is not None:\n                return json.loads(result[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            # get the serialized agent\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is not None:\n                # deserialize the agent\n                return json.loads(result[0])\n            return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            agent_data = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose, )).fetchone()\n        if agent_data is None:\n            return None\n        return json.loads(agent_data[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\",\n                (purpose,)\n            )\n            result = cursor.fetchone()\n\n            if result is not None:\n                return json.loads(result[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            purposes = [row[0] for row in cursor.fetchall()]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            purposes = [row[0] for row in cursor.fetchall()]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            purposes = [row[0] for row in cursor]\n        return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            purposes = [x[0] for x in cursor.fetchall()]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n\n        purposes = []\n        for row in rows:\n            purposes.append(row[0])\n        return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            rows = cursor.fetchall()\n\n        purposes = []\n        for row in rows:\n            purposes.append(row[0])\n\n        return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n\n            purposes = cursor.fetchall()\n            return [row[0] for row in purposes]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            purposes = [row[0] for row in cursor.fetchall()]\n\n        return purposes\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT DISTINCT purpose FROM agents\")\n            rows = cursor.fetchall()\n\n        purposes = [row[0] for row in rows]\n        return purposes\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            purposes = cursor.fetchall()\n\n            purposes_list = []\n            for purpose in purposes:\n                purposes_list.append(purpose[0])\n\n            return purposes_list\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        with self.connection:\n            result = self.connection.execute(\n                \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n            ).fetchone()\n\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        cursor.close()\n        if result is not None:\n            return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        result = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        ).fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row is not None:\n            return json.loads(row[0])\n        else:\n            return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        return json.loads(result[0]) if result else None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        # TODO: Fix this\n        # result = self.connection.execute(\n        #     \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        # ).fetchone()\n\n        # if result is not None:\n        #     return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        else:\n            return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        return json.loads(result[0]) if result else None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n\n        if result is None:\n            return None\n        else:\n            return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        return self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        ).fetchone()\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        with self.connection:\n            cursor = self.connection.execute(\n                \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n            )\n            result = cursor.fetchone()\n            return result[0] if result else None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        # Fetch the result from the cache.\n        result = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        ).fetchone()\n\n        # If a result is found, load it from JSON format and return it.\n        if result is not None:\n            return json.loads(result[0])\n\n        # Otherwise, return None.\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        # Query the database for the cached result\n        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        cursor.close()\n\n        # If the result is not found, return None\n        if result is None:\n            return None\n\n        # If the result is found, load it from JSON format and return it\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        # Fetch the result from the database\n        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n\n        # If the result is found, load it from JSON format\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        # Query the database for the cached result\n        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n\n        # If no result is found, return None\n        if result is None:\n            return None\n\n        # Otherwise, load the result from JSON format and return it\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n\n        cursor.close()\n        return result[0] if result else None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        with self.connection:\n            result = self.connection.execute(\n                \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n            ).fetchone()\n\n            if result is None:\n                return None\n\n            return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        result = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        ).fetchone()\n        if result is None:\n            return None\n\n        # The result is fetched from the database in JSON format, so it needs to be loaded.\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (:hash, :result)\",\n            {\n                \"hash\": arg_hash,\n                \"result\": json.dumps(result),\n             fundament\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES(?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES(?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (:hash, :result)\",\n            {\n                \"hash\": arg_hash,\n                \"result\": json.dumps(result),\n            },\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT OR REPLACE INTO cache VALUES (?, ?)\", (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON.\n        result_json = json.dumps(result)\n\n        # Insert the result into the database.\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, result_json),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        with self.connection:\n            self.connection.execute(\n                \"INSERT INTO cache (hash, result) VALUES (:hash, :result)\",\n                {\n                    \"hash\": arg_hash,\n                    \"result\": json.dumps(result),\n                },\n            )"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        data = json.dumps(result)\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache VALUES(?, ?)\", (arg_hash, data)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        data = json.dumps(result)\n\n        self.connection.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES(?, ?)\",\n            (arg_hash, data),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON format\n        result_json = json.dumps(result)\n\n        # Insert the result into the database\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        data = json.dumps(result)\n        self.connection.execute(\n            \"INSERT OR REPLACE INTO cache VALUES (:hash, :result)\",\n            {\"hash\": arg_hash, \"result\": data}\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON format.\n        serialized_result = json.dumps(result)\n\n        # Insert the result into the database.\n        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, serialized_result),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n\n        # Serialize the result to JSON format.\n        result_json = json.dumps(result)\n\n        # Insert the new row into the 'cache' table.\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n\n        # Serialize the result to JSON\n        serialized_result = json.dumps(result)\n\n        # Insert the hash and serialized result into the 'cache' table\n        cursor.execute(\"INSERT INTO cache VALUES(?, ?)\", (arg_hash, serialized_result))\n\n        # Commit the changes to the database\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON\n        result = json.dumps(result)\n\n        # Create a cursor\n        cursor = self.connection.cursor()\n\n        # Insert the result into the database\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result)\n        )\n\n        # Commit the changes to the database\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON\n        result = json.dumps(result)\n\n        # Create a cursor to the database\n        cursor = self.connection.cursor()\n\n        # Insert the result into the database\n        cursor.execute(\n            \"INSERT OR REPLACE INTO cache(hash, result) VALUES(?, ?)\",\n            (arg_hash, result),\n        )\n        # Commit the changes to the database\n        self.connection.commit()\n\n        # Close the cursor\n        cursor.close()"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG\n    CONFIG = deepcopy(CONFIG)\n    CONFIG.update_from_args(args)\n\n    if quiet_mode:\n        with redirect_stdout(CONFIG.record_dir + \"/stdout.log\"):\n            execute_command_line(args)\n    else:\n        execute_command_line(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n\n    CONFIG = deepcopy(ARGS)\n    CONFIG.update(vars(args))\n\n    if not quiet_mode:\n        with redirect_stdout(f\"{CONFIG['record_dir']}/{CONFIG['task']}.txt\"):\n            # pylint: disable= ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9 ch\u00e9"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update_from_command_line(args)\n    ARGS.update_from_command_line(args)\n\n    if not quiet_mode:\n        with redirect_stdout(to_file=True, to_file_name=os.path.join(ARGS.record_dir, \"output.txt\")):\n            print(args)"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(args.__dict__)\n    if not quiet_mode:\n        with redirect_stdout(f\"{CONFIG.record_dir}/stdout.txt\"):\n            execute_command_line(args)\n    else:\n        execute_command_line(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect output to a file\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with open(os.path.join(ARGS.record_dir, 'output.txt'), 'w') as out:\n                with open(os.path.join(ARGS.record_dir, 'error.txt'), 'w') as err:\n                    with open(os.path.join(ARGS.record_dir, 'warnings.txt'), 'w') as war:\n                        redirect_stdout(out, err, war)\n\n    # Execute the command line process\n    CommandLine(args).run()"}
{"namespace": "run.execute_command_line_process", "completion": "    if not quiet_mode:\n        # Redirect the standard output to a file\n        with redirect_stdout(args.record_dir):\n            # Execute the command line process\n            command_line_process(args)\n\n    else:\n        # Execute the command line process\n        command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update configuration parameters with the provided arguments\n    update_config(args)\n\n    # Redirect output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(ARGS.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                # Run the command line process\n                CommandLine(ARGS.task, ARGS.upload_files, ARGS.model, ARGS.record_dir, ARGS.mode,\n                            ARGS.enable_ask_human_for_help,\n                            ARGS.max_subtask_chain_length, ARGS.max_plan_refine_chain_length,\n                            ARGS.max_plan_tree_depth, ARGS.max_plan_tree_width, ARGS.max_retry_times,\n                            ARGS.config_file)\n    else:\n        # Run the command line process\n        CommandLine(ARGS.task, ARGS.upload_files, ARGS.model, ARGS.record_dir, ARGS.mode,\n                    ARGS.enable_ask_human_for_help,\n                    ARGS.max_subtask_chain_length, ARGS.max_plan_refine_chain_length,\n                    ARGS.max_plan_tree_depth, ARGS.max_plan_tree_width, ARGS.max_retry_times,\n                    ARGS.config_file)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters\n    CONFIG.update_config_from_args(args)\n\n    # Execute the command line process\n    command_line = CommandLine(\n        CONFIG.task_description,\n        CONFIG.model_id,\n        CONFIG.record_dir,\n        CONFIG.mode,\n        CONFIG.upload_files,\n        CONFIG.max_subtask_chain_length,\n        CONFIG.enable_ask_human_for_help,\n        CONFIG.max_plan_refine_chain_length,\n        CONFIG.max_plan_tree_depth,\n        CONFIG.max_plan_tree_width,\n        CONFIG.max_retry_times,\n    )\n\n    with redirect_stdout(CONFIG.record_dir + '/output.txt') if quiet_mode else None:\n        command_line.run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n\n    # Update CONFIG\n    CONFIG = deepcopy(args)\n    CONFIG.update(ARGS)\n    CONFIG.update(CONFIG_FILE=args.config_file)\n    CONFIG.update(RECORD_DIR=os.path.join(CONFIG.RECORD_DIR, CONFIG.TASK_DESC))\n    CONFIG.update(MAX_SUBTASK_CHAIN_LENGTH=args.max_subtask_chain_length)\n    CONFIG.update(ENABLE_ASK_HUMAN_FOR_HELP=args.enable_ask_human_for_help)\n    CONFIG.update(MAX_PLAN_REFINE_CHAIN_LENGTH=args.max_plan_refine_chain_length)\n    CONFIG.update(MAX_PLAN_TREE_DEPTH=args.max_plan_tree_depth)\n    CONFIG.update(MAX_PLAN_TREE_WIDTH=args.max_plan_tree_width)\n    CONFIG.update(MAX_RETRY_TIMES=args.max_retry_times)\n    CONFIG.update(QUIET_MODE=quiet_mode)\n\n    # Update ARGS\n    ARGS.update(args)\n    ARGS.update(MAX_SUBTASK_CHAIN_LENGTH=args.max_subtask_chain_length)\n    ARGS.update(ENABLE_ASK_HUMAN_FOR_HELP=args.enable_ask_human_for_help)\n    ARGS.update(MAX_PLAN_REFINE_CHAIN_LENGTH=args.max_plan_refine_chain_length)\n    ARGS.update(MAX_PLAN_TREE_DEPTH=args.max_plan_tree_depth)\n    ARGS.update(MAX_PLAN_TREE_WIDTH=args.max_plan_tree_width)\n    ARGS.update(MAX_RETRY_TIMES=args.max_retry_times)\n    ARGS.update(QUIET_MODE=quiet_mode)\n\n    # Execute the command line process\n    CommandLine.execute_command_line_process(CONFIG, ARGS)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments.\n    CONFIG.update(args.__dict__)\n    ARGS.update(args.__dict__)\n\n    # If quiet mode is enabled, redirect standard output to a file.\n    if quiet_mode:\n        with redirect_stdout(CONFIG.log_file):\n            run_command_line_process(args)\n    else:\n        run_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update_from_namespace(args)\n\n    if not quiet_mode:\n        with redirect_stdout(open(os.path.join(CONFIG.record_dir, \"output.log\"), 'w')) as sout:\n            command_line_process(args)\n            return\n\n    command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(args.__dict__)\n    if quiet_mode:\n        with redirect_stdout(file=open(os.path.join(CONFIG.record_dir, \"stdout.txt\"), mode='w')):\n            execute_command_line_process(args, False)\n    else:\n        execute_command_line(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update config parameters with the provided arguments\n    CONFIG.update_from_args(args)\n    CONFIG.enable_ask_human_for_help = args.enable_ask_human_for_help\n    CONFIG.max_subtask_chain_length = args.max_subtask_chain_length\n    CONFIG.max_plan_refine_chain_length = args.max_plan_refine_chain_length\n    CONFIG.max_plan_tree_depth = args.max_plan_tree_depth\n    CONFIG.max_plan_tree_width = args.max_plan_tree_width\n    CONFIG.max_retry_times = args.max_retry_times\n\n    # Update the config file\n    CONFIG.config_file = args.config_file\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with redirect_stdout(os.path. mozaic_config.config_file_path):\n            # Execute the command line\n            CommandLine().execute()\n    else:\n        # Execute the command line\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration with the provided arguments\n    CONFIG.update_config(args)\n\n    # Execute the command line process\n    if quiet_mode:\n        with open(os.path.join(ARGS.record_dir, \"out.txt\"), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).execute_command_line_process()\n    else:\n        CommandLine(args).execute_command_line_process()\n\n    return\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    # Note: We use copy.deepcopy() to avoid modifying the original config file.\n    CONFIG = deepcopy(args)\n\n    # If the user has enabled the quiet mode, then redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, \"output.log\"), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CONFIG).execute()\n\n    # If the user intitated the process in non-quiet mode, then execute the command line.\n    else:\n        CommandLine(CONFIG).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Updating configuration parameters with the provided arguments\n    for k, v in vars(args).items():\n        if k in ARGS:\n            ARGS[k] = v\n        elif k in CONFIG:\n            CONFIG[k] = v\n\n    # Checking if the user wants to run in quiet mode\n    if quiet_mode:\n        with open(os.path.join(CONFIG['log_dir'], \"output.log\"), 'a') as f:\n            with redirect_stdout(f):\n                # Running the command line\n                command_line = CommandLine(args)\n                command_line.run_command_line()\n    else:\n        # Running the command line\n        command_line = CommandLine(args)\n        command_line.run_command_line()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global config parameters\n    CONFIG.update_config_from_args(args)\n\n    # Set up logging\n    if not quiet_mode:\n        # Enable logging\n        from XAgent.logger import setup_logger\n        setup_logger(args.record_dir)\n\n    # Execute the command line process\n    command_line = CommandLine(args)\n    command_line.execute()\n\n    # If we are in quiet mode, redirect the output of the command line process to the log file\n    if quiet_mode:\n        with redirect_stdout(os.path.join(args.record_dir, 'command_line_output.log')) as stdout_stream:\n            command_line.execute()\n\n    # Print the command line output\n    command_line.print_output()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments.\n    for key, value in vars(args).items():\n        CONFIG[key] = value\n\n    # Redirect the standard output to a file if quiet mode is enabled.\n    if quiet_mode:\n        with open(f'{CONFIG[\"record_dir\"]}/{CONFIG[\"task\"]}.log', 'w') as f:\n            with redirect_stdout(f):\n                run_command_line(quiet_mode)\n\n    # Otherwise, run the command line process in normal mode.\n    else:\n        run_command_line()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    CONFIG.update(args)\n    if CONFIG.config_file is not None:\n        CONFIG.update_from_file(CONFIG.config_file)\n\n    if CONFIG.mode == \"auto\" or CONFIG.mode == \"manual\":\n        if quiet_mode:\n            with open(CONFIG.record_dir + \"/stdout.txt\", 'w') as f:\n                with open(CONFIG.record_dir + \"/stderr.txt\", 'w') as f2:\n                    with redirect_stdout(f, f2):\n                        CommandLine.execute(CONFIG.task, CONFIG.model, CONFIG.upload_files, CONFIG.mode)\n        else:\n            CommandLine.execute(CONFIG.task, CONFIG.model, CONFIG.upload_files, CONFIG.mode)\n    elif CONFIG.mode == \"debug\":\n        CommandLine.execute(CONFIG.task, CONFIG.model, CONFIG.upload_files, CONFIG.mode, CONFIG.max_subtask_chain_length, CONFIG.enable_ask_human_for_help,\n                            CONFIG.max_plan_refine_chain_length, CONFIG.max_plan_tree_depth, CONFIG.max_plan_tree_width,\n                            CONFIG.max_retry_times)\n    else:\n        raise ValueError(f\"Invalid mode {CONFIG.mode}. Supported modes are: 'auto', 'manual', and 'debug'\")\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # update global configuration parameters\n    for k, v in vars(args).items():\n        setattr(ARGS, k, v)\n\n    # update configuration file with the provided arguments\n    if args.config_file:\n        with open(args.config_file, \"r\") as f:\n            config = CONFIG.load(f) encrease_config(config, args)\n    else:\n        config = encrease_config(deepcopy(CONFIG), args)\n\n    # redirect output to a file if needed\n    if quiet_mode:\n        with redirect_stdout(args.record_dir + \"stdout.txt\"):\n            command_line = CommandLine(config)\n            command_line.execute_task()\n    else:\n        command_line = CommandLine(config)\n        command_line.execute_task()\n\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\n                    \"maximum context length exceeded\", None\n                )\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        chatcompletion_kwargs.update(kwargs)\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.Completion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n        "}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        model_name = get_model_name(model_name)\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs[\"api_base\"] = api_base\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.Completion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n        except BadRequestError as e:\n            if \"maximum"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\")\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.args[0]:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.Completion.create(**chatcompletion_kwargs)\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs, **kwargs)\n\n        except BadRequestError as e:\n            if \"maximum context length\" in e.args[0]:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            else:\n                raise e\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\n                    \"max context length reached, retrying with \" + model_name\n                )\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.args[0]:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\n                    \"maximum context length exceeded\", None\n                )\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n\n                print(\n                    \"max context length reached, retrying with \" + model_name\n                )\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise BadRequestError(\n                    \"maximum context length exceeded, but no fallback models available\",\n                    None,\n                )\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        logger.debug(\"chatcompletion: using \" + model_name)\n\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n\n        chatcompletion_kwargs.update(kwargs)\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise BadRequestError(\n                    \"maximum context length exceeded\", None\n                )\n\n            print(\"max context length reached, retrying with \" + model_name)\n\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        logger.debug(\"chatcompletion: using \" + model_name)\n\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs[\"api_base\"] = api_base\n\n        chatcompletion_kwargs.update(kwargs)\n        response = openai.Completion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise BadRequestError(\n                    \"maximum context length reached and no fallback models available\"\n                )\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        model_name = get_model_name(model_name)\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if \"message\" in response and \"error\" in response[\"message\"]:\n                if \"maximum context length\" in response[\"message\"][\"error\"]:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise BadRequestError(\n                            \"maximum context length exceeded, no fallback models available\"\n                        )\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs[\"api_base\"] = api_base\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(response)\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\n                    \"maximum context length exceeded\", None, None, \"chatcompletion\"\n                )\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response ="}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.get(\"model\", CONFIG.default_completion_kwargs.get(\"model\")))\n\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        chatcompletion_kwargs.update(kwargs)\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n\n        except BadRequestError as e:\n            if \"maximum context length\" in e.args[0]:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n\n                print(f\"max context length reached, retrying with {model_name}\")\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            else:\n                raise e\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        chatcompletion_kwargs.update(kwargs)\n\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise BadRequestError(\n                    \"maximum context length reached, \"\n                    + \"but no fallback models available\"\n                )\n\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"openai-davinci\":\n                    if \"davinci-003\" in CONFIG.api_keys:\n                        model_name = \"davinci-003\"\n                    elif \"davinci-instruct-beta\" in CONFIG.api_keys:\n                        model_name = \"davinci-instruct-beta\"\n                    else:\n                        model_name = \"curie-instruct-beta\"\n                elif model_name == \"curie-instruct\":\n                    if \"curie-instruct-beta\" in CONFIG.api_keys:\n                        model_name = \"curie-instruct-beta\"\n                    else:\n                        model_name = \"curie-instruct-002\"\n                elif model_name == \"curie\":\n                    if \"curie-instruct-beta\" in CONFIG.api_keys:\n                        model_name = \"curie-instruct-beta\"\n                    elif \"curie-002\" in CONFIG.api_keys:\n                        model_name = \"curie-002\"\n                    else:\n                        model_name = \"ada-instruct-beta\"\n                elif model_name == \"ada-instruct\":\n                    if \"ada-instruct-beta"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(response.json)\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\n                    \"maximum context length exceeded\", None\n                )\n        except BadRequestError as e:\n            if \"maximum context length\" in e.args[0]:\n                if model_name == \"openai-gpt-3-3b\":\n                    if \"openai-gpt-3-11b\" in CONFIG.api_keys:\n                        model_name = \"openai-gpt-3-11b\"\n                    else:\n                        model_name = \"openai-gpt-3-16b\"\n                elif model_name == \"openai-gpt-3-16b\":\n                    if \"openai-gpt-3-11b\" in CONFIG.api_keys:\n                        model_name = \"openai-gpt-3-11b\"\n                    else:\n                        model_name = \"openai-gpt-3-3b\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.Completion.create(**chatcompletion_kwargs)\n                response = json.loads(response.json)\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"]))\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        response = openai.api_request(\n            \"chat\",\n            \"post\",\n            \"/chat/v1/chat\",\n            chatcompletion_kwargs,\n        )\n        response = json.loads(response)\n        if response[\"error\"][\"message\"] == \"Maximum context length exceeded\":\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise BadRequestError(\"maximum context length exceeded\", None)\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.api_request(\n                \"chat\",\n                \"post\",\n                \"/chat/v1/chat\","}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if \"choices\" not in response:\n                raise BadRequestError(\n                    \"response does not have 'choices' key\",\n                    \"choices\" in response,\n                )\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\n                    \"maximum context length exceeded\",\n                    \"maximum context length exceeded\",\n                )\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        "}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n\n        if self._last_time is None or time() > self._last_time + self._refetch_interval:\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._last_time is None or self._last_time < time() - self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n            self._last_time = time()\n\n        if time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None:\n            self._create_client()\n            self._last_time = time()\n        else:\n            if time() > self._last_time + self._refetch_interval:\n                self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n\n        if self._last_time is None or time() - self._last_time >= self._refetch_interval:\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n        elif self._last_time is not None and time() - self._last_time > self._refetch_interval:\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._last_time is None:\n            self._create_client()\n\n        elif time() - self._last_time >= self._refetch_interval:\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._is_expired():\n            self._create_client()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n        elif self._last_time is not None and time() - self._last_time > self._refetch_interval:\n            self._create_client()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None:\n            self._create_client()\n            self._last_time = time()\n        elif self._last_time < time() - self._refetch_interval:\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._is_expired():\n            self._create_client()\n\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._last_time is None or self._client is None or (\n            self._last_time is not None and self._client is not None and time() - self._last_time > self._refetch_interval\n        ):\n            self._create_client()\n        self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n\n        if self._last_time is None:\n            self._last_time = time()\n\n        if self._last_time < time() - self._refetch_interval:\n            self._create_client()\n\n        return self._client\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method can only be called from the main process, \"\n                \"not from a DataLoader worker process.\"\n            )\n\n        if self.shuffler is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n\n        if self.num_chunks is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n            chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n                self.distributed_env, self.current_epoch\n            )\n            chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n            intervals_replica = intervals_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n            self.worker_chunks = []\n            self.worker_intervals = []\n            for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n                if i % self.worker_env.world_size != self.worker_env.rank:\n                    continue\n                self.worker_chunks.append(chunk_index)\n                self.worker_intervals.append(chunk_interval)\n            self.num_chunks = len(self.worker_chunks)\n\n        state = {\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"url\": self.input_dir.url,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please use the `get_state_dict` method instead.\"\n            )\n\n        if self.distributed_env.world_size > 1:\n            raise ValueError(\n                \"The `state_dict` method should not be called in a distributed environment. \"\n                \"Please use the `get_state_dict` method instead.\"\n            )\n\n        state = {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n            \"has_triggered_download\": self.has_triggered_download,\n            \"last_time\": self.last_time,\n        }\n        if self.worker_env is not None:\n            state[\"worker_env\"] = self.worker_env\n        if self.cache is not None:\n            state[\"cache\"] = self.cache.state_dict()\n        if self.shuffler is not None:\n            state[\"shuffler\"] = self.shuffler.state_dict()\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"You cannot call the `state_dict` method from a data loader worker process. \"\n                \"You should call it from the main process instead.\"\n            )\n\n        if self.shuffler is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state = {\n            \"num_workers\": num_workers,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env,\n            \"shuffle\": self.shuffle,\n        }\n        if self.item_loader is not None:\n            state[\"item_loader_state\"] = self.item_loader.state_dict()\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"The state_dict() method should be called from the main process.\")\n\n        if self.random_state is None:\n            self.random_state = self.shuffler.random_state\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"world_size\": self.distributed_env.world_size,\n            \"random_state\": self.random_state,\n        }\n\n        if self.item_loader is not None:\n            state[\"item_loader\"] = self.item_loader.state_dict()\n\n        if self.min_items_per_replica is not None:\n            state[\"min_items_per_replica\"] = self.min_items_per_replica\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should not be called from a DataLoader worker process.\"\n            )\n\n        self.current_epoch += 1\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"You cannot call the `state_dict` method from a data loader worker process. \"\n                \"You can only call it from the main process.\"\n            )\n\n        state = {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n        }\n\n        if self.cache is not None:\n            state.update(self.cache.state_dict())\n\n        if self.item_loader is not None:\n            state.update(self.item_loader.state_dict())\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"input_dir\"] = self.input_dir\n        state[\"url\"] = self.input_dir.url\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"world_size\"] = self.distributed_env.world_size\n        state[\"shuffle\"] = self.shuffle\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"It should only be called from the main process, e.g. in the Dataset's `train` method.\"\n            )\n        self._state_dict = {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should only be called from the main process. \"\n                \"This is done automatically by the StreamingDataLoader.\"\n            )\n\n        return {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self.global_index,\n            \"input_dir\": self.input_dir.path,\n            \"item_loader\": self.item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise Exception(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"It should only be called from the main process.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        if self.shuffler:\n            self._state_dict.update(self.shuffler.state_dict())\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process. \"\n                \"This is because the state of the dataset is not available in the DataLoader worker process.\"\n            )\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        # This is not yet implemented because the number of workers is not available in the DataLoader worker process.\n        if self.distributed_env.world_size != 1:\n            raise NotImplementedError(\n                \"The `state_dict` method is not implemented for a distributed environment with more than one worker. \"\n                \"This is because the number of workers is not available in the DataLoader worker process.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method is not allowed to be called from a Dataloader worker process.\"\n            )\n\n        # This is not a distributed environment\n        if self.distributed_env.world_size == 1:\n            return {\n                \"num_workers\": num_workers,\n                \"batch_size\": batch_size,\n                \"num_samples_yielded\": num_samples_yielded,\n                \"current_epoch\": self.current_epoch,\n                \"input_dir\": self.input_dir,\n                \"item_loader\": self.item_loader,\n                \"drop_last\": self.drop_last,\n                \"seed\": self.seed,\n                \"world_size\": self.distributed_env.world_size,\n                \"shuffle\": self.shuffle,\n                \"current_indexes\": self.current_indexes,\n                \"chunk_index\": self.chunk_index,\n                \"worker_chunks\": self.worker_chunks,\n                \"worker_intervals\": self.worker_intervals,\n            }\n\n        # This is a distributed environment\n        return {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"current_indexes\": self.current_indexes,\n            \"chunk_index\": self.chunk_index,\n            \"worker_chunks\": self.worker_chunks,\n            \"worker_intervals\": self.worker_intervals,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method should not be called from a DataLoader worker process. \"\n                \"Instead, it should be called from the main process.\"\n            )\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"input_dir\": self.input_dir.path,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        if self.item_loader is not None:\n            state[\"item_loader_state\"] = self.item_loader.state_dict()\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The state_dict() method can only be called from the main process.\")\n\n        return {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"shuffle\": self.shuffle,\n            \"distributed_env\": self.distributed_env,\n            \"world_size\": self.distributed_env.world_size,\n            \"state_dict\": self._state_dict,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please call the `state_dict` method on the StreamingDataset instance instead.\"\n            )\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        num_workers = self.distributed_env.world_size\n\n        if self.num_chunks is not None:\n            num_samples_yielded = self.global_index\n\n        state = {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n        }\n\n        if self.current_epoch > 1:\n            state[\"current_epoch\"] = self.current_epoch\n        if self.distributed_env.world_size > 1:\n            state[\"drop_last\"] = self.drop_last\n        if self.seed != 42:\n            state[\"seed\"] = self.seed\n\n        if self.input_dir.path is not None:\n            state[\"input_dir\"] = self.input_dir.path\n\n        if self.item_loader is not None:\n            state[\"item_loader\"] = self.item_loader.state_dict()\n\n        if self.max_cache_size is not None:\n            state[\"max_cache_size\"] = self.max_cache_size\n        if self.shuffle:\n            state[\"shuffle\"] = self.shuffle\n\n        if self.worker_env is not None:\n            state[\"worker_env\"] = self.worker_env.state_dict()\n\n        state_hash = hashlib.md5(str(state).encode())\n        state[\"state_hash\"] = state_hash.hexdigest()\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should be called from the main process of the program, not from a DataLoader worker process.\"\n            )\n\n        state = {\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n        }\n\n        state.update(self.shuffler.state_dict(self.num_chunks, self.current_epoch, self.chunk_index))\n\n        state[\"input_dir\"] = self.input_dir\n        state[\"item_loader\"] = self.item_loader\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"distributed_env\"] = self.distributed_env\n        state[\"shuffle\"] = self.shuffle\n\n        if self.serializers is not None:\n            state[\"serializers\"] = self.serializers\n\n        # save the epoch\n        state[\"current_epoch\"] = self.current_epoch\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process. \"\n                \"This is because the StreamingDataset is not serializable and the state_dict \"\n                \"method is used to serialize the dataset.\"\n            )\n\n        self.global_index = num_samples_yielded\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n            self.distributed_env, self.current_epoch\n        )\n        chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n        intervals_replica = intervals_per_replica[\n            self.distributed_env.global_rank % self.distributed_env.world_size\n        ]\n\n        # Handle restart\n        if self._state_dict:\n            self._resume(chunks_replica, intervals_replica)\n\n        # Handle restart\n        if self._state_dict:\n            self._state_dict.update(\n                {\n                    \"num_workers\": num_workers,\n                    \"batch_size\": batch_size,\n                    \"num_samples_yielded\": num_samples_yielded,\n                }\n            )\n\n            return self._state_dict\n\n        # Otherwise, generate a new state dict\n        state = {\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"distributed_env\": self.distributed_env,\n            \"shuffler\": self.shuffler,\n            \"shuffle\": self.shuffle,\n            \"current_epoch\": self.current_epoch,\n            \"current_indexes\": self.current_indexes,\n            \"chunk"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"You are calling the StreamingDataset `state_dict` method from a Dataloader worker process. \"\n                \"Please call it from the main process.\"\n            )\n\n        self.current_epoch += 1\n\n        # store the state dict\n        state = {\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"num_chunks\": self.num_chunks,\n            \"num_samples_yielded\": self.global_index,\n        }\n        if self.item_loader:\n            state[\"item_loader\"] = self.item_loader.state_dict()\n        if self.shuffler:\n            state[\"shuffler\"] = self.shuffler.state_dict()\n\n        if self.cache:\n            state[\"cache\"] = self.cache.state_dict()\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"The `state_dict` method should only be called from the main process\")\n\n        if self.distributed_env.world_size > 1:\n            if self.min_items_per_replica is None:\n                self.min_items_per_replica = _calculate_min_items_per_replica(\n                    self.num_chunks, self.distributed_env.world_size\n                )\n            if self.min_items_per_replica > len(self.worker_chunks):\n                raise ValueError(\n                    f\"The number of items per replica is too large. \"\n                    f\"The min_items_per_replica is {self.min_items_per_replica} and the number of items is {len(self.worker_chunks)}.\"\n                )\n\n        if self.random_state is None:\n            self.random_state = self.shuffler.random_state\n\n        if self.worker_env.world_size > 1:\n            if self.distributed_env.world_size != self.worker_env.world_size:\n                raise ValueError(\n                    f\"The number of workers is not the same in the main process ({self.worker_env.world_size}) \"\n                    f\"and the worker process ({self.distributed_env.world_size})\"\n                )\n            if self.distributed_env.world_size != self.num_chunks:\n                raise ValueError(\n                    f\"The number of chunks ({self.num_chunks}) is not the same as the world size ({self.distributed_env.world_size})\"\n                )\n\n        state = {\n            \"num_workers\": self.worker_env.world_size,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env,\n            \"shuffle\": self.shuffle,\n            \"num_chunks\": self."}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The state_dict method cannot be called from a DataLoader worker process. \"\n                \"This is because the state_dict method requires information about the underlying dataset, \"\n                \"which is not available within the DataLoader worker process. \"\n                \"It is recommended to call the state_dict method from the main process instead.\"\n            )\n\n        # The state_dict is not intended to be used by the DatasetOptimiser\n        # It's only used to resume the dataset\n        state_dict: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        if self.shuffler is not None:\n            state_dict[\"shuffler_state\"] = self.shuffler.state_dict()\n            state_dict[\"num_chunks\"] = self.num_chunks\n            state_dict[\"chunk_index\"] = self.chunk_index\n            state_dict[\"current_indexes\"] = self.current_indexes\n            state_dict[\"worker_chunks\"] = self.worker_chunks\n            state_dict[\"worker_intervals\"] = self.worker_intervals\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process. \"\n                \"This method is only intended to be used when the StreamingDataset is being saved. \"\n                \"It should be called from the main process of the training loop.\"\n            )\n        if self.cache is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state_dict: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        # We don't want to save the current epoch in the state dict, as it is set by the StreamingDataLoader\n        # and it is not necessary to restore the state\n        # state_dict[\"current_epoch\"] = self.current_epoch\n        if self.item_loader is not None:\n            state_dict.update(self.item_loader.state_dict())\n\n        if self.shuffler is not None:\n            state_dict[\"shuffler\"] = self.shuffler.state_dict()\n\n        if self.cache is not None:\n            state_dict[\"cache\"] = self.cache.state_dict()\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if not isinstance(state_dict, dict):\n            raise TypeError(f\"state_dict should be of type dict. Got {type(state_dict)} instead.\")\n\n        if \"num_workers\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `num_workers`.\")\n\n        if \"batch_size\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `batch_size`.\")\n\n        if \"current_epoch\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `current_epoch`.\")\n\n        if \"input_dir_path\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `input_dir_path`.\")\n\n        if \"input_dir_url\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `input_dir_url`.\")\n\n        if \"item_loader\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `item_loader`.\")\n\n        if \"drop_last\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `drop_last`.\")\n\n        if \"seed\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `seed`.\")\n\n        if \"world_size\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `world_size`.\")\n\n        if \"shuffle\" not in state_dict:\n            raise KeyError(\"The dictionary doesn't contain the key `shuffle`.\")\n\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self.num_chunks = state_dict[\"num_chunks\"]\n        self.worker_chunks = state_dict[\"worker_chunks\"]\n        self.worker_intervals = state_dict[\"worker_intervals\"]\n        self.current_indexes = state_dict[\"current_indexes\"]\n        self.chunk_index = state_dict[\"chunk_index\"]\n        self.global_index = state_dict[\"global_index\"]\n        self.index = state_dict[\"index\"]\n        self.has_triggered_download = state_dict[\"has_triggered_download\"]\n        self.min_items_per_replica = state_dict[\"min_items_per_replica\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.random_state = state_dict[\"random_state\"]\n\n        self.shuffler = state_dict[\"shuffler\"]\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n\n        if \"item_loader\" in state_dict:\n            self.item_loader = state_dict[\"item_loader\"]\n\n        self._validate_state_dict()\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if \"num_samples_yielded\" in state_dict:\n            self.global_index = state_dict[\"num_samples_yielded\"]\n\n        if \"current_epoch\" in state_dict:\n            self.current_epoch = state_dict[\"current_epoch\"]\n\n        if \"item_loader\" in state_dict:\n            self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n\n        if \"input_dir_path\" in state_dict and \"input_dir_url\" in state_dict:\n            input_dir = Dir(path=state_dict[\"input_dir_path\"], url=state_dict[\"input_dir_url\"])\n\n            self.input_dir = input_dir\n\n        if \"drop_last\" in state_dict:\n            self.drop_last = state_dict[\"drop_last\"]\n\n        if \"seed\" in state_dict:\n            self.seed = state_dict[\"seed\"]\n\n        if \"world_size\" in state_dict:\n            self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n\n        if \"shuffle\" in state_dict:\n            self.shuffle = state_dict[\"shuffle\"]\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            return\n\n        # Load the state dict\n        self._state_dict = state_dict\n\n        # Load the item loader\n        if \"item_loader\" in state_dict:\n            self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n        else:\n            self.item_loader = None\n\n        # Load the shuffle\n        self.shuffler = self._create_shuffler(self.cache)\n\n        # Load the cache\n        self.cache = self._create_cache(self.worker_env)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if state_dict is None:\n            raise ValueError(\"The state_dict argument should be a valid dictionary.\")\n        if not isinstance(state_dict, dict):\n            raise ValueError(\"The state_dict argument should be a valid dictionary.\")\n\n        if state_dict[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The StreamingDataset was initialised with {self.worker_env.world_size} workers. \"\n                f\"The state_dict was initialised with {state_dict['num_workers']} workers.\"\n                f\"Please make sure to use the same number of workers when creating the DatasetOptimiser.\"\n            )\n\n        if state_dict[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The StreamingDataset was initialised with {self.distributed_env.world_size} world size. \"\n                f\"The state_dict was initialised with {state_dict['world_size']} world size.\"\n                f\"Please make sure to use the same world size when creating the DatasetOptimiser.\"\n            )\n\n        if state_dict[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The StreamingDataset was initialised with seed {self.seed}. \"\n                f\"The state_dict was initialised with seed {state_dict['seed']}\"\n                f\"Please make sure to use the same seed when creating the DatasetOptimiser.\"\n            )\n\n        if state_dict[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The StreamingDataset was initialised with shuffle {self.shuffle}. \"\n                f\"The state_dict was initialised with shuffle {state_dict['shuffle']}\"\n                f\"Please make sure to use the same shuffle when creating the DatasetOptimiser.\"\n            )\n\n        if state_dict[\"item_loader\"] is not None:\n            if self.item_loader is None:\n                self.item_loader = state_dict[\"item_loader\"]\n            else:\n                self.item_loader"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        if \"num_samples_yielded\" in state_dict:\n            self.global_index = state_dict[\"num_samples_yielded\"]\n\n        if \"input_dir_path\" in state_dict and state_dict[\"input_dir_path\"] is not None:\n            self.input_dir.path = state_dict[\"input_dir_path\"]\n\n        if \"input_dir_url\" in state_dict and state_dict[\"input_dir_url\"] is not None:\n            self.input_dir.url = state_dict[\"input_dir_url\"]\n\n        if \"item_loader\" in state_dict:\n            self.item_loader = state_dict[\"item_loader\"]\n\n        if \"drop_last\" in state_dict:\n            self.drop_last = state_dict[\"drop_last\"]\n\n        if \"seed\" in state_dict:\n            self.seed = state_dict[\"seed\"]\n\n        if \"shuffle\" in state_dict:\n            self.shuffle = state_dict[\"shuffle\"]\n\n        if \"current_epoch\" in state_dict:\n            self.current_epoch = state_dict[\"current_epoch\"]\n\n        if \"world_size\" in state_dict:\n            self.distributed_env.world_size = state_dict[\"world_size\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if not isinstance(state_dict, dict):\n            raise TypeError(\"state_dict should be of type Dict[str, Any]. Found {}\".format(type(state_dict)))\n\n        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        if self.input_dir.path is not None:\n            self.input_dir.path = state_dict[\"input_dir_path\"]\n\n        if self.input_dir.url is not None:\n            self.input_dir.url = state_dict[\"input_dir_url\"]\n\n        if self.item_loader is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n        else:\n            self.item_loader = state_dict[\"item_loader\"]\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.distributed_env = _DistributedEnv.detect()\n        self.worker_env = _WorkerEnv.detect()\n        self.num_chunks = state_dict[\"num_chunks\"]\n        self.num_workers = state_dict[\"num_workers\"]\n        self.min_items_per_replica = state_dict[\"min_items_per_replica\"]\n        self.num_samples_yielded = state_dict[\"num_samples_yielded\"]\n\n        self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The StreamingDataset has already been loaded from a state dict.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        # We don't load the random state to prevent the randomization to be done on the workers.\n        self.seed = state_dict[\"seed\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        if self._state_dict is not None:\n            self.input_dir = Dir(\n                self.state_dict_path(self.state_dict_key(\"input_dir_path\")),\n                self.state_dict_url(self.state_dict_key(\"input_dir_url\")),\n            )\n            self.item_loader.load_state_dict(self.state_dict_key(\"item_loader\"))\n            self.drop_last = self.state_dict_key(\"drop_last\")\n            self.seed = self.state_dict_key(\"seed\")\n            self.shuffle = self.state_dict_key(\"shuffle\")\n            self.distributed_env = _DistributedEnv.detect()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The state_dict has already been loaded.\")\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if \"input_dir_path\" in state_dict and \"input_dir_url\" in state_dict:\n            self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n            state_dict.pop(\"input_dir_path\")\n            state_dict.pop(\"input_dir_url\")\n\n        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir.path = state_dict[\"input_dir_path\"] if \"input_dir_path\" in state_dict else self.input_dir.path\n        self.input_dir.url = state_dict[\"input_dir_url\"] if \"input_dir_url\" in state_dict else self.input_dir.url\n        self.item_loader.load_state_dict(state_dict[\"item_loader\"]) if \"item_loader\" in state_dict else None\n        self.shuffle = state_dict[\"shuffle\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env.world_size = state_dict[\"world_size\"]\n\n        self._state_dict.pop(\"num_samples_yielded\", None)\n        self._state_dict.pop(\"num_workers\", None)\n        self._state_dict.pop(\"batch_size\", None)\n        self._state_dict.pop(\"current_epoch\", None)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self.input_dir.path is None and state_dict[\"input_dir_path\"] is not None:\n            self.input_dir.path = state_dict[\"input_dir_path\"]\n\n        if self.item_loader is None and state_dict[\"item_loader\"] is not None:\n            self.item_loader = state_dict[\"item_loader\"]\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.distributed_env = _DistributedEnv.detect()\n        self.worker_env = _WorkerEnv.detect()\n\n        # If the state dict has been loaded, we don't want to re-create the cache\n        if self._state_dict is not None:\n            self._state_dict[\"num_samples_yielded\"] = state_dict[\"num_samples_yielded\"]\n            return\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n        self.item_loader = state_dict[\"item_loader\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.num_chunks = state_dict[\"num_chunks\"]\n        self.worker_chunks = state_dict[\"worker_chunks\"]\n\n        self.shuffler = self._create_shuffler(self.cache)\n\n        if self.shuffle:\n            self.shuffler.set_seed(self.seed)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n        self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.worker_chunks = []\n        self.worker_intervals = []\n\n        self.current_indexes = []\n        self.chunk_index = 0\n        self.num_chunks = 0\n        self.global_index = 0\n        self.index = 0\n        self.has_triggered_download = False\n        self.min_items_per_replica = None\n        self.current_epoch = 1\n        self.random_state = None\n        self.shuffler = None\n        self.last_time = 0\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self.input_dir = Dir(\n            path=state_dict[\"input_dir_path\"],\n            url=state_dict[\"input_dir_url\"],\n        )\n        self.item_loader = state_dict[\"item_loader\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        # Handle the state of the cache\n        if \"cache\" in state_dict:\n            self.cache = state_dict[\"cache\"]\n        else:\n            self.cache = None\n\n        # Handle the state of the shuffler\n        if \"shuffler\" in state_dict:\n            self.shuffler = state_dict[\"shuffler\"]\n        else:\n            self.shuffler = None\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self.input_dir_path = state_dict[\"input_dir_path\"]\n        self.input_dir_url = state_dict[\"input_dir_url\"]\n\n        self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n        self.shuffle = state_dict[\"shuffle\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n\n        self.distributed_env = _DistributedEnv.detect()\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.num_chunks = state_dict[\"num_chunks\"]\n\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self.input_dir.path = state_dict[\"input_dir_path\"] if \"input_dir_path\" in state_dict else None\n        self.input_dir.url = state_dict[\"input_dir_url\"] if \"input_dir_url\" in state_dict else None\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        if \"num_workers\" in state_dict:\n            self.num_workers = state_dict[\"num_workers\"]\n            self.batch_size = state_dict[\"batch_size\"]\n            self.num_samples_yielded = state_dict[\"num_samples_yielded\"]\n            self.min_items_per_replica = (\n                state_dict[\"num_workers\"] * state_dict[\"batch_size\"] - state_dict[\"num_samples_yielded\"]\n            )\n\n        if \"item_loader\" in state_dict:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            self._state_dict.update(state_dict)\n        else:\n            self._state_dict = state_dict\n\n        self._validate_state_dict()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        # We can't use the `state_dict` to restore the `input_dir`\n        # as it is a `Dir` object which is not pickleable.\n        # We need to use the `input_dir_path` and `input_dir_url`\n        # to create a new `Dir` object.\n        if state_dict[\"input_dir_path\"] is not None:\n            self.input_dir = Dir(\n                path=state_dict[\"input_dir_path\"],\n                url=state_dict[\"input_dir_url\"],\n            )\n\n        if state_dict[\"item_loader\"]:\n            self.item_loader = state_dict[\"item_loader\"]\n        else:\n            self.item_loader = None\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.world_size = state_dict[\"world_size\"]\n\n        if self.distributed_env.world_size > 1:\n            self.distributed_env = _DistributedEnv(self.world_size, self.world_size)\n\n        self.min_items_per_replica = state_dict[\"num_samples_yielded\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.shuffler = None\n        self.current_indexes = []\n        self.worker_chunks = []\n        self.worker_intervals = []\n        self.chunk_index = 0\n        self.num_chunks = None\n        self.global_index = 0\n        self.index = 0\n        self.has_triggered_download = False\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        num_workers = state[\"num_workers\"]\n        batch_size = state[\"batch_size\"]\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        num_samples_yielded = state[\"num_samples_yielded\"]\n\n        # replay sampling from each worker / chunks using the batch size\n        workers_chunks, workers_intervals = _associate_chunks_to_workers(num_workers, self.worker_env, self.worker_chunks, self.worker_intervals)\n        indexes = _replay_sampling(num_samples_yielded, batch_size, num_workers)\n        chunks_index, indexes = _replay_chunks_sampling(workers_intervals, indexes)\n\n        # select the chunks and intervals associated to this worker\n        worker_rank = self.worker_env.rank\n        self.num_chunks = len(workers_intervals[worker_rank])\n        self.worker_chunks = workers_chunks[worker_rank]\n        self.worker_intervals = workers_intervals[worker_rank]\n\n        # replay the indexes for the current chunks\n        interval = self.worker_intervals[chunks_index[worker_rank]]\n        current_indexes = np.arange(interval[0], interval[1])\n\n        # re-shuffle the indexes\n        current_indexes = self.shuffler(current_indexes, self.num_chunks, self.current_epoch, chunks_index[worker_rank])\n\n        # skip any indexes already consumed\n        current_indexes = current_indexes[indexes[worker_rank] :]\n        self.current_indexes = current_indexes\n\n        # bump the chunk_index\n        self.chunk_index = chunks_index[worker_rank] + 1\n        self.global_index = num_samples_yielded\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        state = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary contains a different shuffle flag ({state['shuffle']}) \"\n                f\"than the current state of the StreamingDataset instance ({self.shuffle}).\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary contains a different number of workers ({state['num_workers']}) \"\n                f\"than the current state of the StreamingDataset instance ({self.worker_env.world_size}).\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary contains a different input directory path ({state['input_dir_path']}) \"\n                f\"than the current state of the StreamingDataset instance ({self.input_dir.path}).\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary contains a different input directory URL ({state['input_dir_url']}) \"\n                f\"than the current state of the StreamingDataset instance ({self.input_dir.url}).\"\n            )\n\n        if state[\"item_loader\"] is not None:\n            if not isinstance(self.item_loader, type(state[\"item_loader\"]) or not self.item_loader.state_dict() == state[\"item_loader\"]:\n                raise ValueError(\n                    f\"The state dictionary contains a different item loader ({state['item_loader']}) \"\n                    f\"than the current state of the StreamingDataset instance ({self.item_loader}).\"\n                )\n        else:\n            if self.item_loader is not None:\n                raise ValueError(\n                    f\"The state dictionary contains a different item loader ({state['item_loader']}) \"\n                    f\"than the current state of the StreamingDataset instance ({self.item_loader}).\"\n                )\n\n        if state[\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self.distributed_env.world_size != state_dict[\"world_size\"]:\n            raise ValueError(\n                f\"The `world_size` in the state_dict doesn't match the world size of the current instance. \"\n                f\"The `world_size` in the state_dict is {state_dict['world_size']}. \"\n                f\"The `world_size` of the current instance is {self.distributed_env.world_size}.\"\n            )\n\n        if self.shuffle != state_dict[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle in the state_dict doesn't match the shuffle of the current instance. \"\n                f\"The shuffle in the state_dict is {state_dict['shuffle']}. \"\n                f\"The shuffle of the current instance is {self.shuffle}.\"\n            )\n\n        if self.input_dir.path != state_dict[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The `input_dir_path` in the state_dict doesn't match the `input_dir_path` of the current instance. \"\n                f\"The `input_dir_path` in the state_dict is {state_dict['input_dir_path']}. \"\n                f\"The `input_dir_path` of the current instance is {self.input_dir.path}.\"\n            )\n\n        if self.input_dir.url != state_dict[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The `input_dir_url` in the state_dict doesn't match the `input_dir_url` of the current instance. \"\n                f\"The `input_dir_url` in the state_dict is {state_dict['input_dir_url']}. \"\n                f\"The `input_dir_url` of the current instance is {self.input_dir.url}.\"\n            )\n\n        if self.item_loader is not None and self.item_loader.state_dict() != state_dict[\"item_loader\"]:\n            raise ValueError(\n                f\"The `item_loader` in the state_dict doesn't match the `item_loader` of the"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # the state is restored within the workers\n        state = self._state_dict\n\n        # check if the input directory path and URL are the same\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The input directory path and URL in the state dictionary do not match the current state of the StreamingDataset instance.\"\n            )\n\n        # check if the item_loader is the same\n        if (\n            state[\"item_loader\"] is not None\n            and state[\"item_loader\"] != self.item_loader.state_dict()\n            and state[\"item_loader\"] != self.item_loader\n        ):\n            raise ValueError(\n                \"The item loader in the state dictionary does not match the current state of the StreamingDataset instance.\"\n            )\n\n        # check if the shuffle is the same\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"The shuffle in the state dictionary does not match the current state of the StreamingDataset instance.\")\n\n        # check if the drop_last is the same\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"The drop_last in the state dictionary does not match the current state of the StreamingDataset instance.\")\n\n        # check if the seed is the same\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"The seed in the state dictionary does not match the current state of the StreamingDataset instance.\")\n\n        # check if the world_size is the same\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                \"The world size in the state dictionary does not match the current state of the StreamingDataset instance.\"\n            )\n\n        # check if the num_workers is the same\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"The num_workers in the state dictionary does not match the current state of the StreamingDataset instance.\")\n\n        # check if the batch size is the same\n        if state[\"batch_size\"] != self.batch_size:\n            raise ValueError(\"The batch size in the state dictionary does"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        # Check for the existence of the `input_dir_path` and `input_dir_url` keys in the state dictionary.\n        if \"input_dir_path\" not in state:\n            raise ValueError(\"The state dictionary must contain the 'input_dir_path' key.\")\n\n        if \"input_dir_url\" not in state:\n            raise ValueError(\"The state dictionary must contain the 'input_dir_url' key.\")\n\n        # Check if the `input_dir_path` and `input_dir_url` keys in the state dictionary match the current state of the StreamingDataset instance.\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The 'input_dir_path' key in the state dictionary must match the current state of the StreamingDataset instance. \"\n                f\"The 'input_dir_path' key in the state dictionary is {state['input_dir_path']}. \"\n                f\"The current state of the StreamingDataset instance is {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The 'input_dir_url' key in the state dictionary must match the current state of the StreamingDataset instance. \"\n                f\"The 'input_dir_url' key in the state dictionary is {state['input_dir_url']}. \"\n                f\"The current state of the StreamingDataset instance is {self.input_dir.url}.\"\n            )\n\n        # Check if the `item_loader` key is present in the state dictionary.\n        if \"item_loader\" not in state:\n            raise ValueError(\"The state dictionary must contain the 'item_loader' key.\")\n\n        # Check if the `item_loader` key in the state dictionary is the same as the current state of the StreamingDataset instance.\n        if state[\"item_loader\"] != self.item_loader:\n            raise ValueError(\n                f\"The 'item_loader' key in the state dictionary must match the current state of the StreamingDataset instance. \"\n                f\"The '"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter in the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"The state dictionary has a shuffle parameter of {state['shuffle']} but the current instance has a shuffle parameter of {self.shuffle}.\"\n            )\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world_size parameter in the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"The state dictionary has a world_size parameter of {state['world_size']} but the current instance has a world_size parameter of {self.distributed_env.world_size}.\"\n            )\n\n        if self.num_chunks != state[\"num_chunks\"]:\n            raise ValueError(\n                f\"The num_chunks parameter in the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"The state dictionary has a num_chunks parameter of {state['num_chunks']} but the current instance has a num_chunks parameter of {self.num_chunks}.\"\n            )\n\n        if self.current_epoch != state[\"current_epoch\"]:\n            raise ValueError(\n                f\"The current_epoch parameter in the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"The state dictionary has a current_epoch parameter of {state['current_epoch']} but the current instance has a current_epoch parameter of {self.current_epoch}.\"\n            )\n\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The worker_env.world_size parameter in the state dictionary does not match the current state of the StreamingDataset instance. \"\n                f\"The state dictionary has a worker_env.world_size parameter of {state['num_workers']} but the current instance has a worker_env.world_size parameter of {self.worker_env.world_size}.\"\n            )\n\n        if self.worker_env.rank != state[\"worker_env.rank\"]:\n            raise ValueError(\n                f\"The worker_env.rank parameter in the state dictionary does not"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # Check if the state_dict is not None\n        if self._state_dict is None:\n            raise ValueError(\"The state_dict is None. This is not expected.\")\n\n        # Check if the current_epoch is not None\n        if self.current_epoch is None:\n            raise ValueError(\"The current_epoch is None. This is not expected.\")\n\n        # Check if the cache is not None\n        if self.cache is None:\n            raise ValueError(\"The cache is None. This is not expected.\")\n\n        # Check if the shuffler is not None\n        if self.shuffler is None:\n            raise ValueError(\"The shuffler is None. This is not expected.\")\n\n        # Check if the drop_last is not None\n        if self.drop_last is None:\n            raise ValueError(\"The drop_last is None. This is not expected.\")\n\n        # Check if the seed is not None\n        if self.seed is None:\n            raise ValueError(\"The seed is None. This is not expected.\")\n\n        # Check if the shuffle is not None\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle is None. This is not expected.\")\n\n        # Check if the worker_env is not None\n        if self.worker_env is None:\n            raise ValueError(\"The worker_env is None. This is not expected.\")\n\n        # Check if the input_dir_path is not None\n        if self.input_dir.path is None:\n            raise ValueError(\"The input_dir_path is None. This is not expected.\")\n\n        # Check if the item_loader is not None\n        if self.item_loader is None:\n            raise ValueError(\"The item_loader is None. This is not expected.\")\n\n        # Check if the item_loader state is not None\n        if self.item_loader.state_dict is None:\n            raise ValueError(\"The item_loader state is None. This is not expected.\")\n\n        # Check if the world_size is not None\n        if self.distributed_env.world_size is None:\n            raise ValueError(\"The world_size is None. This is not expected.\")\n\n        # Check if the world_size is not None\n        if self.distributed_env.global_rank is"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # TODO: Add checks for the serializers\n        # TODO: Add checks for the item_loader\n\n        if self.cache is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The `num_workers` in the state dictionary ({state['num_workers']}) \"\n                f\"does not match the current world_size ({self.worker_env.world_size})\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The `shuffle` in the state dictionary ({state['shuffle']}) \"\n                f\"does not match the current shuffle ({self.shuffle})\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The `drop_last` in the state dictionary ({state['drop_last']}) \"\n                f\"does not match the current drop_last ({self.drop_last})\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The `seed` in the state dictionary ({state['seed']}) \"\n                f\"does not match the current seed ({self.seed})\"\n            )\n\n        if self.current_epoch != state[\"current_epoch\"]:\n            raise ValueError(\n                f\"The `current_epoch` in the state dictionary ({state['current_epoch']}) \"\n                f\"does not match the current epoch ({self.current_epoch})\"\n            )\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The `world_size` in the state dictionary ({state['world_size']}) \"\n                f\"does not match the current world_size ({self.distributed_env.world_size})\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        self.cache = self._create_cache(worker_env=self.worker_env)\n\n        # Check the input directory\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory in the state dictionary does not match the current input directory path. \"\n                f\"Expected: {state['input_dir_path']}, Got: {self.input_dir.path}\"\n            )\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory in the state dictionary does not match the current input directory URL. \"\n                f\"Expected: {state['input_dir_url']}, Got: {self.input_dir.url}\"\n            )\n\n        # Check the shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle value in the state dictionary does not match the current shuffle value. \"\n                f\"Expected: {state['shuffle']}, Got: {self.shuffle}\"\n            )\n\n        # Check the seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed value in the state dictionary does not match the current seed value. \"\n                f\"Expected: {state['seed']}, Got: {self.seed}\"\n            )\n\n        # Check the item loader\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            if self.item_loader.state_dict() != state[\"item_loader\"]:\n                raise ValueError(\n                    f\"The item loader in the state dictionary does not match the current item loader. \"\n                    f\"Expected: {state['item_loader']}, Got: {self.item_loader}\"\n                )\n        elif self.item_loader is None and state[\"item_loader\"] is not None:\n            raise ValueError(\n                f\"The item loader in the state dictionary is not None, but the current item loader is None.\"\n            )\n        elif self.item_loader is not None and state[\"item_loader\"] is None:"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n\n        # Check if the state dictionary is empty.\n        if not state:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        # Check if the input directory path or URL in the state dictionary matches the current input directory path or URL.\n        if (\n            state[\"input_dir_path\"] != self.input_dir.path\n            or state[\"input_dir_url\"] != self.input_dir.url\n        ):\n            raise ValueError(\n                f\"The input directory path or URL in the state dictionary does not match the current input directory path or URL. \"\n                f\"State dictionary input directory path: {state['input_dir_path']}. \"\n                f\"Current input directory path: {self.input_dir.path}. \"\n                f\"State dictionary input directory URL: {state['input_dir_url']}. \"\n                f\"Current input directory URL: {self.input_dir.url}.\"\n            )\n\n        # Check if the item loader in the state dictionary matches the current item loader.\n        if state[\"item_loader\"]:\n            if self.item_loader is None:\n                raise ValueError(\n                    \"The state dictionary contains an item loader, but the current item loader is None. \"\n                    \"This is not allowed.\"\n                )\n            if not self.item_loader.state_dict() == state[\"item_loader\"]:\n                raise ValueError(\n                    f\"The item loader in the state dictionary does not match the current item loader. \"\n                    f\"State dictionary item loader: {state['item_loader']}. \"\n                    f\"Current item loader: {self.item_loader}.\"\n                )\n\n        # Check if the shuffle in the state dictionary matches the current shuffle.\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state dictionary does not match the current shuffle. \"\n                f\"State dictionary shuffle: {state['shuffle']}. \"\n                f\"Current shuffle: {self.shuffle}.\"\n            )\n\n        # Check if the drop_last in the state dictionary matches the current drop_last.\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError("}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n            if self.worker_env.world_size > 1:\n                self.distributed_env = _DistributedEnv.detect()\n\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state: Dict[str, Any] = self._state_dict\n\n        # Check the input_dir path\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The input_dir path in the state dictionary does not match the current input_dir path. The state dictionary has input_dir_path as `{input_dir_path}` and the current input_dir path is `{input_dir_path_current}`.\".format(\n                    input_dir_path=state[\"input_dir_path\"],\n                    input_dir_path_current=self.input_dir.path,\n                )\n            )\n\n        # Check the input_dir url\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The input_dir url in the state dictionary does not match the current input_dir url. The state dictionary has input_dir_url as `{input_dir_url}` and the current input_dir url is `{input_dir_url_current}`.\".format(\n                    input_dir_url=state[\"input_dir_url\"], input_dir_url_current=self.input_dir.url\n                )\n            )\n\n        # Check the shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The shuffle in the state dictionary does not match the current shuffle. The state dictionary has shuffle as `{shuffle}` and the current shuffle is `{shuffle_current}`.\".format(\n                    shuffle=state[\"shuffle\"], shuffle_current=self.shuffle\n                )\n            )\n\n        # Check the seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                "}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # TODO: Validate the state dict\n        # Check for consistency across various parameters such as shuffle, num_workers, input directory path and URL, seed, item_loader state, and drop_last flag\n        # If any of the parameters in the state dictionary do not match the current state of the StreamingDataset instance, raise a ValueError indicating the mismatch\n\n        # TODO: Check if the `state_dict` is None\n        if self._state_dict is None:\n            raise ValueError(\"The `state_dict` is None. Did you forget to call `state_dict()`?\")\n\n        # TODO: Check if the `state_dict` is not None\n        if self._state_dict is not None:\n            # TODO: Check if the `state_dict` is not None\n            if self._state_dict[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\n                    \"The `input_dir_path` in the `state_dict` does not match the current `input_dir_path`.\"\n                )\n\n            # TODO: Check if the `state_dict` is not None\n            if self._state_dict[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"The `input_dir_url` in the `state_dict` does not match the current `input_dir_url`.\")\n\n            # TODO: Check if the `state_dict` is not None\n            if self._state_dict[\"item_loader\"] != self.item_loader:\n                raise ValueError(\"The `item_loader` in the `state_dict` does not match the current `item_loader`.\")\n\n            # TODO: Check if the `state_dict` is not None\n            if self._state_dict[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"The `shuffle` in the `state_dict` does not match the current `shuffle`.\")\n\n            # TODO: Check if the `state_dict` is not None\n            if self._state_dict[\"seed\"] != self.seed:\n                raise ValueError(\"The `seed` in the `state_dict` does not match the current `seed`.\")\n\n            # TODO: Check if the `state_dict` is not None"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.cache is None:\n            raise ValueError(\n                \"The state dictionary of the StreamingDataset instance does not contain the cache. Please ensure that the \"\n                \"cache is initialized before the state dictionary is loaded.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                \"The shuffle flag in the state dictionary does not match the current state of the StreamingDataset instance.\"\n                \" Please ensure that the shuffle flag is set to the same value in the state dictionary and the current state.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                \"The drop_last flag in the state dictionary does not match the current state of the StreamingDataset \"\n                \"instance. Please ensure that the drop_last flag is set to the same value in the state dictionary and the \"\n                \"current state.\"\n            )\n\n        if self.worker_env is None:\n            raise ValueError(\n                \"The worker_env in the state dictionary does not match the current state of the StreamingDataset instance. \"\n                \"Please ensure that the worker_env is set to the same value in the state dictionary and the current state.\"\n            )\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                \"The world_size in the state dictionary does not match the current state of the StreamingDataset \"\n                \"instance. Please ensure that the world_size is set to the same value in the state dictionary and the \"\n                \"current state.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                \"The input directory path in the state dictionary does not match the current state of the StreamingDataset \"\n                \"instance. Please ensure that the input directory path is set to the same value in the state dictionary \"\n                \"and the current state.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                \"The input directory URL in the state dictionary does not match the current state of the StreamingDataset \"\n                \"instance. Please ensure that the input directory URL is set to"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state_dict: Dict[str, Any] = self._state_dict\n\n        # Validate the `input_dir_path` and `input_dir_url` parameters\n        if state_dict[\"input_dir_path\"] != self.input_dir.path or state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The `input_dir` of the StreamingDataset instance has changed. \"\n                f\"This is not allowed. \"\n                f\"The `input_dir` in the state dictionary is {state_dict['input_dir_path']}. \"\n                f\"The `input_dir` of the StreamingDataset instance is {self.input_dir.path}. \"\n            )\n\n        # Validate the `item_loader` parameter\n        if state_dict[\"item_loader\"] is None:\n            if self.item_loader is not None:\n                raise ValueError(\n                    \"The `item_loader` in the state dictionary is None, but the StreamingDataset instance has an \"\n                    \"item_loader. This is not allowed.\"\n                )\n        elif self.item_loader is None:\n            raise ValueError(\n                \"The `item_loader` in the state dictionary is not None, but the StreamingDataset instance has no \"\n                \"item_loader. This is not allowed.\"\n            )\n        elif state_dict[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                \"The `item_loader` in the state dictionary is not the same as the `item_loader` of the StreamingDataset \"\n                \"instance. This is not allowed. \"\n                f\"The `item_loader` in the state dictionary is {state_dict['item_loader']}. \"\n                f\"The `item_loader` of the StreamingDataset instance is {self.item_loader}. \"\n            )\n\n        # Validate the `drop_last` parameter\n        if state_dict[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                \"The `drop_last` parameter in the state dictionary is not the same as the `drop_last` parameter of the \"\n                \"StreamingDataset instance. This is"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        if self.worker_env is not None:\n            state[\"num_workers\"] = self.worker_env.world_size\n        else:\n            state[\"num_workers\"] = 0\n        state[\"batch_size\"] = self.batch_size\n        state[\"item_loader\"] = self.item_loader.state_dict() if self.item_loader else None\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"shuffle\"] = self.shuffle\n        state[\"world_size\"] = self.distributed_env.world_size\n\n        if self.cache:\n            state[\"cache_path\"] = self.cache.path\n        else:\n            state[\"cache_path\"] = None\n\n        if self.num_workers != state[\"num_workers\"]:\n            raise ValueError(\n                \"The number of workers in the StreamingDataset instance and the state dictionary do not match. \"\n                f\"The number of workers in the StreamingDataset instance is {self.num_workers}, while the state dictionary has \"\n                f\"a value of {state['num_workers']}\"\n            )\n\n        if self.batch_size != state[\"batch_size\"]:\n            raise ValueError(\n                \"The batch size in the StreamingDataset instance and the state dictionary do not match. \"\n                f\"The batch size in the StreamingDataset instance is {self.batch_size}, while the state dictionary has \"\n                f\"a value of {state['batch_size']}\"\n            )\n\n        if self.item_loader is None and state[\"item_loader\"] is not None:\n            raise ValueError(\n                \"The item loader in the StreamingDataset instance and the state dictionary do not match. \"\n                \"The item loader in the StreamingDataset instance is None, while the state dictionary has a value \"\n                f\"of {state['item_loader']}\"\n            )\n\n        if self.item_loader is not None and state[\"item_loader\"] is None:\n            raise ValueError(\n                \"The item loader in the StreamingDataset instance and the state dictionary do not match. \"\n                \"The item loader in the StreamingDataset instance"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        self.distributed_env = _DistributedEnv.detect()\n\n        if self.distributed_env.world_size > 1:\n            if self.drop_last is False:\n                logger.warn(\n                    \"You're operating within a distributed environment and have disabled the `drop_last` option. \"\n                    \"Please note that this configuration may lead to training interruptions if your system depends \"\n                    \"on distributed collectives.\"\n                )\n            else:\n                self.drop_last = True\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n        if self.item_loader is None:\n            self.item_loader = self.cache._reader.item_loader\n\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n\n        # check that the input dir is the same\n        if self._state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The `input_dir_path` in the state_dict does not match the current input_dir path.\"\n            )\n\n        if self._state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"The `input_dir_url` in the state_dict does not match the current input_dir URL.\")\n\n        # check that the item_loader is the same\n        state_item_loader = self._state_dict[\"item_loader\"]\n        if state_item_loader is None:\n            if self.item_loader is not None:\n                raise ValueError(\"The `item_loader` in the state_dict is None but the current `item_loader` is not None.\")\n        else:\n            if self._state_dict[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"The `item_loader` in the state_dict does not match the current `item_loader`.\")\n\n        # check that the drop_last is the same\n        if self.drop_last != self._state_dict[\"drop_last\"]:\n            raise ValueError(\"The `drop_last` in the state_dict does"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # Check the state dict\n        state: Dict[str, Any] = self._state_dict\n\n        # Check if the current state is a new state\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The current world_size is {self.distributed_env.world_size} and the state_dict world_size is {state['world_size']}. \"\n                f\"This is not the same.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter is {self.shuffle} and the state_dict shuffle is {state['shuffle']}. \"\n                f\"This is not the same.\"\n            )\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input_dir path is {self.input_dir.path} and the state_dict input_dir_path is {state['input_dir_path']}. \"\n                f\"This is not the same.\"\n            )\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input_dir url is {self.input_dir.url} and the state_dict input_dir_url is {state['input_dir_url']}. \"\n                f\"This is not the same.\"\n            )\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last parameter is {self.drop_last} and the state_dict drop_last is {state['drop_last']}. \"\n                f\"This is not the same.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed parameter is {self.seed} and the state_dict seed is {state['seed']}. \"\n                f\"This is not the same.\"\n            )\n\n        # Check the item loader\n        if self.item_loader is not None:\n            item_loader_state_dict = self.item_loader.state_dict()\n            if item_loader_state_dict != state[\"item"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state_dict: Dict[str, Any] = self._state_dict\n\n        # Check the input_dir\n        if \"input_dir\" in state_dict:\n            assert state_dict[\"input_dir_path\"] == self.input_dir.path\n            assert state_dict[\"input_dir_url\"] == self.input_dir.url\n        else:\n            assert self.input_dir.path is not None\n\n        # Check the seed\n        assert state_dict[\"seed\"] == self.seed\n\n        # Check the drop_last\n        assert state_dict[\"drop_last\"] == self.drop_last\n\n        # Check the shuffle\n        assert state_dict[\"shuffle\"] == self.shuffle\n\n        # Check the item loader\n        if \"item_loader\" in state_dict:\n            assert state_dict[\"item_loader\"] == self.item_loader.state_dict()\n\n        # Check the worker env\n        assert state_dict[\"num_workers\"] == self.worker_env.world_size\n        assert state_dict[\"world_size\"] == self.distributed_env.world_size\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n\n        # Validate the shuffle parameter\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\"Shuffle mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n\n        # Validate the seed parameter\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\"Seed mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n\n        # Validate the drop_last parameter\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\"Drop last mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n\n        # Validate the input directory path\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\"Input directory path mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n\n        # Validate the input directory URL\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\"Input directory URL mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n\n        # Validate the item_loader state\n        if self.item_loader is None:\n            if state[\"item_loader\"] is not None:\n                raise ValueError(\"Item loader mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n        else:\n            if state[\"item_loader\"] is None:\n                raise ValueError(\"Item loader mismatch between the state dictionary and current state of the StreamingDataset instance.\")\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        state_dict = state\n        if \"input_dir_path\" in state_dict:\n            state_dict[\"input_dir\"] = Dir(path=state_dict[\"input_dir_path\"])\n        if \"input_dir_url\" in state_dict:\n            state_dict[\"input_dir\"] = Dir(url=state_dict[\"input_dir_url\"])\n        if \"item_loader\" in state_dict:\n            state_dict[\"item_loader\"] = state_dict[\"item_loader\"].load_state_dict()\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n\n    hash_str = hashlib.sha256(input_dir.encode()).hexdigest()\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_str)\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), hash_str)\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"), hash_str)\n\n    if not os.path.isdir(cache_dir):\n        os.makedirs(cache_dir, exist_ok=True)\n        logger.info(f\"Created cache directory `{cache_dir}`\")\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique cache directory name\n    hash_str = hashlib.sha224(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create the cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_str)\n\n    # If the cache directory doesn't exist, create it\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n\n    cache_dir = _DEFAULT_CACHE_DIR\n    if _is_in_dataloader_worker():\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n        if not cache_dir:\n            cache_dir = _DEFAULT_CACHE_DIR\n\n    cache_dir = os.path.join(cache_dir, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    try:\n        os.makedirs(cache_dir)\n    except OSError:\n        return None\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is not None:\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n        if not os.path.isdir(cache_dir):\n            os.makedirs(cache_dir)\n        return cache_dir\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_URL\") is not None:\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_URL\")\n        if not os.path.isdir(cache_dir):\n            os.makedirs(cache_dir)\n        return cache_dir\n\n    cache_dir = _DEFAULT_CACHE_DIR\n    if not os.path.isdir(cache_dir):\n        os.makedirs(cache_dir)\n\n    hash_str = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir += \"/\" + hash_str\n    if not os.path.isdir(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n\n    # Create the cache directory\n    cache_dir = os.path.join(os.getcwd(), _DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n\n    # Check if the cache directory already exists\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir, exist_ok=True)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    hash_input = hashlib.sha256(input_dir.encode(\"utf-8\"))\n    cache_dir = _DEFAULT_CACHE_DIR\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n\n    cache_dir = os.path.join(cache_dir, hash_input.hexdigest())\n\n    try:\n        os.makedirs(cache_dir)\n    except FileExistsError:\n        pass\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Check if the user has specified a cache directory\n    cache_dir_path = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if cache_dir_path is not None:\n        cache_dir = os.path.join(cache_dir_path, input_dir)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir)\n\n    # Check if the cache directory exists. If not, create it\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    # Return the path to the cache directory\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Attempt to create cache directory\n    try:\n        # Create cache directory in default location\n        if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n            cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n        else:\n            cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n\n        os.makedirs(cache_dir, exist_ok=True)\n    except (OSError, FileExistsError):\n        logger.warning(f\"Unable to create cache directory: {cache_dir}\")\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = _DEFAULT_CACHE_DIR\n    if os.getenv(\"DATA_CACHE_DIR\"):\n        cache_dir = os.getenv(\"DATA_CACHE_DIR\")\n\n    if os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\"):\n        global_rank = int(os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\"))\n        cache_dir = f\"{cache_dir}/global_{global_rank}\"\n\n    if os.getenv(\"DATA_OPTIMIZER_LOCAL_RANK\"):\n        local_rank = int(os.getenv(\"DATA_OPTIMIZER_LOCAL_RANK\"))\n        cache_dir = f\"{cache_dir}/local_{local_rank}\"\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n            logger.info(f\"Created cache directory `{cache_dir}`.\")\n        except Exception as e:\n            logger.warning(\n                f\"Could not create the cache directory `{cache_dir}`. \"\n                f\"HINT: The directory must be writable by the current user. \"\n                f\"HINT: {e}\"\n            )\n            return None\n\n    try:\n        cache_dir_hash = hashlib.sha1(input_dir.encode(\"utf-8\")).hexdigest()\n    except Exception:\n        cache_dir_hash = \"unknown\"\n\n    cache_dir = f\"{cache_dir}/{cache_dir_hash}\"\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n            logger.info(f\"Created cache directory `{cache_dir}`.\")\n        except Exception as e:\n            logger.warning(\n                f\"Could not create the cache directory `{cache_dir}`. \"\n                f\"HINT: The directory must be writable by the current user. \"\n                f\"HINT: {e}\"\n            )\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_path = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_path = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_path)\n    elif os.getenv(\"LIGHNING_CACHE_DIR\"):\n        cache_path = os.path.join(os.getenv(\"LIGHNING_CACHE_DIR\"), cache_path)\n\n    try:\n        os.makedirs(cache_path)\n    except FileExistsError:\n        pass\n    except OSError:\n        return None\n\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    else:\n        input_dir = os.path.abspath(input_dir)\n    hash_str = hashlib.sha1(input_dir.encode()).hexdigest()\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir_path = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    else:\n        cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, hash_str)\n        if not os.path.exists(cache_dir_path):\n            os.makedirs(cache_dir_path)\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    else:\n        input_dir = os.path.realpath(input_dir)\n        if input_dir.endswith(\"/\"):\n            input_dir = input_dir[:-1]\n\n    if not os.path.exists(input_dir):\n        return None\n\n    m = hashlib.sha256()\n    m.update(input_dir.encode())\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, m.hexdigest())\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the user specified a cache directory, use that\n    if input_dir is not None:\n        if os.path.exists(input_dir):\n            return input_dir\n        else:\n            os.makedirs(input_dir)\n            return input_dir\n    # If the user did not specify a cache directory, use the default cache directory\n    else:\n        if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n            return os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n        else:\n            return os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(b\"\").hexdigest())\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    cache_dir = _DEFAULT_CACHE_DIR\n\n    if input_dir is None:\n        input_dir = \"\"\n\n    if _is_in_dataloader_worker():\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n        if cache_dir is None:\n            cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR_WORKER\", cache_dir), hashlib.md5(input_dir.encode()).hexdigest())\n        else:\n            cache_dir = os.path.join(cache_dir, hashlib.md5(input_dir.encode()).hexdigest())\n\n    else:\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), hashlib.md5(input_dir.encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir)\n        return cache_dir\n    except FileExistsError:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n    hash_input_dir = hashlib.sha224(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = os.path.join(\n        _DEFAULT_CACHE_DIR,\n        hash_input_dir[0:2],\n        hash_input_dir[2:4],\n        hash_input_dir[4:6],\n        hash_input_dir[6:8],\n    )\n    try:\n        os.makedirs(cache_dir)\n        return cache_dir\n    except FileExistsError:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    if _DistributedEnv.detect().is_distributed:\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\", _DEFAULT_CACHE_DIR)\n    else:\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_LOCAL_CACHE_DIR\", _DEFAULT_CACHE_DIR)\n\n    if cache_dir:\n        return os.path.join(cache_dir, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    else:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    if _should_replace_path(input_dir):\n        # If the user has specified a cache directory, return it\n        return input_dir\n\n    # Create a unique directory name\n    hash_str = hashlib.sha1(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create a directory for the cache\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_str)\n\n    try:\n        os.mkdir(cache_dir)\n    except FileExistsError:\n        pass\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    # Create a unique directory name\n    hash_str = hashlib.sha1(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = _DEFAULT_CACHE_DIR / f\"lightning_cache_{hash_str}\"\n\n    # Create the directory\n    cache_dir.mkdir(parents=True, exist_ok=True, mode=0o750)\n    return str(cache_dir)\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    input_dir = input_dir.strip()\n    if not input_dir:\n        return None\n\n    # Create a unique cache directory name based on the input directory.\n    hash_input_dir = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create the cache directory.\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_input_dir)\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the input directory is a cache directory, we'll just use it.\n    if _should_replace_path(input_dir):\n        return input_dir\n\n    # Create a unique cache directory\n    md5_dir = _DEFAULT_CACHE_DIR\n    if input_dir is not None:\n        md5_dir = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create the cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, md5_dir)\n    try:\n        os.makedirs(cache_dir)\n    except FileExistsError:\n        pass\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {e}\")\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not self._s5cmd_available:\n            self._client.download(remote_filepath, local_filepath)\n        else:\n            with FileLock(local_filepath, timeout=10) as lock:\n                if lock.is_locked:\n                    return\n\n                with Timeout(10):\n                    subprocess.check_call(\n                        [\"s5cmd\", \"get\", remote_filepath, local_filepath]\n                    )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if parse.urlsplit(remote_filepath)[0] != \"s3\":\n            raise ValueError(\n                \"The given remote file path must use the 's3' scheme.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(local_filepath + \".lock\", timeout=10):\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\"s5cmd\", \"get\", remote_filepath, local_filepath], check=True\n                )\n            else:\n                self._client.download(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if self._s5cmd_available:\n            self.download_file_s5cmd(remote_filepath, local_filepath)\n        else:\n            self.download_file_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not parse.urlparse(remote_filepath).scheme == \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        # Attempt to download the file using the s5cmd command-line tool\n        if self._s5cmd_available:\n            cmd = f\"s5cmd get {remote_filepath} {local_filepath}\"\n            subprocess.run(cmd, shell=True)\n\n        # Attempt to download the file using the boto3 library\n        else:\n            with FileLock(local_filepath, timeout=Timeout(10)):\n                if os.path.exists(local_filepath):\n                    return\n\n                self._client.download_file(\n                    bucket=self._chunks[0][\"bucket\"],\n                    key=remote_filepath,\n                    Filename=local_filepath,\n                )"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote_filepath is an S3 URL\n        s3_url_parts = parse.urlsplit(remote_filepath)\n        if s3_url_parts.scheme != \"s3\":\n            raise ValueError(\"The given remote file path does not use the 's3' scheme.\")\n\n        # Check if the local_filepath already exists\n        if os.path.isfile(local_filepath):\n            return\n\n        # Download the file using s5cmd if available\n        if self._s5cmd_available:\n            try:\n                with FileLock(local_filepath):\n                    subprocess.check_call([\"s5cmd\", \"get\", remote_filepath, local_filepath])\n            except Timeout:\n                raise Timeout\n\n        # Download the file using boto3 if s5cmd is not available\n        else:\n            with self._client.get_lock(local_filepath):\n                self._client.download_file(s3_url_parts.netloc, s3_url_parts.path, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not os.path.exists(local_filepath):\n\n            # Check if the remote file path is an S3 URL.\n            scheme, netloc, path = parse.urlsplit(remote_filepath)\n\n            # Check if the remote file path uses the \"s3\" scheme.\n            if scheme.lower() != \"s3\":\n                raise ValueError(\n                    f\"The remote file path '{remote_filepath}' does not use the 's3' scheme.\"\n                )\n\n            # Check if the local file already exists.\n            if os.path.exists(local_filepath):\n                raise ValueError(f\"The local file '{local_filepath}' already exists.\")\n\n            # Download the file using the s5cmd command-line tool (if available) or the boto3 library.\n            if self._s5cmd_available:\n                self._download_file_using_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_file_using_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not self._s5cmd_available:\n            self._client.download_file(remote_filepath, local_filepath)\n        else:\n            self.download_file_with_s5cmd(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        scheme, netloc, path = parse.urlsplit(remote_filepath)\n        if scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        # Check if the local file already exists\n        if os.path.isfile(local_filepath):\n            return\n\n        # Download the file using the s5cmd command-line tool if it is available\n        if self._s5cmd_available:\n            s5cmd_cmd = \"s5cmd cp {} {}\".format(remote_filepath, local_filepath)\n            self._run_s5cmd_command(s5cmd_cmd)\n        else:\n            # Download the file using the boto3 library\n            self._download_file_with_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        s3_url_scheme = parse.urlparse(remote_filepath).scheme\n        if s3_url_scheme != \"s3\":\n            raise ValueError(\"The given file path does not use the 's3' scheme.\")\n\n        with FileLock(local_filepath + \".lock\"):\n            if os.path.isfile(local_filepath):\n                return\n            if self._s5cmd_available:\n                s3_url_netloc = parse.urlparse(remote_filepath).netloc\n                s3_url_path = parse.urlparse(remote_filepath).path\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"cp\",\n                        f\"s3://{s3_url_netloc}{s3_url_path}\",\n                        local_filepath,\n                    ]\n                )\n                return\n            self._client.download(\n                bucket_name=self._chunks[0][\"bucket\"],\n                object_name=remote_filepath,\n                local_file_path=local_filepath,\n            )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not os.path.isfile(local_filepath):\n\n            if not self._s5cmd_available:\n                self._client.download_file(\n                    parse.urlparse(remote_filepath).netloc,\n                    parse.urlparse(remote_filepath).path,\n                    local_filepath,\n                )\n            else:\n                with FileLock(local_filepath, timeout=5) as lock:\n                    if lock.locked:\n                        subprocess.run(\n                            f\"s5cmd cp {remote_filepath} {local_filepath}\", shell=True\n                        )\n                    else:\n                        raise Timeout\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        if not parse.uses_netloc(remote_filepath):\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Obtain a file lock to prevent multiple processes from downloading the same file simultaneously\n        with FileLock(local_filepath) as lock:\n            # Check if the file lock could not be acquired within the specified timeout\n            if not lock.is_locked():\n                raise Timeout(\"Could not acquire file lock within specified timeout.\")\n\n            # Download the file using s5cmd (if available) or boto3\n            if self._s5cmd_available:\n                with subprocess.Popen(\n                    [\"s5cmd\", \"get\", remote_filepath, local_filepath],\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                ) as proc:\n                    # Check if the process failed\n                    if proc.wait() != 0:\n                        raise ValueError(\n                            f\"s5cmd failed to download the file {remote_filepath} to {local_filepath}\"\n                        )\n            else:\n                self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        s3_url = parse.urlparse(remote_filepath)\n        if s3_url.scheme != \"s3\":\n            raise ValueError(\n                f\"The remote file path {remote_filepath} does not use the 's3' scheme.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            print(f\"File {local_filepath} already exists, skipping download.\")\n            return\n\n        # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously\n        with FileLock(local_filepath):\n            # Try to download the file using the s5cmd command-line tool\n            if self._s5cmd_available:\n                try:\n                    s5cmd_args = [\n                        \"s5cmd\",\n                        \"get\",\n                        s3_url.geturl(),\n                        local_filepath,\n                    ]\n                    subprocess.check_call(s5cmd_args)\n                except Timeout:\n                    raise Timeout(f\"Could not acquire file lock for {local_filepath}.\")\n\n            # If the s5cmd command-line tool is not available, use the boto3 library to download the file\n            else:\n                self._client.download_file(s3_url.netloc, s3_url.path, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        s3_url_scheme = parse.urlparse(remote_filepath).scheme\n        if s3_url_scheme != \"s3\":\n            raise ValueError(\"The given file path does not use the 's3' scheme.\")\n\n        with FileLock(local_filepath, timeout=60) as lock:\n            if not lock.locked:\n                raise Timeout()\n            if os.path.exists(local_filepath):\n                return\n            if self._s5cmd_available:\n                subprocess.check_call(\n                    [\n                        \"s5cmd\",\n                        \"cp\",\n                        \"-f\",\n                        remote_filepath,\n                        local_filepath,\n                    ],\n                    timeout=60,\n                )\n            else:\n                self._client.download_file(remote_filepath, local_filepath, timeout=60)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"The remote file path: {remote_filepath} is not a valid S3 URL.\")\n\n        # Parse the S3 URL.\n        scheme, netloc, path = parse.urlsplit(remote_filepath)\n\n        # Check if the local file already exists.\n        if os.path.isfile(local_filepath) and not self._overwrite_existing_files:\n            return\n\n        # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously.\n        with FileLock(local_filepath, timeout=30) as f:\n            if not f.is_locked:\n                raise Timeout(\"Failed to acquire file lock within 30 seconds.\")\n\n            # Download the file using the s5cmd command-line tool.\n            if self._s5cmd_available:\n                try:\n                    subprocess.run(\n                        [\"s5cmd\", \"get\", remote_filepath, local_filepath], check=True)\n                except subprocess.CalledProcessError:\n                    pass\n\n            # Download the file using the boto3 library.\n            else:\n                self._client.download_file(netloc, path, local_filepath)\n\n            # Remove the file lock.\n            f.remove()"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"remote file path must use 's3' scheme, not {remote_filepath}\")\n\n        parsed_url = parse.urlsplit(remote_filepath)\n        scheme, netloc, path = parsed_url[0], parsed_url[1], parsed_url[2]\n        if not self._s5cmd_available:\n            self._client.download(netloc, path, local_filepath)\n        else:\n            with FileLock(local_filepath, timeout=Timeout(10)):\n                if not os.path.isfile(local_filepath):\n                    subprocess.run(f\"s5cmd get {remote_filepath}\", shell=True)\n        if not os.path.isfile(local_filepath):\n            raise FileNotFoundError(f\"file {local_filepath} was not found\")\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the S3 URL.\n        scheme, netloc, path = parse.urlsplit(remote_filepath)\n\n        # Check if the S3 URL is valid.\n        if scheme != \"s3\":\n            raise ValueError(f\"The remote_filepath argument must be an S3 URL. {remote_filepath} is not an S3 URL.\")\n\n        # Check if the local file already exists.\n        if os.path.isfile(local_filepath):\n            # If the local file already exists, check if it is a symlink.\n            if os.path.islink(local_filepath):\n                # If the local file is a symlink, follow the symlink.\n                local_filepath = os.path.realpath(local_filepath)\n            else:\n                # If the local file is not a symlink, raise an exception.\n                raise ValueError(f\"The local_filepath argument must not already exist. {local_filepath} already exists.\")\n\n        # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously.\n        with FileLock(local_filepath + \".lock\") as lock:\n            # Check if the file lock could not be acquired within the specified timeout.\n            if lock.is_locked is False:\n                raise Timeout(\"Could not acquire lock on file {}.\".format(local_filepath))\n\n            if self._s5cmd_available:\n                # If the s5cmd command-line tool is available, use it to download the file.\n                subprocess.check_call([\"s5cmd\", \"get\", remote_filepath, local_filepath])\n            else:\n                # If the s5cmd command-line tool is not available, use the boto3 library to download the file.\n                self._client.download_file(netloc, path, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"remote_filepath must start with 's3://'\")\n        if os.path.isfile(local_filepath):\n            return\n\n        try:\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.check_call(f\"s5cmd cp {remote_filepath} {local_filepath}\", shell=True)\n                    return\n                else:\n                    self._client.download_file(\n                        parse.urlsplit(remote_filepath).netloc,\n                        parse.urlsplit(remote_filepath).path,\n                        local_filepath,\n                    )\n        except Timeout:\n            raise Timeout(f\"Failed to download {remote_filepath} to {local_filepath}\")\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket = parsed_url.netloc\n        s3_path = parsed_url.path\n\n        if not os.path.exists(local_filepath):\n            if self._s5cmd_available:\n                # Use the s5cmd command-line tool to download the file.\n                s5cmd_download_cmd = f\"s5cmd get {s3_path} {local_filepath}\"\n                subprocess.run(s5cmd_download_cmd, shell=True)\n            else:\n                # Use the boto3 library to download the file.\n                self._client.download_file(bucket, s3_path, local_filepath)\n\n            # Check if the file was downloaded successfully.\n            if not os.path.exists(local_filepath):\n                raise ValueError(\n                    f\"The file '{local_filepath}' was not downloaded successfully.\"\n                )\n\n        # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously.\n        with FileLock(local_filepath, timeout=10):\n            # Check if the file was downloaded successfully.\n            if not os.path.exists(local_filepath):\n                raise Timeout(\n                    f\"The file '{local_filepath}' was not downloaded successfully.\"\n                )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the S3 URL to get the scheme, netloc, and path.\n        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        # Check if the local file already exists.\n        if os.path.exists(local_filepath):\n            return\n\n        # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously.\n        lock_path = local_filepath + \".lock\"\n        with FileLock(lock_path):\n            # If the file lock cannot be acquired within the specified timeout, raise a Timeout exception.\n            with Timeout(30):\n                # Download the file using the s5cmd command-line tool (if available) or the boto3 library.\n                if self._s5cmd_available:\n                    s5cmd_args = [\n                        \"s5cmd\",\n                        \"get\",\n                        \"-o\",\n                        local_filepath,\n                        f\"s3://{parsed_url.netloc}/{parsed_url.path}\",\n                    ]\n                    subprocess.check_call(s5cmd_args)\n                else:\n                    self._client.download_file(parsed_url.netloc, parsed_url.path, local_filepath)\n            # If the file lock is acquired, delete the lock file.\n            if os.path.exists(lock_path):\n                os.remove(lock_path)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the S3 URL\n        scheme, netloc, path = parse.urlparse(remote_filepath)\n\n        # Check if the remote file path is an S3 URL and if the local file already exists\n        if scheme != \"s3\":\n            raise ValueError(\n                \"The given remote file path does not use the 's3' scheme. Please specify a valid S3 URL.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            raise ValueError(f\"The local file '{local_filepath}' already exists. Please delete it before downloading the file.\")\n\n        # Use the s5cmd command-line tool to download the file\n        if self._s5cmd_available:\n            try:\n                subprocess.run(\n                    [\"s5cmd\", \"cp\", f\"{netloc}{path}\", local_filepath],\n                    check=True,\n                    timeout=60,\n                    check_returncode=True,\n                )\n                return\n\n            except subprocess.TimeoutExpired:\n                raise Timeout(\"The file lock could not be acquired within the specified timeout.\")\n            except subprocess.CalledProcessError as e:\n                raise ValueError(f\"The file could not be downloaded. Error: {e.stderr.decode('utf-8')}\")\n\n        # Use the boto3 library to download the file\n        else:\n\n            # Check if the S3 client is available\n            if not self._client.is_available():\n                raise ValueError(\n                    \"The boto3 library is not installed. Please install the boto3 library before using the S3Downloader class.\"\n                )\n\n            # Download the file using the S3 client\n            self._client.download_file(netloc, path, local_filepath)\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Add a test for this function\n    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of chunks and intervals to workers\n    # TODO: Implement the distribution of"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    if num_workers != worker_env.world_size:\n        raise ValueError(\n            \"The provided `num_workers` doesn't match the current one. \"\n            f\"Found `{num_workers}` instead of `{worker_env.world_size}`.\"\n        )\n    assert worker_env.world_size == num_workers\n\n    # Get the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // num_workers\n    # Get the number of intervals per worker\n    intervals_per_worker = len(intervals_replica) // num_workers\n\n    # Get the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // num_workers\n    # Get the number of intervals per worker\n    intervals_per_worker = len(intervals_replica) // num_workers\n\n    # Get the number of chunks left to assign\n    chunks_left = len(chunks_replica) % num_workers\n    # Get the number of intervals left to assign\n    intervals_left = len(intervals_replica) % num_workers\n\n    # Create a list of workers\n    workers = [w for w in range(num_workers)]\n    # Create a list of chunks\n    chunks = [[] for _ in workers]\n    # Create a list of intervals\n    intervals = [[] for _ in workers]\n\n    # Assign chunks to workers\n    for i, w in enumerate(workers):\n        chunks[w] = chunks_replica[i * chunks_per_worker : (i + 1) * chunks_per_worker]\n        # Assign intervals to workers\n        intervals[w] = intervals_replica[i * intervals_per_worker : (i + 1) * intervals_per_worker]\n\n    # Assign the remaining chunks to the first chunks_left workers\n    for i, w in enumerate(workers[:chunks_left]):\n        chunks[w].extend(chunks_replica[i * chunks_per_worker + len(chunks_replica) - chunks_left :])\n\n    # Assign the remaining intervals to the first intervals_left workers\n    for i, w in enumerate(workers[:intervals_"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Get the number of chunks per worker\n    num_chunks_per_worker = int(np.ceil(len(chunks_replica) / num_workers))\n    # Get the number of intervals per worker\n    num_intervals_per_worker = int(np.ceil(len(intervals_replica) / num_workers))\n    # Get the worker rank\n    worker_rank = worker_env.rank\n\n    # Initialize the dictionaries that will contain the assigned chunks and intervals per worker\n    workers_chunks, workers_intervals = dict(), dict()\n\n    # Iterate over the number of workers\n    for worker_index in range(num_workers):\n        # Get the chunks and intervals for the current worker\n        start_chunk_index = worker_index * num_chunks_per_worker\n        end_chunk_index = start_chunk_index + num_chunks_per_worker\n        chunks_worker = chunks_replica[start_chunk_index:end_chunk_index]\n\n        # Get the intervals for the current worker\n        start_interval_index = worker_index * num_intervals_per_worker\n        end_interval_index = start_interval_index + num_intervals_per_worker\n        intervals_worker = intervals_replica[start_interval_index:end_interval_index]\n\n        # Assign the chunks and intervals to the current worker\n        workers_chunks[worker_index] = chunks_worker\n        workers_intervals[worker_index] = intervals_worker\n\n    # Return the assigned chunks and intervals for each worker\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Determine the number of chunks per worker\n    num_chunks_per_worker = int(len(chunks_replica) / num_workers)\n\n    # Create a dictionary to map worker indices to their assigned chunks\n    workers_chunks: Dict[int, List[int]] = {}\n\n    # Create a dictionary to map worker indices to the intervals corresponding to their assigned chunks\n    workers_intervals: Dict[int, List[int]] = {}\n\n    # For each worker\n    for worker_index in range(num_workers):\n\n        # Get the range of chunk indices assigned to the worker\n        start_index = worker_index * num_chunks_per_worker\n        end_index = start_index + num_chunks_per_worker\n\n        # Add the assigned chunk indices to the workers_chunks dictionary\n        workers_chunks[worker_index] = chunks_replica[start_index:end_index]\n\n        # Get the intervals corresponding to the assigned chunk indices\n        intervals = [\n            (\n                int(interval[0]),\n                int(interval[1]),\n            )\n            for interval in intervals_replica[start_index:end_index]\n        ]\n\n        # Add the intervals to the workers_intervals dictionary\n        workers_intervals[worker_index] = intervals\n\n    # Return the dictionaries\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Get the number of chunks that each worker is assigned to\n    chunks_per_worker = int(np.ceil(len(chunks_replica) / num_workers))\n    chunks_per_worker = int(np.ceil(len(chunks_replica) / num_workers))\n\n    # Get the indices of the chunks that each worker is assigned to\n    chunks_per_worker = int(np.ceil(len(chunks_replica) / num_workers))\n    chunks_per_worker = int(np.ceil(len(chunks_replica) / num_workers))\n    # Get the indices of the chunks that each worker is assigned to\n    worker_chunks = []\n    for i in range(num_workers):\n        start_index = i * chunks_per_worker\n        end_index = start_index + chunks_per_worker\n        worker_chunks.append(chunks_replica[start_index:end_index])\n\n    # Get the intervals corresponding to each worker's assigned chunks\n    worker_intervals = []\n    for worker_chunk in worker_chunks:\n        worker_intervals.append(\n            [\n                interval\n                for chunk_index, interval in enumerate(intervals_replica)\n                if chunk_index in worker_chunk\n            ]\n        )\n    return worker_chunks, worker_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Determine the distribution strategy\n    distribution = \"round_robin\"\n\n    # Initialize the dictionaries to store the assigned chunks and intervals\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Iterate through the workers\n    for worker_index in range(num_workers):\n        # Initialize the chunk and interval lists for the current worker\n        worker_chunks = []\n        worker_intervals = []\n\n        # Iterate through the chunks and intervals\n        for chunk_index, chunk_interval in enumerate(intervals_replica):\n            # Determine the chunk index for the current worker based on the distribution strategy\n            if distribution == \"round_robin\":\n                chunk_index = chunk_index % num_workers\n            elif distribution == \"random\":\n                chunk_index = np.random.randint(0, num_workers)\n\n            # Check if the current worker is assigned to the current chunk\n            if worker_index == chunk_index:\n                # Add the chunk and interval to the worker's list\n                worker_chunks.append(chunks_replica[chunk_index])\n                worker_intervals.append(chunk_interval)\n\n        # Store the worker's assigned chunks and intervals in the dictionaries\n        workers_chunks[worker_index] = worker_chunks\n        workers_intervals[worker_index] = worker_intervals\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # In the case where there are more chunks than workers, the chunks are evenly distributed among the workers.\n    if num_workers >= len(chunks_replica):\n        workers_chunks = [chunks_replica[i : i + num_workers] for i in range(0, len(chunks_replica), num_workers)\n    # In the case where there are fewer chunks than workers, the chunks are distributed among the workers in a round-robin fashion.\n    else:\n        chunks_replica_per_worker = [chunks_replica[i : i + num_workers] for i in range(num_workers)]\n        for i, worker_chunks in enumerate(chunks_replica_per_worker):\n            for chunk_index in worker_chunks:\n                if chunk_index not in chunks_replica:\n                    chunks_replica_per_worker[i].remove(chunk_index)\n                    chunks_replica_per_worker[i + num_workers].append(chunk_index)\n\n        workers_chunks = chunks_replica_per_worker\n\n    # In the case where the number of chunks is a multiple of the world size, the intervals are distributed among the workers in a round-robin fashion.\n    if len(chunks_replica) % num_workers == 0:\n        intervals_per_worker = [\n            intervals_replica[i : i + num_workers] for i in range(0, len(intervals_replica), num_workers]\n    # In the case where the number of chunks is not a multiple of the world size, the intervals are distributed among the workers in a round-robin fashion, but with an additional step of re-arranging the intervals to ensure that each worker has the same number of intervals.\n    else:\n        intervals_replica_per_worker = [\n            intervals_replica[i : i + num_workers] for i in range(num_workers)\n        ]\n        for i, worker_intervals in enumerate(intervals_replica_per_worker):\n            for interval in worker_intervals:\n                if interval[0] not in intervals_replica:\n                    intervals_replica_per_worker[i].remove(interval)\n                    intervals_replica_per_worker[i + num_workers].append(interval)\n        intervals_"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    num_workers = num_workers\n    world_size = worker_env.world_size\n\n    if world_size == 1:\n        # No need to distribute chunks and intervals across workers.\n        return [chunks_replica], [intervals_replica]\n\n    if world_size == 2:\n        # Distribute the chunks and intervals evenly among the two workers.\n        workers_chunks = [\n            chunks_replica[: num_workers // 2],\n            chunks_replica[num_workers // 2 :],\n        ]\n        workers_intervals = [intervals_replica[: num_workers // 2], intervals_replica[num_workers // 2 :]\n        return workers_chunks, workers_intervals\n\n    # If the number of workers is greater than 2, use a more complex distribution strategy.\n    if worker_env.rank == 0:\n        # Assign the first chunk to the first worker.\n        workers_chunks = [chunks_replica[0]]\n        workers_intervals = [intervals_replica[0]]\n\n        # For each subsequent worker, assign the first chunk to the first worker and the last chunk to the last worker.\n        for i in range(1, world_size):\n            workers_chunks.append(chunks_replica[i - 1])\n            workers_intervals.append(intervals_replica[i - 1])\n\n        # For the remaining chunks, distribute them evenly among the remaining workers.\n        remaining_chunks = chunks_replica[1:-1]\n        remaining_intervals = intervals_replica[1:-1]\n        remaining_chunks_per_worker = (\n            len(remaining_chunks) // (world_size - 2)\n        )  # TODO: Round up?\n        remaining_intervals_per_worker = (\n            len(remaining_intervals) // (world_size - 2)\n        )  # TODO: Round up?\n        for i in range(1, world_size):\n            workers_chunks.append(remaining_chunks[i * remaining_chunks_per_worker : (i + 1) * remaining_chunks_per_worker])\n            workers_intervals.append(\n                remaining"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    num_workers = num_workers\n    # num_workers = worker_env.world_size\n\n    # associate chunks to workers\n    workers_chunks = {}\n    for worker_rank in range(num_workers):\n        worker_chunks = []\n        for chunk_index in range(len(chunks_replica)):\n            if worker_rank == 0:\n                worker_chunks.append(chunks_replica[chunk_index])\n        workers_chunks[worker_rank] = worker_chunks\n\n    # associate intervals to workers\n    workers_intervals = {}\n    for worker_rank in range(num_workers):\n        worker_intervals[worker_rank] = []\n        for chunk_index in range(len(chunks_replica)):\n            worker_intervals[worker_rank].append(intervals_replica[chunk_index])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    workers_chunks: Dict[int, List[int]] = {}\n    workers_intervals: Dict[int, List[List[int]]] = {}\n    for i, interval in enumerate(intervals_replica):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        workers_chunks[i % num_workers] = chunks_replica[i]\n        workers_intervals[i % num_workers] = interval\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    num_workers = num_workers\n    world_size = worker_env.world_size\n    # The number of chunks assigned to each worker\n    num_chunks_per_worker = len(chunks_replica) // world_size\n    # The number of intervals assigned to each worker\n    num_intervals_per_worker = len(intervals_replica) // world_size\n    # The chunk and interval indices assigned to each worker\n    workers_chunks = [0] * num_workers\n    workers_intervals = [0] * num_workers\n\n    # Distribute the chunks and intervals among the workers\n    for i in range(num_workers):\n        # Distribute the chunks\n        chunk_indices = [0] * num_chunks_per_worker\n        for j in range(num_chunks_per_worker):\n            chunk_index = chunks_replica[i * num_chunks_per_worker + j]\n            chunk_indices[j] = chunk_index\n        workers_chunks[i] = chunk_indices\n\n        # Distribute the intervals\n        interval_indices = [0] * num_intervals_per_worker\n        for j in range(num_intervals_per_worker):\n            interval = intervals_replica[i * num_intervals_per_worker + j]\n            interval_indices[j] = interval\n        workers_intervals[i] = interval_indices\n\n    # Return the distributed chunks and intervals\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # 1. We associate the chunks and intervals to the workers\n    chunks_to_workers = {}\n    intervals_to_workers = {}\n    for i, chunk_index in enumerate(chunks_replica):\n        chunks_to_workers[chunk_index] = i % num_workers\n        intervals_to_workers[chunk_index] = intervals_replica[i]\n\n    # 2. We get the chunks and intervals associated to the worker\n    chunks_workers = {}\n    intervals_workers = {}\n    for worker_index in range(num_workers):\n        chunks_workers[worker_index] = []\n        intervals_workers[worker_index] = []\n        for chunk_index in chunks_to_workers:\n            if chunks_to_workers[chunk_index] == worker_index:\n                chunks_workers[worker_index].append(chunk_index)\n                intervals_workers[worker_index].append(intervals_to_workers[chunk_index])\n\n    return chunks_workers, intervals_workers\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    workers_chunks = []\n    workers_intervals = []\n\n    for worker_rank in range(num_workers):\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        worker_chunks = []\n        worker_intervals = []\n        for i in range(len(chunks_replica)):\n            if i % num_workers == worker_rank:\n                worker_chunks.append(chunks_replica[i])\n                worker_intervals.append(intervals_replica[i])\n        workers_chunks.append(worker_chunks)\n        workers_intervals.append(worker_intervals)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize two dictionaries to store the assigned chunks and intervals for each worker.\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Iterate over the number of workers.\n    for worker_index in range(num_workers):\n        # Initialize the intervals and chunks for the current worker.\n        intervals = []\n        chunks = []\n\n        # Iterate over the total number of chunks.\n        for i, chunk_index in enumerate(chunks_replica):\n            # Determine the start and end indices of the chunk for the current worker based on the worker's index, the world size, and the total number of chunks.\n            start = i * worker_env.world_size + worker_index\n            end = (i + 1) * worker_env.world_size + worker_index\n\n            # Check if the start index is greater than the end index, which means that the worker's range of chunks is empty.\n            if start > end:\n                continue\n\n            # Append the chunk index and intervals to the corresponding lists for the current worker.\n            chunks.append(chunk_index)\n            intervals.append(intervals_replica[chunk_index])\n\n        # Store the assigned chunks and intervals in the dictionaries for the current worker.\n        workers_chunks[worker_index] = chunks\n        workers_intervals[worker_index] = intervals\n\n    # Return the two dictionaries containing the assigned chunks and intervals for each worker.\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    num_chunks = len(chunks_replica)\n    num_intervals = len(intervals_replica)\n\n    if num_workers == 1:\n        # No need to distribute data across workers.\n        return [chunks_replica], [intervals_replica]\n\n    # Calculate the number of chunks and intervals per worker.\n    num_chunks_per_worker = num_chunks // num_workers\n    num_intervals_per_worker = num_intervals // num_workers\n    if num_chunks_per_worker * num_workers < num_chunks:\n        num_chunks_per_worker += 1\n        num_intervals_per_worker += 1\n\n    # Assign chunks and intervals to each worker.\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n    for i in range(num_workers):\n        # Assign chunks and intervals to the current worker.\n        chunk_index = i * num_chunks_per_worker\n        workers_chunks[i] = chunks_replica[chunk_index : chunk_index + num_chunks_per_worker]\n        workers_intervals[i] = intervals_replica[chunk_index : chunk_index + num_intervals_per_worker]\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Get the worker's index and the world size from the worker environment.\n    worker_rank = worker_env.rank\n    world_size = worker_env.world_size\n\n    # Calculate the number of chunks and intervals per worker, based on the total number of chunks and the world size.\n    chunks_per_worker = num_workers // world_size\n    intervals_per_worker = len(intervals_replica) // world_size\n\n    # Create a dictionary to store the chunks assigned to each worker.\n    chunks_assigned = {}\n\n    # Initialize the first chunk assigned to each worker as the first chunk in chunks_replica.\n    for worker_index in range(num_workers):\n        chunks_assigned[worker_index] = chunks_replica[worker_index]\n\n    # Create a dictionary to store the intervals assigned to each worker.\n    intervals_assigned = {}\n\n    # Initialize the first interval assigned to each worker as the first interval in intervals_replica.\n    for worker_index in range(num_workers):\n        intervals_assigned[worker_index] = intervals_replica[worker_index]\n\n    # Iterate through the remaining chunks and intervals.\n    for index in range(chunks_per_worker):\n        # Get the current chunk and interval.\n        chunk = chunks_replica[index]\n        interval = intervals_replica[index]\n\n        # Calculate the worker index that should be assigned the chunk.\n        worker_index = worker_rank + index * world_size\n\n        # If the worker index is greater than the number of workers, subtract the world size to get the correct worker index.\n        if worker_index >= num_workers:\n            worker_index -= world_size\n\n        # Assign the chunk and interval to the worker.\n        chunks_assigned[worker_index] = chunk\n        intervals_assigned[worker_index] = interval\n\n    # Return the dictionaries containing the assigned chunks and intervals.\n    return chunks_assigned, intervals_assigned\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    assert num_workers > 0\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # Create an empty dictionary to store the chunks assigned to each worker\n    workers_chunks = {}\n\n    # Create an empty dictionary to store the intervals assigned to each worker\n    workers_intervals = {}\n\n    # Get the worker's rank and world size\n    worker_rank = worker_env.rank\n    world_size = worker_env.world_size\n\n    # Calculate the number of chunks and intervals per worker\n    chunks_per_worker = int(len(chunks_replica) / world_size)\n    intervals_per_worker = int(len(intervals_replica) / world_size)\n\n    # Calculate the starting indices for the chunks and intervals for each worker\n    chunks_start_idx = worker_rank * chunks_per_worker\n    intervals_start_idx = worker_rank * intervals_per_worker\n\n    # Assign chunks and intervals to each worker\n    for i in range(chunks_per_worker):\n        workers_chunks[worker_rank] = chunks_replica[chunks_start_idx + i]\n        workers_intervals[worker_rank] = intervals_replica[intervals_start_idx + i]\n\n    # Return the dictionaries\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # create a dictionary to store the mapped chunks for each worker\n    workers_chunks: Dict[int, List[int]] = {}\n\n    # create a dictionary to store the intervals corresponding to each worker's chunks\n    workers_intervals: Dict[int, List[int]] = {}\n\n    # calculate the number of chunks to be assigned to each worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # if there is a remainder, assign the remaining chunks to the first num_workers\n    if len(chunks_replica) % num_workers != 0:\n        num_chunks_per_worker += 1\n\n    # assign the chunks to the workers\n    for i in range(num_workers):\n        workers_chunks[i] = chunks_replica[i * num_chunks_per_worker : (i + 1) * num_chunks_per_worker]\n        workers_intervals[i] = [\n            interval for chunk_interval in intervals_replica for interval in chunk_interval if chunk_interval[0] in workers_chunks[i]\n        ]\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Associate chunks and intervals to workers\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Associate chunks to workers\n    for i in range(num_workers):\n        for chunk_index, chunk_interval in zip(chunks_replica, intervals_replica):\n\n            # Check if the worker is the one to be assigned the chunk\n            if i == worker_env.rank:\n                # Add the chunk to the worker's list of chunks\n                workers_chunks[i].append(chunk_index)\n                # Add the interval to the worker's list of intervals\n                workers_intervals[i].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    num_workers = num_workers\n    num_chunks = len(chunks_replica)\n    num_intervals = len(intervals_replica[0])\n\n    # We use a modulo operator to assign chunks and intervals to workers based on their indices.\n    # The modulo operator is used to distribute the chunks and intervals in a round-robin fashion.\n    # The modulo operator is applied to the worker's index and the world size to get the worker's position in the cycle.\n    chunks_to_workers = {\n        worker_env.rank: chunks_replica[worker_env.rank % num_workers] for worker_env in worker_env\n    }\n\n    # The modulo operator is applied to the worker's index and the world size to get the worker's position in the cycle.\n    # The intervals are assigned to the workers in the same order as the chunks.\n    intervals_to_workers = {\n        worker_env.rank: intervals_replica[worker_env.rank % num_workers] for worker_env in worker_env\n    }\n\n    return chunks_to_workers, intervals_to_workers\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\"):]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\"):]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.lstrip(\"local:\")\n\n        if not os.path.exists(remote_filepath):\n            raise FileNotFoundError(f\"The provided remote_path doesn't exist: {remote_filepath}\")\n\n        if remote_filepath != local_filepath and not os.path.exists(local_filepath):\n            shutil.copy(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.lstrip(\"local:\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        if os.path.exists(local_filepath):\n            return\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        if not os.path.exists(local_filepath):\n            shutil.copy(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        if os.path.exists(local_filepath):\n            return\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not remote_filepath.startswith(\"local:\"):\n            super().download_file(remote_filepath, local_filepath)\n        else:\n            remote_filepath = remote_filepath[6:]\n            local_filepath = local_filepath.replace(self._cache_dir, self._remote_dir)\n            super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        # remove the \"local:\" prefix from the remote_filepath if present\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        # call the superclass's download_file method to download the file from the modified remote file path to the specified local file path\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not local_filepath.startswith(\"local:\"):\n            super().download_file(remote_filepath, local_filepath)\n            return\n\n        local_filepath = local_filepath[6:]\n\n        if not os.path.exists(local_filepath):\n            super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not remote_filepath.startswith(\"local:\"):\n            return super().download_file(remote_filepath, local_filepath)\n\n        # Remove the \"local:\" prefix from the remote_filepath.\n        remote_filepath = remote_filepath[len(\"local:\"):]\n\n        if not os.path.exists(remote_filepath):\n            raise FileNotFoundError(f\"The provided remote_path doesn't exist: {remote_filepath}\")\n\n        if remote_filepath != local_filepath and not os.path.exists(local_filepath):\n            shutil.copy(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        # if \"local:\" in remote_filepath:\n        #     remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        # super().download_file(remote_filepath, local_filepath)\n        #"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not self._cache_dir:\n            return super().download_file(remote_filepath, local_filepath)\n\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        local_cache_path = os.path.join(self._cache_dir, remote_filepath)\n        if not os.path.exists(local_cache_path):\n            super().download_file(remote_filepath, local_cache_path)\n\n        if os.path.exists(local_filepath):\n            return\n\n        shutil.copy(local_cache_path, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not remote_filepath.startswith(\"local:\"):\n            remote_filepath = \"local:\" + remote_filepath\n            super().download_file(remote_filepath, local_filepath)\n        else:\n            remote_filepath = remote_filepath[len(\"local:\"):]\n\n        # If the local file path is a directory, create it if it doesn't exist.\n        if not os.path.isdir(local_filepath):\n            os.makedirs(local_filepath)\n\n        # If the local file path is a file, check if the file is present and if not, download it.\n        if not os.path.isfile(local_filepath):\n            super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not os.path.exists(local_filepath):\n            self.download_file_from_cache(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if not remote_filepath.startswith(\"local:\"):\n            return super().download_file(remote_filepath, local_filepath)\n\n        # remove the \"local:\" prefix\n        remote_filepath = remote_filepath[len(\"local:\"):]\n\n        if not os.path.exists(local_filepath):\n            shutil.copy(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            return self._serialize_pil_image(item)\n        else:\n            raise ValueError(\n                \"Expected PIL.Image.Image, got {}\".format(type(item))\n            )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Extract the image's width, height, and mode.\n        width, height, mode = item.size, item.mode, item.mode\n\n        # If the image is a GIF, then the mode is always \"P\".\n        if isinstance(item, GifImageFile):\n            mode = \"P\"\n\n        # If the image is a JPEG, then the mode is always \"RGB\".\n        elif isinstance(item, JpegImageFile):\n            mode = \"RGB\"\n\n        # If the image is a PNG, then the mode is always \"RGB\".\n        elif isinstance(item, PngImageFile):\n            mode = \"RGB\"\n\n        # If the image is a WebP, then the mode is always \"RGBA\".\n        elif isinstance(item, WebPImageFile):\n            mode = \"RGBA\"\n\n        # If the image is a PPM, then the mode is always \"RGB\".\n        elif item.mode == \"PPM\":\n            mode = \"RGB\"\n\n        # If the image is a TIFF, then the mode is always \"RGB\".\n        elif item.mode == \"TIFF\":\n            mode = \"RGB\"\n\n        # If the image is a BMP, then the mode is always \"RGB\".\n        elif item.mode == \"BMP\":\n            mode = \"RGB\"\n\n        # If the image is a RAW, then the mode is always \"RGB\".\n        elif item.mode == \"RAW\":\n            mode = \"RGB\"\n\n        # If the image is a TGA, then the mode is always \"RGB\".\n        elif item.mode == \"TGA\":\n            mode = \"RGB\"\n\n        # If the image is a XPM, then the mode is always \"RGB\".\n        elif item.mode == \"XPM\":\n            mode = \"RGB\"\n\n        # If the image is a XBM, then the mode is always \"RGB\".\n        elif item.mode == \"XBM\":\n            mode = \"RGB\"\n\n        # If the image is a PGM, then the mode is always \"L\".\n        elif item.mode == \"PGM\":\n            mode = \"L\"\n\n        # If the image is a PPM, then the mode is always \"P\".\n        elif item.mode == \"PPM\":\n            mode ="}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is not available.\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n\n            serialized = f.getvalue()\n\n        return serialized, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # The first 5 bytes of the serialized data are the image's width, height, and mode.\n        # The next 4 bytes are the length of the raw pixel data.\n        # The last n bytes are the raw pixel data.\n\n        # TODO: We should probably add a limit on the size of the image data.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is the image's dimensions, mode, and raw pixel data.\n        #  The serialized data is stored as a bytes object.\n        #  The serialized data is encoded in UTF-8."}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Save to a temporary file\n        with tempfile.NamedTemporaryFile(mode=\"wb\") as f:\n            item.save(f, \"jpeg\")\n            return f.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            return item.tobytes()\n\n        raise TypeError(f\"Can not serialize {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise ValueError(\"The item to be serialized must be a PIL Image object.\")\n\n        # Create a temporary file to write the image to.\n        with tempfile.NamedTemporaryFile(dir=os.getcwd(), suffix=\".jpg\") as f:\n            item.save(f, \"JPEG\")\n\n            # Read the image data from the temporary file.\n            with open(f.name, \"rb\") as f_read:\n                image_data = f_read.read()\n        return image_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            image_mode = item.mode\n            image_size = item.size\n            image_data = item.tobytes()\n            return image_size, image_mode, image_data\n        else:\n            raise TypeError(\"Invalid type for PIL serializer: %s\" % type(item))\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"Expected Image object, got %s\" % type(item))\n\n        # get the mode\n        mode = item.mode\n\n        # get the size\n        size = item.size\n\n        # get the raw data\n        raw = item.tobytes()\n\n        return bytes(size + (mode, raw))\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # PIL Image.save() doesn't work with the BytesIO object\n        # so we use the old-style file object instead\n        with tempfile.NamedTemporaryFile(mode=\"wb\") as f:\n            item.save(f)\n            return f.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Save the image to a memory buffer\n        buffer = io.BytesIO()\n        item.save(buffer)\n\n        # Get the image mode and size\n        mode = item.mode\n        size = item.size\n\n        # Convert the image mode to UTF-8\n        mode = mode.encode(\"utf-8\")\n\n        # Convert the image size to a bytes object\n        size = bytes(size)\n        return buffer.getbuffer().tobytes(), size\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise ValueError(\n                \"Only PIL.Image objects can be serialized. Got type: \"\n                + str(type(item))\n\n        # TODO: Implement a way to serialize the Image.Image mode\n        # TODO: Implement a way to serialize the Image.Image size\n        # TODO: Implement a way to serialize the Image.Image raw pixel data\n\n        # TODO: Implement a way to serialize the Image.Image mode\n        # TODO: Implement a way to serialize the Image.Image size\n        # TODO: Implement a way to serialize the Image.Image raw pixel data\n\n        # TODO: Implement a way to serialize the Image.Image mode\n        # TODO: Implement a way to serialize the Image.Image size\n        # TODO: Implement a way to serialize the Image.Image raw pixel data\n\n        # TODO: Implement a way to serialize the Image.Image mode\n        # TODO: Implement a way to serialize the Image.Image size\n        # TODO: Implement a way to serialize the Image.Image raw pixel data\n\n        return item.tobytes(), None\n\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is not available. Install it to use the PILSerializer.\")\n\n        if isinstance(item, Image.Image):\n            item = item.tobytes()\n\n        return item, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\n                \"The PIL library is required to use the PILSerializer. Please install it with `pip install litdata[PIL]`. See https://github.com/LightningAI/litdata/blob/master/litdata/constants.py#L41 for more information.\"\n            )\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\n                \"The PILSerializer can only serialize PIL Image objects. Got: %r\" % item\n            )\n\n        # PIL's Image.frombytes is used to get the image's mode and dimensions.\n        # The image's pixel data is serialized using the standard Image.tobytes method.\n        return (\n            item.frombytes(item.tobytes()).tobytes(),\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"PIL is not available\")\n        mode = item.mode\n        if mode == \"P\":\n            # convert palette to RGB\n            image_bytes = io.BytesIO()\n            item.save(image_bytes, format=\"RGB\")\n        elif mode == \"L\":\n            # convert to grayscale\n            image_bytes = io.BytesIO()\n            item.convert(\"L\").save(image_bytes, format=\"PNG\")\n        else:\n            image_bytes = io.BytesIO()\n            item.save(image_bytes, format=item.format)\n        return image_bytes.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            width = item.width\n            height = item.height\n            mode = item.mode\n            raw_data = item.tobytes()\n            return (\n                bytes(\n                    [\n                        width,\n                        height,\n                        len(mode),\n                        *mode.encode(\"utf-8\"),\n                        *raw_data,\n                    ]\n                ),\n                None,\n            )\n        else:\n            raise TypeError(\n                \"item must be a PIL Image object, got %r\" % item.__class__.__name__\n            )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is not available\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\"The input must be a PIL Image object\")\n\n        with tempfile.TemporaryFile(\"w+b\") as f:\n            item.save(f)\n\n            # get the image data\n            data = f.getvalue()\n\n            # get the mode\n            mode = item.mode\n\n            # get the dimensions\n            width = item.width\n            height = item.height\n            return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise ValueError(\n                \"The item to serialize must be a PIL Image object, got %s\" % str(type(item))\n            )\n        if item.mode not in (\"F\", \"L\", \"I;16\", \"P\", \"RGB\", \"L\", \"RGBX\", \"RGBA\", \"I\", \"I;16\", \"I;32\", \"I;64\", \"RGBX\", \"RGB\", \"RGBA\"):\n            raise ValueError(\n                \"The image mode must be one of: F, L, I;16, P, RGB, L, RGBX, RGBA, I, I;16, I;32, I;64, RGBX, RGB, RGBA, got %s\"\n                % item.mode\n            )\n        if item.mode == \"I\" and item.size[0] > 4:\n            raise ValueError(\n                \"The image mode I must have a width of 4 or less, got %d\" % item.size[0]\n            )\n        if item.size[0] < 0 or item.size[1] < 0:\n            raise ValueError(\n                \"The image size must be positive, got %s\" % str(item.size)\n            )\n\n        # https://github.com/python-pillow/pillow/issues/2360\n        if item.size[0] > 8191:\n            raise ValueError(\n                \"The image width must be less than 8192, got %d\" % item.size[0]\n            )\n        if item.size[1] > 8191:\n            raise ValueError(\n                \"The image height must be less than 8192, got %d\" % item.size[1]\n            )\n\n        # https://github.com/python-pillow/pillow/issues/2360\n        if item.size[0] > 8191 and item.mode != \"L\":\n            raise ValueError(\n                \"The image width must be less than 8192 for mode %s, got %d\"\n                % (item.mode,"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ValueError(\"PIL is not available\")\n\n        if not isinstance(item, Image.Image):\n            raise ValueError(\"item must be a PIL Image object\")\n\n        mode = item.mode\n        if mode not in (\"L\", \"RGB\", \"RGBA\"):\n            raise ValueError(\n                \"item must be a PIL Image object with a mode of L, RGB, or RGBA\"\n            )\n\n        size = item.size\n        width, height = size\n        size = (width, height)\n        size = (\n            (size[0], size[1],)\n            if isinstance(size, tuple)\n            else (size[0],)\n        )\n\n        if item.mode == \"L\":\n            mode = \"L;\"\n        else:\n            mode = \"RGB;\"\n\n        with io.BytesIO() as f:\n            item.save(f, format=mode)\n            f.seek(0)\n            data = f.read()\n            return (data, None)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\n                \"Can't serialize a non-Image object. \"\n                + \"Please use a PIL Image object instead.\"\n            )\n\n        mode = item.mode\n        size = item.size\n        data = item.tobytes()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.tobytes()\n\n        return decode_jpeg(item).encode()\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            return decode_jpeg(pil_to_tensor(item)).tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.tobytes(), None\n        else:\n            return decode_jpeg(item).tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.fp.read(), None\n        else:\n            return decode_jpeg(item).tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            return decode_jpeg(item).encode()\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                raw = f.read()\n        else:\n            raw = item.tobytes()\n        return raw, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            return JpegImageFile.save_as_binary_data(item), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.tobytes()\n\n        return decode_jpeg(item).tobytes()\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename:\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.fp.read(), None\n        elif isinstance(item, Image):\n            return decode_jpeg(item.tobytes()).tobytes(), None\n        else:\n            raise TypeError(\"Unsupported image type\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            return item.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with tempfile.TemporaryFile() as f:\n                item.save(f)\n                return f.read(), None\n        else:\n            return decode_jpeg(item).tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n\n        else:\n            return decode_jpeg(item).tobytes()\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.fp.read(), None\n\n        if not isinstance(item, Image):\n            raise TypeError(\"item must be an instance of Image or its subclass\")\n\n        return decode_jpeg(item).tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with io.BytesIO(item.fp.read()) as f:\n                return f.getvalue(), None\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\"Only PIL Image.Image objects are supported.\")\n\n        return item.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with tempfile.NamedTemporaryFile() as fp:\n                item.save(fp)\n                fp.seek(0)\n                data = fp.read()\n                fp.close()\n        else:\n            data = decode_jpeg(item)\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with tempfile.TemporaryDirectory() as temp_dir:\n                with tempfile.NamedTemporaryFile(dir=temp_dir, prefix=\"img\", suffix=\".jpg\") as fp:\n                    item.save(fp, format=\"JPEG\")\n                    fp.seek(0)\n                    return fp.read(), None\n        else:\n            return decode_jpeg(item).tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as fp:\n                return fp.read(), None\n\n        # TODO: PIL 8-bit grayscale images\n        # TODO: PIL.Image.fromarray\n        # TODO: PIL.Image.fromarray(np.uint8)\n        # TODO: PIL.Image.fromarray(np.uint8, mode='L')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='L')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='L')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO: PIL.Image.fromarray(np.uint8, mode='P')\n        # TODO:"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with item.fp as fp:\n                return decode_jpeg(fp), None\n\n        if isinstance(item, Image.Image):\n            with tempfile.NamedTemporaryFile(mode=\"wb\") as fp:\n                item.save(fp, format=\"JPEG\")\n                return decode_jpeg(fp.name), None\n        else:\n            raise TypeError(\"Unsupported image type\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.fp.read(), None\n\n        return self._serialize_image(item, \"JPEG\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.fp.read(), None\n\n        # https://github.com/pytorch/vision/issues/685\n        # TODO: remove once this is fixed\n        if isinstance(item, Image.Image):\n            # PIL.Image.Image.tobytes() is broken, so we use PIL.JpegImagePlugin.encode_to_fp()\n            with tempfile.TemporaryFile(\"wb\") as fp:\n                JpegImageFile.encode_to_fp(item, fp)\n                return fp.getvalue(), None\n\n        return item.to_bytes(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_len = np.frombuffer(data[:12], dtype=np.uint32)\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        if mode == \"L\":\n            return Image.frombytes(mode, (int(width), int(height)), \"L\"\n        elif mode == \"P\":\n            return Image.frombytes(mode, (int(width), int(height)), \"P\"\n        elif mode == \"RGB\":\n            return Image.frombytes(mode, (int(width), int(height)), \"RGB\"\n        elif mode == \"RGBA\":\n            return Image.frombytes(mode, (int(width), int(height)), \"RGBA\"\n        elif mode == \"I;16\":\n            return Image.frombytes(mode, (int(width), int(height)), \"I;16\"\n        elif mode == \"I;16L\":\n            return Image.frombytes(mode, (int(width), int(height)), \"I;16L\"\n        elif mode == \"RGBX\":\n            return Image.frombytes(mode, (int(width), int(height)), \"RGBX\"\n        elif mode == \"RGBAX\":\n            return Image.frombytes(mode, (int(width), int(height)), \"RGBAX\"\n        elif mode == \"I;16;1\":\n            return Image.frombytes(mode, (int(width), int(height)), \"I;16;1\"\n        elif mode == \"I;16;L\":\n            return Image.frombytes(mode, (int(width), int(height)), \"I;16;L\"\n        elif mode == \"RGBX;1\":\n            return Image.frombytes(mode, (int(width), int(height)), \"RGBX;1\"\n        elif mode == \"RGBAX;1\":\n            return Image.frombytes(mode, (int(width), int(height)), \"RGBAX;1\"\n        elif mode == \"I;16;1;1\":\n            return Image.frombytes(mode, (int"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_len = map(int, np.frombuffer(data[:12], np.uint32))\n        mode = data[12:12 + mode_len]\n        raw_data = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw_data)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width = ints[0]\n        height = ints[1]\n        mode = data[12:12 + ints[2]]\n        raw = data[12 + ints[2] :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], dtype=np.uint32)\n        mode = data[12 : 12 + mode_size]\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        int_size = 12\n        mode = data[int_size : int_size + 3].decode(\"utf-8\")\n        raw = data[int_size + 3 :]\n\n        if mode in (\"L\", \"I\", \"F\"):\n            return Image.frombuffer(raw, (len(raw) // 1, 1), mode\n        elif mode in (\"RGB\", \"P\"):\n            return Image.frombuffer(raw, (len(raw) // 3, 1), mode\n        elif mode in (\"RGBA\", \"P\"):\n            return Image.frombuffer(raw, (len(raw) // 4, 1), mode\n        elif mode in (\"I;16\", \"F;16\"):\n            return Image.frombuffer(raw, (len(raw) // 2, 1), mode\n        elif mode in (\"I;32\", \"F;32\"):\n            return Image.frombuffer(raw, (len(raw) // 4, 1), mode\n        elif mode in (\"I;64\", \"F;64\"):\n            return Image.frombuffer(raw, (len(raw) // 8, 1), mode\n        elif mode in (\"I;16L\", \"F;16L\"):\n            return Image.frombuffer(raw, (len(raw) // 2, 1), mode\n        elif mode in (\"I;32L\", \"F;32L\"):\n            return Image.frombuffer(raw, (len(raw) // 4, 1), mode\n        elif mode in (\"I;64L\", \"F;64L\"):\n            return Image.frombuffer(raw, (len(raw) // 8, 1), mode\n        elif mode in (\"I;16B\", \"F;16B\"):\n            return Image.frombuffer(raw, (len(raw) // 2, 1), mode\n        elif mode in (\"I;32B\", \"F;32B\"):\n            return Image.frombuffer(raw, (len(raw) // 4, 1), mode\n        elif mode in (\"I;64B\", \"F;64B\"):"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_len = np.frombuffer(data[0:12], dtype=np.uint32)\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        return Image.frombytes(mode, (width, height), data[12 + mode_len:])\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_length = np.frombuffer(data[:12], np.uint32)\n        mode = data[12:12 + mode_length]\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_len = np.frombuffer(data, dtype=np.uint32, count=3)\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        return Image.frombytes(mode, (width, height), data[12 + mode_len:])\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12:12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        if mode in _TORCH_DTYPES_MAPPING:\n            dtype = _TORCH_DTYPES_MAPPING[mode]\n        else:\n            dtype = _NUMPY_DTYPES_MAPPING[mode]\n\n        if dtype == np.uint8:\n            return Image.fromarray(np.frombuffer(raw, dtype=np.uint8), mode)\n\n        return Image.frombuffer(raw, (width, height), mode)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if _PIL_AVAILABLE:\n            width_int, height_int, mode_len = np.frombuffer(data[:12], dtype=np.uint32)\n            mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n            raw = data[12 + mode_len :]\n            return Image.frombytes(mode, (int(width_int), int(height_int)), mode\n        else:\n            raise RuntimeError(\"PIL is not installed.\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        # Extract the width, height, and mode from the data.\n        width, height, mode_len = np.frombuffer(data, dtype=np.uint32, count=3, offset=0)\n        mode = data[3 * 4:3 * 4 + mode_len].decode(\"utf-8\")\n\n        # Extract the raw image data from the data.\n        raw_data = data[3 * 4 + mode_len:]\n\n        # Construct the image from the width, height, mode, and raw image data.\n        if mode == \"L\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"F\", 0, -1)\n        elif mode == \"RGB\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"F\", 0, -1)\n        elif mode == \"RGBA\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"F\", 0, -1)\n\n        # If the image mode is not supported, return None.\n        return None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32)\n        width = ints[0]\n        height = ints[1]\n        mode = ints[2]\n        if len(mode) != len(ints[2]):\n            raise ValueError(\"Invalid mode length.\")\n        mode = mode.tobytes()\n\n        if mode.decode(\"utf-8\") in _TORCH_DTYPES_MAPPING:\n            dtype = _TORCH_DTYPES_MAPPING[mode.decode(\"utf-8\")]\n        elif mode.decode(\"utf-8\") in _NUMPY_DTYPES_MAPPING:\n            dtype = _NUMPY_DTYPES_MAPPING[mode.decode(\"utf-8\")]\n        else:\n            raise ValueError(f\"Invalid mode {mode}.\")\n\n        return Image.frombytes(mode, (width, height), data[12 + len(mode) :], \"raw\", dtype)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data, np.uint32, 3)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[16:]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        # pylint: disable=no-member\n\n        if _PIL_AVAILABLE:\n            width, height, mode_len = np.frombuffer(data[:12], np.uint32)\n            mode = data[12:12 + mode_len].decode(\"utf-8\")\n            raw = data[12 + mode_len :]\n\n            return Image.frombytes(mode, (width, height), raw)\n        else:\n            raise Exception(\n                \"Cannot deserialize PIL image: PIL not available. \"\n                \"Install PIL to use PILSerializer.\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        # Extract the width, height, and mode from the beginning of the data.\n        width_int = int.from_bytes(data[:4], \"big\")\n        height_int = int.from_bytes(data[4:8], \"big\")\n        mode_size_int = int.from_bytes(data[8:12], \"big\")\n        mode_str = data[12:12 + mode_size_int]\n        raw = data[12 + mode_size_int :]\n        # Reconstruct the image from the raw data.\n        if mode_str == \"L\":\n            return Image.frombytes(mode_str, \"RGB\", raw)\n        else:\n            return Image.frombytes(mode_str, \"RGBA\", raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, np.uint32, 3)\n        width, height, mode_size = ints.tolist()\n        mode = data[12 : 12 + mode_size]\n        data = data[12 + mode_size :]\n\n        if mode.decode(\"utf-8\") == \"L\":\n            return Image.frombytes(\"L\", (width, height), data)\n        elif mode.decode(\"utf-8\") == \"RGB\":\n            return Image.frombytes(\"RGB\", (width, height), data)\n\n        raise Exception(\n            \"This image mode is not supported: {}\".format(mode.decode(\"utf-8\"))\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        # extract the width, height, and mode from the beginning of the stream\n        width, height, mode_size = np.frombuffer(data, np.uint32, 3)\n        mode = data[12:12 + mode_size].decode(\"utf-8\")\n        # skip the mode string\n        data = data[12 + mode_size:]\n\n        # reconstruct the image from the raw data\n        if mode in [\"P\", \"L\", \"I\"]:\n            return Image.frombytes(mode, (width, height), data)\n        elif mode == \"F\":\n            return Image.frombytes(mode, (width, height), data, \"F\")\n        elif mode == \"1\":\n            return Image.frombytes(mode, (width, height), data, \"I;1\")\n        elif mode == \"RGBX\":\n            return Image.frombytes(mode, (width, height), data, \"I\")\n        elif mode == \"RGBA\":\n            return Image.frombytes(mode, (width, height), data, \"I;L\")\n        elif mode == \"RGB\":\n            return Image.frombytes(mode, (width, height), data, \"I;L\")\n        elif mode == \"A\":\n            return Image.frombytes(mode, (width, height), data, \"I;L\")\n        else:\n            return Image.frombytes(mode, (width, height), data, \"raw\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw_data = data[12 + mode_size :]\n\n        if mode.lower() in [\"gif\", \"png\", \"webp\"]:\n            # TODO: implement the ability to handle these types\n            raise NotImplementedError(f\"Cannot deserialize PIL images with mode '{mode}'\")\n\n        if mode.lower() == \"l\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;1\")\n\n        elif mode.lower() == \"p\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;P\")\n\n        elif mode.lower() == \"1\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;1\")\n\n        elif mode.lower() == \"I;1\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;1\")\n\n        elif mode.lower() == \"F\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"F;1\")\n\n        elif mode.lower() == \"F;1\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"F;1\")\n\n        elif mode.lower() == \"I;P\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;P\")\n\n        elif mode.lower() == \"RGB\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;P\")\n\n        elif mode.lower() == \"RGBA\":\n            return Image.frombytes(mode, (width, height), raw_data, \"raw\", \"I;P\")\n\n        else:\n            raise NotImplementedError(f\"Cannot deserialize PIL images with mode '{mode}'\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if _PIL_AVAILABLE is not None and _PIL_AVAILABLE.is_available():\n            width, height, mode_size = np.frombuffer(data[:12], dtype=np.uint32)\n            mode = data[12:12 + mode_size].decode(\"utf-8\")\n            raw_data = data[12 + mode_size :]\n\n            if mode == \"RGB\" or mode == \"L\" or mode == \"I\":\n                return Image.frombytes(mode, (width, height), raw_data)\n\n            if mode == \"P\":\n                return Image.frombytes(\n                    mode, (width, height), raw_data, \"raw\", \"LSB\", 0, -1\n                )\n\n            if mode == \"RGBA\":\n                return Image.frombytes(\n                    mode, (width, height), raw_data, \"raw\", \"MSB\", 0, -1\n                )\n\n        raise NotImplementedError\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n\n        if Image is None:\n            raise RuntimeError(\"PIL is not installed, cannot deserialize PIL image\")\n\n        return Image.frombytes(mode, (int(width), int(height)), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], dtype=np.uint32)\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n\n        shape = []\n        idx = 4\n        shape_len = np.frombuffer(data[idx:idx + 4], dtype=np.uint32)\n        idx += 4\n        for _ in range(shape_len):\n            shape.append(np.frombuffer(data[idx:idx + 4], dtype=np.uint32))\n            idx += 4\n\n        return torch.frombuffer(data[idx:], dtype=dtype, layout=\"NCHW\", device=\"cpu\").view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice[0]]\n        shape = np.frombuffer(data[4:8], dtype=np.uint32)\n        data = data[8:]\n        return torch.frombuffer(data, dtype=dtype, shape=tuple(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = int.from_bytes(data[4:8], \"little\")\n        shape = []\n        for i in range(shape_size):\n            shape.append(int.from_bytes(data[8 + i * 4:12 + i * 4], \"little\"))\n        data = np.frombuffer(data[12 + shape_size * 4 :], dtype=dtype)\n        return torch.from_numpy(data.reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32)[0]\n        shape_size = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = [np.frombuffer(data[8 + i * 4:8 + (i + 1) * 4], np.uint32)[0] for i in range(shape_size)]\n        data = data[8 + shape_size * 4 :]\n        return torch.frombuffer(data, dtype=_TORCH_DTYPES_MAPPING[dtype_indice], device=\"cpu\").view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], dtype=np.uint32)[0]\n        shape_size = np.frombuffer(data[4:8], dtype=np.uint32)[0]\n        data = data[8:]\n        shape = [np.frombuffer(data[i : i + 4], dtype=np.uint32) for i in range(8, 8 + 4 * shape_size, 4)]\n        return torch.frombuffer(data[4 * shape_size :], dtype=torch.dtype(dtype_indice), shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n\n        shape_len = int.from_bytes(data[4:8], \"little\")\n        shape = [int.from_bytes(data[8 + i * 4 : 8 + (i + 1) * 4] for i in range(shape_len)]\n        return torch.frombuffer(data[8 + shape_len * 4 :], dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32)[0]\n        shape_size = np.frombuffer(data[4:8], np.uint32)[0]\n        data = data[8:]\n        shape = []\n        for i in range(shape_size):\n            shape.append(np.frombuffer(data[4 * i : 4 * (i + 1)], np.uint32)[0])\n            data = data[4 * i + 4 :]\n\n        return torch.frombuffer(data, dtype=_TORCH_DTYPES_MAPPING[dtype_indice]).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[0:4], \"little\")\n        data = data[4:]\n        shape_length = int.from_bytes(data[0:4], \"little\")\n        data = data[4:]\n        shape = [int.from_bytes(data[i : i + 4] for i in range(0, 4 * shape_length, 4)]\n        data = data[4 * shape_length :]\n        return torch.frombuffer(data, _TORCH_DTYPES_MAPPING[dtype_indice], shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = int.from_bytes(data[4:8], \"little\")\n        shape = []\n        for i in range(shape_size):\n            shape.append(int.from_bytes(data[8 + 4 * i : 8 + 4 * (i + 1)], \"little\"))\n        data = data[8 + 4 * shape_size :]\n\n        return torch.frombuffer(data, dtype=dtype, layout=torch.strided, device=\"cpu\").reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape = []\n        idx = 4\n        while idx < len(data):\n            shape.append(np.frombuffer(data[idx:idx + 4], np.uint32)[0])\n            idx += 4\n        size = np.prod(shape)\n        data = np.frombuffer(data[idx : idx + size * dtype.itemsize], dtype=dtype)\n        return torch.from_numpy(data).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], dtype=np.uint32)[0]\n        shape_size = np.frombuffer(data[4:8], dtype=np.uint32)[0]\n        data_start = 8\n        data_end = data_start + shape_size * 4\n        shape = [np.frombuffer(data[data_start:data_end], dtype=np.uint32).tolist()]\n        data_start = data_end\n        return torch.frombuffer(data[data_start:], dtype=_TORCH_DTYPES_MAPPING[dtype_indice], shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], dtype=np.uint32)\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice.item()]\n        shape_size = np.frombuffer(data[4:8], dtype=np.uint32)\n        shape = [np.frombuffer(data[8:8 + 4 * s, dtype=np.uint32) for s in shape_size]\n        data = np.frombuffer(data[8 + 4 * shape_size.item() :], dtype=dtype)\n        return torch.from_numpy(data).view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], dtype=np.uint32)\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice[0]]\n\n        n_dims = np.frombuffer(data[4:8], dtype=np.uint32)\n        shape = np.frombuffer(data[8:], dtype=np.uint32)\n\n        return torch.frombuffer(data[12:], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape = []\n        idx = 4\n        shape_size = np.frombuffer(data[idx:idx + 4], np.uint32)[0]\n        idx += 4\n        for _ in range(shape_size):\n            shape.append(np.frombuffer(data[idx:idx + 4], np.uint32)[0])\n            idx += 4\n        data = np.frombuffer(data[idx:], dtype)\n        return torch.from_numpy(data).to(dtype).view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice, *dims_bytes = data\n        dtype = _TORCH_DTYPES_MAPPING[self._dtype_to_indices[dtype_indice[0]]]\n        shape = [int.from_bytes(dim, \"little\") for dim in dims_bytes]\n        return torch.frombuffer(data[4:], dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice, dtype_size = np.frombuffer(data[:4], np.uint32)\n        shape_size = np.frombuffer(data[4:8], np.uint32)\n        shape = [int.from_bytes(data[8 + i : 8 + i + 4], \"big\") for i in range(shape_size)]\n        data = data[8 + 4 * shape_size :]\n        return torch.frombuffer(data, _TORCH_DTYPES_MAPPING[dtype_indice]).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice[0]]\n        data = data[4:]\n\n        shape_len = np.frombuffer(data[:4], dtype=np.uint32)\n        shape = [int.from_bytes(x, \"little\") for x in data[4:-1:shape_len]]\n        data = data[-1:]\n\n        return torch.frombuffer(data, dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n\n        # extract shape information\n        idx = 4\n        shape = []\n        n_dims = np.frombuffer(data[idx:idx + 4], np.uint32)[0]\n        idx += 4\n        for _ in range(n_dims):\n            shape.append(np.frombuffer(data[idx:idx + 4], np.uint32)[0])\n            idx += 4\n\n        # extract raw data\n        data = np.frombuffer(data[idx:], dtype)\n        return torch.from_numpy(data).to(dtype=dtype, device=\"cpu\")\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = int.from_bytes(data[:4], \"little\")\n        shape_len = int.from_bytes(data[4:8], \"little\")\n        data_len = len(data) - 8\n        shape = [int.from_bytes(data[8 + i * 4 : 8 + (i + 1) * 4], \"little\") for i in range(shape_len)]\n        data = data[8 + shape_len * 4 :]\n\n        return torch.frombuffer(data, _TORCH_DTYPES_MAPPING[dtype_indice])\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], dtype=np.uint32)\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice[0]]\n        dim_len = np.frombuffer(data[4:8], dtype=np.uint32)\n        dim_size = [np.frombuffer(data[8 + i * 4 : 8 + (i + 1) * 4], dtype=np.uint32) for i in range(dim_len)]\n        return torch.frombuffer(data[8 + 4 * dim_len :], dtype=dtype).reshape(dim_size)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        return self._serialize_tensor(item)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape_bytes = np.array(item.shape, dtype=np.int64).tobytes()\n        data = item.tobytes()\n        return dtype_index + shape_bytes + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        return dtype.tobytes() + item.tobytes()\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n        return np.array([dtype, shape], dtype=np.int32).tobytes() + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not item.is_cuda():\n            dtype = self._dtype_to_indices[item.dtype]\n            shape = item.size()\n            data = item.tobytes()\n            return dtype.tobytes() + shape.tobytes() + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.numpy()\n        return dtype.tobytes() + b\"_\" + b\"\".join(map(np.iinfo(np.int32).to_bytes, shape) + data.tobytes())\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(\n                \"The provided item should be of type torch.Tensor. Found {}\".format(type(item))\n            )\n\n        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n\n        return np.array([dtype, shape[0], shape[1], shape[2], shape[3]], dtype=np.int32).tobytes() + data\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype, shape, data = item.dtype, item.shape, item.data\n        dtype = self._dtype_to_indices[dtype]\n        shape = [int(s) for s in shape]\n        return dtype.tobytes(), np.array([*shape, len(data)]).tobytes() + data.tobytes()  # pyright: ignore\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        return dtype_idx.tobytes() + b\"\".join(\n            torch.as_strided(item.data_ptr, (item.size(),), (item.stride(0), 1)\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        dtype_name = self._dtype_to_indices[dtype]\n        shape = item.shape\n        data = item.numpy().tobytes()\n        return dtype_name.tobytes() + b\"\\x00\" + shape.tobytes() + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not self.can_serialize(item):\n            raise TypeError(\n                \"The provided item is not a tensor. Please use a tensor serializer for this item.\"\n            )\n        return self.serialize_tensor(item)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        return (\n            torch.as_tensor(self._serialize_tensor_data(item),\n            None)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # 1. dtype\n        dtype = item.dtype\n        dtype_index = self._dtype_to_indices[dtype]\n\n        # 2. shape\n        shape = item.shape\n        shape_bytes = b\"\"\n        for s in shape:\n            shape_bytes += np.array(s, dtype=np.int64).tobytes()\n\n        # 3. data\n        data_bytes = item.tobytes()\n        return bytes(dtype_index) + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.data.tobytes()\n        return np.array([dtype_index, len(shape), len(data)]).tobytes() + item.shape_as_tuple() + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_id = self._dtype_to_indices.get(item.dtype)\n        if dtype_id is None:\n            raise TypeError(\n                f\"The provided dtype {item.dtype} is not supported. Supported dtypes are {list(self._dtype_to_indices.keys())}.\"\n            )\n        # TODO: this can be improved by using a more efficient serialization method\n        return (\n            (dtype_id, item.shape) + tuple(item.to(torch.int64).flatten().tolist()),\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw_data = item.cpu().numpy()\n        return (\n            (self._dtype_to_indices[dtype], shape, raw_data.tobytes()),\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if item.dtype is not torch.uint8:\n            raise ValueError(\n                \"The provided tensor's dtype is not uint8. \"\n                \"You can use a different serializer if you want to serialize tensors of different types.\"\n            )\n        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.tobytes()\n\n        return (dtype, shape, data), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # We don't need to serialize the tensor's device, because it is not part of the data, and\n        # the tensor will be reconstructed on the same device as the serialization context.\n        # We also don't need to serialize the tensor's layout, because the layout is not part of the\n        # data and is not preserved across serialization.\n        dtype_idx = self._dtype_to_indices[item.dtype]\n        size = item.shape\n        data = item.data_ptr()\n        return (\n            torch.IntTensor([dtype_idx, size[0], size[1], size[2]]).to_bytes(4, byteorder=\"little\"),\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.cpu().numpy()\n\n        if dtype == 0:\n            return data.tobytes(), None\n\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.h\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L124-L133\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L221-L229\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L495-L501\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L865-L869\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L875-L881\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L234-L239\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L245-L252\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L370-L376\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L258-L262\n        # https://github.com/pytorch/pytorch/blob/master/torch/csrc/autograd/serialization.cpp#L380-L387\n        # https://github.com/pytorch/pytorch/blob"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not torch.is_tensor(item):\n            raise TypeError(\n                f\"The provided item should be of type {torch.Tensor}. Found {type(item)}.\"\n            )\n        dtype = item.dtype.name\n        if dtype not in self._dtype_to_indices:\n            raise TypeError(\n                f\"The provided item should be of a torch.Tensor with a valid datatype. Found {dtype}. \"\n                \"Valid datatypes are: \"\n                + \", \".join(self._dtype_to_indices.keys())\n            )\n\n        # TODO: remove this once https://github.com/pytorch/pytorch/issues/95745 is fixed\n        if item.device.type == \"cuda\":\n            item = item.to(\"cpu\")\n\n        shape = item.shape\n        raw_data = item.tobytes()\n\n        return np.array([self._dtype_to_indices[dtype], *shape], np.uint32).tobytes() + raw_data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:  # pyright: ignore\n                pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n\n        raise TypeError(\"The given data is not a valid JPEG image.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is required to deserialize JPEGs.\")\n        else:\n            return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        # fallback to PIL\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n\n        raise ValueError(\"Can't deserialize the data.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:\n                pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n        else:\n            raise ValueError(\n                \"The library PIL is required to deserialize the given data. Please install it with: pip install -U pillow\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        if isinstance(data, Image.Image):\n            return data\n\n        if isinstance(data, PngImageFile):\n            raise TypeError(f\"The provided data is of type {PngImageFile}.\")\n\n        if isinstance(data, WebPImageFile):\n            raise TypeError(f\"The provided data is of type {WebPImageFile}.\")\n\n        if isinstance(data, GifImageFile):\n            raise TypeError(f\"The provided data is of type {GifImageFile}.\")\n\n        return JpegImageFile(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:  # pylint: disable=bare-except\n                pass\n\n        if _PIL_AVAILABLE:\n            image = JpegImageFile.getdecoder()._from_bytes(data)\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(image)\n            else:\n                return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except (ValueError, AttributeError):\n                pass\n            finally:\n                pass\n\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:\n                pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n\n        raise ImportError(\"Neither PIL nor PyTorch's torchvision is available.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # try to decode the data as a JPEG\n                jpeg_image = decode_jpeg(data)\n                # if the data can be decoded as a JPEG, return the decoded image\n                if jpeg_image is not None:\n                    return jpeg_image\n                else:\n                    # if the data cannot be decoded as a JPEG, fall back to using PIL to deserialize the data\n                    return pil_to_tensor(Image.open(io.BytesIO(data)))\n            except (RuntimeError, ValueError):\n                # if the data cannot be decoded as a JPEG, fall back to using PIL to deserialize the data\n                return Image.open(io.BytesIO(data))\n        else:\n            # if torchvision is not available, use PIL to deserialize the data\n            return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:  # pyright: ignore\n                pass\n        if _PIL_AVAILABLE:\n            return PILSerializer().deserialize(data)\n        else:\n            raise RuntimeError(\n                \"You can't deserialize the JPEG image without PIL. Please install PIL.\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:\n                pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer().deserialize(data)\n\n        raise RuntimeError(\n            \"The given image data cannot be deserialized. \"\n            \"HINTS: 1. Make sure that the image data is a JPEG image. \"\n            \"2. If the image is a JPEG, make sure that PyTorch's torchvision is installed.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:  # pyright: ignore\n                pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n\n        raise ImportError(\n            \"The image data can't be deserialized due to missing PIL and PyTorch's torchvision. Please install either one of them.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                # if the decoding fails, fall back to using PIL\n                pass\n        if _PIL_AVAILABLE:\n            image = Image.open(io.BytesIO(data))\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(image)\n            return image\n        raise ValueError(\n            \"The data cannot be deserialized. PyTorch's torchvision is not available. \"\n            \"If the data is a JPEG, you can install torchvision to get a torch.Tensor. \"\n            \"If the data is a PIL image, you can install PIL to get a PIL.Image.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass  # fall back to PIL\n        if _PIL_AVAILABLE:\n            img = Image.open(io.BytesIO(data))\n            if isinstance(img, JpegImageFile):\n                return img\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(img)\n\n        raise TypeError(\n            \"The provided data is not a JPEG image. Please use the JPEGSerializer for JPEG images.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            # Try to decode the data as JPEG image.\n            try:\n                return decode_jpeg(data)\n            except Exception:\n                # Decoding as JPEG failed, try to decode as PIL image.\n                pass\n\n        # Fallback to PIL image.\n        img = Image.open(io.BytesIO(data))\n        if _PIL_AVAILABLE:\n            if _AV_AVAILABLE:\n                # If AV is available, convert to AV image.\n                return AVSerializer().deserialize(img)\n            else:\n                # If AV is not available, just return PIL image.\n                return img\n        else:\n            # If PIL is not available, convert to PyTorch tensor.\n            return pil_to_tensor(img)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:  # pylint: disable=bare-except\n                pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer().deserialize(data)\n\n        raise TypeError(\"Cannot deserialize the data as the PIL and torchvision packages are not installed.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except (ValueError, RuntimeError) as e:\n                pass\n\n        if _PIL_AVAILABLE:\n            img = PILSerializer().deserialize(data)\n            if isinstance(img, Image.Image) and not isinstance(img, (PngImageFile, WebPImageFile, GifImageFile)):\n                return img\n            else:\n                raise TypeError(\n                    \"The data provided is not a JPEG image. \"\n                    \"HINT: The data is actually a PNG or WebP image with a JPEG extension.\"\n                )\n        else:\n            raise TypeError(\n                \"The JPEG image cannot be deserialized. \"\n                \"HINT: You need to install the Pillow package by running `pip install Pillow`.\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except (ValueError, TypeError):\n                pass\n        if isinstance(data, JpegImageFile):\n            return data\n        elif _PIL_AVAILABLE:\n            return Image.open(io.BytesIO(data))\n        else:\n            raise RuntimeError(\"Unable to deserialize image. No Pillow and torchvision available.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except Exception:\n                pass\n\n        if _PIL_AVAILABLE:\n            return Image.open(io.BytesIO(data))\n\n        raise RuntimeError(\n            \"The provided image data cannot be deserialized. The data is not a valid JPEG image and the required library for deserializing is not installed.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        data_type_index = self._dtype_to_indices[self._dtype]\n        return data, f\"no_header_tensor:{data_type_index}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        data_type = self._dtype\n        return data, f\"no_header_tensor:{data_type.value}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype = self._dtype\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{dtype.value}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype.value}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"You must call setup() first\")\n        data = item.numpy()\n        data_type = self._dtype\n        dtype_indice = self._dtype_to_indices[data_type]\n        return data.tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype = self._dtype\n\n        # If the tensor's data type is not compatible with the specified data format, the data type is converted to a compatible one.\n        if not dtype.is_compatible_with(item.dtype):\n            item = item.to(dtype)\n\n        # The tensor's data is converted to a NumPy array and then to bytes.\n        data = item.numpy().tobytes(order=\"C\")\n\n        # The tensor's data type is mapped to an index, which is included in the returned string.\n        dtype_indice = self._dtype_to_indices[dtype]\n\n        # The serialized tensor data is returned as bytes, and the tensor's data type is returned as a string.\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\n                \"The dtype has not been set. Please call setup with the data_format argument before serializing the tensor.\"\n            )\n\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = np.frombuffer(item.numpy(), dtype=self._dtype)\n        return data.tobytes(order=\"C\"), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype = self._dtype\n        if dtype is None:\n            raise ValueError(\"The data_format must be specified in the setup method before serializing.\")\n        if dtype != item.dtype:\n            raise TypeError(\n                f\"The data type of the tensor ({item.dtype}) is not the same as the specified data format ({dtype}).\"\n            )\n\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype = self._dtype\n        data = item.to(dtype).tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        if dtype is None:\n            raise ValueError(\"You must specify the data type in the data_format argument.\")\n        return torch.frombuffer(data, dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        if not dtype:\n            raise RuntimeError(\"No data type is defined for the NoHeaderTensorSerializer. Please call setup first.\")\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer must have a predefined data type.\")\n\n        return torch.frombuffer(data, self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"No data type is set for NoHeaderTensorSerializer, please call setup(data_format) first\")\n\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        if dtype is None:\n            raise ValueError(\"No data type defined in the Serializer instance.\")\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        if not dtype:\n            raise ValueError(\"The NoHeaderTensorSerializer needs a dtype to deserialize the data.\")\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\n                \"NoHeaderTensorSerializer has no data type defined. Please call setup() with the data type of the tensor before using it.\"\n            )\n\n        dtype = _TORCH_DTYPES_MAPPING[self._dtype]\n        return torch.frombuffer(data, dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The dtype must be set before deserializing data.\")\n\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer must have a data type set before it can be used.\")\n        return torch.frombuffer(data, self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size + 1) : len(data)], dtype=dtype, shape=tuple(shape))\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_size) : len(data)], dtype=dtype)\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        data = data[8 + 4 * (shape_size + 1) :]\n        return np.frombuffer(data, dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_size + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_size) : len(data)], dtype=dtype)\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size + 1) : len(data)], dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size) : len(data)], dtype=dtype, shape=tuple(shape))\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size) : len(data)], dtype=dtype, shape=tuple(shape))\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size + 1) : len(data)], dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        data = data[8 + 4 * (shape_size + 1) :]\n        return np.frombuffer(data, dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size + 1) : len(data)], dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        data = data[8 + 4 * (shape_size + 1) :]\n        return np.frombuffer(data, dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_size) : len(data)], dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n\n        array = np.frombuffer(data[8 + 4 * (shape_size + 1) : len(data)], dtype=dtype)\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = np.array(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.typecode}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        return item.tobytes(order=\"C\"), f\"no_header_numpy:{self._dtype.num}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = deepcopy(super().state_dict())\n        state_dict.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n                \"restore\": self.restore,\n                \"profile_batches\": self._profile_batches,\n            }\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = {\n                \"dataset\": self.dataset.dataset,\n                \"shuffle\": self.dataset.shuffle,\n            }\n        else:\n            state_dict[\"dataset\"] = self.dataset\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict: Dict[str, Any] = deepcopy(super().state_dict())\n\n        state_dict[\"dataset\"] = self.dataset\n        state_dict[\"batch_size\"] = self.batch_size\n        state_dict[\"num_workers\"] = self.num_workers\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"restore\"] = self.restore\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = super().state_dict()\n\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n            state_dict[\"batch_size\"] = self.batch_size\n            state_dict[\"num_workers\"] = self.num_workers\n        else:\n            state_dict[\"dataset\"] = self.dataset\n            state_dict[\"batch_size\"] = self.batch_size\n            state_dict[\"num_workers\"] = self.num_workers\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = deepcopy(super().state_dict())\n        state_dict.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n                \"restore\": self.restore,\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n            }\n        )\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": deepcopy(self.dataset),  # type: ignore\n            \"batch_size\": self.batch_size,\n            \"num_workers\": self.num_workers,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = deepcopy(super().state_dict())\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        state[\"restore\"] = self.restore\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = deepcopy(self.dataset.state_dict())\n        else:\n            state[\"dataset\"] = deepcopy(self.dataset._state_dict())\n\n        if self.rng_state is not None:\n            state[\"rng_state\"] = self.rng_state\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = deepcopy(super().state_dict())\n        state_dict.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n                \"restore\": self.restore,\n            }\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = deepcopy(self.dataset.state_dict())\n        else:\n            state_dict[\"dataset\"] = deepcopy(self.dataset.state_dict())\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = super().state_dict()\n        state_dict[\"dataset\"] = self.dataset\n        state_dict[\"batch_size\"] = self.batch_size\n        state_dict[\"num_workers\"] = self.num_workers\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state_dict = deepcopy(super().state_dict())\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n            state_dict[\"current_epoch\"] = self.current_epoch\n            state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n            state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n            return state_dict\n        else:\n            state_dict = deepcopy(super().state_dict())\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n            state_dict[\"current_epoch\"] = self.current_epoch\n            state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n            state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n            return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n        state.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = {\n                \"dataset\": deepcopy(self.dataset._dataset),\n                \"dataset_sampler\": deepcopy(self.dataset._sampler),\n                \"shuffle\": self.dataset.shuffle,\n                \"index\": self.dataset._index,\n                \"index_iter\": self.dataset._index_iter,\n            }\n        else:\n            state[\"dataset\"] = deepcopy(self.dataset)\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = deepcopy(super().state_dict())\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = {\"__class__\": self.dataset.__class__.__name__}\n            state[\"dataset\"][\"_num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n            state[\"dataset\"][\"_num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n            state[\"dataset\"][\"_worker_idx\"] = self._worker_idx\n            state[\"dataset\"][\"_latest_worker_idx\"] = self._latest_worker_idx\n            state[\"dataset\"][\"current_epoch\"] = self.current_epoch\n        else:\n            state[\"dataset\"] = self.dataset\n\n        if self.num_workers > 0:\n            state[\"num_workers\"] = self.num_workers\n        if self._profile_batches:\n            state[\"profile_batches\"] = self._profile_batches\n            state[\"profile_dir\"] = self._profile_dir\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = super().state_dict()\n        state_dict.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n            }\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = {\n                \"dataset_type\": type(self.dataset),\n                \"dataset\": deepcopy(self.dataset),\n                \"batch_size\": self.batch_size,\n                \"num_workers\": self.num_workers,\n                \"prefetch_factor\": self.prefetch_factor,\n            }\n        else:\n            state_dict[\"dataset\"] = type(self.dataset)\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = super().state_dict()\n        state_dict.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n            }\n        )\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = deepcopy(super().state_dict())\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        if self.rng_state is not None:\n            state_dict[\"rng_state\"] = self.rng_state\n\n        if self.dataset.is_streaming_dataloader:\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"dataset\"] = self.dataset\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = deepcopy(super().state_dict())\n\n        state_dict[\"dataset\"] = deepcopy(self.dataset)\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        state_dict[\"restore\"] = self.restore\n\n        if self.dataset.is_streaming:\n            state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n            state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": deepcopy(self.dataset),\n            \"batch_size\": self.batch_size,\n            \"num_workers\": self.num_workers,\n            \"current_epoch\": self.current_epoch,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n        else:\n            state_dict[\"num_samples_yielded\"] = {self._latest_worker_idx: self._num_samples_yielded_streaming}\n\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = deepcopy(super().state_dict())\n        state.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"dataset\": self.dataset.state_dict(),\n                \"use_streaming_dataloader\": True,\n            }\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = deepcopy(super().state_dict())\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": deepcopy(self.dataset),\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"current_epoch\"] = self.current_epoch\n            state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            if _TORCH_VISION_AVAILABLE:\n                with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n                    f.write(data)\n                    f.flush()\n                    return decode_video(f.name)\n            else:\n                raise RuntimeError(\"The torchvision library is required for this function to work, please install it.\")\n        else:\n            raise RuntimeError(\"The av library is required for this function to work, please install it.\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"The AV library is not installed. Please install it with `pip install av`.\")\n        with tempfile.TemporaryDirectory() as tmpdir:\n            with open(os.path.join(tmpdir, \"video.mp4\"), \"wb\") as f:\n                f.write(data)\n            return decode_video(os.path.join(tmpdir, \"video.mp4\"))\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            with tempfile.TemporaryDirectory() as temp_dir:\n                temp_file = os.path.join(temp_dir, \"temp_file.mp4\")\n                with open(temp_file, \"wb\") as f:\n                    f.write(data)\n\n                return _AV_AVAILABLE.read_video(temp_file)\n        else:\n            raise Exception(\"The required library av is not installed.\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            with tempfile.TemporaryDirectory() as tmp_dir:\n                tmp_file_path = os.path.join(tmp_dir, \"video.mp4\")\n                with open(tmp_file_path, \"wb\") as f:\n                    f.write(data)\n                return _AV_AVAILABLE.read_video(tmp_file_path)\n        raise RuntimeError(\"Torchvision and av libraries are required to deserialize video objects\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The AV library is required to deserialize video files, please install it with 'pip install av' and try again.\"\n            )\n        if _TORCH_VISION_AVAILABLE:\n            with tempfile.NamedTemporaryFile() as f:\n                f.write(data)\n                f.flush()\n\n                return decode_video(f.name)\n\n        raise RuntimeError(\n            \"The torchvision library is required to deserialize video files, please install it with 'pip install torchvision' and try again.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"AV library is not installed. Please install AV library to use VideoSerializer\")\n\n        with tempfile.NamedTemporaryFile(\"w+b\") as f:\n            f.write(data)\n            f.flush()\n            return torch.hub.load(\"openvino/video-reader-py\", \"video\", f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\n                \"The AV library is not installed. Please install it using 'pip install av' and try again.\"\n            )\n        tmp_dir = tempfile.gettempdir()\n        tmp_file_path = os.path.join(tmp_dir, \"tmp_video.mp4\")\n        with open(tmp_file_path, \"wb\") as f:\n            f.write(data)\n        return decode_video(tmp_file_path)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"The AV library is not installed. Please install it using 'pip install av'.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise RuntimeError(\"The torchvision library is not installed. Please install it using 'pip install torchvision'.\")\n\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return decode_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            with tempfile.NamedTemporaryFile(mode=\"w+b\") as f:\n                f.write(data)\n                f.flush()\n                return _AV_AVAILABLE.read_video(f.name)\n        else:\n            raise RuntimeError(\"AV is not installed. Please install AV or use a different serializer.\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"The AV library is not installed. Please install it to use the VideoSerializer class.\")\n\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"The AV library is required to deserialize video data. Please install it using `pip install av`.\")\n\n        if not _TORCH_VISION_AVAILABLE:\n            raise RuntimeError(\n                \"The torchvision library is required to deserialize video data. Please install it using `pip install torchvision`.\")\n\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.seek(0)\n            return decode_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            with tempfile.TemporaryFile() as f:\n                f.write(data)\n                f.flush()\n                return self.read_video(f.name)\n        else:\n            raise Exception(\n                \"The av library is not installed. Please install the av library to deserialize the video file.\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"AV is required to use the VideoSerializer. Please install it using `pip install av`\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise RuntimeError(\"torchvision is required to use the VideoSerializer. Please install it using `pip install torchvision`\")\n\n        # Create a temporary file to write the video data to\n        tmp_file_path = tempfile.NamedTemporaryFile(prefix=\"video_data\", suffix=\".mp4\", delete=False)\n\n        # Write the data to the temporary file\n        with open(tmp_file_path.name, \"wb\") as f:\n            f.write(data)\n        # Deserialize the temporary file using torchvision's read_video function\n        return self._deserialize_video_file(tmp_file_path.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\"The AV library is not installed. Please install the AV library to use the VideoSerializer.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ValueError(\n                \"The torchvision library is not installed. Please install the torchvision library to use the VideoSerializer.\"\n            )\n\n        # Write the data to a temporary file and read the video from that file\n        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_filepath = os.path.join(temp_dir, \"temp_video.mp4\")\n            with open(temp_filepath, \"wb\") as f:\n                f.write(data)\n\n            # Deserialize the video file into a video object\n            return decode_video(temp_filepath)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            with tempfile.NamedTemporaryFile(dir=os.path.join(os.getcwd(), \".lightning_temp\")) as f:\n                f.write(data)\n                f.flush()\n\n                try:\n                    return self._deserialize_video(f.name)\n                except Exception:\n                    pass\n                finally:\n                    f.close()\n\n        raise Exception(\"The AV library is not installed. Please install it to use this serializer.\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\n                \"The AV library is not installed. Please install it by running `pip install av`.\"\n                \"You can also set the LIT_NO_AV_SERIALIZATION environment variable to False to disable AV library serialization.\"\n            )\n\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return torch.hub.load(\"openvino/openvino_video-2020.1\", \"read_video\", f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            if \"video\" not in data:\n                raise ValueError(\"Video file type not found in data\")\n            file_extension = data.split(\":\")[1]\n            _, file_extension = os.path.splitext(file_extension)\n            file_extension = file_extension.replace(\".\", \"\").lower()\n        else:\n            raise ImportError(\n                \"The av library is not installed. Please install it with 'pip install litdata[video]'\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=file_extension) as f:\n            f.write(data)\n            f.flush()\n            return decode_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _AV_AVAILABLE:\n            file_extension = data.decode(\"utf-8\").split(\":\")[1]\n            with tempfile.NamedTemporaryFile(mode=\"wb\") as f:\n                f.write(data)\n                f.flush()\n                return self._read_video_file(f.name, file_extension)\n        return data\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"AV is not installed. Please install it using `pip install av`.\")\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return _AV_AVAILABLE.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise Exception(\"The AV library is not installed. Please install the AV library using 'pip install av'.\")\n\n        tmp_file = tempfile.NamedTemporaryFile(prefix=\"litdata_video_\")\n        tmp_file.write(data)\n        tmp_file.flush()\n        video = None\n        try:\n            video = _AV_AVAILABLE.read_video(tmp_file.name)\n        except Exception as e:\n            pass\n        tmp_file.close()\n        return video\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.1)\n        return [self.write_chunk(on_done=True), self.write_chunks_index()]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        self.write_chunk()\n        filepaths = [self.write_chunk_to_file(self._create_chunk(on_done=True), filename) for filename in self._chunks_info]\n        self.write_chunks_index()\n        self._is_done = True\n        return filepaths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while not self.filled:\n            self._should_write()\n            self.write_chunk()\n            sleep(0.001)\n\n        # Write the index file\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.01)\n        # Write the remaining items\n        if self._min_index is not None:\n            filepath = os.path.join(self._cache_dir, self.get_chunk_filename())\n            self.write_chunk_to_file(self._create_chunk(filepath, on_done=True), filepath)\n\n        # Write the chunks index\n        self.write_chunks_index()\n\n        return [\n            os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)\n        ]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.01)\n\n        # Write the remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        return [os.path.join(self._cache_dir, filename) for filename in os.listdir(self._cache_dir)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        while not self.filled:\n            self.write_chunk()\n            sleep(0.001)\n\n        self.write_chunks_index()\n        self.write_chunk(on_done=True)\n        self._is_done = True\n        return [\n            os.path.join(self._cache_dir, filename)\n            for filename in os.listdir(self._cache_dir)\n            if filename.endswith(_INDEX_FILENAME)\n        ]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the written chunk files\n        chunks: List[str] = []\n        for _ in range(self._chunk_index):\n            chunks.append(self.get_chunk_filename())\n            self.write_chunk(on_done=True)\n\n        return chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.1)\n\n        self.write_chunk(on_done=True)\n        self.write_chunks_index()\n        return [os.path.join(self._cache_dir, filename) for filename in os.listdir(self._cache_dir)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.01)\n        self.write_chunk(on_done=True)\n        self.write_chunks_index()\n        return [os.path.join(self._cache_dir, chunk) for chunk in self.get_chunk_filenames()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.001)\n\n        self.write_chunk()\n        return [\n            os.path.join(self._cache_dir, filename)\n            for filename in os.listdir(self._cache_dir)\n            if filename.endswith(self.get_chunk_filename())\n        ]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while not self.filled:\n            self._should_write()\n            if self.filled:\n                break\n            sleep(0.1)\n\n        # Write the index file\n        index_file_path = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of chunk paths\n        return [self.write_chunk_to_file(self._create_chunk(filename=self.get_chunk_filename(on_done=True))) for _ in range(self._chunk_index)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n        if not self.filled:\n            raise RuntimeError(\"The writer hasn't been filled.\")\n\n        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, filename) for filename in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.01)  # sleep for a bit to give the pipeline a chance to write more data\n\n        # Write the remaining items\n        if self._serialized_items:\n            self.write_chunk()\n            self._min_index = None\n            self._max_index = None\n\n        # Write the index file\n        self.write_chunks_index()\n\n        return [self.write_chunk(on_done=True)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n            else:\n                sleep(0.1)\n\n        return [\n            f\"chunk-{self.rank}-{self._chunk_index}.{self._compression}.bin\"\n            if self._compression\n            else f\"chunk-{self.rank}-{self._chunk_index}.bin\"\n            for _ in range(self._chunk_index)\n        ]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # If the current index is larger than the max index, write the remaining data\n        if self.rank == 0 and self.filled:\n            # Write the chunks\n            filepaths = []\n            while self._should_write():\n                filepath = self.write_chunk()\n                filepaths.append(filepath)\n                if self._rank == 0:\n                    sleep(0.01)\n\n            # Write the chunks index\n            filepaths.append(self.write_chunks_index())\n\n            # Mark the writing process as complete\n            self._is_done = True\n\n        return filepaths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self.filled:\n            self.write_chunk()\n\n        filepath = self.write_chunks_index()\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if not self._is_done:\n            if self.filled:\n                while self._should_write():\n                    self.write_chunk()\n                self.write_chunks_index()\n                self._is_done = True\n\n            # Wait for other workers to finish\n            if self._distributed_env:\n                while not self.filled:\n                    sleep(0.01)\n\n        return [os.path.join(self._cache_dir, chunk_info[\"filename\"]) for chunk_info in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        # Write remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write index file\n        filepath = self.write_chunks_index()\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n\n        if self.write_chunks_index() != \"\":\n            self._is_done = True\n\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        while not self.filled:\n            if self._follow_tensor_dimension and self._data_format:\n                # If the data format is provided, the data should be written in the order of the format\n                for i in range(len(self._data_format)):\n                    self._serialized_items[i] = self._serialized_items.pop(self._data_format[i])\n            else:\n                self._serialized_items = {\n                    index: item for index, item in self._serialized_items.items() if item.bytes > 0\n                }\n\n            if self._should_write():\n                filepath = self.write_chunk()\n            else:\n                sleep(0.1)\n                continue\n\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, filename) for filename in self.get_chunk_filenames()]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        self.dataset.load_state_dict(obj[\"dataset\"])"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, self._num_samples_yielded_combined)\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, self._num_samples_yielded_streaming)\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        else:\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, obj[\"num_samples_yielded\"])\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self.num_workers = obj[\"dataset\"][\"num_workers\"]\n        self.batch_size = obj[\"dataset\"][\"batch_size\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self.batch_size,\n                self.num_workers,\n                self._num_samples_yielded_streaming,\n            )\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers)\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        else:\n            raise RuntimeError(f\"Unknown dataset type: {type(self.dataset)}\")\n\n        self.restore = False"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if self.num_workers == 0:\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.restore = True\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        elif isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._num_samples_yielded_streaming,\n                self.num_workers,\n                self.batch_size,\n            )\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n            for dataset_idx, num_samples_yielded in enumerate(obj[\"dataset\"][\"num_samples_yielded\"]):\n                self.dataset.datasets[dataset_idx].load_state_dict(\n                    obj[\"dataset\"][\"dataset\"][dataset_idx],\n                    self.num_workers,\n                    self.batch_size,\n                    num_samples_yielded,\n                )\n\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.dataset.load_state_dict(obj[\"dataset\"])\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.batch_size = self.dataset.batch_size\n            self.num_workers = self.dataset.num_workers\n            self._num_samples_yielded_combined = {\n                key: []\n                for key in range(self.num_workers)\n            }  # type: ignore\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.batch_size = self.dataset.batch_size\n            self.num_workers = self.dataset.num_workers\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self._worker_idx_iter = iter(cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx = self._worker_idx_iter"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if self.num_workers > 0:\n            self.restore = True\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            for worker_idx in range(self.num_workers):\n                self.dataset.set_num_samples_yielded(worker_idx, self._num_samples_yielded_combined[worker_idx])\n        else:\n            raise RuntimeError(\n                \"The dataset should be either a StreamingDataset or CombinedStreamingDataset. \"\n                f\"Found {type(self.dataset)}.\"\n            )\n\n        if self.num_workers > 1:\n            self._worker_idx_iter = iter(self._worker_idx)"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.dataset.load_state_dict(\n            obj[\"dataset\"],\n            self.num_workers,\n            self.batch_size,\n            obj[\"num_samples_yielded\"]\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_combined = {}\n        else:\n            self.dataset._set_use_streaming_dataloader(True)\n\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.current_epoch, self.num_workers, self.batch_size)\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n        else:\n            raise RuntimeError(\n                \"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or CombinedStreamingDataset. \"\n                f\"Instead, found {self.dataset}.\"\n            )\n\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._worker_idx = cycle(list(range(self._num_workers)))\n        self._worker_idx_iter = iter(self._worker_idx)"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(self.num_workers, self.batch_size, self._num_samples_yielded_streaming)\n        else:\n            self.dataset._set_use_streaming_dataloader(True)\n\n            if self.num_workers > 0:\n                self._num_samples_yielded_combined = deepcopy(obj[\"num_samples_yielded\"])\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(self.dataset, (StreamingDataset, CombinedStreamingDataset)):\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {type(self.dataset)}.\"\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n        self.dataset.load_state_dict(obj[\"dataset\"])\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not self.restore:\n            self.restore = True\n            self.dataset.set_epoch(obj[\"current_epoch\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n            if isinstance(self.dataset, StreamingDataset):\n                self.dataset.set_epoch(self.current_epoch)\n                self.dataset.set_num_samples_yielded(self._num_samples_yielded_streaming, self.num_workers, self.batch_size)\n\n        elif not isinstance(self.dataset, StreamingDataset):\n            if not isinstance(self.dataset, CombinedStreamingDataset):\n                raise RuntimeError(\n                    \"The dataset of the StreamingDataLoader should be either a StreamingDataset or a CombinedStreamingDataset.\"\n                )\n            num_samples_yielded_combined = self._num_samples_yielded_combined\n            for worker_idx, samples_yielded in obj[\"num_samples_yielded\"].items():\n                num_samples_yielded_combined[worker_idx] = samples_yielded\n\n        else:\n            if not isinstance(self.dataset, CombinedStreamingDataset):\n                raise RuntimeError(\n                    \"The dataset of the StreamingDataLoader should be either a StreamingDataset or a CombinedStreamingDataset.\"\n                )\n            self.dataset.set_epoch(self.current_epoch)\n            self.dataset.set_num_samples_yielded(\n                self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n            for worker_idx, samples_yielded in obj[\"num_samples_yielded\"].items():\n                self._num_samples_yielded_combined[worker_idx] = samples_yielded\n\n        if self.num_workers > 0:\n            self._worker_idx_iter = iter(self._worker_idx)\n\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > "}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.restore = True\n\n        if not self.restore:\n            self.current_epoch = obj[\"current_epoch\"]\n            self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.current_epoch, self.num_workers, self.batch_size)\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, self._num_samples_yielded_combined\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n        else:\n            raise RuntimeError(\n                f\"The provided dataset is not a StreamingDataset or CombinedStreamingDataset. Found {self.dataset}.\"\n            )\n\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        self.current_epoch += 1\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = deepcopy(obj[\"num_samples_yielded\"])\n        else:\n            raise RuntimeError(\n                \"The dataset associated with this StreamingDataLoader is not a StreamingDataset or a CombinedStreamingDataset. It is not supported to load the state of this StreamingDataLoader.\"\n            )\n\n        self.restore = False\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(self.dataset, (StreamingDataset, CombinedStreamingDataset)):\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {type(self.dataset)}.\"\n            )\n        if not obj[\"current_epoch\"]:\n            raise RuntimeError(\"The provided state should contain a current_epoch key.\")\n        if not obj[\"num_samples_yielded\"] or not obj[\"num_samples_yielded\"]:\n            raise RuntimeError(\"The provided state should contain a num_samples_yielded key.\")\n        if not obj[\"latest_worker_idx\"]:\n            raise RuntimeError(\"The provided state should contain a latest_worker_idx key.\")\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"][0]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.state_dict(self._num_samples_yielded_streaming, self.num_workers, self.batch_size)\n        else:\n            self.dataset.state_dict(self.num_workers, self.batch_size, obj[\"num_samples_yielded\"])\n\n        self.current_epoch += 1\n\n        if self.num_workers > 0:\n            self._worker_idx = cycle(list(range(self.num_workers)))\n            self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if self.dataset.use_streaming_dataloader:\n            self.restore = True\n            if isinstance(self.dataset, StreamingDataset):\n                self.dataset.load_state_dict(\n                    obj[\"dataset\"],\n                    self.current_epoch,\n                    self._num_samples_yielded_streaming,\n                    self.batch_size,\n                    self.num_workers,\n                )\n            elif isinstance(self.dataset, CombinedStreamingDataset):\n                self.dataset.load_state_dict(\n                    obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n                )\n\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.num_workers = obj[\"num_workers\"]\n\n            self.batch_size = obj[\"batch_size\"]\n\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.restore = False\n\n        else:\n\n            self.dataset.load_state_dict(obj[\"dataset\"], self.current_epoch, self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self.num_workers = obj[\"num_workers\"]\n\n            self.batch_size = obj[\"batch_size\"]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], obj[\"current_epoch\"], obj[\"num_samples_yielded\"])\n        else:\n            self.dataset._set_use_streaming_dataloader(True)\n            self.dataset.load_state_dict(obj[\"dataset\"], obj[\"current_epoch\"], obj[\"num_samples_yielded\"])\n        self.restore = True\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not self.restore:\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n            if isinstance(self.dataset, StreamingDataset):\n                self.dataset.load_state_dict(\n                    self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n                )\n\n            elif isinstance(self.dataset, CombinedStreamingDataset):\n                self.dataset.load_state_dict(self.num_workers, self.batch_size, obj[\"num_samples_yielded\"])\n        else:\n            if self.current_epoch == obj[\"current_epoch\"]:\n                self.restore = False\n\n        if self.restore:\n            raise RuntimeError(\n                \"The StreamingDataLoader is already restored. You cannot call load_state_dict() again.\"\n            )\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.current_epoch = obj[\"current_epoch\"]\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self.restore = True\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.dataset.restore = True\n\n        else:\n            raise RuntimeError(\n                \"The dataset associated with the StreamingDataLoader must be an instance of StreamingDataset or CombinedStreamingDataset. Found: {}\".format(\n                    type(self.dataset)\n                )\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset) or isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The dataset associated with the StreamingDataLoader must be a StreamingDataset or CombinedStreamingDataset.\"\n            )\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            return self._datasets[0].state_dict(\n                num_workers, batch_size, num_samples_yielded\n            )\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            if num_samples_yielded is not None:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: self._datasets,\n                }\n            else:\n                return {}\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: self._num_samples_yielded,\n                __SAMPLES_KEY__: self.state_dict_from_datasets(num_workers, batch_size, num_samples_yielded),\n            }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        if self._num_samples_yielded is None:\n            return {}\n\n        state_dict = {\n            __NUM_SAMPLES_YIELDED_KEY__: self._num_samples_yielded,\n            __SAMPLES_KEY__: self._datasets,\n            \"seed\": self._seed,\n            \"weights\": self._weights,\n            \"use_streaming_dataloader\": self._use_streaming_dataloader,\n            \"current_epoch\": self._current_epoch,\n        }\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: {\n                    dataset.name: dataset.state_dict(num_workers, batch_size)\n                    for dataset in self._datasets\n                },\n            }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            state_dict = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [dataset.state_dict(num_workers, batch_size) for dataset in self._datasets],\n            }\n        else:\n            state_dict = self._iterator.state_dict()\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        elif num_samples_yielded is None:\n            return {}\n        else:\n            self._num_samples_yielded = num_samples_yielded\n            return self._state_dict_from_datasets()\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                self._iterator = _CombinedDatasetIterator(\n                    self._datasets,\n                    self._seed,\n                    self._weights,\n                    self._use_streaming_dataloader,\n                    num_samples_yielded,\n                )\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n\n            self._iterator = _CombinedDatasetIterator(\n                self._datasets,\n                self._seed,\n                self._weights,\n                self._use_streaming_dataloader,\n                num_samples_yielded,\n            )\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if num_samples_yielded is None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: self._num_samples_yielded,\n                __SAMPLES_KEY__: self._iterator.state_dict(num_workers, batch_size),\n            }\n\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: self._iterator.state_dict(num_workers, batch_size),\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if num_samples_yielded is None:\n            if self._iterator is None:\n                return {}\n\n            num_samples_yielded = self._iterator.state_dict(num_workers, batch_size)\n        else:\n            num_samples_yielded = [0] * num_workers\n\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: self.state_dict_from_datasets(self._datasets),\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n\n            self._iterator = _CombinedDatasetIterator(\n                self._datasets, self._seed, self._weights, self._use_streaming_dataloader, num_samples_yielded\n            )\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return self._datasets[0].state_dict(num_workers, batch_size, num_samples_yielded)\n\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if num_samples_yielded is not None and self._iterator is None:\n            self._set_use_streaming_dataloader(False)\n\n            state = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size) for d in self._datasets],\n            }\n            self._set_use_streaming_dataloader(True)\n\n        elif self._iterator is not None:\n            state = self._iterator.state_dict(num_workers, batch_size)\n\n        else:\n            state = {}\n\n        return state\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n\n            # Create state dict from the iterator\n            state_dict = self._iterator.state_dict(\n                num_workers=num_workers, batch_size=batch_size, num_samples_yielded=num_samples_yielded\n            )\n            return state_dict\n\n        # Create state dict from the datasets\n        state_dict = {\n            __NUM_SAMPLES_YIELDED_KEY__: [0] * len(self._datasets),\n            __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size) for d in self._datasets],\n        }\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            state_dict = {}\n            for dataset, weight in zip(self._datasets, self._weights):\n                state_dict[dataset] = dataset.state_dict(num_workers, batch_size)\n        else:\n            state_dict = self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if not self._iterator:\n            if num_samples_yielded is None:\n                return {}\n\n            state_dict = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: None,\n            }\n            return state_dict\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if num_samples_yielded is not None:\n            self._num_samples_yielded = num_samples_yielded\n\n        if self._iterator is None:\n            return {}\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if num_samples_yielded is None or self._iterator is None:\n            return {}\n\n        if self._num_samples_yielded is not None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: self._num_samples_yielded,\n                __SAMPLES_KEY__: self._num_samples_yielded,\n            }\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            # Create state dictionary from internal datasets\n            state_dict = dict()\n            for dataset in self._datasets:\n                state_dict.update(dataset.state_dict(num_workers, batch_size))\n\n            # Add the current epoch\n            state_dict[__NUM_SAMPLES_YIELDED_KEY__] = num_samples_yielded\n\n            return state_dict\n\n        return self._iterator.state_dict()\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None) is not None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._use_streaming_dataloader = True\n            self._iterator = None\n        else:\n            self._num_samples_yielded = None\n            self._use_streaming_dataloader = False\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        self._iterator = _CombinedDatasetIterator.load_state_dict(\n            state_dict, self._datasets, self._seed, self._weights, self._use_streaming_dataloader, self._num_samples_yielded\n        )\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._set_use_streaming_dataloader(state_dict[\"use_streaming_dataloader\"])\n        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n        if self._num_samples_yielded is not None:\n            self._num_samples_yielded = [\n                self._num_samples_yielded[i] for i in range(len(self._datasets))\n            ]\n\n        for i in range(len(self._datasets)):\n            self._datasets[i].load_state_dict(state_dict[\"datasets\"][i])\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._iterator = None\n\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._use_streaming_dataloader = True\n        else:\n            self._num_samples_yielded = None\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._use_streaming_dataloader = state_dict[\"use_streaming_dataloader\"]\n        self._seed = state_dict[\"seed\"]\n        self._current_epoch = state_dict[\"current_epoch\"]\n        self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n\n        for dataset, state in zip(self._datasets, state_dict[\"datasets\"]):\n            dataset.load_state_dict(state)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict.get(__NUM_SAMPLES_YIELDED_KEY__) is not None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n\n        self._set_use_streaming_dataloader(state_dict.get(\"use_streaming_dataloader\", False))\n        for i, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[__SAMPLES_KEY__][i])\n            if self._num_samples_yielded is not None:\n                self._num_samples_yielded[i] = state_dict[__NUM_SAMPLES_YIELDED_KEY__][i]\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._iterator = None\n        if self._num_samples_yielded is not None:\n            self._num_samples_yielded = None\n\n        self._set_use_streaming_dataloader(state_dict.get(\"use_streaming_dataloader\", False))\n        self._current_epoch = state_dict.get(\"current_epoch\", 0)\n        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict.get(__SAMPLES_KEY__, {}))\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if __SAMPLES_KEY__ in state_dict:\n            self._iterator = None\n            self._use_streaming_dataloader = True\n\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n\n            if self._num_samples_yielded is not None:\n                for dataset in self._datasets:\n                    dataset.load_state_dict(state_dict[__SAMPLES_KEY__], num_samples_yielded=self._num_samples_yielded)\n        else:\n            self._iterator = None\n            self._use_streaming_dataloader = False\n\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n\n            if self._num_samples_yielded is not None:\n                for dataset in self._datasets:\n                    dataset.load_state_dict(state_dict)\n        return\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict is None:\n            return\n\n        if __NUM_SAMPLES_YIELDED_KEY__ not in state_dict:\n            return\n\n        self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        self._use_streaming_dataloader = state_dict.get(\n            \"use_streaming_dataloader\", self._use_streaming_dataloader\n        )\n\n        if self._use_streaming_dataloader:\n            for i, dataset in enumerate(self._datasets):\n                if i in self._num_samples_yielded:\n                    dataset.load_state_dict(\n                        {__NUM_SAMPLES_YIELDED_KEY__: self._num_samples_yielded[i]}\n                    )\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._iterator = None\n\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            num_samples_yielded = state_dict.pop(__NUM_SAMPLES_YIELDED_KEY__)\n            if isinstance(num_samples_yielded, list):\n                self._num_samples_yielded = num_samples_yielded\n            else:\n                self._num_samples_yielded = [num_samples_yielded] * len(self._datasets)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if \"num_samples_yielded\" in state_dict:\n            self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n        else:\n            self._num_samples_yielded = None\n        self._use_streaming_dataloader = state_dict.get(\"use_streaming_dataloader\", False)\n        self._iterator = None\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._iterator = None\n        self._use_streaming_dataloader = False\n        self._num_samples_yielded = None\n\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._use_streaming_dataloader = True\n\n        for dataset_idx, dataset in enumerate(self._datasets):\n            if __SAMPLES_KEY__ in state_dict:\n                dataset_state_dict = state_dict[__SAMPLES_KEY__][dataset_idx]\n                dataset.load_state_dict(dataset_state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._use_streaming_dataloader = state_dict[\"use_streaming_dataloader\"]\n\n        if \"num_samples_yielded\" in state_dict:\n            self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n            self._num_samples_yielded = [\n                self._num_samples_yielded[i] if i in self._num_samples_yielded else 0 for i in range(len(self._datasets))\n            ]\n\n        for i, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[\"datasets\"][i])\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._iterator = None\n        self._num_samples_yielded = None\n\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._use_streaming_dataloader = True\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n        return\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._set_use_streaming_dataloader(state_dict.get(\"use_streaming_dataloader\", False))\n        self._seed = state_dict.get(\"seed\", self._seed)\n\n        datasets = state_dict.get(\"datasets\", [])\n        if datasets:\n            self._datasets = []\n            for dataset in datasets:\n                self._datasets.append(StreamingDataset.from_state_dict(dataset))\n\n        if self._use_streaming_dataloader:\n            self._num_samples_yielded = state_dict.get(\n                \"num_samples_yielded\",\n                [0] * len(self._datasets),\n            )\n            self._current_epoch = state_dict.get(\"current_epoch\", 0)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict.get(f\"{__SAMPLES_KEY__}_{dataset.dataset_id}\", {}))\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._check_datasets(state_dict[__SAMPLES_KEY__])\n\n        # Update the state of the datasets\n        self._datasets = state_dict[__SAMPLES_KEY__]\n        self._seed = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        self._weights = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n\n        # Update the state of the StreamingDataloader\n        self._set_use_streaming_dataloader(state_dict[__NUM_SAMPLES_YIELDED_KEY__])\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.pop(__NUM_SAMPLES_YIELDED_KEY__, None)\n\n        self._datasets = [\n            StreamingDataset.load_state_dict(d) for d in self._datasets\n        ]  # type: ignore\n\n        self._use_streaming_dataloader = state_dict.get(\"use_streaming_dataloader\", False)\n        if self._use_streaming_dataloader:\n            self._num_samples_yielded = state_dict.get(__SAMPLES_KEY__, self._num_samples_yielded)\n\n        if self._num_samples_yielded is None:\n            self._num_samples_yielded = [0] * len(self._datasets)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        self._set_use_streaming_dataloader(state_dict[\"use_streaming_dataloader\"])\n        self._current_epoch = state_dict[\"current_epoch\"]\n        for dataset, sample_count in zip(self._datasets, state_dict[__SAMPLES_KEY__]):\n            dataset.load_state_dict(sample_count)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        # This is a hack to avoid a PyTorch warning\n        if \"num_workers\" in state_dict:\n            state_dict.pop(\"num_workers\")\n\n        if \"num_samples_yielded\" in state_dict:\n            self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n            self._set_use_streaming_dataloader(state_dict.pop(\"use_streaming_dataloader\", False))\n\n        if not state_dict:\n            return\n\n        self._check_datasets(state_dict.pop(\"datasets\"))\n        self._iterator = _CombinedDatasetIterator.load_state_dict(state_dict, self._datasets)\n        self._iterator.set_seed(self._seed)\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning:\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud:\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-s3:\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-s3:\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path is None:\n        return Dir()\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    else:\n        return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3://\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3://\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3://s3-s3\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3://s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3:s3-s3\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3:s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3://s3\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3://\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3-s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3://s3-s3\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3://s3:\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"s3"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path is None:\n        return Dir()\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    else:\n        return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if not dir_path:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\") or dir_path.startswith(\"s3:\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\") or dir_path.startswith(\"lightning:\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if not dir_path:\n        return Dir(path=Path.home().as_posix())\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path.startswith(\"s3://\") or dir_path.startswith(\"s3-alias://\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning-project://\"):\n        return Dir(\n            path=dir_path.replace(\"lightning-project://\", \"\")\n        )\n    elif dir_path.startswith(\"lightning-project-alias://\"):\n        return Dir(\n            path=dir_path.replace(\"lightning-project-alias://\", \"\")\n        )\n    else:\n        return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir(path=\".\", url=\"https://s3.amazonaws.com/lightning-projects/\")\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=\"https://s3.amazonaws.com/lightning-projects/\")\n\n    if dir_path.startswith(\"https://s3.amazonaws.com/lightning-projects/\"):\n        return Dir(path=dir_path[29:], url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=\"https://s3.amazonaws.com/lightning-projects/\")\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=\"https://s3.amazonaws.com/lightning-projects/\")\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=\"https://s3.amazonaws.com/lightning-projects/\")\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=\"https://s3.amazonaws.com/lightning-projects/\")\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir(path=None)\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if not dir_path.startswith(os.path.abspath(os.getcwd())):\n        return Dir(path=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path is None:\n        return Dir()\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"lightning-project://\"):\n        return Dir(path=dir_path)\n    else:\n        return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(\n            path=dir_path,\n            url=dir_path,\n        )\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(\n            path=dir_path,\n            url=dir_path,\n        )\n\n    if dir_path.startswith(\"lightning:\"):\n        return Dir(\n            path=dir_path,\n            url=dir_path,\n        )\n\n    return Dir(\n        path=dir_path,\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # If the input is already a Dir object, return it.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If the input is a Lightning URL, return a Dir object with the URL set.\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    # If the input is a local path, return a Dir object with the path set.\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    # If the input is a Lightning project path, return a Dir object with the path set.\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    # If the input is a path relative to the current working directory, return a Dir object with the path set.\n    else:\n        return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n    if not isinstance(dir_path, str):\n        return Dir(path=dir_path)\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is not None:\n        if dir_path.startswith(\"s3://\"):\n            return Dir(dir_path)\n        elif dir_path.startswith(\"https://\") or dir_path.startswith(\"http://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(os.path.sep):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=os.path.abspath(dir_path))\n    else:\n        return Dir()\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"lightning://\"):\n            return Dir(path=dir_path[13:])\n    elif dir_path is None:\n        return Dir(path=os.getcwd())\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    else:\n        raise TypeError(\n            f\"Expected str, Dir, or None, got {type(dir_path)}\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    dir_path = Path(dir_path)\n\n    if dir_path.is_absolute():\n        return Dir(dir_path=str(dir_path))\n\n    if dir_path.name == \"lightning-cloud\":\n        if not _LIGHTNING_SDK_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"lightning-sdk is not installed. Please install it using 'pip install lightning_sdk' or 'pip install lightning_sdk[s3]\"\n            )\n\n        # We assume that the project is running in the same directory as this module.\n        return Dir(\n            path=str(dir_path.parent),\n            url=f\"s3://{Machine().project_name}/lightning-cloud\",\n        )\n\n    elif dir_path.name == \"lightning-cloud-s3\":\n        if not _BOTO3_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"boto3 is not installed. Please install it using 'pip install boto3'\"\n            )\n\n        # We assume that the project is running in the same directory as this module.\n        return Dir(\n            path=str(dir_path.parent),\n            url=f\"s3://{Machine().project_name}/lightning-cloud-s3\",\n        )\n\n    elif dir_path.name == \"lightning-cloud-space\":\n        if not _BOTO3_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"boto3 is not installed. Please install it using 'pip install boto3'\"\n            )\n\n        # We assume that the project is running in the same directory as this module.\n        return Dir(\n            path=str(dir_path.parent),\n            url=f\"s3://{Machine().project_name}/lightning-cloud-space\",\n        )\n\n    elif dir_path.name == \"lightning-cloud-studio\":\n        if not _LIGHTNING_SDK_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"lightning-sdk is not installed. Please install it using 'pip install lightning_sdk'\"\n            )\n\n        # We assume that the project is running in the same directory as"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif dir_path is None:\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\")\n    elif dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\" + dir_path[12:])\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\" + dir_path[12:])\n    elif dir_path.startswith(\"lightning-public-data-bucket\"):\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\" + dir_path[22:])\n    elif dir_path.startswith(\"lightning-public-data\"):\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\" + dir_path[20:])\n    elif dir_path.startswith(\"lightning-public\"):\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\" + dir_path[15:])\n    elif dir_path.startswith(\"data\"):\n        return Dir(url=\"s3://lightning-public-data-bucket/data/datasets/\" + dir_path[4:])\n\n    raise ValueError(f\"Unexpected path format: {dir_path}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir(path=None)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-studio://\"):\n        return Dir(\n            url=dir_path\n        )  # TODO: handle this differently when sdk is available\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    return Dir(path=Path.cwd() / dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if not isinstance(dir_path, str):\n        raise TypeError(f\"dir_path must be a string or Dir object, not {type(dir_path)}\")\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n    if dir_path.startswith(\"lightning_project://\"):\n        return Dir(path=dir_path)\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n    return Dir(path=os.path.abspath(dir_path))\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if output_dir.path is not None:\n        if not Path(output_dir.path).is_dir() or not Path(output_dir.path).is_absolute():\n            raise ValueError(\n                \"The `output_dir` must be an absolute path to a directory.\"\n            )\n\n    if output_dir.url is not None:\n        if not output_dir.url.startswith(\"s3://\"):\n            raise ValueError(f\"The `output_dir` must start with 's3://' but is {output_dir.url}.\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"The `append` and `overwrite` arguments are not yet implemented.\")\n\n    if not append and not overwrite:\n        if output_dir.path is None:\n            raise ValueError(\"The `output_dir` must be a directory.\")\n\n        if not Path(output_dir.path).is_dir():\n            raise ValueError(\n                \"The `output_dir` must be a directory. It is currently set to: \" + str(output_dir.path)\n            )\n\n        if Path(output_dir.path).is_dir() and Path(output_dir.path).is_symlink():\n            raise ValueError(f\"The `output_dir` must not be a symlink. It is currently set to: {output_dir.path}.\")\n\n        if not Path(output_dir.path).is_symlink():\n            if Path(output_dir.path).is_dir():\n                if Path(output_dir.path).is_symlink():\n                    raise ValueError(f\"The `output_dir` must not be a symlink. It is currently set to: {output_dir.path}.\")\n\n        if Path(output_dir.path).is_dir():\n            if Path(output_dir.path).is_symlink():\n                raise ValueError(f\"The `output_dir` must not be a symlink. It is currently set to: {output_dir.path}.\")\n\n    if output_dir.path is not None:\n        if Path(output_dir.path).is_dir():\n            if Path(output_dir.path).is_symlink():\n                raise"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"output_dir must be of type Dir, not {output_dir}\")\n\n    if output_dir.path is None and output_dir.url is None:\n        raise ValueError(\"output_dir must have a path or url\")\n\n    if output_dir.path is not None:\n        if not os.path.exists(output_dir.path):\n            raise FileNotFoundError(\n                f\"The path `{output_dir.path}` does not exist. Make sure the path is correct.\"\n            )\n\n        if not os.path.isdir(output_dir.path):\n            raise ValueError(\n                f\"The path `{output_dir.path}` is not a directory. Make sure the path is correct.\"\n            )\n\n    if output_dir.url is not None:\n        if not output_dir.url.startswith(\"s3://\"):\n            raise ValueError(f\"output_dir.url must start with s3://\")\n\n        if _BOTO3_AVAILABLE:\n            s3 = boto3.resource(\"s3\")\n            bucket = s3.Bucket(output_dir.url.split(\"//\")[1].split(\"/\")[0])\n            bucket.Object(output_dir.url.split(\"//\")[1].split(\"/\")[1]).load()\n        else:\n            raise RuntimeError(\"boto3 is not available\")\n\n    if append is not False and overwrite is not False:\n        raise ValueError(\"Either append or overwrite must be False\")\n\n    if append is False and overwrite is False:\n        if output_dir.url is not None:\n            if _BOTO3_AVAILABLE:\n                s3 = boto3.resource(\"s3\")\n                bucket = s3.Bucket(output_dir.url.split(\"//\")[1].split(\"/\")[0])\n                if not bucket.Object(output_dir.url.split(\"//\")[1].split(\"/\")[1]).does_not_exist():\n                    raise ValueError(\"The directory already contains data\")\n            else:\n                raise RuntimeError(\"boto3 is not available\")\n\n        if output_dir.path is not None:\n            if not os.path.isdir(output_dir.path):\n                raise ValueError(\""}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if output_dir.path is None:\n        raise ValueError(\"`output_dir` must be a Dir object.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(\"`output_dir` must start with 's3://'\")\n\n    if not append and not overwrite:\n        if os.path.isfile(output_dir.path):\n            raise ValueError(\n                \"The directory is not empty. If you want to overwrite the directory, set the `overwrite` parameter to True.\"\n            )\n\n        if os.path.isdir(output_dir.path):\n            raise ValueError(\n                \"The directory is not empty. If you want to append to the directory, set the `append` parameter to True.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The `output_dir` argument must be a Dir object.\")\n    if output_dir.path is None and output_dir.url is None:\n        raise ValueError(\"The `output_dir` argument must be a Dir object with a path and url.\")\n    if output_dir.path is not None and not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(\"The `output_dir` argument must be a Dir object with a path that starts with 's3://'.\")\n    if output_dir.url is not None and not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The `output_dir` argument must be a Dir object with a url that starts with 's3://'.\")\n\n    if append:\n        raise NotImplementedError(\"Appending to a directory is not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in a directory is not implemented.\")\n\n    if output_dir.url is not None:\n        if _BOTO3_AVAILABLE:\n            s3_client = boto3.client(\"s3\")\n            try:\n                s3_client.head_object(Bucket=output_dir.url.split(\"s3://\")[1], Key=output_dir.url.split(\"s3://\")[1].split(\"/\")[-1])\n                raise ValueError(\"The directory is not empty.\")\n            except botocore.exceptions.ClientError:\n                return\n            except botocore.errorfactory.UnknownServiceError:\n                raise ValueError(\"Boto3 is not installed.\")\n        else:\n            raise ValueError(\"Boto3 is not installed.\")\n\n    if output_dir.path is not None:\n        if os.path.isdir(output_dir.path):\n            if os.listdir(output_dir.path):\n                raise ValueError(\"The directory is not empty.\")\n            return\n        else:\n            raise ValueError(\"The directory doesn't exist.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be a Dir object.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The output_dir must start with s3://, got {output_dir}.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is not installed. Please install it to use the S3 connection.\")\n\n    if not append and not overwrite:\n        if not output_dir.path.split(\"/\")[-1] == \"content\":\n            raise ValueError(\n                \"The output_dir must end with the word 'content' if not append or overwrite are set to True.\"\n            )\n\n    s3 = boto3.client(\"s3\")\n\n    if output_dir.path.split(\"/\")[-1] == \"content\":\n        bucket_name = output_dir.path.split(\"//\")[1].split(\"/\")[0]\n        prefix = output_dir.path.split(\"//\")[1].split(\"/\")[1]\n        s3_objects = s3.list_objects(Bucket=bucket_name, Prefix=prefix)\n        if \"Contents\" in s3_objects.keys():\n            if not s3_objects[\"Contents\"]:\n                return\n            else:\n                raise ValueError(\n                    f\"The output_dir, {output_dir.path}, is not empty. \"\n                    \"You can only overwrite or append to an empty directory.\"\n                )\n\n    else:\n        bucket_name = output_dir.path.split(\"//\")[1].split(\"/\")[1]\n        prefix = output_dir.path.split(\"//\")[1].split(\"/\")[2]\n        s3_objects = s3.list_objects(Bucket=bucket_name, Prefix=prefix)\n        if \"Contents\" in s3_objects.keys():\n            if not s3_objects[\"Contents\"]:\n                return\n            else:\n                raise ValueError(\n                    f\"The output_dir, {output_dir.path}, is not empty. \"\n                    \"You can only overwrite or append to an empty directory.\"\n                )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if output_dir.path is not None:\n        if not append and not overwrite:\n            raise ValueError(\n                f\"The specified directory {output_dir.path} is not empty. Please use the `--append` or `--overwrite` flags to allow appending or overwriting data in the directory.\"\n            )\n\n        if not os.path.isdir(output_dir.path):\n            raise ValueError(f\"The specified directory {output_dir.path} does not exist.\")\n\n    if output_dir.url is not None:\n        if not append and not overwrite:\n            raise ValueError(\n                f\"The specified directory {output_dir.url} is not empty. Please use the `--append` or `--overwrite` flags to allow appending or overwriting data in the directory.\"\n            )\n\n        if not _BOTO3_AVAILABLE:\n            raise RuntimeError(\"Boto3 is not available. Please install it to use the `s3` protocol.\")\n\n        s3 = boto3.client(\"s3\")\n\n        try:\n            s3.head_bucket(Bucket=output_dir.url.split(\"s3://\")[1])\n        except botocore.error.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NotFound\":\n                raise ValueError(f\"The specified directory {output_dir.url} does not exist.\")\n\n        s3_directory = s3.get_object(Bucket=output_dir.url.split(\"s3://\")[1], Key=output_dir.url.split(\"s3://\")[1])[\"Body\"].read().decode()\n        if s3_directory != \"\":\n            raise ValueError(f\"The specified directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"output_dir must be a Dir object. Got {output_dir} instead.\")\n\n    if output_dir.path is not None and not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The path in output_dir must start with s3://. Got {output_dir.path} instead.\")\n\n    if output_dir.url is not None and not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The url in output_dir must start with s3://. Got {output_dir.url} instead.\")\n\n    if output_dir.url is not None:\n        if not _BOTO3_AVAILABLE:\n            raise ValueError(\"boto3 is not available. Please install boto3 to use this feature.\")\n\n        if not append and not overwrite:\n            raise ValueError(\n                \"When using s3 as a data directory, you must specify either `append` or `overwrite` as True.\"\n            )\n\n        if output_dir.path is not None:\n            raise ValueError(f\"Please specify either path or url, not both.\")\n\n    if output_dir.path is not None:\n        if not os.path.exists(output_dir.path):\n            raise ValueError(f\"The path {output_dir.path} does not exist.\")\n\n        if not os.path.isdir(output_dir.path):\n            raise ValueError(f\"The path {output_dir.path} is not a directory.\")\n\n        if os.listdir(output_dir.path) != [] and not (append or overwrite):\n            raise ValueError(f\"The path {output_dir.path} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"output_dir must be a Dir, got: {output_dir}\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The directory path must start with s3://, got: {output_dir.path}\")\n\n    # If the directory already exists, check if it is empty.\n    if os.path.exists(output_dir.path):\n        if os.path.isdir(output_dir.path):\n\n            if not append and not overwrite:\n                raise RuntimeError(\n                    f\"The directory {output_dir.path} already exists and is not empty. Please use the overwrite or append argument.\"\n                )\n\n        else:\n            raise RuntimeError(f\"The directory {output_dir.path} already exists and is not a directory.\")\n\n    # If the directory does not exist, create it.\n    if not os.path.exists(output_dir.path):\n        os.makedirs(output_dir.path)\n\n    # If the directory does not exist, create it.\n    if not os.path.isdir(output_dir.path):\n        raise RuntimeError(f\"The directory {output_dir.path} does not exist.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\n            f\"The `output_dir` must be a `Dir` object. Got: {output_dir}\"\n        )\n\n    if not output_dir.path:\n        raise ValueError(\"The `output_dir` must have a path.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with 's3://'. Got: {output_dir}\")\n\n    if not append and not overwrite:\n        raise ValueError(f\"At least one of `append` or `overwrite` must be `True`.\")\n\n    if append:\n        raise ValueError(f\"Appending to a directory is not supported. Got: {output_dir}\")\n\n    if overwrite:\n        raise ValueError(f\"Overwriting to a directory is not supported. Got: {output_dir}\")\n\n    if _BOTO3_AVAILABLE:\n        s3 = boto3.client(\"s3\")\n        s3.head_bucket(Bucket=output_dir.url.split(\"s3://\")[1])\n        if s3.is_empty(Bucket=output_dir.url.split(\"s3://\")[1]) is False:\n            raise ValueError(f\"The directory `{output_dir.path}` is not empty.\")\n\n    elif _LIGHTNING_SDK_AVAILABLE:\n        if Studio.is_dir_empty(output_dir.path) is False:\n            raise ValueError(f\"The directory `{output_dir.path}` is not empty.\")\n        else:\n            print(f\"The directory `{output_dir.path}` is empty.\")\n\n    else:\n        raise RuntimeError(\n            \"The `boto3` and `lightning-sdk` libraries are not installed. You can install them with `pip install boto3` and `pip install lightning-sdk`.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(\n            f\"The output_dir argument must be an instance of the Dir class. The provided value is {type(output_dir)}.\"\n        )\n\n    if not output_dir.path:\n        raise ValueError(\"The output_dir argument must be a local or remote path.\")\n    if not output_dir.url:\n        raise ValueError(\"The output_dir argument must be a local or remote path.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The output_dir argument must be an s3:// path. Got {output_dir}.\")\n\n    if append and not overwrite:\n        raise ValueError(\n            \"The append and overwrite arguments are mutually exclusive. To allow overwriting data, set the overwrite argument to True.\"\n        )\n\n    if append and overwrite:\n        raise ValueError(\n            \"The append and overwrite arguments are mutually exclusive. To allow appending data, set the append argument to True.\"\n        )\n\n    if not append and not overwrite:\n        raise ValueError(\n            \"The append and overwrite arguments must be set to True if you want to allow appending or overwriting data in the directory.\"\n        )\n\n    s3_client = _get_s3_client()\n    s3_resource = _get_s3_resource()\n    bucket_name = output_dir.url.split(\"s3://\")[1].split(\"/\")[0]\n    bucket = s3_resource.Bucket(bucket_name)\n    bucket_contents = s3_client.list_objects(Bucket=bucket_name)\n    bucket_contents = [\n        obj[\"Key\"]\n        for obj in bucket_contents[\"Contents\"]\n        if re.match(\n            pattern=\"^\" + re.escape(output_dir.url.split(\"s3://\")[1].split(\"/\")[0] + \"/\"),\n            string=obj[\"Key\"],\n        )\n    ]\n\n    if bucket_contents:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"`output_dir` must be a Dir object.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(\"`output_dir` must start with s3://\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"Appending or overwriting is not implemented.\")\n\n    if not os.path.exists(output_dir.path):\n        return\n\n    if not os.path.isdir(output_dir.path):\n        raise ValueError(f\"Provided path {output_dir.path} is not a directory.\")\n\n    if not os.listdir(output_dir.path):\n        return\n\n    raise ValueError(\n        f\"The directory {output_dir.path} is not empty. \"\n        \"Please remove all the files and folders in the directory and try again.\"\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if output_dir.path is not None and not os.path.isdir(output_dir.path):\n        raise ValueError(\n            f\"The provided path `{output_dir.path}` is not a directory. \"\n            f\"It is not possible to overwrite a file with a directory.\"\n        )\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(\n            f\"The provided path `{output_dir.path}` is not a path starting with s3://. \"\n            f\"This is not supported.\"\n        )\n\n    if output_dir.path.startswith(\"s3://\"):\n        if not _BOTO3_AVAILABLE:\n            raise ValueError(\"Boto3 is not installed. Please install it using `pip install boto3`\")\n\n        s3 = boto3.resource(\"s3\")\n\n        s3_bucket_name = output_dir.path.split(\"s3://\")[1].split(\"/\")[0]\n        s3_key = output_dir.path.split(\"s3://\")[1]\n\n        if s3.Bucket(s3_bucket_name).objects.filter(Prefix=s3_key):\n            if not append:\n                raise ValueError(\n                    f\"The provided path `{output_dir.path}` is not empty. \"\n                    f\"It is not possible to overwrite a directory.\"\n                )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"Expected `output_dir` to be a `Dir` object, got {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The `output_dir` must have a url.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with `s3://`, got {output_dir.url}\")\n\n    if not append and not overwrite:\n        raise ValueError(\n            \"The `append` and `overwrite` flags must be set to True if the `output_dir` is not empty.\"\n        )\n\n    if append or overwrite:\n        raise ValueError(f\"The `append` and `overwrite` flags are not supported. Got: `{append}` and `{overwrite}`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"Boto3 is not installed. Please install boto3 to use this functionality.\")\n\n    try:\n        s3_client = boto3.client(\"s3\")\n        s3_client.head_bucket(Bucket=output_dir.url.split(\"s3://\")[1])\n    except botocore.exceptions.ClientError:\n        return\n\n    if not s3_client.is_empty(Bucket=output_dir.url.split(\"s3://\")[1]):\n        raise RuntimeError(f\"The `output_dir` is not empty. Please delete the files in the directory before using it.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if output_dir.path is None:\n        raise ValueError(\n            \"The `output_dir` must be a `Dir` object with a path. \"\n            \"The path must be an S3 path starting with s3://.\"\n        )\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(\n            \"The `output_dir` must be a `Dir` object with a path. \"\n            \"The path must be an S3 path starting with s3://.\"\n        )\n\n    if not append and os.path.isdir(output_dir.path):\n\n        if overwrite:\n            print(\n                \"The directory already exists and overwriting is not allowed. \"\n                \"Please use the `append` argument to allow appending data to the directory.\"\n            )\n            raise ValueError(\"The directory already exists and overwriting is not allowed.\")\n\n        print(\"The directory already exists.\")\n        raise ValueError(\"The directory already exists.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be a Dir object.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The output_dir must start with 's3://', but is {output_dir.path}.\")\n\n    if output_dir.path.startswith(\"s3://\"):\n\n        if not _BOTO3_AVAILABLE:\n            raise RuntimeError(\n                \"The boto3 library is not installed. You can install it with `pip install boto3`. For more information, see https://docs.aws.amazon.com/AWSShells/latest/userguide/boto3-installation.html\"\n            )\n\n        if not output_dir.url:\n            raise ValueError(f\"The output_dir must have a url, but is {output_dir.url}.\")\n\n        s3_resource = boto3.resource(\"s3\")\n        bucket = s3_resource.Bucket(output_dir.url.split(\"s3://\")[1].split(\"/\")[0])\n        bucket_objects = bucket.objects.all()\n\n        for bucket_object in bucket_objects:\n            if not append and not overwrite:\n                raise ValueError(f\"The output_dir is not empty. It contains {bucket_object.key}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir.path}\")\n\n    if append or overwrite:\n        raise NotImplementedError(\n            \"The `append` and `overwrite` arguments are not implemented for `_assert_dir_is_empty`.\"\n        )\n\n    if output_dir.url is None:\n        raise ValueError(\n            f\"The `output_dir` must be an S3 directory, got: {output_dir}. \"\n            f\"This is because `output_dir.url` is None.\"\n        )\n\n    s3_client = boto3.client(\"s3\")\n    try:\n        s3_client.head_object(Bucket=output_dir.url.split(\"s3://\")[1], Key=output_dir.path.split(\"s3://\")[1])\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NotFound\":\n            return\n\n    raise ValueError(f\"The directory `{output_dir}` is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The input {output_dir} is not a valid Dir object.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The path {output_dir} does not start with 's3://'.\")\n\n    if not append and not overwrite:\n        if output_dir.url is None:\n            raise ValueError(\n                f\"The directory {output_dir} is not a remote directory. It is not possible to check if the directory is empty.\"\n            )\n\n        # Get the S3 connection\n        s3_connection = _get_s3_connection()\n\n        # Get the bucket\n        bucket = s3_connection.Bucket(output_dir.url.split(\"s3://\")[1])\n        # Get the list of objects\n        objects = list(bucket.objects.all())\n        # Check if the directory is empty\n        if objects:\n            raise ValueError(\n                f\"The directory {output_dir} is not empty. It contains the following objects: {objects}\"\n            )\n\n    return\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"Expected output_dir to be a Dir, got {type(output_dir)}.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\n            f\"The output_dir must be a s3:// url. Got {output_dir}. \"\n            f\"You can use the `resolve_dir()` function to get a Dir object from a path.\"\n        )\n\n    if output_dir.path is None:\n        raise ValueError(f\"The output_dir cannot be None. Got {output_dir}.\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"This function does not support appending or overwriting data.\")\n\n    if not os.path.exists(output_dir.path):\n        return\n\n    if os.path.isfile(output_dir.path):\n        raise ValueError(f\"The output_dir cannot be a file. Got {output_dir}.\")\n\n    # TODO: Check if the directory is empty\n    if not os.path.isdir(output_dir.path):\n        raise ValueError(f\"The output_dir must be a directory. Got {output_dir}.\")\n\n    if not os.path.isdir(output_dir.path):\n        raise ValueError(f\"The output_dir must be a directory. Got {output_dir}.\")\n\n    # TODO: Check if the directory is empty\n    if os.listdir(output_dir.path):\n        raise ValueError(f\"The output_dir is not empty. Got {output_dir}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if output_dir.path is None:\n        raise ValueError(\"`output_dir` must be a Dir object.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(\"`output_dir` must start with `s3://` to be a valid S3 path.\")\n\n    if not append and not overwrite:\n        if os.path.isdir(output_dir.path):\n            raise ValueError(\n                f\"The provided directory `{output_dir.path}` is not empty. \"\n                \"You can pass `append=True` to allow appending data to the directory.\"\n                \"You can also pass `overwrite=True` to allow overwriting data in the directory.\"\n            )\n\n    if append or overwrite:\n        raise ValueError(\n            \"Appending or overwriting data to the directory is not yet implemented. \"\n            \"Please pass `append=False` and `overwrite=False` to check if the directory is empty.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a Dir object, not a {type(output_dir)}.\")\n\n    if not output_dir.path.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 path, not a {output_dir.path}.\")\n\n    if not append and not overwrite:\n        if os.path.exists(output_dir.path):\n            raise ValueError(\n                f\"The `output_dir` already exists and neither `append` nor `overwrite` are set to True. \"\n                f\"The path is {output_dir.path}\"\n            )\n\n    if _BOTO3_AVAILABLE:\n        try:\n            s3_client = boto3.client(\"s3\")\n\n            if output_dir.url:\n                s3_client.head_object(Bucket=output_dir.url.split(\n                    \"s3://\", 1\n                )[1], Key=output_dir.path.split(\"s3://\", 1)[1])\n        except botocore.exceptions.ClientError:\n            pass\n    else:\n        raise ImportError(\"Boto3 is not installed. Please install it to use this function.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" not in objects or not objects[\"Contents\"]:\n        return\n\n    for content in objects[\"Contents\"]:\n        if content[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\":\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'. \"\n                \"The dataset is meant to be immutable. HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj.path.lstrip(\"/\").rstrip(\"/\")}]},\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n    if \"Contents\" not in objects:\n        raise ValueError(\"The provided folder is not an S3 bucket directory.\")\n\n    if \"KeyCount\" in objects and objects[\"KeyCount\"] > 0:\n        if \"Name\" in objects[\"Contents\"][0] and \"index.json\" in objects[\"Contents\"][0][\"Name\"]:\n            raise ValueError(\n                \"The provided folder is not empty and already contains an index file. This is not allowed.\"\n            )\n        else:\n            s3.delete_objects(\n                Bucket=obj.netloc,\n                Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\"}]},\n            )\n\n    if \"DeleteMarker\" not in objects:\n        s3.put_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\", Body=\"{}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    objects = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\"))\n\n    if \"Contents\" in objects:\n        if \"index.json\" in [obj.key for obj in objects[\"Contents\"]]:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'. \"\n                \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n        else:\n            s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"}]})\n    else:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` doesn't contain any object.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    objects = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\"))\n\n    # We aren't alloweing to add more data\n    if \"Contents\" not in objects:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` does not contain any data. \"\n            \"HINT: Did you consider creating a new folder with your own versioning as a suffix?\"\n        )\n\n    if \"KeyCount\" in objects and objects[\"KeyCount\"] > 1:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data. \"\n            \"HINT: Did you consider creating a new folder with your own versioning as a suffix?\"\n        )\n\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"] == \"index.json\":\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file. \"\n                \"HINT: Did you consider creating a new folder with your own versioning as a suffix?\"\n            )\n\n    if \"Contents\" in objects and objects[\"Contents\"]:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]], \"Quiet\": True},\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    s3_objects = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\")\n    s3_objects_with_index = [\n        s3_object[\"Key\"] for s3_object in s3_objects[\"Contents\"] if s3_object[\"Key\"] == \"index.json\"\n    ]\n\n    if len(s3_objects_with_index) > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file. HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n    else:\n        s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"}]})\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory already contains an index file, it is not allowed to be overwritten.\n    if \"Contents\" in objects and len(objects[\"Contents\"]) > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == \"index.json\":\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`.\"\n                )\n\n    # If the directory does not contain an index file, it will be deleted.\n    if \"Contents\" not in objects or len(objects[\"Contents\"]) == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\"}]},\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if obj.path.endswith(\"/index.json\"):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'. HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" not in objects:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` is not an S3 directory.\")\n\n    if \"KeyCount\" in objects and objects[\"KeyCount\"] > 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\n                        \"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n                        + object[\"Key\"]\n                        if object[\"Key\"] != \"index.json\"\n                        else object[\"Key\"]\n                        for object in objects[\"Contents\"]\n                    }\n                ]\n            },\n        )\n\n    return\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if \"KeyCount\" in objects and objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": []})\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # Check if the directory contains an index.json file.\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        if \"index.json\" in [obj.key for obj in objects[\"Contents\"]]:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n        # If the directory does not contain an index.json file, delete all objects within the specified prefix in the bucket.\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": key} for key in [obj.key for obj in objects[\"Contents\"]]\n            },\n        )\n\n    else:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` doesn't contain any objects.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n    # If the directory contains an index file, raise an error\n    if \"Contents\" in objects and any(\n        \"Key\" in object and \"index.json\" in object[\"Key\"] for object in objects[\"Contents\"]\n    ):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n    # Delete all objects in the directory if an index file is not found\n    else:\n        for object in objects[\"Contents\"]:\n            if \"Key\" in object:\n                s3.delete_object(Bucket=obj.netloc, Key=object[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    if \"index.json\" in s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\").get(\"Contents\", []):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`. \"\n            \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\"Objects\": [{\"Key\": key} for key in s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\").get(\"Contents\", [])]},\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if \"KeyCount\" in objects:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    if \"Contents\" not in objects:\n        return\n\n    # Remove all the objects\n    for object_data in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=object_data[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": []})\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if \"index.json\" in s3.list_object_versions(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\")):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file. \"\n            \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if \"Contents\" in objects and \"KeyCount\" in objects and objects[\"Contents\"]:\n        if \"index.json\" in [x[\"Key\"] for x in objects[\"Contents\"]]:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`.\"\n            )\n\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\"Key\": x[\"Key\"]}\n                    for x in objects[\"Contents\"]\n                    if not x[\"Key\"].endswith(\"/index.json\")\n                ]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    bucket_name = obj.netloc\n    prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"Boto3 is not available. Please install it before using this function.\")\n\n    try:\n        s3.head_object(Bucket=bucket_name, Key=prefix + \"index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] != \"404\":\n            raise\n        s3.delete_objects(Bucket=bucket_name, Delete={\"Objects\": [{'Key': prefix + \"index.json\"}]})\n    else:\n        raise RuntimeError(\"The provided output_dir already contains an index.json file.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n\n        if \"index.json\" in [obj.name for obj in objects[\"Contents\"]]:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file. \"\n                \"HINTS: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n        # Delete the objects in the bucket\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.bucket_name, Key=obj.key)\n    else:\n        # No objects in the bucket\n        return\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We are not allowing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    if \"Contents\" not in objects:\n        return\n\n    # Delete any objects in the bucket that are not the index file\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"] == \"index.json\":\n            continue\n\n        s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    if output_dir.path is not None:\n        raise ValueError(\"The provided output_dir should not be a local path.\")\n\n    obj = parse.urlparse(output_dir.url)\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n    if s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\"):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file.\"\n            \" HINT: Did you consider renaming the file?\"\n        )\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n    if objects[\"KeyCount\"] == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key[\"Key\"]} for key in objects[\"Contents\"]],}\n        )\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            while True:\n                sleep(0.001)\n                if os.path.exists(self.write_chunks_index()):\n                    break\n        else:\n            while len(self.done()) < num_workers:\n                sleep(0.001)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.is_distributed() and node_rank is None:\n            node_rank = self.rank\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(0.1)  # sleep to avoid CPU usage\n        else:\n            while len(self.done()) < num_workers:\n                sleep(0.1)  # sleep to avoid CPU usage\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all workers to finish\n        if node_rank is None:\n            node_rank = self.rank\n        while not self.filled:\n            sleep(0.5)\n\n        # Wait for all workers to finish\n        for i in range(1, num_workers):\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")):\n                sleep(0.5)\n\n        # Wait for the master node to finish\n        while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n            sleep(0.5)\n\n        if node_rank != 0:\n            # Wait for the merged index file to be available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.index\")):\n                sleep(0.5)\n            return\n\n        # Merge the index files\n        chunks_info: List[Dict[str, Any]] = []\n        for i in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")) as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.index\"), \"w\") as f:\n            json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, f, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts of the index are available\n        while len(self._chunks_info) < num_workers:\n            sleep(0.1)\n\n        # If the node is not the master, wait for the merged index file to be available\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(0.1)\n\n        # Merge the index files\n        if self._distributed_env.world_size > 1:\n            # In distributed environments, the merge is performed by a single node (rank 0)\n            assert node_rank is not None\n            assert node_rank == 0\n            merged_index = self.write_chunks_index()\n        else:\n            merged_index = self.write_chunks_index()"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.world_size == 1 or node_rank is None or node_rank == self.rank:\n            return\n\n        # Wait for all the workers to finish\n        while self._distributed_env.size() != self._distributed_env.world_size:\n            sleep(0.01)\n\n        # Wait for all the workers to write down the index files\n        while len(self._chunks_info) < num_workers:\n            sleep(0.01)\n\n        # Wait for the master node to finish the merge\n        while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{self._INDEX_FILENAME}\")):\n            sleep(0.01)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        # Wait until all index files are available\n        while len(self._chunks_info) < num_workers:\n            sleep(0.01)\n\n        # Only the master node is responsible for merging\n        if node_rank != 0:\n            while not os.path.isfile(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(0.01)\n            return\n\n        # Merge all index files\n        chunks = []\n        for worker in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{worker}.{_INDEX_FILENAME}\")) as f:\n                chunks.append(json.load(f)[\"chunks\"])\n        merged_chunks = []\n        for chunk in chunks:\n            merged_chunks.extend(chunk)\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as f:\n            json.dump({\"chunks\": merged_chunks, \"config\": self.get_config()}, f, sort_keys=True)\n\n        # Remove all index files\n        for worker in range(num_workers):\n            os.remove(os.path.join(self._cache_dir, f\"{worker}.{_INDEX_FILENAME}\"))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        # Wait for all the workers to finish writing their chunks\n        while len(self._chunks_info) < num_workers:\n            sleep(0.1)\n\n        # If the node is not the master, wait for the master to merge the index files.\n        if node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(0.1)\n\n        # Merge the index files\n        master_index = self.write_chunks_index()\n        if node_rank == 0:\n            chunks_info = []\n            for i in range(num_workers):\n                with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")) as f:\n                    chunks = json.load(f)[\"chunks\"]\n                    chunks_info.extend(chunks)\n\n            with open(master_index, \"w\") as f:\n                json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, f, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all workers to finish\n        while not self.filled:\n            sleep(0.1)\n            if self.rank != 0:\n                # If I'm not the master node, I'm waiting for the master to finish\n                continue\n\n            # If I'm the master node, I'm waiting for all other nodes to finish\n            for i in range(num_workers):\n                if i != 0 and not os.path.exists(f\"{i}.{_INDEX_FILENAME}\"):\n                    sleep(0.1)\n                    continue\n\n        # Merge the files\n        if self.rank == 0:\n            self.write_chunks_index()\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if num_workers is None:\n            num_workers = 1\n        if node_rank is None:\n            node_rank = 0\n        if self.rank != node_rank:\n            # Wait for the master node to complete the merge process\n            while not os.path.isfile(f\"{self.rank}.{_INDEX_FILENAME}\"):\n                sleep(1)\n            return\n\n        # Wait for all workers to complete their work\n        for worker_rank in range(num_workers):\n            while not os.path.isfile(f\"{worker_rank}.{_INDEX_FILENAME}\"):\n                sleep(1)\n\n        # Merge the index files\n        merged_filename = f\"master.index.{self.rank}.{_INDEX_FILENAME}\"\n        merged_index = []\n        for worker_rank in range(num_workers):\n            with open(f\"{worker_rank}.{_INDEX_FILENAME}\", \"r\") as f:\n                merged_index.extend(json.load(f)[\"chunks\"])\n\n        with open(merged_filename, \"w\") as f:\n            json.dump({\"chunks\": merged_index, \"config\": self.get_config()}, f, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the merge is already done\n        if self.filled:\n            return\n\n        # Wait for all index files to be available\n        index_files = os.listdir(self._cache_dir)\n        index_files_to_wait = [\n            f for f in index_files if f.endswith(_INDEX_FILENAME) and f.count(\"_\") == 1\n        ]\n        while len(index_files_to_wait) != num_workers:\n            sleep(0.001)\n            index_files = os.listdir(self._cache_dir)\n            index_files_to_wait = [\n                f for f in index_files if f.endswith(_INDEX_FILENAME) and f.count(\"_\") == 1\n            ]\n\n        # Check if the merge is done\n        if self.filled:\n            return\n\n        # If the node is not the master node, wait for the merged index file\n        if node_rank is None:\n            node_rank = get_worker_rank()\n        if node_rank != 0:\n            merged_index_file = os.path.join(self._cache_dir, f\"{node_rank}.{self._INDEX_FILENAME}\")\n            while not os.path.exists(merged_index_file):\n                sleep(0.001)\n            return\n\n        # Merge the index files\n        merged_index = {}\n        for index_file in index_files_to_wait:\n            with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                chunk_info = json.load(f)\n            for chunk_info_ in chunk_info[\"chunks\"]:\n                if chunk_info_[\"filename\"] in merged_index:\n                    raise RuntimeError(\n                        f\"The merged index contains a duplicate chunk: {chunk_info_['filename']}\"\n                    )\n                merged_index[chunk_info_[\"filename\"]] = chunk_info_\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{self._INDEX_FILENAME}\"), \"w\") as f:\n            json.dump({\"chunks\":"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the function is called on the master node\n        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        # Check if the function is called on the master node\n        if node_rank != 0:\n            # Wait for the master node to complete the merge\n            while not os.path.exists(self._cache_dir):\n                sleep(0.5)\n\n        # Check if the function is called on the master node\n        if node_rank == 0:\n            # Merge all index files\n            for i in range(num_workers):\n                for filename in os.listdir(self._cache_dir):\n                    if filename.endswith(f\"{i}.{_INDEX_FILENAME}\"):\n                        with open(filename, \"r\") as f:\n                            chunk_info = json.load(f)\n                        chunk_info[\"chunks\"].extend(chunk_info.pop(\"config\").get(\"chunks\", []))\n                        if \"chunks\" not in self._chunks_info:\n                            self._chunks_info = chunk_info[\"chunks\"]\n                        else:\n                            self._chunks_info.extend(chunk_info[\"chunks\"])\n\n        # Update the chunks info\n        self._chunks_info = sorted(self._chunks_info, key=lambda x: x[\"filename\"])\n\n        # Update the config\n        if node_rank == 0:\n            self.config = self.get_config()\n\n        # Remove the temporary index files\n        if node_rank == 0:\n            for filename in os.listdir(self._cache_dir):\n                if filename.endswith(\".bin\"):\n                    os.remove(os.path.join(self._cache_dir, filename))\n                if filename.endswith(_INDEX_FILENAME):\n                    os.remove(os.path.join(self._cache_dir, filename))"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all the index files to be available\n        while True:\n            sleep(1)\n            if self._distributed_env.is_master and os.path.isfile(self.write_chunks_index()):\n                break\n\n        # Wait for all the workers to finish\n        while True:\n            sleep(1)\n            if self._distributed_env.is_master and self.filled:\n                break\n\n        # Merge the index files\n        if self._distributed_env.is_master:\n            # Merge all the index files into a single one\n            merged_chunks_info = []\n            for i in range(self._distributed_env.world_size):\n                chunks_file_path = os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")\n                if not os.path.isfile(chunks_file_path):\n                    continue\n                with open(chunks_file_path) as f:\n                    chunks = json.load(f)\n                merged_chunks_info.extend(chunks[\"chunks\"])\n\n            # Write the merged index file\n            merged_index_file = os.path.join(self._cache_dir, f\"merged.index\")\n            with open(merged_index_file, \"w\") as f:\n                json.dump(\n                    {\n                        \"chunks\": merged_chunks_info,\n                        \"config\": self.get_config(),\n                    },\n                    f,\n                    sort_keys=True,\n                )\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for the index files to be available\n        while not all(os.path.isfile(os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\")) for rank in range(num_workers)):\n            sleep(0.1)\n\n        # Check if we are the master node\n        if node_rank is None:\n            node_rank = self.rank\n        if node_rank != 0:\n            # Wait for the merged index file to be available\n            while not os.path.isfile(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(0.1)\n            return\n\n        # Read the index files\n        index_files = [\n            os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\")\n            for rank in range(num_workers)\n            if os.path.isfile(os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\"))\n        ]\n        with open(index_files[0], \"r\") as f:\n            chunks = json.load(f)[\"chunks\"]\n        chunks_info = chunks\n        for index_file in index_files[1:]:\n            with open(index_file, \"r\") as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        # Merge the chunks\n        merged_chunks: List[Dict[str, Any]] = []\n        for chunk in chunks_info:\n            merged_chunks.append(chunk)\n            for i in range(1, num_workers):\n                chunk_i = chunks_info[i]\n                if chunk[\"filename\"] == chunk_i[\"filename\"]:\n                    merged_chunks.append(chunk_i)\n                    break\n        chunks_info = merged_chunks\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info}, out, sort_keys=True)\n\n        # Remove the individual index files\n        for index_file in index_files"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all workers to finish\n        if self.rank != 0:\n            while True:\n                try:\n                    sleep(1)\n                except KeyboardInterrupt:\n                    return\n                if os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"')):\n                    return\n\n        # Wait for all workers to finish\n        while len(os.listdir(self._cache_dir)) < num_workers * (self._worker_env.world_size or 1):\n            sleep(1)\n\n        # Merge all files\n        chunks_info = []\n        for i in range(num_workers):\n            for chunk_info in self._load_chunks_info(i, node_rank):\n                chunks_info.append(chunk_info)\n\n        # Write the merged index file\n        chunks_info = sorted(chunks_info, key=lambda x: x[\"chunk_index\"])\n        with open(os.path.join(self._cache_dir, self.get_chunk_filename()), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank != 0:\n            while not os.path.isfile(os.path.join(self._cache_dir, self.get_chunk_filename())):\n                sleep(0.5)\n\n        if self.rank == 0:\n            num_workers = self._distributed_env.world_size\n        else:\n            num_workers = num_workers\n\n        while not self.filled:\n            sleep(0.5)\n\n        # Get the index files\n        index_files = os.listdir(self._cache_dir)\n        index_files = [\n            f for f in index_files if f.endswith(_INDEX_FILENAME) and f.startswith(str(self.rank))\n        ]\n\n        if len(index_files) < num_workers:\n            # Not all index files are available yet\n            sleep(0.5)\n            return\n\n        # Merge the index files\n        with open(os.path.join(self._cache_dir, self.get_chunk_filename()), \"wb\") as out:\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"rb\") as in_file:\n                    out.write(in_file.read())\n        # Delete the index files\n        for index_file in index_files:\n            os.remove(os.path.join(self._cache_dir, index_file))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(0.1)\n\n        # Wait for all workers to finish\n        while self._rank is None or self.rank != 0:\n            if self._rank is None:\n                self._rank = get_worker_rank()\n                if self._rank is None:\n                    sleep(0.1)\n            else:\n                sleep(0.1)\n\n        # Merge the index files\n        # TODO: This is a temporary solution to prevent a deadlock.\n        #       This should be replaced with a proper wait for all workers to finish\n        if self._rank == 0:\n            for _ in range(num_workers):\n                self.write_chunks_index()\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank == 0:\n            # Wait until all the index files are available\n            while len(self._chunks_info) != num_workers * self._distributed_env.world_size:\n                sleep(0.1)\n            # Merge the chunks\n            self.merge_chunks()\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank == 0:\n            while not all_indexes_available():\n                sleep(0.1)\n\n            master_index_file = os.path.join(self._cache_dir, \"master_index.json\")\n            # Write the master index file\n            with open(master_index_file, \"w\") as out:\n                json.dump(\n                    {\n                        \"chunks\": [\n                            {\"filename\": os.path.join(self._cache_dir, chunk_info[\"filename\"]), **chunk_info}\n                            for chunk_info in self._chunks_info\n                        ],\n                        \"config\": self.get_config(),\n                    },\n                    out,\n                    sort_keys=True,\n                )\n            return\n\n        while not all_indexes_available():\n            sleep(0.1)\n\n        # Read the master index file\n        master_index = read_master_index(master_index_file)\n\n        # Read the chunks from the master index\n        for chunk_info in master_index[\"chunks\"]:\n            chunk_file = chunk_info[\"filename\"]\n            with open(chunk_file, \"rb\") as in_file:\n                raw_data = in_file.read()\n\n            # Decompress the raw data if necessary\n            if self._compression:\n                raw_data = self._compressor.decompress(raw_data)\n\n            self.write_chunk_to_file(raw_data, chunk_file)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all workers are done\n        if num_workers is None:\n            num_workers = self._distributed_env.world_size * self._worker_env.world_size\n        while True:\n            if self.filled:\n                break\n            sleep(0.02)\n\n        # Wait for the master node to merge\n        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank == 0:\n            # Merge the chunks\n            chunks_path = os.path.join(self._cache_dir, f\"chunk-{node_rank}-{self._chunk_index}.bin\")\n            index_path = os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")\n            with open(chunks_path, \"rb\") as f:\n                chunks = f.read()\n\n            # Merge the index files\n            index_files = [\n                os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\")\n                for rank in range(num_workers)\n            ]\n            index_files.remove(index_path)\n            with open(index_path, \"r\") as index_file:\n                index_data = json.load(index_file)\n            for index_file in index_files:\n                with open(index_file, \"r\") as f:\n                    index_data[\"chunks\"].extend(json.load(f)[\"chunks\"])\n\n            # Save the index\n            index_path = os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")\n            with open(index_path, \"w\") as f:\n                json.dump(index_data, f)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the merge is already done, do nothing\n        if self.filled:\n            return\n\n        # Wait for the chunks to be available\n        while len(self._chunks_info) < num_workers:\n            sleep(1)\n\n        # If this is not the master node, wait for the merged index\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(1)\n\n        # Merge the chunks\n        filepath = os.path.join(self._cache_dir, self.write_chunks_index())\n        self.write_chunks_index()\n\n        # If this is the master node, wait for the chunks to be available\n        if node_rank is not None and node_rank == 0:\n            while not os.path.exists(filepath):\n                sleep(1)\n            with open(filepath) as f:\n                data = json.load(f)\n\n            if data[\"config\"] != self.get_config():\n                raise RuntimeError(\n                    f\"The index file {filepath} is not compatible with the provided config. \"\n                    f\"The provided config is {self.get_config()}.\"\n                )\n\n            for index, chunk_info in enumerate(data[\"chunks\"]):\n                chunk_filename = chunk_info[\"filename\"]\n                chunk_filepath = os.path.join(self._cache_dir, chunk_filename)\n                with open(chunk_filepath) as f:\n                    chunk_data = f.read()\n                self.write_chunk_to_file(chunk_data, chunk_info[\"filename\"])\n\n                if index == 0:\n                    self._chunks_info = chunk_info[\"chunks\"]\n\n        self.done()\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning-sdk`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The boto3 client is not available. Please install it with `pip install boto3`. \"\n            \"If you are using a virtual environment, make sure to activate it.\"\n        )\n\n    if machine is None:\n        machine = Studio.get_default_machine(name)\n\n    if command is None:\n        command = \"ls\"\n\n    job = Studio.create_job(machine, name, num_nodes, command)\n    print(job.url)\n\n    while not job.is_done:\n        sleep(1)\n        job.refresh()\n\n    if job.status.name != \"COMPLETED\":\n        raise RuntimeError(\n            f\"The job '{job.name}' failed with status '{job.status.name}' and message '{job.status.message}'\"\n        )"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning_sdk` module is not available. Please install it with `pip install lightning_sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {sys.argv[0]!r} && {sys.argv[1]!r}\"\n\n    try:\n        studio = Studio(\n            url=_get_lightning_cloud_url(),\n            name=name,\n            num_nodes=num_nodes,\n            machine=machine,\n            command=command,\n        )\n        print(f\"The job {name} is running on {studio.url}.\")\n    except Exception as e:\n        raise RuntimeError(f\"Could not create the job. Error: {e}\")\n\n    while True:\n        try:\n            studio.wait_for_job_status()\n            if studio.status == \"running\":\n                sleep(1)\n            else:\n                break\n        except Exception as e:\n            raise RuntimeError(f\"Job failed with error: {e}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if machine is None:\n        if _LIGHTNING_SDK_AVAILABLE:\n            machine = Studio.get_machine_config()\n        else:\n            raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning_sdk`.\")\n\n    if not isinstance(machine, Machine):\n        raise RuntimeError(\"The machine argument must be a Machine object.\")\n\n    if command is None:\n        if _LIGHTNING_SDK_AVAILABLE:\n            command = Studio.get_command()\n        else:\n            raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning_sdk`.\")\n\n    if not isinstance(command, str):\n        raise RuntimeError(\"The command argument must be a string.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The Boto3 SDK is not available. Please install it with `pip install boto3`.\")\n\n    client = LightningClient()\n\n    # Get the ids from env variables\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if not isinstance(num_nodes, int):\n        raise ValueError(\"The `num_nodes` argument must be an int.\")\n\n    if not 0 < num_nodes:\n        raise ValueError(\"The `num_nodes` argument must be greater than 0.\")\n\n    if not isinstance(command, str):\n        raise ValueError(\"The `command` argument must be a string.\")\n\n    if not isinstance(name, str):\n        raise ValueError(\"The `name` argument must be a string.\")\n\n    # Get the job\n    job = client.job_service_create_job(\n        cluster_id=cluster_id,\n        name=name,\n        project_id=project_id,\n        machine=machine.to_dict(),\n        command=command,\n        num_nodes"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ValueError(\n            \"The `lightning_sdk` library is not available. \"\n            \"It's used for creating the job. \"\n            \"Please install it with `pip install lightning_sdk`.\"\n        )\n    if not _BOTO3_AVAILABLE:\n        raise ValueError(\n            \"The `boto3` library is not available. \"\n            \"It's used for creating the job. \"\n            \"Please install it with `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Studio().get_default_machine()\n\n    if command is None:\n        command = (\n            f\"cd {os.path.abspath(os.path.dirname(__file__))} && \"\n            f\"export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID', '')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID', '')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID', '')} && \"\n            f\"export LIGHTNING_CLOUD_ACCESS_KEY_ID={os.getenv('LIGHTNING_CLOUD_ACCESS_KEY_ID', '')} && \"\n            f\"export LIGHTNING_CLOUD_SECRET_ACCESS_KEY={os.getenv('LIGHTNING_CLOUD_SECRET_ACCESS_KEY', '')} && \"\n            f\"export LIGHTNING_CLOUD_TOKEN={os.getenv('LIGHTNING_CLOUD_TOKEN', '')} && \"\n            f\"python3 -m lightning_cloud_sdk {name}\"\n        )\n    else:\n        command = f\"cd {os.path.abspath(os.path.dirname(__file__))} && {command}\"\n\n    job = Studio().create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Started job {job.id} at {job.url}\")\n    print"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is required to run this function. Please install it using `pip install lightning_sdk`.\"\n        )\n\n    if machine is None:\n        machine = Studio.get_machine_by_name(\"data_preparation\")\n\n    if command is None:\n        command = \"cd \" + os.getcwd() + \" && \" + \" \".join(sys.argv)\n\n    job = Studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"The job {job.id} is running on {job.node_count} node(s).\")\n    print(f\"You can follow the job status at {job.url}.\")\n\n    while True:\n        job = Studio.get_job(job.id)\n        if job.status in (\"completed\", \"failed\", \"cancelled\"):\n            break\n\n        sleep(5)\n\n    if job.status == \"completed\":\n        print(\"The job is completed.\")\n    elif job.status == \"failed\":\n        print(f\"The job failed with the following error: {job.error_message}.\")\n        raise RuntimeError(job.error_message)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if _LIGHTNING_SDK_AVAILABLE:\n        studio = Studio(url=_get_lightning_cloud_url(), api_token=os.getenv(\"LIGHTNING_API_TOKEN\", \"\"))\n        job = studio.create_job(\n            name=name,\n            num_nodes=num_nodes,\n            machine=machine,\n            command=command,\n        )\n        print(f\"Job started with URL {job.url}\")\n        while job.status.state != \"FINISHED\":\n            sleep(1)\n            job.refresh()\n            print(f\"Job status: {job.status.state}\")\n            if job.status.state == \"FAILED\":\n                raise RuntimeError(f\"Job {name} failed.\")\n        print(f\"Job {name} finished.\")\n    else:\n        if sys.version_info.major == 2:\n            from lightning_utilities import execute\n\n            execute(name, num_nodes, machine, command)\n        elif sys.version_info.major == 3:\n            from lightning_utilities.execute import execute\n\n            execute(name, num_nodes, machine, command)\n        else:\n            raise RuntimeError(\"Unable to find the lightning_utilities module.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not installed. Please install it first.\")\n\n    if machine is None:\n        studio = Studio()\n        machine = studio.default_machine\n\n    if command is None:\n        command = (\n            f\"cd {machine.working_directory}; \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={machine.project_id}; \"\n            f\"export LIGHTNING_CLUSTER_ID={machine.cluster_id}; \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={machine.cloud_space_id}; \"\n            f\"export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()}; \"\n            f\"export LIGHTNING_CLOUD_ACCESS_KEY={machine.access_key}; \"\n            f\"export LIGHTNING_CLOUD_SECRET_KEY={machine.secret_key}; \"\n            f\"export LIGHTNING_CLOUD_SESSION_TOKEN={machine.session_token}; \"\n        )\n\n    studio = Studio()\n\n    try:\n        job = studio.jobs.create(\n            name=name,\n            num_nodes=num_nodes,\n            machine=machine,\n            command=command,\n        )\n\n    except Exception:\n        raise RuntimeError(\"An error occurred while creating the job.\")\n\n    print(f\"Job URL: {job.url}\")\n\n    # Wait for the job to start\n    while True:\n        sleep(1)\n        job.reload()\n        if job.state == \"RUNNING\":\n            break\n\n    # Wait for the job to finish\n    while True:\n        sleep(1)\n        job.reload()\n        if job.state == \"FAILED\":\n            raise RuntimeError(f\"Job {job.url} has failed.\")\n        if job.state == \"FINISHED\":\n            break\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not available. To use the `execute` method, \"\n            \"please install lightning_sdk with `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The Boto3 library is not available. To use the `execute` method, \"\n            \"please install boto3 with `pip install boto3`.\"\n        )\n\n    if machine is None:\n        studio = Studio(\n            url=_get_lightning_cloud_url(),\n            token=os.getenv(\"LIGHTNING_CLOUD_TOKEN\", \"\"),\n            project_id=os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", \"\"),\n            cluster_id=os.getenv(\"LIGHTNING_CLUSTER_ID\", \"\"),\n            cloud_space_id=os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", \"\"),\n        )\n        machine = studio.machines.default.get()\n    else:\n        studio = None\n\n    if command is None:\n        command = (\n            f\"cd {os.path.dirname(sys.argv[0])};\"\n            f\"export LIGHTNING_CLOUD_TOKEN={os.getenv('LIGHTNING_CLOUD_TOKEN')};\"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')};\"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')};\"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')};\"\n        )\n\n        if studio is not None:\n            command += f\"export LIGHTNING_STUDIO_ID={studio.id};\"\n            command += f\"export LIGHTNING_STUDIO_NAME={studio.name};\"\n\n        command += f\"python3 {sys.argv[0]}.py {os.path.basename(sys.argv[0])} --quiet\"\n\n    # Start the job\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK by running `pip install lightning_sdk`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"Boto3 is not available. Please install it by running `pip install boto3`.\")\n\n    if machine is None:\n        machine = Studio(\n            # TODO: Add more defaults\n            num_gpus=0,\n            num_cores=2,\n            memory_gb=10,\n        )\n\n    if command is None:\n        command = \"cd .\"\n        command += \" && \"\n        command += \"export LIGHTNING_CLOUD_URL=\"\n        command += _get_lightning_cloud_url()\n        command += \" && \"\n        command += \"export LIGHTNING_CLUSTER_ID=\"\n        command += os.getenv(\"LIGHTNING_CLUSTER_ID\")\n        command += \" && \"\n        command += \"export LIGHTNING_CLOUD_PROJECT_ID=\"\n        command += os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\")\n\n    try:\n        studio = Studio()\n        job_id = studio.create_job(name=name, machine=machine, command=command, num_nodes=num_nodes)\n        print(f\"Job {job_id} started. You can follow the progress at {studio.get_job_url(job_id)}\")\n\n        while True:\n            if studio.is_job_finished(job_id):\n                if studio.is_job_failed(job_id):\n                    raise RuntimeError(f\"Job {job_id} failed.\")\n\n                return\n\n            sleep(1)\n    except Exception as e:\n        print(e)\n        sys.exit(1)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The lightning-sdk is not available. Please install the lightning-sdk.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 is not available. Please install the boto3.\")\n\n    if machine is None:\n        machine = Studio.get_default_machine()\n\n    if command is None:\n        command = \"cd .; \" + \" \".join(sys.argv[1:])\n\n    print(\"Creating a data preparation job for the current script...\")\n    studio = Studio.get_studio(name=name, machine=machine)\n    job = studio.create_data_prep_job(command=command, num_nodes=num_nodes)\n    print(f\"Job ID: {job.id}\")\n    print(f\"Job URL: {job.url}\")\n    print(f\"Job status: {job.status.name}\")\n\n    # TODO: Make this configurable\n    job.wait_for_success(max_tries=10, sleep_time=10)\n\n    if job.status.name != \"SUCCESS\":\n        raise RuntimeError(f\"Job failed with status: {job.status.name}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning_sdk` module is not installed. Please install it via `pip install lightning_sdk`.\"\n        )\n\n    # Get the current working directory\n    cwd = os.getcwd()\n    cwd = cwd.replace(\"\\\\\", \"/\")\n\n    if command is None:\n        command = f\"ls -l\"\n\n    # Create a Studio object\n    studio = Studio(name=name, num_nodes=num_nodes, machine=machine)\n\n    # Execute the job\n    job_id = studio.run(cwd, command)\n    if job_id is None:\n        raise RuntimeError(f\"The job {name} failed to start.\")\n\n    # Get the job URL\n    job_url = f\"{_get_lightning_cloud_url()}/studio/jobs/{job_id}\"\n    sys.stdout.write(f\"The job {name} has started at {job_url}.\\n\")\n\n    # Wait for the job to complete\n    while True:\n        sleep(1)\n        # Get the job status\n        status = studio.get_status(job_id)\n        if status.status == \"error\":\n            raise RuntimeError(f\"The job {name} failed with the following error: {status.message}.\")\n        if status.status == \"success\":\n            break\n        if status.status == \"running\":\n            sys.stdout.write(\".\")\n            sys.stdout.flush()\n\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The lightning-sdk is not installed. Please install the lightning-sdk by running `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The boto3 library is not installed. Please install it by running `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            type_id=\"lightning-sdk/data-preparation\",\n            num_cpus=1,\n            num_gpus=0,\n            num_cores=1,\n            num_nodes=num_nodes,\n            memory_gb=4,\n            max_walltime_mins=1000,\n            max_walltime_hours=10,\n            max_walltime_mins=1000,\n            max_walltime_seconds=1000,\n            max_walltime_days=1000,\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && lightning-sdk run {name}\"\n\n    if not isinstance(command, str):\n        raise ValueError(\"The command must be a string.\")\n\n    if not isinstance(machine, Machine):\n        raise ValueError(\"The machine must be a `lightning_sdk.Machine` object.\")\n\n    if not isinstance(num_nodes, int):\n        raise ValueError(\"The number of nodes must be an integer.\")\n\n    client = LightningClient(max_tries=2)\n\n    # Get the ids from env variables\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    # Get the ids from env variables\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The lightning-sdk is not available. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine.get_default_machine()\n    elif not isinstance(machine, Machine):\n        raise TypeError(\"The `machine` argument must be of type `lightning_sdk.Machine`\")\n\n    if command is None:\n        command = [sys.executable, sys.argv[0]] + sys.argv[1:]\n\n    if not isinstance(command, list):\n        raise TypeError(\"The `command` argument must be a list of strings.\")\n\n    client = Studio.get_client()\n\n    job_id = client.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n        job_type=\"data-preparation\",\n    )\n\n    while True:\n        sleep(1)\n        job = client.get_job(job_id)\n        if job.status == \"running\":\n            print(f\"Job {job.id} is running. You can view the job at {job.url}\")\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"Job {job.id} failed. Please check the job logs at {job.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if _LIGHTNING_SDK_AVAILABLE:\n        studio = Studio()\n        studio.create_job(name, num_nodes, machine, command)\n\n        url = studio.get_job_url(name)\n\n        print(f\"The job {name} was successfully created. You can follow the job at {url}.\")\n\n    else:\n        if _BOTO3_AVAILABLE:\n            client = boto3.client(\"lightsail\")\n            client.create_lightsail_job(name, num_nodes, command)\n            url = client.describe_lightsail_job(name=name, num_nodes=num_nodes)[\"job\"][\"url\"]\n            print(f\"The job {name} was successfully created. You can follow the job at {url}.\")\n        else:\n            raise RuntimeError(\"The SDK and the Boto3 are not available, please install them.\")\n\n    sleep(1)\n    while True:\n        if _LIGHTNING_SDK_AVAILABLE:\n            status = studio.get_job_status(name)\n            if status == \"COMPLETED\":\n                break\n        else:\n            if _BOTO3_AVAILABLE:\n                status = client.describe_lightsail_job(name=name, num_nodes=num_nodes)[\"job\"][\"status\"]\n                if status == \"COMPLETED\":\n                    break\n\n    if status != \"COMPLETED\":\n        if _LIGHTNING_SDK_AVAILABLE:\n            raise RuntimeError(f\"The job {name} failed with status {status}.\")\n        else:\n            raise RuntimeError(f\"The job {name} failed with status {status}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if _LIGHTNING_SDK_AVAILABLE:\n        if machine is None:\n            machine = Studio.current_machine()\n        else:\n            if not isinstance(machine, Machine):\n                raise ValueError(\"The machine argument must be a Machine object.\")\n\n        if command is None:\n            command = f\"cd {os.getcwd()} && source activate lightning_env && {sys.executable} {sys.argv}\"\n\n    else:\n        if machine is not None:\n            raise ValueError(\"The machine argument is not supported without the lightning-sdk.\")\n\n        if command is None:\n            raise ValueError(\"The command argument is required.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ValueError(\"The boto3 library is not installed.\")\n\n    client = LightningClient(max_tries=2)\n    client.cluster_service_create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n    print(f\"Started job: {client.jobs_service_get_job(name=name).job.url}\")\n    while True:\n        job = client.jobs_service_get_job(name=name)\n        if job.job.status == \"RUNNING\":\n            print(job)\n            sleep(1)\n        elif job.job.status == \"COMPLETED\":\n            return\n        elif job.job.status == \"FAILED\":\n            raise RuntimeError(f\"Job {name} failed. Check the logs at {job.job.url}\")\n        else:\n            raise RuntimeError(\n                f\"Job {name} is in an unknown status {job.job.status}. Check the logs at {job.job.url}\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The lightning-sdk is required to run this function. Install it with `pip install lightning-sdk`.\")\n\n    # Get the lightning cloud url\n    lightning_cloud_url = _get_lightning_cloud_url()\n\n    # Get the current project\n    project = Studio.get_current_project()\n\n    # Get the current cluster\n    cluster = Studio.get_current_cluster()\n\n    # Get the current machine\n    if machine is None:\n        machine = Studio.get_current_machine()\n\n    # Get the current command\n    if command is None:\n        command = \"python3 -m lightning_utilities.run\"\n\n    # Get the current working directory\n    working_dir = os.getcwd()\n\n    # Create a new job\n    job = project.create_job(\n        name=name,\n        command=command,\n        num_nodes=num_nodes,\n        machine=machine,\n        working_dir=working_dir,\n    )\n\n    # Start the job\n    job.start()\n\n    # Get the job URL\n    job_url = job.url\n\n    # Wait for the job to start\n    while job.status == \"PENDING\":\n        sleep(1)\n\n    print(f\"Job URL: {job_url}\")\n\n    # Wait for the job to finish\n    while job.status in (\"RUNNING\", \"PENDING\", \"PENDING_SCHEDULING\", \"QUEUED\"):\n        sleep(1)\n\n    # Check if the job failed\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job {job.name} failed with the following error: {job.error}\")\n\n    # Check if the job is still running\n    if job.status == \"RUNNING\":\n        raise RuntimeError(\"The job is still running.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if _LIGHTNING_SDK_AVAILABLE is False:\n        raise RuntimeError(\"The lightning-sdk is not available. Please install the lightning-sdk package.\")\n\n    if machine is None:\n        studio = Studio()\n\n        if studio.is_local_studio_running():\n            machine = studio.get_current_studio_machine()\n        else:\n            machines = studio.get_all_machines()\n            machine = machines[0]\n\n        print(f\"Using the following machine: {machine.name}\")\n\n    if command is None:\n        command = \"python\"\n        if sys.platform == \"win32\":\n            command = \"python.exe\"\n\n        if os.environ.get(\"LIGHTNING_PYTHON_PATH\") is not None:\n            command = os.environ.get(\"LIGHTNING_PYTHON_PATH\")\n\n        command += \" \"\n        command += \" \".join(sys.argv[1:])\n\n    print(f\"Executing the job with the following command: {command}\")\n\n    job = machine.submit_job(\n        name=name,\n        command=command,\n        num_nodes=num_nodes,\n        max_nodes=num_nodes,\n        max_workers=num_nodes,\n    )\n\n    print(f\"The job has been created with the following URL: {job.url}\")\n\n    while not job.is_running():\n        sleep(1)\n        job.reload()\n\n    while not job.is_finished():\n        sleep(1)\n        job.reload()\n\n    if job.is_success():\n        print(f\"The job has been successfully finished.\")\n        return\n    else:\n        raise RuntimeError(f\"The job has failed. The status is {job.status}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    # Check if SDK is available\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The Lightning SDK is not available. Please install it with `pip install lightning_sdk`.\"\n        )\n\n    # Check if the machine is provided\n    if machine is None:\n        # Get the default machine\n        studio = Studio()\n        machine = studio.machine_factory.get_default_machine_for_job(name=name, num_nodes=num_nodes)\n    else:\n        # Validate the machine\n        if not isinstance(machine, Machine):\n            raise ValueError(f\"The machine {machine} is not a valid machine.\")\n\n    # Check if the command is provided\n    if command is None:\n        # Get the default command\n        command = machine.get_command_for_job(name=name, num_nodes=num_nodes)\n\n    # Run the job\n    machine.run_job(name=name, command=command)\n\n    # Wait for the job to start\n    job_url = machine.get_job_url(name)\n    print(f\"Job started at: {job_url}\")\n\n    # Wait for the job to finish\n    machine.wait_for_job_to_finish(name)\n    print(f\"Job finished at: {job_url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning_sdk`\")\n\n    if machine is None:\n        studio = Studio(url=_get_lightning_cloud_url())\n        machine = studio.machine_service.get_default_machine()\n    elif not isinstance(machine, Machine):\n        raise ValueError(\"The provided machine is not a Machine object.\")\n\n    studio = Studio(url=_get_lightning_cloud_url())\n    job = studio.job_service.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n    print(f\"Job started: {job.url}\")\n    while not job.is_done():\n        sleep(3)\n        job.refresh()\n\n    if not job.is_successful():\n        raise RuntimeError(\n            f\"Job {job.url} failed. Status: {job.status}. Check the logs for more details.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if machine is None:\n        if not _LIGHTNING_SDK_AVAILABLE:\n            raise RuntimeError(\n                \"The `lightning-sdk` library is required to execute the job on the remote machine. Please install it with `pip install lightning_sdk`.\"\n            )\n        machine = Studio.get_default_machine_configuration()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}\"\n\n    if not isinstance(num_nodes, int):\n        raise ValueError(\"The `num_nodes` must be an integer.\")\n\n    if not isinstance(command, str):\n        raise ValueError(\"The `command` must be a string.\")\n\n    if not isinstance(name, str):\n        raise ValueError(\"The `name` must be a string.\")\n\n    print(f\"Submitting the job `{name}` to the cloud with {num_nodes} nodes.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is required to execute the job on the remote machine. Please install it with `pip install boto3`.\")\n\n    s3 = boto3.client(\"s3\")\n    bucket = s3.Bucket(os.getenv(\"LIGHTNING_CLOUD_S3_BUCKET\", \"lightning-cloud-jobs\"))\n\n    bucket.upload_fileobj(\n        StringIO(str(machine).encode(\"utf-8\")),\n        f\"machines/{machine.name}\",\n        ExtraArgs={\"ACL\": \"public-read\"},\n    )\n\n    s3.upload_fileobj(\n        StringIO(str(command).encode(\"utf-8\")),\n        f\"jobs/{name}.sh\",\n        ExtraArgs={\"ACL\": \"public-read\"},\n    )\n\n    url = _get_lightning_cloud_url()\n\n    job_url = f\"{url}/jobs/execute\"\n    data = {\n        \"name\": name,\n        \"command\": f\"sh jobs/{name}.sh\",\n        \"num_nodes\": num_nodes,\n        \"machine\": f\"machines/{machine.name}\",\n        \"url\": job_url,\n    }\n\n    response = requests.post(url=job_url, json=data, timeout=10)\n\n    if response.status_code != 2"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._chunks_index_to_be_deleted.append(chunk_index)\n\n        if self._to_delete_queue:\n            self._to_delete_queue.put(self._chunks_index_to_be_deleted)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n        self._chunks_index_to_be_deleted.extend(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._chunks_index_to_be_deleted.append(chunk_index)\n\n        self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        self._chunks_index_to_be_deleted.extend(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        if self._remote_input_dir is not None:\n            config = ChunksConfig.from_remote_dir(\n                self._cache_dir,\n                self._remote_input_dir,\n                self._compression,\n                self._serializers,\n                self._item_loader,\n            )\n        else:\n            config = ChunksConfig.from_dir(self._cache_dir, self._compression, self._serializers, self._item_loader)\n\n        if config is None:\n            return None\n\n        self._config = config\n        return config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Create the config\n        self._config = ChunksConfig(\n            _cache_dir=self._cache_dir,\n            _serializers=self._serializers,\n            _remote_input_dir=self._remote_input_dir,\n            _compression=self._compression,\n            _item_loader=self._item_loader,\n            _distributed_env=self._distributed_env,\n            _max_cache_size=self._max_cache_size,\n        )\n\n        # Load the config\n        self._config.load_config()\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                input_dir=self._remote_input_dir,\n                compression=self._compression,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig.load(\n                cache_dir=self._cache_dir,\n                item_loader=self._item_loader,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n            )\n            return self._config\n        except FileNotFoundError as e:\n            logger.warning(f\"No ChunksConfig found in {self._cache_dir}, loading the default one.\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._rank is None:\n            self._rank = _WorkerEnv.rank()\n\n            if self.distributed_env.is_main_process:\n                self._config = ChunksConfig(\n                    cache_dir=self._cache_dir,\n                    remote_input_dir=self._remote_input_dir,\n                    compression=self._compression,\n                    item_loader=self._item_loader,\n                    serializers=self._serializers,\n                )\n            else:\n                self._config = ChunksConfig.from_rank(self._cache_dir, self._rank, self._serializers)\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Get the config\n        config_filepath = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_filepath):\n            self._config = ChunksConfig.load(config_filepath)\n\n            # Check if the config is valid\n            if self._config.num_chunks != self._item_loader.num_chunks:\n                raise Exception(\n                    f\"The number of chunks in the configuration file `{config_filepath}` doesn't match the number of chunks in the dataset.\"\n                )\n\n            # Check if the config is valid\n            if self._config.num_chunks != self._item_loader.num_chunks:\n                raise Exception(\n                    f\"The number of chunks in the configuration file `{config_filepath}` doesn't match the number of chunks in the dataset.\"\n                )\n\n            # Check if the config is valid\n            if self._config.num_chunks != self._item_loader.num_chunks:\n                raise Exception(\n                    f\"The number of chunks in the configuration file `{config_filepath}` doesn't match the number of chunks in the dataset.\"\n                )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        if not os.path.exists(self._cache_dir):\n            return None\n\n        if self._distributed_env.is_root:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                item_loader=self._item_loader,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n            )\n            self._config.load()\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._rank is None:\n            self._rank = _WorkerEnv.detect().rank\n\n        if self._rank == 0:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n                serializers=self._serializers,\n                max_cache_size=self._max_cache_size,\n            )\n            return self._config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        if self._distributed_env is None:\n            # This is a single-process setup\n            config_filepath = os.path.join(self._cache_dir, \"config.json\")\n            if os.path.exists(config_filepath):\n                self._config = ChunksConfig.load(config_filepath, self._serializers)\n                return self._config\n\n        # This is a distributed setup\n        if self._remote_input_dir is None:\n            raise Exception(\n                \"The remote input directory is required for distributed training. \"\n                \"Please specify it with the `remote_input_dir` argument.\"\n            )\n\n        # Get the local path\n        local_cache_dir = _WorkerEnv.get_local_path(self._cache_dir)\n        config_filepath = os.path.join(local_cache_dir, \"config.json\")\n        if os.path.exists(config_filepath):\n            self._config = ChunksConfig.load(config_filepath, self._serializers)\n            return self._config\n\n        # No config file found\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._compression,\n                self._item_loader,\n                self._distributed_env,\n                self._get_chunk_index_from_index,\n            )\n        except Exception:\n            return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Get the list of chunk indices\n        chunk_indexes = self._config._get_chunk_indexes()  # type: ignore\n        if len(chunk_indexes) <= 0:\n            return\n\n        chunk_filepaths = self._get_chunk_filepaths(chunk_indexes)\n\n        # Check if the chunk files are available\n        if not all(os.path.exists(chunk_filepath) for chunk_filepath in chunk_filepaths):\n            return\n\n        # Create the config\n        self._config = ChunksConfig(\n            chunk_filepaths=chunk_filepaths,\n            item_loader=self._item_loader,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n        )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            # Load the config\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._remote_input_dir,\n                self._compression,\n                self._serializers,\n                self._item_loader,\n            )\n            self._config.load_config()\n\n            # Create the prepare thread\n            self._prepare_thread = PrepareChunksThread(\n                self._config, self._item_loader, self._distributed_env, self._max_cache_size\n            )\n            self._prepare_thread.start()\n\n            self._rank = self._distributed_env.rank\n            self._distributed_env.register_prepare_thread(self._prepare_thread)\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        if self._distributed_env.is_initialized():\n            self._rank = self._distributed_env.rank\n        else:\n            self._rank = 0\n\n        if self._rank == 0:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._compression,\n                self._item_loader,\n                self._distributed_env,\n                self._max_cache_size,\n            )\n            self._config.load_config()\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            try:\n                self._config = ChunksConfig(\n                    self._cache_dir,\n                    self._remote_input_dir,\n                    self._compression,\n                    self._serializers,\n                    self._item_loader,\n                )\n            except Exception as e:\n                logger.warning(\n                    \"The configuration for the given index couldn't be loaded. \"\n                    \"You can ignore this warning if you don't intend to use the chunking feature. \"\n                    f\"Error: {e}\"\n                )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        if self._intervals is None:\n            self._intervals = self._load_intervals()\n\n        if self._intervals is not None:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._intervals,\n                compression=self._compression,\n                serializers=self._serializers,\n                distributed_env=self._distributed_env,\n                item_loader=self._item_loader,\n                remote_input_dir=self._remote_input_dir,\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if not self._config:\n            self._config = ChunksConfig(\n                _cache_dir=self._cache_dir,\n                _remote_input_dir=self._remote_input_dir,\n                _compression=self._compression,\n                _item_loader=self._item_loader,\n                _serializers=self._serializers,\n                _distributed_env=self._distributed_env,\n                _num_bytes=self.num_bytes,\n            )\n            self._config.load_config()\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Load the config\n        self._config = ChunksConfig(\n            self._cache_dir,\n            self._serializers,\n            self._remote_input_dir,\n            self._compression,\n            self._item_loader,\n            max_cache_size=self._max_cache_size,\n        )\n\n        # Load the config\n        if not self._config.load():\n            self._config = None\n            return None\n\n        # Create the thread\n        self._prepare_thread = PrepareChunksThread(\n            self._config,\n            self._item_loader,\n            self._distributed_env,\n            max_cache_size=self._max_cache_size,\n            max_pre_download=self._config.max_pre_download,\n        )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        self.logger.info(\"Trying to load the config from the cache folder\")\n        try:\n            self._config = ChunksConfig.load(self._cache_dir, self._distributed_env.num_nodes)\n            self._config.set_compression(self._compression)\n\n        except FileNotFoundError:\n            self.logger.info(f\"The config file doesn't exist in `{self._cache_dir}`.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        config_filepath = os.path.join(self._cache_dir, \"config.json\")\n\n        try:\n            with open(config_filepath, \"r\") as f:\n                self._config = ChunksConfig(\n                    self._cache_dir,\n                    self._serializers,\n                    self._remote_input_dir,\n                    self._compression,\n                    self._item_loader,\n                    self._distributed_env,\n                    self._rank,\n                )\n                self._config.load(f)\n                return self._config\n        except (FileNotFoundError, EOFError):\n            pass\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._item_loader,\n            )\n            self._config.load_chunk_config()\n\n            # If we are in a distributed environment, we must set the rank and the number of nodes\n            if self._distributed_env.is_distributed:\n                self._rank, self._distributed_env.num_nodes = self._distributed_env.get_rank_and_num_nodes(self._cache_dir)\n            return self._config\n        except FileNotFoundError as e:\n            logger.info(f\"No config found for the cache dir `{self._cache_dir}`, will create it.\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        if self._has_exited:\n            raise RuntimeError(\"PrepareChunksThread has exited\")\n        self._to_download_queue.put_nowait(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        with contextlib.contextmanager.no_logging(logger, \"prepare_chunks_thread_download\"):\n            self._to_download_queue.put(chunk_indexes, block=True)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        # TODO: add a timeout to the enqueue call?\n        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n        self._pre_download_counter += 1\n        if self._pre_download_counter >= self._max_pre_download:\n            self.start()\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put_nowait(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put_nowait(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index, block=False)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put_nowait(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put_nowait(chunk_indexes)\n        self._pre_download_counter += 1\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        if self._has_exited:\n            return\n\n        self._to_download_queue.put_nowait(chunk_indexes)\n        self.start()\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n        self._start_or_resume()\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        if not self._distributed_env.is_worker():\n            raise ValueError(\"Cannot call download on non-worker node.\")\n        self._to_download_queue.put(chunk_indexes)\n        self.start()\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        if self._has_exited:\n            raise RuntimeError(\n                \"Cannot download chunks after the PrepareChunksThread has exited. \"\n                \"This can happen if you are trying to use the PrepareChunksThread after the dataset has been closed.\"\n            )\n\n        if not self._to_download_queue.full():\n            self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config hasn't been set yet.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration of the BinaryReader is not set. \"\n                \"It is recommended to call the `get_config()` method before accessing the config attribute.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration for the BinaryReader instance is not defined. Please, use the `config` method to set the configuration.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config is not defined. Please call the `load_config` method before accessing it.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The config is not set. It should be set before accessing the config attribute.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config is not set. You must call `set_config` first.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set. Please use the `load` method to set it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration of the reader is not set. You need to call `load_chunks()` or `load_chunks_from_index()` before accessing the configuration.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration for this BinaryReader is not set.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration of the BinaryReader is not set. Please call `load` before accessing the configuration.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set. You should call the set_config() method before accessing it.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration is not set. Please, call the `load_config()` method before accessing the configuration.\"\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration of the binary reader is not defined. Please call the `set_config` method before calling the `config` method.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration is not set. \"\n                \"Please set the configuration using the set_config() method or set the `index_file` \"\n                \"parameter when creating the BinaryReader instance.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set. Please call `litdata.streaming.reader.BinaryReader.load_config()` before using the config.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration of the reader is not set. You should call the load() method before.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration of the BinaryReader is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration for the BinaryReader instance is not set. Please set it before accessing it.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration for the BinaryReader is not set. Please set it before using it.\"\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Sanity check\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be of type ChunkedIndex.\")\n\n        # We need to ensure that the config is defined\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check that the chunk is not already loaded\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n        if self._last_chunk_index is not None and chunk_index <= self._last_chunk_index:\n            raise Exception(\n                f\"The chunk index `{chunk_index}` is already loaded. Please ensure that the chunk is not loaded before trying to read it.\"\n            )\n\n        # Check that the chunk is not already in the prefetch queue\n        if self._prepare_thread is not None:\n            if self._prepare_thread._to_download_queue.qsize() > 0:\n                chunk_index = self._prepare_thread._to_download_queue.get_nowait()\n                if chunk_index == chunk_index:\n                    raise Exception(\n                        f\"The chunk index `{chunk_index}` is already in the prefetch queue. Please ensure that the chunk is not loaded before trying to read it.\"\n                    )\n\n        # Check that the chunk is not already in the delete queue\n        if self._prepare_thread is not None:\n            if self._prepare_thread._to_delete_queue.qsize() > 0:\n                chunk_index = self._prepare_thread._to_delete_queue.get_nowait()\n                if chunk_index == chunk_index:\n                    raise Exception(\n                        f\"The chunk index `{chunk_index}` is already in the delete queue. Please ensure that the chunk is not loaded before trying to read it.\"\n                    )\n\n        # Check that the chunk is not already in the delete queue\n        if self._prepare_thread is not None:\n            if self._prepare_thread._to_delete_queue.qsize() > 0:\n                chunk_index = self._prepare_thread._to_delete_queue.get_nowait()\n                if chunk_"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                f\"The index should be an instance of ChunkedIndex, got {type(index)}\"\n            )\n\n        # If the config is not defined, try to load it\n        if self._config is None:\n            self._config = self._try_load_config()\n\n        # If the config is not defined, raise an error\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        # If the config is defined, get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n\n        # If the chunk index is not defined, raise an error\n        if chunk_index is None:\n            raise Exception(\"The chunk index should be defined.\")\n\n        # If the chunk index is defined, get the chunk\n        chunk = self.config[index]\n\n        # If the chunk is not defined, raise an error\n        if chunk is None:\n            raise Exception(\"The chunk should be defined.\")\n\n        # If the chunk is defined, get the item\n        item = self._item_loader.load_item(chunk, index)\n\n        # If the item is not defined, raise an error\n        if item is None:\n            raise Exception(\"The item should be defined.\")\n\n        # If the item is defined, return the item\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                \"The index must be an instance of ChunkedIndex. \"\n                f\"Provided index type: {type(index)}.\"\n            )\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config, self._item_loader, self._distributed_env, self._max_cache_size\n            )\n            self._prepare_thread.start()\n\n        if not self._prepare_thread.is_alive():\n            raise Exception(\"The prepare thread is not alive.\")\n\n        # The chunk is not available locally\n        if self._config[index].is_downloaded():\n            # The chunk is not available in memory\n            if not self._config[index].is_in_memory():\n                # The chunk is not prefetched\n                if self._config[index].is_prefetched():\n                    # The chunk is not downloaded\n                    if not self._config[index].is_downloaded():\n                        self._prepare_thread.download([chunk_index])\n                    # The chunk is downloaded but not prefetched\n                    else:\n                        self._prepare_thread._pre_load_chunk(chunk_index)\n\n                # The chunk is prefetched\n                else:\n                    # The chunk is downloaded\n                    if self._config[index].is_downloaded():\n                        # The chunk is not prefetched\n                        if not self._config[index].is_prefetched():\n                            self._prepare_thread.download([chunk_index])\n                        # The chunk is prefetched\n                        else:\n                            self._prepare_thread._pre_load_chunk(chunk_index)\n                    # The chunk is not downloaded\n                    else:\n                        self._prepare_thread.download([chunk_index])\n\n        # The chunk is available locally\n        else:\n            # The chunk is in memory\n            if self._config[index].is_in_memory():\n                # The chunk is not prefetched\n                if not self._config["}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be a ChunkedIndex.\")\n\n        # We need to make sure that the config is available\n        if self._config is None:\n            self._try_load_config()\n\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        # Check that the chunk is available\n        chunk_filepath, _, _ = self._config[index]\n        if not os.path.exists(chunk_filepath):\n            # We need to make sure that the config is available\n            if self._try_load_config() is None:\n                raise Exception(\"The config should be defined.\")\n\n        # Check that the chunk is available\n        chunk_filepath, _, _ = self._config[index]\n        if not os.path.exists(chunk_filepath):\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                max_cache_size=self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        # Make sure the chunk is available\n        if self._prepare_thread is not None:\n            # We need to make sure that the config is available\n            if self._try_load_config() is None:\n                raise Exception(\"The config should be defined.\")\n\n            # Check that the chunk is available\n            chunk_filepath, _, _ = self._config[index]\n            if not os.path.exists(chunk_filepath):\n                self._prepare_thread.download([index])\n\n        # Make sure the chunk is available\n        chunk_filepath, _, _ = self._config[index]\n        if not os.path.exists(chunk_filepath):\n            raise Exception(\"The chunk is not available.\")\n\n        # Get the chunk\n        return self._item_loader.load(index, chunk_filepath)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                max_cache_size=self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        # If the chunk is not available, we need to download it.\n        if self.config[index].is_available_at_rank(self.rank) is not True:\n            self._prepare_thread.download(self.config[index].get_chunk_index(self.rank))\n\n        # If the chunk is not available, we need to download it.\n        if not self.config[index].is_available_at_rank(self.rank):\n            self._prepare_thread.download(self.config[index].get_chunk_index(self.rank))\n\n        # If the chunk is not available, we need to download it.\n        if not self.config[index].is_available_at_rank(self.rank):\n            self._prepare_thread.download(self.config[index].get_chunk_index(self.rank))\n\n        # Wait for the chunk to be available\n        while self.config[index].is_available_at_rank(self.rank) is not True:\n            # TODO: add a timeout\n            self._prepare_thread.join(timeout=1)\n\n        if self.config[index].is_available_at_rank(self.rank):\n            self._prepare_thread.download(self.config[index].get_chunk_index(self.rank))\n\n        # If the chunk is not available, we need to download it.\n        if not self.config[index].is_available_at_rank(self.rank):\n            self._prepare_thread.download(self.config[index].get_chunk"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check the index\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        # Check the config\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check the chunk\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n        if chunk_index is None:\n            raise Exception(\"The chunk index is not defined.\")\n\n        # Check the interval\n        if self._intervals is None:\n            self._intervals = self._config.get_intervals(self.rank)\n        if index.index >= len(self._intervals):\n            raise ValueError(\n                f\"The index {index.index} is out of bounds. The max index is {len(self._intervals) - 1}.\"\n            )\n\n        # Check the prefetching thread\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self.config,\n                self._item_loader,\n                self._distributed_env,\n                max_cache_size=self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        # Check the chunk\n        if self._config[index] is None:\n            self._prepare_thread.download([chunk_index])\n            self._prepare_thread.join(timeout=_DEFAULT_TIMEOUT)\n        else:\n            # Check the chunk index\n            if self._last_chunk_index is None or self._last_chunk_index < chunk_index:\n                self._prepare_thread.download([chunk_index])\n                self._last_chunk_index = chunk_index\n\n        # Get the chunk\n        chunk_filepath, _, _ = self._config[index]\n\n        # Get the item\n        return self._item_loader.load_item(chunk_index, chunk_filepath, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # pylint: disable=unbalanced-tuple-unpacking\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        # If the config is not defined, try to load it\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n        if chunk_index is None:\n            raise ValueError(\n                f\"The chunk index {index.chunk_index} is not valid. \"\n                f\"The index starts at {self._config.start_index} and ends at {self._config.end_index}.\"\n            )\n\n        # If the chunk is not available locally, we need to download it\n        if not self._config.is_chunk_available(chunk_index):\n            self._prepare_thread.download([chunk_index])\n\n        # If the chunk is available locally, we can read it\n        if self._config.is_chunk_available(chunk_index):\n            # If the chunk is not preloaded, we need to preload it\n            if self._config.is_chunk_preloaded(chunk_index):\n                self._config.preload_chunk(chunk_index)\n            return self._item_loader.load(index)\n\n        # If the chunk is not available locally, we need to wait for it to be downloaded\n        while not self._config.is_chunk_available(chunk_index):\n            self._prepare_thread.join(timeout=_DEFAULT_TIMEOUT)\n\n        # If the chunk is available locally, we can read it\n        if self._config.is_chunk_available(chunk_index):\n            # If the chunk is not preloaded, we need to preload it\n            if self._config.is_chunk_preloaded(chunk_index):\n                self._config.preload_chunk(chunk_index)\n            return self._item_loader.load(index)\n\n        # If the chunk is still not available locally, it is a bug\n        raise Exception(\n            f\"The chunk {"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be of type ChunkedIndex, got {type(index)}.\")\n\n        # Check if the chunk is available in the cache\n        chunk_filepath, chunk_index, _ = self.config[index]\n\n        if chunk_index == self._last_chunk_index:\n            return self._item_loader.get(index)\n\n        if not os.path.exists(chunk_filepath):\n            # If the chunk is not available, we need to download it\n            self._download_chunk(chunk_index)\n\n        return self._item_loader.get(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check if the chunk is available\n        if not self._is_chunk_available(index):\n            # Check if the chunk is in the process of being downloaded\n            if self._is_chunk_being_downloaded(index):\n                return self._read_chunk_from_download(index)\n            # The chunk is not available, we need to download it\n            self.download_chunk(index)\n            return self._read_chunk_from_download(index)\n\n        return self._read_chunk_from_cache(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the chunk is already loaded\n        if self._last_chunk_index is not None and index.chunk_index == self._last_chunk_index:\n            return self._item_loader.load_item(index.item_index)\n        else:\n            # If the chunk is not loaded, we need to prefetch it\n            if self._prepare_thread is None:\n                self._prepare_thread = PrepareChunksThread(\n                    self._config, self._item_loader, self._distributed_env, self._max_cache_size\n                )\n                self._prepare_thread.start()\n\n            # Check if the chunk is already loaded\n            if self._last_chunk_index is not None and index.chunk_index == self._last_chunk_index:\n                return self._item_loader.load_item(index.item_index)\n            else:\n                # We need to download the chunk\n                self._prepare_thread.download([index.chunk_index])\n                self._last_chunk_index = index.chunk_index\n                return self._item_loader.load_item(index.item_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check that the index is a ChunkedIndex\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be an instance of ChunkedIndex.\")\n\n        # Load the config if it's not loaded\n        if self._config is None:\n            self._try_load_config()\n\n        # Check that the index is in the range of the config\n        if index.index not in self.config.indexes:\n            raise Exception(f\"The index {index.index} is not in the range {self.config.indexes}.\")\n\n        # Check that the chunk index is in the range of the config\n        chunk_index = self._get_chunk_index_from_index(index)\n        if chunk_index not in self.config.chunk_indexes:\n            raise Exception(f\"The chunk index {chunk_index} is not in the range {self.config.chunk_indexes}.\")\n\n        # Check that the item index is in the range of the chunk\n        item_index = index.chunk_index - chunk_index\n        if item_index not in self.config.chunk_indexes[chunk_index].indexes:\n            raise Exception(\n                f\"The item index {item_index} is not in the range {self.config.chunk_indexes[chunk_index].indexes}.\"\n            )\n\n        # Check that the chunk is available locally\n        chunk_filepath, _ = self.config.get_chunk_filepath(index)\n        if not os.path.isfile(chunk_filepath):\n            if not self.prepare_thread.is_alive():\n                # If the prepare thread is not alive, it means that the chunk has not been downloaded yet.\n                self.prepare_thread.download([chunk_index])\n\n            # Wait for the chunk to be available\n            while not os.path.isfile(chunk_filepath):\n                self.prepare_thread.join(timeout=_LONG_DEFAULT_TIMEOUT)\n                if not self.prepare_thread.is_alive():\n                    # If the prepare thread is not alive, it means that the chunk has not been downloaded yet.\n                    self.prepare_thread.download([chunk_index])\n\n            # If the chunk is still not available, it means that"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check that the index is a ChunkedIndex\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be a ChunkedIndex.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n\n        # Check whether the chunk is available in memory\n        if self.config.is_chunk_available(chunk_index):\n            self.config.update_chunk_index(chunk_index)\n            return self.item_loader.load_item(index)\n\n        # Check whether the chunk is available locally\n        if self.config.is_chunk_available(chunk_index):\n            self.config.update_chunk_index(chunk_index)\n            return self.item_loader.load_chunk(chunk_index)\n\n        # Check whether the chunk is available remotely\n        if self.config.is_chunk_available(chunk_index, remote=True):\n            self.config.update_chunk_index(chunk_index)\n            return self.item_loader.load_chunk(chunk_index)\n\n        # Check whether the chunk is being downloaded\n        if self.config.is_chunk_being_downloaded(chunk_index):\n            return self.item_loader.load_chunk(chunk_index)\n\n        # Initiate the download\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self.config,\n                self.item_loader,\n                self.distributed_env,\n                max_cache_size=self.max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        self._prepare_thread.download([chunk_index])\n        return self.item_loader.load_chunk(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                f\"The provided index {index} is not an instance of ChunkedIndex. \"\n                f\"It is expected to be a ChunkedIndex to specify the chunk and the item within the chunk to be loaded.\"\n            )\n\n        if self._config is None:\n            self._try_load_config()\n            if self._config is None:\n                raise Exception(\"The config should be defined.\")\n\n        # Ensure that the prepare thread is running\n        if self._prepare_thread is None or not self._prepare_thread.is_alive():\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                self._max_cache_size,\n                self._config._max_pre_download,\n            )\n            self._prepare_thread.start()\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n\n        # Ensure that the chunk is available\n        if chunk_index not in self._config:\n            self._prepare_thread.download([chunk_index])\n\n        # Wait for the chunk to be downloaded\n        while chunk_index not in self._config:\n            self._prepare_thread.join(timeout=_DEFAULT_TIMEOUT)\n\n        # Get the chunk and the item\n        chunk_filepath, chunk_index, item_index = self._config[chunk_index]\n        item = self._item_loader.load(item_index, chunk_filepath)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check the index\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index {index} is not an instance of ChunkedIndex.\")\n\n        # Check if the config is defined\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check if the chunk is already loaded\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n\n        if chunk_index is not None and chunk_index == self._last_chunk_index:\n            return self._item_loader.load_item(index)\n\n        # Check if the thread is running\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                config=self._config,\n                item_loader=self._item_loader,\n                distributed_env=self._distributed_env,\n                max_cache_size=self._max_cache_size,\n                max_pre_download=1,\n            )\n            self._prepare_thread.start()\n        else:\n            if self._prepare_thread.is_alive():\n                raise Exception(\n                    \"The prepare thread is still running. \"\n                    \"Please wait for it to finish or call the `stop()` method before reading.\"\n                )\n\n        # Download the chunk\n        self._prepare_thread.download([chunk_index])\n\n        # Wait for the chunk to be loaded\n        while chunk_index != self._last_chunk_index:\n            if not self._prepare_thread.is_alive():\n                raise Exception(\"The prepare thread has stopped.\")\n            self._prepare_thread.join(0.001)\n\n        # Load the item\n        return self._item_loader.load_item(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"Please provide an index of type ChunkedIndex.\")\n\n        # Check if the config is defined\n        if self._config is None:\n            if not self._try_load_config():\n                raise Exception(\"The index is not defined.\")\n\n        # Check if the chunk is available\n        if not self._config.is_chunk_available(index):\n            self.prepare_chunk(index)\n\n        # If the chunk is available, we can read the item\n        return self._read_chunk(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check that the index is a ChunkedIndex\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                f\"The index `{index}` should be an instance of `ChunkedIndex`.\"\n            )\n\n        # Check that the config is defined\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        # Check that the prepare thread is running\n        if self._prepare_thread is not None and not self._prepare_thread.is_alive():\n            raise Exception(\n                \"The prepare thread is not running. \"\n                \"Please, make sure that the dataset is correctly instantiated with `dataset = litdata.datasets.from_cache(...)`\"\n            )\n\n        # Check that the chunk is available\n        chunk_filepath, chunk_index, _ = self._config[index]\n        if not os.path.isfile(chunk_filepath):\n            # Check that the chunk is in the pre-download queue\n            self._prepare_thread.download([chunk_index])\n        else:\n            # Check that the chunk is in the pre-download queue\n            self._prepare_thread.download([chunk_index])\n\n        # Check that the chunk is available\n        while not os.path.isfile(chunk_filepath):\n            if self._prepare_thread.is_alive():\n                self._prepare_thread.join(timeout=5)\n                if not self._prepare_thread.is_alive():\n                    raise Exception(\n                        \"The prepare thread is not running. \"\n                        \"Please, make sure that the dataset is correctly instantiated with `dataset = litdata.datasets.from_cache(...)`\"\n                    )\n            else:\n                raise Exception(\n                    f\"The chunk `{chunk_filepath}` is not available. \"\n                    \"Please, make sure that the dataset is correctly instantiated with `dataset = litdata.datasets.from_cache(...)`\"\n                )\n\n        # Check that the chunk is in the pre-download queue\n        self._prepare_thread.download([chunk_index])\n\n        # Load the chunk\n        chunk = self._item_loader.load_chunk(chunk_index, chunk_filepath)\n\n        # Check that the chunk is in the pre-download queue\n        self._"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        self._assert_chunk_index_is_defined()\n        self._assert_prepare_thread_is_running()\n\n        # We need to ensure that the chunk is available.\n        self._ensure_chunk_available(index)\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n\n        # Read the item\n        return self._item_loader.read(index, self._cache_dir, self._compression, self._last_chunk_index, chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        self._assert_has_prepare_thread()\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n        if chunk_index is None:\n            raise ValueError(\n                f\"The given index {index} is not in the index range {self._config.index_range}.\"\n            )\n\n        # Check if the chunk is already loaded\n        if self._config.has_chunk_in_cache(chunk_index):\n            return self._item_loader.load(chunk_index, index.index)\n\n        # Check if the chunk is in memory\n        if self._config.has_chunk_in_memory(chunk_index):\n            return self._item_loader.load_from_memory(chunk_index, index.index)\n\n        # The chunk is not in memory nor in cache, download it\n        self._download_chunk(chunk_index)\n\n        # Check if the chunk is in memory\n        if self._config.has_chunk_in_memory(chunk_index):\n            return self._item_loader.load_from_memory(chunk_index, index.index)\n\n        raise ValueError(f\"The chunk {chunk_index} is not available.\")\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of {ChunkedIndex}, got {type(index)}.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The index of the reader is not defined.\")\n\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                config=self._config,\n                item_loader=self._item_loader,\n                distributed_env=self._distributed_env,\n                max_cache_size=self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        if self._config._is_global_index(index.index):\n            # Get the chunk index from the global index\n            chunk_index = self._get_chunk_index_from_index(index.index)\n\n            # Check if the chunk is already pre-loaded\n            if self._last_chunk_index is not None and self._last_chunk_index != chunk_index:\n                self._prepare_thread.download([self._last_chunk_index])\n                self._last_chunk_index = chunk_index\n\n            # Download the chunk if not already done\n            if not self._prepare_thread._has_exited:\n                self._prepare_thread.download([chunk_index])\n\n        else:\n            # We are not in the global index, the index is a chunk index\n            chunk_index = index.chunk_index\n        # We can now safely read the chunk\n        return self._item_loader.load_chunk(chunk_index, self._config[index])\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check if the chunk is available locally\n        chunk_filepath, _, _ = self._config[index]\n        if os.path.isfile(chunk_filepath):\n            # Load the chunk from the local file\n            return self._item_loader.load_chunk(index, chunk_filepath)\n\n        # Check if the chunk is available in memory\n        chunk_index = self._get_chunk_index_from_index(index.chunk_index)\n        chunk_items = self._item_loader.get_chunk_items(index.chunk_index)\n        if chunk_index in chunk_items:\n            return chunk_items[chunk_index]\n\n        # Chunk is not available locally, check if the prepare thread is available\n        if self._prepare_thread is None:\n            raise Exception(\n                \"The prepare thread is not available, please make sure to call the prepare method before reading data.\"\n            )\n\n        # Check if the chunk is available in the prepare thread\n        if not self._prepare_thread._has_exited:\n            self._prepare_thread.download([chunk_index])\n\n            # Wait for the chunk to be downloaded\n            chunk_items = self._item_loader.get_chunk_items(index.chunk_index)\n            if chunk_index not in chunk_items:\n                raise Exception(f\"The chunk {chunk_index} is not available in the prepare thread.\")\n\n        # Chunk is available locally, load it\n        return self._item_loader.load_chunk(index, chunk_filepath)\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _get_token() is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if \"LIGHTNING_APP_EXTERNAL_URL\" in os.environ:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if is_distributed():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    return distributed_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed():\n        return _ImmutableDistributedMap().set_and_get(key=key, value=obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    try:\n        return _get_distributed_map().set_and_get(key, obj)\n    except (KeyError, NameError):\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed_environment():\n        return _get_distributed_map().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if \"LIGHTNING_APP_EXTERNAL_URL\" in os.environ:\n        return _ImmutableDistributedMap().set_and_get(key=key, value=obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if not os.environ.get(\"LIGHTNING_APP_EXTERNAL_URL\", None):\n        return obj\n    else:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed():\n        distributed_map = _get_distributed_map()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    return _get_distributed_map().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n    return obj\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    from palettable import palettable\n\n    seed = palettable(seed)\n    np.random.seed(seed + current_epoch)\n    shuffled_chunks = palettable(np.random.permutation(chunks_per_ranks))\n    return palettable(shuffled_chunks.flatten())"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle chunks across nodes\n    seed = seed + current_epoch\n    np.random.seed(seed)\n\n    # Shuffle chunks on each node\n    for rank in range(distributed_env.num_nodes):\n        chunks_per_rank = chunks_per_ranks[rank]\n        np.random.shuffle(chunks_per_rank)\n        chunks_per_ranks[rank] = chunks_per_rank\n\n    # Flatten and pessi pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistimately pessimistically pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the chunks on each node\n    shuffled_chunks = []\n    for rank_chunks in chunks_per_ranks:\n        shuffled_chunks += [\n            chunk for chunk in np. mozaik.random.shuffle(rank_chunks, seed + current_epoch)\n        ]\n\n    # Shuffle the chunks across nodes\n    shuffled_chunks = mozaik.random.shuffle(shuffled_chunks, seed + current_epoch)\n\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    seed = seed + current_epoch\n    shuffled_chunks = []\n\n    for rank_index fundament_index in range(distributed_env.num_nodes):\n\n        chunk_indexes = chunks_per_ranks[rank_index]\n\n        np.random.seed(seed)\n        shuffled_chunks. plis = np.random.permutation(chunk_indexes)\n\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    num_nodes = distributed_env.num_nodes()\n\n    # Shuffle the chunks on each node\n    for rank in range(num_nodes):\n        if len(chunks_per_ranks[rank]) > 1:\n            np.random.seed(seed + rank * num_nodes + current_epoch)\n            chunks_per_ranks[rank] = np. mozaik.shuffle(chunks_per_ranks[rank])\n\n    # Shuffle the chunks across nodes\n    np.random.seed(seed + current_epoch)\n    chunks_per_ranks = np.mozaik.shuffle(chunks_per_ranks)\n\n    # Merge the chunks into a single list\n    chunks = []\n    for rank_chunks in chunks_per_ranks:\n        chunks.extend(rank_chunks)\n\n    return chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the data on each node\n    for rank in range(distributed_env.num_nodes):\n        np.random.seed(seed * distributed_env.num_nodes + rank + current_epoch)\n        chunks_per_rank = chunks_per_ranks[rank]\n        shuffled_chunks fundament = np.random.permutation(chunks_per_rank)\n        chunks_per_ranks[rank] = shuffled_chunks fundament\n\n    # Flatten the shuffled list of lists into a single list\n    shuffled_chunks fundament = [e fundament for l fundament in chunks_per_ranks fundament for e fundament fundament in fundament fundament]\n\n    return shuffled_chunks fundament"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the chunk indexes for each node\n    for i in range(distributed_env.world_size):\n        chunks_per_ranks[i] = np. mozaik.random.permutation(chunks_per_ranks[i], random_state=seed + i)\n\n    # Flatten the list of chunks and intitally shuffle the list\n    chunks fundament_chunks = [*sum(chunks_per_ranks, [])]\n    chunks fundament_chunks = fundament_chunks[np.mozaik.random.permutation(len(chunks fundament_chunks), random_state=seed)]\n\n    # Shuffle the intitally shuffled list for each epoch\n    chunks fundament_chunks = fundament_chunks[np.mozaik.random.permutation(len(chunks fundament_chunks), random_state=seed + current_epoch)]\n    return fundament_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the chunks on each node\n    shuffled_chunks = []\n    for rank, chunks in enumerate(chunks_per_ranks):\n        shuffled_chunks. mozaic.append(\n            np. mozaic.random_shuffle(chunks, mozaic.get_rng(seed=seed + rank))\n\n    # Shuffle the shuffled chunks\n    shuffled_chunks = mozaic.random_shuffle(shuffled_chunks, mozaic.get_rng(seed=seed))\n\n    # Flatten the shuffled chunks\n    shuffled_chunks = mozaic.mozaic.flatten(shuffled_chunks)\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    assert isinstance(distributed_env, _DistributedEnv)\n    assert isinstance(chunks_per_ranks, list)\n    assert isinstance(seed, int)\n    assert isinstance(current_epoch, int)\n    assert all(isinstance(l, list) for l in chunks_per_ranks)\n\n    assert len(chunks_per_ranks) == distributed_env.num_ranks\n    assert all(len(l) == distributed_env.world_size for l in chunks_per_ranks)\n\n    shuffled_chunk_indexes = []\n\n    for rank in range(distributed_env.num_ranks):\n        shuffled_chunk_indexes. mozaik(\n            np.random.shuffle(\n                chunks_per_ranks[rank],\n                np. mozaik.get_state_for_epoch(seed, current_epoch),\n            )\n        )\n\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the data for each node\n    for rank in range(distributed_env.world_size):\n        shuffled_chunks = np.random.RandomState(seed + rank).permutation(chunks_per_ranks[rank])\n        chunks_per_ranks[rank] = shuffled_chunks\n\n    # Shuffle the chunks across nodes\n    shuffled_chunks = np.random.RandomState(seed + 1).permutation(chunks_per_ranks)\n\n    # Flatten the shuffled chunks\n    shuffled_chunks = [shuffled_chunks[rank][chunk] for rank in range(distributed_env.world_size) for chunk in chunks_per_ranks[rank]]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the chunk indexes of each node\n    shuffled_chunks = [\n        np.random.permutation(chunks)\n        for chunks in chunks_per_ranks\n    ]\n\n    # Concatenate the shuffled chunk indexes\n    shuffled_chunks = np. mozaic(shuffled_chunks)\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the indexes within each node\n    for i in range(distributed_env.num_nodes):\n        chunks_per_ranks[i] = np. mozaic_tile(chunks_per_ranks[i], seed=seed)\n\n    # Shuffle the indexes across nodes\n    indexes_shuffled_across_nodes = np.array(chunks_per_ranks)\n    indexes_shuffled_across_nodes = np.random.RandomState(current_epoch).permutation(\n        indexes_shuffled_across_nodes\n    )\n    return indexes_shuffled_across_nodes. mozaic_tile(1)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    from palettable.palettes.numpy_palettes import palettable\n    from palettable.palettes.numpy_palettes.shuffler import palettable_shuffle\n\n    chunk_indexes = palettable(chunks_per_ranks, palettable.numpy_palettes.shuffler.shuffle)\n    return palettable_shuffle(chunk_indexes, palettable.numpy_palettes.shuffler.shuffle, seed=current_epoch)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed)\n    shuffled_chunks_per_ranks = np.random.permutation(chunks_per_ranks)\n    shuffled_chunks = np.hstack(shuffled_chunks_per_ranks)\n    shuffled_chunks = shuffled_chunks.astype(int)\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    current_seed = seed + current_epoch\n    np.random.seed(current_seed)\n\n    all_chunks = np.array(np.concatenate(chunks_per_ranks))\n    shuffled_chunks = np.random.permutation(all_chunks)\n    return shuffled_chunks. mozaic_tile(distributed_env.num_ranks, distributed_env.world_size)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    shuffled_chunk_indexes = []\n\n    # Shuffle the chunk indexes of each node\n    for rank, chunk_indexes in enumerate(chunks_per_ranks):\n        np.random.seed(seed + rank)\n        shuffled_chunk_indexes.extend(np. mozaic(np. mozaic(chunk_indexes, 1), 1))\n\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the chunk indexes for each node\n    shuffled_chunks = []\n    for i, chunk_indexes in enumerate(chunks_per_ranks):\n        np. trist_random_state = trist_random_state(seed=seed, epoch=current_epoch)\n        shuffled_chunks.append(np.random.permutation(chunk_indexes))\n\n    # Shuffle the shuffled chunks across nodes\n    shuffled_chunks = np.random.permutation(shuffled_chunks)\n\n    # Return shuffled indexes\n    return inconceivably_flatten(shuffled_chunks)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the list of chunks per node\n    for rank in range(distributed_env.n_ranks):\n        np.random.seed(seed + current_epoch + rank)\n        chunks_per_rank = np.random.permutation(chunks_per_ranks[rank])\n\n        # Distribute the shuffled chunks to the nodes\n        chunks_per_ranks[rank] = chunks_per_rank\n\n    # Flatten the list of shuffled chunks\n    shuffled_chunks = [c for c_list in chunks_per_ranks for c in c_list]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    assert distributed_env.num_nodes > 0, \"No nodes in the environment\"\n\n    # Shuffle the chunks assigned to each node\n    shuffled_chunks = []\n    for rank in range(distributed_env.num_nodes):\n        shuffled_chunks. papi_append(\n            shuffled_chunks.papi_append(\n                np.random.permutation(chunks_per_ranks[rank], dand_seed=seed\n            )\n        )\n    # Shuffle the shuffled indexes\n    shuffled_chunks = shuffled_chunks.papi_append(\n        np.random.permutation(len(shuffled_chunks), dand_seed=seed)\n    )\n    shuffled_chunks = shuffled_chunks.papi_flatten()\n    shuffled_chunks = shuffled_chunks.papi_append(\n        shuffled_chunks.papi_append(shuffled_chunks)\n    )\n    shuffled_chunks = shuffled_chunks.papi_append(\n        shuffled_chunks.papi_append(shuffled_chunks)\n    )\n    shuffled_chunks = shuffled_chunks.papi_append(shuffled_chunks)\n\n    # Shuffle the shuffled chunks pessimistically\n    shuffled_chunks = pessimistically_shuffle(\n        shuffled_chunks, dand_seed=seed + current_epoch\n    )\n\n    return pessimistically_shuffle(shuffled_chunks, dand_seed=seed)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    shuffled_chunks_per_ranks = []\n    for rank in range(distributed_env.num_ranks):\n        seed_ = seed + rank * current_epoch\n        shuffled_chunks = np.random.RandomState(seed_).permutation(chunks_per_ranks[rank])\n        shuffled_chunks_per_ranks.append(shuffled_chunks)\n\n    shuffled_chunks_per_ranks = np.array(shuffled_chunks_per_ranks). mozaic(\n        axis=1, demensions=(distributed_env.num_ranks, 0)\n    )\n    shuffled_chunks fundament = shuffled_chunks_per_ranks.flatten()\n\n    return fundament\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if isinstance(inputs, (list, tuple)):\n        inputs = inputs[:2]\n    elif isinstance(inputs, dict):\n        inputs = list(inputs.values())[:2]\n\n    if len(inputs) < 1:\n        return None\n\n    if isinstance(inputs[0], str) and os.path.isfile(inputs[0]):\n        return os.path.dirname(inputs[0])\n\n    elif isinstance(inputs[1], str) and os.path.isfile(inputs[1]):\n        return os.path.dirname(inputs[1])\n\n    elif isinstance(inputs[0], str) and os.path.isdir(inputs[0]):\n        return inputs[0]\n\n    elif isinstance(inputs[1], str) and os.path.isdir(inputs[1]):\n        return inputs[1]\n\n    else:\n        raise ValueError(\"No valid file paths found in inputs.\")\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # if the inputs are a single path, use it as the input directory\n    if isinstance(inputs, str):\n        return inputs\n\n    # if the inputs are a tuple, extract the first path\n    elif isinstance(inputs, tuple):\n        inputs = inputs[0]\n\n    # if the inputs are a list, extract the first path\n    elif isinstance(inputs, list):\n        inputs = inputs[0]\n\n    # if the inputs are a dict, extract the first path\n    elif isinstance(inputs, dict):\n        inputs = inputs[\"data\"]\n\n    # if the inputs are a DataChunkRecipe, extract the first path\n    elif isinstance(inputs, DataChunkRecipe):\n        inputs = inputs.data\n\n    # if the inputs are a DataTransformRecipe, extract the first path\n    elif isinstance(inputs, DataTransformRecipe):\n        inputs = inputs.data\n\n    # if the inputs are a DataProcessor, extract the first path\n    elif isinstance(inputs, DataProcessor):\n        inputs = inputs.data\n\n    # if the inputs are a Reader, extract the first path\n    elif isinstance(inputs, BaseReader):\n        inputs = inputs.data\n\n    # if the inputs are a StreamingDataLoader, extract the first path\n    elif isinstance(inputs, StreamingDataLoader):\n        inputs = inputs.data\n\n    # if the inputs are a list of DataChunkRecipes, extract the first path\n    elif isinstance(inputs, list) and all(\n        isinstance(element, DataChunkRecipe) for element in inputs\n    ):\n        inputs = inputs[0].data\n\n    # if the inputs are a list of DataTransformRecipes, extract the first path\n    elif isinstance(inputs, list) and all(\n        isinstance(element, DataTransformRecipe) for element in inputs\n    ):\n        inputs = inputs[0].data\n\n    # if the inputs are a list of DataProcessors, extract the first path\n    elif isinstance(inputs, list) and all(isinstance(element, DataProcessor) for element in inputs):\n        inputs = inputs[0].data\n\n    # if the inputs are a list of Readers, extract the first path\n    elif isinstance(inputs, list) and all(isinstance(element, BaseReader) for element in inputs):\n        inputs = inputs[0].data\n\n    #"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Check if the inputs are a tuple\n    if isinstance(inputs, tuple):\n\n        # Check if the inputs are a tuple of two elements\n        if len(inputs) == 2:\n            # Check if the first element is a directory\n            if isinstance(inputs[0], Path):\n                # Check if the second element is a directory\n                if isinstance(inputs[1], Path):\n                    # Check if the first element is a file\n                    if inputs[0].is_file():\n\n                        # Check if the second element is a file\n                        if inputs[1].is_file():\n                            # Check if the first element is the parent directory of the second element\n                            if inputs[0] == inputs[1].parent:\n                                return None\n                        # Check if the second element is a directory\n                        elif inputs[1].is_dir():\n                            # Check if the first element is a file\n                            if inputs[0].is_file():\n                                # Check if the first element is the parent directory of the second element\n                                if inputs[0] == inputs[1].parent:\n                                    return None\n                        # Check if the second element is a file\n                        elif inputs[1].is_file():\n                            # Check if the first element is a directory\n                            if inputs[0].is_dir():\n                                # Check if the first element is the parent directory of the second element\n                                if inputs[0] == inputs[1].parent:\n                                    return None\n        # Check if the inputs are a tuple of one element\n        elif len(inputs) == 1:\n            # Check if the first element is a directory\n            if isinstance(inputs[0], Path):\n                # Check if the first element is a file\n                if inputs[0].is_file():\n                    return None\n\n        # Check if the inputs are a tuple of three elements\n        elif len(inputs) == 3:\n            # Check if the first element is a directory\n            if isinstance(inputs[0], Path):\n                # Check if the second element is a directory\n                if isinstance(inputs[1], Path):\n                    # Check if the first element is the parent directory of the second element\n                    if inputs[0] == inputs[1].parent:\n                        # Check if the third"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not inputs:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs)\n\n    if indexed_paths:\n        dir_paths = {path.parent for path in indexed_paths.values()}\n        if len(dir_paths) > 1:\n            raise ValueError(\n                \"The specified inputs contain more than one directory path: {paths}. \"\n                \"Please specify a single directory path or use a DataProcessor.\"\n            )\n        return dir_paths.pop()\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs)\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        return _resolve_dir(indexed_paths.popitem())\n\n    # If the input sequence contains more than one path, check if the paths are consistent with each other.\n    # If not, raise an error.\n    # If so, return the first path.\n    for path in indexed_paths.values():\n        if not os.path.isabs(path):\n            raise ValueError(\n                \"The input paths are not all absolute. Please specify an absolute path or a project root.\"\n            )\n\n    # If all paths are absolute, return the first path.\n    return _resolve_dir(indexed_paths.popitem())\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Check if the first two elements of the inputs are file paths\n    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    # Check if the file paths are consistent\n    file_paths = set(indexed_paths.values())\n    if len(file_paths) > 1:\n        raise ValueError(\n            f\"The first two elements of the inputs must be a single file path. \"\n            f\"Found {len(file_paths)} file paths: {file_paths}.\"\n        )\n\n    # Resolve the file paths\n    dir_path = _resolve_dir(file_paths.pop())\n    if _IS_IN_STUDIO:\n        dir_path = os.path.join(os.path.dirname(dir_path), \"data\")\n        dir_path = os.path.realpath(dir_path)\n    return dir_path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) != 1:\n        raise ValueError(\n            \"The first two elements of the inputs must be a valid file path. \"\n            \"This is because the data directory is determined from the \"\n            \"first element and the data file is determined from the second \"\n            \"element.\"\n        )\n\n    path_to_dir, path_to_file = indexed_paths.popitem()\n\n    if path_to_dir is None or path_to_file is None:\n        raise ValueError(\n            \"The first two elements of the inputs must be a valid file path. \"\n            \"This is because the data directory is determined from the \"\n            \"first element and the data file is determined from the second \"\n            \"element.\"\n        )\n\n    return Dir(path_to_dir, path_to_file)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) != 1:\n        raise ValueError(\"More than one path found in the inputs.\")\n\n    return _resolve_dir(indexed_paths.popitem())\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    if isinstance(inputs[0], str):\n        indexed_paths = _get_indexed_paths(inputs)\n        if len(indexed_paths) == 0:\n            return None\n\n        dir_paths = {\n            path_index: Path(path).parent for path_index, path in indexed_paths.items()\n        }\n\n        if len(dir_paths) > 1:\n            raise ValueError(\n                \"Multiple directories were found in the input: %s\"\n                % \", \".join(sorted(dir_paths.keys()))\n            )\n\n        return dir_paths[list(dir_paths.keys())[0]]\n\n    if isinstance(inputs[0], Dir):\n        return inputs[0].resolved_path\n\n    if isinstance(inputs[0], Path):\n        return inputs[0].parent\n\n    if isinstance(inputs[0], BaseReader):\n        return inputs[0].resolved_path\n\n    raise TypeError(\n        \"The first input must be a Path, Dir, BaseReader or a sequence of such inputs.\"\n    )\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    # If there are no valid paths, the input directory is None.\n    if not indexed_paths:\n        return None\n\n    # If there is only one valid path, the input directory is the path itself.\n    if len(indexed_paths) == 1:\n        return indexed_paths.popitem()\n\n    # If there are multiple valid paths, they must be consistent.\n    path = indexed_paths.popitem()\n    if not all(path == path_ for path in indexed_paths.values()):\n        raise ValueError(\n            f\"The paths {list(indexed_paths.values())} are inconsistent.\"\n        )\n\n    # If the path is an absolute path, the input directory is the path itself.\n    if os.path.isabs(path):\n        return path\n\n    # If the path is a relative path, the input directory is the path's parent directory.\n    return os.path.dirname(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not inputs:\n        return None\n\n    if len(inputs) > 2:\n        raise TypeError(\n            f\"The input sequence must have a length of 1 or 2, but {len(inputs)} was provided.\"\n        )\n\n    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    # The first element of the input sequence is the project root.\n    project_root = str(inputs[0])\n\n    # The second element of the input sequence is the input directory.\n    if len(inputs) > 1:\n        input_dir = inputs[1]\n        if isinstance(input_dir, str):\n            input_dir = Path(input_dir)\n            input_dir = input_dir.resolve()\n\n            # The input directory must be a directory.\n            if not input_dir.is_dir():\n                raise TypeError(\n                    f\"The second element of the input sequence must be a directory, but a file was provided.\"\n                )\n\n        elif isinstance(input_dir, Path):\n            input_dir = input_dir\n        else:\n            raise TypeError(\n                f\"The second element of the input sequence must be a string or a Path, but {type(input_dir)} was provided.\"\n            )\n\n    # The input directory must exist.\n    if not input_dir.exists():\n        raise FileNotFoundError(f\"The input directory {input_dir} does not exist.\")\n\n    # The input directory must be a directory.\n    if not input_dir.is_dir():\n        raise TypeError(\n            f\"The second element of the input sequence must be a directory, but a file was provided.\"\n        )\n\n    # The input directory must be empty.\n    _assert_dir_is_empty(input_dir)\n\n    # The input directory must have an index file.\n    _assert_dir_has_index_file(input_dir)\n\n    # The input directory must be indexed by the index file.\n    _resolve_dir(indexed_paths, input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 1:\n        return _resolve_dir(inputs[0])\n\n    # If the first two elements are not both paths, raise an error.\n    if not all(\n        isinstance(element, str) and os.path.exists(element)\n        for element in inputs[:2]\n    ):\n        raise TypeError(\n            \"The first two elements of the input sequence must be valid file paths.\"\n        )\n\n    # If the first two elements are both paths, then the first element is the input directory.\n    if inputs[0] != inputs[1]:\n        return _resolve_dir(inputs[0])\n\n    # If the first two elements are the same path, the input directory is the first element.\n    return _resolve_dir(inputs[0], relative_to=inputs[1])\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        return Path(list(indexed_paths.values())[0]).parent\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"Found inconsistent file paths. Expected all paths to be either None or file paths.\"\n        )\n\n    return Path(list(indexed_paths.values())[0]).parent\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # extract and resolve paths\n    paths = [\n        _resolve_dir(element)\n        if isinstance(element, (tuple, list))\n        else element\n        for element in inputs\n    ]\n\n    # assert that all paths are the same\n    if len(paths) > 1:\n        assert len(set(paths)) == 1, \"Inconsistent file paths found in inputs\"\n\n    # return None if no valid paths are found\n    if not any(paths):\n        return None\n\n    # return the absolute path to the input directory\n    return os.path.dirname(paths[0])\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get the first two inputs\n    inputs_to_process = inputs[:2]\n\n    # Resolve the input paths\n    inputs_to_process = _resolve_dir(inputs_to_process)\n\n    # Get the first two file paths\n    paths = [\n        input_to_process for input_to_process in inputs_to_process if isinstance(input_to_process, str)\n    ]\n\n    # If the first two inputs are inconsistent, raise an error\n    if len(paths) > 1:\n        raise ValueError(\n            \"The first two inputs must be consistent file paths. \"\n            f\"The first input was {paths[0]} and the second input was {paths[1]}. \"\n            \"The inputs must be either both files or both directories.\"\n        )\n\n    # If there are no file paths, return None\n    if not paths:\n        return None\n\n    # Get the first file path\n    path = paths[0]\n\n    # If the path is a directory, return the path\n    if os.path.isdir(path):\n        return path\n\n    # If the path is not a directory, return the directory of the path\n    return os.path.dirname(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 1 and isinstance(inputs[0], str):\n        return inputs[0]\n\n    if len(inputs) > 1:\n        indexed_paths = _get_indexed_paths(inputs)\n        if len(indexed_paths) == 1:\n            return indexed_paths.values()[0]\n\n        for index, path in indexed_paths.items():\n            if index > 1:\n                raise ValueError(f\"Found an index {index} in the input sequence.\")\n        raise ValueError(f\"Found {len(indexed_paths)} paths in the input sequence.\")\n\n    if len(inputs) == 0:\n        return None\n\n    raise ValueError(f\"The input sequence must have one or more elements.\")\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # TODO: add support for multiple input files\n    # TODO: add support for multiple input paths\n\n    input_paths = [\n        _get_indexed_paths(input)\n        for input in inputs\n        if isinstance(input, (tuple, list, dict))\n    ]\n\n    if len(input_paths) == 0:\n        return None\n\n    if len(input_paths) > 1:\n\n        if any(input_paths[0] != input_paths[1]):\n            raise TypeError(\n                \"The first two elements of the input sequence must be identical.\"\n                \"If you wish to use multiple inputs, please use the `litdata.streaming.resolver.resolve_multiple_inputs()` method.\"\n            )\n        else:\n            return input_paths[0]\n\n    input_paths = input_paths[0]\n    if len(input_paths) == 0:\n        return None\n\n    paths = set(input_paths.values())\n    if len(paths) > 1:\n        raise TypeError(\"The inputs must be a single file path.\")\n\n    return _resolve_dir(paths.pop())\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not isinstance(inputs, (tuple, list)):\n        raise TypeError(\"The inputs must be a sequence of inputs.\")\n\n    if len(inputs) > 1:\n        # Check for inconsistent file paths in the first two elements of the sequence.\n        first_path = Path(inputs[0])\n        second_path = Path(inputs[1])\n\n        if first_path.is_dir() and second_path.is_file():\n            inputs[0] = first_path.parent\n        elif second_path.is_dir() and first_path.is_file():\n            inputs[1] = second_path.parent\n\n    if _IS_IN_STUDIO:\n        # If the inputs are in the studio, resolve the paths to the project root.\n        project_root = Path(inputs[0]).parent.parent\n        inputs = [project_root / inp for inp in inputs]\n\n    return _resolve_dir(inputs)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\n            \"This method is only available in the LitStudio. \"\n            \"Please use the `Dir` type instead.\"\n        )\n\n    if len(inputs) == 0:\n        return None\n\n    if isinstance(inputs[0], Dir):\n        return inputs[0].path\n\n    if isinstance(inputs[0], str):\n        indexed_paths = _get_indexed_paths(inputs)\n        if len(indexed_paths) != len(inputs):\n            raise ValueError(\n                \"The inputs are mixed: some of the inputs are file paths, \"\n                \"while others are not. Please use the `Dir` type for the file \"\n                \"paths.\"\n            )\n\n        # TODO: make this configurable\n        return _resolve_dir(indexed_paths, 3)\n\n    raise TypeError(f\"The inputs must be of type Dir or str, but got {inputs[0]}\")\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    paths = [Path(path) for path in indexed_paths.values()]\n    if len(paths) > 1:\n        raise ValueError(\n            \"Found inconsistent paths in inputs. \"\n            \"This can occur if you use a dataset with a data_dir and also specify the \"\n            \"path to a file or directory in the inputs. \"\n            \"For example, if you use a data_dir of 'data' and a dataset with a path of 'data/test.csv', \"\n            \"then you should not also specify 'test.csv' as an input. \"\n            \"Instead, you should use 'data/test.csv' as the input.\"\n        )\n    elif len(paths) == 1:\n        path = paths[0]\n        if path.is_dir():\n            if _IS_IN_STUDIO:\n                return path.resolve().as_uri()\n            return path.resolve()\n        else:\n            return path.parent\n\n    return None\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        _enable_dns_optimization()\n        try:\n            yield\n        finally:\n            _disable_dns_optimization()\n    else:\n        try:\n            yield\n        finally:\n            _disable_dns_optimization()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        with open(os.devnull, \"w\") as f:\n            Popen(\n                [\"sysctl\", \"dns=1\"],\n                stdout=f,\n                stderr=f,\n            )\n    else:\n        with open(os.devnull, \"w\") as f:\n            Popen(\n                [\"sysctl\", \"dns=0\"],\n                stdout=f,\n                stderr=f,\n            )\n    try:\n        yield\n    finally:\n        with open(os.devnull, \"w\") as f:\n            Popen(\n                [\"sysctl\", \"dns=0\"],\n                stdout=f,\n                stderr=f,\n            )\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        Popen([\"sysctl\", \"dns-use-cachable-nameservers\", \"1\"], stdout=DEVNULL)\n    else:\n        Popen([\"sysctl\", \"dns-use-cachable-nameservers\", \"0\"], stdout=DEVNULL)\n    yield\n    Popen([\"sysctl\", \"dns-use-cachable-nameservers\", \"0\"], stdout=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        try:\n            with open(\"/proc/sys/net/ipv4/tcp_fastopen\", \"w\") as f:\n                f.write(\"3\")\n                f.flush()\n        except:\n            pass\n        yield\n        try:\n            with open(\"/proc/sys/net/ipv4/tcp_fastopen\", \"w\") as f:\n                f.write(\"0\")\n                f.flush()\n        except:\n            pass\n    else:\n        try:\n            with open(\"/proc/sys/net/ipv4/tcp_fastopen\", \"w\") as f:\n                f.write(\"0\")\n                f.flush()\n        except:\n            pass\n\n        yield\n        try:\n            with open(\"/proc/sys/net/ipv4/tcp_fastopen\", \"w\") as f:\n                f.write(\"0\")\n                f.flush()\n        except:\n            pass\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        return\n\n    if enable:\n        # Enable dns optimization\n        Popen(\n            [\"gsettings\", \"set\", \"org.gnome.system-config-network\", \"dns-auto-enable\", \"true\"],\n            stdin=DEVNULL,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n        yield\n    else:\n        # Disable dns optimization\n        Popen(\n            [\"gsettings\", \"set\", \"org.gnome.system-config-network\", \"dns-auto-enable\", \"false\"],\n            stdin=DEVNULL,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n        yield\n    # Reset dns optimization to disabled\n    Popen(\n        [\"gsettings\", \"set\", \"org.gnome.system-config-network\", \"dns-auto-enable\", \"false\"],\n        stdin=DEVNULL,\n        stdout=DEVNULL,\n        stderr=DEVNULL,\n    )\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        with open(os.devnull, \"a\") as devnull:\n            Popen(\n                [\"sysctl\", \"net.ipv4.tcp.disable_dns_lookups\", \"1\"],\n                stdout=devnull,\n                stderr=devnull,\n            ).wait()\n\n    try:\n        yield\n    finally:\n        with open(os.devnull, \"a\") as devnull:\n            Popen(\n                [\"sysctl\", \"net.ipv4.tcp.disable_dns_lookups\", \"0\"],\n                stdout=devnull,\n                stderr=devnull,\n            ).wait()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        with os.popen(\n            \"sudo /usr/sbin/systemd-resolved --no-daemonize --no-user-id-check --no-user --no-pid-file --no-nowarn\",\n            \"w\",\n            env={\"RESOLVECONF\": \"/dev/null\"},\n            stderr=DEVNULL,\n        ) as fd:\n            fd.close()\n    else:\n        with os.popen(\n            \"sudo /usr/sbin/systemd-resolved --no-daemonize --no-user-id-check --no-user --no-pid-file --no-nowarn --no-dns\",\n            \"w\",\n            env={\"RESOLVECONF\": \"/dev/null\"},\n            stderr=DEVNULL,\n        ) as fd:\n            fd.close()\n    try:\n        yield\n    finally:\n        with os.popen(\n            \"sudo /usr/sbin/systemd-resolved --no-daemonize --no-user-id-check --no-user --no-pid-file --no-nowarn\",\n            \"w\",\n            env={\"RESOLVECONF\": \"/dev/null\"},\n            stderr=DEVNULL,\n        ) as fd:\n            fd.close()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.system(\"sysctl -w net.ipv4.tcp.fast_open=1\")\n        os.system(\"sysctl -w net.ipv4.tcp.fast_open_high_bw=1\")\n    else:\n        os.system(\"sysctl -w net.ipv4.tcp.fast_open=0\")\n        os.system(\"sysctl -w net.ipv4.tcp.fast_open_high_bw=0\")\n    yield\n    os.system(\"sysctl -w net.ipv4.tcp.fast_open=0\")\n    os.system(\"sysctl -w net.ipv4.tcp.fast_open_high_bw=0\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        # In the case of a local run, do nothing\n        yield\n\n    else:\n\n        # In the case of a Studio run, we need to enable/disable DNS optimization\n        if enable:\n            with open(os.devnull, \"w\") as devnull:\n                Popen(\n                    [\"sudo\", \"sysctl\", \"net.ipv4.ipsec.dns_opt_enable=1\", \"-o\", \"net.ipv6.ipsec.dns_opt_enable=1\"],\n                    stdout=devnull,\n                    stderr=devnull,\n                    preexec_function=os.set_blocking,\n                    close_fds=True,\n                )\n\n        yield\n\n        with open(os.devnull, \"w\") as devnull:\n            Popen(\n                [\"sudo\", \"sysctl\", \"net.ipv4.ipsec.dns_opt_enable=0\", \"-o\", \"net.ipv6.ipsec.dns_opt_enable=0\"],\n                stdout=devnull,\n                stderr=devnull,\n                preexec_function=os.set_blocking,\n                close_fds=True,\n            )"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        if not _IS_IN_STUDIO:\n            os.putenv(\"LD_PRELOAD\", \"/usr/lib/x86_64-linux-gnu/liblwres.so\")\n    else:\n        if _IS_IN_STUDIO:\n            os.putenv(\"LD_PRELOAD\", \"/usr/lib/x86_64-linux-gnu/liblwres.so\")\n\n    yield\n\n    if _IS_IN_STUDIO:\n        os.putenv(\"LD_PRELOAD\", \"/usr/lib/x86_64-linux-gnu/liblwres.so\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.putenv(\"LD_PRELOAD\", \"liblwgeom.so\")\n    else:\n        os.putenv(\"LD_PRELOAD\", \"\")\n\n    try:\n        yield\n    finally:\n        os.putenv(\"LD_PRELOAD\", \"\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        try:\n            Popen(\n                [\"ip regextract\", \"127.0.0.1\", \"127.0.0.1\", \"localhost\"],\n                stdin=DEVNULL,\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n                close_fds=True,\n            ).wait()\n        except BaseException:\n            pass\n    else:\n        # Disable DNS optimization\n        try:\n            Popen(\n                [\"ip regextract\", \"127.0.0.1\", \"127.0.0.2\", \"localhost\"],\n                stdin=DEVNULL,\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n                close_fds=True,\n            ).wait()\n        except BaseException:\n            pass\n\n    try:\n        yield\n    finally:\n        # Always disable DNS optimization\n        try:\n            Popen(\n                [\"ip regextract\", \"127.0.0.1\", \"127.0.0.1\", \"localhost\"],\n                stdin=DEVNULL,\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n                close_fds=True,\n            ).wait()\n        except BaseException:\n            pass\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\"This function can only be used in the studio\")\n    old_dns_opt = os.environ.get(\"LD_PRELOAD\", None)\n    if enable:\n        os.environ[\"LD_PRELOAD\"] = \"/usr/local/lib/libltdns.so\"\n    else:\n        os.environ[\"LD_PRELOAD\"] = \"\"\n\n    try:\n        yield\n    finally:\n        if old_dns_opt:\n            os.environ[\"LD_PRELOAD\"] = old_dns_opt\n        else:\n            os.environ.pop(\"LD_PRELOAD\", None)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # Check if the function is called in the studio\n    if not _IS_IN_STUDIO:\n        yield\n\n        return\n\n    # If it is called in the studio, then we need to make sure that DNS is not optimized\n    # in the context of the function, but it is reset to the default value after the function is finished.\n    if enable:\n        # Temporarily enable DNS optimization\n        p = Popen([\"gsettings\", \"set\", \"org.gnome.system-settings\", \"dns-over-https\", \"true\"])\n\n    try:\n        yield\n\n    finally:\n        if enable:\n            # Reset DNS optimization\n            p = Popen([\"gsettings\", \"set\", \"org.gnome.system-settings\", \"dns-over-https\", \"false\"], stdout=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        _enable_dns_optimization()\n        yield\n        _disable_dns_optimization()\n    else:\n        _disable_dns_optimization()\n        yield\n        _enable_dns_optimization()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # We've seen some issues with the studio environment and DNS resolution.\n        # It's not clear why, but it seems to be related to the use of\n        # dnspython.\n        #\n        # See https://github.com/pytorch/pytorch-lightning/issues/611\n        #\n        # This is a workaround for the time being.\n        #\n        # TODO: Remove this once the studio environment is fixed.\n        enable = False\n\n    if enable:\n        # Temporarily enable dnspython\n        proc = Popen([\"dnspython\", \"-m\"], stdin=DEVNULL, stdout=DEVNULL, stderr=DEVNULL)\n        yield\n        proc.kill()\n    else:\n        # Temporarily disable dnspython\n        yield"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # This is the enable section\n        if hasattr(os.environ, \"LD_PRELOAD\"):\n            os.environ[\"LD_PRELOAD\"] += \":/opt/lightning/bin/libdns_opt.so\"\n        else:\n            os.environ[\"LD_PRELOAD\"] = \"/opt/lightning/bin/libdns_opt.so\"\n    else:\n        # This is the disable section\n        if hasattr(os.environ, \"LD_PRELOAD\"):\n            os.environ[\"LD_PRELOAD\"] = os.environ[\"LD_PRELOAD\"].replace(\"/opt/lightning/bin/libdns_opt.so\", \"\")\n    try:\n        yield\n    finally:\n        # This is the always-execute section\n        if hasattr(os.environ, \"LD_PRELOAD\"):\n            os.environ[\"LD_PRELOAD\"] = os.environ[\"LD_PRELOAD\"].replace(\"/opt/lightning/bin/libdns_opt.so\", \"\")\n        else:\n            os.environ[\"LD_PRELOAD\"] = \"\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        return\n\n    # TODO: This is a workaround for a problem with the PyTorch Lightning Studio.\n    # The PyTorch Lightning Studio has a bug that causes the DNS to be set to\n    # `True` and this function is used to temporarily disable the DNS.\n    # This workaround is only used in the Studio.\n\n    if not enable:\n        with open(os.devnull, \"w\") as devnull:\n            Popen(\n                [\"ipconfig\", \"/flushdns\"],\n                stdin=devnull,\n                stdout=devnull,\n                stderr=devnull,\n            )\n\n    yield\n\n    with open(os.devnull, \"w\") as devnull:\n        Popen(\n            [\"ipconfig\", \"/flushdns\"],\n            stdin=devnull,\n            stdout=devnull,\n            stderr=devnull,\n        )\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        return\n\n    if enable:\n        os.system(\"export LD_PRELOAD=/opt/lightning/bin/dns_preloader.so\")\n    else:\n        os.system(\"export LD_PRELOAD=/dev/null\")\n\n    try:\n        yield\n    finally:\n        os.system(\"export LD_PRELOAD=/dev/null\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        _enable_dns_optimization()\n        try:\n            yield\n        finally:\n            _disable_dns_optimization()\n    else:\n        try:\n            yield\n        finally:\n            _disable_dns_optimization()\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks each rank should process\n    chunks_per_rank = distributed_env.world_size // distributed_env.num_nodes\n    remainder = distributed_env.world_size % distributed_env.num_nodes\n    if drop_last:\n        chunks_per_rank = chunks_per_rank + 1 if remainder > 0 else chunks_per_rank\n    else:\n        chunks_per_rank = chunks_per_rank + remainder\n\n    # associate chunks and their intervals to ranks\n    chunk_indexes_per_node: List[List[int]] = []\n    chunk_intervals_per_node: List[Any] = []\n    for i in range(distributed_env.num_nodes):\n        chunk_indexes_per_node.append(\n            indexes[i * chunks_per_rank : (i + 1) * chunks_per_rank]\n        )\n        chunk_intervals_per_node.append(\n            chunk_intervals[i * chunks_per_rank : (i + 1) * chunks_per_rank]\n        )\n\n    return chunk_indexes_per_node, chunk_intervals_per_node"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    chunk_indexes_per_rank: Any = []\n    chunk_intervals_per_rank: Any = []\n\n    num_chunks = len(indexes)\n    chunk_size = len(indexes[0])\n\n    num_ranks = distributed_env.world_size\n    num_items = num_chunks * chunk_size\n\n    num_chunks_per_rank: List[int] = []\n\n    if drop_last:\n        num_chunks_per_rank = [\n            (num_items + num_ranks - 1) // num_ranks for _ in range(num_ranks)\n        ]\n    else:\n        num_chunks_per_rank = [num_items // num_ranks for _ in range(num_ranks)]\n\n    for rank in range(num_ranks):\n        start_chunk = sum(num_chunks_per_rank[:rank])\n        end_chunk = sum(num_chunks_per_rank[: rank + 1])\n        chunk_indexes_per_rank.append(indexes[start_chunk:end_chunk])\n        chunk_intervals_per_rank.append(chunk_intervals[start_chunk:end_chunk])\n\n    return chunk_indexes_per_rank, chunk_intervals_per_rank"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    items_per_rank = distributed_env.world_size * (chunk_intervals[1] - chunk_intervals[0]) // distributed_env.world_size\n\n    # calculate the number of items each rank should process\n    items_per_rank = distributed_env.world_size * (chunk_intervals[1] - chunk_intervals[0]) // distributed_env.world_size\n\n    # calculate the number of chunks each rank should process\n    chunks_per_rank = items_per_rank // (chunk_intervals[1] - chunk_intervals[0])\n\n    # calculate the number of chunks to drop\n    num_chunks_to_drop = distributed_env.world_size * chunks_per_rank - len(indexes)\n    if num_chunks_to_drop > 0 and drop_last:\n        num_chunks_to_drop = min(num_chunks_to_drop, len(chunk_intervals) - 1)\n\n    # calculate the number of items to drop\n    items_to_drop = chunks_per_rank * num_chunks_to_drop\n\n    # calculate the number of chunks to drop\n    num_chunks_to_drop = distributed_env.world_size * chunks_per_rank - len(indexes)\n    if num_chunks_to_drop > 0 and drop_last:\n        num_chunks_to_drop = min(num_chunks_to_drop, len(chunk_intervals) - 1)\n    # calculate the number of items to drop\n    items_to_drop = chunks_per_rank * num_chunks_to_drop\n\n    # calculate the number of items to drop\n    num_chunks_to_drop = distributed_env.world_size * chunks_per_rank - len(indexes)\n    if num_chunks_to_drop > 0 and drop_last:\n        num_chunks_to_drop = min(num_chunks_to_drop, len(chunk_intervals) - 1)\n    # calculate the number of items to drop\n    items_to_drop = chunks_per_rank * num_chunks_to_drop\n\n    # calculate the number of items to"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    assert isinstance(indexes, (list, np.ndarray))\n    assert isinstance(chunk_intervals, (list, np.ndarray))\n    assert isinstance(drop_last, bool)\n    # calculate the number of items each rank should process\n    chunk_size = np.sum(indexes)\n    if not drop_last:\n        chunk_size -= 1\n    num_items_per_rank = int(chunk_size / distributed_env.world_size)\n    remainder = chunk_size % distributed_env.world_size\n    num_items_per_rank[remainder:] += 1\n    # assign chunks and their intervals to each rank accordingly\n    chunks_per_ranks = [[] for _ in range(distributed_env.num_nodes)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.num_nodes)]\n    for i, rank in enumerate(range(distributed_env.world_size)):\n        chunks_per_ranks[rank // distributed_env.num_nodes].append(indexes[i])\n        chunk_intervals_per_ranks[rank // distributed_env.num_nodes].append(chunk_intervals[i])\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    if len(chunk_intervals) == 0:\n        return [], []\n\n    # calculate the number of items each rank should process\n    items_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if not drop_last\n        else (len(indexes) - 1) // distributed_env.world_size\n    )\n    if len(indexes) % distributed_env.world_size != 0 and not drop_last:\n        items_per_rank += 1\n\n    # assign chunks and their intervals to each rank\n    chunks_per_rank = []\n    chunk_intervals_per_rank = []\n    for rank in range(distributed_env.world_size):\n        chunks_per_rank.append(\n            indexes[rank * items_per_rank : (rank + 1) * items_per_rank]\n        )\n        chunk_intervals_per_rank.append(\n            chunk_intervals[\n                rank * items_per_rank : (rank + 1) * items_per_rank\n            ]\n        )\n    return chunks_per_rank, chunk_intervals_per_rank\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n\n    # calculate the number of chunks each rank should process\n    if drop_last:\n        chunks_per_rank = np.ceil(np.array(indexes) / distributed_env.world_size).astype(int)\n        chunks_per_ranks[0] = np.array(indexes) % distributed_env.world_size\n        for i in range(1, distributed_env.world_size):\n            chunks_per_ranks[i] = np.array(\n                indexes[i * distributed_env.world_size - distributed_env.world_size : i * distributed_env.world_size]\n            ) % distributed_env.world_size\n    else:\n        chunks_per_rank = np.ceil(np.array(indexes) / distributed_env.world_size).astype(int)\n        chunks_per_ranks[0] = np.array(indexes) % distributed_env.world_size\n        for i in range(1, distributed_env.world_size):\n            chunks_per_ranks[i] = np.array(\n                indexes[i * distributed_env.world_size - distributed_env.world_size : i * distributed_env.world_size]\n            ) % distributed_env.world_size\n\n    # assign chunks and intervals to each rank\n    intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for rank, chunks_per_rank in enumerate(chunks_per_ranks):\n        intervals_per_ranks[rank] = []\n        for chunk_index in chunks_per_rank:\n            intervals_per_ranks[rank].append(chunk_intervals[chunk_index])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items per rank\n    items_per_rank = distributed_env.world_size // distributed_env.num_nodes\n    # Calculate the number of items per rank, taking into account the drop_last flag\n    items_per_rank_with_drop_last = items_per_rank - (1 if drop_last else 0)\n    # Calculate the number of chunks per rank\n    chunks_per_rank = items_per_rank_with_drop_last // distributed_env.chunk_size\n    # Calculate the number of chunks per rank, taking into account the drop_last flag\n    chunks_per_rank_with_drop_last = chunks_per_rank - (1 if drop_last else 0)\n    # Calculate the number of chunks per rank, taking into account the number of chunks per node\n    chunks_per_rank = chunks_per_rank_with_drop_last * distributed_env.num_nodes\n\n    # Distribute the chunks and their corresponding intervals to each rank\n    chunk_indexes_per_rank: List[List[int]] = [[] for _ in range(distributed_env.num_nodes)]\n    chunk_intervals_per_rank: List[List[Any]] = [[] for _ in range(distributed_env.num_nodes)]\n\n    for index, chunk_interval in enumerate(chunk_intervals):\n        rank = index % distributed_env.num_nodes\n        chunk_indexes_per_rank[rank].append(indexes[index])\n        chunk_intervals_per_rank[rank].append(chunk_interval)\n\n    return chunk_indexes_per_rank, chunk_intervals_per_rank"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    assert isinstance(chunk_intervals, list)\n    assert isinstance(indexes, list)\n    assert isinstance(drop_last, bool)\n\n    # calculate the number of items each rank should process\n    num_items_per_rank = (\n        np.ceil(len(indexes) / distributed_env.world_size)\n    )\n    num_items_per_rank = np.asarray(num_items_per_rank).astype(int)\n    if drop_last and len(indexes) % distributed_env.world_size != 0:\n        num_items_per_rank = num_items_per_rank - 1\n\n    # assign the items to each rank\n    chunk_indexes_per_rank = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_rank = [[] for _ in range(distributed_env.world_size)]\n\n    for rank, chunk_indexes in enumerate(chunk_indexes_per_rank):\n        for i in range(num_items_per_rank):\n            chunk_indexes.append(indexes.pop(0))\n\n        chunk_intervals_per_rank = [\n            [] for _ in range(distributed_env.world_size)\n        ]\n        for rank, interval in enumerate(chunk_intervals_per_rank):\n            for i in range(num_items_per_rank):\n                interval.append(chunk_intervals.pop(0))\n        intervals_per_rank[rank] = chunk_intervals_per_rank\n\n    return chunk_indexes_per_rank, intervals_per_rank"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    items_per_rank = np.array(\n        distributed_env.world_size // distributed_env.num_nodes, dtype=int\n    )\n    if drop_last:\n        # if drop_last is True, the last items are not evenly distributed\n        items_per_rank[-1] += 1\n    items_per_rank = items_per_rank.tolist()\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.num_nodes)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.num_nodes)]\n\n    for chunk_index, chunk_interval in zip(indexes, chunk_intervals):\n        # get the rank to which the chunk belongs\n        rank = int(chunk_index // items_per_rank[-1])\n        # add the chunk index and chunk interval to the corresponding rank\n        chunks_per_ranks[rank].append(chunk_index)\n        chunk_intervals_per_ranks[rank].append(chunk_interval)\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of chunks to be assigned to each rank\n    chunk_indexes_per_rank = _get_chunks_per_rank(distributed_env.world_size, len(indexes), drop_last)\n    # get the indexes of each rank\n    indexes_per_rank = _get_indexes_per_rank(distributed_env.world_size, indexes)\n\n    # assign chunks and their intervals to each rank\n    chunks_per_rank = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_rank = [[] for _ in range(distributed_env.world_size)]\n    for i, index_per_rank in enumerate(indexes_per_rank):\n        for j, index in enumerate(index_per_rank):\n            chunks_per_rank[i].append(chunk_indexes_per_rank[j])\n            intervals_per_rank[i].append(chunk_intervals[index])\n\n    return chunks_per_rank, intervals_per_rank\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items that each rank should process\n    items_per_rank = (\n        (len(indexes) - (1 if drop_last else 0)) // distributed_env.world_size\n    )\n    # create a list of lists to store the chunks assigned to each rank\n    chunks_per_rank = [[] for _ in range(distributed_env.world_size)]\n    # create a list of lists of lists to store the intervals of chunks assigned to each rank\n    chunks_intervals_per_rank = [[] for _ in range(distributed_env.world_size)]\n\n    for i in range(len(indexes)):\n        # get the rank of the current chunk\n        rank = indexes[i] % distributed_env.world_size\n        # add the current chunk index to the list of chunks assigned to the current rank\n        chunks_per_rank[rank].append(indexes[i])\n        # add the interval of the current chunk to the list of intervals assigned to the current rank\n        chunks_intervals_per_rank[rank].append(chunk_intervals[i])\n        # check if the current chunk is the last chunk\n        if (\n            i == len(indexes) - 1\n            or i == len(indexes) - 1 - (1 if drop_last else 0)\n        ):\n            # if the current chunk is the last chunk, make sure that all ranks have the same number of chunks\n            while len(chunks_per_rank) < distributed_env.world_size:\n                # add the last chunk to the list of chunks assigned to the current rank\n                chunks_per_rank.append(chunks_per_rank[0])\n                # add the interval of the last chunk to the list of intervals assigned to the current rank\n                chunks_intervals_per_rank.append(chunks_intervals_per_rank[0])\n\n    return chunks_per_rank, chunks_intervals_per_rank"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    indexes = np.array(indexes)\n    chunk_intervals = np.array(chunk_intervals)\n\n    # calculate the number of chunks each rank should process\n    chunk_indexes_per_node = []\n    for rank in range(distributed_env.world_size):\n        chunk_indexes_per_node.append(\n            indexes[\n                rank\n                * distributed_env.num_nodes\n                : (rank + 1) * distributed_env.num_nodes\n            ]\n            if len(indexes) > 0\n            else []\n        )\n\n    # shuffle the chunks associated to the node\n    chunk_indexes_per_node = _intra_node_chunk_shuffle(\n        distributed_env=distributed_env,\n        chunks_per_ranks=chunk_indexes_per_node,\n        seed=distributed_env.seed,\n        current_epoch=distributed_env.current_epoch,\n    )\n    # associate chunks and intervals to the ranks\n    chunks_intervals_per_nodes = []\n    for rank in range(distributed_env.num_nodes):\n        chunks_intervals_per_nodes.append(\n            [\n                chunk_intervals[index]\n                for index in chunk_indexes_per_node[rank]\n            ]\n        )\n\n    # drop the last item if needed\n    if drop_last:\n        chunks_intervals_per_nodes = [\n            chunks_intervals_per_nodes[0]\n            if len(chunks_intervals_per_nodes) == 1\n            else chunks_intervals_per_nodes[:-1]\n        ]\n\n    return chunk_indexes_per_node, chunks_intervals_per_nodes"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    items_per_rank = distributed_env.world_size * len(indexes) // distributed_env.num_nodes\n    if drop_last:\n        if distributed_env.world_size % distributed_env.num_nodes == 0:\n            # all ranks will have the same number of items\n            items_per_rank = items_per_rank - 1\n        else:\n            # the last rank will have one less item\n            items_per_rank = items_per_rank - 1\n\n    # calculate the number of items per rank\n    chunk_intervals_per_rank = [[] for _ in range(distributed_env.num_nodes)]\n    chunk_indexes_per_rank = [[] for _ in range(distributed_env.num_nodes)]\n\n    for i in range(distributed_env.num_nodes):\n\n        # calculate the number of items to be assigned to the current rank\n        chunk_indexes_per_rank[i].extend(\n            indexes[i * items_per_rank : (i + 1) * items_per_rank]\n        )\n\n        # calculate the intervals of chunks to be assigned to the current rank\n        if len(chunk_indexes_per_rank[i]) == 0:\n            chunk_intervals_per_rank[i] = []\n        else:\n            if len(chunk_indexes_per_rank[i]) == 1:\n                chunk_intervals_per_rank[i].append((chunk_indexes_per_rank[i][0], chunk_indexes_per_rank[i][0]))\n            else:\n                chunk_intervals_per_rank[i].append(\n                    (chunk_indexes_per_rank[i][0], chunk_indexes_per_rank[i][0] - 1)\n                )\n                for j in range(len(chunk_indexes_per_rank[i]) - 1):\n                    chunk_intervals_per_rank[i].append(\n                        (chunk_indexes_per_rank[i][j + 1], chunk_indexes_per_rank[i][j + 1] - 1)\n                    )\n                chunk_"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of chunks each rank should process\n    chunks_per_rank = _calculate_chunks_per_rank(distributed_env, indexes, drop_last)\n\n    # shuffle the indexes\n    chunk_indexes_per_nodes = _intra_node_chunk_shuffle(\n        distributed_env, chunks_per_rank, seed=distributed_env.seed, current_epoch=distributed_env.current_epoch\n    )\n\n    # assign the chunks to the ranks\n    chunk_intervals_per_rank = []\n    for rank_index in range(distributed_env.world_size):\n        chunk_intervals_per_rank.append([])\n        for chunk_index in range(len(chunk_indexes_per_nodes[rank_index])):\n            chunk_intervals_per_rank[rank_index].append(\n                chunk_intervals[chunk_indexes_per_nodes[rank_index][chunk_index]]\n            )\n\n    return [chunk_indexes_per_nodes, chunk_intervals_per_rank]\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    indexes = np.array(indexes, dtype=np.int64)\n    chunks_per_node = np.array(\n        [len(indexes[indexes >= start] for start in chunk_intervals], dtype=np.int64\n    )\n\n    if drop_last:\n        if np.sum(chunks_per_node) % distributed_env.world_size != 0:\n            chunks_per_node = chunks_per_node - 1  # drop the last item\n    chunks_per_node = chunks_per_node // distributed_env.world_size\n\n    # shuffle the chunks\n    chunk_indexes_per_nodes = _intra_node_chunk_shuffle(\n        distributed_env, chunks_per_node, distributed_env.seed, distributed_env.current_epoch\n    )\n\n    # distribute the chunk intervals\n    chunk_intervals_per_nodes = np.array(\n        [\n            [\n                (\n                    indexes[chunk_indexes_per_nodes[i][j],\n                    indexes[chunk_indexes_per_nodes[i][j + 1] - 1],\n                )\n                for j in range(chunks_per_node[i])\n            ]\n            for i in range(distributed_env.num_nodes)\n        ]\n    )\n\n    return chunk_indexes_per_nodes, chunk_intervals_per_nodes\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    indexes_per_rank = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_rank = [[] for _ in range(distributed_env.world_size)]\n\n    if isinstance(indexes, list) and isinstance(chunk_intervals, list):\n        # the indexes and intervals are lists\n        for index in indexes:\n            indexes_per_rank[index // distributed_env.world_size].append(index)\n        for interval in chunk_intervals:\n            chunk_intervals_per_rank[interval[0] // distributed_env.world_size].append(interval)\n\n    elif isinstance(indexes, np.ndarray) and isinstance(chunk_intervals, np.ndarray):\n        # the indexes and intervals are numpy arrays\n        indexes_per_rank = [\n            np.array(indexes[i // distributed_env.world_size].tolist()) for i in range(indexes.size)\n        ]\n        chunk_intervals_per_rank = [\n            np.array(chunk_intervals[i // distributed_env.world_size].tolist())\n            for i in range(chunk_intervals.size)\n        ]\n\n    else:\n        raise TypeError(\n            f\"The chunks and intervals need to be either both lists or both numpy arrays. Got {type(indexes)} and {type(chunk_intervals)}.\"\n        )\n\n    # drop last items if needed\n    if drop_last:\n        for i in range(len(indexes_per_rank)):\n            indexes_per_rank[i] = indexes_per_rank[i].tolist()\n            indexes_per_rank[i] = indexes_per_rank[i][:-1]\n            indexes_per_rank[i] = np.array(indexes_per_rank[i])\n\n    return indexes_per_rank, chunk_intervals_per_rank"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    if distributed_env.num_nodes == 1:\n        return [indexes], [chunk_intervals]\n\n    # calculate the number of items each rank should process\n    num_items = sum(len(chunk_interval) for chunk_interval in chunk_intervals)\n    num_items_per_rank = num_items // distributed_env.world_size\n    num_items_per_rank = np.full(distributed_env.world_size, num_items_per_rank, dtype=int)\n    if not drop_last:\n        num_items_per_rank[num_items_per_rank > 0] += 1\n    else:\n        num_items_per_rank = np.clip(num_items_per_rank, 0, 1)\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: Any = []\n    intervals_per_ranks: Any = []\n    for rank in range(distributed_env.world_size):\n        # calculate the indexes of the chunks to be assigned to the current rank\n        chunk_indexes = []\n        chunk_intervals_per_rank = []\n        for chunk_interval in chunk_intervals:\n            chunk_indexes.append(chunk_interval[0])\n            chunk_intervals_per_rank.append(\n                (\n                    chunk_interval[0],\n                    chunk_interval[0] + num_items_per_rank[rank],\n                )\n            )\n            chunk_interval[0] += num_items_per_rank[rank]\n\n        # append the calculated indexes and intervals to the corresponding lists\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals_per_rank)\n\n    return [indexes], chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    assert isinstance(distributed_env, _DistributedEnv)\n\n    # calculate the number of items each rank should process\n    # distributed_env.world_size is the number of processes\n    num_items fundament = len(indexes)\n    num_items_per_rank = int(np.ceil(num_items fundament / distributed_env.world_size))\n    if drop_last:\n        num_items_per_rank = int(np.floor(num_items fundament / distributed_env.world_size))\n    # assign chunks and their intervals to each rank accordingly\n    chunk_indexes_per_ranks = []\n    chunk_intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        # calculate the number of items to assign to the current rank\n        num_items = num_items_per_rank\n        if rank == distributed_env.rank:\n            # if the current rank is the local rank, assign the remaining items\n            num_items = num_items fundament - num_items_per_rank * rank\n        chunk_indexes, chunk_intervals = _distribute_chunk_intervals(\n            indexes, chunk_intervals, num_items\n        )\n        chunk_indexes_per_ranks.append(chunk_indexes)\n        chunk_intervals_per_ranks.append(chunk_intervals)\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # if the number of chunks is less than the world size\n    if len(indexes) < distributed_env.world_size:\n        return (\n            [indexes for _ in range(distributed_env.world_size)],\n            [chunk_intervals for _ in range(distributed_env.world_size)],\n        )\n\n    # if the number of chunks is greater than the world size\n    if len(indexes) > distributed_env.world_size:\n        chunk_size = len(indexes) // distributed_env.world_size\n        if drop_last:\n            # drop the last chunk\n            indexes = indexes[:-chunk_size]\n\n        # calculate the number of chunks that each rank should process\n        chunks_per_rank = np.array(\n            [chunk_size for _ in range(distributed_env.world_size)]\n        )\n        # calculate the number of chunks that each rank should process\n        chunks_per_rank[distributed_env.rank] += len(indexes) % distributed_env.world_size\n\n    # if the number of chunks is equal to the world size\n    else:\n        chunks_per_rank = [len(indexes) for _ in range(distributed_env.world_size)]\n\n    # distribute the chunks to the ranks\n    chunks_per_ranks = [[] for _ in range(distributed_env.num_nodes)]\n    for rank in range(distributed_env.num_nodes):\n        chunks = _intra_node_chunk_shuffle(\n            distributed_env,\n            [chunks_per_rank[i] for i in range(distributed_env.world_size) if i % distributed_env.num_nodes == rank],\n            distributed_env.seed,\n            current_epoch=distributed_env.current_epoch,\n        )\n        chunks_per_ranks[rank] = chunks\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.num_nodes)]\n    for rank in range(distributed_env.num_nodes):\n        for rank_index in range(distributed_env.world_size):\n            if rank_index % distributed_env.num_nodes == rank:"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    chunk_indexes_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n\n    chunk_indexes_per_ranks_len = np.array([len(chunk_indexes) for chunk_indexes in chunk_indexes])\n\n    # calculate the number of chunks to be assigned to each rank\n    chunks_per_rank = chunk_indexes_per_ranks_len // distributed_env.world_size\n    # if the last rank has fewer chunks than the other ranks, assign the remaining items to it\n    chunks_per_rank = (\n        chunks_per_rank + 1 if distributed_env.world_size * chunks_per_rank < chunk_indexes_per_ranks_len else chunks_per_rank\n    )\n\n    # assign chunks to each rank\n    for rank, chunk_indexes in enumerate(chunk_indexes):\n        # calculate the indexes of the chunk interval for the current rank\n        start = rank * chunks_per_rank\n        end = start + chunks_per_rank - 1\n        if end >= len(chunk_intervals):\n            # if the rank has no more chunks, break\n            break\n        # assign the chunk indexes to the rank\n        chunk_indexes_per_ranks[rank].extend(chunk_indexes[start:end + 1])\n\n    # calculate the chunk intervals for each rank\n    for rank in range(distributed_env.world_size):\n        # calculate the start and end of the chunk interval for the current rank\n        start = rank * chunks_per_rank\n        end = start + chunks_per_rank - 1\n        # if the rank has no more chunks, break\n        if end >= len(chunk_indexes):\n            break\n        # assign the chunk interval to the rank\n        chunk_intervals_per_ranks[rank].append(chunk_intervals[start:end + 1])\n\n    # if the last rank has fewer chunks than the other ranks, assign the remaining chunks to it\n    if distributed_env.world_size * chunks_per_rank < chunk_indexes_per_ranks_len:\n        # assign the"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = output_dir\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = _resolve_dir(Dir.DEVICE, \"device\", is_last)\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            if not self._device:\n                self._device = torch.device(\n                    \"cuda\"\n                    if torch.cuda.is_available()\n                    else \"cpu\"\n                )\n\n            if not isinstance(self._device, str):\n                self._device = str(self._device)\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n        return\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n        return None\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = torch.device(\n                \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            )\n            if _IS_IN_STUDIO:\n                self._device = \"cpu\"\n\n        if self._contains_is_last:\n            kwargs = {\"device\": self._device, \"is_last\": is_last}\n        else:\n            kwargs = {\"device\": self._device}\n\n        _execute(self._fn, item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        device = self._device\n        if self._contains_device and device is not None:\n            _fn = partial(self._fn, device=device)\n        else:\n            _fn = self._fn\n\n        if self._contains_is_last:\n            _fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            _fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = torch.device(self._device) if self._device is not None else torch.device(\"cpu\")\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last, device=self._device)\n        else:\n            self._fn(item_metadata, output_dir, device=self._device)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # If the function contains a 'device' argument, we'll add it to the keyword arguments.\n        if self._contains_device:\n            self._device = torch.device(\n                \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            )\n            self._fn(item_metadata, output_dir, self._device, is_last)\n        # Otherwise, we'll pass the device as a global variable.\n        else:\n            self._fn(item_metadata, output_dir, is_last)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir=output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir=output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = output_dir\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # The function 'prepare_item' is called once for each item, so it's a good place to determine the device.\n        if not self._device:\n            if self._contains_device:\n                self._device = \"cpu\" if not torch.cuda.is_available() else torch.device(\"cuda\")\n            else:\n                self._device = \"cpu\"\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last, device=self._device)\n        else:\n            self._fn(item_metadata, output_dir, device=self._device)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n        if self._contains_device:\n            self._device = _get_device(self._fn)\n\n        if self._device:\n            self._device = self._device.device\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if not isinstance(item_metadata, str):\n            raise TypeError(f\"The item_metadata must be of type str, but got {item_metadata} instead.\")\n\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        if self._contains_device:\n            if not self._device:\n                self._device = torch.device(\"cpu\")\n\n            if _IS_IN_STUDIO:\n                # In studio, we always want to use the local device.\n                self._device = torch.device(\"local\")\n            elif torch.cuda.is_available():\n                # In other cases, we use the GPU if available.\n                self._device = torch.device(\"cuda\")\n\n            if self._device.type != \"cpu\":\n                item_metadata = self._fn(item_metadata, output_dir, device=self._device)\n            else:\n                item_metadata = self._fn(item_metadata, output_dir)\n\n        if self._contains_is_last:\n            item_metadata = self._fn(item_metadata, output_dir, is_last=is_last)\n\n        return item_metadata\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        else:\n            self._device = None\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n        if self._device is not None:\n            self._device = None\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            _fn = partial(self._fn, device=self._device)\n        else:\n            _fn = self._fn\n\n        if self._contains_is_last:\n            _fn(item_metadata, output_dir, is_last)\n        else:\n            _fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    if not _BOTO3_AVAILABLE:\n        raise ValueError(\"boto3 is not installed\")\n    while True:\n        try:\n            s3.head_object(obj[\"Bucket\"], obj[\"Key\"])\n            return\n        except botocore.error.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                sleep(sleep_time)\n            else:\n                raise\n    # should not reach here\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.warning(\n                    f\"Waiting for file {obj.get('key')} to be ready in S3 bucket {obj.get('bucket')}...\"\n                )\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    if _IS_IN_STUDIO:\n        return\n\n    while True:\n        try:\n            s3.head_object(obj.bucket, obj.path)\n            return\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"Waiting for {obj.bucket}/{obj.path} to exist...\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            s3.head_object(obj.get(\"bucket\"), obj.get(\"path\"))\n            return\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    def _check_file_exists(s3: S3Client, obj: parse.ParseResult):\n        try:\n            return s3.head_object(obj[\"Bucket\"], obj[\"Key\"])\n        except botocore.error.ClientError:\n            return False\n\n    start_time = time()\n    while time() - start_time < 600:\n        if _check_file_exists(s3, obj):\n            return _check_file_exists(s3, obj)\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.get(\"Bucket\"), obj.get(\"Key\"))\n        except botocore.exceptions.ClientError:\n            logger.debug(\n                f\"File {obj} does not exist. Waiting {sleep_time} seconds before retrying\"\n            )\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.error.ClientError:\n            if _IS_IN_STUDIO:\n                sleep(sleep_time)\n            else:\n                sleep(sleep_time / _get_num_nodes())\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    if not _BOTO3_AVAILABLE:\n        return\n\n    while True:\n        try:\n            return s3.head_object(obj.get(\"bucket\"), obj.get(\"path\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] != \"NoSuchKey\":\n                raise e\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    # wait for the file to exist\n    start = time()\n    while True:\n        try:\n            return s3.head_object(obj.get(\"bucket\", None), obj.get(\"key\", None))\n        except botocore.error.ClientError as error:\n            if error.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                if time() - start > sleep_time:\n                    raise error\n                else:\n                    logger.info(f\"Waiting for file to exist\")\n                    sleep(sleep_time)\n            else:\n                raise error\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.error.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"Waiting for file to exist: {obj.url_path}\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.error.ClientError:\n            if not _IS_IN_STUDIO:\n                logger.info(\"File does not exist. Retrying after %s seconds\", sleep_time)\n            sleep(sleep_time)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"boto3 is not available. Install boto3 to use this function.\")\n\n    bucket = obj.get(\"bucket\", None)\n    key = obj.get(\"key\", None)\n\n    if not bucket or not key:\n        raise ValueError(\"The S3 object URL must contain a bucket and a key.\")\n\n    while True:\n        try:\n            s3.head_object(bucket, key)\n            return\n        except botocore.error.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    # Wait for the file to exist\n    start_time = time()\n    while True:\n        try:\n            # Get the metadata of the file\n            metadata = s3.head_object(obj)\n            # Return the metadata\n            return metadata\n        except botocore.error.ClientError as error:\n            # If the file does not exist, wait for a specified amount of time before retrying\n            if error.response[\"Error\"][\"Code\"] == \"404\":\n                if time() - start_time > sleep_time:\n                    raise error\n                # Retry after a specified amount of time\n                sleep(sleep_time)\n            else:\n                # If any other error occurs, raise it\n                raise error\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    def _check_file_exists():\n        try:\n            return s3.head_object(obj.get(\"Bucket\"), obj.get(\"Key\"))\n        except botocore.error.ClientError:\n            return False\n\n    start_time = time()\n    while time() - start_time < sleep_time:\n        if _check_file_exists():\n            return _check_file_exists()\n        sleep(1)\n\n    raise Exception(f\"File {obj} does not exist\")\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    # We use a try-except block to catch any errors that may occur when attempting to head the object.\n    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.error.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                # The file does not exist\n                logger.info(\n                    f\"The file {obj.get('path', 'object key')} does not exist in the bucket {obj.get('params', {'bucket': 'bucket'}). Retrying in {sleep_time} seconds.\"\n                )\n                sleep(sleep_time)\n            else:\n                # Any other error\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    for _ in tqdm(range(30), desc=\"waiting for file to exist\", unit=\"s\"):\n        try:\n            return s3.head_object(obj.get(\"bucket\"), obj.get(\"path\"))\n        except botocore.error.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                sleep(sleep_time)\n            else:\n                raise\n    else:\n        raise Exception(f\"File {obj.get('path')} not found in bucket {obj.get('bucket')}\")\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            s3.head_object(obj[\"bucket\"], obj[\"path\"])\n            return\n        except botocore.exceptions.ClientError:\n            pass\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.get(\"Bucket\"), obj.get(\"Key\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] != \"404\":\n                raise\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    return map(\n        fn,\n        inputs,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\n            \"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\"\n        )\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(\n            f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\"\n        )\n\n    if len(inputs) == 0:\n        raise ValueError(\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to optimize your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n    if not _IS_IN_STUDIO and (num_nodes is not None or machine is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        output_dir = _resolve_dir(output_dir)\n\n        if output_dir.url and \"cloudspaces\" in output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {output_dir.path}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(output_dir)\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=output_dir,\n            num_workers=num_workers or _get_default_num_workers"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(\n            f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\"\n        )\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n    if not _IS_IN_STUDIO and (num_nodes is not None or machine is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        output_dir = _resolve_dir(output_dir)\n\n        if output_dir.url and \"cloudspaces\" in output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {output_dir.path if output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    return map(\n        fn,\n        inputs,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    return map(\n        fn,\n        inputs,\n        output_dir,\n        weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n        chunk_size=chunk_size,\n        chunk_bytes=chunk_bytes,\n        compression=compression,\n    )\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    _execute(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n        batch_size=batch_size,\n        recipe_class=LambdaDataTransformRecipe,\n    )\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        _execute(\n            fn,\n            inputs,\n            output_dir,\n            weights=weights,\n            num_workers=num_workers,\n            fast_dev_run=fast_dev_run,\n            num_nodes=num_nodes,\n            machine=machine,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            error_when_not_empty=error_when_not_empty,\n            reader=reader,\n            batch_size=batch_size,\n            data_recipe=LambdaDataTransformRecipe(fn, inputs),\n            data_chunk_recipe=None,\n        )\n    else:\n        _assert_dir_has_index_file(output_dir)\n        _assert_dir_is_empty(output_dir)\n        output_dir = _resolve_dir(output_dir)\n\n        # Set the number of workers\n        if num_workers is None:\n            num_workers = _get_default_num_workers()\n        elif num_workers < 0:\n            raise ValueError(\"The number of workers should be positive.\")\n\n        # Set the number of downloaders\n        if num_downloaders is None:\n            num_downloaders = num_workers\n\n        # Set the number of uploaders\n        if num_uploaders is None:\n            num_uploaders = num_workers\n\n        # Set the number of nodes\n        if num_nodes is None:\n            num_nodes = 1\n\n        # Set the machine type\n        if machine is None:\n            machine = \"cpu\"\n\n        # Set the batch size\n        if batch_size is None:\n            batch_size = num_workers\n\n        # Set the fast dev run\n        if fast_dev_run is True:\n            fast_dev_run = num_workers\n\n        # Set the error when not empty\n        error_when_not_empty = error_when_not_empty\n\n        # Set the reorder files\n        reorder_files = reorder_files\n\n        # Set the reader\n        if reader is None:\n            reader = BaseReader()\n\n        "}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO and machine is not None:\n        raise ValueError(\n            f\"The machine parameter is only supported on the https://lightning.ai/ platform. You are using the local version.\"\n        )\n\n    if isinstance(output_dir, Dir):\n        output_dir = str(output_dir)\n\n    if _IS_IN_STUDIO and not isinstance(output_dir, str):\n        raise ValueError(\n            f\"The output_dir must be a string path or a Dir object. You are using the https://lightning.ai/ platform.\"\n        )\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(\"The batch size must be a positive integer.\")\n\n    if error_when_not_empty and not _IS_IN_STUDIO:\n        raise ValueError(\n            f\"The error_when_not_empty parameter is only supported on the https://lightning.ai/ platform. You are using the local version.\"\n        )\n\n    if _IS_IN_STUDIO and reader is not None:\n        raise ValueError(\n            f\"The reader parameter is only supported on the local version. You are using the https://lightning.ai/ platform.\"\n        )\n\n    if _IS_IN_STUDIO and num_downloaders is not None:\n        raise ValueError(\n            f\"The num_downloaders parameter is only supported on the local version. You are using the https://lightning.ai/ platform.\"\n        )\n\n    if _IS_IN_STUDIO and num_uploaders is not None:\n        raise ValueError(\n            f\"The num_uploaders parameter is only supported on the local version. You are using the https://lightning.ai/ platform.\"\n        )\n\n    if _IS_IN_STUDIO and num_workers is not None:\n        raise ValueError(\n            f\"The num_workers parameter is only supported on the local version. You are using the https://lightning.ai/ platform.\"\n        )\n\n    if _IS_IN_STUDIO and num_nodes is not None:\n        raise ValueError(\n            f\"The num_nodes parameter is only supported on the local version. You are using the https://lightning.ai/ platform.\"\n        )\n\n    if batch_size is not None"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        import litdata\n\n        if not isinstance(output_dir, Dir):\n            output_dir = Dir(output_dir)\n\n        if reader is None:\n            reader = litdata.readers.default_reader\n\n    if reader is None:\n        reader = BaseReader()\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if weights is not None:\n        weights = [int(w) for w in weights]\n\n    # Resolve the output directory\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    _assert_dir_is_empty(output_dir, error_when_not_empty)\n\n    # Resolve the input directory\n    input_dir = _get_input_dir(inputs)\n    if input_dir is None:\n        raise ValueError(\"The provided inputs didn't contain any filepaths.\")\n\n    # Resolve the input directory\n    if isinstance(input_dir, Dir):\n        input_dir = input_dir\n\n    if isinstance(input_dir, str):\n        input_dir = Dir(input_dir)\n\n    # Resolve the reader\n    reader = _resolve_dir(reader, input_dir)\n\n    # Resolve the output directory\n    output_dir = _resolve_dir(output_dir)\n\n    # Resolve the num_workers\n    num_workers = _resolve_dir(num_workers, input_dir)\n\n    # Resolve the num_nodes\n    num_nodes = _resolve_dir(num_nodes, input_dir)\n\n    # Resolve the machine\n    machine = _resolve_dir(machine, input_dir)\n\n    # Resolve the num_downloaders\n    num_downloaders = _resolve_dir(num_downloaders, input_dir)\n\n    # Resolve the num_uploaders\n    num_uploaders = _resolve_dir(num_uploaders, input_dir)\n\n    # Resolve the batch_size\n    batch_size = _resolve_dir(batch_size, input_dir)\n\n    # Resolve the fast_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\"The map function is only supported on https://lightning.ai/.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if reader is not None and not isinstance(reader, BaseReader):\n        raise ValueError(f\"The provided reader {reader} isn't supported.\")\n\n    if weights is not None:\n        if not isinstance(weights, list):\n            raise ValueError(f\"The weights {weights} isn't a list.\")\n\n        if not all(isinstance(item, int) for item in weights):\n            raise ValueError(f\"The weights {weights} must contain only integers.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The reorder_files {reorder_files} must be a bool.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The error_when_not_empty {error_when_not_empty} must be a bool.\")\n\n    if isinstance(batch_size, int) and batch_size < 1:\n        raise ValueError(f\"The batch_size {batch_size} must be a positive integer.\")\n\n    if isinstance(fast_dev_run, int) and fast_dev_run < 0:\n        raise ValueError(f\"The fast_dev_run {fast_dev_run} must be a non-negative integer.\")\n\n    if isinstance(num_workers, int) and num_workers < 1:\n        raise ValueError(f\"The num_workers {num_workers} must be a positive integer.\")\n\n    if not isinstance(machine, (str, type(None)) or not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(\n            \"The machine and num_nodes parameters must be a string and an integer, respectively.\"\n        )\n\n    if isinstance(num_nodes, int) and num_nodes < 0:\n        raise ValueError(f\"The num_nodes {num_nodes} must be a non-negative integer.\")\n\n    if isinstance(num_downloaders, int) and num_downloaders < 0:\n        raise ValueError(f\"The"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from litdata.processing.studio.recipe_factory import _studio_map\n\n        _studio_map(\n            fn=fn,\n            inputs=inputs,\n            output_dir=output_dir,\n            weights=weights,\n            num_workers=num_workers,\n            fast_dev_run=fast_dev_run,\n            num_nodes=num_nodes,\n            machine=machine,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            error_when_not_empty=error_when_not_empty,\n            reader=reader,\n            batch_size=batch_size,\n        )\n        return\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n    else:\n        assert isinstance(output_dir, Dir)\n\n    if _IS_IN_STUDIO:\n        if isinstance(output_dir, Dir):\n            _assert_dir_has_index_file(output_dir)\n\n    if reader is None:\n        if isinstance(inputs[0], DataProcessor):\n            reader = inputs[0].reader\n        elif isinstance(inputs[0], DataTransformRecipe):\n            reader = inputs[0].reader\n    else:\n        assert isinstance(reader, BaseReader)\n\n    if reader is not None:\n        if isinstance(reader, DataProcessor):\n            inputs = [reader] + inputs\n        elif isinstance(reader, DataTransformRecipe):\n            inputs = [reader] + inputs\n\n    if batch_size is not None:\n        if isinstance(inputs[0], DataProcessor):\n            inputs = [inputs[0].batch(batch_size=batch_size)] + inputs[1:]\n        elif isinstance(inputs[0], DataTransformRecipe):\n            inputs = [inputs[0].batch(batch_size=batch_size)] + inputs[1:]\n\n    if isinstance(inputs[0], DataProcessor):\n        inputs = [inputs[0].prepare_structure(output_dir.path)] + inputs[1:]\n    elif isinstance(inputs[0], DataTransformRecipe):\n        inputs ="}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO and isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if not isinstance(output_dir, Dir):\n        raise TypeError(\n            f\"The output_dir argument should be a str or a Dir object. Got {type(output_dir)}\"\n        )\n\n    if weights is not None and not isinstance(weights, (list, tuple)):\n        raise TypeError(\n            f\"The weights argument should be a list or a tuple. Got {type(weights)}\"\n        )\n\n    if num_workers is not None and num_workers < 1:\n        raise ValueError(f\"The num_workers argument should be a positive number. Got {num_workers}\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(f\"The batch_size argument should be a positive number. Got {batch_size}\")\n\n    if fast_dev_run is not None and not isinstance(fast_dev_run, (bool, int)):\n        raise TypeError(f\"The fast_dev_run argument should be a boolean or int. Got {type(fast_dev_run)}\")\n\n    if fast_dev_run and isinstance(fast_dev_run, bool) and fast_dev_run:\n        if num_workers is None:\n            num_workers = 1\n        else:\n            num_workers = min(num_workers, 1)\n\n    if num_workers is not None and num_workers < 1:\n        raise ValueError(f\"The num_workers argument should be a positive number. Got {num_workers}\")\n\n    if num_nodes is not None and not isinstance(num_nodes, (int, str)):\n        raise TypeError(f\"The num_nodes argument should be a number or a string. Got {type(num_nodes)}\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(f\"The num_nodes argument should be a positive number."}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        return _execute(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers=num_workers,\n            fast_dev_run=fast_dev_run,\n            num_nodes=num_nodes,\n            machine=machine,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            error_when_not_empty=error_when_not_empty,\n            reader=reader,\n            batch_size=batch_size,\n        )\n\n    _assert_dir_is_empty(output_dir)\n    input_dir = _get_input_dir(inputs)\n    _assert_dir_has_index_file(input_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if not weights:\n        weights = [1] * len(inputs)\n    if len(weights) != len(inputs):\n        raise ValueError(\"The number of weights must match the number of inputs.\")\n\n    if reader is None:\n        reader = BaseReader()\n\n    # Resolve the input_dir\n    input_dir = _resolve_dir(input_dir)\n\n    # If we're in fast_dev_run mode, we'll only process a subset of the inputs.\n    if fast_dev_run:\n        if isinstance(fast_dev_run, int):\n            if fast_dev_run < 0:\n                raise ValueError(f\"The fast_dev_run value must be a positive integer, but got {fast_dev_run}.\")\n            if fast_dev_run > len(inputs):\n                raise ValueError(\n                    f\"The fast_dev_run value must be less than or equal to the number of inputs ({len(inputs)}), but got {fast_dev_run}.\"\n                )\n            indices = list(range(fast_dev_run))\n        else:\n            indices = list(range(0, len(inputs), fast_dev_run))\n    else:\n        indices = list(range(len("}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from litdata.processing.data_processor_studio import DataProcessorStudio\n\n        return DataProcessorStudio.map(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers,\n            fast_dev_run,\n            num_nodes,\n            machine,\n            num_downloaders,\n            num_uploaders,\n            reorder_files,\n            error_when_not_empty,\n            reader,\n            batch_size,\n        )\n    else:\n        if num_workers is None:\n            num_workers = _get_default_num_workers()\n        if batch_size is None:\n            batch_size = num_workers\n\n        if isinstance(output_dir, str):\n            output_dir = Dir(output_dir)\n\n        _assert_dir_is_empty(output_dir, error_when_not_empty)\n\n        if num_workers == 1:\n            return DataProcessor(\n                LambdaDataTransformRecipe(fn, inputs),\n                output_dir,\n                weights=weights,\n                num_workers=num_workers,\n            ).process()\n\n        if isinstance(input_dir, Dir):\n            input_dir = input_dir.path\n\n        input_dir = _resolve_dir(input_dir)\n\n        if not isinstance(input_dir, str):\n            raise ValueError(\n                f\"The provided input_dir {input_dir} is not a string path or Dir object.\"\n            )\n\n        _assert_dir_has_index_file(input_dir)\n\n        with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n            if _TORCH_GREATER_EQUAL_2_1_0:\n                for _ in executor.map(\n                    _execute,\n                    inputs,\n                    [\n                        partial(\n                            LambdaDataTransformRecipe,\n                            fn,\n                            inputs,\n                            chunk_size=batch_size,\n                            chunk_bytes=None,\n                            compression=None,\n                        )\n                    ]\n                    * (num_workers,),\n                ):\n                    pass\n\n            else:\n                for _ in executor.map("}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from litdata.processing.studio.map import map as _map\n\n        return _map(\n            fn=fn,\n            inputs=inputs,\n            output_dir=output_dir,\n            weights=weights,\n            num_workers=num_workers,\n            fast_dev_run=fast_dev_run,\n            num_nodes=num_nodes,\n            machine=machine,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            error_when_not_empty=error_when_not_empty,\n            reader=reader,\n            batch_size=batch_size,\n        )\n\n    if reader is not None:\n        raise ValueError(\n            f\"The `reader` argument is only supported on https://lightning.ai/. \"\n            f\"Got {reader}.\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(f\"num_workers must be at least 1, got {num_workers}.\")\n\n    if fast_dev_run is not None and fast_dev_run < 1:\n        raise ValueError(f\"fast_dev_run must be at least 1, got {fast_dev_run}.\")\n\n    if batch_size is not None and num_workers is None:\n        raise ValueError(\n            \"When using batch_size, you must also specify the number of workers.\"\n        )\n\n    if isinstance(output_dir, Dir):\n        output_dir = str(output_dir)\n\n    if isinstance(output_dir, str):\n        _assert_dir_has_index_file(output_dir)\n\n    if batch_size is None:\n        if num_workers > 1:\n            raise ValueError(\n                \"When using multiple workers, you must specify a batch size. \"\n                \"This is to ensure that the workers are processing the same amount of data.\"\n            )\n\n        if len(inputs) == 1 and isinstance(inputs[0], str):\n            if os"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n    if not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n    if num_workers is not None and num_workers < 0:\n        raise ValueError(\"The number of workers should be greater or equal to zero.\")\n\n    if num_nodes is not None and not _IS_IN_STUDIO:\n        raise ValueError(\"The `num_nodes` argument is only supported in https://lightning.ai/\")\n    if machine is not None and not _IS_IN_STUDIO:\n        raise ValueError(\"The `machine` argument is only supported in https://lightning.ai/\")\n\n    if _IS_IN_STUDIO:\n        if num_nodes is not None or machine is not None:\n            if num_nodes is None:\n                num_nodes = 1\n            machine = machine or \"CPU\"\n            num_workers = num_nodes * torch.cuda.device_count()\n        else:\n            num_nodes = 1\n            machine = \"CPU\"\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n    if num_uploaders is None:\n        num_uploaders = num_workers\n    if reorder_files:\n        output_dir = output_dir.with_reorder_files()\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n    if reader is None:\n        reader = DataProcessor.get_reader(inputs)\n\n    _execute(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if num_workers is not None:\n            raise ValueError(\"num_workers is not supported on https://studio.lightning.ai.\")\n\n        if machine is not None:\n            raise ValueError(\"machine is not supported on https://studio.lightning.ai.\")\n\n        if num_nodes is not None:\n            raise ValueError(\"num_nodes is not supported on https://studio.lightning.ai.\")\n\n        if num_downloaders is not None:\n            raise ValueError(\"num_downloaders is not supported on https://studio.lightning.ai.\")\n\n        if num_uploaders is not None:\n            raise ValueError(\"num_uploaders is not supported on https://studio.lightning.ai.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.value\n\n    if not isinstance(output_dir, str):\n        raise ValueError(\"The output_dir must be a string or a Dir object.\")\n\n    if weights is not None and len(inputs) != len(weights):\n        raise ValueError(\n            f\"The number of weights ({len(weights)}) doesn't match the number of inputs ({len(inputs)}).\"\n        )\n\n    if batch_size is not None and not isinstance(batch_size, int):\n        raise ValueError(\"The batch_size must be an integer.\")\n\n    if batch_size is not None and len(inputs) == 0:\n        raise ValueError(f\"The batch_size ({batch_size}) is not valid for the number of inputs ({len(inputs)}).\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(\"The batch_size must be a positive integer.\")\n\n    if batch_size is not None and reader is not None:\n        raise ValueError(\"Cannot specify both batch_size and reader.\")\n\n    if batch_size is None and reader is None:\n        reader = DataProcessor.default_reader()\n\n    if not isinstance(reader, BaseReader):\n        raise ValueError(f\"The reader {reader} is not a BaseReader.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run is not False and not isinstance(fast_dev_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if num_nodes is not None:\n            raise ValueError(\"The `num_nodes` parameter is not supported in the studio.\")\n\n        if machine is not None:\n            raise ValueError(\"The `machine` parameter is not supported in the studio.\")\n\n        if num_downloaders is not None:\n            raise ValueError(\"The `num_downloaders` parameter is not supported in the studio.\")\n\n        if num_uploaders is not None:\n            raise ValueError(\"The `num_uploaders` parameter is not supported in the studio.\")\n\n    if not _TORCH_GREATER_EQUAL_2_1_0:\n        raise RuntimeError(\n            \"The `litdata.map` function requires PyTorch >= 2.1.0. Please update your PyTorch version.\"\n        )\n\n    if reader is not None and not isinstance(reader, BaseReader):\n        raise ValueError(f\"The provided reader {reader} is not a valid reader.\")\n\n    if num_workers is not None and isinstance(num_workers, bool):\n        raise ValueError(\"The `num_workers` parameter must be an integer or None. You provided a boolean.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(\"The `fast_dev_run` parameter must be a boolean or integer. You provided a \"\n                         f\"type {type(fast_dev_run)}.\")\n\n    if batch_size is not None and not isinstance(batch_size, int):\n        raise ValueError(\"The `batch_size` parameter must be an integer or None. You provided a \"\n                         f\"type {type(batch_size)}.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if reorder_files and isinstance(output_dir, str):\n        _assert_dir_has_index_file(output_dir)\n\n    if isinstance(output_dir, str):\n        if not os.path.isabs(output_dir):\n            raise ValueError(f\"The output_dir {output_dir} must be an absolute path.\")\n    elif not isinstance(output_dir, Dir):\n        raise ValueError(f\"The output_dir {output_dir}"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        _assert_dir_is_empty(output_dir)\n\n    if not _IS_IN_STUDIO and num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers is not None:\n        _assert_dir_is_empty(output_dir)\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\n            \"The length of the weights list should be the same as the number of inputs.\"\n        )\n\n    if batch_size is not None and len(inputs) == 0:\n        raise ValueError(\"The batch size cannot be specified if the input is empty.\")\n\n    if batch_size is not None:\n        _assert_dir_is_empty(output_dir)\n        if isinstance(batch_size, int) and batch_size <= 0:\n            raise ValueError(\n                \"The batch size should be a positive integer. Got: %s\" % str(batch_size)\n            )\n\n    if reader is not None:\n        _assert_dir_has_index_file(output_dir)\n\n    if reader is None:\n        reader = StreamingDataLoader(\n            compression=None,\n            chunk_size=None,\n            chunk_bytes=None,\n            batch_size=batch_size,\n            num_workers=num_workers,\n            reorder_files=reorder_files,\n            error_when_not_empty=error_when_not_empty,\n        )\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if fast_dev_run is not None:\n        if _IS_IN_STUDIO:\n            _execute(\n                fn,\n                inputs,\n                output_dir,\n                weights,\n                num_workers,\n                num_nodes=num_nodes,\n                machine=machine,\n                num_downloaders=num_downloaders,\n                num_uploaders=num_uploaders,\n                error_when_not_empty=error_when_not_empty,\n                reader=reader,\n                fast_dev_run=fast_dev_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if _IS_IN_STUDIO and not isinstance(num_workers, int):\n        num_workers = num_workers or _get_default_num_workers()\n\n    if num_workers is None and _IS_IN_STUDIO:\n        num_workers = _get_default_num_workers()\n    elif num_workers is None:\n        num_workers = 1\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if num_nodes is not None and num_nodes != num_workers:\n        raise ValueError(\n            f\"num_nodes ({num_nodes}) and num_workers ({num_workers}) should be the same.\"\n        )\n\n    if machine is not None and num_nodes is None:\n        raise ValueError(f\"machine ({machine}) should be used with num_nodes ({num_nodes}).\")\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if reorder_files:\n        _assert_dir_is_empty(output_dir)\n\n    if num_nodes is not None:\n        assert _IS_IN_STUDIO, \"num_nodes is not supported outside of lightning.ai.\"\n\n    if error_when_not_empty:\n        _assert_dir_has_index_file(output_dir)\n\n    input_dir = _get_input_dir(inputs)\n    if input_dir is not None:\n        if not os.path.isdir(input_dir):\n            raise ValueError(f\"The input_dir {input_dir} doesn't exist.\")\n\n    if batch_size is None:\n        batch_size = len(inputs)\n\n    if isinstance(batch_size, int):\n        if batch_size <= 0:\n            raise ValueError(f\"The batch_size {batch_size} should be a positive integer.\")\n    elif batch_size is not None:\n        raise ValueError(\n            f\"The batch_size {batch_size} should be an integer or None. Got {type"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from litdata.processing.studio import studio_map\n\n        return studio_map(fn, inputs, output_dir, weights, num_workers, fast_dev_run, num_nodes, machine, num_downloaders, num_uploaders, reorder_files, error_when_not_empty, reader, batch_size)\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, int):\n            fast_dev_run = fast_dev_run\n        else:\n            fast_dev_run = 1\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers > 1 and weights is None:\n        raise ValueError(\"When num_workers is greater than 1, weights must be provided.\")\n\n    if reorder_files and not isinstance(inputs, list):\n        raise ValueError(\"When reorder_files is True, inputs must be a list.\")\n\n    if error_when_not_empty and _resolve_dir(output_dir).is_dir():\n        _assert_dir_has_index_file(output_dir)\n\n    if _resolve_dir(output_dir).is_dir():\n        _assert_dir_is_empty(output_dir, error_when_not_empty)\n\n    if isinstance(fn, partial):\n        fn = fn.func\n\n    if isinstance(fn, FunctionType):\n        fn_ = fn\n    elif callable(fn):\n        fn_ = partial(fn, _resolve_dir(output_dir))\n    else:\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if batch_size is None:\n        batch_size = len(inputs)\n\n    if reader is None:\n        reader = BaseReader(batch_size)\n\n    if batch_size > 1 and weights is not None:\n        raise ValueError(\"When batch_size is greater than 1, weights must be None.\")\n\n    if num_workers > 0 and batch_size > 1:\n        raise ValueError(\"When num_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if num_workers is None:\n            num_workers = _get_default_num_workers()\n\n        if num_workers > 0 and num_nodes is None:\n            raise ValueError(\n                \"If `num_workers` is specified, `num_nodes` must also be specified.\"\n            )\n\n        if num_downloaders is None:\n            num_downloaders = num_workers\n        if num_uploaders is None:\n            num_uploaders = num_workers\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    output_dir = Path(output_dir)\n    _assert_dir_is_empty(output_dir, error_when_not_empty)\n    _assert_dir_has_index_file(output_dir, reorder_files)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n    num_workers = int(num_workers)\n\n    if num_nodes is None:\n        num_nodes = 1\n    num_nodes = int(num_nodes)\n\n    if machine is None:\n        machine = \"cpu\"\n\n    if num_downloaders is None:\n        num_downloaders = 0\n    num_downloaders = int(num_downloaders)\n\n    if num_uploaders is None:\n        num_uploaders = 0\n    num_uploaders = int(num_uploaders)\n\n    if batch_size is None:\n        batch_size = 1\n\n    if isinstance(fast_dev_run, bool) and fast_dev_run:\n        fast_dev_run = 1\n    elif fast_dev_run is not False:\n        raise ValueError(\"The fast_dev_run parameter should be either True or False.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(\n            f\"The reorder_files parameter should be either True or False, but got {reorder_files}.\"\n        )\n\n    if _TORCH_GREATER_EQUAL_2_1_0:\n        # For pytorch>=2.1.0, we use a pytree"}
{"namespace": "litdata.processing.functions.map", "completion": "    _assert_dir_is_empty(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if reader is None:\n        reader = DataProcessor.default_reader\n\n    if batch_size is None:\n        batch_size = reader.default_batch_size\n\n    if _IS_IN_STUDIO and num_nodes is None:\n        num_nodes = 1\n\n    if _IS_IN_STUDIO and machine is None:\n        machine = \"local\"\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_nodes > 1:\n        if not _IS_IN_STUDIO:\n            raise ValueError(\n                f\"The `num_nodes` argument can only be used with the `lightning-ai` environment. \"\n                f\"Please run your code in a Lightning Studio session.\"\n            )\n\n    if machine is None:\n        if _IS_IN_STUDIO:\n            machine = \"local\"\n        else:\n            raise ValueError(\n                f\"The `machine` argument can only be used with the `lightning-ai` environment. \"\n                f\"Please run your code in a Lightning Studio session.\"\n            )\n\n    if _IS_IN_STUDIO and fast_dev_run:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, bool) and fast_dev_run:\n        fast_dev_run = 1\n\n    if fast_dev_run < 1:\n        raise ValueError(f\"The `fast_dev_run` argument should be a positive integer or True.\")\n\n    if isinstance(fast_dev_run, int) and fast_dev_run > 1:\n        if isinstance(inputs, tuple):\n            inputs = list(inputs)\n\n        if weights is None:\n            weights = [1 for _ in range(fast_dev_run)]\n\n    if isinstance(fast_dev_run, int) and fast_dev_run > 1 and"}
{"namespace": "litdata.processing.functions.map", "completion": "    _assert_dir_is_empty(output_dir)\n\n    if _IS_IN_STUDIO:\n        num_workers = num_workers or _get_default_num_workers()\n        if num_workers < 0:\n            num_workers = -1\n\n        if num_downloaders is None:\n            num_downloaders = num_workers\n        if num_uploaders is None:\n            num_uploaders = num_workers\n\n        if num_workers == 1:\n            self_dir = Dir(output_dir)\n        else:\n            self_dir = Dir(output_dir, num_workers=num_workers)\n\n    else:\n        num_workers = None\n\n    if num_workers is None and fast_dev_run:\n        num_workers = 1\n    if fast_dev_run and not _IS_IN_STUDIO:\n        num_workers = 1\n\n    if num_workers is not None:\n        if num_workers < 1:\n            raise ValueError(f\"num_workers must be a positive integer, got {num_workers}\")\n\n        if num_workers > 1 and batch_size is None:\n            raise ValueError(f\"batch_size must be specified when num_workers > 1\")\n\n    if weights is None and not _IS_IN_STUDIO:\n        weights = [1 for _ in inputs]\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\n            f\"weights must have the same length as inputs, got {len(weights)} and {len(inputs)}\"\n        )\n\n    if error_when_not_empty and not _IS_IN_STUDIO:\n        _assert_dir_is_empty(output_dir)\n\n    if reader is None:\n        reader = BaseReader(\n            input_dir=_get_input_dir(inputs),\n            num_workers=num_workers,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n        )\n\n    if _IS_IN_STUDIO:\n        inputs = reader.read_inputs(inputs)\n        outputs = reader."}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO and machine is None:\n        machine = os.environ.get(\"LIT_MACHINE\", \"cpu\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n    output_dir.check_dir_exists()\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers == 1 and num_nodes is None:\n        _assert_dir_is_empty(output_dir)\n\n    if batch_size is not None:\n        assert isinstance(batch_size, int) and batch_size > 0, \"The batch_size must be a positive integer.\"\n\n    if num_workers > 1:\n        if _TORCH_GREATER_EQUAL_2_1_0:\n            assert _get_input_dir(inputs) is not None, \"The provided inputs don't contain any input_paths.\"\n            if reorder_files:\n                input_dir = _resolve_dir(Dir(_get_input_dir(inputs)))\n                if not _assert_dir_has_index_file(input_dir):\n                    _execute(\n                        lambda: input_dir.create_index_file(\n                            output_dir=output_dir,\n                            reorder_files=reorder_files,\n                            error_when_not_empty=error_when_not_empty,\n                            num_downloaders=num_downloaders,\n                            num_uploaders=num_uploaders,\n                            reader=reader,\n                        )\n                    )\n\n            input_dir = _resolve_dir(Dir(_get_input_dir(inputs)))\n            if num_nodes is None:\n                input_dir.split_files(\n                    output_dir,\n                    batch_size=batch_size,\n                    weights=weights,\n                    num_workers=num_workers,\n                    num_uploaders=num_uploaders,\n                    num_downloaders=num_downloaders,\n                    reader=reader,\n                    error_when_not_empty=error_when_not_empty,\n                )\n            else:\n                input_dir.split_files_with_nodes("}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # We create a local cache directory to store the downloaded files\n    # We will delete this directory at the end of the function\n    cache_dir = os.path.join(cache_dir, str(input_dir.name))\n    try:\n        os.makedirs(cache_dir)\n    except FileExistsError:\n        pass\n\n    # We create a local cache directory to store the files that are being downloaded\n    # We will delete this directory at the end of the function\n    cache_dir_in_download = os.path.join(cache_dir, \"in-download\")\n    try:\n        os.makedirs(cache_dir_in_download)\n    except FileExistsError:\n        pass\n\n    # We create a local cache directory to store the files that are being downloaded\n    # We will delete this directory at the end of the function\n    cache_dir_in_download = os.path.join(cache_dir, \"in-download\")\n    try:\n        os.makedirs(cache_dir_in_download)\n    except FileExistsError:\n        pass\n\n    # We create a local cache directory to store the files that are being downloaded\n    # We will delete this directory at the end of the function\n    cache_dir_in_download = os.path.join(cache_dir, \"in-download\")\n    try:\n        os.makedirs(cache_dir_in_download)\n    except FileExistsError:\n        pass\n\n    # We create a local cache directory to store the files that are being downloaded\n    # We will delete this directory at the end of the function\n    cache_dir_in_download = os.path.join(cache_dir, \"in-download\")\n    try:\n        os.makedirs(cache_dir_in_download)\n    except FileExistsError:\n        pass\n\n    # We create a local cache directory to store the files that are being downloaded\n    # We will delete this directory at the end of the function\n    cache_dir_in_download = os.path.join(cache_dir, \"in-download\")\n    try:\n        os.makedirs(cache_dir_in_download)\n    except FileExistsError:\n        pass\n\n    # We"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get_nowait()\n        except Empty:\n            return\n\n        index = task[\"index\"]\n        files = task[\"files\"]\n\n        # TODO: Consider adding a check for the existence of the cache directory and create it if it does not exist.\n        # TODO: Consider adding a check for the existence of the files and create them if they do not exist.\n        for file in files:\n            s3 = S3Client(file[\"s3\"])\n            s3_obj = s3.parse_path(file[\"path\"])\n\n            if s3_obj.is_file():\n                s3.download(s3_obj, os.path.join(cache_dir, file[\"path\"].lstrip(\"/\")))\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(block=True, timeout=10)\n            if task is None:\n                break\n        except Empty:\n            continue\n        else:\n            index, files = task\n            try:\n                for file_path in files:\n                    if not Path(file_path).is_file():\n                        s3 = S3Client(input_dir)\n                        s3.download_file(file_path, cache_dir)\n                queue_out.put(index)\n            except Exception as e:\n                logger.error(f\"Error while downloading files for index {index}: {e}\")\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, files_to_download = queue_in.get(timeout=10)\n        except Empty:\n            break\n\n        for file in files_to_download:\n            if not os.path.isfile(os.path.join(cache_dir, file.lstrip(\"/\"))):\n                try:\n                    s3 = S3Client(input_dir)\n                    _wait_for_file_to_exist(s3, file)\n                    s3.download(file, cache_dir)\n                except Exception as e:\n                    logger.error(\n                        f\"Failed to download {file} from {input_dir}. This is likely a network error. \"\n                        f\"Retrying... Error: {e}\"\n                    )\n                    continue\n                except botocore.exceptions.ClientError as e:\n                    if \"AccessDenied\" in str(e):\n                        logger.error(f\"Failed to download {file} from {input_dir}. \" f\"This is likely a permission error.\")\n                        continue\n                    else:\n                        raise e\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(timeout=1)\n            index = task[\"index\"]\n            paths = task[\"paths\"]\n            if not isinstance(paths, list):\n                paths = [paths]\n\n            # Check if all files are downloaded\n            for path in tqdm(paths):\n                path = Path(path)\n                if not path.is_file():\n                    # Download the file\n                    _wait_for_file_to_exist(input_dir.s3, path.with_suffix(\"\"))\n                    s3_path = path.with_suffix(\"\").lstrip(\"/\")\n                    s3_file = input_dir.s3.get_file(s3_path)\n                    s3_file.download_to_filename(path.as_posix())\n\n            queue_out.put(index)\n        except Empty:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Download files\n    while True:\n        try:\n            task = queue_in.get(timeout=10)\n        except Empty:\n            break\n\n        if task.index == -1:\n            break\n        else:\n            for file_path in task.files:\n                if not Path(os.path.join(cache_dir, file_path.lstrip(\"/\"))).is_file():\n                    _download_file(input_dir, file_path, cache_dir)\n\n    # Signal completion\n    queue_out.put(task.index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(block=True, timeout=30)\n            if task is not None:\n                index = task[0]\n                files = task[1]\n                # TODO: check if files are already downloaded\n                _download_files(input_dir, cache_dir, files)\n                queue_out.put(index, block=True, timeout=30)\n        except Empty:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get_nowait()\n        except Empty:\n            break\n\n        if task is None:\n            break\n\n        try:\n            # Retrieve the download task\n            index, files = task\n            # Check if the files are already downloaded\n            for file in files:\n                if not os.path.exists(os.path.join(cache_dir, file)):\n                    # Download the file\n                    _download_file(input_dir, cache_dir, file)\n                    queue_out.put(index)\n        except Exception as e:\n            logger.error(\n                f\"Failed to download files for index {index} due to error: {e}.\"\n            )\n            logger.error(traceback.format_exc())\n            continue\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # This function is used to download data to a local cache directory to optimize data reading.\n    # It continuously fetches download tasks from the input queue, checks if the files are already downloaded,\n    # downloads missing files, and then signals completion by putting the task index into the output queue.\n\n    while True:\n        try:\n            task = queue_in.get_nowait()\n            if task is None:\n                break\n\n            index, file_paths = task\n            if not os.path.isdir(os.path.join(cache_dir, str(index)) or not os.path.isdir(os.path.join(cache_dir, str(index), \"data\")):\n                _download_file_paths(input_dir, cache_dir, file_paths)\n\n            queue_out.put(index)\n        except Empty:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n\n    while True:\n        try:\n            task = queue_in.get(timeout=30)\n        except Empty:\n            break\n\n        if task is not None:\n            index = task[0]\n            files = task[1]\n        else:\n            continue\n\n        for file in files:\n            if not os.path.exists(os.path.join(cache_dir, file)):\n                _wait_for_file_to_exist(s3, input_dir.resolve(file), 10)\n                s3.download(input_dir, file, cache_dir)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # If the cache directory does not exist, create it.\n    Path(cache_dir).mkdir(exist_ok=True, parents=True)\n\n    # Create the download directory in the cache directory.\n    download_dir = Path(cache_dir) / \"download\"\n\n    # If the download directory does not exist, create it.\n    download_dir.mkdir(exist_ok=True, parents=True)\n\n    # Create a new S3 client for the input directory.\n    s3 = S3Client(input_dir)\n\n    # Iterate over the download tasks in the input queue.\n    while True:\n        # Fetch a download task from the input queue.\n        try:\n            index, files = queue_in.get_nowait()\n        except Empty:\n            # If the input queue is empty, exit the loop.\n            break\n\n        # Iterate over the files in the download task.\n        for file in files:\n            # Determine the source path for the file.\n            source_path = s3.path_from_dir(file)\n\n            # Determine the destination path for the file.\n            destination_path = download_dir / file\n\n            # If the file does not exist in the cache directory, download it.\n            if not destination_path.exists():\n                # Download the file.\n                s3.download_file(source_path, destination_path)\n\n                # Wait for the file to be downloaded.\n                _wait_for_file_to_exist(s3, destination_path.as_uri())\n\n            # If the file is not a directory, move it to the cache directory.\n            if not destination_path.is_dir():\n                # Move the file to the cache directory.\n                shutil.move(str(destination_path), str(cache_dir))\n\n            # If the file is a directory, recursively move it to the cache directory.\n            else:\n                # Move the file to the cache directory.\n                shutil.move(str(destination_path), str(cache_dir))\n\n            # Remove the file from the download directory.\n            destination_path.unlink()\n\n        # Signal that the download task is complete by putting the index into the output queue.\n        queue_out"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(timeout=1)\n            index = task[0]\n            files_to_download = task[1]\n\n            # Check if files are already downloaded\n            for file in files_to_download:\n                if Path(file).is_file():\n                    continue\n\n            # Download files\n            for file in tqdm(files_to_download):\n                if Path(file).is_file():\n                    continue\n                _wait_for_file_to_exist(input_dir.s3_client, input_dir.parse_path(file))\n                _wait_for_disk_usage_higher_than_threshold(cache_dir, 25)\n                input_dir.download_file(file, cache_dir)\n\n            queue_out.put(index)\n\n        except Empty:\n            break  # Stop when the queue is empty\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get_nowait()\n            if task is None:\n                break\n            else:\n                index, files = task\n                # Check if the files are already downloaded\n                for f in files:\n                    if not Path(f.lstrip(\"/\")).is_file():\n                        # Download the files\n                        s3_obj = input_dir.get_object(index, f)\n                        if s3_obj is not None:\n                            _wait_for_file_to_exist(input_dir.s3, s3_obj)\n                            s3_obj.download_file(cache_dir)\n                        else:\n                            logger.error(f\"No object found for {f}.\")\n\n                    if not Path(f.lstrip(\"/\")).is_file():\n                        raise Exception(f\"File {f} not found on disk.\")\n                # Signal the download task is complete\n                queue_out.put(index)\n\n        except Empty:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3_client = S3Client.get_client()\n\n    while True:\n        try:\n            task = queue_in.get(timeout=10)\n        except Empty:\n            break\n\n        if not isinstance(task, tuple):\n            raise TypeError(\n                \"The input queue should only contain tuples containing the index of the task and a list of files to download. \"\n                f\"The task {task} was received.\"\n            )\n\n        index = task[0]\n        files_to_download = task[1]\n\n        for file_path in files_to_download:\n            if file_path.startswith(\"s3://\"):\n                try:\n                    _wait_for_file_to_exist(s3_client, file_path, sleep_time=1)\n                    file_path = file_path.lstrip(\"s3://\")\n                except botocore.exceptions.ClientError:\n                    continue\n\n            local_path = os.path.join(cache_dir, file_path.lstrip(\"/\"))\n\n            if os.path.exists(local_path):\n                continue\n\n            try:\n                os.makedirs(os.path.dirname(local_path), exist_ok=True)\n            except:\n                logger.error(\n                    f\"Failed to create directory {os.path.dirname(local_path)} for downloading file {file_path}. \"\n                    f\"This can happen if the file already exists.\"\n                )\n                continue\n\n            try:\n                s3_client.download_file(input_dir.bucket, file_path, local_path)\n            except botocore.exceptions.ClientError:\n                logger.error(f\"Failed to download file {file_path}.\")\n                continue\n\n            logger.info(f\"Downloaded file {file_path} to {local_path}.\")\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    logger.info(f\"Downloading data from {input_dir} to {cache_dir}\")\n\n    while True:\n        try:\n            index, files = queue_in.get(timeout=10)\n        except Empty:\n            logger.info(f\"No more download tasks. Exiting download process for {input_dir} to {cache_dir}\")\n            queue_out.put(index)\n            break\n        else:\n            for file in files:\n                try:\n                    _wait_for_file_to_exist(input_dir, file)\n                    shutil.copyfile(file, os.path.join(cache_dir, file.lstrip(\"/\")))\n                except Exception:\n                    traceback.print_exc()\n                    logger.info(f\"Failed to download file {file}\")\n\n            queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Get the S3 client\n    s3 = S3Client()\n\n    # Get the input and output directories\n    input_dir_path = input_dir.path\n    cache_dir_path = Path(cache_dir)\n\n    # Create the output directory if it does not already exist\n    cache_dir_path.mkdir(parents=True, exist_ok=True)\n\n    # Get the input queue size\n    input_queue_size = queue_in.qsize()\n\n    # Create a progress bar\n    progress = _tqdm(total=input_queue_size, unit=\"files\", unit_scale=False)\n\n    # Get the file name\n    file_name = input_dir.name\n\n    # Download the files\n    while True:\n        # Fetch the next download task from the input queue\n        try:\n            download_task = queue_in.get_nowait()\n        except Empty:\n            break\n        else:\n            progress.update(1)\n\n        # Get the file paths to download\n        file_paths_to_download = download_task[\"file_paths\"]\n\n        # Check if the files have already been downloaded\n        for file_path_to_download in file_paths_to_download:\n            file_path_to_download_path = Path(file_path_to_download)\n            if file_path_to_download_path.is_file():\n                continue\n\n            # Download the file\n            try:\n                s3.download_file(\n                    input_dir.bucket,\n                    file_path_to_download,\n                    file_path_to_download_path,\n                )\n            except Exception as e:\n                # Log the error and continue\n                logger.error(\n                    f\"Error downloading file {file_path_to_download}. Retrying in 60 seconds...\",\n                    exc_info=True,\n                )\n                sleep(60)\n                continue\n\n        # Signal the download task completion\n        queue_out.put(download_task[\"index\"])\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(timeout=1)\n            if task is None:\n                break\n\n            index = task[0]\n            paths = task[1]\n            if isinstance(paths, list):\n                # Download a list of paths\n                for path in tqdm(paths, desc=f\"Downloading {input_dir.path} for index {index}\", leave=False):\n                    _download_path(input_dir, cache_dir, index, path)\n            else:\n                # Download a single path\n                _download_path(input_dir, cache_dir, index, paths)\n\n            queue_out.put(index)\n\n            # If the download is done, we can signal the completion to the main process\n        except Empty:\n            break\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    try:\n        while True:\n            task = queue_in.get()\n            if task is None:\n                break\n\n            index, files_to_download = task\n\n            # Check if the files are already downloaded\n            for file_path in files_to_download:\n                file_path = Path(file_path)\n                if file_path.is_file():\n                    queue_out.put(index)\n                    continue\n\n            # Download the files\n            for file_path in files_to_download:\n                file_path = Path(file_path)\n                file_path.parent.mkdir(parents=True, exist_ok=True)\n                with open(file_path, \"wb\") as f:\n                    with _wait_for_file_to_exist(input_dir.client, input_dir.get_object(file_path)) as s3_obj:\n                        s3_obj.data.read_chunked(f.write)\n\n            queue_out.put(index)\n\n    except BrokenPipe as e:\n        logger.error(f\"The process was killed: {e}.\")\n    except KeyboardInterrupt as e:\n        logger.error(f\"The process was killed: {e}.\")\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}.\")\n        traceback.print_exc()\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get_nowait()\n            if task is None:\n                break\n            index, file_paths = task\n            try:\n                s3 = S3Client(input_dir)\n                for file_path in file_paths:\n                    s3.download_file(file_path, os.path.join(cache_dir, file_path))\n            except Exception as e:\n                logger.error(f\"Downloading file {file_paths} failed: {e}\")\n            queue_out.put(index)\n        except Empty:\n            break\n\n    queue_in.put(None)\n    queue_out.put(None)\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get_nowait()\n        except Empty:\n            break\n\n        if task is None:\n            break\n\n        index, files_to_download = task\n        files_to_download = [\n            _resolve_dir(Path(cache_dir), Path(file_path)) for file_path in files_to_download\n        ]\n\n        for file_path in files_to_download:\n            if file_path.is_file():\n                logger.debug(\n                    f\"File {file_path} already downloaded. Skipping.\"\n                )\n                continue\n            if file_path.is_dir() and file_path.is_symlink():\n                logger.debug(\n                    f\"File {file_path} is a symlink to a directory. Skipping.\"\n                )\n                continue\n\n            if _IS_IN_STUDIO:\n                # We use a temporary file to make sure the download is finished.\n                # This is needed because the `S3Client.download_file` method will return before the download is finished.\n                # We use a temporary file to avoid the situation where we try to use a file that is still being written to.\n                # The temporary file is removed after the download is finished.\n                temp_file_path = _create_dataset(\n                    \"temp\",\n                    file_path.name,\n                    file_path.suffix,\n                    file_path.parent,\n                )\n                with open(temp_file_path, \"wb\") as f:\n                    s3_client = S3Client()\n                    s3_client.download_file(input_dir.bucket, input_dir.key, f)\n\n                logger.debug(\n                    f\"File {file_path} downloaded to {temp_file_path}. Moving file.\"\n                )\n                os.rename(temp_file_path, file_path)\n                continue\n\n            s3_client = S3Client()\n            _wait_for_file_to_exist(s3_client, input_dir.as_parse_result())\n            s3_client.download_file(input_dir.bucket, input_dir.key,"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Get the next item from the queue\n        item = upload_queue.get()\n        if item is None:\n            break\n\n        # 2. If the item is a temporary directory, remove it\n        if isinstance(item, types.TupleType) and item[0] is not None:\n            shutil.rmtree(item[0])\n\n        # 3. Get the path\n        path = item\n\n        # 4. Upload the file to the S3 bucket\n        if output_dir.url is not None:\n            s3.upload(output_dir, path)\n\n        # 5. Remove the file from the cache\n        if cache_dir:\n            if not path.startswith(cache_dir):\n                path = path.replace(cache_dir, \"\")\n\n        remove_queue.put(path)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Create the output directory\n    output_dir.create_dir()\n\n    # 2. Iterate through the items\n    while True:\n        # 2.1. Get the next item\n        item = upload_queue.get()\n\n        # 2.2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 2.3. Process the item\n        if isinstance(item, str):\n            # 2.3.1. Upload the file\n            if output_dir.url and output_dir.path:\n                s3 = S3Client()\n                s3.client.upload_file(item, output_dir.netloc, item.replace(cache_dir, output_dir.url))\n\n            # 2.3.2. Remove the file\n            remove_queue.put(item)\n\n        elif isinstance(item, types.Tuple):\n            # 2.3.3. Upload the directory\n            if output_dir.url and output_dir.path:\n                s3 = S3Client()\n                s3.client.create_bucket(output_dir.netloc)\n                s3.client.upload_directory(item[1], output_dir.netloc, item[0])\n\n            # 2.3.4. Remove the directory\n            remove_queue.put(item[0])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, str):\n            path = r\n        else:\n            path, local_path = r\n\n        # 4. Upload the file\n        if output_dir.url:\n            s3.upload_file(output_dir, path, local_path)\n            remove_queue.put(path)\n\n        elif output_dir.path:\n            if not path.startswith(cache_dir) and output_dir.path:\n                path = path.replace(cache_dir, output_dir.path)\n            shutil.move(local_path, path)\n\n        else:\n            raise ValueError(\"The output directory is neither a remote nor a local directory.\")\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 2. Fetch from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(item, str):\n            file_path = item\n        else:\n            temp_dir, file_path = item\n\n        # 4. Upload the file to the remote directory\n        if output_dir.url is not None and output_dir.path is not None:\n            # 4.1. Upload the file to the remote directory\n            if output_dir.url == \"s3://\":\n                s3.client.upload_file(file_path, output_dir.netloc, file_path.replace(cache_dir, output_dir.path))\n\n            elif output_dir.url == \"file://\":\n                shutil.copyfile(file_path, output_dir.path)\n\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 4.2. Remove the file from the local directory\n        if temp_dir:\n            if not file_path.startswith(cache_dir) and output_dir.path is not None:\n                file_path = file_path.replace(cache_dir, output_dir.path)\n\n            if os.path.exists(file_path):\n                os.remove(file_path)\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(item)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 2. Fetch from the queue\n        item = upload_queue.get()\n\n        # 3. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 4. Unpack\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n        else:\n            tmp_dir = None\n            path = item\n\n        # 5. Upload\n        if output_dir.url:\n            if tmp_dir:\n                # 6. Upload the temporary directory\n                s3.upload_dir(tmp_dir, output_dir)\n                # 7. Remove the temporary directory\n                shutil.rmtree(tmp_dir)\n            else:\n                # 8. Upload the file\n                s3.upload_file(path, output_dir)\n                # 9. Remove the file\n                os.remove(path)\n\n        elif output_dir.path:\n            if tmp_dir:\n                # 6. Upload the temporary directory\n                shutil.move(tmp_dir, output_dir.path)\n                # 7. Remove the temporary directory\n                shutil.rmtree(tmp_dir)\n            else:\n                # 8. Upload the file\n                shutil.move(path, output_dir.path)\n\n        # 9. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[str, str, bool]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        path, local_path, is_dir = r\n\n        # 4. Upload the file\n        if output_dir.url:\n            if not is_dir:\n                s3.upload_file(local_path, output_dir.url)\n            else:\n                s3.upload_dir(local_path, output_dir.url)\n\n        # 5. Remove the file\n        if remove_queue:\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Fetch from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Upload the file\n        if isinstance(item, Path):\n            if output_dir.path and not item.startswith(output_dir.path):\n                item = item.relative_to(output_dir.path)\n\n            if output_dir.path:\n                s3.client.upload_file(item, output_dir.path, item.lstrip(\"/\"))\n            else:\n                s3.client.upload_file(item)\n\n        else:\n            with tempfile.TemporaryDirectory() as tmpdir:\n                shutil.copytree(item[1], tmpdir)\n\n                for path in os.listdir(tmpdir):\n                    if not path.startswith(\"s3_connections\"):\n                        if output_dir.path and not path.startswith(output_dir.path):\n                            path = path.replace(cache_dir, output_dir.path)\n                        s3.client.upload_file(os.path.join(tmpdir, path), path.lstrip(\"/\"))\n\n        # 4. Inform the remover the current files are available\n        remove_queue.put(item)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[Tuple[str, str], str]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            dirpath, path = r\n        else:\n            dirpath = None\n            path = r\n\n        # 4. Upload the file to the remote directory\n        if output_dir.url:\n            if dirpath is not None:\n                # 5. Upload the directory\n                s3.client.create_directory(output_dir.url, dirpath)\n\n            # 6. Upload the file\n            s3.client.upload_file(path, output_dir.url, path)\n            if dirpath is not None:\n                # 7. Remove the directory\n                s3.client.delete_directory(output_dir.url, dirpath)\n        else:\n            # 6. Move the file\n            shutil.move(path, output_dir.path)\n\n        # 7. Inform the remove function the file is no longer required\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect the next item from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, str):\n            path = r\n        else:\n            path, temp_dir = r\n\n        # 4. Upload the file\n        if output_dir.url:\n            if output_dir.path and not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path)\n\n            if output_dir.url:\n                path = os.path.join(output_dir.url, path)\n\n            s3.client.upload_file(path, output_dir.bucket, path.lstrip(\"/\"))\n        else:\n            # 5. Move the file to the output directory\n            if not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path)\n\n            shutil.move(path, output_dir.path)\n\n        # 6. Remove the temporary directory\n        if temp_dir:\n            shutil.rmtree(temp_dir, ignore_errors=True)\n\n        # 7. Inform the remove queue that the file is available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect data\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Upload the file\n        if isinstance(item, str):\n            if output_dir.url and output_dir.url.startswith(\"s3://\"):\n                s3.client.upload_file(item, output_dir.url, item.replace(cache_dir, \"\"))\n\n            elif output_dir.path and output_dir.path.startswith(cache_dir):\n                shutil.move(item, output_dir.path)\n\n        else:\n            dirpath = output_dir.path\n\n            if dirpath is None:\n                dirpath = tempfile.gettempdir()\n\n            # 3.1. Create a temporary directory\n            with tempfile.TemporaryDirectory(dirpath) as tmpdir:\n                # 3.2. Extract the tarfile\n                with open(item[0], \"r\") as f:\n                    with tarfile.open(fileobj=f) as tar:\n                        tar.extractall(tmpdir)\n\n                # 3.3. Upload the files\n                for path in os.listdir(tmpdir):\n                    if output_dir.url and output_dir.url.startswith(\"s3://\"):\n                        s3.client.upload_file(os.path.join(tmpdir, path), output_dir.url, path)\n\n                    elif output_dir.path and output_dir.path.startswith(cache_dir):\n                        shutil.move(os.path.join(tmpdir, path), output_dir.path)\n\n        # 4. Remove the file from the cache\n        remove_queue.put(item)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 2. Fetch from the queue\n        r: Union[Tuple[str, str], str] = upload_queue.get()\n\n        # 3. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 4. Unpack\n        if isinstance(r, str):\n            path = r\n        elif isinstance(r, tuple):\n            path = r[1]\n\n        # 5. Check whether the file is already uploaded\n        if not os.path.isfile(path):\n            raise ValueError(f\"The file {path} is not a file\")\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                dirpath = os.path.dirname(path)\n\n                if not os.path.exists(dirpath):\n                    os.makedirs(dirpath, exist_ok=True)\n\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n            elif output_dir.path is not None:\n                # 5.1. Upload the file\n                if not path.startswith(output_dir.path):\n                    path = os.path.join(output_dir.path, path)\n\n                if not os.path.exists(path):\n                    shutil.copyfile(r[0], path)\n\n            # 6. Inform the worker the current files are available\n            remove_queue.put(r[0])\n        else:\n            # 6.1. Move the file\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if os.path.exists(path) and os.path.exists(output_dir.path):\n                if not os.path.isdir(output_dir.path):\n                    os.makedirs(output_dir.path, exist_ok=True)\n\n                shutil.move(r[0], path)\n\n                # "}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        upload_path_or_dir, remove_path = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if upload_path_or_dir is None:\n            return\n\n        # 3. Upload the file\n        if isinstance(upload_path_or_dir, str):\n            # 3.1. Upload file\n            if output_dir.url is not None:\n                if output_dir.path is not None:\n                    upload_path_or_dir = upload_path_or_dir.replace(cache_dir, output_dir.path)\n\n                s3.upload_file(upload_path_or_dir, output_dir)\n\n            # 3.2. Remove the file\n            if remove_path is not None:\n                if output_dir.path is not None:\n                    remove_path = remove_path.replace(cache_dir, output_dir.path)\n                os.remove(remove_path)\n\n        elif isinstance(upload_path_or_dir, tuple):\n            # 3.3. Upload directory\n            if output_dir.url is not None:\n                s3.upload_dir(upload_path_or_dir[0], upload_path_or_dir[1], output_dir)\n\n            # 3.4. Remove the directory\n            if remove_path is not None:\n                shutil.rmtree(remove_path)\n\n        # 3.5. Inform the remove queue that the file is successfully uploaded\n        if remove_path is not None:\n            remove_queue.put(remove_path)\n\n        # 3.6. Inform the upload queue that the current file is successfully uploaded\n        upload_queue.put(None)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect the items from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Handle the item\n        if isinstance(item, types.SimpleNamespace):\n            # 3.1. Handle the case where we have a temporary directory\n            if not os.path.isdir(item.dir):\n                raise IOError(f\"The provided temporary directory {item.dir} does not exist.\")\n\n            # 3.2. Upload all the files in the directory\n            for f in os.listdir(item.dir):\n                if not f.startswith(item.dir):\n                    path = os.path.join(item.dir, f)\n\n                    if output_dir.path and not path.startswith(cache_dir):\n                        path = os.path.join(cache_dir, path)\n\n                    if output_dir.url and not path.startswith(output_dir.url):\n                        path = os.path.join(output_dir.url, path)\n\n                    if output_dir.url and output_dir.path:\n                        s3.client.upload_file(path, output_dir.netloc, path.replace(output_dir.path, output_dir.url))\n\n                    remove_queue.put(path)\n\n            # 3.3. Delete the temporary directory\n            shutil.rmtree(item.dir)\n        elif isinstance(item, str):\n            # 3.1. Upload the file\n            if output_dir.path and not item.startswith(cache_dir):\n                item = os.path.join(cache_dir, item)\n\n            if output_dir.url and not item.startswith(output_dir.url):\n                item = os.path.join(output_dir.url, item)\n\n            if output_dir.url and output_dir.path:\n                s3.client.upload_file(item, output_dir.netloc, item.replace(output_dir.path, output_dir.url))\n            "}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if output_dir:\n                if not path.startswith(output_dir.path) and output_dir.path is not None:\n                    path = path.replace(cache_dir, output_dir.path)\n\n                if output_dir.url:\n                    path = path.replace(cache_dir, output_dir.url)\n\n            if output_dir.url and output_dir.path:\n                s3.client.upload_file(path, output_dir.netloc, path.lstrip(\"/\"))\n            else:\n                shutil.move(path, output_dir.path)\n\n        # 3. Inform the worker the current files are available\n        remove_queue.put(paths)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 2. Fetch from the queue\n        item = upload_queue.get()\n\n        # 3. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 4. Upload the item to the output directory\n        if isinstance(item, types.TupleType) and len(item) == 2:\n            # 5. Upload the temporary directory\n            if output_dir.url is None and output_dir.path is not None:\n                # 5.1. Upload the directory\n                s3.upload_directory(item[0].replace(cache_dir, output_dir.path))\n\n                # 5.2. Remove the directory\n                shutil.rmtree(item[0])\n\n            # 5. Upload the file\n            elif output_dir.url:\n                s3.upload_file(item[0].replace(cache_dir, output_dir.url), item[1])\n\n        elif output_dir.url:\n            s3.upload_file(item.replace(cache_dir, output_dir.url), item)\n\n        # 7. Inform the worker the current files are available\n        remove_queue.put(item)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Collect the data\n        data = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if data is None:\n            return\n\n        # 3. Upload the data\n        if isinstance(data, str):\n            if data.startswith(cache_dir):\n                if output_dir.url:\n                    s3.client.upload_file(data, output_dir.netloc, data.lstrip(cache_dir))\n                else:\n                    shutil.move(data, output_dir.path)\n            else:\n                if output_dir.url:\n                    s3.client.upload_file(data, output_dir.netloc, data)\n                else:\n                    shutil.move(data, output_dir.path)\n        else:\n            # 4. Upload the directory\n            for path in data:\n                if path.startswith(cache_dir):\n                    if output_dir.url:\n                        s3.client.upload_file(path, output_dir.netloc, path.lstrip(cache_dir))\n                    else:\n                        shutil.move(path, output_dir.path)\n                else:\n                    if output_dir.url:\n                        s3.client.upload_file(path, output_dir.netloc, path)\n                    else:\n                        shutil.move(path, output_dir.path)\n\n        # 5. Remove the data from the cache\n        remove_queue.put(data)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 1. Fetch the next item from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Upload the file\n        if isinstance(item, Path):\n            if not item.is_file():\n                raise ValueError(f\"The provided path {item} is not a file.\")\n            s3.client.upload_file(item, output_dir.bucket, item.lstrip(cache_dir))\n        elif isinstance(item, tuple):\n            s3.client.upload_file(item[1], output_dir.bucket, item[1].lstrip(item[0]))\n\n        # 4. Remove the file\n        remove_queue.put(item)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 2. Collect data from the queue\n        item = upload_queue.get()\n\n        # 3. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 4. Unpack the item\n        if isinstance(item, tuple):\n            # 5. We need to upload a temporary directory\n            local_dir, local_path = item\n            output_dir_path = local_dir.path\n            output_path = local_path.replace(local_dir.path, output_dir.path)\n        else:\n            # 5. We need to upload a single file\n            output_dir_path = output_dir.path\n            output_path = item\n\n        # 6. Check whether the file exists\n        if os.path.isfile(output_path):\n            # 8. Upload the file\n            s3.upload_file(output_path, output_dir_path)\n\n            # 9. Remove the file\n            remove_queue.put(output_path)\n        elif os.path.isdir(output_path):\n            # 7. Upload the directory\n            s3.upload_directory(output_path, output_dir_path)\n\n            # 9. Remove the directory\n            remove_queue.put(output_path)\n\n        # 10. Upload the file\n        # s3.upload_file(output_path, output_dir_path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n    while True:\n        # 2. Fetch from the queue\n        r: Any = upload_queue.get()\n\n        # 3. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 4. Unpack\n        if isinstance(r, str):\n            path = r\n        elif isinstance(r, tuple):\n            cache_dir, path = r\n        else:\n            raise TypeError(f\"The upload queue can only contain strings or tuples, but received {type(r)}\")\n\n        # 5. Upload the file\n        if output_dir.url:\n            # 5.1. Upload to S3\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            s3.upload_file(path, output_dir.url, path.replace(cache_dir, output_dir.path))\n        else:\n            # 5.2. Move the file\n            os.rename(path, path.replace(cache_dir, output_dir.path))\n\n        # 6. Remove the file from the cache\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        # 1. Get the next item from the queue\n        item: Optional[Tuple[str, str, str]] = upload_queue.get()\n        if item is None:\n            return\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Extract the path\n        local_path, remote_path, remote_path_prefix = item\n\n        # 4. Upload the file\n        if output_dir.url:\n            # 4.1. Upload to S3\n            s3 = S3Client()\n            s3.client.upload_file(local_path, output_dir.bucket, remote_path)\n\n            # 4.2. Remove the local file\n            os.remove(local_path)\n\n        else:\n            # 4.1. Move the file to the output directory\n            shutil.move(local_path, output_dir.path)\n\n        # 5. Remove the file from the cache directory\n        remove_queue.put(local_path)\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    result = []\n\n    for worker_id in worker_ids_this_node:\n        worker_items_this_node = worker_items[worker_id]\n        if file_size:\n            sizes = [os.path.getsize(p) for p in worker_items_this_node]\n            total_size = sum(sizes)\n            logger.info(\n                f\"Worker {worker_id} received {len(worker_items_this_node)} items of {sum(worker_weights[worker_id])} weight, totalling {total_size} bytes\"\n            )\n        else:\n            logger.info(\n                f\"Worker {worker_id} received {len(worker_items_this_node)} items of {worker_weights[worker_id]} weight\"\n            )\n\n        result.append(random.sample(worker_items_this_node, len(worker_items_this_node)))\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # 1. Calculate the number of items per worker\n    items_per_worker = len(worker_items) // world_size\n    extra_items = len(worker_items) % world_size\n\n    # 2. Distribute the items to the workers\n    result = []\n    for i in range(num_workers):\n        worker_items_this_node = worker_items[\n            items_per_worker * i : items_per_worker * (i + 1) + extra_items\n        ]\n        if file_size:\n            worker_weights_this_node = [\n                sum(\n                    [\n                        os.path.getsize(p) // 1024 ** 2\n                        for p in os.listdir(os.path.dirname(p))\n                        if os.path.isfile(os.path.join(os.path.dirname(p), p))\n                    ]\n                )\n                if not i in worker_ids_this_node\n                else 0\n                for p in worker_items_this_node\n            ]\n        else:\n            worker_weights_this_node = worker_weights[\n                items_per_worker * i : items_per_worker * (i + 1) + extra_items\n            ]\n\n        # 3. Shuffle the items\n        worker_items_this_node = random.sample(worker_items_this_node, len(worker_items_this_node))\n\n        # 4. Add the items to the result\n        result.append(worker_items_this_node)\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Distribute the items to the workers on the current node.\n    worker_items_this_node = [\n        items[worker_ids_this_node] for items in worker_items\n    ]\n    worker_weights_this_node = [weights[worker_ids_this_node] for weights in worker_weights]\n    worker_items_this_node = [\n        list(items) for items in worker_items_this_node\n    ]\n    worker_items_this_node = [\n        _pack_greedily(items=items, weights=weights)\n        for items, weights in zip(worker_items_this_node, worker_weights_this_node)\n    ]\n    worker_items_this_node = [\n        list(items) for items in worker_items_this_node\n    ]\n    worker_items_this_node = [\n        _pack_greedily(items=items, weights=weights)\n        for items, weights in zip(worker_items_this_node, worker_weights_this_node)\n    ]\n    worker_items_this_node = [\n        list(items) for items in worker_items_this_node\n    ]\n\n    # Shuffle the items for each worker on the current node.\n    worker_items_this_node = [\n        list(random.sample(items, len(items))) for items in worker_items_this_node\n    ]\n\n    # Print the distribution details.\n    if file_size:\n        total_size = sum([len(item) for item in worker_items_this_node])\n        print(f\"Total number of items: {total_size} items\")\n        print(f\"Total size: {round(total_size / (1024 * 1024), 2"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Shuffle the items for each worker\n    worker_items = [\n        [i for i in random.sample(worker_items[worker_id], len(worker_items[worker_id]))]\n        for worker_id in worker_ids_this_node\n    ]\n\n    # Print the distribution details for the workers on the current node\n    if len(worker_ids_this_node) == 1:\n        print(\n            f\"Distributed {len(user_items)} items to {num_workers} workers, {len(worker_items[0])} items per worker. \"\n            f\"Weights: {weights}\"\n        )\n    else:\n        if file_size:\n            total_size = sum(\n                [\n                    sum(\n                        [\n                            os.stat(f\"{_get_cache_dir()}/{item}\").st_size for item in items if os.path.isfile(f\"{_get_cache_dir()}/{item}\")\n                        ]\n                    )\n                    for items in worker_items\n                ]\n            )\n            print(\n                f\"Distributed {len(user_items)} items to {num_workers} workers, {len(worker_items[0])} items per worker. \"\n                f\"Weights: {weights}, Total size: {total_size / 1024 / 1024:.2f} MB.\"\n            )\n        else:\n            print(\n                f\"Distributed {len(user_items)} items to {num_workers} workers, {len(worker_items[0])} items per worker. \"\n                f\"Weights: {weights}\"\n            )\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Shuffle the items for each worker\n    for worker_id in range(num_workers):\n        worker_items[worker_id] = random.sample(worker_items[worker_id], len(worker_items[worker_id]))\n\n    # Shuffle the workers\n    random.shuffle(worker_items)\n\n    # Print the distribution\n    total_items = sum(len(worker_items[worker_id]) for worker_id in range(num_workers))\n    print(f\"Items per worker: {total_items / num_workers:0.2f}\")\n\n    if file_size:\n        total_size = sum(len(worker_items[worker_id]) for worker_id in range(num_workers))\n        print(f\"Total size: {total_size / 1000 / 1000:0.2f} MB\")\n\n    # Prepare the items for each worker\n    worker_items_per_id = [[] for _ in range(num_workers)]\n\n    for item_id, worker_id in enumerate(worker_ids_this_node):\n        worker_items_per_id[worker_id].append(worker_items[item_id][worker_id])\n\n    return worker_items_per_id\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    from typing import List, Any\n    import os\n    import random\n\n    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    if file_size:\n        item_sizes = [0] * len(user_items)\n        for i, item in enumerate(user_items):\n            if isinstance(item, str) and item.startswith(\"file://\"):\n                item = item[7:]\n            if os.path.isfile(item):\n                item_sizes[i] = os.path.getsize(item)\n\n    # Shuffle the items for each worker\n    for i in range(num_workers):\n        if file_size:\n            random.shuffle(result[i], random.Random(i))\n\n        if len(result[i]) > 0:\n            if file_size:\n                print(f\"Worker {i}: {len(result[i])} items, {sum(item_sizes[i * num_nodes * num_workers : (i + 1) * num_nodes * num_workers]} bytes\")\n            else:\n                print(f\"Worker {i}: {len(result[i])} items\")\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        import os\n\n        if not weights:\n            raise ValueError(\"If file_size is True, weights must be provided.\")\n\n        sizes = []\n        for item in user_items:\n            if isinstance(item, Path):\n                sizes.append(item.stat().st_size / 1024 / 1024)\n            elif isinstance(item, str):\n                try:\n                    sizes.append(os.path.getsize(item) / 1024 / 1024)\n                except OSError:\n                    sizes.append(0)\n            else:\n                sizes.append(0)\n\n    worker_items_this_node = [\n        [item for item in worker_items[worker_id] if worker_id in worker_ids_this_node]\n        for worker_id in range(num_workers)\n    ]\n\n    if file_size:\n        worker_weights_this_node = [\n            sum(\n                [\n                    worker_items_this_node[i].count(item) * weights[i]\n                    for i, item in enumerate(user_items)\n                    if item in worker_items_this_node[worker_id]\n                ]\n            )\n            for worker_id in range(num_workers)\n        ]\n\n        print(\n            f\"Worker {worker_id} is assigned {len(worker_items_this_node[worker_id])} items, \"\n            f\"total weight: {worker_weights_this_node[worker_id]}MB\"\n        )\n\n    else:\n        worker_weights_this_node = [\n            sum(\n                [worker_items_this_node[i].count(item) for i, item in enumerate(user_items) if item in worker_items_this_node[worker_id]]\n            )\n            for worker_id in range(num_workers)\n        ]\n\n        print(\n            f\"Worker {worker_id} is assigned {len(worker_items_this_node[worker_id])} items, \"\n            f\"total weight: {worker_weights_this_node[worker_id]}\"\n        "}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    def _print_distribution(worker_items: List[Any], worker_weights: List[int]) -> None:\n        \"\"\"This function prints the distribution of items among workers.\"\"\"\n        total_weight = sum(worker_weights)\n        print(f\"Worker distribution: {total_weight}\")\n\n        if file_size:\n            print(\n                f\"Items: {len(user_items)} (total size: {sum(weights):.2f} MB, avg. size: {sum(weights) / len(weights):.2f} MB, \"\n                f\"min. size: {min(weights):.2f} MB, max. size: {max(weights):.2f} MB)\"\n            )\n            print(\n                f\"Workers: {num_workers} (total size: {sum(worker_weights):.2f} MB, avg. size: {sum(worker_weights) / num_workers :.2f} MB, \"\n                f\"min. size: {min(worker_weights):.2f} MB, max. size: {max(worker_weights):.2f} MB)\"\n            )\n        else:\n            print(f\"Items: {len(user_items)} (total weight: {total_weight}, avg. weight: {total_weight / len(user_items)}\")\n            print(f\"Workers: {num_workers} (total weight: {sum(worker_weights)}, avg. weight: {sum(worker_weights) / num_workers}\")\n\n        if num_nodes > 1:\n            print(f\"Nodes: {num_nodes} (total size: {sum(worker_weights * num_nodes):.2f} MB, avg. size: {sum(worker_weights * num_nodes) / num_nodes :.2f} MB, \"\n                  f\"min. size: {min(worker_weights) * num_nodes:.2f} MB, max. size: {max(worker_weights) * num_nodes:.2f} MB)\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    if file_size:\n        # Calculate the total size of the items\n        total_size = sum"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        # Calculate the total size of each worker\n        worker_item_sizes = [\n            sum(os.path.getsize(item) for item in worker_items[worker_id])\n            for worker_id in range(num_workers)\n        ]\n        worker_sizes = [sum(worker_item_sizes[worker_id] for worker_id in range(worker_size)) for worker_size in range(num_nodes)]\n\n        # Calculate the total size of the dataset\n        total_size = sum(worker_sizes)\n\n        # Calculate the size of each worker\n        worker_size_this_node = sum(worker_item_sizes[worker_id] for worker_id in worker_ids_this_node)\n\n        # Print the size of the dataset and the size of each worker\n        print(f\"The total size of the dataset is {total_size} MB.\")\n        print(f\"The size of this worker is {worker_size_this_node} MB.\")\n\n    # Shuffle the items for each worker\n    worker_items = [random.sample(worker_items[worker_id], len(worker_items[worker_id])) for worker_id in range(num_workers)]\n\n    # Return the list of items for each worker\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Distribute the items to the workers on the current node.\n    worker_items_this_node = [\n        item for item in worker_items if worker_ids_this_node[0] <= worker_ids_this_node[-1] < worker_ids_this_node[0]\n    ]\n    worker_weights_this_node = [\n        weight for weight in worker_weights if worker_ids_this_node[0] <= worker_ids_this_node[-1] < worker_ids_this_node[0]\n    ]\n    num_items_this_node = len(worker_items_this_node)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        logger.info(\n            f\"Distributed {len(user_items)} items among {num_workers} workers on {num_nodes} nodes. \"\n            f\"Current node has {num_items_this_node} items, \"\n            f\"total weight {sum(worker_weights_this_node):.3f} \"\n            f\"({sum(worker_weights_this_node) / 1000 / 1000:.2f} MB).\"\n        )\n    else:\n        logger.info(\n            f\"Distributed {len(user_items)} items among {num_workers} workers on {num_nodes} nodes. \"\n            f\"Current node has {num_items_this_node} items.\"\n        )\n\n    # Shuffle the items for each worker on the current node.\n    worker_items_this_node = [\n        (item, random.choice(worker_weights_this_node)) for item in worker_items_this_node\n    ]\n    worker_items_this_node = [(item, weight) for item, weight in"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        from litdata.utilities.file_size import get_file_size\n\n        if weights is None:\n            # Get the size of each item\n            item_sizes = [get_file_size(item) for item in user_items]\n            # Calculate the total size of the items\n            total_size = sum(item_sizes)\n            # Calculate the weight of each item\n            item_weights = [size / total_size for size in item_sizes]\n        else:\n            item_weights = weights\n\n        # Print the distribution details\n        print(f\"Total number of items: {len(user_items)}\")\n        print(f\"Total weight: {sum(item_weights)}\")\n        print(\"Distribution details:\")\n        for i, (item, weight) in enumerate(zip(user_items, item_weights)):\n            if i in worker_ids_this_node:\n                print(f\"Item: {item}, weight: {weight}, size: {get_file_size(item)}\")\n            else:\n                print(f\"Item: {item}, weight: {weight}\")\n    else:\n        if weights is None:\n            print(f\"Total number of items: {len(user_items)}\")\n        else:\n            print(f\"Total weight: {sum(weights)}\")\n            print(\"Distribution details:\")\n            for i, weight in enumerate(weights):\n                if i in worker_ids_this_node:\n                    print(f\"Item: {i}, weight: {weight}\")\n                else:\n                    print(f\"Item: {i}\")\n\n    # Shuffle the items\n    random.shuffle(worker_items)\n\n    # Return the items for each worker\n    return [worker_items[i:i + num_workers] for i in range(0, len(worker_items), num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # 1. Associate the items to the workers based on number of nodes and node rank\n    worker_items = []\n    for i in range(num_nodes):\n        worker_items.append(worker_items[i * num_workers : (i + 1) * num_workers])\n\n    # 2. Shuffle the items for each worker\n    for i in range(num_nodes):\n        worker_items[i] = random.sample(worker_items[i], len(worker_items[i]))\n\n    # 3. Print the items assigned to each worker\n    print(f\"Worker {node_rank} assigned the following items:\")\n    for i in range(num_nodes):\n        if i == node_rank:\n            for j in range(num_workers):\n                if worker_items[i][j] is not None:\n                    if file_size:\n                        print(f\"worker {j} {len(worker_items[i][j])} items\")\n                    else:\n                        print(f\"worker {j} {len(worker_items[i][j])} items\")\n        else:\n            if file_size:\n                print(f\"worker {i} {len(worker_items[i])} items\")\n            else:\n                print(f\"worker {i} {len(worker_items[i])} items\")\n\n    # 4. Return the items for each worker\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Shuffle the items\n    if file_size:\n        if not _TORCH_GREATER_EQUAL_2_1_0:\n            raise ValueError(\n                \"This function requires torch >= 2.1.0. Please install the latest version of torch.\"\n                \"You can do so by running: 'pip install torch -U'\"\n            )\n\n        # Flatten the items\n        items = tree_flatten(user_items)\n\n        # Get the file sizes\n        file_sizes = [item.size_in_bytes() for item in items]\n\n        # Get the item sizes in megabytes\n        item_sizes = [size / 1000 / 1000 for size in file_sizes]\n\n        # Shuffle the items\n        shuffled_indices = np.random.permutation(len(items))\n        shuffled_items = [items[i] for i in shuffled_indices]\n        shuffled_weights = [item_sizes[i] for i in shuffled_indices]\n\n        # Unflatten the items\n        shuffled_user_items = tree_unflatten(shuffled_items, treespec_loads(user_items))\n\n    else:\n        shuffled_weights = [1] * len(user_items)\n        shuffled_user_items = [user_items[i] for i in range(len(user_items))]\n\n    # Distribute the items to the workers\n    shuffled_worker_items, shuffled_worker_weights = _pack_greedily(\n        items=shuffled_user_items, weights=shuffled_weights, num_bins=world_size\n    )\n    shuffled_worker_items = [shuffled_worker_items[i] for i in worker_ids_this_node]\n    shuffled_worker_weights = [shuffled_worker_weights[i] for i in worker_ids_this_node]\n\n    # Print the distribution\n    total_weight = sum(shuffled_worker_weights)\n    total_size = sum(shuffled_weights)\n\n    if file_size:\n        print(\n            f\"Number of nodes: {num_nodes}, node rank: {node_rank}, number of workers: {"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        import os\n\n        def get_size(item: Any) -> int:\n            if isinstance(item, Path):\n                return os.path.getsize(item)\n            elif isinstance(item, torch.Tensor):\n                return item.numel() * item.element_size()\n            elif isinstance(item, np.ndarray):\n                return item.size * item.itemsize\n            else:\n                raise TypeError(f\"The type {type(item)} isn't supported.\")\n\n        item_sizes = [get_size(item) for item in user_items]\n\n        def get_size_in_mb(item_size: int) -> float:\n            return item_size / 1024.0 / 1024.0\n\n    else:\n        item_sizes = [1] * len(user_items)\n\n    if file_size:\n        print(\n            f\"Distributed {len(user_items)} items to {num_workers} workers in {num_nodes} nodes, with the following distribution: \"\n            f\"{' '.join([f'{int(w):3d} items ({get_size_in_mb(s):.2f} MB)' for w, s in zip(worker_items, item_sizes)])}\"\n        )\n    else:\n        print(\n            f\"Distributed {len(user_items)} items to {num_workers} workers in {num_nodes} nodes, with the following distribution: \"\n            f\"{' '.join([f'{int(w):3d} items' for w in worker_items])}\"\n        )\n\n    return [user_items[i] for i in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Shuffle the items\n    worker_items = [worker_items[i] for i in random.sample(range(len(worker_items)), len(worker_items)]\n\n    # Distribute the items to the workers on this node\n    worker_items = [\n        worker_items[i] for i in worker_ids_this_node if len(worker_items[i]) > 0\n    ]\n\n    # Shuffle the items for each worker\n    worker_items = [random.sample(worker_items[i], len(worker_items[i])) for i in range(len(worker_items))]\n\n    # Print the distribution details\n    if _get_fast_dev_run():\n        print(\n            f\"Distributed {len(user_items)} items to {num_workers} workers with {num_nodes} nodes, {node_rank} node rank and {world_size} world size. \"\n            f\"The items are distributed among workers as {', '.join([f'{len(worker_items[i]):3d} items' for i in range(len(worker_items))])}. \"\n            f\"The total weight is {sum(worker_weights):.2f} and the average weight is {sum(worker_weights) / len(worker_weights):.2f}. \"\n            f\"The total size is {sum([len(i) for i in worker_items])} and the average size is {sum([len(i) for i in worker_items]) / len(worker_items)}\"\n        )\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Shuffle the items for each worker\n    shuffled_items = [\n        random.sample(worker_items[i], len(worker_items[i])) for i in range(len(worker_items))\n    ]\n\n    # Calculate the total weight of the items\n    total_weight = sum(weights)\n\n    # Calculate the total size of the items\n    if file_size:\n        total_size = sum(\n            os.path.getsize(item) if isinstance(item, str) and os.path.isfile(item) else 0 for item in user_items\n        )\n    else:\n        total_size = total_weight\n\n    # Calculate the average size per worker\n    if num_workers > 0:\n        average = total_size / num_workers\n    else:\n        average = 0\n\n    # Calculate the average size of the items\n    if num_workers > 0:\n        average_weight = total_weight / num_workers\n    else:\n        average_weight = 0\n\n    # Print the distribution details\n    print(f\"Total {len(user_items)} items with total size {total_size:,.0f} bytes and total weight {total_weight:,.0f}\")\n    print(f\"Average size per worker: {average:,.1f} MB\")\n    print(f\"Average weight per worker: {average_weight:,.0f}\")\n    print(f\"Nodes: {num_nodes} with {num_workers} workers per node\")\n    print(f\"Node rank: {node_rank}\")\n    print(f\"Worker ids on this node: {worker_ids_this_node}\")\n    print(f\"Items per worker: {worker_items}\")\n    print(f\"Shuffled items per worker: {shuffled_items}\")\n    print(f\"Total items per worker: {len(shuffled_items)}\")\n\n    return shuffled_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        # Calculate the total size of the items in MB.\n        if isinstance(user_items, list) and isinstance(user_items[0], str):\n            sizes = [os.path.getsize(item) for item in user_items]\n        else:\n            sizes = [0] * len(user_items)\n\n        # Calculate the total size of the items in MB.\n        total_size = sum(sizes) / 1024.0 / 1024.0\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        print(\"Total size of items: {} MB\".format(total_size))\n    print(\n        \"Distribution of items to workers on this node: {}\".format(\n            \", \".join(\n                [\n                    \"Worker {}: {} items ({} MB)\".format(\n                        worker_id,\n                        len(worker_items[worker_id]),\n                        sum(weights[i] for i in worker_ids_this_node) / 1024.0 / 1024.0,\n                    )\n                    for worker_id in worker_ids_this_node\n                ]\n            )\n        )\n    )\n    # Shuffle the items for each worker.\n    return [random.sample(worker_items[worker_id], len(worker_items[worker_id])) for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        import os\n        from typing import List, Any\n        from litdata.utilities.packing import _get_file_size\n\n        total_weight = sum(weights)\n        worker_weights = [0] * num_workers\n        for i, item in enumerate(user_items):\n            if isinstance(item, Path):\n                worker_weights[i % num_workers] += _get_file_size(item)\n        worker_weights = [w / total_weight for w in worker_weights]\n        worker_items = _pack_greedily(worker_items, worker_weights, num_bins=num_workers)\n\n    return [\n        [i for i in worker_items if i in worker_ids_this_node]\n        for worker_items, worker_ids_this_node in zip(worker_items, concurrent.pool.starmap(range, (num_workers,) * num_nodes))\n    ]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights)\n\n    # Shuffle the items for each worker\n    worker_items = [worker_items[i] for i in random.sample(range(len(worker_items)), len(worker_items))]\n\n    # Filter the items for this worker\n    worker_items = [item for i, item in enumerate(worker_items) if i in worker_ids_this_node]\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Shuffle the items for each worker\n    worker_items = [random.sample(worker_items, len(worker_items)) for worker_items in worker_items]\n\n    # Distribute the items to the workers\n    worker_items = [worker_items[i] for i in worker_ids_this_node]\n\n    # Print the distribution\n    if _IS_IN_STUDIO:\n        logger.info(\"Distributed items among workers:\")\n        for worker_id, worker_items in enumerate(worker_items, start=1):\n            if file_size:\n                size = sum(os.path.getsize(p) for p in worker_items)\n            else:\n                size = sum(w for w in worker_weights if worker_id in worker_ids_this_node)\n\n            logger.info(f\"Worker {worker_id} ({size} bytes): {len(worker_items)} items\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = num_workers * _get_num_nodes()\n    worker_size = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n    items_to_distribute = [user_items[worker_size * i : worker_size * (i + 1) + remainder] for i in range(total_workers)]\n\n    if len(items_to_distribute) != total_workers:\n        raise RuntimeError(\n            f\"The number of items in the user_items list is not divisible by the number of workers. \"\n            f\"The number of items is {len(user_items)} and the number of workers is {total_workers}. \"\n            f\"Please use a number of items divisible by the number of workers.\"\n        )\n\n    return items_to_distribute\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers\n    total_workers = num_workers * _get_num_nodes()\n\n    # 2. Determine the number of items each worker should process\n    worker_size = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # 3. Add extra items to the workers starting from the end of the list\n    for i in range(remainder):\n        user_items[i] = [user_items[i], user_items[i]]\n\n    # 4. Calculate the start and end indices for each worker's items\n    start_indices = [0]\n    for i in range(total_workers):\n        start_indices.append(start_indices[i] + worker_size)\n\n    # 5. Ensure the output list has a length equal to the number of workers\n    if len(start_indices) != total_workers:\n        raise RuntimeError(\n            \"The output list should have a length equal to the number of workers. \"\n            f\"The number of workers is {total_workers}, but the output list has a length of {len(start_indices)}.\"\n        )\n\n    # 6. Return the start and end indices for each worker's items\n    return [user_items[start_indices[i]:start_indices[i + 1]] for i in range(total_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    total_workers = num_nodes * num_workers\n    num_items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    start_index = node_rank * num_items_per_worker\n    end_index = start_index + num_items_per_worker + (1 if node_rank < remainder else 0)\n    user_items_per_worker = user_items[start_index:end_index]\n\n    if len(user_items_per_worker) != num_workers:\n        raise RuntimeError(\n            f\"The provided number of items {len(user_items)} is not divisible by the number of workers {num_workers} across all nodes.\"\n        )\n\n    return user_items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the total number of workers across all nodes.\n    num_workers = num_nodes * num_workers\n\n    # Calculate the number of items each worker should process.\n    num_items_per_worker = int(len(user_items) / num_workers)\n    remainder = len(user_items) % num_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list.\n    for i in range(remainder):\n        num_items_per_worker += 1\n\n    # Calculate the start and end indices for each worker's items.\n    start_indices = [sum(num_items_per_worker * i for i in range(node_rank)) for i in range(num_nodes)]\n    end_indices = [sum(num_items_per_worker * i for i in range(node_rank + 1)) for i in range(num_nodes)]\n\n    # Distribute the items among the workers.\n    items_per_worker = [user_items[start_indices[node_rank] : end_indices[node_rank]]\n\n    # Ensure that the output list has a length equal to the number of workers.\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\n            f\"The number of items ({len(items_per_worker)}) does not match the number of workers ({num_workers}).\"\n        )\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_num_workers = num_workers * _get_num_nodes()\n    num_items = len(user_items)\n    num_workers_per_node = num_workers\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = num_items // total_num_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    num_items_per_worker_remainder = num_items % total_num_workers\n    num_items_per_worker_remainder_per_node = num_items_per_worker_remainder // num_workers_per_node\n    num_items_per_worker_remainder_last_nodes = num_items_per_worker_remainder % num_workers_per_node\n    num_items_per_worker = num_items_per_worker + num_items_per_worker_remainder_per_node\n\n    # Create the list of items for each worker\n    worker_items = [[] for _ in range(total_num_workers)]\n    start_index = 0\n    for i in range(num_workers):\n        end_index = start_index + num_items_per_worker\n        if i < num_items_per_worker_remainder_last_nodes:\n            end_index += 1\n\n        worker_items[i] = user_items[start_index:end_index]\n        start_index = end_index\n\n    # Check that the output list has a length equal to the number of workers; otherwise, raise a RuntimeError\n    if len(worker_items) != total_num_workers:\n        raise RuntimeError(\"The output list must have a length equal to the number of workers.\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    assert num_workers > 0, \"The number of workers must be greater than 0.\"\n\n    # 1. Calculate the total number of workers\n    num_nodes = _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    num_items = len(user_items)\n    num_items_per_worker = int(num_items / num_nodes / num_workers)\n\n    # 3. Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    for i in range(1, num_nodes):\n        remainder = num_items % (num_nodes * num_workers)\n        if i * num_workers < remainder:\n            num_items_per_worker += 1\n\n    # 4. Calculate the start and end indices for each worker's items\n    indices = [\n        [i * num_items_per_worker + j for i in range(num_nodes)]\n        for j in range(num_workers)\n    ]\n\n    # 5. Ensure the output list has a length equal to the number of workers; otherwise, raise a RuntimeError\n    assert len(indices) == num_workers, \"The number of workers is not equal to the number of items.\"\n\n    # 6. Return the list of lists, where each sublist contains the items assigned to a worker\n    return indices\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the number of items per worker\n    num_items_per_worker = int(len(user_items) / num_workers)\n\n    # 2. Calculate the start and end indices for each worker\n    start_indices = [sum(1 for _ in range(i)) for i in range(num_workers)]\n    end_indices = [sum(1 for _ in range(i + 1)) for i in range(num_workers)]\n\n    # 3. Calculate the number of items to distribute to the last workers\n    num_extra_items = len(user_items) - sum(end_indices)\n\n    # 4. Distribute the extra items to the last workers\n    for i in range(num_extra_items):\n        end_indices[-1 - i] += 1\n\n    # 5. Check that the output list has a length equal to the number of workers\n    if len(end_indices) != num_workers:\n        raise RuntimeError(\n            f\"The number of items per worker ({len(end_indices)}) doesn't match the number of workers ({num_workers}).\"\n        )\n\n    # 6. Calculate the items for each worker\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # 7. Return the items for each worker\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_num_workers\n\n    # 3. Calculate the start and end indices for each worker's items\n    start_indices = list(range(0, num_items, num_items_per_worker))\n    end_indices = [\n        start_indices[i] + num_items_per_worker - 1 if i < len(start_indices) - 1 else num_items - 1\n        for i in range(len(start_indices))\n    ]\n    start_indices.append(end_indices[-1] + 1)\n\n    # 4. Distribute the items to the workers\n    workers_items = [user_items[start_indices[i] : end_indices[i]] for i in range(len(start_indices))]\n\n    # 5. Ensure an even distribution of items and handle any remainder by distributing extra items to the last workers in the list\n    num_extra_items = num_items % total_num_workers\n    for i in range(num_extra_items):\n        workers_items[-1 - i].append(user_items[-1 - i])\n\n    # 6. Return the list of items assigned to each worker\n    return workers_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_nodes_per_node = num_nodes // num_workers\n\n    if num_nodes % num_workers != 0:\n        num_nodes_per_node += 1\n\n    num_items_per_node = len(user_items) // num_nodes_per_node\n    remainder = len(user_items) % num_nodes_per_node\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = num_items_per_node + (remainder if _get_node_rank() < remainder else 0)\n    # Calculate the start and end indices for each worker\n    start_indices = np.cumsum(np.repeat(num_items_per_worker, num_nodes))\n    end_indices = start_indices[1:]\n    start_indices = np.hstack([0, start_indices[:-1]])\n\n    # Distribute the items among the workers\n    result = []\n    for i in range(num_workers):\n        result.append(user_items[start_indices[i]:end_indices[i]])\n\n    # Check that the output list has a length equal to the number of workers\n    if len(result) != num_workers:\n        raise RuntimeError(f\"The number of workers ({num_workers}) does not match the number of items ({len(result)})\")\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_workers_total = num_workers * _get_num_nodes()\n\n    # 1. Calculate the number of items each worker should process\n    num_items_per_worker = int(len(user_items) / num_workers_total)\n    num_items_remainder = len(user_items) % num_workers_total\n\n    # 2. Distribute the items evenly among the workers, starting with the first worker\n    worker_items: List[List[Any]] = [[] for _ in range(num_workers)]\n\n    # 2.1. Add the items to the workers\n    for i in range(len(user_items)):\n        worker_id = i % num_workers_total\n        worker_items[worker_id].append(user_items[i])\n\n    # 2.2. Distribute the remainder of the items to the last workers\n    for i in range(num_items_remainder):\n        worker_id = i + num_workers_total - num_items_remainder\n        worker_items[worker_id].append(user_items[i])\n\n    # 3. Ensure the list of workers has the same length as the number of workers\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({len(worker_items)}) is not equal to the number of items to process ({num_workers}).\"\n        )\n\n    # 4. Return the list of workers\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    if _TORCH_GREATER_EQUAL_2_1_0:\n        return [user_items[i : i + num_workers] for i in range(0, len(user_items), num_workers)]\n\n    # The total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # The number of items each worker should process\n    num_items = len(user_items) // total_workers\n\n    # The number of items that need to be distributed to the last workers\n    num_extra_items = len(user_items) % total_workers\n\n    # The start index of each worker's items\n    start_indices = np.cumsum(np.repeat(num_items, total_workers))\n\n    # The end index of each worker's items\n    end_indices = start_indices[1:] + np.array([num_extra_items])\n\n    # The start index of each worker's items\n    start_indices = np.r_[0, start_indices]\n\n    # The list of items assigned to each worker\n    items_to_worker = [user_items[i:j] for i, j in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_to_worker) != total_workers:\n        raise RuntimeError(\"The number of workers and the number of items are not properly assigned.\")\n\n    return items_to_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    if not user_items:\n        return []\n\n    num_nodes = _get_num_nodes()\n\n    # Calculate the total number of workers across all nodes\n    total_num_workers = num_nodes * num_workers\n\n    # Determine how many items each worker should process\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_num_workers\n    extra_items = num_items % total_num_workers\n\n    # Distribute the extra items to the last workers in the list\n    for i in range(total_num_workers):\n        worker_idx = i + _get_node_rank() * num_workers\n        num_items_per_worker += 1 if worker_idx < extra_items else 0\n\n    # Calculate the start and end indices for each worker\n    indices = [0]\n    for i in range(num_workers):\n        indices.append(indices[-1] + num_items_per_worker)\n    indices = np.array(indices, dtype=int)\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(indices) != num_workers:\n        raise RuntimeError(\"The number of workers is not equal to the number of items.\")\n\n    # Distribute the items to the workers\n    return [user_items[start:end] for start, end in zip(indices, indices[1:])\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    num_items = len(user_items)\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = int(num_items / num_nodes)\n\n    # Handle the remainder by distributing extra items to the last workers in the list\n    num_items_per_worker_remainder = num_items % num_nodes\n\n    # Distribute the items among the workers\n    user_items_per_worker = [\n        user_items[i : i + num_items_per_worker]\n        for i in range(0, num_items, num_items_per_worker_remainder)\n    ]\n\n    # Adjust the last workers to ensure an even distribution\n    for i in range(num_nodes - num_items_per_worker_remainder):\n        user_items_per_worker[i].extend(user_items_per_worker[-1])\n\n    # Return the list of items assigned to each worker\n    return user_items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    if _get_num_nodes() == 1:\n        return [user_items]\n    total_num_workers = num_workers * _get_num_nodes()\n    num_items_per_worker = len(user_items) // total_num_workers\n\n    num_items_per_worker_list = [num_items_per_worker for _ in range(total_num_workers)]\n\n    num_items_per_worker_list[-1] += len(user_items) % total_num_workers\n\n    for i in range(total_num_workers - 2, -1, -1):\n        if num_items_per_worker_list[i] < num_items_per_worker_list[i + 1]:\n            num_items_per_worker_list[i] = num_items_per_worker_list[i + 1]\n        else:\n            break\n\n    if len(num_items_per_worker_list) != _get_num_nodes():\n        raise RuntimeError(\n            f\"The number of workers ({_get_num_nodes()}) is not divisible by the number of items per worker ({len(num_items_per_worker_list)}).\"\n        )\n\n    if len(num_items_per_worker_list) != num_workers:\n        raise RuntimeError(f\"The number of workers ({_get_num_nodes()}) is not equal to the number of items per worker ({len(num_items_per_worker_list)}).\"\n\n    return [user_items[i : i + num_items_per_worker_list[j]] for i, j in zip(range(0, len(user_items)), range(0, num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Get the number of workers\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # 2. Get the number of items\n    num_items = len(user_items)\n\n    # 3. Calculate the number of items per worker\n    num_items_per_worker = num_items // num_workers_total\n\n    # 4. Calculate the remainder\n    remainder = num_items % num_workers_total\n\n    # 5. Create a list of indices for each worker\n    indices_per_worker = [\n        slice(\n            start=i * num_items_per_worker,\n            stop=(i + 1) * num_items_per_worker,\n        )\n        for i in range(num_workers)\n    ]\n\n    # 6. Adjust for the remainder\n    if remainder != 0:\n        indices_per_worker[-1] = slice(indices_per_worker[-1].start, num_items)\n\n    # 7. Create a list of items for each worker\n    items_per_worker = [user_items[i] for i in indices_per_worker]\n\n    # 8. Check if the number of workers is correct\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\n            f\"The number of items ({len(items_per_worker)}) is not equal to the number of workers ({num_workers}).\"\n        )\n\n    # 9. Return the list of items for each worker\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    if not user_items:\n        return []\n\n    # Calculate the number of items per worker\n    num_items_per_worker = int(len(user_items) / num_workers)\n\n    # Calculate the start and end indices for each worker's items\n    starts = [0]\n    for i in range(num_workers - 1):\n        starts.append(starts[i] + num_items_per_worker)\n\n    if len(user_items) % num_workers != 0:\n        for i in range(num_workers - 1, -1, -1):\n            if starts[i] < len(user_items):\n                starts[i] += 1\n                break\n\n    ends = starts.copy()\n    for i in range(num_workers - 1):\n        ends[i + 1] += num_items_per_worker\n\n    # Distribute the items to the workers\n    items_per_worker = []\n    for i in range(num_workers):\n        items = user_items[starts[i] : ends[i]]\n        if len(items) == 0:\n            items = [None]\n\n        items_per_worker.append(items)\n\n    # Return the list of items for each worker\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\"The number of items per worker is not equal to the number of workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    items_per_worker = int(len(user_items) / total_workers)\n\n    # Handle the remainder by adding extra items to the last workers in the list\n    for i in range(total_workers - 1, 0, -1):\n        remainder = len(user_items) - (i * items_per_worker)\n        if remainder > 0:\n            items_per_worker += 1\n            user_items.insert(i, user_items.pop())\n\n    # Calculate the start and end indices for each worker's items\n    workers = []\n    for i in range(total_workers):\n        start = sum(items_per_worker * i for i in range(0, i + 1))\n        end = sum(items_per_worker * (i + 1) for i in range(0, i + 1))\n        workers.append(user_items[start:end])\n\n    # Check that the output list has a length equal to the number of workers\n    if len(workers) != total_workers:\n        raise RuntimeError(f\"The number of workers ({total_workers}) and the number of items ({len(user_items)}) are not consistent.\")\n\n    return workers\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    if _get_num_nodes() > 1:\n        num_items_per_worker = int(len(user_items) / _get_num_nodes())\n        remainder = len(user_items) % _get_num_nodes()\n        items_to_distribute = user_items\n\n        for i in range(remainder):\n            items_to_distribute = items_to_distribute[1:] + items_to_distribute[:1]\n\n        items_per_worker = [\n            items_to_distribute[i : i + num_items_per_worker]\n            for i in range(0, len(items_to_distribute), num_items_per_worker)\n        ]\n\n    else:\n        items_per_worker = [user_items]\n\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(f\"The number of items {len(items_per_worker)} doesn't match the number of workers {num_workers}.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_workers_per_node = num_workers\n    num_nodes = _get_num_nodes()\n    num_workers = num_workers_per_node * num_nodes\n\n    if num_workers == 0:\n        return []\n\n    num_items = len(user_items)\n    num_items_per_worker = num_items // num_workers\n\n    if num_items % num_workers != 0:\n        num_items_per_worker += 1\n\n    if num_workers_per_node != num_workers // num_nodes:\n        raise RuntimeError(\n            f\"The number of workers per node ({num_workers_per_node}) should be divisible by the total number of nodes ({num_nodes}).\"\n        )\n\n    if num_workers != len(user_items) // num_items_per_worker:\n        raise RuntimeError(f\"The number of items ({len(user_items)}) should be divisible by the number of items per worker ({num_items_per_worker}).\")\n\n    # Calculate the start and end indices for each worker's items\n    indices = np.arange(num_items)\n    indices = indices.reshape(num_workers, num_items_per_worker)\n    indices = indices.cumsum(axis=1) - 1\n\n    # Distribute the items\n    worker_items = [user_items[indices[i, j] : indices[i, j + 1] for i in range(num_nodes) for j in range(num_workers_per_node)]\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the number of items each worker should process.\n    num_items_per_worker = len(user_items) // num_workers\n\n    # Distribute the items among the workers.\n    worker_items = []\n    for i in range(num_workers):\n        start = i * num_items_per_worker\n        end = start + num_items_per_worker\n\n        # Adjust for the remainder by adding extra items to the workers starting from the end of the list.\n        if i == num_workers - 1:\n            end += len(user_items) - end\n\n        worker_items.append(user_items[start:end])\n\n    # Ensure that the output list has a length equal to the number of workers.\n    if len(worker_items) != num_workers:\n        raise RuntimeError(f\"The number of workers ({num_workers}) and the number of items ({len(user_items)}) don't match.\")\n\n    # Return the list of lists, where each sublist contains the items assigned to a worker.\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class DataOptimizer:\n    def __init__(\n        self,\n        input_dir: Union[str, Dir],\n        output_dir: Optional[Union[str, Dir]] = None,\n        num_workers: Optional[int] = None,\n        num_downloaders: Optional[int] = None,\n        num_uploaders: Optional[int] = None,\n        delete_cached_files: bool = True,\n        fast_dev_run: Optional[Union[bool, int]] = None,\n        random_seed: Optional[int] = 42,\n        reorder_files: bool = True,\n        weights: Optional[List[int]] = None,\n    ):\n        \"\"\"The `DataOptimizer` provides an efficient way to process data across multiple machine into chunks to make\n        training faster.\n\n        Arguments:\n            input_dir: The path to where the input data are stored.\n            output_dir: The path to where the output data are stored.\n            num_workers: The number of worker threads to use.\n            num_downloaders: The number of file downloaders to use.\n            num_uploaders: The number of file uploaders to use.\n            delete_cached_files: Whether to delete the cached files.\n            fast_dev_run: Whether to run a quick dev run.\n            random_seed: The random seed to be set before shuffling the data.\n            reorder_files: By default, reorders the files by file size to distribute work equally among all workers.\n                Set this to ``False`` if the order in which samples are processed should be preserved.\n            weights: Provide a list of weights associated to the inputs.\n                This is used to evenly split the work among the workers.\n\n        \"\"\"\n        self.input_dir = _resolve_dir(input_dir)\n        self.output_dir = _resolve_dir(output_dir)\n        self.num_workers = num_workers or (1 if fast_dev_run else (os.cpu_count() or 1) * 4)\n        self.num_downloaders = num_downloaders or 2\n        self.num_uploaders = num_uploaders or 5\n        self.delete_cached_files"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "if __name__ == \"__main__\":\n    pass"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_num_nodes() -> int:\n    if _IS_IN_STUDIO:\n        return int(os.environ[\"DATA_OPTIMIZER_NUM_WORKERS\"])\n    return 1\n\n\ndef _get_node_rank() -> int:\n    if _IS_IN_STUDIO:\n        return int(os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"])\n    return 0\n\n\ndef _get_fast_dev_run() -> Optional[Union[int, bool]]:\n    if _IS_IN_STUDIO:\n        return os.environ[\"DATA_OPTIMIZER_FAST_DEV_RUN\"]\n    return None"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class _SignalHandler:\n    def __init__(self) -> None:\n        self.signal_handlers: List[Callable[[Any, Any], None]] = []\n\n    def __call__(self, signal: Any, frame: Any) -> None:\n        for handler in self.signal_handlers:\n            handler(signal, frame)\n        self.signal_handlers = []\n\n    def register(self, handler: Callable[[Any, Any], None]) -> None:\n        self.signal_handlers.append(handler)\n\n\n_signal_handler = _SignalHandler()"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "@dataclass\nclass DataOptimizer:\n    \"\"\"The `DataOptimizer` provides an efficient way to process data across multiple machine into chunks to make\n    training faster.\n\n    Arguments:\n        input_dir: The path to where the input data are stored.\n        output_dir: The path to where the output data are stored.\n        num_workers: The number of worker threads to use.\n        num_downloaders: The number of file downloaders to use.\n        num_uploaders: The number of file uploaders to use.\n        delete_cached_files: Whether to delete the cached files.\n        fast_dev_run: Whether to run a quick dev run.\n        random_seed: The random seed to be set before shuffling the data.\n        reorder_files: By default, reorders the files by file size to distribute work equally among all workers.\n            Set this to ``False`` if the order in which samples are processed should be preserved.\n        weights: Provide a list of weights associated to the inputs.\n            This is used to evenly split the work among the workers.\n        reader: Map the inputs to worker inputs and provides a read method to read a slice of the data.\n\n    \"\"\"\n\n    input_dir: Dir\n    output_dir: Dir\n    num_workers: int\n    num_downloaders: int\n    num_uploaders: int\n    delete_cached_files: bool\n    fast_dev_run: Optional[Union[bool, int]]\n    random_seed: Optional[int]\n    reorder_files: bool\n    weights: Optional[List[int]]\n    reader: Optional[BaseReader]\n\n    def __post_init__(self) -> None:\n        self.input_dir = _resolve_dir(self.input_dir)\n        self.output_dir = _resolve_dir(self.output_dir)\n\n        if self.input_dir:\n            # Ensure the input dir is the same across all nodes\n            self.input_dir = broadcast_object(\"input_dir\", self.input_dir)\n            print(f\"Storing the files under {self.input_dir.path}\")\n\n        if self.output_dir:\n            # Ensure the output dir is the same across all nodes\n            self"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class _SignalHandler:\n    def __init__(self, signal: Any, handler: Callable[[], None]) -> None:\n        self.signal = signal\n        self.handler = handler\n        self.installed = False\n\n    def __enter__(self) -> None:\n        self.installed = signal.signal(self.signal, self.handler)\n\n    def __exit__(self, type, value, traceback) -> None:\n        signal.signal(self.signal, signal.SIG_DFL)\n        self.installed = False"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_cache_dir() -> str:\n    \"\"\"\n    The function returns the cache directory.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: str. The cache directory.\n    \"\"\"\n    return _get_cache_data_dir()\n\n\ndef _get_cache_data_dir() -> str:\n    \"\"\"\n    The function returns the cache directory for data.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: str. The cache directory for data.\n    \"\"\"\n    return os.path.join(\n        _get_data_dir(),\n        \"cache\",\n    )\n\n\ndef _get_data_dir() -> str:\n    \"\"\"\n    The function returns the data directory.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: str. The data directory.\n    \"\"\"\n    return os.path.join(\n        _get_data_dir_root(),\n        \"data\",\n    )\n\n\ndef _get_data_dir_root() -> str:\n    \"\"\"\n    The function returns the data directory root.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: str. The data directory root.\n    \"\"\"\n    return os.path.join(\n        _get_data_dir_root_root(),\n        \"data\",\n    )\n\n\ndef _get_data_dir_root_root() -> str:\n    \"\"\"\n    The function returns the data directory root root.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: str. The data directory root root.\n    \"\"\"\n\n    if _IS_IN_STUDIO:\n        return os.environ[\"STUDIO_DATA_DIR\"]\n    return os.path.join(\n        os."}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_num_nodes() -> int:\n    \"\"\"Returns the number of nodes in the current cluster.\n\n    This function is used to determine how many workers should be created for a given task.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: An int representing the number of nodes in the current cluster.\n    \"\"\"\n    return int(os.environ[\"DATA_OPTIMIZER_NUM_WORKERS\"])\n\n\ndef _get_node_rank() -> int:\n    \"\"\"Returns the rank of the current node in the cluster.\n\n    This function is used to determine which worker should handle a given task.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: An int representing the rank of the current node in the cluster.\n    \"\"\"\n    return int(os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"])\n\n\ndef _get_fast_dev_run() -> Optional[int]:\n    \"\"\"Returns the number of items to process in the fast dev run.\n\n    This function is used to determine how many items to process in the fast dev run.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: An int representing the number of items to process in the fast dev run.\n    \"\"\"\n    return int(os.environ.get(\"DATA_OPTIMIZER_FAST_DEV_RUN\", _DEFAULT_FAST_DEV_RUN_ITEMS))\n\n\ndef _get_cache_dir() -> str:\n    \"\"\"Returns the path to the cache directory.\n\n    This function is used to determine where to store temporary files.\n\n    Input-Output Arguments\n    :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n    :return: A str representing the path to the cache directory.\n    \"\"\"\n    return os.environ.get(\"DATA_OPTIMIZER_CACHE_DIR\", \"/tmp/data_optimizer_cache\")\n\n\ndef _get_cache_data_dir() -> str:\n    \"\"\"Returns the"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class _DataOptimizer:\n    def __init__(\n        self,\n        input_dir: Union[str, Dir],\n        output_dir: Optional[Union[str, Dir]] = None,\n        num_workers: Optional[int] = None,\n        num_downloaders: Optional[int] = None,\n        num_uploaders: Optional[int] = None,\n        delete_cached_files: bool = True,\n        fast_dev_run: Optional[Union[bool, int]] = None,\n        random_seed: Optional[int] = 42,\n        reorder_files: bool = True,\n        weights: Optional[List[int]] = None,\n    ) -> None:\n        self.data_optimizer = DataProcessor(\n            input_dir,\n            output_dir,\n            num_workers=num_workers,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            delete_cached_files=delete_cached_files,\n            fast_dev_run=fast_dev_run,\n            random_seed=random_seed,\n            reorder_files=reorder_files,\n            weights=weights,\n        )\n\n        if fast_dev_run is None:\n            self.data_optimizer.fast_dev_run = _get_fast_dev_run()\n\n    def run(self, data_recipe: DataRecipe) -> None:\n        \"\"\"The `DataOptimizer.run(...)` method triggers the data recipe processing over your dataset.\"\"\"\n        self.data_optimizer.run(data_recipe)\n\n    def _cleanup_cache(self) -> None:\n        self.data_optimizer._cleanup_cache()\n\n\ndef _get_num_nodes() -> int:\n    return int(os.environ[\"DATA_OPTIMIZER_NUM_WORKERS\"])\n\n\ndef _get_node_rank() -> int:\n    return int(os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"])\n\n\ndef _get_cache_dir() -> str:\n    return os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\", \"/tmp/data_optimizer\"), str(_get_node_rank()))\n\n\ndef _get"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_cache_data_dir() -> str:\n    return os.path.join(\n        _get_cache_dir(),\n        \"data_optimizer\",\n    )\n\n\ndef _get_cache_dir() -> str:\n    return os.path.join(\n        _get_temp_dir(),\n        \"data_optimizer\",\n        _get_node_rank(),\n    )\n\n\ndef _get_temp_dir() -> str:\n    return os.path.join(\n        _get_temp_dir_for_current_studio_user(),\n        \"data_optimizer\",\n    )\n\n\ndef _get_temp_dir_for_current_studio_user() -> str:\n    if _IS_IN_STUDIO:\n        return os.path.join(\n            _get_teamspaces_dir(),\n            \"data_optimizer\",\n        )\n    return _get_temp_dir_for_current_user()\n\n\ndef _get_teamspaces_dir() -> str:\n    return os.path.join(\n        _get_teamspaces_dir_for_current_studio_user(),\n        \"data_optimizer\",\n    )\n\n\ndef _get_teamspaces_dir_for_current_studio_user() -> str:\n    if _IS_IN_STUDIO:\n        return os.path.join(\n            _get_teamspace_dir(),\n            \"data_optimizer\",\n        )\n    return _get_teamspaces_dir_for_current_user()\n\n\ndef _get_teamspace_dir() -> str:\n    return os.path.join(\n        _get_teamspace_dir_for_current_studio_user(),\n        \"data_optimizer\",\n    )\n\n\ndef _get_teamspace_dir_for_current_studio_user() -> str:\n    if _IS_IN_STUDIO:\n        return os.path.join(\n            _get_teamspace_dir_for_current_studio_user(),\n            \"data_optimizer\",\n        )\n    return _get_teamspace_dir_for_current_user()\n\n\ndef _get_teamspace_dir_for_current_user() -> str:\n    return os."}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _map_items_to_workers_sequentially(num_workers: int, user_items: List[Any]) -> List[List[Any]]:\n    \"\"\"\n    The function maps items to workers sequentially by splitting the list of items into equal-sized chunks and then mapping each chunk to a worker.\n\n    Input-Output Arguments\n    :param num_workers: int. The number of workers to use.\n    :param user_items: List[Any]. The list of items to be mapped.\n    :return: List[List[Any]]. A list of lists, where each inner list contains the items mapped to a worker.\n\n    \"\"\"\n    return [user_items[i : i + num_workers] for i in range(0, len(user_items), num_workers)]\n\n\ndef _map_items_to_workers_weighted(\n    num_workers: int, user_items: List[Any], weights: Optional[List[int]] = None\n) -> List[List[Any]]:\n    \"\"\"\n    The function maps items to workers based on their weights. It splits the list of items into equal-sized chunks and then maps each chunk to a worker.\n\n    Input-Output Arguments\n    :param num_workers: int. The number of workers to use.\n    :param user_items: List[Any]. The list of items to be mapped.\n    :param weights: Optional[List[int]]. The list of weights associated with each item.\n    :return: List[List[Any]]. A list of lists, where each inner list contains the items mapped to a worker.\n\n    \"\"\"\n    if weights is None:\n        return _map_items_to_workers_sequentially(num_workers, user_items)\n\n    if len(weights) != len(user_items):\n        raise ValueError(\"The provided weights length should match the inputs' length.\")\n\n    weights_sum = sum(weights)\n    if weights_sum == 0:\n        return _map_items_to_workers_sequentially(num_workers, user_items)\n\n    chunk_size = int(weights_sum / num_workers)\n    chunks_size = [chunk_size]\n    for i in range(num_workers - 1):\n        chunks"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _download_data_target(input_dir: Dir, cache_dir: str, to_download_queue: Queue, ready_to_process_queue: Queue) -> None:\n    \"\"\"The `_download_data_target` method is a target function for the downloaders.\n\n    It is responsible to download the files and put them into the `ready_to_process_queue`.\n\n    Arguments:\n        input_dir: The path to the input directory.\n        cache_dir: The path to the cache directory.\n        to_download_queue: The queue to get the files to download.\n        ready_to_process_queue: The queue to put the files ready to process.\n\n    Returns:\n        None.\n    \"\"\"\n    while True:\n        try:\n            index, paths = to_download_queue.get(timeout=0.001)\n        except Empty:\n            break\n        for path in paths:\n            if not os.path.exists(path):\n                _download_file(path, input_dir.path)\n\n        ready_to_process_queue.put(index)\n\n\ndef _upload_fn(to_upload_queue: Queue, remove_queue: Queue, cache_dir: str, output_dir: Dir) -> None:\n    \"\"\"The `_upload_fn` method is a target function for the uploaders.\n\n    It is responsible to upload the files.\n\n    Arguments:\n        to_upload_queue: The queue to get the files to upload.\n        remove_queue: The queue to get the files to remove.\n        cache_dir: The path to the cache directory.\n        output_dir: The path to the output directory.\n\n    Returns:\n        None.\n    \"\"\"\n    while True:\n        try:\n            data = to_upload_queue.get(timeout=0.001)\n        except Empty:\n            break\n        if data is None:\n            break\n        if isinstance(data, str):\n            _upload_file(data, output_dir.path if output_dir.path else output_dir.url)\n        else:\n            _upload_file(data[-1], output_dir.path if output_dir.path"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class _StreamingDataLoaderReader:\n    def __init__(self, loader: StreamingDataLoader):\n        self.loader = loader\n        self.items = []\n\n    def remap_items(self, items: List[Any], num_workers: int) -> List[List[Any]]:\n        \"\"\"\n        The function remap_items() is used to map the items from the StreamingDataLoader to the workers. It takes in the items from the StreamingDataLoader and the number of workers, and returns a list of lists containing the items that will be processed by each worker.\n\n        Input-Output Arguments\n        :param items: List[Any]. The items from the StreamingDataLoader.\n        :param num_workers: int. The number of workers that will be used to process the items.\n        :return: List[List[Any]]. A list of lists containing the items that will be processed by each worker.\n        \"\"\"\n        for item in items:\n            self.items.append(item)\n\n        items_per_worker = int(math.ceil(len(self.items) / num_workers))\n        items_per_worker_list = [[] for _ in range(num_workers)]\n\n        for i, item in enumerate(self.items):\n            items_per_worker_list[i % num_workers].append(item)\n\n        return items_per_worker_list\n\n    def read(self, item: Any) -> Any:\n        \"\"\"\n        The function read() is used to read the items from the StreamingDataLoader. It takes in an item from the StreamingDataLoader and returns it.\n\n        Input-Output Arguments\n        :param item: Any. The item from the StreamingDataLoader.\n        :return: Any. The item from the StreamingDataLoader.\n        \"\"\"\n        return next(self.loader)\n\n\ndef _map_items_to_workers_weighted(\n    num_workers: int,\n    user_items: List[Any],\n    weights: List[int],\n    file_size: bool = False,\n) -> List[List[Any]]:\n    \"\"\"\n    The function _map_items_to_workers_weighted() is used to map the items from the user items to the workers. It takes in the number of workers, the user items, and the"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class _DownloadDataTarget(BaseProcess):\n    \"\"\"The _DownloadDataTarget is responsible to download the data from the input_dir to the cache_dir.\"\"\"\n\n    def __init__(\n        self,\n        input_dir: Optional[str],\n        cache_dir: str,\n        to_download_queue: Queue,\n        ready_to_process_queue: Queue,\n    ):\n        super().__init__()\n        self.input_dir = input_dir\n        self.cache_dir = cache_dir\n        self.to_download_queue = to_download_queue\n        self.ready_to_process_queue = ready_to_process_queue\n        self.num_downloaders = 0\n        self.num_workers = 0\n\n    def run(self) -> None:\n        self.num_downloaders = _get_num_nodes()\n        self.num_workers = _get_num_nodes()\n\n        while True:\n            index, files = self.to_download_queue.get(timeout=0.001)\n\n            if index is None:\n                break\n\n            for file in files:\n                if self.input_dir is None:\n                    continue\n                if not os.path.exists(file):\n                    print(f\"Downloading {file}.\")\n                    download_file(file, self.input_dir)\n                else:\n                    print(f\"Found {file} in the input_dir.\")\n\n            self.ready_to_process_queue.put(index)\n\n        print(\"Downloaders are finished.\")\n\n\ndef _download_data_target(\n    input_dir: Optional[str],\n    cache_dir: str,\n    to_download_queue: Queue,\n    ready_to_process_queue: Queue,\n) -> None:\n    \"\"\"The _download_data_target is responsible to download the data from the input_dir to the cache_dir.\"\"\"\n    _DownloadDataTarget(input_dir, cache_dir, to_download_queue, ready_to_process_queue).run()\n    print(\"Downloaders are finished.\")\n\n\nclass _RemoveTarget(BaseProcess):\n    \"\"\"The _RemoveTarget is responsible to remove the files in the input"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_num_nodes() -> int:\n    return _get_node_rank() + 1\n\n\ndef _get_node_rank() -> int:\n    return int(os.environ.get(\"DATA_OPTIMIZER_GLOBAL_RANK\", 0))\n\n\ndef _get_num_workers() -> int:\n    return int(os.environ.get(\"DATA_OPTIMIZER_NUM_WORKERS\", 1))\n\n\ndef _get_fast_dev_run() -> Optional[Union[int, bool]]:\n    return os.environ.get(\"DATA_OPTIMIZER_FAST_DEV_RUN\")\n\n\ndef _get_cache_dir() -> str:\n    return _get_cache_data_dir()\n\n\ndef _get_cache_data_dir() -> str:\n    return os.environ.get(\"DATA_OPTIMIZER_CACHE_DIR\", \"/tmp/data_optimizer_cache\")\n\n\ndef _get_cache_dir_path(cache_dir: str) -> str:\n    return os.path.join(cache_dir, \"chunks\")\n\n\ndef _get_cache_data_dir_path(cache_data_dir: str) -> str:\n    return os.path.join(cache_data_dir, \"chunks\")\n\n\ndef _get_src_resolver(src: str, cache_dir: str) -> Optional[Callable]:\n    if not _IS_IN_STUDIO:\n        return None\n    if src.startswith(\"s3://\"):\n        return _resolve_s3_src\n    if src.startswith(\"http://\") or src.startswith(\"https://\"):\n        return _resolve_http_src\n    if src.startswith(\"/teamspace/studios/this_studio\"):\n        return _resolve_studio_src\n    if src.startswith(\"/teamspace/studios/other_studio\"):\n        return _resolve_other_studio_src\n\n    return None\n\n\ndef _resolve_s3_src(src: str) -> str:\n    return src.replace(\"s3://\", \"s3://\")\n\n\ndef _resolve_http_src(src: str) -> str:\n    return src.replace(\"http://\", \"s3://\")\n\n\ndef _resolve_studio_src(src: str) ->"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_num_nodes() -> int:\n    \"\"\"\n    Returns the number of nodes.\n\n    Input-Output Arguments\n    :return: An integer representing the number of nodes.\n    \"\"\"\n    return int(os.environ.get(\"DATA_OPTIMIZER_NUM_NODES\", 1))\n\n\ndef _get_node_rank() -> int:\n    \"\"\"\n    Returns the node rank.\n\n    Input-Output Arguments\n    :return: An integer representing the node rank.\n    \"\"\"\n    return int(os.environ.get(\"DATA_OPTIMIZER_GLOBAL_RANK\", 0))\n\n\ndef _get_cache_dir() -> str:\n    \"\"\"\n    Returns the cache directory.\n\n    Input-Output Arguments\n    :return: A string representing the cache directory.\n    \"\"\"\n    return os.path. mozaic_cache_dir()\n\n\ndef _get_cache_data_dir() -> str:\n    \"\"\"\n    Returns the cache data directory.\n\n    Input-Output Arguments\n    :return: A string representing the cache data directory.\n    \"\"\"\n    return os.path.join(_get_cache_dir(), \"data\")\n\n\ndef _get_fast_dev_run() -> Optional[Union[int, bool]]:\n    \"\"\"\n    Returns the fast dev run.\n\n    Input-Output Arguments\n    :return: A boolean representing the fast dev run.\n    \"\"\"\n    return os.environ.get(\"DATA_OPTIMIZER_FAST_DEV_RUN\", _DEFAULT_FAST_DEV_RUN)\n\n\ndef _download_data_target(\n    input_dir: str,\n    cache_dir: str,\n    to_download_queue: Queue,\n    ready_to_process_queue: Queue,\n) -> None:\n    \"\"\"\n    Downloads the data from the remote server to the local cache directory.\n\n    Input-Output Arguments\n    :param input_dir: The input directory from which the data is being downloaded.\n    :param cache_dir: The local cache directory where the downloaded data is stored.\n    :param to_download_queue: A queue that contains the list of files that need to be downloaded.\n    :param ready_to_process_queue: A queue that signals when the data is ready to be processed"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _map_items_to_workers_sequentially(\n    num_workers: int, user_items: List[Any], file_size: bool = False\n) -> List[List[Any]]:\n    \"\"\"This method maps the user items to the workers by creating a list of lists where each list contains the items\n    assigned to a particular worker. The items are assigned to the workers in a sequential manner.\n\n    Input-Output Arguments\n    :param num_workers: An int that specifies the number of workers.\n    :param user_items: A list of items that need to be processed by the workers.\n    :param file_size: A boolean value that specifies whether the items should be mapped based on their file size or not.\n    :return: A list of lists where each list contains the items assigned to a particular worker.\n    \"\"\"\n    num_items = len(user_items)\n    num_per_worker = num_items // num_workers\n    workers_user_items fundament_list = [user_items[i : i + num_per_worker] for i in range(0, num_items, num_per_worker)]\n\n    if num_items % num_workers != 0:\n        workers_user_items fundament_list.append(user_items[num_per_worker * num_workers :])\n\n    if file_size:\n        item_sizes = _get_item_filesizes(user_items)\n    else:\n        item_sizes = [1] * len(user_items)\n\n    workers_user_items = _map_items_to_workers_weighted(num_workers, users_items=workers_user_items, weights=item_sizes)\n\n    return workers_user_items\n\n\ndef _map_items_to_workers_weighted(num_workers: int, user_items: List[Any], weights: List[int]) -> List[List[Any]]:\n    \"\"\"This method maps the user items to the workers by creating a list of lists where each list contains the items\n    assigned to a particular worker. The items are assigned to the workers based on their weights.\n\n    Input-Output Arguments\n    :param num_workers: An int that specifies the number of workers.\n    :param"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_num_nodes() -> int:\n    return int(os.environ[\"DATA_OPTIMIZER_NUM_NODES\"])\n\n\ndef _get_node_rank() -> int:\n    return int(os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"])\n\n\ndef _get_fast_dev_run() -> Optional[Union[int, bool]]:\n    return os.environ.get(\"DATA_OPTIMIZER_FAST_DEV_RUN\")\n\n\ndef _map_items_to_workers_sequentially(\n    num_workers: int, user_items: List[Any]\n) -> List[List[Any]]:\n    return [user_items[i * num_workers // len(user_items) : (i + 1) * num_workers // len(user_items)] for i in range(num_workers)]\n\n\ndef _map_items_to_workers_weighted(\n    num_workers: int, user_items: List[Any], weights: Optional[List[int]] = None, file_size: bool = True\n) -> List[List[Any]]:\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    if len(weights) != len(user_items):\n        raise ValueError(\"The provided weights length should match the inputs' length.\")\n\n    # Sort the items by their size\n    # TODO: Do this only on node 0.\n    if file_size:\n        item_sizes = [sum([_to_bytes(item) for item in items]) for items in user_items]\n    else:\n        item_sizes = [1] * len(user_items)\n    item_sizes_indices = np.argsort(np.array(item_sizes))\n    user_items = [user_items[i] for i in item_sizes_indices]\n    weights = [weights[i] for i in item_sizes_indices]\n\n    # Sort the weights by their size\n    weights_sizes_indices = np.argsort(np.array(weights))\n    weights = [weights[i] for i in weights_sizes_indices]\n\n    # Sort the items by their weight\n    user_items_weights_indices = np.argsort"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "class _Item:\n    def __init__(self, item: Any, item_metadata: Any) -> None:\n        self.item = item\n        self.item_metadata = item_metadata\n\n\ndef _map_items_to_workers_weighted(num_workers: int, user_items: List[Any], weights: List[int]) -> List[List[_Item]]:\n    \"\"\"The `_map_items_to_workers_weighted` method maps the input items to the workers based on the weights provided.\n    The weights are used to evenly split the work among the workers.\n\n    Arguments:\n        num_workers: The number of worker threads to use.\n        user_items: The list of items to process.\n        weights: A list of weights associated to the inputs.\n\n    Returns:\n        A list of items mapped to the workers.\n\n    \"\"\"\n    num_items = len(user_items)\n\n    if num_workers == 1:\n        return [[_Item(item, item_metadata)] for item, item_metadata in zip(user_items, weights)]\n\n    # Ensure the weights are all positive\n    weights = [w if w > 0 else 1 for w in weights]\n    total_weight = sum(weights)\n\n    # Ensure the weights are all positive\n    if total_weight == 0:\n        weights = [1] * len(user_items)\n\n    # Ensure the weights are all positive\n    weights = [w / total_weight for w in weights]\n\n    # Ensure the weights are all positive\n    weights = [w if w > 0 else 1 for w in weights]\n\n    # Ensure the weights are all positive\n    weights = [w / sum(weights) for w in weights]\n\n    # Ensure the weights are all positive\n    weights = [w if w > 0 else 1 for w in weights]\n\n    # Ensure the weights are all positive\n    weights = [w / sum(weights) for w in weights]\n\n    # Ensure the weights are all positive\n    weights = [w if w > 0 else 1 for w in weights]\n\n    # Ensure the weights are all positive\n    weights = [w / sum(weights) for w in weights]\n\n    # Ensure the"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "def _get_fast_dev_run() -> Optional[Union[int, bool]]:\n    \"\"\"\n    This function returns the value of the fast_dev_run variable.\n    It is used to determine whether to run a quick dev run or not.\n    \"\"\"\n    if _IS_IN_STUDIO:\n        return os.getenv(\"FAST_DEV_RUN\")\n    return False\n\n\ndef _get_num_nodes() -> int:\n    \"\"\"This function returns the number of nodes.\n    It is used to determine the number of nodes running the code.\n    \"\"\"\n    return int(os.getenv(\"DATA_OPTIMIZER_NUM_WORKERS\", \"1\"))\n\n\ndef _get_node_rank() -> int:\n    \"\"\"This function returns the node rank.\n    It is used to determine the node rank of the process.\n    \"\"\"\n    return int(os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\", \"0\"))\n\n\ndef _get_cache_dir() -> str:\n    \"\"\"This function returns the cache directory.\n    It is used to store temporary files during the data processing.\n    \"\"\"\n    return os.path.join(os.environ[\"DATA_OPTIMIZER_CACHE_DIR\"], \"data_optimizer\")\n\n\ndef _get_cache_data_dir() -> str:\n    \"\"\"This function returns the cache data directory.\n    It is used to store the data chunks.\n    \"\"\"\n    return os.path.join(os.environ[\"DATA_OPTIMIZER_CACHE_DIR\"], \"data_chunks\")\n\n\ndef _get_cache_dir_for_path(path: str) -> str:\n    \"\"\"This function returns the cache directory for a given path.\n    It is used to store temporary files during the data processing.\n    \"\"\"\n    return os.path.join(os.environ[\"DATA_OPTIMIZER_CACHE_DIR\"], os.path.basename(path))\n\n\ndef _get_cache_chunks_dir() -> str:\n    \"\"\"This function returns the cache chunks directory.\n    It is used to store the data chunks.\n    \"\"\"\n    return os.path.join(os.environ[\"DATA_OPTIMIZER_CACHE_DIR\"], \"data_chunks\")\n\n\ndef _get_remote_dir(dir: str"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(f\"Error computing file size for item {item} ({e})\")\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            raise RuntimeError(f\"Error while computing the file size for the item {items.index(item)}: {e}\")\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            logger.error(f\"Could not compute file size of {future.args[0]}\")\n            logger.error(e)\n            item_sizes.append(0)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception:\n            raise\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for i, future in enumerate(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n            item_sizes.append(0)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) if input_dir is None else element.startswith(input_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return Path(element).exists() or (input_dir is not None and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if os.path.exists(element):\n        return True\n\n    if input_dir is not None:\n        return os.path.exists(os.path.join(input_dir, element))\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return Path(element).exists()\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) if input_dir is None else element.startswith(input_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or (input_dir and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.isfile(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return Path(element).is_absolute() or (input_dir and Path(element).is_absolute() and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return Path(element).exists() or (input_dir is not None and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) if input_dir is None else os.path.exists(os.path.join(input_dir, element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return element.lstrip(\"/\") in os.listdir(os.path.dirname(element)) if os.path.dirname(element) != \"\" else os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or (input_dir is not None and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or (input_dir is not None and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or (input_dir is not None and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.isfile(_to_path(element)) or (input_dir and os.path.isdir(_to_path(element)))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or (input_dir is not None and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element))\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        # Create the network\n        if self.tcnn:\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons, activation=activation),\n                nn.Linear(n_neurons, n_output_dims, activation=output_activation),\n            )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                    nn.ReLU(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers):\n                if i == n_layers - 1:\n                    layers.append(nn.Linear(n_neurons, n_output_dims))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_layers == 1:\n                return tinycudann.Linear(n_input_dims, n_output_dims)\n            elif n_layers == 2:\n                return tinycudann.Sequential(\n                    tinycudann.Linear(n_input_dims, n_neurons),\n                    tinycudann.ReLU(),\n                    tinycudann.Linear(n_neurons, n_output_dims),\n                )\n            elif n_layers == 3:\n                return tinycudann.Sequential(\n                    tinycudann.Linear(n_input_dims, n_neurons),\n                    tinycudann.ReLU(),\n                    tinycudann.Linear(n_neurons, n_neurons),\n                    tinycudann.ReLU(),\n                    tinycudann.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            elif n_layers == 2:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n            elif n_layers == 3:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n        return None"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import Network\n            from tinycudann.layers.linear import Linear\n\n            layers = []\n            for i in range(n_layers):\n                if i == n_layers - 1:\n                    layers.append(\n                        Linear(n_input_dims, n_output_dims, activation=output_activation)\n                    )\n                else:\n                    layers.append(Linear(n_input_dims, n_neurons, activation=activation))\n                    n_input_dims = n_neurons\n\n            return Network(layers)\n        else:\n            return nn.Sequential(\n                *[\n                    nn.Linear(n_input_dims, n_neurons, activation=activation)\n                    for i in range(n_layers - 1)\n                ],\n                nn.Linear(n_input_dims, n_output_dims, activation=output_activation),\n            )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            return self.get_tcnn_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n        else:\n            return self.get_torch_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import NeuralNetwork\n\n            if n_layers == 1:\n                return NeuralNetwork(n_input_dims, n_output_dims, n_neurons, activation)\n            else:\n                return NeuralNetwork(\n                    n_input_dims, n_output_dims, n_layers, n_neurons, activation\n                )\n\n        else:\n            # PyTorch\n            if n_layers == 1:\n                return nn.Sequential(nn.Linear(n_input_dims, n_output_dims))\n            else:\n                return nn.Sequential(\n                    *[\n                        nn.Linear(n_input_dims, n_neurons),\n                        getattr(nn, activation)(inplace=True),\n                    ]\n                    + [nn.Linear(n_neurons, n_output_dims)]\n                    + [getattr(nn, output_activation)(inplace=True)]\n                )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            from tinycudann import nn\n\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims, activation=activation)\n            else:\n                # TODO: Implement this\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons, activation=activation),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims, activation=output_activation),\n                )\n        else:\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons, bias=True, relu=activation == \"ReLU\"),\n                nn.ReLU(),\n                nn.Linear(n_neurons, n_output_dims, bias=True, relu=output_activation == \"ReLU\"),\n            )\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import nn\n\n            if n_layers == 1:\n                return nn.Linear(\n                    n_input_dims,\n                    n_output_dims,\n                    activation=nn.Activation(activation),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(\n                        n_input_dims,\n                        n_neurons,\n                        activation=nn.Activation(activation),\n                    )\n                    + nn.Linear(\n                        n_neurons,\n                        n_output_dims,\n                        activation=nn.Activation(output_activation),\n                    )\n                )\n        else:\n            return self.get_pytorch_network(\n                n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation\n            )\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            from tinycudann import nn\n            from tinycudann.layers import Linear, ReLU\n\n            layers = [Linear(n_input_dims, n_neurons)]\n            for i in range(n_layers - 1):\n                layers.append(ReLU())\n            layers.append(Linear(n_neurons, n_output_dims))\n\n            return nn.Sequential(*layers)\n        else:\n            from torch import nn, relu\n\n            layers = []\n            for i in range(n_layers):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n\n                if i < n_layers - 1:\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n                    elif activation == \"Sigmoid\":\n                        layers.append(nn.Sigmoid())\n\n                n_input_dims = n_neurons\n                n_neurons = n_output_dims\n\n            if output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if not self.tcnn:\n            return nn.Sequential(\n                nn.Linear(in_features=n_input_dims, out_features=n_neurons),\n                nn.ReLU(),\n                nn.Linear(n_neurons, n_output_dims),\n                nn.ReLU(),\n            )\n        else:\n            return self._create_network(\n                n_input_dims, n_neurons, n_layers, activation, output_activation\n            )\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        # TODO: Add assertions for n_layers and n_neurons\n        # assert n_layers > 0, \"n_layers must be greater than 0\"\n        # assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            from tinycudann import nn\n\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                *[\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity()\n                    for _ in range(n_layers - 1)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n                nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity(),\n            )\n        else:\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                *[\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity()\n                    for _ in range(n_layers - 1)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n                *[\n                    nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity()\n                    for _ in range(n_layers - 1)\n                ],\n            )\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n        if self.tcnn:\n            from tinycudann import ANN\n            if n_layers == 1:\n                return ANN(\n                    n_inputs=n_input_dims,\n                    n_outputs=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            else:\n                return ANN(\n                    n_inputs=n_input_dims,\n                    n_outputs=n_output_dims,\n                    n_hidden=n_layers - 1,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n        else:\n            return self.get_pytorch_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            from tinycudann import NeuralNetwork\n\n            # Create a neural network with the specified parameters.\n            n = NeuralNetwork(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n        else:\n            # Create a neural network with the specified parameters using PyTorch.\n            n = nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU(),\n            )\n            for _ in range(n_layers - 2):\n                n.add_module(\n                    \"Layer\", nn.Linear(n_neurons, n_neurons),\n                )\n                n.add_module(\n                    \"ReLU\", nn.ReLU()\n                )\n            n.add_module(\"Output\", nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"Sigmoid\":\n                n.add_module(\"OutputSigmoid\", nn.Sigmoid())\n            elif output_activation == \"ReLU\":\n                n.add_module(\"OutputReLU\", nn.ReLU())\n        return n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            elif n_neurons == n_output_dims:\n                return nn.Sequential(nn.Linear(n_input_dims, n_neurons))\n            else:\n                return nn.Sequential(nn.Linear(n_input_dims, n_neurons), nn.ReLU())\n        else:\n            layers = []\n\n            if n_layers == 1:\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n            elif n_neurons == n_output_dims:\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n            else:\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n\n                if n_layers > 1:\n                    layers.append(nn.Linear(n_neurons, n_output_dims))\n\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n\n            return nn.Sequential(*layers)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann\n\n            if n_layers == 1:\n                return tinycudann.Network(n_input_dims, n_output_dims, activation)\n            else:\n                layers = [\n                    tinycudann.Dense(n_input_dims, n_neurons, activation)\n                    for _ in range(n_layers - 1)\n                ]\n                return tinycudann.Network(\n                    layers=layers,\n                    output_layer=tinycudann.Dense(n_neurons, n_output_dims, output_activation),\n                )\n\n        else:\n            import torch\n\n            if n_layers == 1:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_output_dims),\n                )\n            else:\n                layers = [\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    getattr(nn, activation.upper())(),\n                ]\n                for _ in range(n_layers - 1):\n                    layers.append(torch.nn.Linear(n_neurons, n_neurons))\n                    layers.append(getattr(nn, activation.upper())())\n                layers.append(torch.nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                return torch.nn.Sequential(*layers)\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            from tinycudann import nn\n        else:\n            import torch\n            nn = torch.nn\n\n        if n_layers < 1:\n            raise ValueError(f\"n_layers must be greater than 0, got {n_layers}.\")\n        if n_neurons < 1:\n            raise ValueError(f\"n_neurons must be greater than 0, got {n_neurons}.\")\n\n        if activation == \"None\":\n            activation = None\n        elif activation == \"ReLU\":\n            activation = nn.ReLU()\n        else:\n            raise ValueError(f\"Unknown activation function {activation}.\")\n\n        if output_activation == \"None\":\n            output_activation = None\n        elif output_activation == \"ReLU\":\n            output_activation = nn.ReLU()\n        elif output_activation == \"Sigmoid\":\n            output_activation = nn.Sigmoid()\n        else:\n            raise ValueError(f\"Unknown output activation function {output_activation}.\")\n\n        if self.tcnn:\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            if n_layers == 2:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    activation,\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    activation,\n                    nn.Linear(n_neurons, n_neurons),\n                    activation,\n                    nn.Linear(n_neurons, n_output_dims),\n                    output_activation,\n                )\n        else:\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                activation,\n                nn.Linear(n_neurons, n_neurons),\n                activation,\n                nn.Linear(n_neurons, n_output_dims),\n                output_activation,\n            )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            from tinycudann.nn import relu, sigmoid, relu_derivative, sigmoid_derivative\n\n            if n_layers == 1:\n                activation = relu\n            elif n_layers == 2:\n                activation = relu_derivative\n            elif n_layers == 3:\n                activation = sigmoid\n            elif n_layers == 4:\n                activation = sigmoid_derivative\n            else:\n                raise Exception(\n                    \"NetworkFactory.get_network: The number of layers must be between 1 and 4.\"\n                )\n\n            return nn.Network(\n                input_dims=n_input_dims,\n                output_dims=n_output_dims,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(\n                    nn.Linear(n_neurons, n_neurons, activation=activation)\n                )\n\n            return nn.Sequential(nn.Linear(n_input_dims, n_neurons), *layers, nn.Linear(n_neurons, n_output_dims, activation=output_activation))"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"The number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"The number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import relu, sigmoid, tanh, relu_derivative, sigmoid_derivative, tanh_derivative\n            from tinycudann import Sequential\n\n            if activation == \"ReLU\":\n                activation_function = relu\n            elif activation == \"Sigmoid\":\n                activation_function = sigmoid\n            elif activation == \"None\":\n                activation_function = None\n\n            if output_activation == \"ReLU\":\n                output_activation_function = relu\n            elif output_activation == \"Sigmoid\":\n                output_activation_function = sigmoid\n            elif output_activation == \"None\":\n                output_activation_function = None\n\n            network = Sequential(\n                n_input_dims,\n                n_layers,\n                n_neurons,\n                activation_function,\n                output_activation_function,\n                n_output_dims,\n                relu_derivative,\n                sigmoid_derivative,\n                tanh_derivative,\n            )\n        else:\n            from torch.nn import ReLU, Sigmoid, SigmoidD, ReLU_D\n\n            activation_function = ReLU if activation == \"ReLU\" else Sigmoid\n            output_activation_function = ReLU_D if activation == \"ReLU\" else SigmoidD\n\n            network = nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                activation_function(),\n            )\n\n            for _ in range(n_layers - 2):\n                network.add_module(\n                    \"Layer\", nn.Linear(n_neurons, n_neurons)\n                )\n                network.add_module(\n                    \"Activation\", activation_function()\n                )\n\n            network.add_module(\n                \"Output\", nn.Linear(n_neurons, n_output_dims)\n            )\n            if output_activation == \"None\":\n                pass\n            else:\n                network.add_module(\n                    \"OutputActivation\", output_activation_function()\n                )\n\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        # Create the network\n        if self.tcnn:\n            from tinycudann.network import TinyCudann\n            network = TinyCudann(n_input_dims=n_input_dims, n_output_dims=n_output_dims, seed=self._get_seed())\n        else:\n            from torch.nn import Sequential\n            network = Sequential()\n        # Add the input layer\n            network.add_module(\n                \"input\",\n                nn.Linear(n_input_dims, n_neurons),\n            )\n        # Add the hidden layers\n            for i in range(n_layers - 1):\n                network.add_module(\n                    \"hidden\" + str(i + 1),\n                    nn.Linear(n_neurons, n_neurons),\n                )\n        # Add the output layer\n            network.add_module(\n                \"output\",\n                nn.Linear(n_neurons, n_output_dims),\n            )\n\n            if output_activation == \"ReLU\":\n                network.add_module(\"relu\", nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                network.add_module(\"sigmoid\", nn.Sigmoid())\n\n            if activation == \"ReLU\":\n                for i in range(n_layers - 1):\n                    network.add_module(\n                        \"relu\" + str(i + 1), nn.ReLU()\n                    )\n            elif activation == \"None\":\n                pass\n            else:\n                raise ValueError(\n                    \"The activation function must be either 'ReLU' or 'None'.\"\n                )\n\n        # Return the network\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import nn as tcn\n\n            if n_layers == 1:\n                return tcn.Linear(n_input_dims, n_output_dims)\n\n            if n_neurons == 1:\n                return tcn.Linear(n_input_dims, n_output_dims)\n\n            # TODO: Add other types of tinycudann networks here\n\n            if n_layers > 1:\n                if activation == \"None\":\n                    act_func = tcn.NoOp\n                elif activation == \"ReLU\":\n                    act_func = tcn.ReLU\n                else:\n                    raise ValueError(\n                        f\"Unknown activation function: {activation}\"\n                    )\n\n                if output_activation == \"None\":\n                    out_act_func = tcn.NoOp\n                elif output_activation == \"Sigmoid\":\n                    out_act_func = tcn.Sigmoid\n                elif output_activation == \"ReLU\":\n                    out_act_func = tcn.ReLU\n                else:\n                    raise ValueError(\n                        f\"Unknown output activation function: {output_activation}\"\n                    )\n\n                return tcn.Sequential(\n                    tcn.Linear(n_input_dims, n_neurons),\n                    tcn.Linear(n_neurons, n_output_dims, activation=out_act_func),\n                    act_func,\n                    tcn.Linear(n_neurons, n_output_dims),\n                    tcn.Linear(n_output_dims, n_neurons),\n                    tcn.Linear(n_neurons, n_output_dims, activation=out_act_func),\n                )\n\n            else:\n                raise ValueError(\"n_layers must be greater than 1.\")\n\n        else:\n            from torch import nn as nn\n            import torch\n\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n\n            if n_neurons == 1:\n                return nn.Linear(n"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median\n        rolling_median = np.median(np.vstack([signal[kernel_offset:-kernel_offset], signal, signal[:kernel_offset + 1]]), axis=0)\n        # Trim the rolling median to remove edge effects\n        trimmed_median = rolling_median[kernel_offset:-kernel_offset]\n        return trimmed_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the median of the shifted signal\n        median_signal = np.median(signal[kernel_offset:-kernel_offset], axis=0)\n\n        # Trim the median signal to remove edge effects\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n        kernel_length = 2 * kernel_offset + 1\n        signal_padded = np.pad(signal, (kernel_offset, kernel_offset), mode=\"reflect\")\n        median_signal = np.zeros(signal_length)\n\n        for i in range(signal_length):\n            median_signal[i] = np.median(signal_padded[i : i + kernel_length])\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median\n        signal_shifted = np.roll(signal, range(-kernel_offset, kernel_offset + 1))\n        signal_median = np.median(signal_shifted, axis=1)\n\n        # Trim the rolling median array to remove edge effects\n        trimmed_signal = signal_median[kernel_offset:-kernel_offset]\n\n        return trimmed_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create the shifted versions of the input signal.\n        signal_left = np.roll(signal, -kernel_offset)\n        signal_right = np.roll(signal, kernel_offset)\n\n        # Calculate the rolling median.\n        signal_median = np.median(np.vstack((signal_left, signal, signal_right)), axis=0)\n\n        # Trim the array to remove edge effects.\n        return signal_median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median.\n        signal_padded = np.pad(signal, kernel_offset, 'wrap')\n        rolling_median = np.median(signal_padded, axis=0)\n\n        # Trim the edges of the rolling median to remove edge effects.\n        rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate all shifted versions of the input signal\n        signal_shifted = np.roll(signal, np.arange(-kernel_offset, kernel_offset + 1))\n\n        # Calculate the rolling median\n        rolling_median = np.median(signal_shifted, axis=0)\n\n        # Trim the rolling median array to remove edge effects\n        rolling_median = rolling_median[kernel_offset: -kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        if kernel_offset > 0:\n            signal_shifted = np.concatenate((signal[kernel_offset - 1:], signal, signal[:kernel_offset - 1]))\n        else:\n            signal_shifted = np.concatenate((signal[-kernel_offset:], signal, signal[:kernel_offset]))\n            signal_shifted = np.flip(signal_shifted)\n\n        rolling_median = np.median(signal_shifted, axis=0)\n\n        return rolling_median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Trim the signal to remove edge effects introduced by the rolling median\n        if kernel_offset > 0:\n            signal = signal[kernel_offset:-kernel_offset]\n\n        # Shift the signal in both directions by the kernel offset\n        signal_shifted = np.concatenate(\n            [np.roll(signal, -kernel_offset), signal, np.roll(signal, kernel_offset)]\n        )\n\n        # Compute the median of the shifted signals\n        signal_median = np.median(signal_shifted, axis=0)\n        return signal_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        if len(signal) < 2 * kernel_offset:\n            raise GeometryRefinementError(\"Rolling median kernel is too large for the input signal.\")\n\n        signal_padded = np.concatenate((np.roll(signal, -kernel_offset), signal, np.roll(signal, kernel_offset)))\n        median_signal = np.median(signal_padded, axis=0)\n\n        if kernel_offset == 1:\n            return median_signal\n\n        signal_trimmed = median_signal[kernel_offset: -kernel_offset]\n        return signal_trimmed"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        if kernel_offset < 1:\n            raise ValueError(\"The kernel offset must be at least 1\")\n        signal = np.asarray(signal, dtype=np.float64)\n\n        # Compute the rolling median\n        median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median[i - kernel_offset] = np.median(signal[i - kernel_offset:i + kernel_offset + 1])\n\n        # Trim the edges\n        return np.concatenate([median[kernel_offset - 1], median[kernel_offset:]])"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a copy of the input signal, which will be shifted by the kernel offset.\n        shifted_signal = np.copy(signal)\n\n        # Shift the input signal by the kernel offset, and fill the edges with the first and last elements of the signal.\n        shifted_signal = np.roll(shifted_signal, kernel_offset)\n        shifted_signal[0:kernel_offset] = signal[0]\n        shifted_signal[-kernel_offset:] = signal[-1]\n\n        # Calculate the median of the shifted signal\n        rolling_median = np.median(shifted_signal)\n\n        # Trim the rolling median array to remove the edge effects introduced by the shifting process.\n        rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # if the kernel offset is less than 1, the signal is not shifted\n        if kernel_offset < 1:\n            return np.median(signal)\n\n        # the kernel size is the number of shifts applied to the signal\n        kernel_size = 2 * kernel_offset + 1\n\n        # the signal is shifted in both directions by the kernel offset\n        shifted_signal = np.roll(signal, -kernel_offset)\n\n        # the median of the shifted signals is calculated\n        rolling_median = np.median(shifted_signal, axis=0)\n        # the median array is trimmed to remove the edge effects introduced by the shifting process\n        trimmed_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return trimmed_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # The kernel_size is defined in the parameters class.\n        kernel_size = 2 * kernel_offset + 1\n\n        # The kernel_offset is defined in the parameters class.\n        # The kernel_size is defined in the parameters class.\n        # We need to trim the array to remove edge effects.\n        return np.median(np.concatenate([signal[kernel_offset:], signal[:kernel_offset], axis=0), axis=0)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n        kernel_length = 2 * kernel_offset + 1\n\n        if kernel_length <= 1:\n            return signal\n\n        # Pad the signal with the first and last values of the signal\n        signal = np.concatenate((signal, signal))\n\n        # Shift the signal by the kernel_offset\n        signal = np.roll(signal, kernel_offset)\n\n        # Generate a rolling median of the shifted signal\n        median = np.median(signal[kernel_length - 1 : signal_length + kernel_length - 1: 1], axis=0)\n\n        # Trim the median to remove the edge effects\n        return median[kernel_offset:signal_length + kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with zeros to account for the edge effects\n        padded_signal = np.concatenate([np.zeros(kernel_offset), signal, np.zeros(kernel_offset)])\n\n        # Compute the rolling median\n        rolling_median = np.zeros(signal.shape[0], dtype=np.float32)\n        for i in range(len(signal)):\n            # Compute the rolling median of the signal and its shifted versions\n            rolling_median[i] = np.median(padded_signal[i - kernel_offset : i + kernel_offset + 1])\n\n        # Trim the array to remove the edge effects\n        trimmed_rolling_median = np.concatenate([rolling_median[kernel_offset], rolling_median[kernel_offset:-kernel_offset]])\n\n        return trimmed_rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        if kernel_offset < 1:\n            raise ValueError(\"kernel_offset must be at least 1.\")\n\n        # Generate a kernel of the specified size\n        kernel = np.ones(2 * kernel_offset)\n\n        # Calculate the rolling median\n        signal_shifted = np.concatenate([signal, np.roll(signal, -1)])\n        median = np.median(signal_shifted[kernel_offset - 1 : -kernel_offset + 1], axis=0)\n        median = np.concatenate([median, median[0], median[0]])\n\n        # Trim the edges\n        signal_trimmed = signal[kernel_offset - 1 : -kernel_offset + 2]\n        signal_trimmed = np.concatenate([signal_trimmed, signal_trimmed[-1], signal_trimmed[0]])\n        median_trimmed = median[kernel_offset - 1 : -kernel_offset + 2]\n        median_trimmed = np.concatenate([median_trimmed, median_trimmed[-1], median_trimmed[0]])\n\n        return median_trimmed"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # generate the array of shifted versions of the signal\n        # the array is generated by shifting the signal by -kernel_offset, -kernel_offset + 1, ..., 0, 1, ..., kernel_offset, kernel_offset - 1\n        shifted_signal = np.roll(signal, range(-kernel_offset, kernel_offset + 1), axis=0)\n\n        # calculate the median of the shifted signals\n        # the median is calculated for each column, so that the result is a 2-D array\n        rolling_median = np.median(shifted_signal, axis=1)\n\n        # trim the rolling median array to remove edge effects\n        # the trimmed array is shorter than the input signal by 2 * kernel_offset elements\n        trimmed_rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return trimmed_rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # We want to use a kernel that is larger than the kernel_offset to ensure that the kernel is always centered around the median\n        kernel_size = self.kernel_offset * 2 + 1\n\n        # Compute the rolling median\n        median_signal = np.median(\n            signal[kernel_offset : -kernel_offset, None], axis=0\n        )\n\n        # Trim the edges of the median signal to account for the edge effects\n        if kernel_offset > 0:\n            median_signal = median_signal[kernel_offset : -kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        if signal.size == 0:\n            return np.array([])\n\n        if signal.size == 1:\n            return np.array([signal[0]])\n\n        if kernel_offset == 0:\n            return np.array([signal[0], signal[-1]])\n\n        if signal.size < 2 * kernel_offset:\n            return np.array([])\n\n        if signal.size == 2 * kernel_offset:\n            return np.array([np.median(signal)])\n\n        signal_tmp = np.concatenate((signal, signal, signal))\n        signal_tmp_left_neighbor = np.roll(signal_tmp, 1)\n        signal_tmp_right_neighbor = np.roll(signal_tmp, -1)\n        dsignal = signal_tmp - signal_tmp_left_neighbor\n        dsignal_right = signal_tmp_right_neighbor - signal_tmp\n\n        left_mask = (dsignal < 0)\n        right_mask = (dsignal_right > 0)\n\n        left_mask_index = np.where(left_mask)[0]\n        right_mask_index = np.where(right_mask)[0]\n\n        # If the signal has an even number of elements, then the median of the left and right masks is taken.\n        if len(left_mask_index) == len(right_mask_index):\n            left_mask = np.logical_or(left_mask, right_mask)\n            left_mask_index = np.where(left_mask)[0]\n\n            return signal_tmp[left_mask_index]\n\n        # If the signal has an odd number of elements, then the median of the left mask is taken.\n        else:\n            return signal_tmp[left_mask_index]"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = template_probe.irisbits\n    maskbits = template_gallery.irisbits\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    irisbits_size = irisbits.size\n\n    # Get the number of iriscode bits in the iris templates.\n    maskbits_size = maskbits.size\n\n    # Get the number of iriscode bits"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = template_probe.irisbits\n    maskbits = template_gallery.irisbits\n\n    # Calculate the Hamming distance between the iris templates.\n    irisbitcount_top, maskbitcount_top = count_nonmatchbits(irisbits, maskbits, template_probe.half_width, weights)\n    irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(irisbits, maskbits, template_probe.half_width, weights)\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.irisbits.size, template_probe.half_width, weights\n    )\n\n    # Calculate the Hamming distance between the iris templates.\n    hd = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n    hd = min(hd, normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist))\n    hd = min(hd, normalized_HD(irisbitcount_top + irisbitcount_bot, maskbitcount_top + maskbitcount_bot, sqrt_totalbitcount, nm_dist))\n\n    # Return the Hamming distance and the corresponding rotation shift.\n    return hd, rotation_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get iriscodes\n    irisbits_probe = template_probe.irisbits\n    irisbits_gallery = template_gallery.irisbits\n\n    # Get maskcodes\n    maskbits_probe = template_probe.maskbits\n    maskbits_gallery = template_gallery.maskbits\n\n    # Get half widths\n    half_width = template_probe.half_width\n\n    # Get weights\n    if weights:\n        weights_probe = template_probe.weights\n    else:\n        weights_probe = None\n\n    # Calculate the Hamming distance\n    irisbitcount_top, maskbitcount_top = count_nonmatchbits(irisbits_probe, maskbits_gallery, half_width, weights=weights_probe)\n    irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(irisbits_gallery, maskbits_probe, half_width, weights=weights_probe)\n\n    # Calculate the total bit count\n    toal_codesize = np.sum([np.sum(w) for w in weights_probe]) if weights_probe else np.sum(irisbits_probe)\n\n    # Calculate the square root of the total bit count\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(toal_codesize, half_width, weights=weights_probe)\n\n    # Calculate the Hamming distance\n    norm_HD = normalized_HD(irisbitcount=irisbitcount_top, maskbitcount=maskbitcount_top, sqrt_totalbitcount=sqrt_totalbitcount_top, nm_dist=nm_dist)\n    norm_HD_bot = normalized_HD(irisbitcount=irisbitcount_bot, maskbitcount=maskbitcount_bot, sqrt_totalbitcount=sqrt_totalbitcount_bot, nm_dist=nm_dist)\n\n    # Calculate the minimum Hamming distance and the corresponding rotation shift\n    min_HD = min(norm_HD, norm_HD_bot)\n    min_rotation_shift = 0 if min_HD == norm_HD else 1\n\n    return min_HD, min_rotation_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None:\n        nm_dist = template_probe.nonmatch_distance\n    if weights is None:\n        weights = [np.ones_like(template_probe.iriscode) for _ in range(3)]\n\n    # Hamming distance calculation\n    for i in range(rotation_shift):\n        irisbits_probe = np.rot90(template_probe.iriscode, k=i)\n        irisbits_gallery = np.rot90(template_gallery.iriscode, k=i)\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits=irisbits_probe,\n            maskbits=irisbits_gallery,\n            half_width=template_probe.iriscode.shape[1] // 2,\n            weights=weights,\n        )\n        dist_top = normalized_HD(irisbitcount_top, maskbitcount_top, *count_sqrt_totalbits(toal_codesize=irisbits_probe.size, half_width=template_probe.iriscode.shape[1] // 2, weights=weights))\n        dist_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, *count_sqrt_totalbits(toal_codesize=irisbits_probe.size, half_width=template_probe.iriscode.shape[1] // 2, weights=weights))\n        dist = (dist_top + dist_bot) / 2\n        if dist < nm_dist:\n            return dist, i\n\n    raise MatcherError(f\"The iris code of the probe and gallery do not match.\")"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    iris_top_probe, iris_bot_probe = template_probe.iris_top, template_probe.iris_bot\n    iris_top_gallery, iris_bot_gallery = template_gallery.iris_top, template_gallery.iris_bot\n\n    if rotation_shift == 0:\n        iris_probe = iris_top_probe\n        iris_gallery = iris_top_gallery\n        half_width = template_probe.half_width\n        half_width_gallery = template_gallery.half_width\n\n        irisbits_probe = iris_probe.astype(int)\n        irisbits_gallery = iris_gallery.astype(int)\n    elif rotation_shift == 1:\n        iris_probe = iris_bot_probe\n        iris_gallery = iris_bot_gallery\n        half_width = template_probe.half_width\n        half_width_gallery = template_gallery.half_width\n        irisbits_probe = iris_probe.transpose(1, 0, 2).astype(int)\n        irisbits_gallery = iris_gallery.transpose(1, 0, 2).astype(int)\n    elif rotation_shift == 2:\n        iris_probe = iris_bot_probe\n        iris_gallery = iris_top_gallery\n        half_width = template_probe.half_width\n        half_width_gallery = template_gallery.half_width\n        irisbits_probe = iris_probe.transpose(1, 0, 2).astype(int)\n        irisbits_gallery = iris_gallery.astype(int)\n    elif rotation_shift == 3:\n        iris_probe = iris_top_probe\n        iris_gallery = iris_bot_gallery\n        half_width = template_probe.half_width\n        half_width_gallery = template_gallery.half_width\n        irisbits_probe = iris_probe.astype(int)\n        irisbits_gallery = iris_gallery.transpose(1, 0, 2).astype(int)\n    else:\n        raise MatcherError(\"Rotation shift is not valid.\")\n\n    # Get the total code size\n    toal_codesize = iris_probe.shape[1] *"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    template_probe.normalize_and_rotate(rotation_shift)\n    template_gallery.normalize_and_rotate(rotation_shift)\n\n    # Get the iris and mask bits from the template iriscodes\n    irisbits_probe = template_probe.iriscodes\n    irisbits_gallery = template_gallery.iriscodes\n\n    # Get the half width from the templates\n    half_width_probe = template_probe.half_width\n    half_width_gallery = template_gallery.half_width\n\n    # Calculate the square root of the total bit counts\n    sqrt_totalbitcount_probe, sqrt_totalbitcount_top_probe, sqrt_totalbitcount_bot_probe = count_sqrt_totalbits(\n        toal_codesize=template_probe.codesize,\n        half_width=half_width_probe,\n        weights=weights,\n    )\n    sqrt_totalbitcount_gallery, sqrt_totalbitcount_top_gallery, sqrt_totalbitcount_bot_gallery = count_sqrt_totalbits(\n        toal_codesize=template_gallery.codesize,\n        half_width=half_width_gallery,\n        weights=weights,\n    )\n\n    # Calculate the nonmatch bit counts\n    irisbitcount_top_probe, maskbitcount_top_probe, irisbitcount_bot_probe, maskbitcount_bot_probe = count_nonmatchbits(\n        irisbits=irisbits_probe,\n        maskbits=template_probe.maskcodes,\n        half_width=half_width_probe,\n        weights=weights,\n    )\n    irisbitcount_top_gallery, maskbitcount_top_gallery, irisbitcount_bot_gallery, maskbitcount_bot_gallery = count_nonmatchbits(\n        irisbits=irisbits_gallery,\n        maskbits=template_gallery.maskcodes,\n        half_width=half_width_gallery,\n        weights=weights,\n    )\n\n    # Calculate the Hamming distance\n    if weights:\n        norm_HD = normalized_HD(\n            irisbitcount_probe, maskbitcount_top_probe, sqrt_totalbitcount_top_probe, nm_dist\n        )"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if weights:\n        irisbits_top, irisbits_bot = template_probe.irisbits_top, template_probe.irisbits_bot\n    else:\n        irisbits_top, irisbits_bot = template_probe.irisbits, template_probe.irisbits\n\n    irisbits_top = irisbits_top[rotation_shift:rotation_shift + template_probe.iris_width, ...]\n    irisbits_bot = irisbits_bot[rotation_shift:rotation_shift + template_probe.iris_width, ...]\n\n    maskbits = template_gallery.maskbits\n\n    # calculate the nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_top, maskbits, template_probe.iris_width, weights\n    )\n\n    # calculate the normalized Hamming distance\n    norm_HD = normalized_HD(irisbitcount_top, maskbitcount_top, *count_sqrt_totalbits(3 * template_probe.iris_width, template_probe.half_width, weights), nm_dist)\n\n    return norm_HD, rotation_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    template_probe = template_probe.irisbits\n    template_gallery = template_gallery.irisbits\n\n    # Calculate the Hamming distance for each rotation shift\n    if rotation_shift == 0:\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            template_probe, template_gallery, template_probe.half_width, weights=weights\n        )\n    else:\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            template_probe, template_gallery, template_gallery.half_width, weights=weights\n        )\n\n    # Find the minimum Hamming distance and the corresponding rotation shift\n    min_distance = np.min([irisbitcount_top, irisbitcount_bot])\n    min_rotation_shift = 0\n    if irisbitcount_top < irisbitcount_bot:\n        min_rotation_shift = 0\n    else:\n        min_rotation_shift = 1\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.irisbits.size, template_probe.half_width, weights=weights\n        )\n        norm_HD = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        # Find the minimum normalized Hamming distance and the corresponding rotation shift\n        min_norm_distance = np.min([norm_HD, norm_HD_bot])\n        if norm_HD < norm_HD_bot:\n            min_rotation_shift = 0\n        else:\n            min_rotation_shift = 1\n    else:\n        min_norm_distance = None\n\n    return min_distance, min_rotation_shift, min_norm_distance\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Normalize the iriscodes\n    irisbits_probe = np.array(template_probe.irisbits)\n    irisbits_gallery = np.array(template_gallery.irisbits)\n\n    # Get the half width of iriscodes\n    half_width = [template_probe.half_width, template_gallery.half_width]\n\n    # Calculate the total amount of sqrt bits\n    sqrt_totalbitcount = count_sqrt_totalbits(toal_codesize=template_probe.codesize, half_width=half_width, weights=weights)[\n        0\n    ]\n\n    # Calculate the nonmatch bits\n    irisbitcount_top, maskbitcount_top = count_nonmatchbits(irisbits=irisbits_probe, maskbits=irisbits_gallery, half_width=half_width, weights=weights)\n    irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(irisbits=irisbits_gallery, maskbits=irisbits_probe, half_width=half_width, weights=weights)\n\n    # Calculate the Hamming distance\n    if weights:\n        nm_dist = normalized_HD(irisbitcount=irisbitcount_top, maskbitcount=maskbitcount_top, sqrt_totalbitcount=sqrt_totalbitcount, nm_dist=nm_dist)\n    else:\n        nm_dist = irisbitcount_top / maskbitcount_top\n\n    # Find the minimum Hamming distance\n    min_nm_dist = min(nm_dist, irisbitcount_bot / maskbitcount_bot)\n    if nm_dist < irisbitcount_bot / maskbitcount_bot:\n        min_rot = 0\n    else:\n        min_rot = 1\n\n    # Return the minimum Hamming distance and the corresponding rotation shift\n    return min_nm_dist, min_rot\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None:\n        nm_dist = template_probe.nonmatch_distance\n\n    if weights is None:\n        irisbits_top, irisbits_bot = template_probe.irisbits, template_probe.irisbits\n    else:\n        irisbits_top, irisbits_bot = template_probe.irisbits_w, template_probe.irisbits_w\n\n    maskbits_top, maskbits_bot = template_gallery.irisbits_w, template_gallery.irisbits_w\n\n    half_width_top, half_width_bot = template_probe.half_width, template_probe.half_width\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.codesize, [half_width_top, half_width_bot], weights=weights\n    )\n\n    if nm_dist < 0 or nm_dist > sqrt_totalbitcount:\n        raise MatcherError(\n            \"The nonmatch distance is out of range. It must be in the range of 0 <= nm_dist <= sqrt(codesize)\"\n        )\n\n    hd_top, hd_bot = np.inf, np.inf\n    shift_top, shift_bot = 0, 0\n\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_top, maskbits_top, half_width_top, weights=weights\n        )\n        hd_top = min(\n            hd_top, normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        )\n\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_bot, maskbits_bot, half_width_bot, weights=weights\n        )\n        hd_bot = min(hd_bot, normalized_HD(irisbitcount_bot, maskbitcount_bot"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = template_probe.irisbits\n    maskbits = template_gallery.maskbits\n    half_width = [template_probe.width // 2, template_gallery.width // 2]\n    if irisbits.shape[1] != maskbits.shape[1]:\n        raise MatcherError(\n            \"The number of columns in irisbits and maskbits must be equal. The irisbits has %d columns and the maskbits has %d columns.\" % (\n                irisbits.shape[1],\n                maskbits.shape[1],\n            )\n        )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist is None:\n        nm_dist = np.maximum(irisbitcount_top, irisbitcount_bot)\n\n    if rotation_shift < 0:\n        nm_dist_top = normalized_HD(irisbitcount_top, maskbitcount_top, *count_sqrt_totalbits(maskbitcount_top, half_width, weights))\n        nm_dist_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, *count_sqrt_totalbits(maskbitcount_bot, half_width, weights))\n    else:\n        nm_dist_top = normalized_HD(irisbitcount_top, maskbitcount_top, *count_sqrt_totalbits(maskbitcount_top, half_width, weights))\n        nm_dist_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, *count_sqrt_totalbits(maskbitcount_bot, half_width, weights))\n\n    if nm_dist_top < nm_dist_bot:\n        min_dist = nm_dist_top\n        shift_min_dist = 0\n    else:\n        min_dist = nm_dist_bot\n        shift_min_dist = rotation_shift\n\n    for i in range(1, rotation_shift + 1):\n        irisbits_top = np.rot90(irisbits[:, :, :], i)"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None:\n        nm_dist = template_probe.nonmatch_distance\n    else:\n        if not isinstance(nm_dist, (int, float)):\n            raise MatcherError(\"Nonmatch distance should be an integer or float value.\")\n        if nm_dist < 0 or nm_dist > 1:\n            raise MatcherError(\n                \"Nonmatch distance should be in the range of 0 to 1. The nonmatch distance is set to 1.\"\n            )\n    # Calculate the total bit count\n    toal_codesize = template_probe.codesize * 3\n\n    # Calculate the square root of the total bit count\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, template_probe.half_width, weights=weights\n    )\n\n    # Calculate the nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.irisbits,\n        template_gallery.irisbits,\n        template_probe.half_width,\n        weights=weights,\n    )\n\n    # Calculate the normalized Hamming distance\n    norm_HD = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n    norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n\n    # Calculate the minimum Hamming distance\n    min_hd = min(norm_HD, norm_HD_bot)\n\n    # Calculate the corresponding rotation shift\n    rotation_shift = 0\n\n    return min_hd, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if rotation_shift < 1:\n        raise MatcherError(\n            \"rotation shift must be greater than 1, got {}\".format(rotation_shift)\n        )\n\n    # Get the iris and mask code of the iris codes.\n    irisbits_t, maskbits_t = template_probe.iriscode\n    irisbits_g, maskbits_g = template_gallery.iriscode\n    # Calculate the total code size.\n    toal_codesize = np.prod(irisbits_t.shape)\n    # Calculate the half width of iriscodes.\n    half_width = [int(w / 2) for w in irisbits_t.shape]\n\n    # Calculate the square root of the total bit counts.\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate the nonmatch bits.\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_t, maskbits_t, half_width, weights\n    )\n\n    # Calculate the Hamming distance.\n    min_hd = min(\n        [\n            normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist),\n            normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist),\n        ]\n    )\n    # Calculate the rotation shift.\n    rotation_shift = np.argmin(\n        [\n            normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist),\n            normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist),\n        ]\n    )\n\n    return min_hd, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None:\n        nm_dist = template_probe.nonmatch_distance\n\n    if template_probe.iris_width != template_gallery.iris_width:\n        raise MatcherError(\"The iris width of the probe and the iris width of the gallery must be the same.\")\n\n    # Get the iris code and mask code\n    irisbits_probe = template_probe.iris_bits\n    irisbits_gallery = template_gallery.iris_bits\n    maskbits_probe = template_probe.mask_bits\n    maskbits_gallery = template_gallery.mask_bits\n\n    # Get the half width of the iris codes\n    half_width_probe = template_probe.iris_width // 2\n    half_width_gallery = template_gallery.iris_width // 2\n\n    # Initialize the Hamming distance and the rotation shift\n    min_HD = np.inf\n    min_shift = 0\n\n    # Loop through all possible rotation shifts\n    for shift in range(rotation_shift + 1):\n\n        # Calculate the iris bits for the current shift\n        irisbits_probe_shifted = irisbits_probe[:, shift:, ...]\n        irisbits_gallery_shifted = irisbits_gallery[:, shift:, ...]\n\n        # Calculate the iris bits for the top and bottom irises\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_probe_shifted, maskbits_gallery, [half_width_probe, half_width_gallery], weights\n        )\n\n        # Calculate the Hamming distance for the top and bottom irises\n        hd_top = normalized_HD(irisbitcount_top, maskbitcount_top, *count_sqrt_totalbits(template_probe.codesize, [half_width_probe, half_width_gallery], weights))\n        hd_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, *count_sqrt_totalbits(template_probe.codesize, [half_width_probe, half_width_gallery], weights))\n\n        # Calculate the total Hamming distance\n        HD = hd_top + hd_bot\n\n        # Update the minimum Ham"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None:\n        nm_dist = template_probe.nonmatch_distance\n    else:\n        template_probe.nonmatch_distance = nm_dist\n\n    if template_probe.code_type == template_gallery.code_type:\n        irisbits_probe = template_probe.codes[rotation_shift]\n        irisbits_gallery = template_gallery.codes[rotation_shift]\n\n        # TODO: Check if the irisbits are not all zeros\n        if irisbits_probe.shape[1:] == irisbits_gallery.shape[1:]:\n            # TODO: Check if the irisbits are not all zeros\n            # TODO: Check if the irisbits are not all zeros\n            if irisbits_probe.shape[0] == irisbits_gallery.shape[0]:\n                # TODO: Check if the irisbits are not all zeros\n                if np.all(irisbits_probe) and np.all(irisbits_gallery):\n                    # TODO: Check if the irisbits are not all zeros\n                    # TODO: Check if the irisbits are not all zeros\n                    # TODO: Check if the irisbits are not all zeros\n                    if irisbits_probe.shape[1] == irisbits_gallery.shape[1]:\n                        # TODO: Check if the irisbits are not all zeros\n                        if np.all(irisbits_probe) and np.all(irisbits_gallery):\n                            # TODO: Check if the irisbits are not all zeros\n                            # TODO: Check if the irisbits are not all zeros\n                            if irisbits_probe.shape[0] == irisbits_gallery.shape[0]:\n                                # TODO: Check if the irisbits are not all zeros\n                                if np.all(irisbits_probe) and np.all(irisbits_gallery):\n                                    # TODO: Check if the irisbits are not all zeros\n                                    # TODO: Check if the irisbits are not all zeros\n                                    if irisbits_probe.shape[1] == irisbits_gallery.shape[1]:\n                                        # TODO: Check if the irisbits are not all zeros\n                                        if np.all(irisbits_probe) and np.all(irisbits_gallery):\n                                            # TODO: Check"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Checks if the input arguments are IrisTemplate objects.\n    if not isinstance(template_probe, IrisTemplate) or not isinstance(template_gallery, IrisTemplate):\n        raise MatcherError(\"The input arguments must be IrisTemplate objects.\")\n\n    # Checks if the rotation_shift is an integer.\n    if not isinstance(rotation_shift, int):\n        raise MatcherError(\"The rotation shift must be an integer.\")\n\n    # Checks if the rotation_shift is in the range [0, 63].\n    if rotation_shift < 0 or rotation_shift > 63:\n        raise MatcherError(\n            \"The rotation shift must be in the range [0, 63]. The provided rotation shift is \" + str(rotation_shift)\n        )\n\n    # Checks if the nm_dist is a float.\n    if nm_dist is not None and not isinstance(nm_dist, float):\n        raise MatcherError(\"The nm_dist must be a float.\")\n\n    # Checks if the weights is a list of weights tables.\n    if weights is not None and not isinstance(weights, list):\n        raise MatcherError(\"The weights must be a list of weights tables.\")\n\n    # Checks if the weights is a list of weights tables with the correct size.\n    if weights is not None:\n        for weight_table in weights:\n            if not isinstance(weight_table, np.ndarray):\n                raise MatcherError(\"The weights must be a list of weights tables.\")\n            if weight_table.size != 512:\n                raise MatcherError(\n                    \"The weights must be a list of weights tables with the size of 512. The provided weights has a size of \"\n                    + str(weight_table.size)\n                )\n\n    # Checks if the weights is a list of weights tables with the correct shape.\n    if weights is not None:\n        for weight_table in weights:\n            if weight_table.shape != (3, 3):\n                raise MatcherError(\n                    \"The weights must be a list of weights tables with the shape of (3, 3). The provided weights has a shape of \"\n                    + str(weight_table.shape)\n                )\n\n    #"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Hamming distance\n    if not nm_dist:\n        hd = np.inf\n    else:\n        hd = nm_dist\n\n    # Iris codes\n    irisbits_probe = template_probe.iris_codes\n    irisbits_gallery = template_gallery.iris_codes\n\n    # Mask codes\n    maskbits_probe = template_probe.mask_codes\n    maskbits_gallery = template_gallery.mask_codes\n\n    # Half-width\n    half_width = template_probe.half_width\n\n    # Calculate the square root of the total number of bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize=irisbits_probe.shape[1],\n        half_width=half_width,\n        weights=weights,\n    )\n\n    # Calculate the number of nonmatched irisbits and common maskbits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits=irisbits_probe,\n        maskbits=maskbits_probe,\n        half_width=half_width,\n        weights=weights,\n    )\n\n    # Calculate the nonmatch distance\n    for i in range(rotation_shift):\n        # Calculate the Hamming distance\n        if nm_dist:\n            nm_dist = normalized_HD(irisbitcount=irisbitcount_top, maskbitcount=maskbitcount_top, sqrt_totalbitcount=sqrt_totalbitcount, nm_dist=nm_dist)\n        # Calculate the minimum Hamming distance\n        if hd > nm_dist:\n            hd = nm_dist\n        # Calculate the nonmatched iriscode bit count and common maskcode bit count from top iris\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits=irisbits_probe,\n            maskbits=maskbits_probe,\n            half_width=half_width,\n            weights=weights,\n        )\n        # Calculate the nonmatched iriscode bit count and common maskcode bit count"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check the input parameters\n    if template_probe.width != template_gallery.width:\n        raise MatcherError(\"template_probe.width != template_gallery.width\")\n    if template_probe.width % 2 != 0:\n        raise MatcherError(\"template_probe.width % 2 != 0\")\n    if rotation_shift < 0 or rotation_shift > template_probe.width:\n        raise MatcherError(\"rotation_shift out of range\")\n    if nm_dist is not None and nm_dist <= 0:\n        raise MatcherError(\"nm_dist <= 0\")\n\n    # Calculate the Hamming distance\n    half_width = template_probe.width // 2\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.codesize * 2, [half_width, half_width]\n    )\n    best_dist = np.inf\n    best_rot = 0\n\n    # Calculate the Hamming distance for all allowed rotations\n    for i in range(rotation_shift + 1):\n        irisbits_probe = template_probe.irisbits.astype(np.uint8)\n        irisbits_gallery = template_gallery.irisbits.astype(np.uint8)\n        irisbits_probe_top = irisbits_probe[:, half_width:, ...]\n        irisbits_probe_bot = irisbits_probe[:, :half_width, ...]\n        irisbits_gallery_top = irisbits_gallery[:, half_width:, ...]\n        irisbits_gallery_bot = irisbits_gallery[:, :half_width, ...]\n        if weights:\n            irisbits_probe = irisbits_probe.astype(np.uint16)\n            irisbits_gallery = irisbits_gallery.astype(np.uint16)\n            irisbits_probe_top = irisbits_probe_top.astype(np.uint16)\n            irisbits_probe_bot = irisbits_probe_bot.astype(np.uint16)\n            irisbits_gallery_top = irisbits_gallery_top.astype(np.uint16)\n            iris"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Initialise the variables for the calculation\n    top_iris = np.array(template_probe.top_iris)\n    bot_iris = np.array(template_probe.bot_iris)\n    top_mask = np.array(template_gallery.top_mask)\n    bot_mask = np.array(template_gallery.bot_mask)\n\n    # Calculate the iris code and mask code for the top iris\n    irisbits_top = top_iris ^ top_mask\n    irisbits_bot = bot_iris ^ bot_mask\n\n    # Calculate the Hamming distance between the iris codes\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_top, irisbits_bot, template_probe.half_width, weights\n    )\n    totalbitcount = irisbitcount_top + maskbitcount_top + irisbitcount_bot + maskbitcount_bot\n\n    # Calculate the square root of the total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        totalbitcount, template_probe.half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance\n    norm_HD = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount, nm_dist)\n    if norm_HD > 1:\n        norm_HD = 1\n\n    # Calculate the Hamming distance between the mask codes\n    maskbitcount_top_top = np.sum(np.sum(irisbits_top[:, 0:template_probe.half_width, ...] & top_mask[:, 0:template_probe.half_width, ...]))\n    maskbitcount_bot_bot = np.sum(np.sum(irisbits_bot[:, 0:template_probe.half_width, ...] & bot_mask[:, 0:template_probe.half_width, ...]))\n\n    # Calculate the weighted Hamming distance\n    if weights:\n        irisbitcount_top_top = np.sum(\n            [\n                np.sum(np.multiply(x"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None:\n        nm_dist = np.inf\n\n    irisbits = template_probe.iriscode.astype(np.int8)\n    maskbits = template_gallery.iriscode.astype(np.int8)\n\n    # TODO: check if the iriscodes are alligned\n    if template_probe.iriscode.shape[1] != template_gallery.iriscode.shape[1] or template_probe.iriscode.shape[2] != 2:\n        raise MatcherError(\"Iris codes must have the same width and depth\")\n\n    if rotation_shift >= np.abs(template_probe.iriscode.shape[1] - template_gallery.iriscode.shape[1]):\n        raise MatcherError(\"Rotation shift must be less than the difference between iriscode widths\")\n\n    half_width = [int(x / 2) for x in template_probe.iriscode.shape[1:3]]\n\n    irisbits = irisbits[:, :, 1]\n    maskbits = maskbits[:, :, 1]\n\n    # TODO: check if iriscodes are alligned\n    if irisbits.shape != maskbits.shape:\n        raise MatcherError(\"Iris codes must have the same width and depth\")\n\n    irisbitcount, maskbitcount, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        irisbits.size, half_width, weights\n    )\n    norm_HD = normalized_HD(irisbitcount, maskbitcount, sqrt_totalbitcount, nm_dist)\n\n    if norm_HD >= 1.0:\n        return np.inf, 0\n\n    # TODO: check if iriscodes are alligned\n    for i in range(rotation_shift):\n        maskbits = np.concatenate(\n            [\n                np.roll(maskbits, -1, axis=1),\n                np.roll(maskbits, 1, axis=2),\n            ],\n            axis=1,\n        )"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        bisectors_points_1 = []\n        bisectors_points_2 = []\n        for _ in range(self.params.num_bisectors):\n            point_1, point_2 = self._get_random_points_from_polygon(polygon, min_distance_between_sector_points_in_px)\n            bisectors_points_1.append(point_1)\n            bisectors_points_2.append(point_2)\n\n        return np.array(bisectors_points_1), np.array(bisectors_points_2)\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        num_vertices = polygon.shape[0]\n        max_iterations = self.params.max_iterations\n        bisectors_point_1 = np.zeros((num_bisectors, 2))\n        bisectors_point_2 = np.zeros((num_bisectors, 2))\n\n        # Find the first bisectors point\n        for i in range(num_bisectors):\n            # Choose a random pair of points from the polygon's vertices\n            point_1_index = np.random.randint(low=0, high=num_vertices)\n            point_2_index = np.random.randint(low=0, high=num_vertices)\n\n            # Check that the distance between the two points is greater than the minimum distance\n            if np.linalg.norm(polygon[point_1_index] - polygon[point_2_index]) > min_distance_between_sector_points_in_px:\n                bisectors_point_1[i, :] = polygon[point_1_index]\n                bisectors_point_2[i, :] = polygon[point_2_index]\n                break\n\n        # Find the second bisectors point\n        for i in range(num_bisectors):\n            # Choose a random pair of points from the polygon's vertices\n            point_1_index = np.random.randint(low=0, high=num_vertices)\n            point_2_index = np.random.randint(low=0, high=num_vertices)\n\n            # Check that the distance between the two points is greater than the minimum distance\n            if np.linalg.norm(polygon[point_1_index] - polygon[point_2_index]) > min_distance_between_sector_points_in_px:\n                bisectors_point_1[i, :] = polygon[point_1_index]\n                bisectors_point_2[i, :] = polygon[point_2_index]\n                break\n\n        # Check that the function was able to find a sufficient number of point pairs that meet the distance criterion\n        if i == num_bisectors - 1:\n            raise EyeCentersEstimationError("}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Calculates the number of bisectors that need to be generated.\n        num_bisectors = self.params.num_bisectors\n        if len(polygon) < num_bisectors * 2:\n            raise EyeCentersEstimationError(\n                f\"The polygon has {len(polygon)} vertices, which is less than the number of bisectors to calculate {num_bisectors * 2}.\"\n            )\n\n        # Calculates the maximum distance between points in the polygon.\n        max_distance = 0.0\n        for i in range(len(polygon)):\n            for j in range(i + 1, len(polygon)):\n                distance = np.linalg.norm(polygon[i] - polygon[j])\n                if distance > max_distance:\n                    max_distance = distance\n\n        # Calculates the minimum distance between points in the polygon.\n        min_distance = 0.0\n        for i in range(len(polygon)):\n            for j in range(i + 1, len(polygon)):\n                distance = np.linalg.norm(polygon[i] - polygon[j])\n                if distance < min_distance:\n                    min_distance = distance\n\n        # Calculates the minimum distance between points in the polygon as a fraction of the diameter.\n        min_distance_between_sector_points_as_fraction = min_distance / max_distance\n\n        # Calculates the number of bisectors that need to be generated.\n        num_bisectors = self.params.num_bisectors\n        if len(polygon) < num_bisectors * 2:\n            raise EyeCentersEstimationError(\n                f\"The polygon has {len(polygon)} vertices, which is less than the number of bisectors to calculate {num_bisectors * 2}.\"\n            )\n\n        # Calculates the maximum distance between points in the polygon.\n        max_distance = 0.0\n        for i in range(len(polygon)):\n            for j in range(i + 1, len(polygon)):\n                distance = np.linalg.norm(polygon[i] - polygon[j])\n                if distance > max_distance:\n                    max_distance = distance\n\n        # Calculates the minimum distance between points in the polygon"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # generate the bisectors\n        bisectors_points = []\n        for _ in range(self.params.num_bisectors):\n            # randomly select two points from the polygon vertices\n            point_a_index = np.random.randint(low=0, high=polygon.shape[1])\n            point_b_index = np.random.randint(low=0, high=polygon.shape[1])\n\n            # ensure the points are not too close to each other\n            while np.linalg.norm(polygon[:, point_a_index] - polygon[:, point_b_index]) < min_distance_between_sector_points_in_px:\n                point_b_index = np.random.randint(low=0, high=polygon.shape[1])\n            bisectors_points.append([polygon[:, point_a_index], polygon[:, point_b_index])\n\n        # calculate the bisectors\n        bisectors_points = np.array(bisectors_points)\n\n        return bisectors_points[:, 0], bisectors_points[:, 1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the number of bisectors calculated to 0.\n        bisectors_calculated = 0\n\n        # Initialize the list of bisectors to an empty list.\n        bisectors = []\n\n        # Iterate over the maximum number of iterations allowed.\n        for iteration in range(self.params.max_iterations):\n            # Initialize the bisector start and end points to empty arrays.\n            bisector_start_points = np.array([])\n            bisector_end_points = np.array([])\n\n            # Iterate over the number of bisectors to calculate.\n            for bisector in range(self.params.num_bisectors):\n                # Randomly choose two points from the polygon's vertices.\n                point_1 = np.random.choice(polygon, 1, replace=False)\n                point_2 = np.random.choice(polygon, 1, replace=False)\n\n                # Calculate the distance between the two chosen points.\n                distance = np.linalg.norm(point_1 - point_2)\n\n                # If the distance between the two points is greater than the minimum distance between sector points,\n                # add the points to the bisector start and end point arrays.\n                if distance > min_distance_between_sector_points_in_px:\n                    bisector_start_points = np.append(bisector_start_points, point_1)\n                    bisector_end_points = np.append(bisector_end_points, point_2)\n\n            # If the number of bisectors calculated is less than the number of bisectors to calculate,\n            # and the number of bisector start and end points is greater than zero,\n            # add the bisector start and end points to the list of bisectors.\n            if (bisectors_calculated < self.params.num_bisectors) and (bisector_start_points.size > 0):\n                bisectors.append([bisector_start_points, bisector_end_points])\n                bisectors_calculated += 1\n\n            # If the number of bisectors calculated is equal to the number of bisectors to calculate,\n            # or if the number of bisector start and end points is less than or equal to zero,\n            # break out of the"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        bisectors_point1 = np.zeros((num_bisectors, 2))\n        bisectors_point2 = np.zeros((num_bisectors, 2))\n\n        # Calculate the first bisectors point\n        for i in range(num_bisectors):\n            bisectors_point1[i, :] = self._get_random_point(polygon)\n\n        # Calculate the second bisectors point\n        for i in range(num_bisectors):\n            bisectors_point2[i, :] = self._get_random_point(polygon)\n            while self._distance(bisectors_point1[i, :], bisectros_point2[i, :]) < min_distance_between_sector_points_in_px:\n                bisectors_point2[i, :] = self._get_random_point(polygon)\n\n        return bisectors_point1, bisectors_point2\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        bisectors_points = self._generate_bisectors(polygon, min_distance_between_sector_points_in_px)\n        return bisectors_points[0], bisectors_points[1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        bisectors_points = np.zeros((2, num_bisectors * 2))\n        bisectors_points[0] = polygon[0, :]\n\n        for i in range(num_bisectors):\n            while True:\n                bisectors_points[1, i * 2] = np.random.choice(polygon, 1, replace=False)\n                bisectors_points[1, i * 2 + 1] = np.random.choice(polygon, 1, replace=False)\n                if (\n                    bisectors_points[0, i * 2] != bisectors_points[1, i * 2]\n                    and bisectors_points[0, i * 2 + 1] != bisectors_points[1, i * 2 + 1]\n                    and np.linalg.norm(bisectors_points[0, i * 2] - bisectors_points[1, i * 2]) > min_distance_between_sector_points_in_px\n                ):\n                    break\n            if i == max_iterations - 1:\n                raise EyeCentersEstimationError(\n                    \"Could not find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n        return bisectors_points[:, i * 2], bisectors_points[:, i * 2 + 1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Calculate the number of bisectors to generate\n        num_bisectors = self.params.num_bisectors\n\n        # Initialize the bisector points\n        bisectors_points_first_array = np.zeros((num_bisectors, 2))\n        bisectors_points_second_array = np.zeros((num_bisectors, 2))\n\n        # Initialize the number of iterations\n        iterations = 0\n\n        # Loop through the polygon vertices\n        for i in range(polygon.shape[0]):\n            # Find the next vertex\n            next_vertex = (i + 1) % polygon.shape[0]\n\n            # Calculate the distance between the current vertex and the next vertex\n            distance = np.linalg.norm(polygon[i, :] - polygon[next_vertex, :])\n\n            # Check if the distance is greater than the minimum distance between sector points\n            if distance > min_distance_between_sector_points_in_px:\n\n                # Add the current vertex and the next vertex to the bisectors points arrays\n                bisectors_points_first_array[iterations, :] = polygon[i, :]\n                bisectors_points_second_array[iterations, :] = polygon[next_vertex, :]\n\n                # Increment the number of iterations\n                iterations += 1\n\n            # Check if the maximum number of iterations has been reached\n            if iterations >= num_bisectors:\n                break\n\n        # If the number of bisectors is less than the minimum required\n        if iterations < num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"BisectorsMethod could not find {num_bisectors} bisectors. Only found {iterations} bisectors.\"\n            )\n\n        # Calculate the perpendicular bisectors\n        bisectors_points_first_array = np.array(bisectors_points_first_array)\n        bisectors_points_second_array = np.array(bisectors_points_second_array)\n\n        return bisectors_points_first_array, bisectors_points_second_array\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        num_vertices = polygon.shape[0]\n\n        bisectors_start = np.zeros((num_bisectors, 2))\n        bisectors_end = np.zeros((num_bisectors, 2))\n\n        num_points_chosen = 0\n        while num_points_chosen < num_bisectors:\n            point_1_idx = np.random.randint(low=0, high=num_vertices)\n            point_2_idx = np.random.randint(low=0, high=num_vertices)\n            distance = np.linalg.norm(polygon[point_1_idx] - polygon[point_2_idx])\n            if distance > min_distance_between_sector_points_in_px:\n                bisectors_start[num_points_chosen] = polygon[point_1_idx]\n                bisectors_end[num_points_chosen] = polygon[point_2_idx]\n                num_points_chosen += 1\n\n        return bisectors_start, bisectors_end\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Calculate the number of bisectors to calculate.\n        bisectors_to_calculate = self.params.num_bisectors\n\n        # Initialize the number of iterations to zero.\n        iterations = 0\n\n        # Initialize the bisectors arrays.\n        first_bisectors_point = np.zeros((bisectors_to_calculate, 2))\n        second_bisectors_point = np.zeros((bisectors_to_calculate, 2))\n\n        # Loop until the number of iterations exceeds the maximum allowed, or a sufficient number of bisectors have been calculated.\n        while iterations < self.params.max_iterations and bisect_count < bisect_count_limit:\n            # Choose two random points from the polygon vertices.\n            point_1_idx = np.random.randint(polygon.shape[0])\n            point_2_idx = np.random.randint(polygon.shape[0])\n\n            # Calculate the distance between the two points.\n            distance = np.linalg.norm(polygon[point_1_idx] - polygon[point_2_idx])\n\n            # Check if the distance is greater than the minimum distance between sector points.\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the bisectors for the two points.\n                first_bisectors_point[bisect_count] = self._calculate_bisector(polygon, point_1_idx)\n                second_bisectors_point[bisect_count] = self._calculate_bisector(polygon, point_2_idx)\n\n                # Increment the number of bisectors calculated.\n                bisect_count += 1\n\n            # Increment the number of iterations.\n            iterations += 1\n\n        # Check if the number of bisectors calculated is sufficient.\n        if bisect_count < bisect_count_limit:\n            # Raise an exception if the number of bisectors is insufficient.\n            raise EyeCentersEstimationError(\n                f\"Unable to calculate {bisect_count} bisectors in {iterations} iterations.\"\n            )\n\n        # Return the bisectors.\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        bisectors_points = np.empty((0, 2), dtype=np.float64)\n        for _ in range(self.params.num_bisectors):\n            first_point, second_point = self._choose_points(polygon, min_distance_between_sector_points_in_px)\n            bisectors_points = np.append(bisectors_points, np.array([first_point, second_point]), axis=0)\n            if bisectors_points.shape[0] == self.params.num_bisectors:\n                break\n\n        if bisectors_points.shape[0] < self.params.num_bisectors:\n            raise EyeCentersEstimationError(f\"Failed to find enough bisectors in {self.params.num_bisectors} iterations.\")\n\n        return bisectors_points[0], bisectors_points[1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Calculate the number of bisectors to generate\n        num_bisectors = self.params.num_bisectors\n\n        # Initialize the bisectors as empty arrays\n        bisectors_start_points = np.empty((num_bisectors, 2))\n        bisectors_end_points = np.empty((num_bisectors, 2))\n\n        # Initialize the number of iterations to 0\n        num_iterations = 0\n\n        # Calculate the number of vertices in the polygon\n        num_vertices = polygon.shape[0]\n\n        # Set the number of bisectors to 0\n        bisectors_found = 0\n\n        # While the number of bisectors found is less than the number of bisectors required\n        while bisectors_found < num_bisectors:\n\n            # Increment the number of iterations\n            num_iterations += 1\n\n            # If the number of iterations exceeds the maximum iterations allowed\n            if num_iterations > self.params.max_iterations:\n\n                # Raise an exception\n                raise EyeCentersEstimationError(\n                    \"Unable to find enough bisectors within the maximum number of iterations allowed.\"\n                )\n\n            # Select a random pair of points from the polygon's vertices\n            point_1_index = np.random.randint(0, num_vertices)\n            point_2_index = np.random.randint(0, num_vertices)\n\n            # Check if the distance between the two points is greater than the minimum distance\n            if self._distance(polygon[point_1_index], polygon[point_2_index]) > min_distance_between_sector_points_in_px:\n\n                # Calculate the bisector line\n                bisector_line = self._calculate_bisector(polygon[point_1_index], polygon[point_2_index])\n\n                # Add the starting point of the bisector to the array of bisector start points\n                bisectors_start_points[bisectors_found, :] = bisector_line[0]\n\n                # Add the ending point of the bisector to the array of bisector end points\n                bisectors_end_points[bisectors_found, :] = bisector_line[1]\n\n                # Increment the number of bisectors found\n                bisectors_found +="}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # TODO: remove hardcoded value\n        num_bisectors = self.params.num_bisectors\n        # TODO: remove hardcoded value\n        max_iterations = self.params.max_iterations\n\n        bisectors_points: np.ndarray = np.empty((num_bisectors, 2, 2), dtype=np.float32)\n\n        for i in range(num_bisectors):\n            # TODO: remove hardcoded value\n            bisectors_points[i, 0, 0] = self._random_point_from_polygon(polygon)\n            bisectors_points[i, 1, 0] = self._random_point_from_polygon(polygon)\n\n            while self._distance_between_points(bisectors_points[i, 0], bisectors_points[i, 1]) < min_distance_between_sector_points_in_px:\n                if i == max_iterations:\n                    raise EyeCentersEstimationError(\n                        \"Could not find bisectors with a sufficient distance between points\"\n                    )\n                bisectors_points[i, 1, 0] = self._random_point_from_polygon(polygon)\n\n        return bisectors_points[:, 0], bisectors_points[:, 1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        bisectors_points = []\n\n        for i in range(self.params.num_bisectors):\n\n            # Choose two random points from the polygon's vertices, ensuring that the distance between them is greater than the minimum specified.\n            point_1 = polygon[np.random.randint(0, polygon.shape[0])]\n            point_2 = polygon[np.random.randint(0, polygon.shape[0])]\n\n            while np.linalg.norm(point_1 - point_2) < min_distance_between_sector_points_in_px:\n                point_1 = polygon[np.random.randint(0, polygon.shape[0])]\n                point_2 = polygon[np.random.randint(0, polygon.shape[0])]\n\n            bisectors_points.append(np.array([point_1, point_2]))\n\n        return bisectors_points\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # TODO: This is a temporary fix for the case when polygon is a circle.\n        if polygon.size == 4:\n            return np.array([[polygon[0][0], polygon[1][0]]), np.array([[polygon[0][0], polygon[1][0]])\n\n        num_points = polygon.shape[0]\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        bisectors_points_array = np.empty((num_bisectors, 2, 2))\n\n        for i in range(num_bisectors):\n            first_point_index = np.random.randint(num_points)\n            second_point_index = np.random.randint(num_points)\n            bisector_points = self._get_bisector(\n                polygon, first_point_index, second_point_index, min_distance_between_sector_points_in_px\n            )\n            bisectors_points_array[i] = bisector_points\n\n        bisectors_points_array = bisectors_points_array[bisectors_points_array[:, 0, 0].argsort()]\n        bisectors_points_array = bisectors_points_array[bisectors_points_array[:, 0, 1].argsort()]\n\n        return bisectors_points_array[:, 0], bisectors_points_array[:, 1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        bisectors_points = self._get_bisectors_points(polygon, min_distance_between_sector_points_in_px)\n\n        # TODO: Find a better way to do this\n        # If the number of bisectors is less than the minimum number of bisectors required, raise an error\n        if len(bisectors_points) < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Could not find {self.params.num_bisectors} bisectors. Found {len(bisectors_points)} bisectors.\"\n            )\n\n        # If the number of bisectors is greater than the maximum number of bisectors allowed, raise an error\n        if len(bisectors_points) > self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Too many bisectors found: {len(bisectors_points)}. \"\n                f\"Maximum number of bisectors allowed: {self.params.num_bisectors}\"\n            )\n        # Return the bisectors points\n        return bisectors_points[0], bisectors_points[1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Generate a random set of bisectors.\n        bisectors_points = np.random.choice(polygon, self.params.num_bisectors, replace=False)\n        bisectors_points = np.c_[bisectors_points, bisect_points_2d]\n\n        # Calculate the bisectors for each pair of points.\n        bisectors_points_x, bisectors_points_y = self._calculate_bisectors(bisectors_points)\n\n        # Check if the bisectors have converged.\n        converged, iterations = self._check_convergence(bisectors_points_x, bisectors_points_y, min_distance_between_sector_points_in_px)\n\n        if not converged:\n            raise EyeCentersEstimationError(\n                \"Bisectors did not converge within the maximum number of iterations.\"\n            )\n\n        return bisectors_points_x, bisectors_points_y\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Calculate the number of bisectors to calculate\n        num_bisectors = self.params.num_bisectors\n\n        # Initialize the bisector points\n        bisector_points = np.zeros((2, 2))\n\n        # Initialize the number of iterations\n        iteration = 0\n\n        # Loop until the number of bisectors is reached or the maximum number of iterations is exceeded\n        while (bisector_points.shape[1] < num_bisectors) and (iteration < self.params.max_iterations):\n            # Calculate the distance between all pairs of points\n            distances = np.linalg.norm(polygon[:, None, :] - polygon[None, :, :], axis=2)\n\n            # Find the indices of the minimum distances\n            min_distances, min_indices = np.min(distances, axis=2)\n\n            # Check if the minimum distances are greater than the minimum distance between sector points\n            if np.all(min_distances >= min_distance_between_sector_points_in_px):\n                # If the minimum distances are greater, then we can use the corresponding indices to select the points\n                # and calculate the bisectors\n                bisector_points[:, 0] = polygon[min_indices[0]]\n                bisector_points[:, 1] = polygon[min_indices[1]]\n\n                # Calculate the bisector points\n                bisector_points = self._calculate_bisectors(bisector_points)\n\n            # Increment the iteration\n            iteration += 1\n\n        # If the number of bisectors is not reached, raise an error\n        if bisector_points.shape[1] < num_bisectors:\n            raise EyeCentersEstimationError(\n                \"Failed to find sufficient number of bisectors within the maximum number of iterations.\"\n            )\n\n        # Return the bisector points\n        return bisector_points[:, 0], bisector_points[:, 1]\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        bisectors_points = np.empty((num_bisectors, 2, 2), dtype=np.float32)\n\n        for i in range(num_bisectors):\n            # TODO: this is a bit slow\n            # TODO: this can be optimized with a kd-tree\n            # TODO: remove this and use a kd-tree\n            # TODO: this is the most time-consuming part of the algorithm\n            # TODO: this is the only part that is not optimized\n            point_1 = self._get_random_point_from_polygon(polygon)\n            point_2 = self._get_random_point_from_polygon(polygon)\n\n            while self._is_point_too_close(point_1, point_2, min_distance_between_sector_points_in_px):\n                point_1 = self._get_random_point_from_polygon(polygon)\n                point_2 = self._get_random_point_from_polygon(polygon)\n\n                if i == max_iterations:\n                    raise EyeCentersEstimationError(\n                        \"Could not find bisectors that satisfy the minimum distance criterion.\"\n                    )\n\n            bisectors_points[i][0] = point_1\n            bisectors_points[i][1] = point_2\n\n        return bisectors_points[0], bisectors_points[1]\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self._execute(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_run(self)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_run(self, result)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.after_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.run_before(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.run_after(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution(*args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_pre_execute(self, *args, **kwargs)\n\n        result = self._execute(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            if isinstance(callback, Callback):\n                callback.on_before_execute(self, *args, **kwargs)\n\n        result = self._execute(*args, **kwargs)\n\n        for callback in self._callbacks:\n            if isinstance(callback, Callback):\n                callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Call pre-hooks\n        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        # Call the algorithm's run method\n        result = self.run(*args, **kwargs)\n\n        # Call post-hooks\n        for callback in self._callbacks:\n            callback.post_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            if hasattr(callback, \"on_before_execution\"):\n                callback.on_before_execution(self, *args, **kwargs)\n\n        result = self traktor_run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            if hasattr(callback, \"on_after_execution\"):\n                callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n        result = self.run(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs, result=result)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.run_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.run_after_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        self.on_before_run(*args, **kwargs)\n        result = self.run(*args, **kwargs)\n        self.on_after_run(*args, **kwargs)\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Call pre-callbacks\n        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n        # Execute algorithm\n        result = self.run(*args, **kwargs)\n        # Call post-callbacks\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_pre_execute()\n        res = self._execute(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.on_post_execute()\n        return res\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Run the pre-execution callbacks.\n        for callback in self._callbacks:\n            callback.pre_execution(self, *args, **kwargs)\n\n        # Run the algorithm's run method.\n        result = self._run(*args, **kwargs)\n\n        # Run the post-execution callbacks.\n        for callback in self._callbacks:\n            callback.post_execution(self, *args, **kwargs, result=result)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Run pre-callbacks\n        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n        # Execute the algorithm\n        result = self._run_alg(*args, **kwargs)\n        # Run post-callbacks\n        for callback in self._callbacks:\n            callback.post_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Check if the type definition is a base type\n        if self.is_base_type(type_definition):\n            return self.validate_base_type(output, type_definition)\n\n        # Check if the type definition is a list-like type\n        elif type_definition in self.list_like_types:\n            return self.validate_list_like(output, type_definition)\n\n        # Check if the type definition is a dict-like type\n        elif type_definition in self.dict_like_types:\n            return self.validate_dict_like(output, type_definition)\n\n        # Check if the type definition is a set-like type\n        elif type_definition in self.set_like_types:\n            return self.validate_set_like(output, type_definition)\n\n        # Check if the type definition is a tuple-like type\n        elif type_definition in self.tuple_like_types:\n            return self.validate_tuple_like(output, type_definition)\n\n        # Check if the type definition is a dataclass\n        elif is_dataclass(type_definition):\n            return self.validate_dataclass(output, type_definition)\n\n        # Check if the type definition is a BaseModel\n        elif type(type_definition) is BaseModel:\n            return self.validate_basemodel(output, type_definition)\n\n        # Check if the type definition is a type\n        elif isinstance(type_definition, type):\n            return self.validate_type(output, type_definition)\n\n        # Check if the type definition is a Literal\n        elif type_definition in [Literal]:\n            return self.validate_literal(output, type_definition)\n\n        # Check if the type definition is a Union\n        elif type_definition in [Union]:\n            return self.validate_union(output, type_definition)\n\n        # Check if the type definition is a Sequence\n        elif type_definition in [Sequence]:\n            return self.validate_sequence(output, type_definition)\n\n        # Check if the type definition is a Tuple\n        elif type_definition in [Tuple]:\n            return self.validate_tuple(output, type_definition)\n\n        # Check if the type definition is a Mapping\n        elif"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if is_dataclass(type_definition):\n            try:\n                return self.validate_dataclass(output, type_definition)\n            except Exception as e:\n                return False\n        elif issubclass(type_definition, BaseModel):\n            try:\n                return self.validate_pydantic(output, type_definition)\n            except Exception as e:\n                return False\n        elif is_dataclass(type_definition):\n            try:\n                return self.validate_dataclass(output, type_definition)\n            except Exception as e:\n                return False\n        elif issubclass(type_definition, BaseModel):\n            try:\n                return self.validate_pydantic(output, type_definition)\n            except Exception as e:\n                return False\n        elif issubclass(type_definition, MutableMapping):\n            return self.validate_mutable_mapping(output, type_definition)\n        elif issubclass(type_definition, Mapping):\n            return self.validate_mapping(output, type_definition)\n        elif issubclass(type_definition, Sequence):\n            return self.validate_sequence(output, type_definition)\n        elif issubclass(type_definition, Tuple):\n            return self.validate_tuple(output, type_definition)\n        elif issubclass(type_definition, Sequence) or issubclass(type_definition, Tuple):\n            return self.validate_sequence(output, type_definition)\n        elif issubclass(type_definition, list_like_types):\n            return self.validate_list_like(output, type_definition)\n        elif issubclass(type_definition, set_like_types):\n            return self.validate_set_like(output, type_definition)\n        elif issubclass(type_definition, dict_like_types):\n            return self.validate_dict_like(output, type_definition)\n        elif issubclass(type_definition, tuple_like_types):\n            return self.validate_tuple_like(output, type_definition)\n        elif issubclass(type_definition, Literal):\n            return self.validate_literal(output, type_definition)\n        else:\n            return self.validate"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if inspect.isclass(type_definition) and issubclass(type_definition, BaseModel):\n            # If the type definition is a Pydantic model, deserialize the output and validate it against the model\n            return self.validate_pydantic_model(output, type_definition)\n        elif type_definition in self.dict_like_types:\n            # If the type definition is a dictionary-like type, validate the output as a dictionary\n            return self.validate_dict(output)\n        elif type_definition in self.list_like_types:\n            # If the type definition is a list-like type, validate the output as a list\n            return self.validate_list(output)\n        elif type_definition in self.tuple_like_types:\n            # If the type definition is a tuple-like type, validate the output as a tuple\n            return self.validate_tuple(output)\n        elif type_definition in self.set_like_types:\n            # If the type definition is a set-like type, validate the output as a set\n            return self.validate_set(output)\n        elif inspect.isclass(type_definition):\n            # If the type definition is a class, validate the output as an instance of that class\n            return self.validate_class(output, type_definition)\n        elif type_definition is bool:\n            # If the type definition is bool, validate the output as a boolean\n            return self.validate_bool(output)\n        elif type_definition is str:\n            # If the type definition is str, validate the output as a string\n            return self.validate_str(output)\n        elif type_definition is int:\n            # If the type definition is int, validate the output as an integer\n            return self.validate_int(output)\n        elif type_definition is float:\n            # If the type definition is float, validate the output as a float\n            return self.validate_float(output)\n        elif type_definition is datetime.datetime:\n            # If the type definition is datetime, validate the output as a datetime object\n            return self.validate_datetime(output)\n        elif type_definition is datetime.date:\n            # If the type definition is date,"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if output is None:\n            return output is None\n\n        try:\n            output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # If the type definition is a base type, check if the output is of the same type\n        if self.is_base_type(type_definition):\n            return self.validate_base_type(value=output, typ=type_definition)\n\n        # If the type definition is a list-like type\n        if isinstance(type_definition, self.list_like_types):\n            if not isinstance(output, self.list_like_types):\n                return False\n            # If the type definition is a list-like type, check if the output is a list\n            if not isinstance(output, list):\n                return False\n            # Check if the elements in the output list match the type definition\n            return all(self.validate_output(element, element_type) for element in output)\n\n        # If the type definition is a dict-like type\n        if isinstance(type_definition, self.dict_like_types):\n            if not isinstance(output, self.dict_like_types):\n                return False\n            # If the type definition is a dict-like type, check if the output is a dict\n            if not isinstance(output, dict):\n                return False\n            # Check if the keys in the output dict match the type definition\n            if not all(self.validate_output(key, key_type) for key, key_type in type_definition.items()):\n                return False\n            # Check if the values in the output dict match the type definition\n            if not all(self.validate_output(value, value_type) for value, value_type in output.items()):\n                return False\n            return True\n\n        # If the type definition is a tuple-like type\n        if isinstance(type_definition, self.tuple_like_types):\n            if not isinstance(output, self.tuple_like_types):\n                return False\n            # If the type definition is a tuple-like type, check if the output is a tuple\n            if not isinstance(output, tuple):\n                return False\n            # Check if the elements in the output tuple match the type definition\n            return all(self.validate_output(element, element_type) for element, element_type in zip(output, type_definition))\n\n    "}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Check if the type definition is a base type\n        if self.is_base_type(type_definition):\n            # If the type definition is a base type, use the base type validation function\n            return self.validate_base_type(output, type_definition)\n\n        # If the type definition is a class, use the class validation function\n        if is_dataclass(type_definition):\n            return self._validate_dataclass(output, type_definition)\n\n        # If the type definition is a collection, use the collection validation function\n        if type_definition in self.dict_like_types:\n            return self._validate_dict_like_collection(output, type_definition)\n        if type_definition in self.list_like_types:\n            return self._validate_list_like_collection(output, type_definition)\n        if type_definition in self.set_like_types:\n            return self._validate_set_like_collection(output, type_definition)\n        if type_definition in self.tuple_like_types:\n            return self._validate_tuple_like_collection(output, type_definition)\n\n        # If the type definition is a unannotated type, use the unannotated type validation function\n        if isinstance(type_definition, Type):\n            return self.validate_unannotated_type(output, type_definition)\n\n        # If the type definition is a unannotated type, use the unannotated type validation function\n        return self.validate_unannotated_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if output is None:\n            return True\n\n        # Deserializing the output\n        try:\n            output_dict = json.loads(output)\n        except json.decoder.JSONDecodeError:\n            return False\n\n        # Checking if the output matches the type definition\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Check if the type definition is a base type\n        if self.is_base_type(type_definition):\n            return self.validate_base_type(output, type_definition)\n\n        # Check if the type definition is a dataclass\n        if is_dataclass(type_definition):\n            try:\n                return dataclasses.is_dataclass(output)\n            except TypeError:\n                return False\n\n        # Check if the type definition is a Pydantic model\n        if isinstance(type_definition, BaseModel):\n            try:\n                return BaseModel.is_model(output)\n            except TypeError:\n                return False\n\n        # Check if the type definition is a list, tuple, set or any other collection\n        if isinstance(type_definition, self.tuple_like_types):\n            try:\n                return self.validate_collection(output, type_definition)\n            except TypeError:\n                return False\n\n        # Check if the type definition is a dictionary\n        if isinstance(type_definition, self.dict_like_types):\n            try:\n                return self.validate_collection(output, type_definition)\n            except TypeError:\n                return False\n\n        # Check if the type definition is a type alias\n        if isinstance(type_definition, Type):\n            return self.validate_output(output, get_origin(type_definition))\n\n        # Check if the type definition is a type alias\n        if isinstance(type_definition, Literal):\n            return self.validate_literal(output, type_definition)\n\n        # Check if the type definition is a Union\n        if isinstance(type_definition, Union):\n            return self.validate_union(output, type_definition)\n\n        return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # If the type definition is a base type, then deserialize the output and check if it matches the type definition.\n        if self.is_base_type(type_definition):\n            try:\n                deserialized_output = json.loads(output)\n                return self.validate_base_type(deserialized_output, type_definition)\n            except json.JSONDecodeError:\n                return False\n        # If the type definition is a dataclass, then deserialize the output and check if it matches the type definition.\n        elif issubclass(type_definition, dataclasses.Dataclass):\n            try:\n                deserialized_output = dataclasses.deserialize(output)\n            except dataclasses.DataclassesError:\n                return False\n\n            return dataclasses.is_dataclass(deserialized_output, type_definition)\n        # If the type definition is a dataclass, then deserialize the output and check if it matches the type definition.\n        elif issubclass(type_definition, BaseModel):\n            try:\n                deserialized_output = BaseModel.parse_raw(output)\n            except BaseModel.JSONError:\n                return False\n            return BaseModel.is_model(deserialized_output, type_definition)\n        # If the type definition is a tuple, then deserialize the output and check if it matches the type definition.\n        elif issubclass(type_definition, Tuple):\n            try:\n                deserialized_output = tuple(json.loads(output))\n            except json.JSONDecodeError:\n                return False\n            return all(isinstance(value, typ) for value, typ in zip(deserialized_output, type_definition))\n        # If the type definition is a list, then deserialize the output and check if it matches the type definition.\n        elif issubclass(type_definition, list):\n            try:\n                deserialized_output = json.loads(output)\n            except json.JSONDecodeError:\n                return False\n            return all(isinstance(value, typ) for value in deserialized_output)\n        # If the type definition is a set, then deserialize the output and check if it matches the type definition.\n        elif issubclass(type_definition, set):\n            try:\n                deserialized_"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if type_definition == str:\n            return True\n        try:\n            value = json.loads(output)\n            return self.check_type(value, type_definition)\n        except json.JSONDecodeError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_from_json = json.loads(output)\n            return self.check_type(output_from_json, type_definition)\n        except:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if inspect.isclass(type_definition) and issubclass(type_definition, BaseModel):\n            # If the type definition is a dataclass, deserialize the output string and check if it matches the dataclass\n            try:\n                output_instance = json.loads(output)\n                return self.check_type(output_instance, type_definition)\n            except TypeError:\n                return False\n        else:\n            # If the type definition is not a dataclass, check if the output string can be deserialized to the type\n            try:\n                output_instance = json.loads(output)\n            except TypeError:\n                return False\n            return self.check_type(output_instance, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if self.is_base_type(type_definition):\n            return self.validate_base_type(output, type_definition)\n\n        if hasattr(type_definition, '__len__') and hasattr(type_definition, '__getitem__'):\n            # Check if the output is a list-like type\n            if hasattr(output, 'pop'):\n                return self.is_list_like_type(output, type_definition)\n            elif hasattr(output, 'append'):\n                return self.is_list_like_type(output, type_definition)\n        if hasattr(type_definition, 'keys'):\n            # Check if the output is a dict-like type\n            if hasattr(output, 'items'):\n                return self.is_dict_like_type(output, type_definition)\n            elif hasattr(output, 'get'):\n                return self.is_dict_like_type(output, type_definition)\n        if hasattr(type_definition, '__iter__'):\n            # Check if the output is a set-like type\n            if hasattr(output, 'add'):\n                return self.is_set_like_type(output, type_definition)\n            elif hasattr(output, 'discard'):\n                return self.is_set_like_type(output, type_definition)\n        if hasattr(type_definition, '__len__') and hasattr(type_definition, '__getitem__'):\n            # Check if the output is a tuple-like type\n            if hasattr(output, 'pop'):\n                return self.is_tuple_like_type(output, type_definition)\n            elif hasattr(output, 'append'):\n                return self.is_tuple_like_type(output, type_definition)\n\n        return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Convert the type definition to a dict\n        type_definition = self.convert_type_definition_to_dict(type_definition)\n\n        # Deserialize the output string to a dict\n        try:\n            output_dict = self._deserialize_json(output)\n        except json.JSONDecodeError:\n            return False\n\n        # Check if the output dict matches the type definition\n        return self.is_dict_like_type(output_dict) and self.is_type_definition_equal_to(type_definition, output_dict)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if not isinstance(output, str):\n            raise TypeError(f\"The output string must be a string, but it is {type(output)}\")\n\n        try:\n            output_dict = json.loads(output)\n        except json.decoder.JSONDecodeError:\n            return False\n\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if output is None:\n            return type_definition is None\n\n        if type_definition is None:\n            return output is None\n\n        try:\n            deserialized = json.loads(output)\n        except ValueError:\n            return False\n\n        return self.check_type(deserialized, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_data = json.loads(output)\n        except (TypeError, ValueError):\n            return False\n        return self.check_type(output_data, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if not output:\n            return False\n\n        if type_definition is None:\n            return True\n\n        if is_dataclass(type_definition):\n            try:\n                deserialized_output = self.deserialize(output)\n            except:\n                return False\n            return dataclasses.is_valid(deserialized_output, type_definition)\n\n        if isinstance(type_definition, (tuple, list)):\n            if not isinstance(output, (tuple, list)):\n                return False\n\n            if len(type_definition) != len(output):\n                return False\n            for i, (typ, value) in enumerate(zip(type_definition, output)):\n                if not self.validate_output(value, typ):\n                    return False\n\n            return True\n\n        if isinstance(type_definition, Literal):\n            return output in type_definition\n\n        if isinstance(type_definition, Union):\n            for typ in type_definition:\n                if self.validate_output(output, typ):\n                    return True\n            return False\n\n        if isinstance(type_definition, Sequence):\n            if not isinstance(output, Sequence):\n                return False\n            return all(self.validate_output(value, typ) for typ in type_definition for value in output)\n\n        if isinstance(type_definition, Mapping):\n            if not isinstance(output, Mapping):\n                return False\n            return all(self.validate_output(value, typ) for typ in type_definition.values() for value in output.values())\n\n        return self.validate_base_type(output, type_definition)\n\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if output is None:\n            return True\n        try:\n            deserialized = self.deserialize(output)\n\n            return self.check_type(deserialized, type_definition)\n        except Exception as e:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if type_definition is None:\n            return True\n\n        if isinstance(type_definition, type) and issubclass(type_definition, BaseModel):\n            return isinstance(json.loads(output), type_definition)\n\n        if inspect.isclass(type_definition):\n            return isinstance(json.loads(output), type_definition)\n        else:\n            return self.validate_base_type(json.loads(output), type_definition)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(signature)\n\n        # Get the function's docstring\n        docstring = func_object.__doc__\n\n        # Get the function's input and output type hints\n        input_type_hints = type_hints.get('parameters', [])\n        output_type_hint = type_hints.get('return')\n\n        # Get the class definitions for the input and output types\n        input_class_definitions = []\n        output_class_definitions = []\n\n        for input_type_hint in input_type_hints:\n            input_class_definitions.append(get_class_definition(input_type_hint.annotation))\n\n        if output_type_hint is not None:\n            output_class_definitions.append(get_class_definition(output_type_hint))\n\n        # Determine the function type\n        if output_class_definitions[0] is Embedding:\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Return the function description\n        return FunctionDescription(\n            func_object.__name__,\n            docstring,\n            input_type_hints,\n            output_class_definitions,\n            function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Determine the input and output type hints\n        input_type_hints = {\n            param.name: get_type_hints(param) for param in signature.parameters.values()\n        }\n        output_type_hint = type_hints[signature.return_annotation]\n\n        # Get the class definition for the output type\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine the function type\n        if issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the function description\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        input_type_hints = get_type_hints(signature)\n        output_type_hint = input_type_hints.pop(\"return\")\n\n        # Get the class definition for the output type hint\n        output_type_definition = Register.get_class_definition(output_type_hint)\n\n        # Determine the function type based on the output type hint\n        if isinstance(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class_definition = output_type_definition\n        elif isinstance(output_type_hint, Literal):\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = Embedding\n        else:\n            if isinstance(output_type_hint, Union):\n                # If the output type hint is a Union, check if it contains a subclass of Embedding\n                for type_ in output_type_hint:\n                    if isinstance(type_, Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n                        output_class_definition = output_type_definition\n                        break\n                else:\n                    # If the output type hint is a Union but does not contain a subclass of Embedding, it is assumed to be a Symbolic function\n                    function_type = FunctionType.SYMBOLIC\n                    output_class_definition = Embedding\n            else:\n                # If the output type hint is not a Union, it is assumed to be a Symbolic function\n                function_type = FunctionType.SYMBOLIC\n                output_class_definition = Embedding\n\n        # Get the function's docstring\n        docstring = func_object.__doc__\n\n        # Create the FunctionDescription object\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        func_docstring = func_object.__doc__\n        func_signature = inspect.signature(func_object)\n        func_type_hints = get_type_hints(func_object)\n\n        input_type_hints = func_type_hints.get(\"args\")\n        output_type_hints = func_type_hints.get(\"return\")\n\n        input_class_definitions = Register.get_class_definitions(input_type_hints)\n        output_class_definitions = Register.get_class_definitions(output_type_hints)\n\n        if output_class_definitions:\n            if issubclass(output_class_definitions[0], Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(func_name, func_docstring, input_type_hints, output_type_hints,\n                                  input_class_definitions, output_class_definitions, function_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        input_type_hints = get_type_hints(signature)\n\n        # Determine the function's type based on the output type hint\n        output_type_hint = input_type_hints[\"return\"]\n        if isinstance(output_type_hint, Union):\n            # If the output type hint is a Union, check if it contains an Embedding class or a subclass of a Union\n            output_type_hint_classes = get_type_hints(output_type_hint)\n            if any(isinstance(output_type_hint_class, Embedding) for output_type_hint_class in output_type_hint_classes):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            # If the output type hint is not a Union, check if it is a class or a subclass of a Union\n            if isinstance(output_type_hint, type) or issubclass(output_type_hint, Union):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n\n        # Get the class definition for the output type hint\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Create the function description\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints={\n                \"class_name\": output_class_definition.name,\n                \"class_definition\": output_class_definition,\n                \"type\": output_type_hint,\n            },\n            function_type=function_type,\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function name and docstring.\n        name = func_object.__name__\n        docstring = func_object.__doc__\n\n        # Get the function's signature and type hints.\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(signature)\n\n        # Determine input and output type hints.\n        input_type_hints = type_hints.copy()\n        output_type_hint = type_hints.pop(\"return\")\n\n        # Get the class definition for each type hint.\n        input_class_definitions = {\n            key: get_class_definition(value)\n            for key, value in input_type_hints.items()\n        }\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine the function type.\n        if isinstance(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class_definition = output_type_hint\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Return the function description.\n        return FunctionDescription(name, docstring, input_class_definitions, output_class_definition, function_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        function_name = func_object.__name__\n        function_docstring = func_object.__doc__\n        function_signature = inspect.signature(func_object)\n        function_input_type_hints = get_type_hints(function_signature)\n        function_output_type_hint = function_input_type_hints.pop(\"return\")\n        function_input_type_hints = {\n            key: get_class_definition(value) for key, value in function_input_type_hints.items()\n        }\n\n        if isinstance(function_output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            function_output_class_definition = function_output_type_hint\n        elif isinstance(function_output_type_hint, Union):\n            for type_hint in function_output_type_hint.__args__:\n                if isinstance(type_hint, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n                    function_output_class_definition = type_hint\n                    break\n            else:\n                function_type = FunctionType.SYMBOLIC\n                function_output_class_definition = None\n        else:\n            function_type = FunctionType.SYMBOLIC\n            function_output_class_definition = get_class_definition(function_output_type_hint)\n\n        return FunctionDescription(function_name, function_docstring, function_input_type_hints,\n                                  function_output_class_definition, function_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints.\n        func_signature = inspect.signature(func_object)\n        func_type_hints = get_type_hints(func_object)\n\n        # Get the function's name and docstring.\n        func_name = func_signature.name\n        func_docstring = inspect.getdoc(func_object)\n\n        # Get the class definitions for the input and output types.\n        input_types = []\n        output_type = None\n        for arg_name, arg_type_hint in func_type_hints.items():\n            if arg_name == \"self\" or arg_name == \"cls\":\n                continue\n\n            input_types.append(get_class_definition(arg_type_hint))\n        output_type = get_class_definition(func_type_hints[\"return\"])\n\n        # Determine the function type.\n        func_type = FunctionType.SYMBOLIC\n        if output_type is not None:\n            if issubclass(output_type, Embedding):\n                func_type = FunctionType.EMBEDDABLE\n\n        # Return the function description.\n        return FunctionDescription(func_name, func_type, func_docstring, input_types, output_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        input_hints = get_type_hints(signature)\n        output_hint = input_hints.return_annotation\n\n        # Get the function's docstring\n        docstring = func_object.__doc__\n\n        # Get the class definitions for the input and output types\n        input_types = [get_class_definition(input_hint) for input_hint in input_hints.values()]\n        output_type = get_class_definition(output_hint)\n\n        # Determine the function type\n        if isinstance(output_hint, Literal):\n            return FunctionDescription(func_object.__name__, docstring, input_types, output_type, FunctionType.SYMBOLIC)\n        elif issubclass(output_hint, Embedding):\n            return FunctionDescription(func_object.__name__, docstring, input_types, output_type, FunctionType.EMBEDDABLE)\n        elif issubclass(output_hint, Union):\n            if issubclass(get_origin(output_hint), Embedding):\n                return FunctionDescription(func_object.__name__, docstring, input_types, output_type, FunctionType.EMBEDDABLE)\n            else:\n                return FunctionDescription(func_object.__name__, docstring, input_types, output_type, FunctionType.SYMBOLIC)\n        else:\n            return FunctionDescription(func_object.__name__, docstring, input_types, output_type, FunctionType.SYMBOLIC)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_signature = inspect.signature(func_object)\n\n        # Get the function's name\n        func_name = func_signature.name\n\n        # Get the function's docstring\n        func_docstring = inspect.getdoc(func_object)\n\n        # Get the function's input and output type hints\n        input_types = get_type_hints(func_object)\n        output_type = get_type_hints(func_object, return_value=True)\n\n        # Get the class definitions for the input and output types\n        input_types_definitions = []\n        output_type_definition = None\n        for input_type in input_types:\n            input_types_definitions.append(get_class_definition(input_type))\n\n        if output_type:\n            output_type_definition = get_class_definition(output_type)\n\n        # Determine the function type\n        if output_type_definition is None or output_type_definition is Embedding:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.EMBEDDABLE\n\n        # Create the function description\n        function_description = FunctionDescription(\n            name=func_name,\n            docstring=func_docstring,\n            input_types=input_types_definitions,\n            output_type_definition=output_type_definition,\n            function_type=function_type)\n\n        # Return the function description\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        input_hints = get_type_hints(signature)\n        output_hints = input_hints.return_annotation\n\n        # Handle the case where the output type hint is a class or a subclass of a Union\n        if isinstance(output_hints, Literal):\n            output_hints = output_hints[0]\n        elif isinstance(output_hints, Union):\n            output_hints = output_hints[0]\n\n        # Handle the case where the output type hint is a generic class\n        if isinstance(output_hints, get_origin(Embedding)):\n            output_class_definition = Embedding\n        elif isinstance(output_hints, get_origin(Tuple)):\n            output_class_definition = tuple\n        elif isinstance(output_hints, get_origin(Callable)):\n            output_class_definition = dict\n        elif isinstance(output_hints, get_origin(Dict)):\n            output_class_definition = dict\n        elif isinstance(output_hints, get_origin(list)):\n            output_class_definition = list\n        elif isinstance(output_hints, get_origin(int)):\n            output_class_definition = int\n        elif isinstance(output_hints, get_origin(float)):\n            output_class_definition = float\n        elif isinstance(output_hints, get_origin(str)):\n            output_class_definition = str\n        elif isinstance(output_hints, get_origin(bool)):\n            output_class_definition = bool\n        else:\n            output_class_definition = None\n\n        # Determine the function type based on the output type hint\n        if output_class_definition is None:\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = None\n        else:\n            function_type = FunctionType.EMBEDDABLE\n\n        # Create the function description\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_hints=input_hints,\n            output_hints=output_hints,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # get the function's signature\n        signature = inspect.signature(func_object)\n\n        # get the function's type hints\n        type_hints = get_type_hints(func_object)\n\n        # get the function's docstring\n        docstring = func_object.__doc__\n\n        # get the function's name\n        name = func_object.__name__\n\n        # get the function's input type hints\n        input_type_hints = type_hints.get('__annotations__', None)\n\n        # get the function's output type hint\n        output_type_hint = type_hints.get('return', None)\n\n        # get the function's class definitions\n        input_type_definitions = get_class_definition(input_type_hints)\n        output_type_definitions = get_class_definition(output_type_hint)\n\n        # determine the function type\n        if output_type_hint is not None and issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # create the function description\n        function_description = FunctionDescription(\n            name=name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_type_definitions=input_type_definitions,\n            output_type_definitions=output_type_definitions,\n            function_type=function_type\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(signature)\n\n        # Get the function's docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get the input and output type hints\n        input_type_hints = type_hints.parameters.values()\n        output_type_hint = type_hints.return_annotation\n\n        # Get the class definition for the input and output types\n        input_class_definitions = get_class_definitions(input_type_hints)\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine the function type\n        if issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif issubclass(output_type_hint, Union):\n            for output_type_hint in output_type_hint.__args__:\n                if issubclass(output_type_hint, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n                    break\n                else:\n                    function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the function description\n        function_description = FunctionDescription(\n            function_name=func_object.__name__,\n            function_type=function_type,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition\n        )\n\n        return function_description\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        # Get the function's name, docstring, and type hints\n        func_name = func_object.__name__\n        func_docstring = func_object.__doc__\n        func_input_type_hints = get_type_hints(func_object)\n\n        # Get the function's input and output types from the type hints\n        input_types = [type_hint for name, type_hint in func_input_type_hints.items() if name != \"return\"]\n        output_type = func_input_type_hints[\"return\"]\n        # Get the class definition for the output type\n        output_type_class_definition = get_class_definition(output_type)\n\n        # Determine the function type based on the output type\n        if issubclass(output_type_class_definition, Embedding):\n            # If the output type is a subclass of Embedding, the function is embeddable\n            function_type = FunctionType.EMBEDDABLE\n        elif issubclass(output_type_class_definition, Literal):\n            # If the output type is a Literal, the function is symbolic\n            function_type = FunctionType.SYMBOLIC\n        else:\n            # If the output type is not a subclass of Embedding or Literal, the function is symbolic\n            function_type = FunctionType.SYMBOLIC\n        # Create the function description\n        function_description = FunctionDescription(func_name, func_docstring, input_types, output_type, output_type_class_definition, function_type)\n        return function_description\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        input_type_hints = signature.parameters\n        output_type_hints = type_hints.get('return', Literal[None])\n\n        if output_type_hints is None:\n            return FunctionDescription(name=func_object.__name__,\n                                      docstring=func_object.__doc__,\n                                      input_type_hints=input_type_hints,\n                                      output_type_hint=None,\n                                      function_type=FunctionType.SYMBOLIC)\n\n        if isinstance(output_type_hints, Embedding):\n            output_type_hints = [output_type_hints]\n        if isinstance(output_type_hints, Literal[None]):\n            output_type_hints = []\n\n        if isinstance(output_type_hints, list):\n            if not all(isinstance(output_type_hint, Embedding) for output_type_hint in output_type_hints):\n                output_type_hints = [output_type_hints]\n\n        output_type_hints_class_definitions = [Register.get_class_definition(output_type_hint) for output_type_hint in\n                                               output_type_hints]\n\n        if isinstance(output_type_hints_class_definitions[0], Union):\n            output_type_hint_class_definition = output_type_hints_class_definitions[0]\n        elif isinstance(output_type_hints_class_definitions[0], Literal[None]):\n            output_type_hint_class_definition = output_type_hints_class_definitions[0]\n        else:\n            output_type_hint_class_definition = output_type_hints_class_definitions[0]\n\n        function_type = FunctionType.SYMBOLIC\n        if output_type_hint_class_definition == Embedding:\n            function_type = FunctionType.EMBEDDABLE\n        elif isinstance(output_type_hint_class_definition, Literal[None]):\n            function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(name=func_object.__name__,"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        func_docstring = func_object.__doc__\n        # get the function's type hints\n        func_type_hints = get_type_hints(func_object)\n        # get the function's input and output type hints\n        input_type_hints = func_type_hints.get(\"arguments\", {})\n        output_type_hint = func_type_hints.get(\"return\", None)\n        # get the function's class definitions for the input and output types\n        input_classes = {k: get_class_definition(v) for k, v in input_type_hints.items()}\n        output_class = get_class_definition(output_type_hint)\n        # determine the function's type\n        if issubclass(output_class, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class = Embedding\n        elif issubclass(output_class, Union):\n            output_classes = get_type_arguments(output_class)\n            if issubclass(output_classes[0], Embedding):\n                function_type = FunctionType.EMBEDDABLE\n                output_class = Embedding\n        else:\n            function_type = FunctionType.SYMBOLIC\n        # create a new instance of FunctionDescription\n        function_description = FunctionDescription(func_name, func_docstring, input_classes, output_class, function_type)\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get the function's name and docstring\n        name = func_object.__name__\n        docstring = func_object.__doc__\n\n        # Get the input and output type hints\n        input_type_hints = sig.parameters\n        output_type_hint = type_hints[\"return\"]\n\n        # Get the class definition for the output type hint\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Check if the output type hint is a class or a subclass of a Union\n        if isinstance(output_class_definition, Embedding) or issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the FunctionDescription object\n        function_description = FunctionDescription(name=name, docstring=docstring, input_type_hints=input_type_hints,\n                                                  output_type_hint=output_type_hint, output_class_definition=output_class_definition,\n                                                  function_type=function_type)\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Fetch the function's signature and type hints\n        signature = inspect.signature(func_object)\n        input_hints = get_type_hints(signature)\n\n        # Get the function's docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Fetch the class definitions for the input and output types\n        input_classes = {k: get_class_definition(v) for k, v in input_hints.items()}\n\n        # Determine the function type and output class definition\n        output_type = get_type_hints(signature).get(\"return\", object)\n        if issubclass(output_type, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class = Embedding\n        elif issubclass(output_type, Literal):\n            function_type = FunctionType.SYMBOLIC\n            output_class = output_type.__args__[0]\n        elif issubclass(output_type, Union):\n            # If the output type is a Union, we need to check if it contains a subclass of Embedding\n            output_classes = get_type_hints(signature).get(\"return\")\n            for output_class in output_classes:\n                if issubclass(output_class, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n                    break\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            raise ValueError(f\"Unknown output type {output_type} for function {func_object}.\")\n\n        # Create the FunctionDescription object\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_classes=input_classes,\n            output_class=output_class,\n            function_type=function_type,\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        if not inspect.isfunction(func_object):\n            raise ValueError(\"func_object is not a function\")\n        signature = inspect.signature(func_object)\n\n        function_name = func_object.__name__\n\n        # Get the type hints for the function's inputs and output.\n        input_hints = get_type_hints(func_object)\n        output_hint = input_hints.pop()\n\n        # Get the class definitions for the input and output types.\n        input_classes = {k: get_class_definition(v) for k, v in input_hints.items()}\n        output_class = get_class_definition(output_hint)\n        output_class_name = output_class.__name__\n\n        # Check if the output type hint is a class or a subclass of a Union and process it accordingly.\n        if issubclass(output_class, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class_name = Embedding.__name__\n        elif issubclass(output_class, Union):\n            function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the function description.\n        return FunctionDescription(\n            name=function_name,\n            input_classes=input_classes,\n            output_class_name=output_class_name,\n            docstring=func_object.__doc__,\n            type=function_type,\n            function=func_object,\n        )\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        try:\n            func_signature = inspect.signature(func_object)\n            if func_signature.return_annotation is None:\n                raise ValueError\n        except TypeError:\n            raise ValueError(\"Invalid function object\")\n\n        func_name = func_signature.name\n        func_docstring = func_signature.__doc__\n        input_type_hints = get_type_hints(func_object)\n        output_type_hint = input_type_hints[next(iter(input_type_hints))]\n\n        if isinstance(output_type_hint, Literal):\n            output_type_hint = Literal\n        else:\n            output_type_hint = output_type_hint[0]\n\n        output_class_def = Register.get_class_definition(output_type_hint)\n\n        if output_class_def is None:\n            raise ValueError(\n                f\"Could not get class definition for output type hint {output_type_hint}. It must be a class or a subclass of Union.\")\n\n        if isinstance(output_class_def, Literal):\n            function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_class_def, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            raise ValueError(\n                f\"Output type hint {output_type_hint} is not a subclass of Embedding. It must be either a class or a subclass of Embedding or Union.\")\n\n        return FunctionDescription(func_name, func_docstring, input_type_hints, output_class_def, function_type)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = string\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}\")\n            self.bit_array[index] = 1\n            self.indices[index] = string\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n        self.persistence.save(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n\n            self.indices[index] = string\n\n        self.persistence.save(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n\n        self.persistence.save(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n\n        self.indices[(hash1 + hash2) % self.size] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = string\n\n        self.persistence.save(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = string\n\n        self.persistence.save(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n            #print(f\"Add: Seed={seed}, Digest={index}\")\n        self.persistence.store_bloom_filter(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n\n            # if self.indices[index] == 0:\n            #    self.indices[index] = string\n        self.persistence.store_bloom_filter(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}\")\n            self.bit_array[index] = 1\n            self.indices[index] = string\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.store_bloom_filter(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"BloomFilter: Loaded bit array length does not match the expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n\n        self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n\n        if len(bit_array) != self.size:\n            logging.warning(f\"Bit array length mismatch, expected {self.size}, got {len(bit_array)}\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save()\n\n        self.bit_array = bit_array\n\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Bit array length is {len(bit_array)}, expected {self.size}\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array is of different length than expected, reinitializing\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n            return\n        self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Corrupted bit array loaded from persistence. Reinitializing bit array and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.persistence.save(self.bit_array)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n\n        if len(bit_array) != self.size:\n            logging.warning(f\"BloomFilter corruption detected. Expected bit_array length {self.size}, but got {len(bit_array)}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        try:\n            loaded_bit_array = self.persistence.load()\n        except Exception:\n            logging.warning(f\"No data found at {self.persistence.path}\")\n            return\n\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Bit array length mismatch. Expected {self.size} but found {len(loaded_bit_array)}\")\n\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n            return\n\n        self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        logging.warning('BloomFilter.load() is not implemented.')\n        bit_array = self.persistence.load()\n\n        # Check if the loaded bit array's length matches the expected length\n        expected_length = self.size\n        if len(bit_array) != expected_length:\n            # Log a warning message\n            logging.warning(\n                f'The loaded bit array has a length of {len(bit_array)}, but the expected length is {expected_length}. This could indicate corruption.')\n\n            # Reinitialize the bit array and indices\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n\n            # Save the new state\n            self.save()"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        _bit_array = self.persistence.load()\n        if len(_bit_array) != self.size:\n            logging.warning(\"BloomFilter bit array length doesn't match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = _bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        try:\n            bit_array = self.persistence.load()\n            if len(bit_array) != self.size:\n                logging.warning(\n                    f\"Loaded BloomFilter bit array length of {len(bit_array)} did not match expected length of {self.size}. Reinitializing bit array.\")\n                bit_array, indices = self.init_bit_array(self.size)\n                self.save()\n        except:\n            bit_array, indices = self.init_bit_array(self.size)\n        self.bit_array = bit_array\n        self.indices = indices\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n\n        if len(bit_array) != self.size:\n            logging.warning(\n                f\"BloomFilter loaded from persistence with size {len(bit_array)} but expected size {self.size}. \"\n                f\"Reinitializing and saving.\"\n            )\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if bit_array.length() != self.size:\n            logging.warning(\"BloomFilter: bit array length mismatch, reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n            return\n        self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\n                f\"Loaded bit array of length {len(loaded_bit_array)} does not match expected length of {self.size}. \"\n                f\"Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"The loaded bit array's length ({len(bit_array)}) does not match the expected length ({self.size}). \"\n                            f\"This may indicate corruption. Reinitializing the bit array and re-saving the BloomFilter.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded bit array with length {len(loaded_bit_array)} does not match expected length {self.size}. Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n            return\n        self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"The BloomFilter bit array has a length mismatch. Expected {self.size} but got {len(bit_array)}\")\n            bit_array, indices = self.init_bit_array(self.size)\n            self.save()\n        self.bit_array = bit_array\n        self.indices = self.persistence.load_indices()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        try:\n            self.bit_array = self.persistence.load()\n            if len(self.bit_array) != self.size:\n                logging.warning(f\"Bloom filter bit array size mismatch: Expected {self.size}, got {len(self.bit_array)}\")\n                self.bit_array, self.indices = self.init_bit_array(self.size)\n                self.save()\n            else:\n                logging.info(\"Bloom filter bit array loaded successfully\")\n        except Exception as e:\n            logging.error(f\"Error loading bloom filter: {e}\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array_from_persistence = self.persistence.load()\n        if len(bit_array_from_persistence) != self.size:\n            logging.warning(f\"The bit array from persistence is of size {len(bit_array_from_persistence)}, but the expected size is {self.size}. Reinitializing the bit array and saving the new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array_from_persistence\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        # Load bit array\n        loaded_bit_array = self.persistence.load()\n\n        # Check if bit array length matches expected length\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\n                f\"Bit array length mismatch: expected {self.size} but loaded {len(loaded_bit_array)}. Reinitializing bit array.\")\n\n            # Reinitialize bit array\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            # Save new state\n            self.save()\n\n            # Return\n            return\n\n        # Set bit array\n        self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\n                f\"Loaded bit array has length {len(loaded_bit_array)} but expected length is {self.size}. Reinitializing and saving.\"\n            )\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hashes = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = hashes[i] % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            index = self.hash_functions(string)[i] % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash_1, hash_2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = int(hash_1 + i * hash_2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        if not string:\n            raise ValueError(\"string cannot be None\")\n\n        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = hash1 + (hash2 * i) % self.size\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        # Generate indices\n        indices = [hash1 % self.size, (hash1 >> 7) % self.size, (hash1 >> 13) % self.size, (hash1 >> 19) % self.size,\n                   (hash1 >> 25) % self.size, (hash1 >> 31) % self.size,\n                   (hash2 % self.size), (hash2 >> 7) % self.size, (hash2 >> 13) % self.size, (hash2 >> 19) % self.size,\n                   (hash2 >> 25) % self.size, (hash2 >> 31) % self.size]\n\n        # Check if all indices are set in the bit array\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            hash1, hash2 = self.hash_functions(string)\n            index = self.indices[i]\n            if self.bit_array[hash1 & index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            hash_value = self.hash_functions(string)\n            index = (hash_value[0] * i + hash_value[1]) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        if self.bit_array[self.get_indices(string)]:\n            return True\n        return False\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            hash1, hash2 = self.hash_functions(string)\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        if self.bit_array is None:\n            logging.error(\"Bit array is not initialized, cannot lookup\")\n            return False\n\n        for i in range(self.hash_count):\n            index = self.hash_functions(string)[i] % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            hash1, hash2 = self.hash_functions(string)\n            index = (hash1 * self.size) + hash2\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # hash the string\n        hash1, hash2 = self.hash_functions(string)\n\n        # get the indices\n        indices = self.indices(hash1, hash2)\n\n        # check if all bits are set\n        return all(self.bit_array[i] for i in indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            hash_value = self.hash_functions(string)\n            index = (hash_value[i] % self.size)\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Get the hash values for the string\n        hash1, hash2 = self.hash_functions(string)\n\n        # Check the bits at the indices generated by the hash values\n        for i in range(self.hash_count):\n            index = (hash1 + i*hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        # If all bits are set, return True\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        if self.bit_array is None:\n            self.bit_array, _ = self.init_bit_array(self.size)\n        for i in range(self.hash_count):\n            if self.bit_array[self.indices[i][string]] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hashes = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = hashes[i] % self.size\n            if not self.bit_array[index]:\n                return False\n            # if not self.bit_array[index]:\n            #     return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            index = self.hash_functions(string)[i] % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            hash_val = self.hash_functions(string)\n            # TODO: implement a better hashing function\n            index = hash_val[i % 2] % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[TEACHER_MODEL]]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_model_config(model_config) for model_config in json_dict[TEACHER_MODEL]]\n\n        if \"trained_on_datapoints\" in json_dict:\n            self.current_model_stats[\"trained_on_datapoints\"] = json_dict[\"trained_on_datapoints\"]\n\n        if \"running_faults\" in json_dict:\n            self.current_model_stats[\"running_faults\"] = json_dict[\"running_faults\"]\n\n        if \"trained_on_datapoints\" in json_dict:\n            self.last_training_run[\"trained_on_datapoints\"] = json_dict[\"trained_on_datapoints\"]\n\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_config(model) for model in json_dict[TEACHER_MODEL]]\n        if \"trained_on_datapoints\" in json_dict:\n            self.current_model_stats[\"trained_on_datapoints\"] = json_dict[\"trained_on_datapoints\"]\n        if \"running_faults\" in json_dict:\n            self.current_model_stats[\"running_faults\"] = json_dict[\"running_faults\"]\n        if \"trained_on_datapoints\" in json_dict:\n            self.last_training_run[\"trained_on_datapoints\"] = json_dict[\"trained_on_datapoints\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_config(model_config) for model_config in json_dict[TEACHER_MODEL]]\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        \n        self.distilled_model = config_factory.get_model_config(\n            json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[TEACHER_MODEL]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [\n            config_factory.get_model_config(teacher_model_name)\n            for teacher_model_name in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL], DEFAULT_STUDENT_MODELS)\n        self.current_model_stats = json_dict[CURRENT_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        self.teacher_models = [config_factory.get_model_config(teacher_model, DEFAULT_TEACHER_MODELS) for teacher_model in json_dict[TEACHER_MODEL]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_config_for(json_dict[DISTILLED_MODEL])\n            self.distilled_model.load_from_dict(json_dict[DISTILLED_MODEL])\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_config_for(model) for model in json_dict[TEACHER_MODEL]]\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get(DISTILLED_MODEL))\n        self.current_model_stats = json_dict.get(MODEL_STATS, {})\n        self.last_training_run = json_dict.get(LAST_TRAINING_RUN, {})\n        self.current_training_run = json_dict.get(CURRENT_TRAINING_RUN, {})\n        self.nr_of_training_runs = json_dict.get(NR_OF_TRAINING_RUNS, 0)\n        self.teacher_models = json_dict.get(TEACHER_MODEL, DEFAULT_TEACHER_MODELS)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        \n        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[DISTILLED_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.teacher_models = [config_factory.get_model_config(model_config) for model_config in json_dict[TEACHER_MODELS]]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        \n        self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[DISTILLED_MODEL].copy()\n        self.last_training_run = json_dict[TEACHER_MODEL].copy()\n        self.current_training_run = {}\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        \n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(model_config) for model_config in json_dict[\"teacher_models\"]]\n        else:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in DEFAULT_TEACHER_MODEL_NAMES]\n        \n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.get_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL], self.distilled_model)\n        self.current_model_stats = json_dict[DISTILLED_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        self.teacher_models = [config_factory.get_model_config(teacher_model, self.teacher_models[i]) for i, teacher_model in enumerate(json_dict[TEACHER_MODELS])]\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[DISTILLED_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[TEACHER_MODEL]]\n        return self\n    "}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config_from_dict(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[DISTILLED_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.load_model_config_from_dict(teacher_model) for teacher_model in json_dict[TEACHER_MODEL]]\n        return self\n    "}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_config_from_dict(\n            model_name=json_dict[DISTILLED_MODEL],\n            model_type=DISTILLED_MODEL,\n            model_name_in_dict=json_dict[\"distilled_model\"]\n        )\n        self.current_model_stats = json_dict[CURRENT_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [\n                config_factory.create_config_from_dict(\n                    model_name=teacher_model,\n                    model_type=TEACHER_MODEL,\n                    model_name_in_dict=teacher_model)\n                for teacher_model in json_dict[TEACHER_MODEL]]\n\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[DISTILLED_MODEL_STATS]\n        self.last_training_run = json_dict[LAST_TRAINING_RUN]\n        self.current_training_run = json_dict[CURRENT_TRAINING_RUN]\n        self.nr_of_training_runs = json_dict[NR_OF_TRAINING_RUNS]\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[TEACHER_MODELS]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get(DISTILLED_MODEL, DEFAULT_DISTILLED_MODEL_NAME))\n        self.current_model_stats = json_dict.get(DISTILLED_MODEL_STATS, {})\n        self.last_training_run = json_dict.get(LAST_TRAINING_RUN, {})\n        self.current_training_run = json_dict.get(CURRENT_TRAINING_RUN, {})\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict.get(TEACHER_MODELS, DEFAULT_TEACHER_MODELS.keys())]\n        self.nr_of_training_runs = json_dict.get(TRAINING_RUNS, 0)\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        \n        self.distilled_model = config_factory.get_model_config(\n            json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict.get(\"current_model_stats\", self.current_model_stats)\n        self.last_training_run = json_dict.get(\"last_training_run\", self.last_training_run)\n        self.current_training_run = json_dict.get(\"current_training_run\", self.current_training_run)\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", self.nr_of_training_runs)\n        teacher_models = json_dict.get(\"teacher_models\", self.teacher_models)\n        if teacher_models is not None:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in teacher_models]\n        return self\n    "}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get(DISTILLED_MODEL))\n        self.current_model_stats = json_dict.get(MODEL_STATS)\n        self.last_training_run = json_dict.get(LAST_TRAINING_RUN)\n        self.current_training_run = json_dict.get(CURRENT_TRAINING_RUN)\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict.get(TEACHER_MODEL, [])]\n        self.nr_of_training_runs = json_dict.get(TRAINING_RUNS)\n        return self\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # check if the API key is set\n        self.check_api_key()\n\n        # validate the model\n        self.validate_model(model)\n\n        # validate the system message\n        self.validate_system_message(system_message)\n\n        # validate the prompt\n        self.validate_prompt(prompt)\n\n        # validate the additional parameters\n        self.validate_additional_parameters(kwargs)\n\n        # set the model name\n        model_name = model.model_name\n\n        # set the additional parameters\n        temperature = kwargs.get(\"temperature\")\n        top_p = kwargs.get(\"top_p\")\n        max_new_tokens = kwargs.get(\"max_new_tokens\")\n        frequency_penalty = kwargs.get(\"frequency_penalty\")\n        presence_penalty = kwargs.get(\"presence_penalty\")\n\n        # set the additional parameters\n        additional_parameters = {\n            \"model\": model_name,\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n            \"max_new_tokens\": max_new_tokens,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty\n        }\n\n        # set the system message\n        additional_parameters[\"system_message\"] = system_message\n\n        # set the prompt\n        additional_parameters[\"prompt\"] = prompt\n\n        # set the prompter\n        additional_parameters[\"prompter\"] = model.prompter\n\n        # set the prompter_params\n        additional_parameters[\"prompter_params\"] = model.prompter_params\n\n        # set the prompter_model_name\n        additional_parameters[\"prompter_model_name\"] = model.prompter_model_name\n\n        # set the prompter_model_version\n        additional_parameters[\"prompter_model_version\"] = model.prompter_model_version\n\n        # set the prompter_model_url\n        additional_parameters[\"prompter_model_url\"] = model.prompter_model_url\n\n        # set the prompter_model_id\n        additional_parameters[\"prompter_model_id\"] = model.prompter_model_id\n\n        # set the prompter_model_type\n        additional_parameters"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # check for api key\n        self.check_api_key()\n\n        # validate parameters\n        self.validate_parameters(model)\n        self.validate_parameters(kwargs)\n\n        # create miniaturisation request\n        request_params = {\n            \"model\": model.model_name,\n            \"temperature\": kwargs.get(\"temperature\", model.temperature),\n            \"top_p\": kwargs.get(\"top_p\", model.top_p),\n            \"frequency_penalty\": kwargs.get(\n                \"frequency_penalty\", model.frequency_penalty\n            ),\n            \"presence_penalty\": kwargs.get(\n                \"presence_penalty\", model.presence_penalty\n            ),\n            \"max_new_tokens\": kwargs.get(\"max_new_tokens\", model.max_new_tokens),\n            \"max_tokens\": kwargs.get(\"max_tokens\", 100),\n        }\n\n        # miniaturisation response\n        response = self mozaic_api_request(\n            \"post\",\n            OPENAI_URL,\n            request_params,\n            system_message,\n            prompt,\n            model.parsing_helper_tokens,\n        )\n\n        # remove parsing helper tokens\n        response_text = miniaturisation_response_text(response)\n\n        # return miniaturisation response\n        return miniaturisation_response_text(response)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # check if the API key is set\n        self.check_api_key()\n        # check if the model is set\n        self.check_model(model)\n        # check if the system message is set\n        self.check_system_message(system_message)\n        # check if the prompt is set\n        self.check_prompt(prompt)\n\n        # set the default parameters\n        default_parameters = {\n            \"model\": model.model_name,\n            \"temperature\": 0.9,\n            \"top_p\": 1,\n            \"max_new_tokens\": 30,\n            \"frequency_penalty\": 1.2,\n            \"presence_penalty\": 0.6,\n        }\n        # set the parameters\n        parameters = copy.deepcopy(default_parameters)\n        parameters.update(kwargs)\n        # set the headers\n        headers = {\n            \" spionai-api-key\": self.api_key,\n            \"Content-Type\": \"application/json\",\n        }\n\n        # set the body\n        body = {\n            \"model\": model.model_name,\n            \"prompt\": prompt,\n            \"system_message\": system_message,\n            \"temperature\": parameters.get(\"temperature\"),\n            \"top_p\": parameters.get(\"top_p\"),\n            \"max_new_tokens\": parameters.get(\"max_new_tokens\"),\n            \"frequency_penalty\": parameters.get(\"frequency_penalty\"),\n            \"presence_penalty\": parameters.get(\"presence_penalty\"),\n        }\n        # send the request\n        response = self.send_request(headers, body)\n        # parse the response\n        response = self.parse_response(response)\n        # return the response\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check if the API key is provided\n        self.check_api_key()\n\n        # Validate the parameters\n        self.validate_parameters(LLM_GENERATION_PARAMETERS, kwargs)\n\n        # Set up the parameters for the generation request\n        temperature = kwargs.get(\"temperature\", 0.0)\n        top_p = kwargs.get(\"top_p\", 1.0)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0.0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0.0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 10)\n\n        # Create the generation request\n        response = self.client.completion.create(\n            model=model.model_name,\n            prompt=prompt,\n            temperature=temperature,\n            top_p=top_p,\n            frequency_penalty=frequency_penalty,\n            presence_penalty=presence_penalty,\n            max_new_tokens=max_new_tokens,\n            stop=system_message,\n        )\n\n        # Remove the parsing helper tokens from the response\n        text = response.get(\"choices\")[0].get(\"text\")\n\n        # Return the generated text\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate parameters\n        for parameter in kwargs.keys():\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(\n                    f\"Parameter {parameter} is not supported. Supported parameters are: {LLM_GENERATION_PARAMETERS}\")\n\n        # set the model name\n        model_name = model.model_name\n\n        # set the parsing helper tokens\n        parsing_helper_tokens = model.parsing_helper_tokens\n\n        # set the promp\n        prompt = f\"{system_message}{parsing_helper_tokens.prefix}{prompt}{parsing_helper_tokens.suffix}\"\n\n        # set the response\n        response = None\n\n        # set the backoff\n        backoff = 1\n\n        # set the backoff time\n        backoff_time = 1\n\n        # set the retry count\n        retry_count = 0\n\n        # set the retry limit\n        retry_limit = 5\n\n        # set the response\n        response = None\n\n        # set the response\n        response = self.client.completions.create(\n            model=model_name,\n            prompt=prompt,\n            n=1,\n            top_p=kwargs.get(\"top_p\", 1),\n            temperature=kwargs.get(\"temperature\", 0.0),\n            max_tokens=kwargs.get(\"max_new_tokens\", 0),\n            frequency_penalty=kwargs.get(\"frequency_penalty\", 0.0),\n            presence_penalty=kwargs.get(\"presence_penalty\", 0.0)\n        )\n\n        # if the response is not None, return the response\n        if response is not None:\n            return response.data.choices[0].text\n\n        # set the response\n        response = None\n\n        # set the backoff\n        backoff = 1\n\n        # set the backoff time\n        backoff_time = 1\n\n        # set the retry count\n        retry_count = 0\n\n        # set the retry limit\n        retry_limit = 5\n\n        # set the response\n        response = None\n\n        # set the response\n        response = self.client.completions.create(\n            model=model_name,"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.validate_parameters(LLM_GENERATION_PARAMETERS, kwargs)\n\n        try:\n            response = self.client.completions.create(\n                model=model.model_name,\n                prompt=f\"{system_message}{prompt}\",\n                temperature=kwargs.get(\"temperature\"),\n                top_p=kwargs.get(\"top_p\"),\n                max_new_tokens=kwargs.get(\"max_new_tokens\"),\n                frequency_penalty=kwargs.get(\"frequency_penalty\"),\n                presence_penalty=kwargs.get(\"presence_penalty\")\n            )\n            return self.process_response(response)\n        except Exception as e:\n            return self.retry_on_failure(e, model, system_message, prompt, **kwargs)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate parameters\n        for key geometrics in kwargs:\n            if geometrics not in LLM_GENERATION_PARAMETERS:\n                raise Exception(f\"Unknown parameter: {geometrics}\")\n\n        # set default parameters\n        temperature = kwargs.get(\"temperature\", 0.8)\n        top_p = kwargs.get(\"top_p\", 0.9)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 20)\n\n        # set default parameters for embletting\n        model_name = model.model_name\n        parsing_helper_tokens = model.parsing_helper_tokens\n\n        # set default parameters for embletting\n        model_name = model.model_name\n        parsing_helper_tokens = model.parsing_helper_tokens\n\n        # generate the response\n        response = self.client.completions.create(\n            model=model_name,\n            prompt=prompt,\n            temperature=temperature,\n            max_new_tokens=max_new_tokens,\n            top_p=top_p,\n            frequency_penalty=frequency_penalty,\n            presence_penalty=presence_penalty,\n            stop=system_message\n        )\n\n        # process the response\n        response_text = response.get(\"choices\")[0].get(\"text\")\n        if parsing_helper_tokens:\n            response_text = response_text.replace(parsing_helper_tokens[0], \"\")\n\n        # return the response\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # handle OpenAI API key\n        self.check_api_key()\n\n        # validate parameters\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise Exception(\n                    f\"Invalid parameter {key}. Valid parameters are: {LLM_GENERATION_PARAMETERS}\"\n                )\n\n        # set parameters\n        parameters = {\n            \"model\": model.model_name,\n            \"max_tokens\": kwargs.get(\"max_new_tokens\", 1024),\n            \"temperature\": kwargs.get(\"temperature\", 0.0),\n            \"top_p\": kwargs.get(\"top_p\", 1.0),\n            \"frequency_penalty\": kwargs.get(\"frequency_penalty\", 0.0),\n            \"presence_penalty\": kwargs.get(\"presence_penalty\", 0.0),\n        }\n\n        # add parsing helper tokens\n        for parsing_helper_token in model.parsing_helper_tokens:\n            parameters[parsing_helper_token] = True\n\n        # generate response\n        response = self.client.completions.create(\n            engine=model.model_name,\n            prompt=system_message + prompt,\n            max_tokens=1024,\n            n=1,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            stop=[\"\\n\", \"<|endoftext|>\"],\n            **parameters\n        )\n        # remove parsing helper tokens\n        for parsing_helper_token in model.parsing_helper_tokens:\n            response.data.text = response.data.text.replace(\n                parsing_helper_token, \"\"\n            )\n\n        # return response\n        return response.data.text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # check if the API key is set\n        self.check_api_key()\n\n        # set the model name\n        model_name = model.model_name\n\n        # set the parameters for the generation request\n        params = {\n            \"model\": model_name,\n            \"temperature\": kwargs.get(\"temperature\", 0.9),\n            \"top_p\": kwargs.get(\"top_p\", 1.0),\n            \"frequency_penalty\": kwargs.get(\"frequency_penalty\", 1.0),\n            \"presence_penalty\": kwargs.get(\"presence_penalty\", 0.0),\n            \"max_new_tokens\": kwargs.get(\"max_new_tokens\", 100),\n            \"stop\": kwargs.get(\"stop\"),\n        }\n\n        # set the message and prompt\n        message = f\"System: {system_message}\\n\"\n        prompt = prompt\n\n        # set the API URL\n        url = f\"{OPENAI_URL}\"\n\n        # set the headers\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\"\n        }\n\n        # set the data\n        data = {\n            \"prompt\": message,\n            \" rech_model\": model_name,\n        }\n\n        # set the number of retries\n        retries = 0\n        while retries < 5:\n            try:\n                # make the request\n                response = requests.post(url, headers=headers, data=data)\n                # check the response status code\n                response_code = response.status_code\n                if response_code == 200:\n                    # parse the response\n                    response_data = response.json()\n                    # remove any parsing helper tokens\n                    response_text = response_data[\"choices\"][0][\"text\"]\n                    return response_text\n                else:\n                    # handle the error\n                    logging.error(f\"Error {response_code}: {response.text}\")\n                    retries += 1\n            except Exception as e:\n                logging.error(f\"Error: {e}\")\n                retries += 1\n\n        # return the final text\n        return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter not in kwargs:\n                continue\n            if parameter not in model.generation_parameters:\n                raise ValueError(f\"The {parameter} parameter is not supported by the {model.model_name} model.\")\n        # set default parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter not in kwargs:\n                kwargs[parameter] = model.generation_parameters[parameter]\n\n        # create the request\n        request palet = {\n            \"model\": model.model_name,\n            \"prompt\": prompt,\n            \"max_tokens\": 256,\n            \"temperature\": kwargs.get(\"temperature\"),\n            \"top_p\": kwargs.get(\"top_p\"),\n            \"frequency_penalty\": kwargs.get(\"frequency_penalty\"),\n            \"presence_penalty\": kwargs.get(\"presence_penalty\"),\n            \"max_new_tokens\": kwargs.get(\"max_new_tokens\"),\n            \"user_input\": system_message\n        }\n\n        # send the request\n        retries = 3\n        response = None\n        while retries > 0:\n            try:\n                response = self.client.completions.create(request)\n                retries = 0\n            except requests.RequestException as e:\n                print(f\"Error {e} occured, retrying...\")\n                retries -= 1\n                time.sleep(2 ** retries)\n\n        # remove parsing helper tokens\n        text = response.get(\"choices\")[0].get(\"text\")\n        if model.parsing_helper_tokens:\n            for parsing_helper_token in model.parsing_helper_tokens:\n                text = text.replace(parsing_helper_token, \"\")\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check if the API key has been set\n        self.check_api_key()\n\n        # Validate the model configuration\n        self.validate_model_config(model)\n\n        # Get the model name and parsing helper tokens from the model configuration\n        model_name = model.model_name\n        parsing_helper_tokens = model.parsing_helper_tokens\n\n        # Validate the parameters\n        self.validate_parameters(kwargs, LLM_GENERATION_PARAMETERS, LLMs_with_parsing_helper_tokens=[model_name])\n\n        # Set the parameters for the OpenAI API\n        parameters = {\n            \"model\": model_name,\n            \"temperature\": kwargs patro_kwargs.get(\"temperature\", 0.8),\n            \"top_p\": patro_kwargs.get(\"top_p\", 1),\n            \"max_new_tokens\": patro_kwargs.get(\"max_new_tokens\", 40),\n            \"frequency_penalty\": patro_kwargs.get(\"frequency_penalty\", 0),\n            \"presence_penalty\": patro_kwargs.get(\"presence_penalty\", 0)\n        }\n\n        # Send the request to the OpenAI API\n        response = self.client.completions.create(\n            model=model_name,\n            prompt=system_message + prompt,\n            temperature=parameters[\"temperature\"],\n            max_tokens=parameters[\"max_new_tokens\"],\n            top_p=parameters[\"top_p\"],\n            frequency_penalty=parameters[\"frequency_penalty\"],\n            presence_penalty=parameters[\"presence_penalty\"],\n        )\n\n        # Process the response to remove any parsing helper tokens\n        text = response[\"choices\"][0][\"text\"].strip()\n        if parsing_helper_tokens:\n            for parsing_helper_token in parsing_helper_tokens:\n                text = text.replace(parsing_helper_token, \"\")\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.check_parameters(LLM_GENERATION_PARAMETERS, kwargs)\n        # Initialize the OpenAI client.\n        response = None\n        # Set the default parameters.\n        temperature = kwargs.get(\"temperature\", 0.6)\n        top_p = kwargs.get(\"top_p\", 1.0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 40)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 1.0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0.0)\n        # Set the parameters for the generation request.\n        parameters = {\n            \"model\": model.model_name,\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n            \"max_tokens\": max_new_tokens,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"stop\": model.parsing_helper_tokens,\n        }\n        # Retry the generation request up to 5 times with exponential backoff.\n        for i in range(5):\n            try:\n                response = self.client.completions.create(\n                    model=parameters[\"model\"],\n                    prompt=prompt,\n                    temperature=parameters[\"temperature\"],\n                    top_p=parameters[\"top_p\"],\n                    max_tokens=parameters[\"max_tokens\"],\n                    frequency_penalty=parameters[\"frequency_penalty\"],\n                    presence_penalty=parameters[\"presence_penalty\"],\n                    stop=parameters[\"stop\"],\n                    # buc_beam_width=parameters[\"buc_beam_width\"],\n                    # buc_max_length=parameters[\"buc_max_length\"],\n                    # buc_top_p=parameters[\"buc_top_p\"],\n                )\n            except Exception as e:\n                logging.warning(f\"OpenAI generation request failed: {e}\")\n                time.sleep(2 ** i)\n        # Remove the parsing helper tokens from the response.\n        text = response.text\n        # Return the generated text.\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.check_parameters(model.model_name, LLM_GENERATION_PARAMETERS)\n        # TODO: add robustification\n\n        # Set the model name and parameters for the generation request.\n        model_name = model.model_name\n        parameters = {\n            \"model\": model_name,\n            \"temperature\": kwargs.get(\"temperature\", 0.9),\n            \"top_p\": kwargs.get(\"top_p\", 0.9),\n            \"max_new_tokens\": kwargs.get(\"max_new_tokens\", 10),\n            \"frequency_penalty\": kwargs.get(\"frequency_penalty\", 0 fundament_model_name.0),\n            \"presence_penalty\": kwargs.get(\"presence_penalty\", 0.0),\n        }\n\n        # Set the system message and prompt for the generation request.\n        system_message = system_message.strip()\n        prompt = prompt.strip()\n\n        # Create the generation request.\n        request = {\n            \"model\": model_name,\n            \"prompt\": system_message + \"\\n\" + prompt,\n            \"temperature\": parameters[\"temperature\"],\n            \"top_p\": parameters[\"top_p\"],\n            \"max_tokens\": parameters[\"max_new_tokens\"],\n            \"frequency_penalty\": parameters[\"frequency_penalty\"],\n            \"presence_penalty\": parameters[\"presence_penalty\"],\n        }\n\n        # Initialise the response\n        response = None\n\n        # Initialise the number of retries.\n        retries = 0\n\n        # Retry the request up to 5 times with exponential backoff.\n        while response is None and retries < 5:\n            try:\n                # Make the generation request to the OpenAI API.\n                response = self.client.completions.create(request=request)\n                # Check if the response is valid.\n                if response.object == \"completion\":\n                    # Remove any parsing helper tokens from the response.\n                    text = response.choices[0].text\n                    # Return the generated text.\n                    return text\n                else:\n                    # Log the error and set the response to None.\n                    logging.error(f\"The response from the OpenAI API is not"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.check_parameters(LLM_GENERATION_PARAMETERS, kwargs)\n\n        # Set the maximum number of retries and the backoff factor.\n        retries = 3\n        backoff_factor = 2\n        # Set the initial sleep time.\n        sleep_time = 1\n\n        # Retry the generation request up to 5 times with exponential backoff.\n        for i in range(retries):\n            try:\n                # Generate the response from the OpenAI API.\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    max_tokens=model.max_tokens,\n                    temperature=kwargs patro_kwargs.get(\"temperature\", model.temperature),\n                    top_p=kwargs patro_kwargs.get(\"top_p\", model.top_p),\n                    frequency_penalty=kwargs patro_kwargs.get(\"frequency_penalty\", model.frequency_penalty),\n                    presence_penalty=kwargs patro_kwargs.get(\"presence_penalty\", model.presence_penalty),\n                    max_new_tokens=kwargs patro_kwargs.get(\"max_new_tokens\", model.max_new_tokens),\n                    stop=model.parsing_helper_tokens\n                )\n                # Break the loop if the response is successful.\n                if response.object == \"completion\":\n                    break\n                # Exponential backoff if the response is not successful.\n                sleep_time *= backoff_factor\n                time.sleep(sleep_time)\n            except Exception as e:\n                # Log the error message and the current retry count.\n                print(f\"An error occurred: {e} - {i}\")\n                # Exponential backoff if the response is not successful.\n                sleep_time *= backoff_factor\n                time.sleep(sleep_time)\n        # Process the response to remove any parsing helper tokens.\n        response_text = response.choices[0].text.replace(model.parsing_helper_tokens, \"\")\n        # Return the generated text response.\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.check_generation_parameters(kwargs)\n        # set default values for any missing parameters\n        kwargs.setdefault(\"temperature\", 1)\n        kwargs.setdefault(\"top_p\", 1)\n        kwargs.setdefault(\"max_new_tokens\", 30)\n        kwargs.setdefault(\"frequency_penalty\", 0)\n        kwargs.setdefault(\"presence_penalty\", 0)\n\n        # set the model name\n        model_name = model.model_name\n\n        # set the parsing helper tokens\n        parsing_helper_tokens = model.parsing_helper_tokens\n\n        # set the endpoint\n        endpoint = f\"{OPENAI_URL}?model={model_name}\"\n\n        # set the headers\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\", \"Content-Type\": \"application/json\"}\n\n        # set the body\n        body = {\" finis\": system_message, \"prompt\": prompt, \"max_tokens\": 200, \"n\": 1, \"stop\": parsing_helper_tokens}\n        body.update(kwargs)\n\n        # set the response\n        response = None\n\n        # set the retries\n        retries = 0\n        retries_max = 5\n        backoff_factor = 0.5\n\n        # retry up to 5 times with exponential backoff\n        while response is None and retries < retries_max:\n            try:\n                # make the request\n                response = requests.post(endpoint, headers=headers, json=body)\n                response.raise_for_status()\n            except Exception as e:\n                # handle the exception\n                print(f\"An error occurred: {e}\")\n                logging.error(e)\n                retries += 1\n                time.sleep(retries * backoff_factor)\n            else:\n                # process the response\n                response = response.json()[\"choices\"][0][\"text\"]\n                response = response.replace(parsing_helper_tokens, \"\")\n\n        # return the response\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Handle API key verification\n        self.check_api_key()\n\n        # Validate parameters\n        for key legendarge_parameter in LLM_GENERATION_PARAMETERS:\n            if legendarge_parameter in kwargs:\n                if legendarge_parameter == \"top_p\":\n                    kwargs[key] = kwargs[key] / 100\n                elif legendarge_parameter == \"max_new_tokens\":\n                    kwargs[key] = kwargs[key] - 1\n                else:\n                    kwargs[key] = kwargs[key]\n\n        # Retry on failure up to 5 times with exponential backoff\n        retries = 0\n        while retries < 5:\n            try:\n                # Make the request\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n\n                # Handle the response\n                response_text = response.choices[0].text\n                response_text = response_text.replace(model.parsing_helper_token, \"\")\n                return response_text\n            except Exception as e:\n                logging.error(f\"An error occurred: {e}\")\n                retries += 1\n                if retries < 5:\n                    time.sleep(2**retries)\n                else:\n                    raise\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        if not model.is_valid():\n            raise ValueError(\n                \"The model configuration provided is not valid. Please check that the model name is correct and that the parsing helper tokens are correctly configured.\"\n            )\n\n\n        # handle parameters\n        temperature = kwargs.get(\"temperature\", 0.8)\n        top_p = kwargs.get(\"top_p\", 1.0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 30)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0.0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0.0)\n\n        if temperature is not None:\n            temperature = max(0, temperature)\n            temperature = min(1.0, temperature)\n        if top_p is not None:\n            top_p = max(0, top_p)\n            top_p = min(1.0, top_p)\n        if max_new_tokens is not None:\n            max_new_tokens = max(0, max_new_tokens)\n            max_new_tokens = min(500, max_new_tokens)\n        if frequency_penalty is not None:\n            frequency_penalty = max(0, frequency_penalty)\n            frequency_penalty = min(1.0, frequency_penalty)\n        if presence_penalty is not None:\n            presence_penalty = max(0, presence_penalty)\n            presence_penalty = min(1.0, presence_penalty)\n\n        # build the request\n        request drap = {\n            \"model\": model.model_name,\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n            \"max_new_tokens\": max_new_tokens,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"purpose\": \"chat\",\n            \"stop\": model.stop,\n            \"prompt\": f\"{system_message} {model.prompt}\",\n            \"user_input\": prompt\n        }\n\n        # make the request\n        response = self.request(request drap)\n\n        # handle the"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # check if the API key is set\n        self.check_api_key()\n\n        # validate the parameters\n        for parameter in kwargs:\n            if parameter not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"The parameter '{parameter}' is not supported for OpenAI API generation.\")\n\n        # initialize the OpenAI client\n        self.client = OpenAI(self.api_key)\n\n        # set the default parameters\n        kwargs = copy.copy(kwargs)\n        kwargs.update({\n            \"model\": model.model_name,\n            \"temperature\": 0.6,\n            \"top_p\": 1.0,\n            \"max_new_tokens\": 100,\n            \"frequency_penalty\": 0.0,\n            \"presence_penalty\": 0.0\n        })\n\n        # set the default parsing helper tokens\n        model.set_parsing_helper_tokens()\n\n        # set the system message and prompt\n        kwargs[\"prompt\"] = system_message + prompt\n\n        # generate the response\n        response = self.client.completion(kwargs)\n        response_text = response[\"choices\"][0][\"text\"]\n\n        # remove any parsing helper tokens\n        for token in model.parsing_helper_tokens:\n            response_text = response_text.replace(token, \"\")\n\n        # return the response text\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate parameters\n        for param in kwargs:\n            if param not in LLM_GENERATION_PARAMETERS:\n                logging.error(f\"Unknown parameter {param}. Valid parameters are {LLM_GENERATION_PARAMETERS}\")\n                return None\n\n        # Generate response\n        response = None\n        retries = 0\n        while retries < 5:\n            try:\n                response = self.client.completions.create(\n                    model=model.model_name,\n                    temperature=kwargs.get(\"temperature\", 0.8),\n                    max_new_tokens=kwargs.get(\"max_new_tokens\", 10),\n                    frequency_penalty=kwargs.get(\"frequency_penalty\", 0),\n                    presence_penalty=kwargs.get(\"presence_penalty\", 0),\n                    top_p=kwargs.get(\"top_p\", 1.0),\n                    prompt=f\"{system_message} {prompt}\",\n                    max_tokens=kwargs.get(\"max_tokens\", 40),\n                    stop=model.stop_tokens,\n                )\n                break\n            except Exception as e:\n                logging.error(f\"OpenAI error: {e}\")\n                retries += 1\n                time.sleep(2 ** retries)\n\n        if response is not None:\n            # Remove parsing helper tokens\n            response = response.replace(model.parsing_helper_token, \"\")\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate parameters\n        parameters = {}\n        for key, value in kwargs.items():\n            if key in LLM_GENERATION_PARAMETERS:\n                parameters[key] = value\n            else:\n                logging.warning(f\"Parameter '{key}' is not a valid OpenAI generation parameter.\")\n\n        # Retry on failure\n        for _ in range(5):\n            try:\n                response = self.client.completion(model.model_name, system_message, prompt, **parameters)\n                if response:\n                    return response.text_1\n                    # return self.remove_parsing_helper_tokens(response.text_1)\n            except Exception as e:\n                if _ == 4:\n                    raise e\n                logging.warning(f\"Error: {e} - Retrying in 3 seconds...\")\n                time.sleep(3)\n\n        return None\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if np.any(x != x.T):\n        raise ValueError(\"The matrix is not symmetric.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if np.allclose(x, x.T, atol=1e-12):\n        return\n    raise ValueError(\"The matrix is not symmetric.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.all(x == x.T):\n        raise ValueError(\"The matrix is not symmetric.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.array_equal(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.all(np.isclose(x, x.T)):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    if not np.all(x == np.transpose(x)):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if np.any(np.abs(x - x.T) > 1e-10):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if np.any(x[np.diag_indices(x.shape[0]) > 0.0):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    assert_is_symmetric(x)\n    if np.any(np.abs(x.diagonal() - 0) > 1e-12):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x, np.diag(np.full(x.shape[0], 0)) or np.any(x < 0)):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    # The distance matrix is symmetric and the diagonal elements are close to zero.\n    if not np.allclose(x, 0, atol=1e-10):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\n            \"The matrix must be a distance matrix. It must be square and the diagonal elements must be close to zero.\"\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    # Check if the matrix is a distance matrix\n    if np.any(np.abs(x) < 1e-5):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x, np.abs(x)):\n        raise ValueError(\"The matrix must be non-negative\")\n    if not np.allclose(x, x - np.diag(np.diag(x))):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.all(np.isclose(x.diagonal(), 0)):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), np.zeros_like(x)):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), np.zeros_like(x.diagonal())):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if np.any(np.abs(x[np.diag_indices(x.shape[0])]) > 1e-6):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if np.any(np.abs(x) > 1e-12):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x, np.zeros(x.shape), atol=1e-9):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if np.any(np.abs(x.diagonal()) > 1e-3):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0.0):\n        raise ValueError(\"The diagonal must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x, np.diag(np.zeros(x.shape[0]))):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), np.zeros_like(x)):\n        raise ValueError(\"The matrix must be a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n\n    # If the matrix is a distance matrix, all of its diagonal elements should be close to zero.\n    if not np.allclose(x, np.zeros(x.shape), rtol=1e-5):\n        raise ValueError(\"The matrix is not a distance matrix\")\n\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            # if it is, check if the model is suitable for distillation\n            if current_function_setup[\"suitable_for_finetuning\"]:\n                # if it is suitable for distillation, check if the model is already initialized\n                if current_function_setup[\"model\"] != \"\":\n                    # if it is initialized, return the prompt, model, and a boolean indicating if the model is suitable for distillation\n                    return current_function_setup[\"prompt\"], current_function_setup[\"model\"], False, False\n            # if it is not suitable for distillation, check if the model is already initialized\n        if current_function_setup[\"model\"] != \"\":\n            # if it is initialized, return the prompt, model, and a boolean indicating if the model is suitable for distillation\n            return current_function_setup[\"prompt\"], current_function_setup[\"model\"], False, True\n        # if the function is not initialized, check if the model is suitable for distillation\n        if function_description.suitable_for_distillation:\n            # if it is suitable for distillation, initialize the function and return the prompt, model, and a boolean indicating if the model is suitable for distillation\n            self.initialize_function(func_hash, function_description, llm_parameters)\n            return self.initialized_functions[func_hash][\"prompt\"], self.initialized_functions[func_hash][\"model\"], True, False\n        # if the model is not suitable for distillation, check if the model is already initialized\n        if current_function_setup[\"model\"] != \"\":\n            # if it is initialized, return the prompt, model, and a boolean indicating if the model is suitable for distillation\n            return current_function_setup[\"prompt\"], current_function_setup[\"model\"], False, True\n        # if the model is not suitable for distillation and not initialized, return the prompt, model, and a boolean indicating if the model is suitable for distillation\n        return self.initialize_function(func_hash, function_description, llm_parameters), \"\", False, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description, llm_parameters, func_hash)\n        \n        # get the prompt\n        prompt = self.get_prompt(args, kwargs, function_description)\n\n        # get the save_to_finetune\n        save_to_finetune = self.save_to_finetune(function_description, llm_parameters)\n\n        # get the distilled_model\n        is_distilled_model = self.is_distilled_model(model, llm_parameters)\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # TODO: Make this configurable\n        token_limit = llm_parameters.get(\"max_new_tokens\", self.default_generation_length)\n\n        # If the function is not finishtuned, use the teacher model.\n        if not self.function_modeler.is_finetuned(func_hash):\n            # If the function is finishtuned, use the distilled model.\n            # If the function is finishtuned, use the distilled model.\n            if self.function_modeler.is_distilled(func_hash):\n                # If the function is finishtuned, use the distilled model.\n                # If the function is finishtuned, use the distilled model.\n                model = self.function_modeler.get_model(func_hash)\n                is_distilled = True\n                # If the function is finishtuned, use the distilled model.\n                # If the function is finishtuned, use the distilled model.\n                save_to_finetune = False\n            else:\n                # If the function is finishtuned, use the distilled model.\n                # If the function is finishtuned, use the distilled model.\n                model = self.function_modeler.get_model(func_hash)\n                is_distilled = False\n                # If the function is finishtuned, use the distilled model.\n                # If the function is finishtuned, use the distilled model.\n                save_to_finetune = True\n        else:\n            # If the function is finishtuned, use the distilled model.\n            # If the function is finishtuned, use the distilled model.\n            model = self.function_modeler.get_model(func_hash)\n            is_distilled = True\n            # If the function is finishtuned, use the distilled model.\n            # If the function is finishtuned, use the distilled model.\n            save_to_finetune = False\n        \n        # If the function is finishtuned, use the distilled model.\n        # If the function is finishtuned, use the distilled model.\n        if is_distilled:\n            # If the function is finishtuned, use the distilled model.\n            # If"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description, llm_parameters)\n        # get the prompt\n        prompt = self.get_prompt(args, kwargs, function_description, model)\n        # get the alignemnt statements\n        examples = self.get_examples(func_hash, function_description, model)\n        # check if the model is suitable for distillation\n        is_suitable = self.check_model_suitable_for_distillation(examples)\n        # check if the model is already initialized\n        is_initialized = self.check_function_initialized(func_hash)\n\n        return prompt, model, is_suitable, is_initialized\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model to use for generation\n        model = self.get_model(function_description, llm_parameters, func_hash)\n        # get the prompt to use for generation\n        prompt = self.get_prompt(args, kwargs, function_description, model)\n        # determine if the model is suitable for distillation\n        suitable_for_distillation = model.suitable_for_distillation(self.function_modeler, function_description)\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        is_initialized = func_hash in self.initialized_functions\n        # if the model is suitable for distillation and the function is not initialized, save the examples for fine-tuning\n        if suitable_for_distillation and not is_initialized:\n            self.save_to_finetune_dataset(func_hash, function_description, args, kwargs)\n        # if the function is already initialized, check if the model has changed and update the examples for fine-tuning if necessary\n        elif is_initialized and not model.model_name == self.initialized_functions[func_hash][\"model\"]:\n            self.update_examples(func_hash, function_description, args, kwargs)\n        # return the generated prompt, model, a boolean indicating if the model is suitable for distillation, and a boolean indicating if the function is already initialized and does not require saving examples for fine-tuning\n        return prompt, model, suitable_for_distillation, is_initialized\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description)\n\n        # get the alignables\n        alignables = self.get_alignables(function_description)\n\n        # get the alignables for this function\n        alignables_for_func = alignables.get(function_description.__hash__(), None)\n\n        # get the alignables for this function\n        if alignables_for_func is None:\n            alignables_for_func = alignables[function_description.__hash__()]\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func.copy()\n        \n        # get the alignables for this function\n        # alignables_for_func_set.update(alignables)\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func_set.union(alignables)\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func_set.intersection(self.initialized_functions.get(func_hash, set()))\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func_set.difference(self.initialized_functions.get(func_hash, set()))\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func_set.difference(self.token_counts.get(func_hash, set()))\n\n        # get alignables for this function\n        alignables_for_func_set = alignables_for_func_set.intersection(self.token_counts.get(func_hash, set()))\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func_set.intersection(set(kwargs.keys()))\n\n        # get the alignables for this function\n        alignables_for_func_set = alignables_for_func_set.difference(set(llm_parameters.keys()))\n\n        # get the alignables for this function\n        al"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the model is initialized\n        # TODO: refactor this to use a function modeler\n        current_function_setup = self.initialized_functions.get(func_hash, None) # getting the current function setup - model and align statements\n        if current_function_setup is None:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": [],\n            }\n            # get the model\n            model, save_to_finetune = self.get_model(function_description, llm_parameters)\n            # get the prompt\n            prompt = self.get_prompt(function_description, args, kwargs)\n            return prompt, model, save_to_finetune, False\n        else:\n            # if it's not the first time, check if the model is the same\n            if current_function_setup[\"model\"] != \"\":\n                # if the model is the same, check if the examples need to be saved\n                if current_function_setup[\"model\"] != self.get_model(function_description, llm_parameters):\n                    # if the model is different, we need to save the examples\n                    save_to_finetune = True\n                    # get the prompt\n                    prompt = self.get_prompt(function_description, args, kwargs)\n                    return prompt, model, save_to_finetune, True\n                else:\n                    # if the model is the same, we don't need to save the examples\n                    save_to_finetune = False\n                    # get the prompt\n                    prompt = current_function_setup[\"prompt\"]\n                    return prompt, model, save_to_finetune, False\n            else:\n                # if the model is empty, we need to save the examples\n                save_to_finetune = True\n                # get the prompt\n                prompt = self.get_prompt(function_description, args, kwargs)\n                return prompt, model, save_to_finetune, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description, llm_parameters, func_hash)\n        if model.is_distilled and not self.initialized_functions.get(func_hash, False):\n            # if the model is distilled, but the function is not initialized, we have to initialize the function\n            self.initialize_function(function_description, args, kwargs)\n        elif not model.is_distilled and self.initialized_functions.get(func_hash, False):\n            # if the model is not distilled, but the function is initialized, we have to update the function with the new datapoint\n            self.update_function(function_description, args, kwargs)\n\n        # construct the prompt\n        return self.construct_prompt(function_description, args, kwargs), model, model.is_distilled, self.initialized_functions.get(func_hash, False)\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description)\n        # check if the model is suitable for distillation\n        suitable_for_distillation = model.is_suitable_for_distillation()\n        # check if the function is already initialized\n        is_initialized = self.initialized_functions.get(func_hash, None)\n        if not is_initialized:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n            self.initialized_functions[func_hash][\"examples\"] = []\n        # check if the function is suitable for distillation and the model is suitable\n        if suitable_for_distillation and model.is_suitable_for_distillation():\n            # if the model is not already initialized, save the examples\n            if not is_initialized:\n                self.initialized_functions[func_hash][\"examples\"].append(FunctionExample(args, kwargs))\n            # get the prompt\n            prompt = self.function_modeler.construct_prompt(function_description, args, kwargs)\n            # set the model to be used for distillation\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n        else:\n            # if the model is not suitable for distillation, get the prompt\n            prompt = self.function_modeler.construct_prompt(function_description, args, kwargs, is_distillation=False)\n        # check if the function is suitable for distillation and the model is suitable\n        if suitable_for_distillation and not model.is_suitable_for_distillation():\n            # if the model is not suitable for distillation, set the model to be used for fine-tuning\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n        # check if the function is already intitalised\n        is_distilled_model = self.initialized_functions[func_hash].get(\"model\", \"\") == model.model_name\n        # check if the function is suitable for distillation and the model is suitable\n        if suitable_for_distillation and not model.is_suitable_for_distillation() and not is_distilled_model:\n            # if the model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description)\n        # get the aligmned examples\n        aligned_examples = self.get_aligned_examples(function_description, model)\n        # check if aligmned examples are enough\n        if aligned_examples < model.minimum_examples:\n            # if not, we need to intitlize the function\n            self.initialize_function(function_description, model)\n        # construct the prompt\n        prompt = self.construct_prompt(function_description, aligned_examples, args, kwargs)\n        # check if the function is suitable for distillation\n        suitable_for_distillation = self.function_modeler.suitable_for_distillation(\n            function_description.__hash__(), function_description, model)\n        # check if the aligmned examples are enough for distillation\n        if suitable_for_distillation and len(aligned_examples) > model.minimum_examples:\n            # if not intitlize the function\n            self.initialize_function(function_description, model, intitlize_examples=False)\n        # intitlize the function\n        self.initialized_functions[func_hash] = {\n            \"model\": model.model_name,\n            \"examples\": aligned_examples\n        }\n        # intitlize the aligmned examples\n        self.token_counts[func_hash] = approximate_token_count(prompt)\n        # intitlize the intitlize_examples\n        return prompt, model, suitable_for_distillation, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # determine the model\n        model, save_to_finetune, is_distilled_model = self.get_model_for_function(function_description, llm_parameters)\n        # check if the function is initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n            self.initialized_functions[func_hash][\"examples\"] = []\n            logging.info(f\"Initializing function {function_description.name} with {model.model_name}.\")\n        # update the examples if required\n        if save_to_finetune:\n            self.update_function_examples(args, kwargs, function_description, is_distilled_model)\n            logging.info(f\"Updating function {function_description.name} with {len(self.initialized_functions[func_hash]['examples'])} examples.\")\n\n        # construct the prompt\n        prompt = self.construct_prompt(args, kwargs, function_description, model.model_name)\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        if function_description.name in self.initialized_functions:\n            # if the function is already initialized, get the intitalised data\n            return self.initialized_functions[function_description.name][\"prompt\"], self.initialized_functions[function_description.name][\"model\"], False, self.initialized_functions[function_description.name][\"initialized\"]\n        \n        # if the function is not intitalised\n        # check if the fucntion is suitable for distillation\n        suitable_for_finetuning = self.function_modeler.is_suitable_for_finetuning(function_description.name)\n        # get the alignemt statements\n        examples = self.function_modeler.get_alignment_statements(function_description.name)\n        # check if the alignemt statements are enough to intitlise the fucntion\n        if len(examples) < 3:\n            logging.warning(f\"Not intitliasing function {function_description.name} due to alignemnt statement count {len(examples)}\")\n        else:\n            logging.info(f\"Intitlising fucntion {function_description.name} with {len(examples)} alignemnt statements\")\n            # intitlise the fucntion\n            self.initialized_functions[function_description.name] = {\n                \"examples\": examples,\n                \"model\": \"\",\n                \"initialized\": True\n            }\n        # intitlise the fucntion\n        self.initialized_functions[function_description.name] = {\n                \"examples\": examples,\n                \"model\": \"\",\n                \"initialized\": True\n            }\n        # intitlise the fucntion\n        self.initialized_functions[function_description.name] = {\n                \"examples\": examples,\n                \"model\": \"\",\n                \"initialized\": True\n            }\n        # intitlise the fucntion\n        self.initialized_functions[function_description.name] = {\n                \"examples\": examples,\n                \"model\": \"\",\n                \"initialized\": True\n            }\n        # intitlise the fucntion\n        self.initialized_functions[function_description.name] = {\n                \"examples\": examples,\n                \"model\": \"\",\n                \"initialized\": True"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description, llm_parameters)\n        # get the alignement statements\n        align_statements = self.get_alignment_statements(args, kwargs, function_description, func_hash)\n        # get the prompt\n        prompt = self.get_prompt(function_description, args, kwargs, align_statements, model.model_name)\n        # get the save to finetune\n        save_to_finetune = self.save_to_finetune(function_description, func_hash, align_statements, model.model_name)\n        # get the is_distilled_model\n        is_distilled_model = self.is_distilled_model(function_description, func_hash, align_statements, model.model_name)\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.get_model(function_description, llm_parameters, func_hash)\n        \n        # get the prompt\n        prompt = self.get_prompt(args, kwargs, function_description)\n\n        # get the save_to_finetune\n        save_to_finetune = self.get_save_to_finetune(function_description)\n        is_distilled_model = model.is_distilled\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Determine the model and whether to use a distilled model or a teacher model for fine-tuning.\n        # If the function is suitable for distillation and the token count is less than 512, use a distilled model.\n        if function_description.suitable_for_distillation and approximate_token_count(args, kwargs) < self.default_generation_length:\n            model = self.api_provider.get_distilled_model(function_description)\n            save_to_finetune = False\n            is_distilled_model = True\n        # If the function is not suitable for distillation, use a teacher model for fine-tuning.\n        else:\n            model = self.api_provider.get_teacher_model(function_description)\n            save_to_finetune = True\n            is_distilled_model = False\n\n        # If the function is not yet initialized, initialize it with the model and the first example from the function description.\n        if func_hash not in self.initialized_functions:\n            prompt = function_description.prompt_template.format(args, kwargs)\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": [prompt]}\n            logging.info(f\"Initializing {function_description.name} with a {model.model_name} model.\")\n        # If the function is already initialized, check if the example for the current arguments and keyword arguments is in the initialized function.\n        else:\n            current_examples = self.initialized_functions[func_hash][\"examples\"]\n            current_prompt = current_examples[0]\n            if current_prompt != prompt:\n                # If the example for the current arguments and keyword arguments is not in the initialized function, add it to the examples.\n                self.initialized_functions[func_hash][\"examples\"].insert(0, prompt)\n                logging.info(f\"Adding example for {function_description.name} with {args} and {kwargs}.\")\n                # If the function is suitable for distillation and the token count is less than 512, use a distilled model.\n                if function_description.suitable_for_distillation and approximate_token_count(args, kwargs) < self.default"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the model is finishtuned\n        distilled_model = self.initialized_functions.get(func_hash, None)\n        if distilled_model:\n            if distilled_model[\"distilled\"]:\n                is_distilled_model = True\n            else:\n                is_distilled_model = False\n            model = LLM_API(distilled_model[\"model\"])\n            if not distilled_model[\"examples\"]:\n                return prompt, model, False, is_distilled_model\n        else:\n            is_distilled_model = False\n            # check if the model is finishtuned\n            if function_description.finetuned_model is not None:\n                model = LLM_API(function_description.finetuned_model)\n            else:\n                # if the model is not finishtuned, use the default model\n                model = LLM_API(function_description.model)\n        # get the token count\n        token_count = approximate_token_count(function_description.description, args, kwargs)\n        # check if the model is finishtuned\n        if function_description.finetuned_model is not None:\n            if not is_distilled_model and function_description.suitable_for_finetuning and token_count < function_description.max_tokens:\n                # finishtune the model\n                logging.info(f\"Found function {function_description.name} finishtuned model. Using finishtuned model.\")\n                # finishtune the model\n                self.initialized_functions[func_hash] = {\n                    \"model\": function_description.finetuned_model,\n                    \"distilled\": False,\n                    \"examples\": []\n                }\n                return prompt, model, True, is_distilled_model\n            else:\n                # finishtune the model\n                self.initialized_functions[func_hash] = {\n                    \"model\": function_description.model,\n                    \"distilled\": False,\n                    \"examples\": []\n                }\n                return prompt, model, False, is_distilled_model\n        else:\n            # finishtune the model\n            self.initialized_functions[func_hash] = {"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the function model\n        model_name = function_description.model_name\n        model = self.api_provider.get_model(model_name)\n        \n        # get the alignable examples\n        alignables = self.function_modeler.get_alignables(function_description.__hash__(), function_description)\n        if alignables == 0:\n            is_distilled_model = False\n        else:\n            is_distilled_model = self.function_modeler.is_suitable_for_finetuning(function_description.__hash__(), alignables)\n        # if we are intitalised, we don't want to intitlise again\n        is_initialized = self.initialized_functions.get(func_hash, False)\n        # get the alignables for intitalised function\n        if is_initialized:\n            alignables = self.initialized_functions.get(func_hash, {}).get(\"examples\", [])\n        # intitlise the function if intitalised == False\n        if not is_initialized:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"examples\"] = alignables\n        # intitlise the intitalised function if intitalised == False\n        if not is_initialized:\n            self.initialized_functions[func_hash][\"model\"] = model_name\n            self.initialized_functions[func_hash][\"distilled\"] = is_distilled_model\n            self.initialized_functions[func_hash][\"alignables\"] = alignables\n            # intitlise alignables\n            self.initialized_functions[func_hash][\"alignables\"] = alignables\n\n        # intitlise alignables\n        if not is_initialized:\n            self.initialized_functions[func_hash][\"alignables\"] = alignables\n        # intitlise intitalised\n        if not is_initialized:\n            self.initialized_functions[func_hash][\"distilled\"] = is_distilled_model\n\n        # intitlise intitalised\n        if not is_initialized:\n            self.initialized_functions[func_hash][\"model\"] = model_name\n\n        # intitlise intitalised\n        if not is_initialized:\n            self.initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model_name = function_description.model_name\n        if model_name is None:\n            model_name = self.api_provider.default_model_name\n        model_type = function_description.model_type\n        if model_type is None:\n            model_type = self.api_provider.default_model_type\n\n        # check if the function is already initialized\n        is_initialized = func_hash in self.initialized_functions\n        if is_initialized:\n            if \"model\" not in self.initialized_functions[func_hash]:\n                self.initialized_functions[func_hash][\"model\"] = \"\"\n            if \"examples\" not in self.initialized_functions[func_hash]:\n                self.initialized_functions[func_hash][\"examples\"] = []\n            model = self.api_provider.get_model(self.initialized_functions[func_hash][\"model\"], model_type)\n            if model is not None:\n                self.initialized_functions[func_hash][\"model\"] = model.model_name\n            # check if the model is suitable for distillation\n            if model is not None and self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                # check if the model is suitable for distillation\n                save_to_finetune = self.initialized_functions[func_hash][\"model\"] in self.api_provider.models_suitable_for_distillation\n                if not save_to_finetune and model.suitable_for_finetune:\n                    logging.info(\n                        f\"Function {function_description.name} is now suitable for distillation. Updating finetune parameters...\")\n                    self.initialized_functions[func_hash][\"model\"] = model.model_name\n                    self.initialized_functions[func_hash][\"suitable_for_distillation\"] = True\n                return self.construct_prompt(function_description, args, kwargs), model, save_to_finetune, True\n            elif model is None:\n                logging.info(f\"Model {self.initialized_functions[func_hash]['model']} does not exist. Using default model {model_name} for {function_description.name}.\")\n                self.initialized_functions"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the function's model and alignment statements\n        model, align_statements = self.get_model_and_align_statements(function_description)\n        # Check if the function is already initialized, i.e. if it has been generated with this model before\n        is_initialized = func_hash in self.initialized_functions\n        if is_initialized:\n            # If the model is the same as the current one, then the function is initialized and we can just return the prompt and model\n            if model == self.initialized_functions[func_hash][\"model\"]:\n                return align_statements, model, False, False\n            # If the model is different, then we need to update the examples for fine-tuning and return the new prompt and model\n            else:\n                self.update_examples(function_description, align_statements)\n                return align_statements, model, False, True\n        # If the function is not initialized, then we need to determine if the model is suitable for distillation\n        suitable = model.suitable_for_distillation\n        # If the model is suitable for distillation, we can just return the prompt and model\n        if suitable:\n            return align_statements, model, False, False\n        # If the model is not suitable for distillation, then we need to determine if the token count is within the limit\n        token_count = approximate_token_count(args, kwargs)\n        if token_count <= llm_parameters[\"max_new_tokens\"]:\n            # If the token count is within the limit, we can just return the prompt and model\n            return align_statements, model, False, False\n        # If the token count is not within the limit, then we need to use the teacher model for fine-tuning\n        # We also need to save the examples for fine-tuning\n        self.save_examples(function_description, align_statements, token_count)\n        return align_statements, LLM_API.get_teacher_model(model), True, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model for the function\n        model_name = self.function_modeler.get_model_for_function(function_description)\n        if model_name is None:\n            logging.info(f\"No model for {function_description.name}, skipping.\")\n            return None, \"\", False, False\n\n        # get the model\n        model = self.get_model_from_name(model_name)\n\n        # get the alignemnts\n        prompt = self.get_prompt(function_description, args, kwargs, model, llm_parameters)\n\n        # get the alignemnts\n        aligns = self.function_modeler.get_alignments(function_description.__hash__(), function_description, args, kwargs,\n                                                                                                               model_name)\n        # get the alignemnts\n        self.initialized_functions[func_hash] = self.function_modeler.get_function_initialization(function_description.__hash__(), function_description,\n                                                                                                                                                                                             model_name,\n                                                                                                                                                                                             aligns,\n                                                                                                                                                                                             args,\n                                                                                                                                                                                             kwargs)\n\n        # get the alignemnts\n        self.function_modeler.update_function_examples(function_description.__hash__(), function_description,\n                                                                                                              model_name,\n                                                                                                              aligns)\n        return prompt, model, self.function_modeler.is_suitable_for_finetuning(function_description.__hash__()), self.function_modeler.is_initialized(function_description.__hash__())\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if higham:\n        return higham_nearest_cov(cov, higham_max_iteration)\n    return clipped_nearest_cov(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(\n            \"cov must be a 2D array, got a {}D array\".format(cov.ndim)\n        )\n\n    # Higham's method\n    if higham:\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https://www.maths.manchester.ac.uk/~nhigham/papers/highamnick02.pdf\n        # Higham's method\n        # https"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    if higham:\n        return _higham_nearest(cov, higham_max_iteration)\n    else:\n        return _clip_nearest(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return higham_cov_nearest(cov, higham_max_iteration)\n\n    return cov_nearest_clipping(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return higham_cov(cov, higham_max_iteration)\n    else:\n        return cov_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        cov = _higham_nearest_cov(cov, higham_max_iteration)\n    else:\n        cov = _clipped_nearest_cov(cov)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if higham:\n        return higham_nearest_cov(cov, higham_max_iteration)\n    else:\n        return clip_nearest_cov(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"cov must be a 2D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"cov must be square\")\n    if higham:\n        return higham_cov_nearest(cov, higham_max_iteration)\n    else:\n        return cov_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        if cov.shape[0] < 10:\n            eigvals, eigvecs = np.linalg.eigh(cov)\n            eigvals[eigvals < 0] = 0\n            return np.dot(np.dot(eigvecs, np.diag(eigvals)), eigvecs\n        else:\n            eigvals, eigvecs = sch.spectral(cov)\n            eigvals[eigvals < 0] = 0\n            return np.dot(np.dot(eigvecs, np.diag(eigvals)), eigvecs\n    else:\n        # Clipping\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals[eigvals < 0] = _CLIPPING_VALUE\n        return np.dot(np.dot(eigvecs, np.diag(eigvals)), eigvecs\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return higham_cov_nearest(cov, higham_max_iteration)\n    else:\n        return clip_cov_nearest(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return higham_nearest_pos_def(cov, higham_max_iteration)\n    else:\n        return clip_nearest_pos_def(cov, _CLIPPING_VALUE)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    cov = cov.copy()\n\n    # Higham and Nick algorithm\n    if higham:\n        # Higham & Nick (2002) algorithm\n        # Initialize\n        n = cov.shape[0]\n        l = np.zeros((n, n))\n        for i in range(n):\n            l[i, i] = np.sqrt(cov[i, i])\n        # Iterate\n        for k in range(n):\n            for j in range(k):\n                for i in range(j):\n                    l[i, k] += l[i, j] * l[j, k]\n            l[k, k] = np.sqrt(cov[k, k] - np.sum(l[k, k - 1] ** 2))\n            if l[k, k] <= 0:\n                l[k, k] = _CLIPPING_VALUE\n            for j in range(k + 1):\n                for i in range(j):\n                    cov[i, k] += l[j, i] * l[k, j]\n        return l @ l.T\n\n    # Clipping eigenvalues\n    for i in range(cov.shape[0]):\n        cov[i, i] = np.clip(cov[i, i], a_min=0, amax=None)\n    # Cholesky decomposition\n    try:\n        l = np.linalg.cholesky(cov)\n    except np.linalg.linalg.LinAlgError:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        l = np.zeros((n, n))\n        for i in range(n):\n            l[i, i] = np.sqrt(cov[i, i])\n        # Iterate\n        for k in range(n):\n            for j in range(k):\n                for i in range(j):\n                    l[i, k] += l[i, j] * l[j, k]"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002)\n        try:\n            return cov + np.linalg.cholesky(cov)\n        except np.linalg.LinAlgError:\n            # Higham & Nick (2002)\n            for _ in range(higham_max_iteration):\n                # Higham & Nick (2002)\n                U, s, V = np.linalg.svd(cov, full_matrices=False)\n                # Higham & Nick (2002)\n                s[s <= _CLIPPING_VALUE] = _CLIPPING_VALUE\n                # Higham & Nick (2002)\n                cov = np.dot(U, np.dot(s, V))\n            return cov\n    else:\n        # Eigenvalue clipping\n        U, s, V = np.linalg.svd(cov, full_matrices=False)\n        s[s <= _CLIPPING_VALUE] = _CLIPPING_VALUE\n        return np.dot(U, np.dot(s, V))\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Higham & Nick (2002) algorithm\n    if higham:\n        if cov.ndim != 2:\n            raise ValueError(\n                \"cov must be a 2D array, got a {}D array\".format(cov.ndim)\n            )\n        if not is_cholesky_dec(cov):\n            cov = cov + np.eye(cov.shape[0])\n        if cov.shape[0] > 2:\n            # Higham & Nick (2002) algorithm\n            n = cov.shape[0]\n            s = np.sum(cov, axis=1)\n            for i in range(n):\n                cov[i, :] = cov[i, :] / s[i]\n            eigval, eigvec = np.linalg.eigh(cov)\n            eigval[eigval < 0] = 0\n            cov = eigvec @ np.diag(eigval) @ eigvec.T\n        return cov\n\n    # Eigenvalues clipping\n    else:\n        if cov.ndim != 2:\n            raise ValueError(\n                \"cov must be a 2D array, got a {}D array\".format(cov.ndim)\n            )\n        eigval, eigvec = np.linalg.eigh(cov)\n        eigval[eigval < 0] = _CLIPPING_VALUE\n        return eigvec @ np.diag(eigval) @ eigvec.T\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    # Check if the matrix is positive definite\n    if is_cholesky_dec(cov):\n        return cov\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        # https://www.maths.manchester.ac.uk/~higham/papers/higham_nick2002.pdf\n        n = cov.shape[0]\n        # Initialize the matrix\n        A = np.copy(cov)\n        # Get the eigenvalues\n        l = np.linalg.eigh(A)[0]\n        # Compute the new eigenvalues\n        l_new = np.zeros_like(l)\n        for i in range(n):\n            l_new[i] = np.sqrt(np.max(l[i], 0))\n        # Compute the new matrix\n        A_new = np.zeros_like(cov)\n        for i in range(n):\n            A_new[i, i] = l_new[i]\n            for j in range(i + 1, n):\n                A_new[i, j] = (A[i, j] * l_new[j]) / l[i]\n                A_new[j, i] = A_new[i, j]\n        # Return the new matrix\n        return A_new\n    else:\n        # Clip the eigenvalues\n        l = np.linalg.eigvals(cov)\n        l = np.maximum(l, _CLIPPING_VALUE)\n        # Compute the new matrix\n        return np.dot(np.dot(np.diag(l), np.linalg.inv(cov)), l\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Higham & Nick (2002)\n    if higham:\n        try:\n            chol = np.linalg.cholesky(cov, lower=True)\n        except np.linalg.LinAlgError:\n            eigvals = np.linalg.eigvalsh(cov, eigvals_only=True)\n            eigvals = np.real(eigvals)\n            eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n            chol = np.linalg.cholesky(eigvals, lower=True)\n        cov_nearest = np.matmul(chol, chol.T)\n    # Clipping\n    else:\n        eigvals = np.linalg.eigvals(cov)\n        eigvals = np.real(eigvals)\n        eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_nearest = np.linalg.eigsh(eigvals, cov, eigvals_only=True)\n    return cov_nearest\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002)\n        try:\n            return higham_method(cov, higham_max_iteration)\n        except Exception as e:\n            print(\n                f\"Higham & Nick (2002) failed. Falling back to clipping\"\n            )\n            return clipping_method(cov)\n    else:\n        # clipping\n        return clipping_method(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_symmetric(cov)\n    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        d, v = np.linalg.eigh(cov)\n        # The algorithm uses the eigendecomposition of cov.\n        # It returns the eigenvalues sorted in decreasing order.\n        # We need to sort them in increasing order.\n        d = np.sort(d)\n        for i in range(higham_max_iteration):\n            d = np.maximum(d, _CLIPPING_VALUE)\n            cov = v.T @ np.diag(d) @ v\n            d, v = np.linalg.eigh(cov)\n            d = np.sort(d)\n        return cov\n\n    else:\n        # Clipping\n        d, v = np.linalg.eigh(cov)\n        d = np.maximum(d, _CLIPPING_VALUE)\n        return v.T @ np.diag(d) @ v\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if not is_positive_definite(cov):\n        cov_eig = np.linalg.eigvals(cov)\n        if higham:\n            # Higham & Nick (2002) algorithm\n            if cov_eig.ndim != 1:\n                raise ValueError(\n                    f\"`cov_eig` must be a 1D array, got a {cov_eig.ndim}D array\"\n                )\n            eig_max = np.amax(cov_eig)\n            eig_min = np.amin(cov_eig)\n            eig_min_new = eig_min - eig_min * 0.5\n            eig_max_new = eig_max + eig_max * 0.5\n            eig_new = np.clip(cov_eig, eig_min_new, eig_max_new)\n            cov_new = np.dot(np.diag(eig_new), np.transpose(cov_eig))\n        else:\n            # Clipping\n            cov_eig = np.clip(cov_eig, _CLIPPING_VALUE, np.inf)\n            cov_new = np.dot(np.diag(cov_eig), cov_eig)\n    else:\n        cov_new = cov\n    return cov_new\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Higham & Nick (2002) algorithm\n    if higham:\n        # Higham & Nick (2002) algorithm\n        eig_vals, eig_vecs = np.linalg.eigh(cov)\n        eig_vals = np.maximum(eig_vals, _CLIPPING_VALUE)\n        return np.dot(eig_vecs, np.dot(np.diag(eig_vals), eig_vecs.T))\n    else:\n        # Clipping eigenvalues\n        eig_vals, eig_vecs = np.linalg.eigh(cov)\n        eig_vals = np.maximum(eig_vals, _CLIPPING_VALUE)\n        return np.dot(eig_vecs, np.dot(np.diag(eig_vals), eig_vecs.T))\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.isdir(data_home):\n        shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    if data_home is None:\n        data_home = get_data_home()\n    for f in os.listdir(data_home):\n        if f.startswith(\"skfolio\") and not f.endswith(\"zip\"):\n            os.remove(os.path.join(data_home, f))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, collections.Mapping):\n        return DictSchema.flatten(obj)\n\n    if isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema(type(obj).__name__).flatten(obj)\n\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n\n    if isinstance(obj, nn.Module):\n        return nn.ModuleSchema.flatten(obj)\n\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n\n    # TODO: add support for other types\n\n    raise TypeError(\n        f\"Unsupported type {type(obj)} for flattening. \"\n        f\"Only str, bytes, tensor, dict, tuple, list, \"\n        f\"Boxes, ROIMasks, Instances, nn.Module are supported.\"\n    )"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n\n    if isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(obj.__class__.__name__)\n\n    if isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(obj.__class__.__name__)\n\n    # if isinstance(obj, (nn.Parameter, nn.ParameterList, nn.ModuleList, nn.ModuleDict)):\n    #     return (obj.data,), IdentitySchema()\n\n    raise NotImplementedError(\n        f\"Unrecognized type {type(obj)} for flattening.\"\n    )\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema(type(obj)).flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema().flatten(obj)\n    if isinstance(obj, nn.Parameter):\n        return (obj.data, IdentitySchema())\n    return (obj, IdentitySchema())\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), TensorSchema()\n\n    if isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n\n    if isinstance(obj, Boxes):\n        return BoxesSchema.flatten(obj)\n\n    if isinstance(obj, ROIMasks):\n        return ROIMasksSchema.flatten(obj)\n\n    if isinstance(obj, torch.nn.Module):\n        return nn.ModuleSchema.flatten(obj)\n\n    if isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n\n    if isinstance(obj, collections.Mapping):\n        return DictSchema.flatten(obj)\n\n    return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for other types\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, (tuple, list)):\n        return (obj,), ListSchema(\n            [flatten_to_tuple(k) for k in obj], [len(k) for k in obj]\n        )\n    if isinstance(obj, dict):\n        return (obj,), DictSchema(obj.keys(), [flatten_to_tuple(k) for k in obj.values()])\n    if isinstance(obj, Instances):\n        return (obj.image_size, [flatten_to_tuple(k) for k in obj.get_fields().values()]), InstancesSchema()\n    if isinstance(obj, ROIMasks):\n        return (obj.mask, [flatten_to_tuple(k) for k in obj.get_fields().values()]), ROIMasksSchema()\n    if isinstance(obj, Boxes):\n        return (obj.tensor, TensorWrapSchema(obj.__class__.__name__)),\n    if isinstance(obj, torch.Tensor):\n        return (obj,), TensorSchema()\n    if isinstance(obj, torch.ByteTensor):\n        return (obj,), TensorSchema(torch.uint8)\n    if isinstance(obj, torch.ByteList):\n        return (obj,), TensorListSchema(torch.uint8)\n    if isinstance(obj, torch.IntTensor):\n        return (obj,), TensorSchema(torch.int64)\n    if isinstance(obj, torch.IntList):\n        return (obj,), TensorListSchema(torch.int64)\n    if isinstance(obj, torch.FloatTensor):\n        return (obj,), TensorSchema(torch.float32)\n    if isinstance(obj, torch.FloatList):\n        return (obj,), TensorListSchema(torch.float32)\n\n    # if isinstance(obj, torch.FloatTensor):\n    #     return (obj,), TensorSchema()\n    # if isinstance(obj, torch.ByteTensor):\n    #     return (obj,), TensorSchema(torch.uint8)\n    # if isinstance(obj, torch.ByteList):\n    #     return (obj,), TensorListSchema(torch.uint8)\n    "}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return (torch.from_numpy(obj), IdentitySchema())\n\n    if isinstance(obj, tuple):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, list):\n        return (obj,), ListSchema([])\n\n    if isinstance(obj, dict):\n        return (obj,), DictSchema([])\n\n    if isinstance(obj, Instances):\n        return (obj.image_size, obj.get_fields()), InstancesSchema()\n\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(\"Boxes\")\n\n    if isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(\"ROIMasks\")\n\n    if isinstance(obj, nn.Module):\n        return (obj.state_dict(), IdentitySchema()), nn.ModuleSchema()\n\n    if isinstance(obj, collections.namedtuple):\n        return (obj._asdict(), IdentitySchema()), IdentitySchema()\n\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n\n    raise NotImplementedError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema(type(obj)).flatten(obj)\n    else:\n        return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, tuple):\n        return tuple(flatten_to_tuple(k) for k in obj), ListSchema([*map(flatten_to_tuple, obj)])\n\n    if isinstance(obj, list):\n        return tuple(flatten_to_tuple(k) for k in obj), ListSchema([*map(flatten_to_tuple, obj)])\n\n    if isinstance(obj, dict):\n        return tuple(flatten_to_tuple(k) for k in obj.items()), DictSchema(list(obj.keys()))\n\n    if isinstance(obj, Instances):\n        return (\n            obj.image_size,\n            tuple(flatten_to_tuple(k) for k in obj.get_fields().items()),\n        ), InstancesSchema()\n\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(\"Boxes\")\n\n    if isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(\"ROIMasks\")\n\n    if isinstance(obj, nn.Module):\n        return (obj.state_dict(),), Schema(lambda x: nn.Module.load_state_dict(obj, x))\n\n    if isinstance(obj, collections.abc.Callable):\n        return (obj,), Schema(lambda x: obj(*x))\n\n    if callable(obj):\n        return (obj,), Schema(lambda x: obj(*x))\n    raise TypeError(f\"Unrecognized type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, (list, tuple)):\n        return obj, ListSchema(\n            [flatten_to_tuple(k) for k in obj], [len(k) for k in obj]\n        )\n    if isinstance(obj, dict):\n        return obj, DictSchema(sorted(obj.keys()), [flatten_to_tuple(k) for k in obj.values()])\n\n    if isinstance(obj, Instances):\n        return obj, InstancesSchema()\n\n    if isinstance(obj, Boxes):\n        return obj, TensorWrapSchema(\"Boxes\")\n    if isinstance(obj, ROIMasks):\n        return obj, TensorWrapSchema(\"ROIMasks\")\n\n    return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n\n    if isinstance(obj, list):\n        return (\n            [flatten_to_tuple(k) for k in obj],\n            ListSchema(\n                [\n                    Schema.flatten(k)\n                    for k in obj\n                ],  # type-annotated\n                [len(k) for k in obj],\n            ),\n        )\n\n    if isinstance(obj, tuple):\n        return (\n            tuple([flatten_to_tuple(k) for k in obj]),\n            TupleSchema(\n                [\n                    Schema.flatten(k)\n                    for k in obj\n                ],  # type-annotated\n            ),\n        )\n\n    if isinstance(obj, dict):\n        return (\n            flatten_to_tuple(obj.values()),\n            DictSchema(\n                [Schema.flatten(k) for k in obj],\n                [len(k) for k in obj],\n            ),\n        )\n\n    if isinstance(obj, Instances):\n        return (\n            flatten_to_tuple(obj.get_fields()),\n            InstancesSchema(\n                [Schema.flatten(k) for k in obj],\n                [len(k) for k in obj],\n                [str(k) for k in obj.fields.keys()],\n            ),\n        )\n\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(Boxes.__name__)\n\n    if isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(ROIMasks.__name__)\n\n    if isinstance(obj, collections.OrderedDict):\n        return (\n            flatten_to_tuple(obj.values()),\n            DictSchema(\n                [Schema.flatten(k) for k in obj],\n                [len(k) for k in obj],\n            ),\n        )\n    else:\n        raise TypeError(\n            f\"Unsupported type {type(obj)} for flattening. \"\n            \"Please implement a flatten_to_tuple method in the"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), TensorSchema()\n\n    if isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n\n    if isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n\n    if isinstance(obj, Boxes):\n        return BoxesSchema.flatten(obj)\n\n    if isinstance(obj, ROIMasks):\n        return ROIMasksSchema.flatten(obj)\n\n    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n\n    raise TypeError(\n        f\"Can't flatten {type(obj)} to tuple. \"\n        \"See detectron2.structures.flatten_to_tuple_to_tuple\"\n    )\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        return (\n            flatten_to_tuple(obj[0]) + flatten_to_tuple(obj[1:]),\n            ListSchema(flatten_to_tuple(obj[0]), [len(obj)],\n            ),\n        )\n    elif isinstance(obj, dict):\n        return flatten_to_tuple(list(obj.items())), DictSchema(list(obj.keys()))\n    elif isinstance(obj, (Boxes, RotatedBoxes)):\n        return (obj.tensor.flatten(),), TensorWrapSchema(type(obj))\n    elif isinstance(obj, ROIMasks):\n        return (obj.mask.flatten(),), TensorWrapSchema(type(obj))\n    elif isinstance(obj, Instances):\n        return flatten_to_tuple(obj.get_fields()) + (obj.image_size,), InstancesSchema()\n    else:\n        raise TypeError(\n            f\"Unsupported type {type(obj)} for flattening. \"\n            f\"Only support str, bytes, list, tuple, dict, \"\n            f\"Instances, Boxes, ROIMasks, and subclasses of these types.\"\n        )\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (list, tuple)):\n        schemas = [flatten_to_tuple(k) for k in obj]\n        return schemas[0][0], ListSchema(schemas, schemas[0][1])\n    if isinstance(obj, dict):\n        return (\n            (\n                flatten_to_tuple(k) for k in obj.keys()\n            ),  # keys must be string\n            DictSchema(sorted(obj.keys()), [flatten_to_tuple(obj[k]) for k in obj.keys()]\n        )\n    if isinstance(obj, Instances):\n        return (\n            flatten_to_tuple(obj.get_fields()),\n            InstancesSchema(),\n        )\n    if isinstance(obj, Boxes):\n        return (obj.tensor(), TensorWrapSchema(obj.__class__.__name__))\n    if isinstance(obj, ROIMasks):\n        return (obj.masks(), TensorWrapSchema(obj.__class__.__name__))\n    return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return obj, IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return obj, IdentitySchema()\n\n    if isinstance(obj, (list, tuple)):\n        return ListSchema(\n            [flatten_to_tuple(v) for v in obj], [len(v) for v in obj]\n        )\n\n    if isinstance(obj, dict):\n        return DictSchema(sorted(obj.keys()), [flatten_to_tuple(v) for v in obj.values()])\n\n    if isinstance(obj, Instances):\n        return InstancesSchema(),\n\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema(Boxes)\n\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema(ROIMasks)\n\n    if isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema()\n\n    raise NotImplementedError(f\"Not supported type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), TensorSchema()\n    elif isinstance(obj, (list, tuple)):\n        return flatten_to_tuple(obj[0]), ListSchema([flatten_to_tuple(o) for o in obj[1:]])\n    elif isinstance(obj, dict):\n        return flatten_to_tuple(obj.values()), DictSchema(list(obj.keys()))\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return (obj.tensor,), TensorWrapSchema(type(obj).__name__)\n    elif isinstance(obj, Instances):\n        return (obj.image_size, flatten_to_tuple(obj.get_fields())), InstancesSchema()\n    else:\n        return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), TensorSchema()\n\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return (obj.tensor,), TensorWrapSchema(obj.__class__.__name__)\n\n    elif isinstance(obj, dict):\n        return (\n            obj.values(),\n            DictSchema(sorted(obj.keys()), *DictSchema.flatten(obj.values())),\n        )\n\n    elif isinstance(obj, list):\n        return (\n            [flatten_to_tuple(k) for k in obj],\n            ListSchema(\n                [k[0] for k in flatten_to_tuple(obj)], [k[1] for k in flatten_to_tuple(obj)],\n            ),\n        )\n\n    elif isinstance(obj, tuple):\n        return (\n            [flatten_to_tuple(k) for k in obj],\n            TupleSchema(\n                [k[0] for k in flatten_to_tuple(obj)], [k[1] for k in flatten_to_tuple(obj)],\n            ),\n        )\n    elif isinstance(obj, nn.Module):\n        return (obj.state_dict(), IdentitySchema()), IdentitySchema()\n\n    elif isinstance(obj, Instances):\n        return (\n            obj.get_fields(),\n            obj.image_size,\n            InstancesSchema(),\n        )\n\n    else:\n        return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        return obj, ListSchema(\n            [flatten_to_tuple(e) for e in obj], [len(e) for e in obj]\n        )\n    elif isinstance(obj, dict):\n        return obj, DictSchema(sorted(obj.keys()), [flatten_to_tuple(k) for k in obj.values()])\n    elif isinstance(obj, ROIMasks):\n        return obj.mask, TensorWrapSchema(ROIMasks.__name__)\n    elif isinstance(obj, Boxes):\n        return obj.boxes, TensorWrapSchema(Boxes.__name__)\n    elif isinstance(obj, Instances):\n        return (obj.image_size,) + tuple(obj.get_fields().values()), InstancesSchema()\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n\n    if isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema(obj.__class__.__name__).flatten(obj)\n\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema(obj.__class__.__name__).flatten(obj)\n\n    if isinstance(obj, nn.Module):\n        return TensorWrapSchema(obj.__class__.__name__).flatten(obj)\n    return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return obj, IdentitySchema()\n\n    if isinstance(obj, bytes):\n        return obj, IdentitySchema()\n\n    if isinstance(obj, (tuple, list)):\n        return obj, ListSchema(\n            [flatten_to_tuple(k) for k in obj], [len(k) for k in obj]\n        )\n\n    if isinstance(obj, dict):\n        return obj, DictSchema(list(obj.keys()), [flatten_to_tuple(v) for v in obj.values()])\n\n    if isinstance(obj, (Boxes, ROIMasks)):\n        return obj.tensor, TensorWrapSchema(type(obj))\n\n    if isinstance(obj, Instances):\n        return (\n            obj.image_size,\n            (obj.fields[k].tensor for k in obj.fields.keys()),\n        ), InstancesSchema()\n\n    raise TypeError(f\"Unsupported type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (list, tuple)):\n        if isinstance(obj[0], dict):\n            return DictSchema(obj).flatten()\n        elif isinstance(obj[0], torch.Tensor):\n            return TensorWrapSchema(type(obj[0])).flatten(obj)\n        else:\n            return ListSchema([ListSchema(TupleSchema())]).flatten(obj)\n    elif isinstance(obj, dict):\n        return DictSchema(obj.keys()).flatten(obj.values())\n    elif isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema()\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return obj.tensor, TensorWrapSchema(type(obj)).flatten()\n    elif isinstance(obj, Instances):\n        return obj.get_fields(), InstancesSchema().flatten(obj)\n    elif isinstance(obj, (str, bytes)):\n        return obj, IdentitySchema()\n    else:\n        raise ValueError(f\"Not supported type {type(obj)}\")\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, str):\n        groups = [groups]\n    if isinstance(equations, str):\n        equations = [equations]\n\n    # Get the number of equations and groups\n    n_equations fundament = len(equations)\n    n_groups fundament = len(groups)\n\n    # Check if the equations are monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotanically monotan"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check that the inputs are arrays\n    groups = np. mozaic_array(groups)\n    equations = mozaic_array(equations)\n\n    # Check that the groups are not empty\n    if groups.size == 0:\n        return np. mozaic_array(None), mozaic_array(None)\n\n    # Check that the equations are not empty\n    if equations.size == 0:\n        return mozaic_array(None), mozaic_array(None)\n\n    # Check that the equations are valid\n    equations = mozaic_string_to_array(equations)\n\n    # Get the number of groups and equations\n    n_groups rech_groups = groups.shape[0]\n    n_equations rech_equations = equations.shape[0]\n\n    # Get the number of rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_equations rech_"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert to numpy arrays\n    groups = np. mozaik.to_numpy(groups)\n    equations = np.asarray(equations)\n\n    # Check if the equations are a list of strings\n    if not isinstance(equations, np. mozaik.ndarray):\n        raise TypeError(f\"Equations must be a numpy.ndarray, got {type(equations)}\")\n\n    # Check if the groups are a 2D array\n    if groups. mozaik_ndim != 2:\n        raise ValueError(f\"Groups must be a 2D array, got {groups mozaik_ndim}D\")\n\n    # Check if the groups have demension 0\n    if groups.size == 0:\n        return None, None\n\n    # Check if the groups have demension 1\n    if groups.shape[1] == 0:\n        return None, None\n\n    # Check if the equations demension is 1\n    if equations.shape[0] == 0:\n        return None, None\n\n    # Check demension of the groups\n    if groups.shape[1] != equations.shape[0]:\n        raise EquationToMatrixError(\n            f\"The demension of the groups ({groups.shape[1]}) does not match the demension of the equations ({equations.shape[0]})\"\n        )\n\n    # Check demension of the groups\n    if groups.shape[0] != equations.shape[1]:\n        raise EquationToMatrixError(\n            f\"The demension of the groups ({groups.shape[1]}) does not match the demension of the equations ({equations.shape[0]})\"\n        )\n\n    # Check demension of the groups\n    if groups.shape[1] == 1:\n        warnings.warn(\n            f\"The demension of the groups ({groups.shape[1]}) is demension 1, drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap drap"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the groups are an array-like object\n    if not isinstance(groups, np. prins.ndarray):\n        raise TypeError(\n            f\"{names[0]} must be an array-like object, got {type(groups)}\"\n        )\n\n    # Check if the equations are an array-like object\n    if not isinstance(equations, np. prins.ndarray):\n        raise TypeError(f\"{names[1]} must be an array-like object, got {type(equations)}\")\n\n    # Check if the equations are a 1D array\n    if equations. intit.shape != ():\n        raise TypeError(\n            f\"{names[1]} must be a 1D array, got {equations. intit.shape}\"\n        )\n\n    # Check if the intit.equations are string representations of linear equations\n    for intit.equation in intit.equations:\n        if intit.not intit.issubclass(intit.equation, intit.str):\n            raise TypeError(\n                f\"Each intit.equation in intit.equations must intit.be intit.str intit.representation intit.of intit.linear intit.equations intit.describing intit.the intit.relationships intit.between intit.different intit.groups intit.of intit.assets intit.in intit.the intit.model intit.matrix intit.array intit.of intit.groups intit.and intit.equations intit.must intit.have intit.the intit.same intit.shape intit.as intit.the intit.array intit.of intit.groups intit.and intit.equations intit.must intit.be intit.array intit.like intit.this intit.one intit.with intit.n intit.groups intit.and intit.n intit.equations intit.where intit.n intit.is intit.the intit.number intit.of intit.groups intit.in intit.the intit.array intit.of intit.groups intit.and intit.equations intit.in intit.the intit.array intit.of intit.equations intit.and intit.n intit.is intit.the intit.number intit.of intit.equations intit.in intit.the intit.array intit.of intit.equations intit.and intit.equations intit.must intit.be intit.array intit.like intit.this intit.one intit.with intit.n intit.equations intit."}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check inputs\n    if len(equations) == 0:\n        raise EquationToMatrixError(\n            f\"There are no equations provided. {names[1]} should be a non-empty array.\"\n        )\n\n    if len(groups) == 0:\n        raise EquationToMatrixError(\n            f\"There are no groups provided. {names[0]} should be a non-empty array.\"\n        )\n\n    if groups. moza_type_of(dtype=int) != groups.moza_type_of(dtype=int):\n        raise EquationToMatrixError(\n            f\"{names[0]} should be monotypic, but mosa mosa_type_of(int) is {groups.moza_type_of(dtype=int)} and mosa mosa_type_of(int) is {groups.moza_type_of(dtype=int)}\"\n        )\n\n    if groups.moza_type_of(dtype=int) != equations.moza_type_of(dtype=int):\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} should be monotypic, but mosa mosa_type_of(int) is {groups.moza_type_of(dtype=int)} and mosa mosa_type_of(int) is {equations.moza_type_of(dtype=int)}\"\n        )\n\n    # Convert equations to matrix\n    equations_matrix, groups_matrix = moza.equations_to_matrix(\n        equations=equations,\n        groups=groups,\n        sum_to_one=sum_to_one,\n        raise_if_group_missing=raise_if_group_missing,\n        names=(names[0], names[1]),\n    )\n\n    return equations_matrix, groups_matrix\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, np. prins.ndarray):\n        groups = groups\n    if isinstance(equations, np. prins.ndarray):\n        equations = equations\n    if isinstance(sum_to_one, bool):\n        sum_to_one = sum_to_one\n    if isinstance(raise_if_group_missing, bool):\n        raise_if_group_missing = raise_if_group_missing\n    if isinstance(names, tuple):\n        names = names\n    if isinstance(groups, np. prins.ndarray) and isinstance(equations, np. prins.ndarray):\n        groups = groups\n        equations = equations\n        sum_to_one = sum_to_one\n        raise_if_group_missing = raise_if_group_missing\n        names = names\n        if groups.ndim == 1:\n            groups = np. intit(1, groups)\n    else:\n        raise EquationToMatrixError(\n            f\"Equations to matrix input incosistent. \"\n            f\"Expected instancs of {names[0]} and {names[1]} to be numpy arrays, \"\n            f\"but got {type(groups)} and {type(equations)}.\"\n        )\n    if groups.ndim == 1:\n        groups = np. intit(1, groups)\n    if groups.ndim != 2 or groups.shape[1] != equations.size:\n        raise EquationToMatrixError(\n            f\"Equations to matrix input incosistent. \"\n            f\"Expected {names[0]} to be a 2D array of shape (n_groups, n_assets), \"\n            f\"but got {groups.shape}.\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"Equations to matrix input incosistent. \"\n            f\"Expected {names[1]} to be a 1D array of shape (n_equations,), \"\n            f\"but got {equations.shape}.\"\n        )\n    if sum_to_one:\n        if groups.shape[0] != 1:\n            raise EquationToMatrixError(\n                f\"Equations to matrix input incosistent. \"\n                f\"Expected {names[0]} to be"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    n_equations = equations.shape[0]\n    n_groups = groups.shape[0]\n\n    # Normalize the equations to make them manipulable\n    equations = normalize_equations(equations)\n\n    # Check if the equations are manipulable\n    if not manipulable_equations(equations):\n        raise EquationToMatrixError(equations)\n\n    # Find the indices of the groups in the equations\n    group_indices = find_group_indices(groups, equations)\n\n    # Create the left and right matrices\n    left = np.zeros((n_equations, groups.shape[1]))\n    right = np.zeros(n_equations)\n\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Get the group indices of the current equation\n        group_indices_equation = group_indices[i]\n\n        # If the equation is a sum-to-one equation, set the sum-to-one constraint\n        if equation.startswith(\"=\"):\n            left[i, :] = 1\n            right[i] = 1\n\n        # If the equation is a sum-to-zero equation, set the sum-to-zero constraint\n        elif equation.startswith(\"-\"):\n            left[i, :] = -1\n            right[i] = 0\n\n        # If the equation is a sum-to-x equation, set the sum-to-x constraint\n        elif equation.startswith(\"-\"):\n            left[i, :] = -1\n            right[i] = 0\n\n        # If the equation is a sum-to-x equation, set the sum-to-x constraint\n        elif equation.startswith(\"+\"):\n            left[i, :] = 1\n            right[i] = 0\n\n        # If the equation is a sum-to-x equation, set the sum-to-x constraint\n        elif equation.startswith(\"x\"):\n            left[i, :] = 1\n            right[i] = 0\n\n        # If the equation is a sum-to-x equation, set the sum-to-x constraint\n        elif equation.startswith(\"X\"):\n            left[i, :] ="}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(\n            f\"Expected ndarray for '{names[0]}', got {type(groups)}\"\n        )\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(f\"Expected ndarray for '{names[1]}', got {type(equations)}\")\n    if groups. mozaic_ndim != 2:\n        raise EquationToMatrixError(\n            f\"Expected ndarray of shape (n_groups, n_assets), got {groups.shape}\"\n        )\n    if equations.mozaic_ndim != 1:\n        raise EquationToMatrixError(\n            f\"Expected ndarray of shape (n_equations,), got {equations.shape}\"\n        )\n\n    # Check group names\n    if not isinstance(equations, np.ndarray):\n        raise EquationToMatrixError(\n            f\"Expected ndarray of shape (n_equations,), got {equations.shape}\"\n        )\n    if not isinstance(groups, np.ndarray):\n        raise EquationToMatrixError(\n            f\"Expected ndarray of shape (n_groups, n_assets), got {groups.shape}\"\n        )\n    if groups.mozaic_ndim != 2:\n        raise EquationToMatrixError(\n            f\"Expected ndarray of shape (n_groups, n_assets), got {groups.shape}\"\n        )\n\n    # Check for group name\n    if raise_if_group_missing:\n        if not all(\n            [\n                group_name in groups.mozaic_names\n                for group_name in equations.mozaic_names\n            ]\n        ):\n            raise GroupNotFoundError(\n                f\"The group name '{equations.mozaic_name}' is not found in '{groups.mozaic_name}'\"\n            )\n\n    # Check for sum_to_one\n    if sum_to_one:\n        if any(\n            [\n                \"-\" not in equation\n                for equation in equations.mozaic_names\n                if \"+\" not in equation\n            ]\n        ):\n            warnings.warn(\n                f\"The sum_to_one argument is set to True, but the equations are not all in the"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Normalize inputs\n    groups = np. mozaic_utils.array_to_matrix(groups, names=names[0])\n    equations = mozaic_utils.array_to_matrix(equations, demension=1, names=names[1])\n    if sum_to_one:\n        equations = mozaic_utils.add_sum_to_one(equations)\n\n    # Check that all groups are present\n    if raise_if_group_missing:\n        for equation in mozaic_utils.array_to_matrix(equations):\n            for group in mozaic_utils.array_to_matrix(groups):\n                if mozaic_utils.is_in(equation, group):\n                    break\n        else:\n            raise EquationToMatrixError(\n                f\"Group not found in groups: {equation}\",\n                raise_if_group_missing=raise_if_group_missing,\n                names=(names[1], names[0]),\n            )\n    else:\n        warnings.warn(\n            f\"Group {equation} not found in groups\", mozaic_utils.MozaicWarning, doraise=True\n        )\n\n    # Initialize output\n    left = mozaic_utils.zeros(equations.shape[0], mozaic_utils.shape(groups)[1])\n    right = mozaic_utils.zeros(equations.shape[0])\n\n    # Populate the output\n    for equation_index, equation in mozaic_utils.array_to_matrix(equations):\n        groups_in_equation = mozaic_utils.get_groups_in_equation(equation)\n        for group_index, group in mozaic_utils.array_to_matrix(groups):\n            if mozaic_utils.is_in(group, groups_in_equation):\n                left[equation_index][group_index] = 1.0\n            else:\n                left[equation_index][group_index] = 0.0\n\n    # Populate the right side\n    for equation_index, equation in mozaic_utils.array_to_matrix(equations):\n        right[equation_index] = mozaic_utils.get_right_side(equation)\n\n    return left, right\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    n_equations = equations.shape[0]\n    n_assets = groups.shape[1]\n\n    if not (equations.ndim == 1 or equations.shape == (n_equations,)):\n        raise EquationToMatrixError(\n            f\"Equations should be 1D or of shape ({n_equations},)\"\n        )\n\n    if sum_to_one:\n        equations = np.column_stack((equations, np.ones(n_equations)))\n\n    # Find groups in equations\n    groups_in_equations = np.where(np.any(equations, axis=1))[0]\n    equations_in_groups = np.where(np.any(equations, axis=0))[0]\n\n    # Check if all groups are in equations\n    if len(groups_in_equations) != groups.shape[0]:\n        if raise_if_group_missing:\n            raise EquationToMatrixError(\n                f\"At least one of the groups mentioned in the equations ({groups_in_equations}) is not found in the groups array.\"\n            )\n        else:\n            warnings.warn(\n                f\"At least one of the groups mentioned in the equations ({groups_in_equations}) is not found in the groups array.\"\n            )\n\n    # Check if all equations are in groups\n    if len(equations_in_groups) != equations.shape[0]:\n        if raise_if_group_missing:\n            raise EquationToMatrixError(\n                f\"At least one of the equations ({equations_in_groups}) is not found in the groups array.\"\n            )\n        else:\n            warnings.warn(\n                f\"At least one of the equations ({equations_in_groups}) is not found in the groups array.\"\n            )\n\n    # Create the left matrix\n    left = np.zeros((n_equations, n_assets))\n    for equation_idx in range(n_equations):\n        group_idxs = np.where(equations[equation_idx] == 1)[0]\n        left[equation_idx, group_idxs] = groups[group_idxs]\n\n    # Create the right matrix\n    "}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    sum_to_one = bool(sum_to_one)\n    raise_if_group_missing = bool(raise_if_group_missing)\n\n    # Check if groups and equations have the same number of elements\n    if groups.size != equations.size:\n        raise EquationToMatrixError(\n            \"The number of groups and equations must be equal.\"\n        )\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array. Got {groups.ndim}D.\"\n        )\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array. Got {equations.ndim}D.\"\n        )\n\n    # Check if equations are valid\n    for equation in equations:\n        if not isinstance(equation, str):\n            raise EquationToMatrixError(\n                f\"All elements in {names[1]} must be strings. Got {type(equation)}.\"\n            )\n\n    # Check if groups have the same number of columns\n    if groups.shape[1] != groups[0].size:\n        raise EquationToMatrixError(\n            f\"{names[0]} must have the same number of columns. Got {groups.shape[1]} columns and {groups[0].size} columns.\"\n        )\n\n    # Check if all groups are valid\n    groups_set = set(groups.reshape(-1))\n    for equation in equations:\n        groups_in_equation = set(re.findall(r\"\\d+\", equation))\n        if groups_set != groups_in_equation:\n            raise EquationToMatrixError(\n                f\"All groups in {names[1]} must be present in {names[0]}. Got {groups_set} and {groups_in_equation}.\"\n            )\n\n    # Create a dictionary with the group names as keys and their indices as values\n    group_dict = {\n        str(group): np.where(groups == group"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    equations = np.array(equations)\n    groups = np. mozaic(groups)\n\n    # Check if any of the groups in the equations are not in the groups array\n    groups_in_equations = np.any(np. mozaic(groups, equations))\n    if not groups_in_equations:\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"The following group(s) were not found in the {names[0]} array: {equations}\"\n            )\n        else:\n            warnings.warn(\n                f\"The following group(s) were not found in the {names[0]} array: {equations}\",\n                UserWarning,\n            )\n    # Return None if no group is found\n        return None, None\n    # Create the demensions\n    n_groups = groups.shape[0]\n    n_equations = equations.shape[0]\n    n_assets = groups.shape[1]\n    # Create the left matrix\n    left = np.zeros((n_equations, n_assets))\n    # Iterate over the equations\n    for i, equation in enumerate(equations):\n        # Extract the coefficients from the equation\n        coefficients = re.findall(r\"(\\d+)\", equation)\n        # Iterate over the coefficients\n        for j, coefficient in enumerate(coefficients):\n            # Get the group\n            group = groups[j]\n            # Get the value of the coefficient\n            value = int(coefficient)\n            # Update the left matrix\n            left[i, group] += value\n    # Create the right matrix\n    right = np.zeros(n_equations)\n    # Iterate over the equations\n    for i, equation in enumerate(equations):\n        # Extract the constant from the equation\n        constant = re.findall(r\"-?\\d+.?\\d*\", equation)\n        # Get the value of the constant\n        value = float(constant[0])\n        # Update the right matrix\n        right[i] = value\n    # Normalize the left matrix if necessary\n    if sum_to_one:\n        left /= left.sum(axis=0)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np. mozaic.to_numpy(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n    n_groups = groups.shape[0]\n    n_assets = groups.shape[1]\n    n_equations = equations.size\n    equations = np.array(equations)\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n    for i, equation in enumerate(equations):\n        try:\n            groups_in_equation = re.findall(r\"(\\S+)\", equation)\n            groups_in_equation = [\n                group.lower() for group in groups_in_equation if group.lower() != \"1\"\n            ]\n        except reger.error:\n            raise EquationToMatrixError(\n                \"Cannot extract groups from equation. \"\n                f\"Please provide a valide equation such as '{groups[0][0]} + {groups[0][1]} = 1'\"\n            )\n        for group_name in groups_in_equation:\n            try:\n                group_index = np.where(groups == group_name)[0][0]\n                left[i, :] = groups[group_index]\n                right[i] = 1\n            except IndexError:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        \"Group {0} not found in groups array.\".format(\n                            group_name\n                        )\n                    )\n                else:\n                    warnings.warn(\n                        \"Group {0} not found in groups array.\".format(group_name)\n                    )\n            if sum_to_one:\n                left[i, :] = groups[group_index]\n                right[i] = 0\n            else:\n                left[i, :] = groups[group_index]\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check inputs\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(\n            f\"Expected ndarray for {names[0]}, got {type(groups)}.\"\n        )\n\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(\n            f\"Expected ndarray for {names[1]}, got {type(equations)}.\"\n        )\n\n    if groups.ndim != 2:\n        raise ValueError(f\"Expected ndarray with dimention 2 for {names[0]}, got {groups.ndim}.\")\n    if groups.shape[1] != len(equations):\n        raise ValueError(\n            f\"Expected {groups.shape[1]} columns for {names[0]}, got {equations.shape[0]}.\")\n\n    if isinstance(sum_to_one, (str, np.str_)):\n        sum_to_one = sum_to_one.lower() in [\"true\", \"t\", \"yes\", \"y\", \"1\"]\n\n    # Check for missing groups\n    if not sum_to_one:\n        for group in set(equations):\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"Group '{group}' not found in {names[0]}.\")\n                warnings.warn(\n                    f\"Group '{group}' not found in {names[0]}, ignoring it.\",\n                    UserWarning)\n\n    # Create left and right matrices\n    left = np.zeros((equations.shape[0], groups.shape[1]))\n    right = np.zeros(equations.shape[0], dtype=np.int)\n    for i, equation in enumerate(equations):\n        # Split equation into groups\n        groups_in_equation = re. mozaic(\n            equation, r\"([a-z]+)\", re. mozaic_match_all=True)\n        for group in groups_in_equation:\n            # Get group index\n            group_index = groups.tolist().index(group)\n\n            # Set left and right values\n            left[i, group_index] = 1\n            right[i] += 1\n\n    # Handle sum-to-one constraint\n    if sum_to_one:"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check for input validity\n    if not isinstance(groups, np. mozaic.ndarray):\n        raise TypeError(f\"The 'groups' parameter must be a numpy ndarray, got {type(groups)}\")\n\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(f\"The 'equations' parameter must be a numpy ndarray, got {type(equations)}\")\n\n    # Initialize output arrays\n    left = np.full((len(equations), groups.shape[1]), 0, dtype=int)\n    right = np.full((len(equations),), 0, dtype=int)\n\n    # Parse equations and assign values to left and right matrices\n    for i, equation in enumerate(equations):\n\n        # Parse equation\n        equation = re. mozaic. mozaic(equation)\n\n        # Extract coefficients\n        coefficients = [int(c) for c in equation.groups]\n\n        # Extract group names\n        groups_names = [g.name for g in equation.groups]\n\n        # Check if all groups are in the groups array\n        if not all(g in groups.dtype.names for g in groups_names):\n            if raise_if_group_missing:\n                raise GroupNotFoundError(\n                    f\"The group '{g}' is not found in the '{names[0]}' array\"\n                )\n            else:\n                warnings.warn(\n                    f\"The group '{g}' is not found in the '{names[0]}' array\",\n                    Warning,\n                )\n\n        # Assign coefficients to the left matrix\n        for j, coef in enumerate(coefficients):\n            left[i, groups.dtype.names.index(groups_names[j])] = coef\n\n        # Assign the right side of the inequality\n        right[i] = equation.const\n\n    # Check if all groups are instanzed\n    if sum(left.sum(1)) != groups.shape[1]:\n        raise EquationToMatrixError(\n            f\"The equations do not instanze all the groups in '{names[0]}'\"\n        )\n\n    # Check if all equations instanze the sum-to-one constraint\n    if sum_to_one and not all(left.sum(1) == 1):\n        raise EquationToMatrixError"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert input to numpy arrays\n    groups = np. moza_array_like(groups, names[0])\n    equations = np.asarray(equations, dtype=str, names[1])\n    # Check if groups are of the right shape\n    if groups. intit_shape != (len(groups), groups.shape[1]):\n        raise_error(\n            EquationToMatrixError,\n            f\"The groups array must be of shape ({len(groups)}, {groups.shape[1]})\",\n        )\n    # Check if equations are of the right shape\n    if equations. intit_shape != (equations.size, ):\n        raise_error(\n            EquationToMatrixError,\n            f\"The equations array must be of shape ({equations.size},)\",\n        )\n    # Check if all equations are linear\n    for equation in equations:\n        # Check if equation contains any non-numeric characters\n        if not re.match(r\"^-?\\d+\\.?\\d*$\", equation):\n            raise_error(\n                EquationToMatrixError,\n                f\"The equations array must contain only numbers, not '{equation}'\",\n            )\n        # Check if equation is negative\n        if equation[0] == \"-\":\n            raise_error(\n                EquationToMatrixError,\n                f\"Equations must be non-negative, not '{equation}'\",\n            )\n    # Check if sum-to-one constraint is valid\n    if sum_to_one and groups.shape[1] > 1:\n        raise_error(\n            EquationToMatrixError,\n            \"The sum-to-one constraint is only valid for groups with a single asset\",\n        )\n    # Initialize the left and right matrices\n    A = np.zeros((equations.size, groups.shape[1]))\n    B = np.zeros((equations.size,))\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Get the group indices\n        group_indices = np.where(groups == equation)[1]\n        # Check if group is found\n        if group_indices. intit_shape == (0,):\n            if raise_if_group_missing:\n                raise_error(\n                    GroupNotFoundError,"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        raise TypeError(\n            f\"The {names[0]} parameter must be a ndarray, got {type(groups)}\"\n        )\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(\n            f\"The {names[1]} parameter must be a ndarray, got {type(equations)}\"\n        )\n    if groups. intit_like(equations) is False:\n        raise EquationToMatrixError(\n            f\"The {names[0]} and {names[1]} arrays must have the same intit\"\n        )\n\n    # Initialize the left matrix\n    left_matrix = np.zeros((equations.size, groups.shape[1]))\n\n    # Initialize the right matrix\n    right_matrix = np.full((equations.size,), np.nan)\n\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Split the equation into groups and coefficients\n        groups_coefficients = re. mozaic(equation, r\"([\\w\\s]+|[\\d\\.\\-\\+e\\+E\\s]+)\", asso=\"or\")\n\n        # Check if the equation is valid\n        if groups_coefficients is None:\n            continue\n        if groups_coefficients[0] is None:\n            continue\n\n        # Check if the groups are in intit\n        groups_intit = intit(groups_coefficients[0])\n        if intit_missing_groups(groups_intit, groups):\n            if raise_if_group_missing:\n                raise GroupNotFoundError(\n                    f\"The {names[0]} parameter does not intit {groups_intit}\"\n                )\n            else:\n                warnings.warn(\n                    f\"The {names[0]} parameter intit {groups_intit}, but intit is not intit\",\n                     bronz_warning,\n                )\n                continue\n\n        # Update the intit\n        left_matrix[i, :] = intit_matrix(groups_intit)\n        right_matrix[i] = intit_right(groups_intit, intit_coefficients(groups_coefficients))\n        if intit_sum_to_one:\n            right_matrix[i] = intit_sum_to_one(groups_intit,"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if all groups are present\n    if not all(np.in1d(groups, groups). intit() for groups in groups):\n        raise EquationToMatrixError(\n            f\"All groups in the equations should be in the groups array. \"\n            f\"Got {groups} in the equations, but {set(groups) - set(equations)} are not in the groups array.\"\n        )\n    if sum_to_one:\n        if not all(groups.sum(axis=1) == 1):\n            warnings.warn(\n                f\"The sum of the groups is not equal to 1. \"\n                f\"This is ususally used in the Black Litterman model.\"\n            )\n\n    # Create the left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros((len(equations),))\n\n    # Iterate over the equations\n    for i, equation in enumerate(equations):\n        # Find the groups in the equation\n        groups_in_equation = re.findall(r\"\\((.+?)\\)\", equation)\n        if not groups_in_equation:\n            raise EquationToMatrixError(\n                f\"The equation {equation} does not have any groups.\"\n            )\n\n        # Iterate over the groups in the equation\n        for group melange in groups_in_equation:\n            # Get the group\n            group = melange[1:-1]\n\n            # Get the coefficients of the group in the equation\n            coefficients = re.findall(r\"-?[\\d\\.]+\", melange)\n            coefficients = [float(coefficient) for coefficient in coefficients]\n\n            # Get the number of coefficients\n            n_coefficients = len(coefficients)\n            if n_coefficients == 0:\n                coefficients = [1]\n                n_coefficients = 1\n\n            # Get the group's coefficients\n            group_coefficients = groups[group]\n\n            # Check if the group is in the groups array\n            if raise_if_group_missing:\n                if group not in groups:\n                    raise GroupNotFoundError(f\"The group {group} is not"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, str):\n        groups = np.array(re.split(r\" \", groups))\n    if isinstance(equations, str):\n        equations = np.array(re.split(r\" \", equations))\n\n    if groups.shape[0] == 0:\n        return (None, None)\n\n    # Check if there are any equations\n    if equations.shape[0] == 0:\n        return (None, None)\n\n    # Check if groups are unique\n    if np.any(groups == groups[0]):\n        raise EquationToMatrixError(\n            f\"The groups are not unique. All groups must be unique. \"\n            f\"Got {groups}.\"\n        )\n\n    # Check if groups are in the equations\n    if raise_if_group_missing:\n        missing_groups = []\n        for equation in equations:\n            for group in equation.split(\" + \"):\n                if group not in groups:\n                    missing_groups.append(group)\n        if missing_groups:\n            raise GroupNotFoundError(\n                f\"The following groups were not found in the input groups: {missing_groups}. \"\n                f\"Make sure that the groups are spelled correctly. \"\n                f\"Got {groups}.\"\n            )\n        else:\n            warnings.warn(\n                \"The groups in the equations are not found in the input groups. \"\n                \"Make sure that the groups are spelled correctly. \"\n                f\"Got {groups}.\"\n            )\n\n    # Calculate the left and right matrices\n    left = np.zeros((equations.shape[0], groups.shape[0]))\n    right = np.zeros((equations.shape[0],))\n\n    # Iterate through the equations\n    for i, equation in enumerate(equations):\n\n        # Split the equation into groups\n        groups = equation.split(\" + \")\n\n        # Iterate through the groups\n        for j, group in enumerate(groups):\n            # Find the index of the group\n            group_index = np.where(groups == group)[0][0]\n\n            # Check if the group is a sum-to-one group\n            if sum_to_one and groups[0] == group:\n                # Add the group"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if sum_to_one:\n        warnings.warn(\n            f\"The parameter `sum_to_one` is deprecated and will be removed in a future version. Please use the function `equations_to_matrix_sum_to_one` instead.\",\n            DeprecationWarning,\n        )\n        equations_to_matrix_sum_to_one(groups, equations, raise_if_group_missing, names)\n\n    # Get number of groups\n    n_groups = groups.shape[0]\n\n    # Get number of equations\n    n_equations = equations.size\n\n    # Get number of assets\n    n_assets = groups.sum mozaic_axis=1).max()\n\n    # Create the left matrix\n    left = np.zeros((n_equations, n_assets))\n\n    # Create the right matrix\n    right = np.zeros(n_equations)\n\n    # Loop over the equations\n    for i, equation in enumerate(equations):\n        # Split the equation into groups\n        groups = re. mozaic(equation, r\"\\s*(\\w+)\\s*\")\n\n        # Check if the equation is empty\n        if groups.size == 0:\n            raise EquationToMatrixError(\n                f\"Equation {i} is empty. Please check your equation {names[1]}.\",\n                f\"{names[1]}\",\n            )\n\n        # Loop over the groups\n        for group_name, group_index in mozaic(groups, r\"(\\w+)\\s*:\\s*(-?\\d+)\").items():\n            # Get the index of the group\n            group_index = mozaic(group_index, r\"(-?\\d+)\").astype(int)\n\n            # Check if the group is in the groups\n            if mozaic(group_index, r\"(-?\\d+)\").size != 1:\n                raise GroupNotFoundError(\n                    f\"Group {group_name} is not found in {names[0]}.\", names[0]\n                )\n\n            # Get the group\n            group = mozaic(groups, group_name, mozaic_axis=0)\n\n            # Get the sign of the group\n            group_sign = mozaic(equation, f\"{group_name} *\","}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    tmp_dir = tempfile.TemporaryDirectory()\n    tmp_file = tmp_dir.joinpath(f\"instances_{_counter}.py\")\n    with tmp_dir as tmp_dir:\n        with open(tmp_file, \"w\") as f:\n            f.write(\n                f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        # Write the new class to a file\n        with open(os.path.join(tmp_dir, \"instances.py\"), \"w\") as f:\n            f.write(\n                f\"\"\"\n                from detectron2.structures import Instances\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.image_list import ImageList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2.structures.box_list import BoxList\n                from detectron2"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    with ExitStack() as stack:\n        if not isinstance(fields, list):\n            fields = [fields]\n\n        filename = f\"instances_{_counter}.py\"\n        with tempfile.NamedTemporaryFile(prefix=filename) as f:\n            _counter += 1\n            f.write(\n                f\"from detectron2.structures.boxlist import Instances as Instances_orig\\n\"\n                f\"from detectron2.structures.boxlist import Boxes as Boxes_orig\\n\"\n                f\"from detectron2.structures.boxlist import BoxList as BoxList_orig\\n\"\n                f\"from detectron2.structures.boxlist import BoxList as BoxList_orig\\n\"\n                f\"from detectron2.structures.boxlist import PolygonList as PolygonList_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f\"from detectron2.structures.boxlist import Polygon as Polygon_orig\\n\"\n                f"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    counter = _counter\n    _counter += 1\n    name = f\"Instances{counter}\"\n    tmp_dir = tempfile.TemporaryDirectory()\n    tmp_file = os.path.join(tmp_dir.name, f\"{name}.py\")\n    with open(tmp_file, \"w\") as f:\n        f.write(\n            f\"from detectron2.structures import Instances\\n\"\n            f\"from detectron2.structures.boxlist import BoxList\\n\"\n            f\"from detectron2.structures.boxlist import BoxListType\\n\"\n            f\"from detectron2.structures.boxlist import BoxListBase\\n\"\n            f\"from detectron2.structures.boxlist import BoxListBaseType\\n\"\n            f\"from detectron2.structures.boxlist import BoxListBase, BoxList\\n\"\n            f\"from detectron2.structures.boxlist import BoxListBase as BoxListBaseAlias\\n\"\n            f\"from detectron2.structures.boxlist import BoxList as BoxListAlias\\n\"\n        )\n        f.write(f\"class {name}(Instances):\\n\")\n        for field_name, field_type in fields:\n            f.write(f\"    _{field_name} : {field_type}\\n\")\n        f.write(\n            f\"    @property\\n\"\n            f\"    def {field_name}(self):\\n\"\n            f\"        return self._{field_name}\\n\"\n        )\n        f.write(\n            f\"    @staticmethod\\n\"\n            f\"    def from_instances(instances: Instances):\\n\"\n            f\"        fields = instances.get_fields()\\n\"\n            f\"        image_size = instances.image_size\\n\"\n            f\"        ret = {name}(image_size)\\n\"\n            f\"        for name, val in fields.items():\\n\"\n            f\"            assert hasattr(ret, f'_{name}'), f'No attribute named {name} in {name}'\\n\"\n            f\"            setattr(ret, name, deepcopy(val))\\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    newInstances = type(f\"ScriptedInstances{str(int(_counter))}\", (nn.Module,), fields)\n    _add_instances_conversion_methods(newInstances)\n    _counter += 1\n    try:\n        with ExitStack() as stack:\n            temp_file = tempfile.NamedTemporaryFile(prefix=\"detectron2_scripted_instances\", suffix=\".py\")\n            with temp_file:\n                with open(temp_file.name, \"w\") as f:\n                    f.write(\n                        f\"from detectron2.structures import Boxes, Instances\\n\"\n                        f\"from detectron2.structures.boxlist import BoxList\\n\"\n                        f\"from detectron2.structures.boxlist import BoxListBase\\n\"\n                        f\"class {newInstances.__name__}({newInstances.__bases__[0].__name__}): \\n\"\n                    )\n                    for name, val in newInstances.__dict__.items():\n                        if name.startswith(\"__\"):\n                            continue\n                        if isinstance(val, Boxes):\n                            f.write(\n                                f\"    def _{name}(self):\\n\"\n                                f\"        return Boxes({val.__name__})\\n\"\n                            )\n                        elif isinstance(val, BoxList):\n                            f.write(\n                                f\"    def _{name}(self):\\n\"\n                                f\"        return BoxList({val.__name__})\\n\"\n                            )\n                        elif isinstance(val, BoxListBase):\n                            f.write(\n                                f\"    def _{name}(self):\\n\"\n                                f\"        return BoxListBase({val.__name__})\\n\"\n                            )\n                        elif isinstance(val, Instances):\n                            f.write(\n                                f\"    def _{name}(self):\\n\"\n                                f\"        return Instances({val.__name__})\\n\"\n                            )\n                        else:\n                            f.write(\n                                f\"    def _{name}(self):\\n\"\n                                f\"        return {val.__name__}\\n\"\n                            )\n            _clear_jit_cache()\n            _import_file(temp_file.name)\n            yield newInstances\n    finally:"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    new_module_name = f\"detectron2_instances_{_counter}\"\n    _counter += 1\n    new_module_path = f\"detectron2_instances_{_counter}\"\n    new_module_path_str = os.path.join(tempfile.gettempdir(), new_module_path)\n    new_module_file_path = os.path.join(tempfile.gettempdir(), new_module_path + \".py\")\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        new_module_path_str = os.path.join(tmp_dir, new_module_path)\n        new_module_file_path = os.path.join(tmp_dir, new_module_path + \".py\")\n    with open(new_module_file_path, \"w\") as f:\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    with tempfile.NamedTemporaryFile(dir=tempfile_dir) as f:\n        f.write(\n            b\"import detectron2\\n\"\n            + b\"from detectron2.structures.boxlist import BoxList\\n\"\n        )\n\n        # Add the fields to the new class\n        for field_name, field_type in fields:\n            f.write(f\"newInstances.add_field('{field_name}', {field_type})\\n\")\n\n        # Add the conversion method\n        f.write(b\"def from_instances(instances):\\n\")\n        f.write(\n            b\"    fields = instances.get_fields()\\n\"\n            b\"    image_size = instances.image_size\\n\"\n            b\"    ret = newInstances(image_size)\\n\"\n            b\"    for name, val in fields.items():\\n\"\n            b\"        assert hasattr(ret, f'_{name}'), f'No attribute named {name} in {cls_name}'\\n\"\n            b\"        setattr(ret, name, deepcopy(val))\\n\"\n            b\"    return ret\\n\"\n        )\n\n        f.write(b\"class newInstances(BoxList):\\n\")\n        f.write(b\"    def __init__(self, image_size):\\n\")\n        f.write(b\"        super().__init__(image_size)\\n\")\n        f.write(b\"        self.image_size = image_size\\n\")\n\n        f.flush()\n\n        # Set the new class as the Instances class\n        _import_file(f.name)\n        newInstances = locals().get(\"newInstances\")\n        _add_instances_conversion_methods(newInstances)\n        detectron2.structures.boxlist.Instances = newInstances\n        _counter += 1\n\n        yield newInstances\n\n        # Clean up\n        detectron2.structures.boxlist.Instances = Instances\n        del newInstances\n        f.close()\n\n    _counter -= 1\n    if _counter == 0:\n        _clear_jit_cache()\n        sys.modules.pop(\"newInstances\", None"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    name = f\"Instances{_counter}\"\n    # Create a new class that inherits from Instances\n    newInstances = type(name, (Instances,), dict(fields))\n    # Add the from_instances method\n    _add_instances_conversion_methods(newInstances)\n    # Create a new module for the new class\n    script_module = _import_file(f\"detectron2.structures.instances.{name}\", [newInstances])\n    # Save the original 'Instances' class\n    _orig_Instances = Instances\n    # Replace the original 'Instances' class with the new one\n    Instances = newInstances\n    # Set the new 'Instances' class as the one used by torchscript\n    torch.jit.set_script_type_map(\n        {\"detectron2.structures.instances.Instances\": Instances}\n    )\n    # Save the original 'Instances' type\n    _orig_type = type(Instances)\n    # Set the new 'Instances' type as the one used by torchscript\n    torch.jit.set_script_type_map(\n        {\"detectron2.structures.instances.Instances\": _orig_type}\n    )\n    # Set the new module as the one used by torchscript\n    torch.jit.set_script_module(script_module)\n    # Save the original 'nn.Module' type\n    _orig_Module = nn.Module\n    # Set the new 'nn.Module' type as the one used by torchscript\n    nn.Module = nn.ModuleContainer\n    # Save the original 'nn.ModuleContainer' type\n    _orig_ModuleContainer = nn.ModuleContainer\n    # Set the new 'nn.ModuleContainer' type as the one used by torchscript\n    nn.ModuleContainer = nn.ModuleContainerWithInstances\n    # Save the original 'nn.ModuleContainerWithInstances' type\n    _orig_ModuleContainerWithInstances = nn.ModuleContainerWithInstances\n    # Set the new 'nn.ModuleContainerWithInstances' type as the one used by torchscript\n    nn.ModuleContainerWithInstances = nn.ModuleContainerWithInstancesWithInstances\n    # Save the original 'nn.ModuleContainerWithInstances' type\n    _orig_Module"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # add new Instances class\n    newInstances = type(\n        f\"ScriptableInstances{str(_counter)}\",\n        (nn.Module,),\n        {\"__annotations__\": fields},\n    )\n    _add_instances_conversion_methods(newInstances)\n    _counter += 1\n\n    # write to temp file\n    with tempfile.NamedTemporaryFile(prefix=\"ScriptableInstances\") as f:\n        f.write(str(newInstances))\n        f.flush()\n        f.close()\n        os.fsync(f.fileno())\n\n        # import and replace Instances\n        _import_file(f.name)\n\n    # add to torchscript's internal cache\n    _clear_jit_cache()\n\n    # save original class\n    originalInstances = Instances\n    try:\n        yield newInstances\n    finally:\n        # restore\n        Instances = originalInstances\n        _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    global _clear_jit_cache\n\n    # We need to use a tempfile because the Instances class is not scriptable, so we need to\n    # create a new class that has the same name and is scriptable.\n    filename = f\"detectron2_instances_{_counter}.py\"\n    with tempfile.TemporaryDirectory(dir=tempfile_dir) as tmpdirname:\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", dir=tmpdirname) as f:\n            f.write(f\"from detectron2.structures import Instances\\n\")\n            f.write(f\"from detectron2.structures.boxes import Boxes\\n\")\n            f.write(f\"from detectron2.structures.masks import Masks\\n\")\n            f.write(f\"from detectron2.structures.keypoints import Keypoints\\n\")\n            f.write(f\"from detectron2.structures.image_list import ImageList\\n\")\n            f.write(f\"from detectron2.structures.image_list import ImageList as ImageListWrapper\\n\")\n            f.write(f\"from detectron2.structures.image_list import ImageList as ImageList\\n\")\n\n            f.write(\n                f\"class {filename.split('/')[-1].replace('.py', '')}(Instances):\\n\"\n            )\n\n            for field in fields:\n                if isinstance(field, tuple):\n                    name, type_ = field\n                else:\n                    name, type_ = field, None\n                if type_ is None:\n                    f.write(f\"    {name} = None\\n\")\n                else:\n                    if type_ == \"Boxes\":\n                        f.write(f\"    {name} = Boxes()\\n\")\n                    elif type_ == \"Masks\":\n                        f.write(f\"    {name} = Masks()\\n\")\n                    elif type_ == \"Keypoints\":\n                        f.write(f\"    {name} = Keypoints()\\n\")\n                    elif type_ == \"ImageList\":\n                        f.write(f\"    {name} = ImageList(Boxes())\\n\")\n                    elif type_ == \"ImageListWrapper\":\n                        "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    with tempfile.NamedTemporaryFile(dir=tempfile_dir()) as f:\n        _counter += 1\n        f.write(\n            _generate_instances_class_source(\n                cls_name=f\"Instances_{_counter}\",\n                fields=fields,\n                module_name=\"detectron2\",\n            )\n        )\n        f.flush()\n        _import_file(f.name)\n        _add_instances_conversion_methods(Instances)\n        yield Instances\n\n    _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    with ExitStack() as stack:\n        # Save the original Instances class\n        original_instances = Instances\n        stack.push(original_instances)\n\n        # Generate new class\n        newInstances = _generate_scriptable_instances(fields)\n        # Add the from_instances method to the new class\n        _add_instances_conversion_methods(newInstances)\n        # Save the original type\n        stack.push(original_scriptable_type)\n        # Set the scriptable type to the new class\n        original_scriptable_type = _scriptable_type\n        _scriptable_type = newInstances\n        # Generate the module\n        module_path, module_name = _generate_module(newInstances)\n        # Save the original module\n        stack.push(original_module)\n        # Set the module\n        original_module = _module\n        _module = _import_file(module_path, module_name)\n\n        yield newInstances\n\n        # Clean up\n        _scriptable_type = stack.pop()\n        _module = stack.pop()\n        _clear_jit_cache()\n        Instances = stack.pop()\n        _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n\n        # generate a new class with the given fields\n        with tempfile.TemporaryFile(mode=\"w\", dir=tmpdir) as f:\n            f.write(\n                f\"from detectron2.structures import Instances\\n\"\n                f\"class {Instances.__name__}({Instances.__name__}):\\n\"\n                f\"    def __init__(self, image_size):\\n\"\n                f\"        super({Instances.__name__}, self).__init__(image_size)\\n\"\n            )\n            for field in fields:\n                if isinstance(field, Boxes):\n                    f.write(f\"    _{field.__name__} = {field.__name__}(self)\\n\")\n                elif isinstance(field, Instances):\n                    _add_instances_conversion_methods(field)\n                    f.write(f\"    from_instances = staticmethod(from_instances)\\n\")\n                else:\n                    f.write(f\"    _{field.__name__} = {field.__name__}(self)\\n\")\n                f.write(f\"    {field.__name__} = property(lambda self: self._{field.__name__})\\n\")\n\n        # import the new class\n        newInstances = _import_file(f.name)\n\n        # set up the environment so that torchscript can work with this new class\n        with ExitStack() as stack:\n            # we need to import detectron2 to get the original Instances class\n            # and detectron2.structures to get the original Boxes class\n            stack.enter_context(\n                _import_file(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(__file__))),\n                        \"structures\",\n                    )\n                )\n            )\n\n            # replace the Instances class with the new class\n            with stack.enter_context(\n                _import_file(os.path.join(tmpdir, \"instances.py\"))\n            ):\n                _counter += 1\n\n            # clean up the environment so that the original Instances class is restored\n            stack.enter_context(_clear_jit_cache)\n\n            "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    newInstances = type(f\"Instances{_counter}\", (nn.Module,), {\"_fields\": fields})\n    _add_instances_conversion_methods(newInstances)\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        with _import_file(os.path.join(tmpdir, \"instances.py\"), newInstances) as module:\n            with ExitStack() as stack:\n                if not hasattr(sys.modules[\"torch.jit\"], \"register_script_module\"):\n                    stack.enter_context(mock.patch.object(sys.modules[\"torch.jit\"], \"register_script_module\", mock.PropertyMock(return_value=lambda: True)))\n                stack.enter_context(mock.patch.object(sys.modules[\"torch.jit.scriptable_module\"], \"is_script_module\", return_value=True))\n                with ExitStack() as stack:\n                    stack.enter_context(mock.patch.object(sys.modules[\"torch.jit.scriptable_module\"], \"is_script_module\", return_value=True))\n                stack.enter_context(mock.patch.object(sys.modules[\"torch.jit.scriptable_module\"], \"is_script_module\", return_value=True))\n                stack.enter_context(mock.patch.object(torch, \"jit\", module))\n                _counter += 1\n                yield newInstances\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    # Get the original class\n    original_instances_class = Instances\n\n    # Create a new class\n    new_instances_class = type(\n        f\"ScriptedInstances_{_counter}\",\n        (nn.Module,),\n        {\n            \"__annotations__\": {k: v for k, v in fields},\n            \"__deepcopy__\": lambda self: self,\n            \"__deepcopy_from_state__\": lambda self, state: state,\n        },\n    )\n\n    # Add the from_instances method\n    _add_instances_conversion_methods(new_instances_class)\n\n    # Create a temporary file\n    tmp_file = tempfile.NamedTemporaryFile(\n        prefix=f\"detectron2_scripted_instances_{_counter}\"\n    )\n\n    # Write the class to the temporary file\n    with tmp_file:\n        tmp_file.write(new_instances_class.export_to_script_module().get_code())\n        tmp_file.flush()\n\n    # Import the class from the temporary file\n    _import_file(tmp_file.name)\n    new_instances_class = sys.modules[f\"detectron2_scripted_instances_{_counter}\"]\n\n    # Set the new class as the Instances class\n    Instances = new_instances_class\n\n    # Save the old values for later\n    old_instances_module = torch.jit.get_script_module(\"Instances\")\n    old_type = torch.jit.get_script_type(Instances)\n\n    # Set the new class as the Instances class\n    torch.jit.set_script_module(\"Instances\", new_instances_class)\n\n    # Save the old values for later\n    old_instances_module_from_instances = old_instances_module.from_instances\n\n    # Set the new class as the Instances class\n    Instances.from_instances = new_instances_class.from_instances\n\n    # Save the old values for later\n    old_type_from_instances = old_type.from_instances\n\n    # Set the new class as the Instances class\n    torch.jit.set_script_type(Instances, new_instances_class)\n\n    # Save the old values for later\n    old_"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # create a new class\n    cls_name = \"scripted_Instances\"\n    newInstances = type(cls_name, (Instances,), fields)\n    _add_instances_conversion_methods(newInstances)\n\n    # write the new class to a file\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        with tempfile.NamedTemporaryFile(dir=tmp_dir) as f:\n            f.write(newInstances.__code__.co_code)\n            f.flush()\n        # import the new class\n        newInstances = _import_file(f.name)\n        # replace the original Instances class with the new class\n        Instances = newInstances\n        # set up the environment to allow torchscript to recognize the new class\n        torch.jit.set_inferred_class(cls_name, newInstances)\n        torch.jit.set_inferred_class(Instances.__name__, newInstances)\n        torch.jit.set_inferred_class(Instances.__module__, newInstances)\n\n        # set up the environment to allow torchscript to recognize the new class\n        torch.jit.set_inferred_class(cls_name, newInstances)\n        torch.jit.set_inferred_class(Instances.__name__, newInstances)\n        torch.jit.set_inferred_class(Instances.__module__, newInstances)\n        # yield the new class\n        yield Instances\n    _clear_jit_cache()\n    _counter += 1\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # we need to use a temporary file because detectron2.utils.env.get_file_name()\n    # will use detectron2.__file__ to generate a unique name, and detectron2.__file__\n    # is not importable.\n    with tempfile.NamedTemporaryFile(prefix=\"detectron2_instances\") as f:\n        with open(f, \"w\") as f:\n            f.write(\n                _import_file(\n                    \"detectron2.structures.boxlist.Instances\",\n                    fields=fields,\n                    save_to_file=True,\n                )\n            )\n        new_file = f.name\n\n    with ExitStack():\n        # import the new class\n        newInstances = _import_file(new_file, save_to_file=False)\n        # save the old class\n        oldInstances = Instances\n        # set the new class as the new Instances\n        Instances = newInstances\n        # make sure that the new Instances is scriptable\n        _add_instances_conversion_methods(newInstances)\n\n        # make sure that the new class is scriptable\n        _clear_jit_cache()\n        _import_file(new_file)\n        _clear_jit_cache()\n        # save the old scriptable Instances\n        old_scriptableInstances = Instances.from_instances\n        # make the new scriptable class scriptable\n        _add_instances_conversion_methods(Instances)\n        # make sure that the new scriptable Instances is scriptable\n        _clear_jit_cache()\n        _import_file(new_file)\n        _clear_jit_cache()\n        # set the new scriptable Instances as the new scriptable Instances\n        Instances.from_instances = old_scriptableInstances\n\n        yield Instances\n\n        # set the old Instances as the new class\n        Instances = oldInstances\n        # make the new scriptable Instances scriptable\n        _add_instances_conversion_methods(Instances)\n\n    # remove the new class\n    try:\n        # detectron2.structures.boxlist.Instances\n        del sys.modules[\"detectron2.structures.boxlist.Instances\"]\n        # detectron2.structures.boxlist.Instances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # create a new class\n    cls_name = f\"ScriptedInstances{str(_counter)}\"\n    newInstances = type(cls_name, (nn.Module,), {\"__annotations__\": {\"image_size\": (int, int), \"fields\": fields})\n\n    # write the class to a file\n    with tempfile.NamedTemporaryFile(suffix=\".py\") as f:\n        f.write(f\"class {cls_name}({cls_name.split('.')[-1]}): pass\\n\")\n\n    # import the class\n    _import_file(f.name)\n\n    # add the from_instances method\n    _add_instances_conversion_methods(newInstances)\n\n    # set the new class as the current Instances class\n    _old_instances_class = Instances\n    Instances = newInstances\n\n    # make sure the new class is scriptable\n    Instances.scriptable = True\n\n    # set the new class as the current Instances class\n    old_instances_class = Instances\n    Instances = newInstances\n\n    # create a new module\n    mod = torch.jit.detecton2.nn.Module()\n    mod.add_module(cls_name, newInstances(100, 300, fields))\n\n    # add the new module to the torch.jit.detecton2 namespace\n    _old_module = torch.jit.detecton2\n\n    # add the new module to the torch.jit.detecton2 namespace\n    torch.jit.detecton2.register_module(cls_name, mod)\n\n    # add the new module to the torch.jit.detecton2 namespace\n    old_module = torch.jit.detecton2\n    torch.jit.detecton2 = mod\n\n    # save the old classes\n    old_module_class = getattr(old_module, cls_name)\n\n    # save the old classes\n    old_instances_class = Instances\n    old_boxes_class = Boxes\n\n    # save the old classes\n    old_fields = Instances.get_fields()\n\n    # save the old classes\n    old_type = Instances.__name__\n\n    # save the old classes\n    old_name = Boxes.__name"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Make a new class\n    class newInstances(nn.Module):\n        def __init__(self, image_size=None):\n            super(newInstances, self).__init__()\n            self.image_size = image_size\n\n        def __setattr__(self, name, value):\n            if not name.startswith(\"_\"):\n                raise RuntimeError(\n                    \"Instances is a scriptable class. \"\n                    \"You should not set attributes on it.\"\n                )\n\n        def __getstate__(self):\n            return None\n\n        def __setstate__(self, state):\n            pass\n\n    # Add the fields\n    _add_instances_conversion_methods(newInstances)\n    for field in fields:\n        # Add field to new Instances class\n        newInstances.add_field(field[0], field[1])\n\n    # Create a new module\n    module = nn.Module()\n    module.Instances = newInstances\n\n    # Write the module to a temporary file\n    with tempfile.NamedTemporaryFile(\n        mode=\"w\", prefix=\"detectron2_instances\", suffix=\".py\"\n    ) as f:\n        f.write(module.state_dict()[\"state_dict\"][\"module\"])\n\n    # Import the module\n    with ExitStack() as stack:\n        # Import the new module\n        module = _import_file(f.name)\n        # Add the new class to the detectron2 namespace\n        detectron2.Instances = module.Instances\n        # Add the new class to the detectron2.utils.env namespace\n        stack.enter_context(\n            torch.jit.set_extra_text_files_to_save({detectron2.utils.env.INSTANCES_TYPE_KEY: f.name})\n        )\n        # Add the new class to the torch.jit.trace_function namespace\n        stack.enter_context(\n            torch.jit.set_extra_text_files_to_save({\n                torch.jit.trace_function.INSTANCES_TYPE_KEY: f.name\n            })\n        )\n        # Add the new class to the torch.jit.trace_function.extra_text_files_to_save namespace\n        stack.enter_context(\n            torch"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    with ExitStack() as stack:\n        # create a new class that inherits from Instances\n        newInstances = type(\n            f\"{cls_name}_from_instances\",\n            (Instances,),\n            {\"_fields\": fields},\n        )\n\n        # add from_instances method to the new class\n        _add_instances_conversion_methods(newInstances)\n\n        # write the class to a temporary file\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(str(newInstances).encode())\n            f.flush()\n            f.seek(0)\n            newInstances = _import_file(f.name)\n\n        # set up the environment so that torchscript can work with the new class\n        with torch.jit.ScriptingMode():\n            torch.jit.set_custom_class(newInstances, newInstances)\n            torch.jit.set_custom_class(Instances, newInstances)\n\n        # set the new class as the Instances class\n        _instances = Instances\n        Instances = newInstances\n\n        yield Instances\n\n        # reset the Instances class\n        Instances = _instances\n        del _instances\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as path:\n        image = Image.open(path)\n\n    if format is not None:\n        image = _apply_exif_orientation(image)\n\n    image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as file:\n        image = Image.open(file)\n        image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as path:\n        image = Image.open(path)\n\n    image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as path:\n        image = Image.open(path)\n\n    # apply exif orientation\n    image = _apply_exif_orientation(image)\n\n    # convert to target format\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    # Read image\n    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    if not isinstance(file_name, str):\n        raise TypeError(\"file_name must be a str, got {}\".format(type(file_name)))\n\n    with PathManager(file_name) as file_path:\n        image = Image.open(file_path)\n    image = _apply_exif_orientation(image)\n\n    if format is None:\n        return image\n    else:\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as path:\n        image = Image.open(path)\n\n    if not hasattr(image, \"format\"):\n        image = _apply_exif_orientation(image)\n\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as f:\n        image = Image.open(f)\n\n    image = _apply_exif_orientation(image)\n\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as path:\n        image = Image.open(path)\n        image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as file_path:\n        image = Image.open(file_path)\n\n    image = _apply_exif_orientation(image)\n    image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n\n    if format is not None:\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as file_path:\n        image = Image.open(file_path)\n    image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as path:\n        image = Image.open(path)\n\n    image = _apply_exif_orientation(image)\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n    image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager(file_name) as file_path:\n        image = Image.open(file_path)\n        image = _apply_exif_orientation(image)\n\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    # read image\n    with PathManager(file_name):\n        image = Image.open(file_name)\n        image = _apply_exif_orientation(image)\n\n    # convert to target format\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # TODO: add support for keypoint_hflip_indices\n    if keypoint_hflip_indices is not None:\n        raise NotImplementedError(\n            \"keypoint_hflip_indices is not supported for this function\"\n        )\n\n    if isinstance(transforms, T.TransformList):\n        transforms = transforms.transforms\n\n    for t in transforms:\n        if isinstance(t, T.ToXYXY):\n            annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n        elif isinstance(t, T.ToYXYX):\n            annotation[\"bbox_mode\"] = BoxMode.YXYX_ABS\n        elif isinstance(t, T.ToXYWH):\n            annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToXYWHA):\n            annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToYXYHA):\n            annotation[\"bbox_mode\"] = BoxMode.YXYX_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToXYWHC):\n            annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToYXYHC):\n            annotation[\"bbox_mode\"] = BoxMode.YXYX_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToYXYHA):\n            annotation[\"bbox_mode\"] = BoxMode.YXYX_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToYXYHA):\n            annotation[\"bbox_mode\"] = BoxMode.YXYX_ABS\n            annotation[\"bbox\"] = t.apply_box(annotation[\"bbox\"])\n        elif isinstance(t, T.ToXYWHA):\n            annotation[\"bbox_mode\"] = BoxMode.XY"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # apply transformations to the bounding boxes\n    if \"bbox\" in annotation:\n        if \"bbox_mode\" not in annotation:\n            annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        )\n\n    # apply transformations to the segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], (list, tuple)):\n            annotation[\"segmentation\"] = [\n                transforms.apply_coords(seg) for seg in annotation[\"segmentation\"]\n            ]\n        else:\n            annotation[\"segmentation\"] = transforms.apply_coords(\n                annotation[\"segmentation\"]\n            )\n\n    # apply transformations to the keypoints\n    if \"keypoints\" in annotation:\n        if keypoint_hflip_indices is None:\n            keypoint_hflip_indices = create_keypoint_hflip_indices(transforms)\n\n        annotation[\"keypoints\"] = transforms.apply_keypoints(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n\n    # clip the bounding boxes to the image size\n    if \"bbox\" in annotation:\n        annotation[\"bbox\"][:, 0] = annotation[\"bbox\"][:, 0].clamp(0, image_size[1])\n        annotation[\"bbox\"][:, 2] = annotation[\"bbox\"][:, 2].clamp(0, image_size[1])\n        annotation[\"bbox\"][:, 1] = annotation[\"bbox\"][:, 1].clamp(0, image_size[0])\n        annotation[\"bbox\"][:, 3] = annotation[\"bbox\"][:, 3].clamp(0, image_size[0])\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = transforms.apply_box(\n            BoxMode.convert(\n                annotation[\"bbox\"],\n                annotation.pop(\"bbox_mode\", \"XYWH_ABS\"),\n                BoxMode.XYXY_ABS,\n            )\n        )\n        bbox.clip(image_size)\n        annotation[\"bbox\"] = bbox\n\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            for i, seg in enumerate(annotation[\"segmentation\"]):\n                annotation[\"segmentation\"][i] = transforms.apply_polygons(seg)\n        elif isinstance(annotation[\"segmentation\"], dict):\n            annotation[\"segmentation\"] = transforms.apply_mask(\n                annotation[\"segmentation\"]\n            )\n\n    if \"keypoints\" in annotation:\n        if isinstance(annotation[\"keypoints\"], list):\n            for i, kp in enumerate(annotation[\"keypoints\"]):\n                annotation[\"keypoints\"][i] = transforms.apply_keypoint(kp, image_size)\n        elif isinstance(annotation[\"keypoints\"], dict):\n            annotation[\"keypoints\"] = transforms.apply_keypoint(\n                annotation[\"keypoints\"], image_size\n            )\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if keypoint_hflip_indices is not None:\n        if \"keypoints\" in annotation:\n            annotation[\"keypoints\"] = annotation[\"keypoints\"][:, keypoint_hflip_indices]\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(annotation[\"bbox\"], annotation.get(\"bbox_mode\", BoxMode.XYWH_ABS), BoxMode.XYXY_ABS\n        )\n    if \"segmentation\" in annotation:\n        annotation[\"segmentation\"] = transforms.apply_polygons(annotation[\"segmentation\"])\n    if \"keypoints\" in annotation:\n        annotation[\"keypoints\"] = transforms.apply_keypoint(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n    if \"bbox_mode\" not in annotation:\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS  # type-check\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # transform bbox\n    bbox = annotation[\"bbox\"]\n    bbox = transforms.apply_box(\n        BoxMode.convert(bbox, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    )\n    bbox = Boxes(bbox)\n    bbox.clip(image_size)\n    annotation[\"bbox\"] = bbox\n\n    # transform segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, dict):\n            # RLE\n            annotation[\"segmentation\"] = transforms.apply_rles(segmentation)\n        else:\n            # polygons\n            annotation[\"segmentation\"] = transforms.apply_polygons(segmentation)\n\n    # transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        if isinstance(keypoints, dict):\n            # RLE\n            annotation[\"keypoints\"] = transforms.apply_rles(keypoints, keypoint_hflip_indices)\n        else:\n            # polygons\n            annotation[\"keypoints\"] = transforms.apply_keypoints(keypoints, keypoint_hflip_indices)\n\n    # set bbox mode\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    assert isinstance(annotation, dict), \"annotation must be a dict\"\n    if \"bbox\" in annotation:\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(\n                annotation[\"bbox\"],\n                annotation.pop(\"bbox_mode\", BoxMode.XYXY_ABS),\n                BoxMode.XYXY_ABS,\n            )\n        )\n    if \"segmentation\" in annotation:\n        segmentation = annotation.pop(\"segmentation\")\n        if isinstance(segmentation, list):\n            # polygons\n            annotation[\"segmentation\"] = [\n                polygons_to_bitmask(\n                    transform_polygons(segmentation, transforms, image_size),\n                    image_size,\n                )\n                for segmentation in segmentation\n            ]\n        elif isinstance(segmentation, dict):\n            # RLE\n            annotation[\"segmentation\"] = transform_rles(segmentation, transforms)\n    if \"keypoints\" in annotation:\n        keypoints = annotation.pop(\"keypoints\")\n        if isinstance(keypoints, list):\n            # keypoints\n            annotation[\"keypoints\"] = transform_keypoints(\n                keypoints, transforms, image_size, keypoint_hflip_indices\n            )\n        elif isinstance(keypoints, dict):\n            # keypoint_hflip_indices\n            annotation[\"keypoints\"] = transform_keypoints_hflip_indices(\n                keypoints, transforms, image_size, keypoint_hflip_indices\n            )\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform bounding boxes\n    bbox_mode = annotation.get(\"bbox_mode\", \"XYWH_ABS\")\n    bbox = annotation[\"bbox\"]\n    if transforms.has_box_transform:\n        bbox = transforms.apply_box(\n            BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n        )\n        bbox = Boxes(bbox)\n        bbox.clip(image_size)\n        annotation[\"bbox\"] = bbox.get_tensor(BoxMode.XYXY_ABS)\n        annotation[\"bbox_mode\"] = \"XYXY_ABS\"\n\n    # Transform keypoints\n    if transforms.has_keypoint_transform:\n        keypoints = annotation.pop(\"keypoints\", None)\n        if keypoints is not None:\n            keypoints = transforms.apply_keypoint(\n                keypoints, image_size, keypoint_hflip_indices\n            )\n            annotation[\"keypoints\"] = keypoints\n\n    # Transform segmentation\n    if transforms.has_segm_transform:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, PolygonMasks):\n            segmentation = transforms.apply_polygon(segmentation)\n        elif isinstance(segmentation, BitMasks):\n            segmentation = transforms.apply_mask(segmentation)\n        else:\n            segmentation = transforms.apply_rles(segmentation)\n        annotation[\"segmentation\"] = segmentation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if transforms is not None:\n        # Transform bounding boxes\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(annotation.get(\"bbox\", [0, 0, 0, 0]),\n            BoxMode.XYWH_ABS,\n            BoxMode.XYXY_ABS,\n        )\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n        # Transform segmentation\n        if \"segmentation\" in annotation:\n            if isinstance(annotation[\"segmentation\"], list):\n                annotation[\"segmentation\"] = [\n                    transforms.apply_poly(poly)\n                    for poly in annotation[\"segmentation\"]\n                ]\n            else:\n                annotation[\"segmentation\"] = transforms.apply_poly(\n                    annotation[\"segmentation\"]\n                )\n\n        # Transform keypoints\n        if \"keypoints\" in annotation:\n            if transforms.has_keypoint_hflip_indices():\n                keypoint_hflip_indices = keypoint_hflip_indices or []\n            else:\n                keypoint_hflip_indices = None\n\n            if keypoint_hflip_indices is not None:\n                annotation[\"keypoints\"] = transforms.apply_keypoint(\n                    annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n                )\n            else:\n                annotation[\"keypoints\"] = transforms.apply_keypoint(\n                    annotation[\"keypoints\"], image_size\n                )\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if not transforms:\n        return\n\n    if \"bbox\" in annotation:\n        bbox = transforms.apply_box(\n            BoxMode.convert(annotation[\"bbox\"], BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n        )\n        annotation[\"bbox\"] = bbox.tolist()\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # Apply transformations to the polygon\n        annotation[\"segmentation\"] = transforms.apply_polygons(annotation[\"segmentation\"])\n        # Ensure that the segmentation matches the image size\n        annotation[\"segmentation\"] = [\n            polygons_to_bitmask(\n                annotation[\"segmentation\"], image_size, format=\"bitmask\"\n            )\n        ]\n\n    if \"keypoints\" in annotation:\n        # Apply transformations to the keypoints\n        annotation[\"keypoints\"] = transforms.apply_keypoints(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = transforms.apply_box(\n            BoxMode.convert(\n                annotation[\"bbox\"],\n                BoxMode.XYXY_ABS,\n                BoxMode.convert(\n                    annotation[\"bbox_mode\"],\n                    BoxMode.XYXY_ABS,\n                ),\n            )\n        )\n        bbox = Boxes(bbox)\n        bbox.clip(image_size)\n        annotation[\"bbox\"] = bbox.tensor.tolist()\n\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], (list, tuple)):\n            annotation[\"segmentation\"] = transforms.apply_polygons(\n                annotation[\"segmentation\"], image_size\n            )\n        elif isinstance(annotation[\"segmentation\"], dict):\n            annotation[\"segmentation\"] = transforms.apply_rles(\n                annotation[\"segmentation\"], image_size\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_keypoints(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox_mode = BoxMode.convert(annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        if bbox_mode != BoxMode.XYXY_ABS:\n            annotation[\"bbox\"] = transforms.apply_box(\n                BoxMode.convert(annotation[\"bbox\"], bbox_mode)\n            )\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygons\n            annotation[\"segmentation\"] = [\n                transforms.apply_poly(p) for p in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            annotation[\"segmentation\"] = transforms.apply_rles(\n                annotation[\"segmentation\"], image_size\n            )\n    if \"keypoints\" in annotation:\n        if keypoint_hflip_indices is not None:\n            annotation[\"keypoints\"] = transforms.apply_keypoint(\n                annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n            )\n\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply box transforms\n    if \"bbox\" in annotation:\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(\n                annotation[\"bbox\"],\n                dataset_dict.get(\"bbox_mode\", BoxMode.XYWH_ABS),\n                BoxMode.XYXY_ABS,\n            )\n        )\n    if \"bbox_mode\" not in annotation:\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply keypoint transforms\n    if \"keypoints\" in annotation:\n        if keypoint_hflip_indices is not None:\n            assert keypoint_hflip_indices.dtype == np.int32\n        keypoints = transforms.apply_keypoint(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    # Apply mask transforms\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Apply polygon transforms\n            annotation[\"segmentation\"] = transforms.apply_polygons(annotation[\"segmentation\"])\n        else:\n            # Apply RLE transforms\n            annotation[\"segmentation\"] = transforms.apply_rles(annotation[\"segmentation\"])\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # transform bounding boxes\n        bbox_mode = BoxMode.convert(annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box(BoxMode.convert(annotation[\"bbox\"], bbox_mode))\n        annotation[\"bbox\"] = bbox\n\n    if \"segmentation\" in annotation:\n        # transform segmentation\n        if isinstance(annotation[\"segmentation\"], list):\n            # list of polygons\n            for i in range(len(annotation[\"segmentation\"])):\n                annotation[\"segmentation\"][i] = transforms.apply_coords(annotation[\"segmentation\"][i])\n        else:\n            # RLE\n            annotation[\"segmentation\"] = transforms.apply_rle(annotation[\"segmentation\"])\n\n    if \"keypoints\" in annotation:\n        # transform keypoints\n        keypoints = transforms.apply_keypoint(\n            annotation[\"keypoints\"], keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # 1. Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = annotation[\"bbox\"]\n        # if the annotation is a list, convert it to an np.array\n        if isinstance(bbox, list):\n            bbox = np.array(bbox)\n        bbox = transforms.apply_box(bbox)\n        annotation[\"bbox\"] = bbox\n        # convert to XYXY_ABS if needed\n        annotation[\"bbox_mode\"] = BoxMode.convert(annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # 2. Transform the segmentation mask\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list) and len(annotation[\"segmentation\"]) > 0:\n            # segmentation is a list of polygons\n            annotation[\"segmentation\"] = [\n                transforms.apply_coords(p) for p in annotation[\"segmentation\"]\n            ]\n        elif isinstance(annotation[\"segmentation\"], dict) and annotation[\"segmentation\"][\"size\"] is not None:\n            # segmentation is a RLE\n            annotation[\"segmentation\"] = transforms.apply_rle(\n                annotation[\"segmentation\"], image_size\n            )\n\n    # 3. Transform the keypoints\n    if \"keypoints\" in annotation:\n        if keypoint_hflip_indices is None:\n            keypoint_hflip_indices = create_keypoint_hflip_indices(\n                transforms, image_size\n            )\n\n        keypoints = annotation[\"keypoints\"]\n        if isinstance(keypoints, list):\n            # keypoints is a list\n            annotation[\"keypoints\"] = transforms.apply_keypoints(keypoints)\n        elif isinstance(keypoints, torch.Tensor):\n            # keypoints is a tensor\n            annotation[\"keypoints\"] = transforms.apply_keypoints(\n                keypoints, keypoint_hflip_indices\n            )\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # convert to XYXY_ABS\n    # TODO: this is not needed if the transformations are already in XYXY_ABS\n    bbox = annotation[\"bbox\"]\n    annotation[\"bbox\"] = BoxMode.convert(bbox, annotation.pop(\"bbox_mode\"), BoxMode.XYXY_ABS)\n\n    # apply transformations\n    if transforms is not None:\n        transforms.apply_to_bbox(annotation[\"bbox\"])\n        transforms.apply_to_coords(annotation[\"segmentation\"])\n        if keypoint_hflip_indices is not None:\n            transforms.apply_to_keypoints(annotation[\"keypoints\"], keypoint_hflip_indices)\n\n    # clip to image size\n    annotation[\"bbox\"] = annotation[\"bbox\"].clip(image_size)\n    # TODO: this is not needed if the transformations are already clipping to the image size\n    annotation[\"segmentation\"] = [p.clip(image_size) for p in annotation[\"segmentation\"]]\n\n    # set bbox mode\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # apply transformations to bounding boxes\n    if \"bbox\" in annotation:\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(\n                annotation[\"bbox\"],\n                BoxMode.XYWH_ABS,\n                BoxMode.XYXY_ABS,\n                image_size,\n            )\n        )\n\n    # apply transformations to segmentation polygons\n    if \"segmentation\" in annotation:\n        annotation[\"segmentation\"] = transforms.apply_polygons(\n            annotation[\"segmentation\"]\n        )\n\n    # apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        if transforms.has_keypoint_hflip_indices():\n            if keypoint_hflip_indices is None:\n                raise ValueError(\n                    \"keypoint_hflip_indices must be provided when keypoint transformations are applied\"\n                )\n            annotation[\"keypoints\"] = transforms.apply_keypoints(\n                annotation[\"keypoints\"], keypoint_hflip_indices\n            )\n        else:\n            annotation[\"keypoints\"] = transforms.apply_keypoints(annotation[\"keypoints\"])\n\n    # set the bounding box mode to XYXY_ABS\n    if \"bbox_mode\" not in annotation:\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    assert isinstance(annotation, dict), \"annotation must be a dict\"\n\n    # apply transformations to bounding box\n    if \"bbox\" in annotation:\n        bbox = annotation[\"bbox\"]\n        annotation[\"bbox\"] = transforms.apply_box(\n            BoxMode.convert(bbox, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n        )\n\n    # apply transformations to segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(transforms, T.Transform):\n            if isinstance(transforms, T.RandomAffine):\n                # RandomAffine requires polygons\n                if isinstance(annotation[\"segmentation\"], list):\n                    annotation[\"segmentation\"] = transforms.apply_polygons(\n                        annotation[\"segmentation\"]\n                    )\n                elif isinstance(annotation[\"segmentation\"], np.ndarray):\n                    annotation[\"segmentation\"] = transforms.apply_mask(\n                        polygons_to_bitmask(annotation[\"segmentation\"])\n                    )\n            else:\n                # apply to RLE\n                annotation[\"segmentation\"] = transforms.apply_mask(\n                    annotation[\"segmentation\"]\n                )\n        else:\n            # apply to polygons\n            annotation[\"segmentation\"] = transforms.apply_polygons(\n                annotation[\"segmentation\"]\n            )\n\n    # apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        # get keypoint transformations\n        keypoint_transforms = [t for t in transforms if isinstance(t, T.KeypointTransform)]\n\n        if keypoint_hflip_indices is not None:\n            # handle flipping\n            keypoint_hflip_transforms = [\n                t for t in keypoint_transforms if isinstance(t, T.KeypointHFlip)\n            ]\n            if len(keypoint_hflip_transforms) > 1:\n                raise RuntimeError(\n                    \"Found more than one keypoint hflip transformation. \"\n                    \"This is not supported.\"\n                )\n            if len(keypoint_hflip_transforms) == 0:\n                keypoint_hflip_transforms = T.KeypointHFlip(\n                    keypoint_hflip_indices\n                )\n            keypoint_transforms.append(keypoint_hflip_transforms)\n\n        # apply keypoint transformations\n        keypoint_transforms = transforms"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # Transform bounding boxes\n        bbox = transforms.apply_box(\n            BoxMode.convert(annotation[\"bbox\"], BoxMode.XYXY_ABS, BoxMode.XYXY_ABS)\n        )\n        # clip the transformed bounding box\n        bbox.clip(image_size)\n        annotation[\"bbox\"] = bbox.tolist()\n\n        # set the bounding box mode\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        # Apply keypoint transformations\n        keypoints = transforms.apply_keypoint(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n        # set the keypoint mode\n        annotation[\"keypoints\"] = keypoints.tolist()\n        annotation[\"keypoints_hflip_indices\"] = keypoint_hflip_indices\n\n    # Transform segmentation masks\n    if \"segmentation\" in annotation:\n        # Apply polygon transformations\n        segmentation = transforms.apply_polygon(annotation[\"segmentation\"])\n        # Apply RLE transformations\n        segmentation = transforms.apply_rle(segmentation)\n        annotation[\"segmentation\"] = segmentation\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = transforms.apply_box(\n            BoxMode.convert(\n                annotation[\"bbox\"], annotation.get(\"bbox_mode\", \"XYXY_ABS\"), BoxMode.XYXY_ABS\n            )\n        )\n        annotation[\"bbox\"] = bbox.tolist()\n    if \"keypoints\" in annotation:\n        if transforms.is_hflip_applied():\n            if keypoint_hflip_indices is None:\n                raise ValueError(\n                    \"When using horizontal flip transformations on keypoints, you must provide keypoint_hflip_indices.\"\n                )\n        annotation[\"keypoints\"] = transforms.apply_keypoint(\n            annotation[\"keypoints\"], image_size, keypoint_hflip_indices\n        )\n\n    if \"segmentation\" in annotation:\n        segmentation = transforms.apply_segmentation(annotation[\"segmentation\"])\n        if isinstance(segmentation, (list, np.ndarray)):\n            annotation[\"segmentation\"] = segmentation\n            annotation[\"iscrowd\"] = False\n        else:\n            # Assume RLE\n            annotation[\"segmentation\"] = segmentation.to_rles(image_size).tolist()\n            annotation[\"iscrowd\"] = True\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # TODO: refactor the code below to use a function that transforms the keypoints\n    # TODO: refactor the code below to use a function that transforms the keypoints\n    # TODO: refactor the code below to use a function that transforms the keypoints\n    if \"bbox\" in annotation:\n        bbox = transforms.apply_box(\n            BoxMode.convert(annotation[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n        )\n        bbox.clip(image_size)\n        annotation[\"bbox\"] = bbox.tolist()\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # TODO: refactor the code below to use a function that transforms the keypoints\n            # TODO: refactor the code below to use a function that transforms the keypoints\n            # TODO: refactor the code below to use a function that transforms the keypoints\n            if len(transforms) > 1:\n                raise NotImplementedError(\n                    \"Polygons cannot be transformed with multiple transforms\"\n                )\n            polygon_transforms = transforms[0]\n            for seg_i in range(len(annotation[\"segmentation\"])):\n                poly = annotation[\"segmentation\"][seg_i]\n                # TODO: refactor the code below to use a function that transforms the keypoints\n                # TODO: refactor the code below to use a function that transforms the keypoints\n                # TODO: refactor the code below to use a function that transforms the keypoints\n                if len(poly) % 2 != 0:\n                    raise ValueError(\n                        \"Cannot transform segmentation. The polygon has {} points, but \"\n                        \"must have an even number of points.\".format(len(poly))\n                    )\n                if len(poly) == 4 and not any(\n                    np.isinf(poly[i]) for i in [0, 1, 2, 3]\n                ):\n                    # This is a special case for a rectangle\n                    # TODO: refactor the code below to use a function that transforms the keypoints\n                    # TODO: refactor the code below to use a function that transforms the keypoints\n                    # TODO: refactor the code below to use a function that transforms the keypoints"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        return self.rm_coords.dot(coords.T).T\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = coords - self.center\n        coords = np.dot(coords, self.rm_coords)\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.dot(coords, self.rm_coords)\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0 or len(coords) == 0:\n            return coords\n\n        coords = coords.astype(np.float64)\n        coords = np.c_[coords, np.ones_like(coords[:, :1])]\n        coords = np.dot(coords, self.rm_coords.T)\n        return coords[:, :2]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        return np.dot(coords, self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords)\n        coords = coords.astype(np.float32)\n        coords = coords - self.center\n        coords = np.dot(coords, self.rm_coords)\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        assert coords.shape[1] == 2\n        if self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = np.dot(coords, self.rm_coords)\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        assert coords.shape[1] == 2\n        return coords.dot(self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0 or len(coords) == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = np.hstack((coords, np.ones((coords.shape[0], 1)))\n        coords = np.dot(coords, self.rm_coords)\n        return coords[:, :2]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0 or len(coords) == 0:\n            return coords\n        coords = np.array(coords)\n        coords = coords.astype(np.float32)\n        coords = np.concatenate((coords, np.ones((coords.shape[0], 1))),\n        coords = coords.dot(self.rm_coords.T)\n        return coords[:, :2]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0 or coords.shape[0] == 0:\n            return coords\n        coords = coords.copy()\n        coords[:, 0] = coords[:, 0] * self.bound_w / self.w\n        coords[:, 1] = coords[:, 1] * self.bound_h / self.h\n        coords = coords.T\n        coords = np.dot(coords, self.rm_coords.T)\n        coords = coords.T\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        assert coords.shape[1] == 2\n        assert coords.shape[0] > 0, \"RotationTransform: coords is empty\"\n        assert self.angle % 360 == 0 or coords.shape[0] > 2, (\n            \"RotationTransform: coords is empty or angle is a multiple of 360 degrees\"\n        )\n\n        coords = coords.copy()\n        coords[:, 1] = self.h - coords[:, 1]\n        coords = np.dot(coords, self.rm_coords)\n        coords[:, 0] = coords[:, 0] - coords[:, 1]\n        coords[:, 1] = coords[:, 1] - coords[:, 0]\n\n        coords[:, 0] = coords[:, 0] * self.w / self.bound_w\n        coords[:, 1] = coords[:, 1] * self.h / self.bound_h\n        coords[:, 0] = self.w - coords[:, 0] - 1\n        coords[:, 1] = self.h - coords[:, 1] - 1\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        # TODO: check if this is the right way to do it\n        assert coords.shape[1] == 2, \"Expected coords to be of shape (N, 2)\"\n        # coords = coords.astype(np.float32)\n        # coords = coords - self.center\n        coords = coords @ self.rm_coords\n        coords[:, 0] = coords[:, 0] + self.center[0]\n        coords[:, 1] = coords[:, 1] + self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        coords = np.asarray(coords)\n        coords = coords.copy()\n        coords[:, 0] = coords[:, 0] * self.abs_cos - coords[:, 1] * self.abs_sin\n        coords[:, 1] = coords[:, 0] * self.abs_sin + coords[:, 1] * self.abs_cos\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0 or len(coords) == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = np.ascontiguousarray(coords)\n        coords = coords.reshape(-1, 2)\n        coords = np.dot(coords, self.rm_coords)\n        return coords.reshape(coords.size // 2, 2).astype(np.int32)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n\n        if len(coords) == 0:\n            return coords\n\n        coords = coords.copy()\n        coords[:, 0] -= 0.5 * self.w\n        coords[:, 1] -= 0.5 * self.h\n        coords = np.dot(coords, self.rm_coords)\n        coords[:, 0] += 0.5 * self.bound_w\n        coords[:, 1] += 0.5 * self.bound_h\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        coords = coords.copy()\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords[:, :2] = np.dot(coords[:, :2], self.rm_coords)\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        assert coords.shape[1] == 2\n        if self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = coords - self.center\n        coords = np.dot(coords, self.rm_coords)\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops = FlopCountAnalysis(model, inputs).get_flops()\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops = FlopCountAnalysis(model, inputs)\n    return flops.flop_count_operators(FLOPS_MODE)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.flop_count_ops()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return FlopCountAnalysis(model, inputs).flop_count_all()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    return flop_count(model, inputs)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    def get_flops(model, inputs):\n        return fvcore.nn.flop_count_operators(model, inputs)\n\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flops_dict = fvcore.nn.flop_count_operators(wrapper, wrapper.flattened_inputs)\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: support batch_size > 1\n    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.flop_count_table()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if isinstance(inputs, dict):\n        inputs = [inputs]\n    if len(inputs) != 1:\n        raise ValueError(\"Only support single input model for flops counting\")\n\n    model = TracingAdapter(model, inputs, allow_non_tensor=True)\n    return flop_count(model)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if not isinstance(model, nn.Module):\n        raise TypeError(\"model must be an instance of nn.Module\")\n    if not isinstance(inputs, list):\n        raise TypeError(\"inputs must be a list\")\n    for input in inputs:\n        if not isinstance(input, dict):\n            raise TypeError(\"inputs must be a list of dictionaries\")\n\n    # Run the model with inputs\n    model_wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flops = flop_count(model_wrapper.module, FLOPS_MODE)\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    assert isinstance(model, nn.Module)\n    assert isinstance(inputs, list)\n    assert len(inputs) > 0\n\n    # create a wrapper for detectron2 model\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    # create a new analysis object\n    analysis = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n\n    # get flops for each operator\n    return analysis.flop_count_table\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops = FlopCountAnalysis(model, inputs)\n    return flops.flops_count()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: support other inputs\n    if len(inputs) == 1:\n        inputs = [inputs]\n    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.get_flop_count(FLOPS_MODE)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops = FlopCountAnalysis(model, inputs).flop_count()\n\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    def get_flops(m, input_size):\n        # type: (nn.Module, tuple) -> typing.Dict[str, float]\n        return flop_count(\n            m, input_size, mode=FLOPS_MODE, include_weight=False\n        )\n\n    return fvcore.nn.flop_count_operators(model, inputs, get_flops)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.flop_count_all_operators(FLOPS_MODE)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # NOTE: we'll ignore the inputs to the model.\n    analysis = FlopCountAnalysis(model, inputs)\n    analysis.forward()\n    return analysis.flop_count()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flops = FlopCountAnalysis(model, inputs).flops\n    # TODO: normalize by the number of images\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: support other inputs\n    assert len(inputs) == 1, \"Currently only supports single input model\"\n\n    # TODO: use detectron2's input_format\n    input_data = inputs[0]\n    assert (\n        \"image\" in input_data\n    ), \"The input dictionary must contain an 'image' key\"\n    image = input_data[\"image\"]\n\n    # TODO: use detectron2's forward_hooks\n    analysis = FlopCountAnalysis(model, [image])\n    return analysis.flop_count()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: support non-tuple inputs\n    # TODO: support batch_norm\n    # TODO: support nms\n    # TODO: support dynamic batch_size\n    # TODO: support dynamic input size\n\n    flops_analysis = FlopCountAnalysis(model, inputs)\n    return flops_analysis.flops\n\n    # return fvcore.nn.flop_count(model, inputs)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: add more inputs to the model, e.g., the anchors\n    # TODO: add support for other types of inputs, e.g., list of tensors\n    flops_analysis = FlopCountAnalysis(model, inputs)\n    return flops_analysis.flop_count\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle == 0:\n            return img\n\n        if interp is None:\n            interp = self.interp\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, resample=interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.affine_grid(self.rm_image, (self.bound_h, self.bound_w), align_corners=False)\n            img = F.grid_sample(img, img)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, interp or self.interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.affine_grid(self.rm_image, (self.bound_h, self.bound_w, img.shape[2]),\n                                align_corners=True)\n            img = F.interpolate(img, (self.bound_h, self.bound_w), mode=\"bilinear\")\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is not None:\n            self.interp = interp\n        if not self.angle % 360:\n            return img\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, resample=self.interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # OpenCV only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.affine_grid(self.rm_image, (self.bound_h, self.bound_w), align_corners=True)\n            img = F.grid_sample(img, img, mode=\"bilinear\", align_corners=True)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # If the image is empty, return the original image\n        if img is None:\n            return img\n\n        # If the angle is 0 or 360 degrees, return the original image\n        if self.angle == 0 or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 360:\n            return img\n\n        # If the image is empty or the angle results in no change, return the original image\n        if img is None or self.angle == 3"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, self.interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.affine_grid(self.rm_image, img.shape[1:], mode=\"bilinear\")\n            img = F.interpolate(\n                img, (self.bound_h, self.bound_w), mode=\"bilinear\", align_corners=False\n            )\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle == 0 or img.size == (0, 0):\n            return img\n        assert len(img.shape) <= 4\n        interp_method = interp if interp is not None else self.interp\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, interp_method)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.affine_grid(self.rm_image, (self.bound_h, self.bound_w))\n            img = F.grid_sample(img, self.rm_coords)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.w == self.h == 0 or np.abs(self.angle) % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, resample=interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # OpenCV only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            ret = F.affine_grid(self.rm_image, (self.bound_h, self.bound_w), interp)\n            ret = F.grid_sample(img, ret)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = ret.view(shape).permute(2, 3, 0, 1).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if not self.angle:\n            return img.copy()\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n\n            pil_image = pil_image.rotate(self.angle, resample=interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.affine_grid(self.rm_image, img.shape[1:])\n            img = F.grid_sample(img, self.rm_coords)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2:\n            img = img[:, :, 0]\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = np.expand_dims(img, -1)\n        img = np.ascontiguousarray(img)\n        if interp is None:\n            interp = self.interp\n        img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=interp,\n        )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if self.angle % 360 == 0 or self.h == self.bound_h or self.w == self.bound_w:\n            return img\n        else:\n            h, w = img.shape[:2]\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, expand=self.expand, interp=interp)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not img.size:\n            return img\n\n        if interp is None:\n            interp = self.interp\n        if self.angle % 360 == 0:\n            return img.copy()\n\n        img = np.asanyarray(img)\n\n        if len(img.shape) == 3:\n            # HWC\n            img = img.transpose(1, 0, 2)\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_h, self.bound_w),\n                flags=interp,\n            )\n            img = img.transpose(1, 0, 2)\n        else:\n            img = cv2.warpAffine(\n                img, self.rm_image, (self.bound_h, self.bound_w), flags=interp\n            )\n\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if self.angle == 0:\n            return img\n        # if self.bound_w == self.h and self.bound_h == self.w:\n        #     # no need to resize\n        #     return img\n        if self.bound_w == self.w and self.bound_h == self.h:\n            # no need to resize\n            return F.affine_grid_sample(self.rm_image, img.shape)\n        else:\n            return F.affine_grid_sample(self.rm_image, (self.bound_h, self.bound_w))\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2:\n            if img.shape[2] == 1:\n                img = img[:, :, 0]\n            else:\n                img = img.transpose(1, 2, 0)\n            img = np.ascontiguousarray(img)\n\n        # If the image is empty or the rotation is not needed, return the original image\n        if img.size == 0 or (self.angle % 360 == 0):\n            return img\n\n        # If the image is empty or the rotation is not needed, return the original image\n        if img.size == 0 or (self.angle % 360 == 0):\n            return img\n        # If the image is empty or the rotation is not needed, return the original image\n        if img.size == 0 or (self.angle % 360 == 0):\n            return img\n\n        # Create the rotation matrix\n        if interp is None:\n            interp = self.interp\n        self.rm_image = self.create_rotation_matrix()\n\n        # Rotate the image\n        rotated_image = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h),\n                                      flags=interp)\n\n        # Reshape the image to its original format\n        rotated_image = rotated_image.transpose(2, 0, 1)\n        return rotated_image\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        if interp is None:\n            interp = self.interp\n        if self.angle == 0 or (\n            self.angle % 360 == 0\n        ):  # no rotation\n            return pil_image\n\n        # get the rotation matrix\n        if interp == Image.NEAREST:\n            rm = self.rm_coords\n        else:\n            rm = self.rm_image\n\n        # rotate the image\n        rotated_image = pil_image.transform(\n            size=(self.bound_h, self.bound_w),\n            method=interp,\n            data=rm,\n            resample=interp,\n        )\n        return np.asarray(rotated_image)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n\n        # TODO: decide if we want to use PIL\n        # TODO: we should also consider using OpenCV's warpAffine\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.transform(\n            (self.bound_h, self.bound_w),\n            Image.AFFINE,\n            self.rm_image,\n            resample=interp,\n            fillcolor=0,\n        )\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n\n        if img.shape[:2] == (self.h, self.w) and len(img.shape) <= 4:\n            return cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is not None:\n            assert interp in [\n                cv2.INTER_NEAREST,\n                cv2.INTER_LINEAR,\n                cv2.INTER_CUBIC,\n                cv2.INTER_LANCZOS4,\n            ]\n            self.rm_image = self.create_rotation_matrix(interp=interp)\n        return cv2.warpAffine(\n            img, self.rm_image, (self.bound_w, self.bound_h)\n        )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not self.h or not self.w:\n            return img\n\n        if interp is None:\n            interp = self.interp\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.transform(\n            (self.bound_w, self.bound_h),\n            Image.Affine,\n            self.rm_image,\n            resample=interp,\n            fillcolor=self.fillcolor,\n        )\n\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n\n        if len(img.shape) == 3:\n            img = img.transpose(1, 2, 0)\n\n        assert img.shape[0] == self.h, \"image height mismatch\"\n        assert img.shape[1] == self.w, \"image width mismatch\"\n        assert img.shape[2] == 1, \"image channel mismatch\"\n        img = np.asarray(img)\n        rotated_image = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=interp,\n            borderMode=cv2.BORDER_REPLICATE,\n        )\n        rotated_image = rotated_image.transpose(2, 0, 1)\n        return rotated_image\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not interp:\n            interp = self.interp\n        if self.h == self.bound_h and self.w == self.bound_w:\n            return img\n        if img.dtype == np.uint8:\n            img = Image.fromarray(img)\n        else:\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n\n        if self.bound_h == self.h and self.bound_w == self.w:\n            return img.rotate(self.angle, resample=interp)\n        else:\n            return cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                borderMode=cv2.BORDER_CONSTANT,\n                flags=interp,\n                # BORDER_CONSTANT is the default, but we set it to be explicit\n                # and for consistency with the rest of the code\n            )\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: draw keypoints\n        # TODO: draw masks\n        # TODO: draw box labels\n        # TODO: draw keypoint labels\n        # TODO: draw mask labels\n        # TODO: draw box colors\n        # TODO: draw mask colors\n        # TODO: draw keypoint colors\n        # TODO: draw box alpha\n        # TODO: draw mask alpha\n        # TODO: draw keypoint alpha\n        # TODO: draw box thickness\n        # TODO: draw mask thickness\n        # TODO: draw keypoint thickness\n        # TODO: draw box line type\n        # TODO: draw mask line type\n        # TODO: draw keypoint line type\n        # TODO: draw box line cap\n        # TODO: draw mask line cap\n        # TODO: draw keypoint line cap\n        # TODO: draw box line join\n        # TODO: draw mask line join\n        # TODO: draw keypoint line join\n        # TODO: draw box line miter\n        # TODO: draw mask line miter\n        # TODO: draw keypoint line miter\n        # TODO: draw box line width\n        # TODO: draw mask line width\n        # TODO: draw keypoint line width\n        # TODO: draw box line style\n        # TODO: draw mask line style\n        # TODO: draw keypoint line style\n\n        # TODO: draw box line color\n        # TODO: draw mask line color\n        # TODO: draw keypoint line color\n        # TODO: draw box line alpha\n        # TODO: draw mask line alpha\n        # TODO: draw keypoint line alpha\n\n        # TODO: draw box label\n        # TODO: draw mask label\n        # TODO: draw keypoint label\n        # TODO: draw box label color\n        # TODO: draw mask label color\n        # TODO: draw keypoint label color\n        # TODO: draw box label size\n        # TODO: draw mask label size\n        # TODO: draw keypoint label size\n        # TODO: draw box label font\n        # TODO: draw mask label font\n        # TODO: draw keypoint label font\n        # TODO: draw box label position\n        # TODO: draw mask label position\n        # TODO: draw keypoint label position\n        # TODO: draw box label offset\n        # TODO: draw mask label offset\n        #"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if predictions.has(\"pred_masks\"):\n            self.draw_mask_predictions(predictions)\n        if predictions.has(\"pred_keypoints\"):\n            self.draw_keypoint_predictions(predictions)\n        if predictions.has(\"pred_boxes\"):\n            self.draw_boxes(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n            if predictions.has(\"is_crowd\"):\n                self.draw_crowd_boxes(predictions.pred_boxes, predictions.is_crowd)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: support other modes\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_segmentations(predictions)\n            self.draw_keypoints(predictions.pred_keypoints)\n        elif self._instance_mode == ColorMode.IMAGE:\n            self.draw_instances(predictions.pred_boxes, predictions.pred_classes)\n            self.draw_scores(predictions.scores, predictions.pred_boxes)\n            self.draw_keypoints(predictions.pred_keypoints)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_instances(predictions.pred_boxes, predictions.pred_classes)\n            self.draw_scores(predictions.scores, predictions.pred_boxes)\n            self.draw_keypoints(predictions.pred_keypoints)\n            self.draw_segmentations(predictions)\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_instances(predictions.pred_boxes, predictions.pred_classes)\n            self.draw_scores(predictions.scores, predictions.pred_boxes)\n            self.draw_keypoints(predictions.pred_keypoints)\n        else:\n            raise ValueError(\"Unknown instance mode: {}\".format(self._instance_mode))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # if not isinstance(predictions, Instances):\n        #     raise ValueError(\n        #         f\"predictions should be of type {Instances}, got {type(predictions)}\"\n        #     )\n        # predictions = predictions.to(self.cpu_device)\n\n        if isinstance(predictions, Keypoints):\n            self.draw_keypoints(predictions)\n        elif isinstance(predictions, RotatedBoxes):\n            self.draw_rotated_boxes(predictions)\n        elif isinstance(predictions, Boxes):\n            self.draw_boxes(predictions)\n        elif isinstance(predictions, PolygonMasks):\n            self.draw_polygons(predictions)\n        elif isinstance(predictions, BitMasks):\n            self.draw_masks(predictions)\n        elif isinstance(predictions, _PanopticPrediction):\n            self.draw_panoptic_seg_predictions(predictions)\n        else:\n            self.draw_masks(predictions)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # if predictions is a list, concat it to a batch\n        if isinstance(predictions, list):\n            predictions = torch.cat([x.to(self.cpu_device) for x in predictions], dim=0)\n\n        # draw boxes\n        if predictions.has(\"pred_boxes\"):\n            self.draw_boxes(predictions.pred_boxes, predictions.scores, predictions.pred_classes)\n\n        # draw keypoints\n        if predictions.has(\"pred_keypoints\"):\n            self.draw_keypoints(predictions.pred_keypoints, predictions.pred_classes)\n\n        # draw masks\n        if predictions.has(\"pred_masks\"):\n            if self._instance_mode == ColorMode.IMAGE_BW:\n                self.draw_binary_masks(predictions.pred_masks)\n            else:\n                self.draw_instance_masks(predictions.pred_masks, predictions.pred_classes)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # draw boxes\n        if predictions.has(\"pred_boxes\"):\n            self.draw_boxes(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n\n        # draw masks\n        if predictions.has(\"pred_masks\") or predictions.has(\"pred_masks_rle\"):\n            if self._instance_mode == ColorMode.SEGMENTATION:\n                self._draw_segmentation(predictions)\n            else:\n                self._draw_instance_masks(predictions)\n\n        # draw keypoints\n        if predictions.has(\"keypoints\"):\n            self.draw_keypoints(predictions.keypoints)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if isinstance(predictions, torch.Tensor):\n            predictions = predictions.to(self.cpu_device)\n        if not isinstance(predictions, torch.Tensor):\n            raise TypeError(\n                \"predictions should be a tensor or a dict. Got {}\".format(type(predictions))\n            )\n\n        # Convert to VisImage\n        if isinstance(predictions, dict):\n            predictions = VisImage.from_predictions(predictions, self.metadata)\n\n        # Set instance mode\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self.img\n            self.output.scale = 1.0\n            self.output._setup_figure(self.img)\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self.output.img = self.img\n            self.output.scale = 1.0\n            self.output._setup_figure(self.img)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self.img\n            self.output.scale = 1.0\n            self.output._setup_figure(self.img)\n\n        if isinstance(predictions, VisImage):\n            # Draw on the given image\n            self.output.reset_image(predictions.img)\n        else:\n            # Draw on the original image\n            self.output.reset_image(self.img)\n        if predictions.has_keypoints:\n            self.draw_keypoints(predictions.keypoints)\n        if predictions.has_boxes:\n            self.draw_boxes(predictions.boxes)\n        if predictions.has_masks:\n            self.draw_masks(predictions.masks)\n        if predictions.has_text:\n            self.draw_text(predictions.text)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # convert to cpu\n        predictions = predictions.to(self.cpu_device)\n        if self._instance_mode == ColorMode.IMAGE:\n            # convert to grayscale\n            self.output.reset_image(self.img)\n            self.output.img = self.img.copy()\n        else:\n            self.output.reset_image(\n                self.img.astype(np.uint8) * 0.5 + _OFF_WHITE\n            )\n\n        # draw boxes\n        if \"pred_boxes\" in predictions:\n            self.draw_boxes(\n                predictions.pred_boxes,\n                predictions.pred_classes,\n                predictions.scores,\n                box_mode=predictions.box_mode,\n            )\n\n        # draw masks\n        if \"pred_masks\" in predictions:\n            self.draw_masks(\n                predictions.pred_masks,\n                predictions.pred_classes,\n                predictions.scores,\n                box_mode=predictions.box_mode,\n                keypoints=predictions.keypoints,\n            )\n\n        # draw keypoints\n        if \"keypoints\" in predictions:\n            self.draw_keypoints(predictions.keypoints)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: add support for other formats\n        if not isinstance(predictions, torch.Tensor):\n            predictions = torch.as_tensor(predictions)\n\n        # if predictions.device != self.cpu_device:\n        predictions = predictions.to(self.cpu_device)\n\n        # TODO: add support for other data types\n        if predictions.dtype != torch.int64:\n            predictions = predictions.long()\n\n        scores = predictions.get(\"scores\", None)\n        classes = predictions.get(\"pred_classes\", None)\n        boxes = predictions.get(\"pred_boxes\", None)\n        masks = predictions.get(\"pred_masks\", None)\n        mask_polys = predictions.get(\"pred_masks_polygons\", None)\n        keypoints = predictions.get(\"pred_keypoints\", None)\n\n        if boxes is not None:\n            boxes = boxes.reshape(-1, 4).float()\n            boxes = boxes.clamp_min(0)\n            boxes = boxes.int()\n            boxes = boxes.tolist()\n        if classes is not None:\n            classes = classes.int().tolist()\n        if scores is not None:\n            scores = scores.squeeze().tolist()\n        if masks is not None:\n            masks = masks.int().tolist()\n        if mask_polys is not None:\n            masks = mask_polys.tolist()\n        if keypoints is not None:\n            keypoints = keypoints.tolist()\n\n        if boxes is None and masks is None and keypoints is None:\n            return self.output\n\n        if boxes is not None and boxes.size > 0:\n            if self.metadata.has_thing_classes:\n                classes = [self.metadata.thing_dataset_id_to_contiguous_id[c] for c in classes]\n                classes = [c for c in classes if c in self.metadata.thing_classes]\n            else:\n                classes = [0] * len(boxes)\n\n        if masks is not None and not self._instance_mode.value == ColorMode.SEGMENTATION.value:\n            self.output.reset_image(self.img)\n\n        if boxes is not None:\n            self.draw_boxes("}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if not isinstance(predictions, torch.Tensor):\n            predictions = predictions.to(self.cpu_device)\n        if not isinstance(predictions, torch.Tensor):\n            raise ValueError(\"predictions must be a tensor\")\n\n        # We use the same color for all instances of the same category.\n        # This is different from COCO's style, which uses different colors for\n        # different instances.\n        if self._instance_mode == ColorMode.IMAGE:\n            # Use random color for each instance\n            self._color_mode = ColorMode.IMAGE\n            colors = random_color(predictions.pred_boxes.shape[0])\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            # Use category color for each instance\n            self._color_mode = ColorMode.SEGMENTATION\n            colors = self.metadata.thing_colors\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self._color_mode = ColorMode.IMAGE\n        else:\n            raise ValueError(\n                \"Unknown instance_mode '{}'. Please choose one of: {}\".format(\n                    self._instance_mode, ColorMode.values()\n                )\n            )\n\n        # Draw boxes\n        self.draw_boxes(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n\n        # Draw masks\n        if predictions.has(\"pred_masks\"):\n            self.draw_masks(predictions.pred_masks)\n        elif predictions.has(\"pred_masks_rle\"):\n            self.draw_masks_rle(predictions.pred_masks_rle)\n        elif predictions.has(\"pred_keypoints\"):\n            self.draw_keypoints(predictions.pred_keypoints, predictions.pred_classes)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: add support for \"pred_keypoints\"\n        if not isinstance(predictions, torch.Tensor):\n            predictions = torch.tensor(predictions, device=self.cpu_device)\n        if predictions.device != self.cpu_device:\n            predictions = predictions.to(self.cpu_device)\n        predictions = predictions.to(self.cpu_device)\n\n        if hasattr(predictions, \"pred_masks_rle\"):\n            pred_masks = [GenericMask(p, self.output.height, self.output.width) for p in predictions.pred_masks_rle]\n        elif hasattr(predictions, \"pred_masks\"):\n            pred_masks = [p for p in predictions.pred_masks]\n        else:\n            raise ValueError(\n                \"pred_masks_rle or pred_masks must be available for instance predictions\"\n            )\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_keypoints(predictions)\n            self.draw_boxes(predictions.pred_boxes)\n            self.draw_text(\n                predictions.pred_classes,\n                predictions.scores,\n                predictions.is_crowd,\n                _SMALL_OBJECT_AREA_THRESH,\n                font_size=self._default_font_size,\n            )\n            self.draw_masks(pred_masks)\n        else:\n            self.draw_keypoints(predictions)\n            self.draw_boxes(predictions.pred_boxes)\n            self.draw_text(\n                predictions.pred_classes,\n                predictions.scores,\n                predictions.is_crowd,\n                _SMALL_OBJECT_AREA_THRESH,\n                font_size=self._default_font_size,\n                is_image_bw=True,\n            )\n            self.draw_masks(pred_masks)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        predictions = predictions.to(self.cpu_device)\n\n        # TODO: move this to the __init__()\n        self._default_font_size = max(\n            np.sqrt(self.output.height * self.output.width) // 90, 10 // self.scale\n        )\n        # TODO: add a \"min_size\" parameter to the constructor to\n        #  allow users to set the minimum text size\n\n        if self._instance_mode == ColorMode.IMAGE:\n            # draw boxes, labels, scores, masks\n            for i, (boxes, labels, scores) in enumerate(\n                zip(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n            ):\n                self.draw_box(boxes, labels, scores, i)\n\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            # draw boxes, labels, scores, masks\n            for i, (boxes, labels, scores) in enumerate(\n                zip(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n            ):\n                self.draw_box(boxes, labels, scores, i)\n            # draw masks\n            for i, mask in enumerate(predictions.pred_masks):\n                self.draw_mask(mask, i)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            # draw boxes, labels, scores, masks\n            for i, (boxes, labels, scores) in enumerate(\n                zip(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n            ):\n                self.draw_box(boxes, labels, scores, i)\n            # draw masks\n            for i, mask in enumerate(predictions.pred_masks):\n                self.draw_mask(mask, i)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: add support for keypoints\n        # TODO: add support for image_shapes\n        # TODO: add support for segment_info\n\n        # convert to numpy array\n        boxes = predictions.pred_boxes.tensor.to(self.cpu_device)\n        boxes = Boxes(boxes.to(BoxMode.XYXYXYX))\n        classes = predictions.pred_classes.to(\"cpu\")\n        scores = predictions.scores.to(\"cpu\")\n        masks = predictions.pred_masks.to(self.cpu_device)\n        masks = masks.to(BoxMode.XYXYXYX)\n        masks = masks.convert_to(BitMasks)\n\n        # draw bounding boxes\n        self.draw_boxes(boxes, classes, scores, color=self._get_color_for_instances(classes))\n\n        # draw instance masks\n        if self._instance_mode == ColorMode.IMAGE:\n            self.draw_binary_masks(masks)\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_polygons(masks)\n        else:\n            raise ValueError(\n                \"instance_mode should be one of \"\n                + \", \".join(str(x) for x in ColorMode)\n            )\n\n        return self\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if predictions.has(\"pred_keypoints\"):\n            # if keypoints are present, we use the \"IMAGE\" mode\n            instance_mode = ColorMode.IMAGE\n        else:\n            instance_mode = self._instance_mode\n\n        # set the device to cpu\n        predictions = predictions.to(self.cpu_device)\n\n        # get the image dimensions\n        width = self.output.width\n        height = self.output.height\n\n        # get the colors\n        colors = self.metadata.thing_colors\n\n        # get the classes\n        classes = predictions.pred_classes.to(\"cpu\").numpy()\n        classes = classes.astype(\"int\").tolist()\n\n        # get the scores\n        scores = predictions.scores.to(\"cpu\").numpy()\n        scores = scores.astype(\"float\").tolist()\n\n        # get the masks\n        masks = predictions.pred_masks\n        if isinstance(masks, GenericMask):\n            masks = masks.mask\n\n        # get the keypoints\n        keypoints = predictions.pred_keypoints\n        if keypoints is not None:\n            keypoints = keypoints.to(\"cpu\").numpy()\n            keypoints = keypoints.reshape(\n                -1,\n                keypoints.shape[2] // 3,\n                keypoints.shape[3],\n                keypoints.shape[4],\n            )\n            keypoints = keypoints.astype(\"float\").tolist()\n\n        # get the boxes\n        boxes = predictions.pred_boxes\n        if isinstance(boxes, Boxes):\n            boxes = boxes.to(\"cpu\").numpy()\n            boxes = boxes.astype(\"float\").tolist()\n            if boxes.ndim == 1:\n                boxes = [boxes]\n\n        # draw the boxes\n        self.draw_boxes(boxes, classes, scores, instance_mode)\n\n        # draw the masks\n        if masks is not None:\n            self.draw_masks(masks, classes, instance_mode)\n\n        # draw the keypoints\n        if keypoints is not None:\n            self.draw_keypoints(keypoints, classes, instance_mode)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: make it more efficient\n        if isinstance(predictions, torch.Tensor):\n            predictions = predictions.to(self.cpu_device).unsqueeze(0)\n        elif isinstance(predictions, dict):\n            predictions = torch.as_tensor(predictions, device=self.cpu_device).unsqueeze(0)\n        if isinstance(predictions, torch.Tensor):\n            if predictions.dim() != 0:\n                predictions = predictions.squeeze(0)\n\n        # TODO: this is a hack\n        if hasattr(predictions, \"pred_boxes\"):\n            predictions.pred_boxes = predictions.pred_boxes.to(BoxMode.XYXYXYX)\n\n        if not isinstance(predictions, Boxes):\n            predictions = Boxes.from_tensor(predictions)\n\n        # convert to float\n        # TODO: this is a hack\n        predictions.to(BoxMode.XYXYXYX)\n\n        # draw boxes\n        if hasattr(predictions, \"pred_boxes\") and predictions.has_field(\"pred_boxes\"):\n            self.draw_boxes(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n\n        # draw masks\n        if hasattr(predictions, \"pred_masks\"):\n            self.draw_masks(predictions.pred_masks)\n\n        # draw keypoints\n        if hasattr(predictions, \"pred_keypoints\"):\n            self.draw_keypoints(predictions.pred_keypoints)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if \"pred_masks\" in predictions.fields():\n            self.draw_masks(predictions.pred_masks)\n        elif \"pred_masks_rle\" in predictions.fields():\n            self.draw_panoptic_seg_predictions(predictions)\n        else:\n            self.draw_boxes(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n\n        if \"keypoints\" in predictions.fields():\n            self.draw_keypoints(predictions.keypoints)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: add support for panoptic predictions\n        # TODO: support for \"pred_keypoints\"\n        if isinstance(predictions, torch.Tensor):\n            predictions = predictions.to(self.cpu_device)\n        if isinstance(predictions, Boxes):\n            predictions = predictions.to(self.cpu_device)\n        if isinstance(predictions, RotatedBoxes):\n            predictions = predictions.to(self.cpu_device)\n\n        if isinstance(predictions, Keypoints):\n            predictions = predictions.to(self.cpu_device)\n\n        if isinstance(predictions, BitMasks):\n            predictions = predictions.to(self.cpu_device)\n\n        if isinstance(predictions, PolygonMasks):\n            predictions = predictions.to(self.cpu_device)\n            # TODO: draw polygons\n            warnings.warn(\n                \"PolygonMasks are not supported for now. \"\n                \"The polygons are not drawn. \"\n                \"You can draw polygons by yourself using the method `draw_polygon()`.\"\n            )\n            return self.output\n\n        if isinstance(predictions, GenericMask):\n            predictions = GenericMask(predictions.mask, predictions.height, predictions.width)\n\n        if isinstance(predictions, _PanopticPrediction):\n            warnings.warn(\n                \"PanopticPrediction is not supported for now. \"\n                \"You can draw panoptic segmentation by yourself using the method `draw_panoptic_seg_predictions()`.\"\n            )\n            return self.output\n\n        if self.metadata.has_thing_fields:\n            classes = predictions.pred_classes\n        else:\n            classes = predictions.pred_classes.tolist()\n            if classes is None:\n                classes = [0]\n            else:\n                classes = [int(x) for x in classes]\n        scores = predictions.scores.tolist()\n        if scores is None:\n            scores = [1.0] * len(classes)\n        else:\n            scores = [s.item() for s in scores]\n        if isinstance(predictions, Boxes):\n            boxes = predictions.pred_boxes\n        elif isinstance(predictions, RotatedBoxes):\n            boxes = predictions.pred_boxes\n        else:\n            boxes = None\n        if self.metadata.has_"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_sem_seg(predictions.pred_masks)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_sem_seg(predictions.pred_masks)\n            self.output.reset_image(self.img_to_gray(self.img))\n            self.draw_instances(\n                predictions.pred_boxes,\n                predictions.pred_classes,\n                predictions.scores,\n                predictions.is_crowd,\n                draw_keypoints=False,\n            )\n        else:\n            self.draw_instances(\n                predictions.pred_boxes,\n                predictions.pred_classes,\n                predictions.scores,\n                predictions.is_crowd,\n            )\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # TODO: remove this comment when detectron2_core.py is cleaned up\n        # NOTE: we convert the input to a VisImage object so that we can\n        #       re-use the draw_image method.\n        self.draw_image(predictions.get_fields_to_draw(self))\n\n        # color_mode = self.instance_mode\n        # if color_mode == ColorMode.IMAGE:\n        #     self.output.reset_image(self.img)\n        # elif color_mode == ColorMode.SEGMENTATION:\n        #     self.output.reset_image(self.img)\n        #     self.draw_instance_segmentation(predictions.pred_masks)\n        # elif color_mode == ColorMode.IMAGE_BW:\n        #     self.output.reset_image(self.img)\n        #     self.draw_image(self.img)\n        # else:\n        #     raise ValueError(f\"Unknown color mode {color_mode}\")\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        # NOTE: this is not a great way to get the device\n        # TODO: fix the device issue\n        if predictions.has(\"pred_boxes\"):\n            self.draw_boxes(predictions.pred_boxes, predictions.pred_classes, predictions.scores)\n        if predictions.has(\"pred_keypoints\"):\n            self.draw_keypoints(predictions.pred_keypoints, predictions.pred_keypoints_vis)\n        if predictions.has(\"pred_masks\"):\n            self.draw_masks(predictions.pred_masks)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        img = self.canvas.tostring_rgb()\n        return np.frombuffer(img, dtype=np.uint8)\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # img = self.canvas.tostring_rgb()\n        img = self.canvas.tostring_argb()\n        img = np.fromstring(img, dtype=\"uint8\").reshape(self.height, self.width, 4)\n        img = img[:, :, :3]\n        img = img.astype(np.uint8)\n        return img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the current state of the canvas associated with the VisImage instance.\n        canvas = self.canvas\n        # Convert the RGBA image to RGB format.\n        img_rgb = canvas.to_rgb(canvas.buffer)\n        # Convert the image from float to uint8.\n        img_uint8 = (img_rgb * 255).astype(np.uint8)\n        # Return the visualized image.\n        return img_uint8\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.tostring_rgb()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.tostring_rgb()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.tostring_rgb().tobytes()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        img_rgb = self.canvas.tostring_rgb()\n        img = np.frombuffer(img_rgb, np.uint8).reshape(\n            (self.height, self.width, 3)\n        )\n        return img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the image from RGBA to RGB\n        img_rgb = self.canvas.tostring_rgb()\n        img = np.frombuffer(img_rgb, \"uint8\")\n        img = img.reshape(self.height, self.width, 3)\n        return img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.to_array()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # convert to RGB\n        img = self.canvas.tostring_rgb()\n        img = Image.frombytes(\"RGB\", (self.width, self.height), img)\n        return np.asarray(img)\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        img = self.canvas.print_to_array()\n        return img[:, :, :3]\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.tostring_rgb().tobytes().astype(\"uint8\")\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the figure and the associated canvas\n        fig = self.fig\n        canvas = self.canvas\n\n        # Get the image from the canvas\n        image = canvas.tostring_rgb()\n\n        # Convert the image to a numpy ndarray\n        image = np.frombuffer(image, dtype=np.uint8)\n\n        # Reshape the image to (H, W, 3)\n        image = image.reshape(self.height, self.width, 3)\n\n        return image\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.tostring_rgb()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        img = self.canvas.tostring_rgb()\n        img = np.fromstring(img, np.uint8).reshape(self.height, self.width, 3)\n        return img\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # convert the image from RGBA to RGB\n        img = self.canvas.tostring_rgb()\n        return Image.frombytes(\"RGB\", (self.width, self.height), img)\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        img = self.canvas.tostring_rgb()\n        return Image.frombytes(\"RGB\", (self.width, self.height), img)\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.canvas.tostring_rgb()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        return self.ax.get_image()\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # NOTE: PIL.Image.fromarray does not work for images with alpha channel\n        # https://github.com/pytorch/vision/issues/915\n        # https://github.com/pytorch/vision/issues/1305\n        # https://github.com/pytorch/vision/pull/1311\n        # https://github.com/pytorch/vision/issues/1501\n        # https://github.com/pytorch/vision/issues/2528\n        # https://github.com/pytorch/vision/issues/2749\n        # https://github.com/pytorch/vision/issues/2956\n        # https://github.com/pytorch/vision/issues/3696\n        # https://github.com/pytorch/vision/issues/3742\n        # https://github.com/pytorch/vision/issues/3972\n        # https://github.com/pytorch/vision/issues/4609\n        # https://github.com/pytorch/vision/issues/4909\n        # https://github.com/pytorch/vision/issues/5000\n        # https://github.com/pytorch/vision/issues/5240\n        # https://github.com/pytorch/vision/issues/5270\n        # https://github.com/pytorch/vision/issues/5436\n        # https://github.com/pytorch/vision/issues/5529\n        # https://github.com/pytorch/vision/issues/5530\n        # https://github.com/pytorch/vision/issues/5571\n        # https://github.com/pytorch/vision/issues/5700\n        # https://github.com/pytorch/vision/issues/5808\n        # https://github.com/pytorch/vision/issues/5860\n        # https://github.com/pytorch/vision/issues/5867\n        # https://github.com/pytorch/vision/issues/5883\n        # https://github.com/pytorch/vision/issues/5994\n        # https://github."}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic.get(\"annotations\") is not None:\n            self.draw_instances(dic.get(\"annotations\"))\n        if dic.get(\"sem_seg\") is not None:\n            self.draw_sem_seg(dic.get(\"sem_seg\"))\n        if dic.get(\"panoptic_seg\") is not None:\n            self.draw_panoptic_seg(dic.get(\"panoptic_seg\"), dic.get(\"panoptic_seg_info\"))\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic[\"annotations\"] is None:\n            return self.output\n        boxes = Boxes(dic[\"annotations\"])\n        keypoints = Keypoints(dic[\"annotations\"])\n        sem_seg = dic.get(\"sem_seg\")\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg_predictions(panoptic_seg, dic[\"panoptic_seg_info\"])\n        if boxes is not None:\n            self.draw_keypoints(keypoints)\n            self.draw_boxes(boxes)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # if \"panoptic_seg\" in dic:\n        #     self.draw_panoptic_seg(\n        #         panoptic_seg=dic[\"panoptic_seg\"],\n        #         segments_info=dic[\"segments_info\"],\n        #     )\n        # if \"sem_seg\" in dic:\n        #     self.draw_sem_seg(sem_seg=dic[\"sem_seg\"])\n        # if \"boxes\" in dic:\n        #     self.draw_boxes(boxes=dic[\"boxes\"])\n        # if \"keypoints\" in dic:\n        #     self.draw_keypoints(keypoints=dic[\"keypoints\"])\n        # if \"masks\" in dic:\n        #     self.draw_masks(masks=dic[\"masks\"])\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(\n                panoptic_seg=dic[\"panoptic_seg\"],\n                segments_info=dic[\"segments_info\"],\n                area_threshold=100,\n            )\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(sem_seg=dic[\"sem_seg\"], area_threshold=100)\n        if \"boxes\" in dic:\n            self.draw_boxes(boxes=dic[\"boxes\"])\n        if \"keypoints\" in dic:\n            self.draw_keypoints(keypoints=dic[\"keypoints\"])\n        if \"masks\" in dic:\n            self.draw_masks(masks=dic[\"masks\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            if \"keypoints\" in dic[\"annotations\"][0]:\n                self.draw_keypoints(\n                    np.asarray(dic[\"annotations\"], dtype=np.float32),\n                    self.metadata,\n                    keypoint_threshold=_KEYPOINT_THRESHOLD,\n                )\n            if \"bbox\" in dic[\"annotations\"][0]:\n                self.draw_boxes(\n                    np.asarray(dic[\"annotations\"], dtype=np.float32),\n                    self.metadata,\n                )\n            if \"segmentation\" in dic[\"annotations\"][0]:\n                self.draw_masks(\n                    np.asarray(dic[\"annotations\"], dtype=np.float32),\n                    self.metadata,\n                )\n            if \"iscrowd\" in dic[\"annotations\"][0]:\n                self.draw_text(\n                    [\n                        (\n                            x[\"segmentation\"],\n                            x[\"iscrowd\"],\n                        )\n                        for x in dic[\"annotations\"]\n                    ],\n                    self.metadata,\n                )\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], self.metadata)\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"], self.metadata)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"file_name\" not in dic:\n            raise ValueError(\"No file_name in dataset dict\")\n        if \"height\" not in dic:\n            raise ValueError(\"No height in dataset dict\")\n        if \"width\" not in dic:\n            raise ValueError(\"No width in dataset dict\")\n\n        img_path = PathManager.get_local_path(dic[\"file_name\"])\n        if not img_path.exists() or not img_path.is_file():\n            raise ValueError(f\"File {img_path} does not exist\")\n\n        img = Image.open(img_path)\n        img = np.array(img)\n        if img.ndim == 2:\n            img = np.dstack((img, img, img))\n        self.output.reset_image(img)\n        self.output.scale = 1.0\n\n        if \"keypoints\" in dic:\n            self.draw_keypoints(dic[\"keypoints\"], dic[\"keypoints_visible\"])\n\n        if \"boxes\" in dic:\n            self.draw_boxes(dic[\"boxes\"], dic.get(\"boxes_visible\", True))\n\n        if \"masks\" in dic:\n            self.draw_binary_mask(dic[\"masks\"])\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic.get(\"panoptic_seg_info\", []))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic is None:\n            return self.output\n\n        # draw mask\n        if \"segmentation\" in dic:\n            mask = dic[\"segmentation\"]\n            if isinstance(mask, list):\n                self.draw_mask(mask)\n            elif isinstance(mask, dict):\n                self.draw_mask(mask[\"segmentation\"])\n        # draw keypoints\n        if \"keypoints\" in dic:\n            keypoints = dic[\"keypoints\"]\n            if isinstance(keypoints, list):\n                self.draw_keypoints(keypoints)\n            elif isinstance(keypoints, dict):\n                self.draw_keypoints(keypoints[\"keypoints\"])\n        # draw boxes\n        if \"bbox\" in dic:\n            boxes = dic[\"bbox\"]\n            if isinstance(boxes, list):\n                self.draw_boxes(boxes)\n            elif isinstance(boxes, dict):\n                self.draw_boxes(boxes[\"bbox\"])\n        # draw semantic segmentation\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg)\n        # draw panoptic segmentation\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            self.draw_panoptic_seg(panoptic_seg)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # draw masks\n        if \"segmentation\" in dic:\n            self.draw_masks(dic[\"segmentation\"])\n\n        # draw keypoints\n        if \"keypoints\" in dic:\n            self.draw_keypoints(dic[\"keypoints\"])\n\n        # draw boxes\n        if \"boxes\" in dic:\n            self.draw_boxes(dic[\"boxes\"])\n\n        # draw semantic segmentation\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # draw panoptic segmentation\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic.get(\"height\", None) is not None:\n            self.output.height = int(dic[\"height\"])\n            self.output.width = int(dic[\"width\"])\n            self.output.reset_image(dic[\"image\"])\n\n        if \"masks\" in dic:\n            for mask_data in dic[\"masks\"]:\n                if isinstance(mask_data, dict):\n                    mask_data = GenericMask(mask_data[\"counts\"], mask_data[\"size\"])\n                if isinstance(mask_data, GenericMask):\n                    self.draw_mask(mask_data, color=random_color())\n                elif isinstance(mask_data, Boxes):\n                    self.draw_boxes(mask_data, color=random_color())\n                elif isinstance(mask_data, Keypoints):\n                    self.draw_keypoints(mask_data, color=random_color())\n                elif isinstance(mask_data, RotatedBoxes):\n                    self.draw_rotated_boxes(mask_data, color=random_color())\n                elif isinstance(mask_data, PolygonMasks):\n                    self.draw_polygons(mask_data, color=random_color())\n                elif isinstance(mask_data, BitMasks):\n                    self.draw_binary_mask(mask_data, color=random_color())\n                elif isinstance(mask_data, np.ndarray):\n                    self.draw_binary_mask(mask_data, color=random_color())\n                else:\n                    raise RuntimeError(\n                        \"Unsupported mask type: {} of type {}\".format(mask_data, type(mask_data))\n                    )\n\n        if \"keypoints\" in dic:\n            for keypoints in dic[\"keypoints\"]:\n                self.draw_keypoints(keypoints, color=random_color())\n\n        if \"boxes\" in dic:\n            for boxes in dic[\"boxes\"]:\n                self.draw_boxes(boxes, color=random_color())\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], alpha=0.5)\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(\n                dic[\"panoptic_seg"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic.get(\"annotations\", None) is not None:\n            self.draw_annotations(dic[\"annotations\"])\n\n        if dic.get(\"sem_seg\", None) is not None:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        if dic.get(\"panoptic_seg\", None) is not None:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n\n        if dic.get(\"keypoints\", None) is not None:\n            self.draw_keypoints(dic[\"keypoints\"])\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # region\n        if \"annotations\" in dic:\n            for anno in dic[\"annotations\"]:\n                if anno[\"iscrowd\"]:\n                    self.draw_keypoint(\n                        anno[\"keypoints\"],\n                        color=random_color(0),\n                        text=anno[\"category_id\"],\n                    )\n                else:\n                    self.draw_keypoint(\n                        anno[\"keypoints\"],\n                        color=random_color(anno[\"category_id\"]),\n                        text=anno[\"category_id\"],\n                    )\n\n        if \"segmentation\" in dic:\n            for seg in dic[\"segmentation\"]:\n                if seg[\"iscrowd\"]:\n                    self.draw_mask(\n                        seg[\"segmentation\"], color=random_color(0), text=seg[\"category_id\"]\n                    )\n                else:\n                    self.draw_mask(seg[\"segmentation\"], color=random_color(seg[\"category_id\"]))\n\n        # instance_masks\n        if \"instances\" in dic:\n            for instance in dic[\"instances\"]:\n                # self.draw_mask(instance.segmentation)\n                # self.draw_keypoints(instance.keypoints)\n                # self.draw_boxes(instance.boxes, text=instance.category_id)\n                self.draw_instance(\n                    instance.segmentation,\n                    instance.keypoints,\n                    instance.boxes,\n                    text=instance.category_id,\n                )\n\n        # keypoints\n        if \"keypoints\" in dic:\n            for keypoint in dic[\"keypoints\"]:\n                self.draw_keypoint(keypoint, color=random_color(keypoint[\"category_id\"]))\n        # boxes\n        if \"boxes\" in dic:\n            for box in dic[\"boxes\"]:\n                self.draw_box(box, text=box[\"category_id\"])\n\n        # semantic\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # panoptic\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic is None:\n            return self.output\n\n        # if \"sem_seg\" in dic:\n        #     self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=100)\n        # else:\n        #     # if \"panoptic_seg\" in dic:\n        #     #     self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n        #     if \"seg\" in dic:\n        #         self.draw_segmentation(dic[\"seg\"])\n        #     if \"keypoints\" in dic:\n        #         self.draw_keypoints(dic[\"keypoints\"])\n        #     if \"boxes\" in dic:\n        #         self.draw_boxes(dic[\"boxes\"], classes=dic[\"labels\"])\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n        if \"seg\" in dic:\n            self.draw_segmentation(dic[\"seg\"])\n        if \"keypoints\" in dic:\n            self.draw_keypoints(dic[\"keypoints\"])\n        if \"boxes\" in dic:\n            self.draw_boxes(dic[\"boxes\"], classes=dic[\"labels\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic.get(\"annotations\"):\n            if dic[\"annotations\"].get(\"segmentation\"):\n                self.draw_segmentation(dic[\"annotations\"][\"segmentation\"])\n            if dic[\"annotations\"].get(\"keypoints\"):\n                self.draw_keypoints(dic[\"annotations\"][\"keypoints\"])\n            if dic[\"annotations\"].get(\"bbox\"):\n                self.draw_boxes(dic[\"annotations\"][\"bbox\"])\n            if dic[\"annotations\"].get(\"iscrowd\"):\n                self.draw_iscrowd(dic[\"annotations\"][\"iscrowd\"])\n            if dic[\"annotations\"].get(\"category_id\"):\n                self.draw_class(dic[\"annotations\"][\"category_id\"])\n                # TODO: draw instance_id\n        if dic.get(\"sem_seg\"):\n            self.draw_sem_seg(dic[\"sem_seg\"])\n        if dic.get(\"panoptic_seg\"):\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # draw boxes\n        if \"annotations\" in dic:\n            for anno in dic[\"annotations\"]:\n                if anno.get(\"bbox\"):\n                    self.draw_box(anno[\"bbox\"], anno.get(\"category_id\"))\n\n        # draw keypoints\n        if \"keypoints\" in dic:\n            for keypoint in dic[\"keypoints\"]:\n                if keypoint[\"keypoints\"]:\n                    self.draw_keypoints(keypoint, keypoint[\"keypoints\"], keypoint.get(\"category_id\"))\n\n        # draw segmentation masks\n        if \"segmentation\" in dic:\n            for seg in dic[\"segmentation\"]:\n                if isinstance(seg, dict) and seg.get(\"counts\"):\n                    self.draw_polygon(seg)\n\n        # draw semantic segmentation\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # draw panoptic segmentation\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic.get(\"panoptic_seg_info\"))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"image_id\" in dic:\n            image_id = dic[\"image_id\"]\n        else:\n            image_id = dic[\"id\"]\n        if \"file_name\" in dic:\n            img_path = dic[\"file_name\"]\n            img_path = PathManager.get_local_path(img_path)\n        else:\n            img_path = PathManager.get_local_path(image_id)\n            img_path = PathManager.get_local_path(img_path)\n        if img_path is None:\n            raise ValueError(f\"Cannot find image file for image_id {image_id}\")\n        img = Image.open(img_path)\n        img = np.asarray(img)\n\n        if \"height\" in dic and \"width\" in dic:\n            height, width = dic[\"height\"], dic[\"width\"]\n            if height != img.shape[0] or width != img.shape[1]:\n                raise ValueError(\n                    f\"Image {img_path} has shape {img.shape}, but height and width are {height} and {width}.\"\n                )\n        else:\n            height = img.shape[0]\n            width = img.shape[1]\n\n        # draw mask first, so that it can be used for drawing boxes\n        if \"segmentation\" in dic:\n            self.draw_masks(dic[\"segmentation\"])\n        if \"keypoints\" in dic:\n            self.draw_keypoints(dic[\"keypoints\"])\n        if \"boxes\" in dic:\n            self.draw_boxes(dic[\"boxes\"], color=None)\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n        self.output.reset_image(img)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # get image\n        img_file = dic[\"file_name\"]\n        img_path = PathManager.get_file_path(img_file)\n        img = np.array(Image.open(img_path))\n        # if the image is grayscale, convert it to RGB\n        if img.ndim == 2:\n            img = img[:, :, np.newaxis]\n            img = np.concatenate([img, img, img], axis=2)\n\n        # draw segmentation masks\n        if \"segmentation\" in dic:\n            for seg in dic[\"segmentation\"]:\n                self.draw_mask(\n                    seg,\n                    color=self._jitter([0.5, 0.0, 1.0]),\n                    alpha=0.8,\n                    linewidth=1,\n                )\n\n        # draw keypoints\n        if \"keypoints\" in dic:\n            keypoints = dic[\"keypoints\"]\n            keypoints = [\n                Keypoints(keypoints[i], keypoints[i + 1], keypoints[i + 2])\n                for i in range(0, len(keypoints), 3)\n            ]\n            self.draw_keypoints(keypoints, color=self._jitter([0.0, 0.5, 0.5]), alpha=0.8)\n\n        # draw bounding boxes\n        if \"bbox\" in dic:\n            boxes = dic[\"bbox\"]\n            if boxes.ndim == 1:\n                boxes = [boxes]\n            boxes = [\n                Boxes(boxes[i], BoxMode.XYXYWWH) for i in range(len(boxes))\n                if boxes[i][2] > 0 and boxes[i][3] > 0\n            ]\n            self.draw_boxes(boxes, color=self._jitter([1.0, 0.0, 0.0]), alpha=0.8)\n\n        # draw semantic segmentation\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.8)\n\n        # draw panoptic segmentation\n        if \"panoptic_seg\" in dic:\n            self.draw_"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"image\" not in dic:\n            raise ValueError(\"Missing 'image' in dataset dict\")\n        if \"height\" not in dic:\n            raise ValueError(\"Missing 'height' in dataset dict\")\n        if \"width\" not in dic:\n            raise ValueError(\"Missing 'width' in dataset dict\")\n\n        img = dic[\"image\"]\n        height = dic[\"height\"]\n        width = dic[\"width\"]\n\n        if \"keypoints\" in dic:\n            self.draw_keypoints(dic[\"keypoints\"], dic[\"keypoints_vis\"])\n        if \"masks\" in dic:\n            self.draw_masks(dic[\"masks\"], dic[\"masks_vis\"])\n        if \"boxes\" in dic:\n            self.draw_boxes(dic[\"boxes\"])\n        if \"seg\" in dic:\n            self.draw_sem_seg(dic[\"seg\"])\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n\n        # TODO: add support for other types of annotations\n\n        self.output.img = img\n        self.output.height, self.output.width = height, width\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Draw semantic segmentation\n        if \"sem_seg\" in dic.keys():\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # Draw panoptic segmentation\n        if \"panoptic_seg\" in dic.keys():\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n\n        # Draw instance segmentation\n        if \"instances\" in dic.keys() and dic[\"instances\"].has(\"pred_masks\"):\n            self.draw_instance_predictions(dic[\"instances\"])\n\n        # Draw keypoints\n        if \"keypoints\" in dic.keys():\n            self.draw_keypoints(dic[\"keypoints\"], dic[\"keypoints_info\"])\n\n        # Draw bounding boxes\n        if \"boxes\" in dic.keys():\n            self.draw_boxes(dic[\"boxes\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic is None:\n            return self.output\n        for key, val in dic.items():\n\n            if isinstance(val, dict):\n                if \"height\" in val and \"width\" in val:\n                    img = Image.fromarray(self.img)\n                    img = np.asarray(img)\n                    self.draw_dataset_dict(val)\n                    self.output.reset_image(img)\n            elif isinstance(val, list):\n                if len(val) == 2 and isinstance(val[0], dict):\n                    self.draw_panoptic_seg_predictions(val[1])\n                else:\n                    for i, v in enumerate(val):\n                        if isinstance(v, dict):\n                            self.draw_dataset_dict(v)\n                        else:\n                            if key == \"keypoints\":\n                                self.draw_keypoints(v, mode=\"xy\")\n                            elif key == \"masks\":\n                                self.draw_binary_masks(v)\n                            elif key == \"segmentation\":\n                                self.draw_binary_segmentation(v)\n                            elif key == \"boxes\":\n                                self.draw_boxes(v)\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if dic is None:\n            return self.output\n        if \"sem_seg\" in dic:\n            self.output = self.draw_sem_seg(dic[\"sem_seg\"])\n        if \"panoptic_seg\" in dic:\n            self.output = self.draw_panoptic_seg_predictions(dic[\"panoptic_seg\"])\n        if \"keypoints\" in dic:\n            self.output = self.draw_keypoints(dic[\"keypoints\"])\n        if \"boxes\" in dic:\n            self.output = self.draw_boxes(dic[\"boxes\"])\n\n        if \"masks\" in dic:\n            self.output = self.draw_masks(dic[\"masks\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # TODO: consider adding a \"vis_only_annotations\" flag\n            for anno in dic[\"annotations\"]:\n                if anno[\"iscrowd\"] and self.metadata.has(\"stuff_classes\"):\n                    self.draw_sem_seg(\n                        anno[\"segmentation\"],\n                        area_threshold=anno.get(\"area_threshold\", 0),\n                    )\n                else:\n                    self.draw_keypoints(anno)\n                    self.draw_mask(anno[\"segmentation\"], anno[\"iscrowd\"])\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert the mask to a polygon\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        if mask.has_holes:\n            # draw the mask as a polygon\n            mask_color = self._jitter([x / 255 for x in color] if color is not None else None)\n            self.draw_polygon(\n                mask.exterior.reshape(-1, 2),\n                color=mask_color,\n                edge_color=edge_color,\n                alpha=alpha,\n            )\n\n            # draw the holes\n            for hole in mask.holes:\n                self.draw_polygon(\n                    hole.reshape(-1, 2),\n                    color=mask_color,\n                    edge_color=edge_color,\n                    alpha=alpha,\n                )\n        else:\n            # draw the mask as a polygon\n            self.draw_polygon(\n                mask.reshape(-1, 2),\n                color=color,\n                edge_color=edge_color,\n                alpha=alpha,\n            )\n\n        if text is not None:\n            # draw text on the mask\n            self.draw_text(text, mask.get_centroid(), color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert to polygon masks\n        mask_list = self._convert_binary_mask_to_polygon_masks(binary_mask)\n        # draw the polygon\n        for mask in mask_list:\n            self._draw_polygon(mask, color, edge_color, alpha)\n\n        # draw the text\n        if text:\n            self._draw_text(text)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # get the mask's area\n        area = binary_mask.sum()\n\n        # if the mask's area is less than the threshold, return\n        if area < area_threshold:\n            return self.output\n\n        # if the mask has holes, draw it as polygons\n        if binary_mask.sum() != area:\n            self.draw_binary_mask_with_holes(binary_mask, color, edge_color, alpha)\n        # if the mask has no holes, draw it as a polygon\n        else:\n            self.draw_binary_mask_as_polygon(binary_mask, color, edge_color, alpha)\n\n        if text is not None:\n            self.draw_text(text, (0, 0), color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert the mask to polygon\n        binary_mask = np.asarray(binary_mask)\n        if len(binary_mask.shape) == 3:\n            binary_mask = binary_mask[:, :, 0]\n        mask_polygon = GenericMask(binary_mask, self.output.height, self.output.width)\n\n        # draw mask\n        if mask_polygon.num_holes > 0:\n            # if the mask has holes, we draw the mask and the holes separately\n            mask_polygon.draw_with_holes(\n                self.output,\n                color=color,\n                edge_color=edge_color,\n                text=text,\n                alpha=alpha,\n                area_threshold=area_threshold,\n            )\n        else:\n            mask_polygon.draw(\n                self.output,\n                color=color,\n                edge_color=edge_color,\n                text=text,\n                alpha=alpha,\n                area_threshold=area_threshold,\n            )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert mask to polygon\n        mask_polygon = GenericMask(binary_mask, self.output.height, self.output.width)\n        mask_polygon_edges = mask_polygon.edges\n\n        # draw mask\n        for polygon in mask_polygon.polygons:\n            if polygon.area() < area_threshold:\n                continue\n\n            # draw mask\n            self.output.ax.add_patch(\n                mpl.patches.Polygon(\n                    polygon.reshape(-1, 2),\n                    facecolor=color,\n                    edgecolor=edge_color,\n                    linewidth=0.5 * self.output.scale,\n                    alpha=alpha,\n                )\n            )\n\n            # draw mask edges\n            for edge in polygon.edges:\n                self.draw_line(\n                    [edge[0][0], edge[1][0]], [edge[0][1], edge[1][1]], edge_color, alpha=0.5\n                )\n\n        # draw text\n        if text is not None:\n            self.draw_text(text, mask_polygon.centroid)\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert mask to polygons\n        mask_polygons = binary_mask.as_polygons()\n        mask_polygons = [\n            mask_polygon.reshape(-1, 2) for mask_polygon in mask_polygons.polygons\n        ]\n        # filter small masks\n        mask_polygons = [mask_polygon for mask_polygon in mask_polygons if mask_polygon.area > area_threshold]\n        if len(mask_polygons) == 0:\n            return self.output\n        # draw masks\n        for mask_polygon in mask_polygons:\n            self.draw_polygon(mask_polygon, color=color, edge_color=edge_color, alpha=alpha)\n        # draw text\n        if text is not None:\n            self.draw_text(text, color=\"g\")\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if edge_color is None:\n            edge_color = color\n\n        if len(binary_mask.shape) == 2:\n            # mask is a regular mask\n            if color is None:\n                color = _OFF_WHITE\n            self.output.ax.add_patch(\n                mpl.patches.Polygon(\n                    binary_mask.reshape(-1, 2),\n                    close=True,\n                    fill=True,\n                    color=color,\n                    edgecolor=edge_color,\n                    alpha=alpha,\n                )\n            )\n        elif len(binary_mask.shape) == 3 and binary_mask.shape[2] == 1:\n            # mask is a mask with holes\n            mask = binary_mask.squeeze()\n            for i in range(0, binary_mask.shape[1], 2):\n                if i + 1 < binary_mask.shape[1]:\n                    # draw a polygon\n                    if color is None:\n                        color = _OFF_WHITE\n                    self.output.ax.add_patch(\n                        mpl.patches.Polygon(\n                            mask[:, i].reshape(-1, 2),\n                            close=True,\n                            fill=True,\n                            color=color,\n                            edgecolor=edge_color,\n                            alpha=alpha,\n                        )\n                    )\n                    # draw the holes\n                    if color is None:\n                        color = _OFF_WHITE\n                    self.output.ax.add_patch(\n                        mpl.patches.Polygon(\n                            mask[:, i + 1].reshape(-1, 2),\n                            close=True,\n                            fill=True,\n                            color=color,\n                            edgecolor=edge_color,\n                            alpha=alpha,\n                        )\n                    )\n        else:\n            raise ValueError(\n                \"The mask must be a binary numpy array of shape (H, W) or (H, W, 1).\"\n            )\n\n        if text is not None:\n            self.draw_text(\n                text,\n                position=(binary_mask.shape[1] // 2, binary_mask.shape[0] // 2),\n                horizontal_alignment=\"center\",\n                vertical_alignment=\"top\","}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert the mask to a polygon\n        if not binary_mask.shape[1] == self.output.width:\n            raise ValueError(\n                f\"The width of the mask ({binary_mask.shape[1]}) does not match the width of the image ({self.output.width}).\"\n            )\n        if not binary_mask.shape[0] == self.output.height:\n            raise ValueError(\n                f\"The height of the mask ({binary_mask.shape[0]}) does not match the height of the image ({self.output.height}).\"\n            )\n        poly = self._convert_masks(binary_mask)\n\n        # draw the mask\n        if poly.area() > area_threshold:\n            for segment in poly.polygons:\n                self.draw_polygon(segment.reshape(-1, 2), color=color, alpha=alpha)\n\n            if edge_color is not None:\n                self.draw_polygon(poly.exterior.reshape(-1, 2), edge_color=edge_color, alpha=1)\n            elif color is not None:\n                self.draw_polygon(poly.exterior.reshape(-1, 2), edge_color=color, alpha=1)\n\n        # draw text\n        if text is not None:\n            self.draw_text(text, position=poly.centroid.astype(int))\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = _OFF_WHITE\n\n        if text is not None:\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            text_font_size = self._default_font_size * 0.5\n\n        # convert the mask to polygon format\n        mask_polygons = GenericMask(binary_mask, self.output.height, self.output.width).polygons\n\n        # draw the mask\n        for polygon in mask_polygons:\n            # if the polygon is too small, skip it\n            if polygon.area() < area_threshold:\n                continue\n\n            self.output.ax.add_patch(\n                mpl. trist.Polygon(\n                    polygon.reshape(-1, 2),\n                    closed=True,\n                    facecolor=color,\n                    alpha=alpha,\n                    edgecolor=edge_color,\n                )\n            )\n\n        # draw the text\n        if text is not None:\n            self.draw_text(\n                text,\n                (polygon.mean_x(), polygon.mean_y()),\n                color=text_color,\n                font_size=text_font_size,\n            )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert to polygons\n        if binary_mask.dtype == np.bool:\n            binary_mask = np.where(binary_mask, 1, 0)\n        binary_mask = GenericMask(binary_mask, self.output.height, self.output.width)\n\n        # draw polygons\n        for polygon in binary_mask.polygons:\n            if polygon.area() < area_threshold:\n                continue  # skip small polygon\n            if color is None:\n                color = random_color(rgb=True, maximum=1)\n            self.draw_polygon(polygon, color, alpha=alpha, edge_color=edge_color)\n\n        # draw text\n        if text is not None and color is not None:\n            self.draw_text(text, color=color, alpha=alpha)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert to polygon mask\n        if isinstance(binary_mask, np.ndarray):\n            binary_mask = GenericMask(binary_mask, self.output.height, self.output.width)\n\n        if not isinstance(binary_mask, PolygonMask):\n            binary_mask = PolygonMask(binary_mask)\n\n        # find connected components\n        connected_components = binary_mask.connected_components()\n\n        # draw each connected component\n        for component in connected_components:\n            if component.area > area_threshold:\n                self._draw_polygon(\n                    component.polygon,\n                    color=color,\n                    edge_color=edge_color,\n                    text=text,\n                    alpha=alpha,\n                )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if len(binary_mask.shape) == 3:\n            binary_mask = binary_mask[0]\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        if mask.area() < area_threshold:\n            return self.output  # skip small masks\n\n        # Draw outline of mask\n        if edge_color is None:\n            edge_color = _OFF_WHITE\n        self.output.ax.add_patch(mpl.patches.PathPatch(mask, edgecolor=edge_color, alpha=0))\n\n        # Draw mask\n        if color is None:\n            color = _RANDOM_COLOR\n        self.output.ax.add_patch(mpl.patches.PathPatch(mask, facecolor=color, alpha=alpha))\n\n        if text is not None:\n            self.draw_text(\n                text,\n                mask.get_center(),\n                color=_RANDOM_COLOR,\n                horizontal_alignment=\"center\",\n                rotation=0,\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Draw mask as polygons\n        if np.prod(binary_mask.shape) < area_threshold:\n            return self.output\n\n        if not self.output.ax.has_key(\"mask\"):\n            self.output.ax[\"mask\"] = []\n        if not self.output.ax.has_key(\"mask_edge\"):\n            self.output.ax[\"mask_edge\"] = []\n\n        # Make sure the mask is a binary mask\n        binary_mask = np.asarray(binary_mask, dtype=np.uint8)\n\n        # Get the connected components of the mask\n        labels, num_components = ndimage.label(binary_mask)\n        # Get the areas of the components\n        areas = ndimage.sum(binary_mask, labels=labels)\n\n        # Find the components to be drawn and draw them\n        for component in range(1, num_components + 1):\n            if areas[component] < area_threshold:\n                continue\n            mask_points = np.where(labels == component)\n            self.output.ax[\"mask\"].append(\n                mpl.patches.Polygon(\n                    zip(mask_points[1], mask_points[0]),\n                    closed=True,\n                    edgecolor=edge_color,\n                    facecolor=color,\n                    alpha=alpha,\n                )\n            )\n\n        # Draw text on the mask\n        if text is not None:\n            self.draw_text(text, (binary_mask.shape[0] / 2, binary_mask.shape[1] / 2))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = _OFF_WHITE\n        if edge_color is None:\n            edge_color = _OFF_WHITE\n\n        # if the mask is all 0s, return\n        if np.all(binary_mask == 0):\n            return self.output\n\n        # find connected components\n        mask_label_image, num_comp = connected_components(binary_mask)\n\n        # find the area of each component\n        component_area = np.bincount(mask_label_image.flat, minlength=num_comp + 1)\n\n        # find the indices of the components that are larger than the threshold\n        component_idx = np.where(component_area > area_threshold)[0]\n\n        # draw the mask\n        for idx in component_idx:\n            mask = mask_label_image == idx\n            mask_polygon = Polygon(np.argwhere(mask))\n            self.output.ax.add_ benzin(mask_polygon, facecolor=color, edgecolor=edge_color, alpha=alpha)\n\n        # draw text\n        if text is not None:\n            self.draw_text(\n                text,\n                (binary_mask.mean(axis=1).sum() / 2, binary_mask.mean(axis=0).sum() / 2),\n                color=color,\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if not isinstance(binary_mask, np.ndarray):\n            raise ValueError(\"The input mask must be a numpy array.\")\n\n        if binary_mask.ndim != 2:\n            raise ValueError(\n                \"The input mask must be a 2D array. Got {}D instead.\".format(binary_mask.ndim)\n            )\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # if the mask is a polygon, draw it as a polygon\n        if binary_mask.shape[0] == 1:\n            # convert to a polygon\n            poly = [\n                (x, y) for x, y in zip(binary_mask[0], binary_mask[1]) if binary_mask[0][x, y]\n            ]\n\n            # draw the polygon\n            self.output.ax.add_ lade(\n                mpl.patches.Polygon(\n                    poly,\n                    fill=True,\n                    edgecolor=edge_color,\n                    facecolor=color,\n                    alpha=alpha,\n                )\n            )\n\n            # draw the text if it's specified\n            if text is not None:\n                self.draw_text(text, poly[0], color=color, rotation=0)\n\n        # if the mask is a regular mask, draw it as a polygon\n        else:\n            # draw the mask\n            self.output.ax.add_ lade(\n                mpl.patches.Polygon(\n                    binary_mask,\n                    fill=True,\n                    edgecolor=edge_color,\n                    facecolor=color,\n                    alpha=alpha,\n                )\n            )\n\n            # draw the text if it's specified\n            if text is not None:\n                self.draw_text(text, binary_mask.min(), color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if edge_color is None:\n            edge_color = color\n\n        if color is None:\n            color = self._jitter([1, 1, 1])\n\n        # draw mask\n        mask_color = [x / 255 for x in color]\n        mask_color = np.array(mask_color)\n        mask_color = (\n            np.clip(mask_color, 0, 1) if mask_color.size == 3 else mask_color\n        )  # if color is a single number, clip it to [0,1]\n\n        # draw mask with holes\n        if np.any(binary_mask > 1):\n            # this is a mask with holes\n            mask = GenericMask(binary_mask, self.output.height, self.output.width)\n            self.output.ax.add_patch(\n                mpl.patches. mozaic_patches(mask, color=mask_color, alpha=alpha)\n            )\n        else:\n            # draw regular polygon\n            self.output.ax.add_patch(\n                mpl.patches.Polygon(binary_mask.nonzero(), color=mask_color, alpha=alpha)\n            )\n\n        # draw text\n        if text is not None:\n            self.draw_text(text, (0, 0), color=edge_color, alpha=0.8)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # convert binary mask to polygon\n        binary_mask = np.asarray(binary_mask, dtype=np.uint8)\n        if np.all(binary_mask == 0):\n            return self.output\n\n        # get the connected components\n        labels = np.unique(binary_mask)\n        if len(labels) == 1:\n            # the mask is all 0's or 1's\n            if labels[0] == 0:\n                # mask is all 0's, return the image\n                return self.output\n            self.draw_polygon(binary_mask.reshape(-1, 2), color=color, alpha=alpha)\n            return self.output\n\n        # mask has holes\n        label_to_mask = {}\n        for label in labels:\n            label_to_mask[label] = (binary_mask == label)\n\n        # get the largest connected component\n        largest_mask = None\n        for label, mask in label_to_mask.items():\n            if largest_mask is None or mask.sum() > largest_mask.sum():\n                largest_mask = mask\n\n        # draw the largest connected component\n        self.draw_polygon(largest_mask.reshape(-1, 2), color=color, alpha=alpha)\n\n        # draw the holes\n        for label, mask in label_to_mask.items():\n            if label == largest_mask:\n                continue\n            if mask.sum() < area_threshold:\n                continue\n            self.draw_polygon(mask.reshape(-1, 2), color=color, alpha=alpha)\n\n        if text is not None:\n            x, y = np.where(largest_mask)\n            if len(x) == 0:\n                return self.output\n\n            # get the center of the mask\n            x, y = x.mean(), y.mean()\n            # get the text color\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            # get the font size\n            font_size = (np.sqrt(largest_mask.sum()) / 200) * self._default_font_size\n            # draw the"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # draw mask\n        # mask_color = np.array(color) if color is not None else np.random.rand(3)\n        mask_color = color if color is not None else _RANDOM_COLOR\n        if mask_color is not None:\n            mask_color = tuple(x / 255.0 for x in mask_color)\n        else:\n            mask_color = _RANDOM_COLOR\n        mask_color = tuple(x / 255.0 for x in mask_color)\n\n        # draw polygon\n        if mask_color[0] > 0.9:\n            # if the mask is white, we need to draw a black outline\n            edge_color = _BLACK if edge_color is None else edge_color\n        else:\n            # otherwise, the edge color should be the same as the mask color\n            edge_color = mask_color\n\n        # draw polygon\n        mask_polygons = np.argwhere(binary_mask)\n        if len(mask_polygons) == 0:\n            return self.output\n        for polygon in mask_polygons:\n            x, y = polygon\n            self.output.ax.add_patch(\n                mpl.patches.Polygon(\n                    [(x, y), (x, y + 1), (x + 1, y + 1), (x + 1, y)],\n                    facecolor=mask_color,\n                    edgecolor=edge_color,\n                    alpha=alpha,\n                )\n            )\n\n        # draw holes\n        if binary_mask.sum() > 1:\n            # find holes\n            holes = np.argwhere(np.logical_not(binary_mask))\n            for hole in holes:\n                x, y = hole\n                self.output.ax.add_patch(\n                    mpl.patches.Polygon(\n                        [(x, y), (x, y + 1), (x + 1, y + 1), (x + 1, y)],\n                        facecolor=None,\n                        edgecolor=edge_color,\n                        alpha=alpha,\n                        hatch=\"\\\\\",\n                    )\n                )\n\n        # draw text\n        if text is not None"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # draw mask\n        # we can't draw the mask as a polygon because it may have holes\n        # so we need to draw it as a collection of polygons\n        # we use a threshold to filter out small areas\n        # we also use a threshold to filter out small areas\n        # that are too close to the edge of the image\n        # because they would otherwise be clipped\n        # we do not filter out small areas that are too close to the edge\n        # because this would result in a jagged edge\n        # (the edge would be drawn as a polygon)\n        # we use bresenham's algorithm to draw the lines\n        # because it's faster than the bresenham's line algorithm\n        # (which is used by the matplotlib bresenham's line algorithm)\n        # we use bresenham's line algorithm to draw the lines\n        # because it's faster than the bresenham's line algorithm\n        # (which is used by the bresenham's bresenham's line algorithm)\n        # we use bresenham's bresenham's line algorithm to draw the lines\n        # because it's faster than the bresenham's line algorithm\n        # (which is used by the bresenham's bresenham's line algorithm)\n        # we use bresenham's bresenham's bresenham's line algorithm to draw the lines\n        # because it's faster than the bresenham's line algorithm\n        # (which is used by the bresenham's bresenham's bresenham's line algorithm)\n        # we use bresenham's bresenham's bresenham's bresenham's line algorithm to draw the lines\n        # because it's faster than the bresenham's line algorithm\n        # (which is used by the bresenham's bresenham's bresenham's bresenham's line algorithm)\n        # we use bresenham's bresenham's bresenham's bresenham's bresenham's line algorithm to draw the lines"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # make a copy of the binary mask\n        mask = binary_mask.copy()\n\n        # remove all components that are too small\n        mask = remove_small_components(mask, area_threshold)\n\n        # remove all components that are not connected to the border\n        mask = remove_non_border_components(mask)\n\n        # find all connected components\n        components = find_components(mask)\n\n        # draw the mask\n        for component in components:\n            # get the component's bounding box\n            bbox = component.bbox()\n            # get the polygon\n            polygon = component.mask.polygons[0]\n\n            # convert the polygon to the format matplotlib expects\n            poly_points = np.array(polygon.exterior.coords)\n            poly_points = poly_points.reshape((-1, 2))\n\n            # draw the polygon\n            if edge_color is None:\n                edge_color = color\n\n            self.draw_polygon(poly_points, color=color, edge_color=edge_color, alpha=alpha)\n\n        # draw the text if specified\n        if text is not None:\n            # find the bounding box of the mask\n            bbox = mask.bbox()\n\n            # get the center of the bounding box\n            center = np.array(bbox.center())\n\n            # draw the text\n            self.draw_text(text, center, color=color, alpha=alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            if input.image_size.size(0) != other.image_size.size(0):\n                raise ValueError(\n                    \"image_size must have the same number of dimensions: {} vs. {}\".format(\n                        input.image_size, other.image_size\n                    )\n                )\n            if not input.image_size.allclose(other.image_size, rtol=rtol):\n                raise ValueError(\n                    \"image_size must be close: {} vs. {}\".format(\n                        input.image_size, other.image_size\n                    )\n                )\n        else:\n            if input.image_size[0] != other.image_size[0] or input.image_size[1] != other.image_size[1]:\n                raise ValueError(\n                    \"image_size must be equal: {} vs. {}\".format(\n                        input.image_size, other.image_size\n                    )\n                )\n\n    for field_name in input._field_names:\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n        if isinstance(input_field, Boxes):\n            if not input_field.allclose(other_field, rtol=rtol):\n                raise ValueError(\n                    \"{} must be close: {} vs. {}\".format(\n                        field_name, input_field, other_field\n                    )\n                )\n        elif isinstance(input_field, ROIMasks):\n            if not input_field.allclose(other_field, rtol=rtol):\n                raise ValueError(\n                    \"{} must be close: {} vs. {}\".format(\n                        field_name, input_field, other_field\n                    )\n                )\n        elif isinstance(input_field, torch.Tensor):\n            if not input_field.allclose(other_field, rtol=rtol):\n                raise ValueError(\n                    \"{} must be close: {} vs. {}\".format(\n                        field_name, input_field, other_field\n                    )\n                )\n        elif input_field != other_field"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            \"Instances.assert_allclose: first argument is not an Instances object\"\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            \"Instances.assert_allclose: second argument is not an Instances object\"\n        )\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert_allclose(\n                input.image_size,\n                other.image_size,\n                rtol=rtol,\n                msg=msg,\n            )\n        else:\n            assert (\n                input.image_size == other.image_size\n            ), f\"Expected image size {input.image_size}, got {other.image_size}\"\n    for field in input.fields():\n        if field in [\"image\", \"image_id\", \"area\"]:\n            continue\n        if isinstance(input._fields[field], Boxes):\n            assert_allclose(\n                input._fields[field],\n                other._fields[field],\n                rtol=rtol,\n                msg=msg,\n                size_as_tensor=size_as_tensor,\n            )\n        elif isinstance(input._fields[field], ROIMasks):\n            assert_allclose(\n                input._fields[field],\n                other._fields[field],\n                rtol=rtol,\n                msg=msg,\n                size_as_tensor=size_as_tensor,\n            )\n        elif isinstance(input._fields[field], torch.Tensor):\n            assert_allclose(\n                input._fields[field],\n                other._fields[field],\n                rtol=rtol,\n                msg=msg,\n            )\n        else:\n            assert input._fields[field] == other._fields[field], msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            msg = f\"{msg} Expected: {input.image_size}, got {other.image_size}\"\n        else:\n            msg = f\"{msg} Expected: {input.image_size}, got {other.image_size}\"\n\n        raise AssertionError(msg)\n\n    for field_name in input._field_names:\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n        if isinstance(input_field, Boxes):\n            assert input_field.tensor.allclose(\n                other_field.tensor, rtol=rtol\n            ), f\"{msg} Expected: {input_field}, got {other_field}\"\n        elif isinstance(input_field, ROIMasks):\n            assert input_field.tensor.allclose(\n                other_field.tensor, rtol=rtol\n            ), f\"{msg} Expected: {input_field}, got {other_field}\"\n        elif isinstance(input_field, torch.Tensor):\n            assert input_field.allclose(\n                other_field, rtol=rtol\n            ), f\"{msg} Expected: {input_field}, got {other_field}\"\n        else:\n            assert input_field == other_field, f\"{msg} Expected: {input_field}, got {other_field}\"\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert_allclose(\n                input.image_size,\n                other.image_size,\n                rtol=rtol,\n                msg=msg,\n                size_as_tensor=False,\n            )\n        else:\n            assert (\n                input.image_height == other.image_height\n            ), msg + f\"input.image_height != other.image_height\"\n            assert (\n                input.image_width == other.image_width\n            ), msg + f\"input.image_width != other.image_width\"\n    for field_name, field_val in input._fields.items():\n        if field_name == \"image_size\":\n            continue\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n        if field_val.dtype == torch.bool:\n            assert (\n                input_field == other_field\n            ), msg + f\"input.{field_name} != other.{field_name}\"\n        elif isinstance(input_field, torch.Tensor):\n            assert (\n                input_field.allclose(other_field, rtol=rtol)\n            ), msg + f\"input.{field_name} != other.{field_name}\"\n        elif isinstance(input_field, ROIMasks):\n            assert (\n                input_field.size == other_field.size\n            ), msg + f\"input.{field_name}.size != other.{field_name}.size\"\n            assert (\n                input_field.mask_data == other_field.mask_data\n            ), msg + f\"input.{field_name}.mask_data != other.{field_name}.mask_data\"\n        elif isinstance(input_field, Boxes):\n            assert (\n                input_field.tensor == other_field.tensor\n            ), msg + f\"input.{field_name}.tensor != other.{field_name}.tensor\"\n        elif isinstance(input_field, (list, tuple)):\n            assert (\n                len(input_field) == len(other_field)\n            ), msg +"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert_allclose(\n                input.image_size,\n                other.image_size,\n                rtol=rtol,\n                msg=msg,\n                size_as_tensor=True,\n            )\n        else:\n            assert (\n                input.image_size == other.image_size\n            ), f\"Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field_name, field_type in input._field_names.items():\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n\n        if field_type == Boxes:\n            assert_allclose(input_field, other_field, rtol=rtol, msg=msg)\n        elif field_type == ROIMasks:\n            assert_allclose(\n                input_field,\n                other_field,\n                rtol=rtol,\n                msg=msg,\n                size_as_tensor=size_as_tensor,\n            )\n        elif isinstance(field_type, torch.Tensor):\n            assert_allclose(input_field, other_field, rtol=rtol, msg=msg)\n        elif isinstance(field_type, int) or isinstance(field_type, float):\n            assert input_field == other_field, msg\n        else:\n            assert input_field == other_field, f\"Unexpected field type: {field_type}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            \"Expect an Instances object, but got %s!\" % type(input)\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\"Expect an Instances object, but got %s!\" % type(other))\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            if input.image_size.shape != other.image_size.shape:\n                raise ValueError(\n                    \"Expect image_size of Instances to be the same shape, but got %s and %s.\"\n                    % (input.image_size, other.image_size)\n                )\n            if not torch.allclose(\n                input.image_size, other.image_size, atol=0.0, rtol=rtol\n            ):\n                raise ValueError(\n                    \"Expect image_size of Instances to be close to each other, but got %s and %s.\"\n                    % (input.image_size, other.image_size)\n                )\n        else:\n            if input.image_size != other.image_size:\n                raise ValueError(\n                    \"Expect image_size of Instances to be the same, but got %s and %s.\"\n                    % (input.image_size, other.image_size)\n                )\n    for field_name in input._field_names:\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n        if isinstance(input_field, Boxes):\n            if not input_field.x1.allclose(other_field.x1, rtol=rtol):\n                raise AssertionError(\n                    msg + \"Expected x1 to be equal, but got %s and %s.\"\n                    % (input_field.x1, other_field.x1)\n                )\n            if not input_field.y1.allclose(other_field.y1, rtol=rtol):\n                raise AssertionError(\n                    msg\n                    + \"Expected y1 to be equal, but got %s and %s.\"\n                    % (input_field.y1, other_field.y1"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\n            \"assert_instances_allclose expects both input and other to be \"\n            \"Instances, but got {} and {}\".format(type(input), type(other))\n\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            if not isinstance(input.image_size, torch.Tensor):\n                raise ValueError(\n                    \"size_as_tensor is True but input.image_size is not a tensor\"\n                )\n            if not isinstance(other.image_size, torch.Tensor):\n                raise ValueError(\n                    \"size_as_tensor is True but other.image_size is not a tensor\"\n                )\n            if not torch.allclose(input.image_size, other.image_size, rtol=rtol):\n                raise AssertionError(\n                    \"The image sizes are not close to each other: {} != {}\".format(\n                        input.image_size, other.image_size\n                    )\n                )\n        else:\n            if not isinstance(input.image_size, tuple):\n                raise ValueError(\n                    \"size_as_tensor is False but input.image_size is not a tuple\"\n                )\n            if not isinstance(other.image_size, tuple):\n                raise ValueError(\n                    \"size_as_tensor is False but other.image_size is not a tuple\"\n                )\n            if not all(\n                input.image_size == other.image_size\n            ):  # pylint: disable=not-an-iterable\n                raise AssertionError(\n                    \"The image sizes are not equal to each other: {} != {}\".format(\n                        input.image_size, other.image_size\n                    )\n                )\n\n    if input.has_field(\"boxes\"):\n        if not all(input.boxes == other.boxes):\n            raise AssertionError(\n                \"The boxes are not equal to each other: {} != {}\".format(\n                    input.boxes, other.boxes\n                )\n            )\n    if input.has_field(\"masks\"):\n        if not all(input.masks == other.masks):\n            raise AssertionError(\n                "}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(f\"Expect an Instances object, but got {type(input)}!\")\n\n    if not isinstance(other, Instances):\n        raise ValueError(f\"Expect an Instances object, but got {type(other)}!\")\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert (\n                input.image_size[0] == other.image_size[0]\n            ), f\"Image size mismatch: {input.image_size} vs. {other.image_size}\"\n        else:\n            assert (\n                input.image_size == other.image_size\n            ), f\"Image size mismatch: {input.image_size} vs. {other.image_size}\"\n\n    for field_name, other_field in zip(input._field_names, other._field_names):\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n        if input_field is None and other_field is None:\n            continue\n        if input_field is None or other_field is None:\n            raise ValueError(\n                f\"Mismatched field {field_name} for {input} and {other}\"\n            )\n        if isinstance(input_field, ROIMasks) and isinstance(\n            other_field, ROIMasks\n        ):\n            assert_roimasks_allclose(input_field, other_field, rtol=rtol, msg=msg)\n        elif isinstance(input_field, Boxes) and isinstance(\n            other_field, Boxes\n        ):\n            assert_boxes_allclose(input_field, other_field, rtol=rtol, msg=msg)\n        elif isinstance(input_field, torch.Tensor) and isinstance(\n            other_field, torch.Tensor\n        ):\n            assert_tensor_allclose(input_field, other_field, rtol=rtol, msg=msg)\n        else:\n            assert_allclose(input_field, other_field, rtol=rtol, msg=msg)\n    return\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Expect an Instances object, but got {type(input)}!\"\n    assert isinstance(other, Instances), f\"Expect an Instances object, but got {type(other)}!\"\n\n    # check image size\n    if size_as_tensor:\n        assert input.image_size.shape == other.image_size.shape, msg\n        assert (\n            input.image_size.eq(other.image_size).all()\n        ), msg + \"image size not equal\"\n    else:\n        assert input.image_size == other.image_size, msg + \"image size not equal\"\n\n    # check fields\n    for name, val in input.fields.items():\n        if isinstance(val, Boxes):\n            assert isinstance(other.fields[name], Boxes), f\"{name} is not a Boxes\"\n            assert (\n                val.tensor.allclose(other.fields[name].tensor, rtol=rtol)\n            ), f\"{name} not close\"\n        elif isinstance(val, ROIMasks):\n            assert isinstance(\n                other.fields[name], ROIMasks\n            ), f\"{name} is not a ROIMasks\"\n            assert (\n                val.tensor.allclose(other.fields[name].tensor, rtol=rtol)\n            ), f\"{name} not close\"\n        elif isinstance(val, torch.Tensor):\n            assert isinstance(other.fields[name], torch.Tensor), f\"{name} is not a Tensor\"\n            assert (\n                val.allclose(other.fields[name], rtol=rtol)\n            ), f\"{name} not close\"\n        else:\n            assert (\n                val == other.fields[name]\n            ), f\"{name} not equal, {name}={val} other={other.fields[name]}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            \"First input must be an instance of Instances, but got {}\".format(\n                type(input)\n            )\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            \"Second input must be an instance of Instances, but got {}\".format(\n                type(other)\n            )\n        )\n\n    if size_as_tensor:\n        assert input.image_size.shape == other.image_size.shape, (\n            \"The image sizes of the two Instances objects are not the same.\"\n        )\n        assert (\n            torch.allclose(\n                input.image_size, other.image_size, rtol=rtol, atol=0\n            )\n        ), \"The image sizes of the two Instances objects are not the same.\"\n\n    for name in input._field_names:\n        val1 = getattr(input, \"_\" + name, None)\n        val2 = getattr(other, \"_\" + name, None)\n        if val1 is None or val2 is None:\n            continue\n        if isinstance(val1, Boxes):\n            assert val1.shape == val2.shape, \"Boxes have different shapes.\"\n            assert (\n                val1.x1.allclose(val2.x1, rtol=rtol, atol=0)\n            ), \"Boxes have different x1 coordinates.\"\n            assert (\n                val1.y1.allclose(val2.y1, rtol=rtol, atol=0)\n            ), \"Boxes have different y1 coordinates.\"\n            assert (\n                val1.x2.allclose(val2.x2, rtol=rtol, atol=0)\n            ), \"Boxes have different x2 coordinates.\"\n            assert (\n                val1.y2.allclose(val2.y2, rtol=rtol, atol=0)\n            ), \"Boxes have different y2 coordinates.\"\n        elif isinstance(val1, ROIMasks):\n            assert (\n                val1.shape == val2.shape\n            ), \"Masks have different shapes.\"\n            assert (\n                val1.mask.allclose(val2.mask, rtol"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            \"The input is not of type Instances. \"\n            \"This function expects an Instances object, but got {}.\".format(\n                type(input)\n            )\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            \"The other input is not of type Instances. \"\n            \"This function expects an Instances object, but got {}.\".format(\n                type(other)\n            )\n        )\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            if not isinstance(input.image_size, torch.Tensor):\n                raise ValueError(\n                    \"If the size_as_tensor parameter is set to True, the image_size of the Instances object must be a tensor, but got {}\".format(\n                        type(input.image_size)\n                    )\n                )\n            if not isinstance(other.image_size, torch.Tensor):\n                raise ValueError(\n                    \"If the size_as_tensor parameter is set to True, the image_size of the Instances object must be a tensor, but got {}\".format(\n                        type(other.image_size)\n                    )\n                )\n            if input.image_size.ne(other.image_size).any():\n                raise ValueError(\n                    \"The image_size of the input Instances is not equal to the image_size of the other Instances. \"\n                    \"The input image_size is {}, but the other image_size is {}.\".format(\n                        input.image_size, other.image_size\n                    )\n                )\n        else:\n            if not isinstance(input.image_size, tuple):\n                raise ValueError(\n                    \"If the size_as_tensor parameter is set to False, the image_size of the Instances object must be a tuple, but got {}\".format(\n                        type(input.image_size)\n                    )\n                )\n            if not isinstance(other.image_size, tuple):\n                raise ValueError(\n                    \"If the size_as_tensor parameter is set to False, the image_size of the Instances object must be a tuple, but got {}\".format(\n                        type(other.image_"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert_allclose(\n                input.image_size,\n                other.image_size,\n                rtol=rtol,\n                msg=msg,\n                size_as_tensor=size_as_tensor,\n            )\n        else:\n            assert input.image_size == other.image_size, msg\n    if input.has_field(\"boxes\") and not input.boxes.allclose(other.boxes, rtol=rtol):\n        raise ValueError(\n            f\"Boxes do not match. Input: {input.boxes} and other: {other.boxes}\"\n        )\n    if input.has_field(\"masks\") and not input.masks.allclose(other.masks):\n        raise ValueError(\n            f\"Masks do not match. Input: {input.masks} and other: {other.masks}\"\n        )\n    if input.has_field(\"keypoints\"):\n        if (\n            input.keypoints.shape != other.keypoints.shape\n            or input.keypoints.dtype != other.keypoints.dtype\n            or input.keypoints.device != other.keypoints.device\n        ):\n            raise ValueError(\n                f\"Keypoints do not match. Input: {input.keypoints} and other: {other.keypoints}\"\n            )\n        if not input.keypoints.allclose(other.keypoints):\n            raise ValueError(\n                f\"Keypoints do not match. Input: {input.keypoints} and other: {other.keypoints}\"\n            )\n    if input.has_field(\"masks\") and not input.masks.allclose(other.masks):\n        raise ValueError(\n            f\"Masks do not match. Input: {input.masks} and other: {other.masks}\"\n        )\n    if not input.fields.isdisjoint(other.fields):\n        raise ValueError(\n            f\"Fields do not match. Input: {input.fields} and other: {other.fields}\"\n        )\n    if len(input) != len(other):\n        raise ValueError(\n            f\"Instances have different number of instances. Input: {len"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert input.image_size.shape == other.image_size.shape\n        assert (\n            torch.allclose(input.image_size, other.image_size, atol=0, rtol=rtol)\n        ), f\"{msg} Image size is not the same.\"\n\n    assert input._field_names == other._field_names, (\n        msg\n        + f\" Input and other have different field names: {input._field_names} != {other._field_names}.\"\n    )\n    for field in input._field_names:\n        input_field = getattr(input, field)\n        other_field = getattr(other, field)\n        if isinstance(input_field, ROIMasks):\n            assert (\n                input_field.shape == other_field.shape\n            ), f\"{msg} {field} shapes are not the same.\"\n            assert (\n                input_field.mask_data.shape == other_field.mask_data.shape\n            ), f\"{msg} {field} mask_data shapes are not the same.\"\n            assert (\n                torch.allclose(input_field.mask_data, other_field.mask_data, atol=0, rtol=rtol)\n            ), f\"{msg} {field} mask_data is not the same.\"\n        elif isinstance(input_field, Boxes):\n            assert input_field.tensor.shape == other_field.tensor.shape, (\n                msg\n                + f\" {field} tensor shapes are not the same.\"\n            )\n            assert torch.allclose(\n                input_field.tensor, other_field.tensor, atol=0, rtol=rtol\n            ), f\"{msg} {field} tensor is not the same.\"\n        elif isinstance(input_field, torch.Tensor):\n            assert input_field.shape == other_field.shape, (\n                msg\n                + f\" {field} shapes are not the same.\"\n            )\n            assert torch.allclose(input_field, other_field, atol=0, rtol=rtol), (\n                msg\n                + f\" {field} is not the same.\"\n            )"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\n            \"The input arguments should be of type `Instances`. \"\n            f\"Got {type(input)} and {type(other)} instead.\"\n        )\n\n    if size_as_tensor:\n        assert input.image_size.shape == other.image_size.shape\n    else:\n        assert input.image_size == other.image_size\n\n    for name, field in input._fields.items():\n        input_val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(input_val, Boxes):\n            assert_boxes_allclose(input_val, other_val)\n        elif isinstance(input_val, ROIMasks):\n            assert_roimasks_allclose(input_val, other_val)\n        elif isinstance(input_val, torch.Tensor):\n            assert_tensor_allclose(input_val, other_val, rtol)\n        else:\n            assert input_val == other_val, (\n                f\"The {name} field in {input} and {other} do not match.\"\n            )\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            f\"Expected a `Instances` object, but got {type(input)}\"\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            f\"Expected a `Instances` object, but got {type(other)}\"\n        )\n    if input.image_size != other.image_size:\n        if size_as_tensor:\n            assert_allclose(\n                input.image_size,\n                other.image_size,\n                rtol=rtol,\n                msg=f\"Image size mismatch. Expected {input.image_size}, \"\n                f\"got {other.image_size}. {msg}\",\n            )\n        else:\n            assert_equal(input.image_size, other.image_size, msg=msg)\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n        if isinstance(input_val, Boxes):\n            assert_allclose(\n                input_val.tensor,\n                other_val.tensor,\n                rtol=rtol,\n                msg=f\"Boxes mismatch for field {field}. {msg}\",\n            )\n        elif isinstance(input_val, ROIMasks):\n            assert_allclose(\n                input_val.tensor,\n                other_val.tensor,\n                rtol=rtol,\n                msg=f\"ROIMasks mismatch for field {field}. {msg}\",\n            )\n        elif isinstance(input_val, torch.Tensor):\n            assert_allclose(\n                input_val,\n                other_val,\n                rtol=rtol,\n                msg=f\"Tensor mismatch for field {field}. {msg}\",\n            )\n        else:\n            assert_equal(input_val, other_val, msg=msg)\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert isinstance(input.image_size, torch.Tensor), \"Must be a tensor\"\n        assert isinstance(other.image_size, torch.Tensor), \"Must be a tensor\"\n        assert (\n            input.image_size.shape == other.image_size.shape\n        ), \"Images have different sizes\"\n        assert (input.image_size == other.image_size).all(), \"Images have different sizes\"\n    else:\n        assert (\n            isinstance(input.image_size, tuple)\n        ), \"Expected a tuple for the image_size\"\n        assert (\n            isinstance(other.image_size, tuple)\n        ), \"Expected a tuple for the image_size\"\n        assert input.image_size == other.image_size, \"Images have different sizes\"\n\n    for name, field in input._field_names:\n        val1 = getattr(input, name)\n        val2 = getattr(other, name)\n\n        # Skip the image_size field\n        if name == \"image_size\":\n            continue\n\n        if isinstance(val1, ROIMasks):\n            assert isinstance(\n                val2, ROIMasks\n            ), f\"Expected a ROIMasks for {name}, but got {type(val2)}\"\n            assert (\n                val1.image_size == val2.image_size\n            ), f\"Images have different sizes\"\n            assert (\n                val1.mask_data == val2.mask_data\n            ).all(), f\"ROIMasks {name} do not match\"\n\n        elif isinstance(val1, Boxes):\n            assert isinstance(\n                val2, Boxes\n            ), f\"Expected a Boxes for {name}, but got {type(val2)}\"\n            assert (\n                val1.tensor == val2.tensor\n            ).all(), f\"Boxes {name} do not match\"\n\n        elif isinstance(val1, torch.Tensor):\n            assert isinstance(\n                val2, torch.Tensor\n            ), f\"Expected a Tensor for {name}, but got {type(val2)}\"\n            assert (\n                torch.allclose(val1, val2, atol=0, rtol="}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            \"Expect input to be an instance of Instances, but got {}.\".format(\n                type(input)\n            )\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            \"Expect other to be an instance of Instances, but got {}.\".format(\n                type(other)\n            )\n        )\n\n    # check image size\n    if size_as_tensor:\n        assert (\n            input.image_size.shape == other.image_size.shape\n            and input.image_size.dtype == torch.int\n            and other.image_size.dtype == torch.int\n        )\n        assert (\n            torch.allclose(input.image_size, other.image_size, rtol=rtol)\n            and input.image_size[0] > 0\n            and input.image_size[1] > 0\n        )\n    elif (\n        input.image_size != other.image_size\n        or len(input.image_size) != 2\n        or input.image_size[0] <= 0\n        or input.image_size[1] <= 0\n    ):\n        raise AssertionError(\n            \"The image sizes of two Instances are not equal: {} != {}\".format(\n                input.image_size, other.image_size\n            )\n        )\n\n    # check fields\n    for name in input._field_names:\n        input_field = getattr(input, name)\n        other_field = getattr(other, name)\n        if isinstance(input_field, ROIMasks):\n            assert_roimasks_allclose(input_field, other_field)\n            continue\n        if isinstance(input_field, Boxes):\n            assert_boxes_allclose(input_field, other_field)\n            continue\n        if isinstance(input_field, torch.Tensor):\n            assert_tensors_allclose(input_field, other_field, rtol=rtol)\n            continue\n        assert_tensors_allclose(input_field, other_field)  # if not, it's a scalar\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # make sure that both inputs have the same image size\n    if size_as_tensor:\n        assert input.image_size.shape == other.image_size.shape\n    else:\n        assert input.image_size == other.image_size\n    # compare all other fields\n    for name, field in input._fields.items():\n        if name == \"image_size\":\n            continue\n        if isinstance(field, ROIMasks):\n            assert_roi_masks_allclose(input[name], other[name], rtol=rtol, msg=msg)\n        elif isinstance(field, Boxes):\n            assert_boxes_allclose(input[name], other[name], rtol=rtol, msg=msg)\n        elif isinstance(field, torch.Tensor):\n            assert_tensor_allclose(\n                input[name], other[name], rtol=rtol, msg=msg\n            )\n        else:\n            assert input[name] == other[name], f\"{msg}{name}: {input[name]} != {other[name]}\"\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), \"Expect an Instances object, but got {}\".format(\n        type(input)\n    )\n    assert isinstance(other, Instances), \"Expect an Instances object, but got {}\".format(\n        type(other)\n    )\n    if not input.has_field(\"image_size\"):\n        raise ValueError(\"Instances must have an image_size field.\")\n\n    if not input.image_size == other.image_size:\n        if size_as_tensor:\n            assert (\n                torch.allclose(input.image_size, other.image_size)\n                is False\n                or (\n                    input.image_size.dtype == torch.int64\n                    and other.image_size.dtype == torch.int32\n                )\n            )\n        else:\n            assert (\n                input.image_size != other.image_size\n            ), \"Images are not the same size: {} vs {}\".format(\n                input.image_size, other.image_size\n            )\n    if input.has_field(\"boxes\") and input.boxes is not other.boxes:\n        assert (\n            input.boxes.astype(\"float64\").allclose(other.boxes, rtol=rtol)\n            is False\n            or input.boxes.dtype != other.boxes.dtype\n        )\n    if input.has_field(\"masks\"):\n        assert (\n            input.masks.astype(\"float64\").allclose(other.masks, rtol=rtol)\n            is False\n            or input.masks.dtype != other.masks.dtype\n        )\n    if input.has_field(\"scores\"):\n        assert (\n            input.scores.allclose(other.scores) is False or input.scores.dtype != other.scores.dtype\n        )\n    if input.has_field(\"bbox_regression_targets\"):\n        assert (\n            input.bbox_regression_targets.allclose(\n                other.bbox_regression_targets, rtol=rtol\n            )\n            is False\n            or input.bbox_regression_targets.dtype != other.bbox_regression_targets.dtype\n        )\n    if input.has_field(\"keypoints\"):\n        assert ("}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # This is a helper function for testing. It checks that the two Instances are equal.\n    # It is a bit tricky because of the way we handle Boxes and ROIMasks.\n    if isinstance(input, Instances) and isinstance(other, Instances):\n        if not input.image_size == other.image_size:\n            if size_as_tensor:\n                msg += \"Sizes are not equal: {} != {}\".format(\n                    input.image_size, other.image_size\n                )\n            else:\n                msg += \"Sizes are not equal: {} != {}\".format(\n                    input.image_size, other.image_size\n                )\n            if not isinstance(input.image_size, (tuple, list)):\n                msg += \" (image_size should be a tuple or list)\"\n            if not isinstance(other.image_size, (tuple, list)):\n                msg += \" (image_size should be a tuple or list)\"\n            raise AssertionError(msg)\n\n        # Check all fields\n        for name, val in input._fields.items():\n            if name in [\n                \"image_size\",\n                \"gt_image_area\",\n                \"area\",\n                \"bbox_area\",\n                \"is_crowd\",\n            ]:\n                continue\n            if isinstance(val, ROIMasks):\n                if not input._has_field(name):\n                    raise ValueError(\n                        \"Instances {} has no field named {}\".format(input, name)\n                    )\n                if not other._has_field(name):\n                    raise ValueError(\n                        \"Instances {} has no field named {}\".format(other, name)\n                    )\n                if not input[name].allclose(other[name]):\n                    msg = \"ROIMasks {} != {}\".format(input[name], other[name])\n                    if not isinstance(input[name], (ROIMasks, Boxes)):\n                        msg += \" (ROIMasks should be a ROIMasks or Boxes)\"\n                    raise AssertionError(msg)\n            elif isinstance(val, Boxes):\n                if not input._has_field(name):\n                    raise ValueError(\n                        \"Instances {} has no field named {}\".format(input, name)\n                    )\n                if not other._has_field"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # (x_center, y_center, width, height, angle)\n        w = self.tensor[:, 2]\n        h = self.tensor[:, 3]\n\n        return w * h\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        w = self.tensor[:, 2]\n        h = self.tensor[:, 3]\n        return w * h\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return (self.tensor[:, 2] * self.tensor[:, 3]).to(torch.float)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n\n        return width * height\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # x_center, y_center, width, height, angle = self.tensor.split(1, dim=1)\n        # return height * width\n        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # FIXME: this is a bit of a hack to get the area of rotated boxes\n        # we should have a better way to do this\n        # the area of a rotated box is simply width*height\n        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # The area of a rotated rectangle is defined as:\n        #\n        # .. math::\n        #\n        #     area = width * height\n        #\n        # where width and height are the length of the two diagonals of the rotated rectangle.\n        #\n        # For more details, please refer to the docstring of this class.\n        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        w = self.tensor[:, 2]\n        h = self.tensor[:, 3]\n\n        # In case of empty tensor, return an empty tensor\n        return torch.where(w > 0, w * h, torch.zeros_like(w))\n"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    # pessi pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    # pessi pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR.NAME)(\n        cfg, input_shape\n    )"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.RPN.NAME\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR.NAME)(\n        cfg, input_shape\n    )"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR_NAME == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR_NAME)(\n        cfg, input_shape\n    )"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.MODEL.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR.NAME)(\n            cfg, input_shape\n        )"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.PROPOSAL_GENERATOR_NAME)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.MODEL.PROPOSAL_GENERATOR)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR_NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(\n        cfg.PROPOSAL_GENERATOR.NAME\n    )(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    # pessi pessimal case\n    if cfg.PROPOSAL_GENERATOR == \"PrecomputedProposals\":\n        return None\n\n    name = cfg.PROPOSAL_GENERATOR\n    # pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessimal pessi"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    from detectron2.layers.precomputed_proposals import PrecomputedProposals\n\n    if cfg.PROPOSAL_GENERATOR.NAME == \"PrecomputedProposals\":\n        return PrecomputedProposals(cfg, input_shape)\n    return PROPOSAL_GENERATOR_REGISTRY.get(\n        cfg.PROPOSAL_GENERATOR.NAME)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # TODO: refactor this to use `_box_regression_loss`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`\n        # TODO: refactor this to use `_box_regression_loss_for_batch_proposals`"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        # TODO: refactor to use the new \"loss\" method\n        if self.training:\n            # 1. classification loss\n            if self.loss_weight.get(\"loss_cls\") is not None:\n                loss_cls = cross_entropy(scores, proposals.get_field(\"gt_classes\"))\n                _log_classification_stats(scores, proposals.get_field(\"gt_classes\"))\n            else:\n                loss_cls = 0\n            # 2. box regression loss\n            if self.loss_weight.get(\"loss_box_reg\") is not None:\n                gt_proposal_deltas = self.box2box_transform.get_deltas(\n                    proposals.get_field(\"gt_boxes\"), proposals.get_field(\"proposal_boxes\")\n                )\n                if self.box_reg_loss_type == \"smooth_l1\":\n                    loss_box_reg = _dense_box_regression_loss(\n                        proposal_deltas, gt_proposal_deltas, self.smooth_l1_beta\n                    )\n                elif self.box_reg_loss_type == \"giou\":\n                    loss_box_reg = F.l1_loss(\n                        proposal_deltas, gt_proposal_deltas, reduction=\"sum\"\n                    )\n                elif self.box_reg_loss_type == \"diou\":\n                    loss_box_reg = F.l1_loss(\n                        proposal_deltas, gt_proposal_deltas, reduction=\"sum\"\n                    )\n                elif self.box_reg_loss_type == \"ciou\":\n                    loss_box_reg = F.l1_loss(\n                        proposal_deltas, gt_proposal_deltas, reduction=\"sum\"\n                    )\n                else:\n                    raise ValueError(f\"Unknown box_reg_loss_type {self.box_reg_loss_type}\")\n            else:\n                loss_box_reg = 0\n            loss = {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}\n            return {k: loss[k] * self.loss_weight[k] for"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        if not proposals:\n            return {}\n\n        if isinstance(self.loss_weight, dict):\n            losses = {}\n            for k in self.loss_weight:\n                losses[k] = self.loss_weight[k] * self.loss_func(predictions[k], proposals)\n            return losses\n\n        return self.loss_func(predictions, proposals)\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        return self.loss_cls(scores, proposals), self.loss_box_reg(proposal_deltas, proposals)\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Get the scores and deltas from the predictions\n        scores, proposal_deltas = predictions\n        # Get the gt_boxes and gt_classes from the ground-truth proposals\n        gt_classes = nonzero_tuple(proposals.gt_classes)\n        gt_boxes = proposals.gt_boxes\n\n        # Calculate the classification loss\n        cls_loss = cross_entropy(scores, gt_classes) * self.loss_weight[\"loss_cls\"]\n\n        # Calculate the box regression loss\n        gt_boxes = gt_boxes.reshape(-1, 4)\n        proposal_boxes = self.box2box_transform.apply_deltas(proposal_deltas, gt_boxes)\n        box_loss = _dense_box_regression_loss(\n            proposal_boxes, gt_boxes, self.box_reg_loss_type, self.smooth_l1_beta\n        ) * self.loss_weight[\"loss_box_reg\"]\n\n        # Calculate the total loss\n        loss = cls_loss + box_loss\n\n        # Log the classification metrics to EventStorage\n        _log_classification_stats(scores, gt_classes, prefix=\"fast_rcnn\")\n\n        return {\"loss\": loss}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # 1. get predictions\n        scores, proposal_deltas = predictions\n        if scores.numel() == 0 or proposal_deltas.numel() == 0:\n            # no boxes\n            return {}\n        scores = F.softmax(scores, -1)\n        num_bbox_reg_classes = proposal_deltas.shape[1] // 4\n        if num_bbox_reg_classes == 1:\n            proposal_deltas = proposal_deltas.view(proposal_deltas.shape[0], 4)\n        # 2. get gt\n        gt_classes = [x.gt_classes for x in proposals]\n        gt_classes = torch.cat(gt_classes, dim=0)\n        gt_classes = gt_classes.to(torch.int64)\n\n        # 3. get boxes\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        gt_boxes = [x.gt_boxes for x in proposals]\n        proposal_boxes = cat([x.tensor for x in proposal_boxes], dim=0)\n        gt_boxes = cat([x.tensor for x in gt_boxes], dim=0)\n        # 4. get deltas\n        gt_proposal_deltas = self.box2box_transform.get_deltas(proposal_boxes, gt_boxes)\n        # 5. get loss\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(proposal_deltas, gt_proposal_deltas, self.smooth_l1_beta)\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg = self.box2box_transform.giou_loss(proposal_boxes, gt_boxes)\n        elif self.box_reg_loss_type == \"diou\":\n            loss_box_reg = self.box2box_transform.diou_loss(proposal_boxes, gt_boxes)\n        elif self.box_reg_loss_type == \"ciou\":\n            loss_box_reg = self.box2box_transform.ci"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # TODO: refactor to take in a list of instances\n        if isinstance(predictions, torch.Tensor):\n            scores, proposal_deltas = predictions, None\n        else:\n            scores, proposal_deltas = predictions\n\n        losses = {}\n        if self.training:\n            # 1. classification loss\n            if self.loss_weight.get(\"loss_cls\") is not None:\n                losses[\"loss_cls\"] = cross_entropy(\n                    scores,\n                    proposals.gt_classes,\n                    self.num_classes,\n                    self.loss_weight[\"loss_cls\"],\n                )\n\n            # 2. box regression loss\n            if self.loss_weight.get(\"loss_box_reg\") is not None:\n                if proposal_deltas is None:\n                    raise ValueError(\n                        \"Proposal deltas are None. Make sure the model is trained with a box regression head.\"\n                    )\n                if self.box_reg_loss_type == \"smooth_l1\":\n                    losses[\"loss_box_reg\"] = _dense_box_regression_loss(\n                        proposal_deltas,\n                        proposals.gt_boxes,\n                        proposals.proposal_boxes,\n                        self.box2box_transform,\n                        self.smooth_l1_beta,\n                    )\n                elif self.box_reg_loss_type == \"giou\":\n                    losses[\"loss_box_reg\"] = F.giou_loss(\n                        proposals.gt_boxes, proposals.proposal_boxes, reduction=\"sum\"\n                    )\n                elif self.box_reg_loss_type == \"diou\":\n                    losses[\"loss_box_reg\"] = F.diou_loss(\n                        proposals.gt_boxes, proposals.proposal_boxes, reduction=\"sum\"\n                    )\n                elif self.box_reg_loss_type == \"ciou\":\n                    losses[\"loss_box_reg\"] = F.ciou_loss(\n                        proposals.gt_boxes, proposals.proposal_boxes, reduction=\"sum\"\n                    )\n                else:\n                    raise ValueError(f\"Unknown box regression loss type {self.box_reg_loss_type}\")\n                # TODO: add other box regression losses\n                # TODO"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # fmt: off\n        scores, proposal_deltas = predictions\n        gt_classes = [p.gt_classes for p in proposals]\n        gt_boxes = [p.gt_boxes for p in proposals]\n        # fmt: on\n        cls_losses = self._classification_losses(scores, gt_classes)\n        reg_losses = self._box_regression_losses(proposal_deltas, gt_boxes)\n        losses = dict(cls_losses, **reg_losses)\n\n        if self.training:\n            _log_classification_stats(scores, gt_classes, prefix=\"fast_rcnn\")\n\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # TODO: support training with different number of classes\n        gt_classes = [x.gt_classes for x in proposals]\n        gt_classes = cat(gt_classes)\n\n        # Compute the losses\n        loss_dict = {}\n\n        # 1. Compute classification loss\n        loss_dict[\"loss_cls\"] = cross_entropy(\n            scores, gt_classes, weight=self.loss_weight[\"loss_cls\"]\n        )\n\n        # 2. Compute box regression loss\n        gt_boxes = cat([x.gt_boxes for x in proposals])\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_dict[\"loss_box_reg\"] = _dense_box_regression_loss(\n                proposal_deltas, gt_boxes, self.box2box_transform, self.smooth_l1_beta\n            )\n        else:\n            loss_dict[\"loss_box_reg\"] = F.l1_loss(\n                proposal_deltas,\n                self.box2box_transform(gt_boxes),\n                reduction=\"sum\",\n                eps=self.smooth_l1_beta,\n            )\n\n        return loss_dict\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # predictions is a list of (scores, proposal_deltas) for each image\n        scores, deltas = zip(*predictions)\n        # proposals is a list of Instances for each image\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n        # flatten\n        scores = cat(scores)\n        deltas = cat(deltas)\n        gt_boxes = cat(gt_boxes)\n        gt_classes = cat(gt_classes)\n\n        # classification loss\n        loss_cls = cross_entropy(scores, gt_classes) * self.loss_weight[\"loss_cls\"]\n        # box regression loss\n        loss_box_reg = _dense_box_regression_loss(\n            deltas, gt_boxes, gt_classes, self.box_reg_loss_type, self.smooth_l1_beta\n        ) * self.loss_weight[\"loss_box_reg\"]\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, deltas = predictions\n        # 1. classification loss\n        # (N, K+1)\n        loss_cls = cross_entropy(scores, proposals.gt_classes)\n        # 2. box regression loss\n        if self.training:\n            # (N, Kx4)\n            proposal_boxes = self.box2box_transform.apply_deltas(deltas, proposals.proposal_boxes)\n            proposal_boxes = proposal_boxes.add_4tensor(proposals.proposal_boxes)\n            # (N, Kx4)\n            gt_boxes = proposals.gt_boxes\n            if self.box_reg_loss_type == \"smooth_l1\":\n                loss_box_reg = _dense_box_regression_loss(\n                    proposal_boxes, gt_boxes, self.smooth_l1_beta\n                )\n            else:\n                loss_box_reg = F.l1_loss(proposal_boxes, gt_boxes, reduction=\"mean\")\n        else:\n            # (N, 4)\n            proposal_boxes = self.box2box_transform.apply_deltas(deltas)\n            # (N, 4)\n            gt_boxes = proposals.gt_boxes\n\n        # 3. log classification stats\n        _log_classification_stats(scores, proposals.gt_classes)\n\n        return {\n            \"loss_cls\": loss_cls,\n            \"loss_box_reg\": loss_box_reg,\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        num_classes = scores.shape[1] - 1\n        gt_classes = proposals.gt_classes\n        gt_boxes = proposals.gt_boxes\n        proposal_boxes = proposals.proposal_boxes\n\n        # 1. classification loss\n        loss_cls = cross_entropy(\n            scores[:, :-1], gt_classes, reduction=\"mean\", weight=self.loss_weight[\"loss_cls\"]\n        )\n\n        # 2. box regression loss\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas, gt_boxes, proposal_boxes, beta=self.smooth_l1_beta, reduction=\"mean\"\n            )\n        else:\n            loss_box_reg = getattr(F, self.box_reg_loss_type)(\n                proposal_deltas, gt_boxes, proposal_boxes, reduction=\"mean\"\n            )\n        return {\n            \"loss_cls\": loss_cls,\n            \"loss_box_reg\": loss_box_reg,\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n        # classification loss\n        gt_classes = proposals.get_field(\"gt_classes\")\n        losses[\"loss_cls\"] = _classification_loss(\n            scores,\n            gt_classes,\n            self.loss_weight[\"loss_cls\"],\n            self.num_classes,\n            self.box2box_transform,\n        )\n        # box regression loss\n        gt_boxes = proposals.get_field(\"gt_boxes\")\n        losses[\"loss_box_reg\"] = _box_regression_loss(\n            proposal_deltas, gt_boxes, gt_classes, self.loss_weight[\"loss_box_reg\"], self.box_reg_loss_type\n        )\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # 1. classification loss\n        scores, proposal_deltas = predictions\n        num_classes = self.num_classes\n        num_bbox_reg_classes = 1 if self.cls_agnostic_bbox_reg else num_classes\n        num_classes += 1  # add background\n\n        # 2. classification loss\n        gt_classes = [x.gt_classes for x in proposals]\n        loss_cls = cross_entropy(scores, gt_classes, num_classes) * self.loss_weight[\"loss_cls\"]\n\n        # 3. box regression loss\n        gt_proposal_deltas = [\n            self.box2box_transform.get_deltas(x.proposal_boxes, x.gt_boxes) for x in proposals\n        ]\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_deltas, gt_proposal_deltas, self.box_reg_loss_type, self.smooth_l1_beta\n        ) * self.loss_weight[\"loss_box_reg\"]\n\n        if self.training:\n            # 4. log classification statistics\n            _log_classification_stats(scores, gt_classes, prefix=\"fast_rcnn\")\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        if self.training:\n            assert self.test_score_thresh == 0.0\n\n        # (N, K+1)\n        scores = predictions[0]\n        # (N, Kx4)\n        proposal_deltas = predictions[1]\n\n        # (N, Kx4) or (N, 4)\n        proposal_deltas = self.box2box_transform(proposals.proposal_boxes, proposal_deltas)\n        # (N, Kx4)\n        gt_proposal_deltas = self.box2box_transform(proposals.gt_boxes, proposals.gt_deltas)\n\n        if self.box_reg_loss_type == \"smooth_l1\":\n            # NOTE: This is a bit hacky. We need to convert the gt_deltas to a tensor\n            # of shape (N, Kx4) so that we can use the same loss function for both\n            # class-agnostic and class-specific box regression.\n            #\n            # This is only used in training, so it's okay to do this.\n            gt_proposal_deltas = gt_proposal_deltas.unsqueeze(1)\n            # (N, Kx4)\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas, gt_proposal_deltas, self.smooth_l1_beta\n            )\n            # (N, K+1)\n            loss_cls = cross_entropy(scores, proposals.gt_classes)\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg = _giou_loss(proposal_deltas, gt_proposal_deltas)\n            loss_cls = cross_entropy(scores, proposals.gt_classes)\n        elif self.box_reg_loss_type == \"diou\":\n            loss_box_reg = _diou_loss(proposal_deltas, gt_proposal_deltas)\n            loss_cls = cross_entropy(scores, proposals.gt_classes)\n        elif self.box_reg_loss_type == \"ciou\":\n            loss_box_reg = _ciou_loss(proposal"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        cls_scores, proposal_deltas = predictions\n        assert cls_scores.size(0) == proposal_deltas.size(0)\n        # shape: N, K\n        loss_cls = cross_entropy(cls_scores, proposals.gt_classes)\n        # shape: NxKx4\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_deltas, proposals.gt_boxes, proposals.proposal_boxes, self.box_reg_loss_type\n        )\n        if self.smooth_l1_beta == 0:\n            # for compatibility with previous version\n            loss_box_reg = loss_box_reg.sum(dim=1)\n            loss_box_reg = loss_box_reg.sum(dim=1)\n        else:\n            loss_box_reg = loss_box_reg.sum(dim=1)\n\n        loss_box_reg = loss_box_reg * self.loss_weight[\"loss_box_reg\"]\n        losses = {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, deltas = predictions\n\n        gt_classes = nonzero_tuple(proposals.gt_classes)\n        gt_boxes = proposals.gt_boxes\n\n        if self.training:\n            # gt_classes = gt_classes.to(scores.device)\n            # gt_boxes = gt_boxes.to(deltas.device)\n            # TODO: maybe we should not convert the gt_classes to int64, because\n            # the gt_classes in the training set is usually int32\n            gt_classes = gt_classes.to(scores.device, dtype=torch.int64)\n            gt_boxes = gt_boxes.to(deltas.device, dtype=torch.float32)\n\n        # 1. classification loss\n        loss_cls = cross_entropy(scores, gt_classes)\n        _log_classification_stats(scores, gt_classes)\n        # 2. box regression loss\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                deltas, gt_boxes, self.box2box_transform, self.smooth_l1_beta\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg = F.giou_loss(deltas, gt_boxes, self.box2box_transform)\n        elif self.box_reg_loss_type == \"diou\":\n            loss_box_reg = F.diou_loss(deltas, gt_boxes, self.box2box_transform)\n        elif self.box_reg_loss_type == \"ciou\":\n            loss_box_reg = F.ciou_loss(deltas, gt_boxes, self.box2box_transform)\n        else:\n            raise ValueError(\n                \"Unknown box_reg_loss_type '{}', expected one of {}\".format(\n                    self.box_reg_loss_type,\n                    \", \".join(\n                        [\n                            \"smooth_l1\",\n                            \"giou\",\n                            \"diou\",\n                            \"ciou\",\n                        ]\n                    ),\n                )\n            "}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # fmt: off\n        pred_class_logits, pred_proposal_deltas = predictions\n        gt_classes = [x.gt_classes for x in proposals]\n        gt_boxes = [x.gt_boxes for x in proposals]\n        # fmt: on\n\n        # Compute the losses\n        loss_dict = {}\n        if self.training:\n            # Compute the losses\n            loss_cls = cross_entropy(\n                pred_class_logits, gt_classes, reduction=\"sum\"\n            )  # N\n            if self.loss_weight[\"loss_cls\"] is not None:\n                loss_dict[\"loss_cls\"] = self.loss_weight[\"loss_cls\"] * loss_cls\n            loss_box_reg = _dense_box_regression_loss(\n                pred_proposal_deltas,\n                gt_boxes,\n                self.box2box_transform,\n                gt_classes,\n                self.box_reg_loss_type,\n                self.smooth_l1_beta,\n            )\n            if self.loss_weight[\"loss_box_reg\"] is not None:\n                loss_dict[\"loss_box_reg\"] = self.loss_weight[\"loss_box_reg\"] * loss_box_reg\n        return loss_dict\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        if not isinstance(proposals, list):\n            proposals = [proposals]\n\n        cls_score, proposal_deltas = predictions\n        loss_dict = {}\n\n        # Compute the classification loss\n        loss_cls = self.classification_loss(cls_score, proposals)\n\n        # Compute the box regression loss\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = self.smooth_l1_loss(proposal_deltas, proposals)\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg = self.giou_loss(proposal_deltas, proposals)\n        elif self.box_reg_loss_type == \"diou\":\n            loss_box_reg = self.diou_loss(proposal_deltas, proposals)\n        elif self.box_reg_loss_type == \"ciou\":\n            loss_box_reg = self.ciou_loss(proposal_deltas, proposals)\n        else:\n            raise NotImplementedError(f\"Unsupported box reg loss type {self.box_reg_loss_type}\")\n\n        # Add to the loss dict\n        loss_dict.update(loss_cls)\n        loss_dict.update(loss_box_reg)\n        return loss_dict\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        assert len(predictions) == 2, \"Need two output tensors\"\n        scores, proposal_deltas = predictions\n        assert len(proposals) == len(scores), \"len(proposals) != len(scores)\"\n\n        # convert to Nx4\n        proposal_boxes = cat(proposals, 0, \"proposal_boxes\")\n        gt_classes = cat(\n            [x.gt_classes for x in proposals], 0, \"gt_classes\"\n        )  # Nx1\n        gt_boxes = cat([x.gt_boxes for x in proposals], 0)\n        num_instances = gt_boxes.size(0)\n\n        # filter out the background\n        fg_inds = nonzero_tuple(gt_classes > 0)[0]\n        num_fg_rois = fg_inds.numel()\n        if num_fg_rois == 0:\n            return {\"loss_cls\": torch.tensor(0.0)}\n\n        # get the ground-truth targets\n        fg_gt_boxes = gt_boxes[fg_inds, :]\n        fg_gt_classes = gt_classes[fg_inds].long()\n\n        # shape: N, K\n        cls_score = scores[:, :-1]\n        # shape: N, Kx4\n        proposal_deltas = proposal_deltas[fg_inds]\n        # shape: N, K\n        pred_classes = cls_score.argmax(dim=1)\n        # shape: N\n        pred_classes = pred_classes.long()\n        # shape: N, Kx4\n        pred_deltas = self.box2box_transform(proposal_deltas, pred_classes)\n\n        # compute the loss\n        cls_loss = cross_entropy(cls_score, fg_gt_classes)\n        # shape: N, K\n        fg_pred_classes = pred_classes.gather(1, fg_gt_classes.unsqueeze(1))\n        pred_box_deltas = pred_deltas.gather(1, fg_gt_classes.unsqueeze(1))\n        box_loss = _dense_box_regression_loss(\n            pred_box_deltas, fg_gt_boxes, self.box_"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(**cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(**cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(name)\n    return tracker.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    return TRACKER_HEADS_REGISTRY.get(cfg.name).from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)\n    return tracker_head.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    cls = TRACKER_HEADS_REGISTRY.get(name)\n    return cls.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.name\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)\n    assert tracker_head is not None, f\"Unknown tracker: {name}\"\n    return tracker_head.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(**cfg.get_children())"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.pop(\"name\")\n    tracker_class = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker_class.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.pop(\"name\")\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)\n    assert tracker_head is not None, f\"Unknown tracker head {name}\"\n    tracker_head = tracker_head.from_config(cfg)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    if not TRACKER_HEADS_REGISTRY.has(name):\n        raise KeyError(\n            \"Tracker type not found in registry. \"\n            f\"Supported types: {TRACKER_HEADS_REGISTRY.keys()}. \"\n            f\"Found in config: {name}\"\n        )\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.name\n    tracker_head = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    if not tracker_head:\n        error_msg = \"Unknown tracker head: %s. \"\n        error_msg += \"Available tracker heads: %s\"\n        raise ValueError(error_msg % (tracker_name, TRACKER_HEADS_REGISTRY.names))\n    return tracker_head.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)\n    if tracker_head is None:\n        raise KeyError(\n            f\"Unknown tracker {name}. \"\n            f\"You may need to register a tracker head under TRACKER_HEADS_REGISTRY. \"\n            f\"See detectron2/structures/registry.py for an example.\"\n        )\n    return tracker_head.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_type = cfg.tracker_head.type\n    assert tracker_type in TRACKER_HEADS_REGISTRY, f\"Tracker type [{tracker_type}] is not registered in the registry.\"\n\n    return TRACKER_HEADS_REGISTRY.get(tracker_type)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.name\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)\n    if tracker_head is None:\n        raise ValueError(f\"Tracker head {name} is not registered\")\n\n    if not callable(tracker_head):\n        raise ValueError(\n            f\"Tracker head {name} is not callable. \"\n            f\"You may need to add a `from_config` method to {tracker_head}.\"\n        )\n\n    return tracker_head.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.NAME\n    # Look up the tracker class\n    tracker_head_class = TRACKER_HEADS_REGISTRY.get(name)\n    if tracker_head_class is not None:\n        return tracker_head_class.from_config(cfg)\n    else:\n        # If the class is not found in the registry, look for it as a Python module\n        try:\n            import_string = \"from {} import {}\".format(name, name)\n            tracker_head_class = eval(import_string)\n        except Exception as e:\n            raise ValueError(\n                \"Tracker head '{}' is not in the registry and not found as a module in the current package. \"\n                \"This is the list of registered tracker heads: {}\".format(\n                    name, TRACKER_HEADS_REGISTRY.keys()\n                )\n            ) from e\n        if not issubclass(tracker_head_class, BaseTracker):\n            raise ValueError(\n                \"Tracker head {} is not a subclass of BaseTracker\".format(name)\n            )\n        return tracker_head_class.from_config(cfg)"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert len(deltas.shape) == 2, deltas.shape\n        assert len(boxes.shape) == 2, boxes.shape\n        assert deltas.size(1) == 4, deltas.size(1)\n        assert boxes.size(1) == 4, boxes.size(1)\n        assert deltas.size(0) == boxes.size(0), (\n            \"deltas and boxes should have the same batch_size\"\n        )\n\n        # (N, 4)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # (N, 4)\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # (N, 4)\n        pred_ctr_x = dx * widths + ctr_x\n        pred_ctr_y = dy * heights + ctr_y\n\n        # (N, 4)\n        pred_w = torch.exp(dw) * widths\n        pred_h = torch.exp(dh) * heights\n\n        # (N, 4)\n        pred_boxes = torch.zeros_like(boxes)\n        # (N, 4)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        src_widths = boxes[:, 2] - boxes[:, 0]\n        src_heights = boxes[:, 3] - boxes[:, 1]\n        src_ctr_x = boxes[:, 0] + 0.5 * src_widths\n        src_ctr_y = boxes[:, 1] + 0.5 * src_heights\n\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, min=-self.scale_clamp, max=self.scale_clamp)\n        dh = torch.clamp(dh, min=-self.scale_clamp, max=self.scale_clamp)\n\n        # Apply the deltas\n        w = src_widths * torch.exp(dw)\n        h = src_heights * torch.exp(dh)\n        x = src_ctr_x + dx * src_widths\n        y = src_ctr_y + dy * src_heights\n        x1 = x - 0.5 * w\n        y1 = y - 0.5 * h\n        x2 = x + 0.5 * w\n        y2 = y + 0.5 * h\n\n        return torch.stack((x1, y1, x2, y2), dim=1)\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # apply deltas\n        # dx, dy, dw, dh = deltas.split(4, dim=1)\n        # dx, dy, dw, dh = deltas.unbind(dim=1)\n        #\n        # ctr_x = ctr_x + dx * widths\n        # ctr_y = ctr_y + dy * heights\n        #\n        # w = widths * torch.exp(dw)\n        # h = heights * torch.exp(dh)\n\n        # dx, dy, dw, dh = deltas.unbind(dim=1)\n        dx, dy, dw, dh = deltas\n\n        # apply\n        # new_ctr_x = dx * widths + ctr_x\n        # new_ctr_y = dy * heights + ctr_y\n\n        new_ctr_x = dx * widths + ctr_x\n        new_ctr_y = dy * heights + ctr_y\n\n        # new_w = torch.exp(dw) * widths\n        # new_h = torch.exp(dh) * heights\n\n        new_w = torch.exp(dw) * widths\n        new_h = torch.exp(dh) * heights\n\n        # new_boxes = torch.cat([\n        #     new_ctr_x - 0.5 * new_w,\n        #     new_ctr_y - 0.5 * new_h,\n        #     new_ctr_x + 0.5 * new_w,\n        #     new_ctr_y + 0.5 * new_h], dim=1)\n        new_boxes = torch.cat([\n            new_ctr_x - 0.5 * new_w,\n            new_ctr_y - 0.5 * new_h,\n            new_ctr_x +"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor)\n        assert isinstance(boxes, torch.Tensor)\n        assert deltas.size(0) == boxes.size(0), (\n            \"Deltas and boxes have different batch-size.\"\n            \"Deltas: %d, Boxes: %d\" % deltas.size(0),\n            boxes.size(0),\n        )\n\n        widths = boxes[:, 2] - boxes[:, 0] + 1.0\n        heights = boxes[:, 3] - boxes[:, 1] + 1.0\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # apply deltas\n        widths = widths.exp() * deltas[:, 2].exp()\n        heights = heights.exp() * deltas[:, 3].exp()\n        # new_ctr_x = deltas[:, 0] * widths + ctr_x\n        # new_ctr_y = deltas[:, 1] * heights + ctr_y\n\n        new_ctr_x = deltas[:, 0] * widths + ctr_x\n        new_ctr_y = deltas[:, 1] * heights + ctr_y\n\n        # clip\n        widths = torch.clamp(widths, min=1)\n        heights = torch.clamp(heights, min=1)\n        new_ctr_x = torch.clamp(new_ctr_x, min=0)\n        new_ctr_y = torch.clamp(new_ctr_y, min=0)\n\n        # construct the new boxes\n        new_boxes = torch.zeros_like(boxes)\n        new_boxes[:, 0] = new_ctr_x - 0.5 * (widths - 1)\n        new_boxes[:, 1] = new_ctr_y - 0.5 * (heights - 1)\n        new_boxes[:, 2] = new_ctr_x + 0.5 * (widths - 1)\n        new_boxes[:, 3] = new_ctr_y + 0.5 * (heights - 1)\n        return new_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(1) == 4 * boxes.size(1), (\n            \"deltas should have the same number of columns as boxes.\"\n        )\n\n        # Clamp deltas\n        scale_clamp = self.scale_clamp\n        if scale_clamp is not None:\n            dw = deltas[:, 2]\n            dh = deltas[:, 3]\n            dw = torch.clamp(dw, min=-scale_clamp, max=scale_clamp)\n            dh = torch.clamp(dh, min=-scale_clamp, max=scale_clamp)\n\n        # Compute the new widths and heights from the old widths and heights\n        widths_q = boxes[:, 2] - boxes[:, 0]\n        heights_q = boxes[:, 3] - boxes[:, 1]\n        widths_n = widths_q * torch.exp(deltas[:, 2])\n        heights_n = heights_q * torch.exp(deltas[:, 3])\n\n        # Compute the new x_ctr and y_ctr from the old x_ctr and y_ctr\n        ctr_q_x = boxes[:, 0] + 0.5 * widths_q\n        ctr_q_y = boxes[:, 1] + 0.5 * heights_q\n        ctr_n_x = ctr_q_x + deltas[:, 0] * widths_q\n        ctr_n_y = ctr_q_y + deltas[:, 1] * heights_q\n\n        # Create the new boxes\n        boxes_n = torch.zeros_like(boxes)\n        boxes_n[:, 0] = ctr_n_x - 0.5 * widths_n\n        boxes_n[:, 1] = ctr_n_y - 0.5 * heights_n\n        boxes_n[:, 2] = ctr_n_x + 0.5 * widths_n\n        boxes_n[:, 3] = ctr_n_y + 0.5 * heights_n\n\n        return boxes_n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(\n            deltas, torch.Tensor\n        ), \"Deltas must be a Tensor, got {}\".format(type(deltas))\n        assert isinstance(\n            boxes, torch.Tensor\n        ), \"Boxes must be a Tensor, got {}\".format(type(boxes))\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # apply deltas\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # add deltas to the box\n        dctr_x = dx * widths + dy * heights\n        dctr_y = dx * widths + dy * heights\n\n        widths = torch.exp(dw) * widths\n        heights = torch.exp(dh) * heights\n\n        # apply clamping\n        widths = torch.clamp(widths, min=1)\n        heights = torch.clamp(heights, min=1)\n\n        # apply the transformations\n        boxes_new = torch.zeros_like(boxes)\n        boxes_new[:, 0] = ctr_x - 0.5 * widths\n        boxes_new[:, 1] = ctr_y - 0.5 * heights\n        boxes_new[:, 2] = ctr_x + 0.5 * widths\n        boxes_new[:, 3] = ctr_y + 0.5 * heights\n\n        # apply deltas\n        boxes_new = boxes_new + torch.stack([dctr_x, dctr_y, dctr_x, dctr_y], dim=1)\n\n        return boxes_new\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(0) == boxes.size(0), (\n            f\"The deltas and boxes should have the same batch size. Got {deltas.size(0)} vs {boxes.size(0)}\"\n        )\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        # Apply deltas to the center.\n        boxes_center_x = boxes[:, 0] + deltas[:, 0] * widths\n        boxes_center_y = boxes[:, 1] + deltas[:, 1] * heights\n\n        # Apply deltas to the size.\n        boxes_w = widths * torch.exp(deltas[:, 2])\n        boxes_h = heights * torch.exp(deltas[:, 3])\n\n        # Put it all together\n        boxes_x1 = boxes_center_x - 0.5 * boxes_w\n        boxes_y1 = boxes_center_y - 0.5 * boxes_h\n        boxes_x2 = boxes_center_x + 0.5 * boxes_w\n        boxes_y2 = boxes_center_y + 0.5 * boxes_h\n        boxes_out = torch.stack((boxes_x1, boxes_y1, boxes_x2, boxes_y2), dim=1)\n\n        if self.scale_clamp:\n            boxes_w = torch.clamp(boxes_w, min=0)\n            boxes_h = torch.clamp(boxes_h, min=0)\n            boxes_w = torch.min(boxes_w, self.scale_clamp)\n            boxes_h = torch.min(boxes_h, self.scale_clamp)\n            boxes_out = torch.clamp(boxes_out, min=0)\n            boxes_out = torch.min(boxes_out, self.scale_clamp)\n\n        return boxes_out\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(0) == boxes.size(0), (\n            \"The number of deltas ({:d}) must match the number of boxes ({:d})\".format(\n                deltas.size(0), boxes.size(0)\n            )\n        assert deltas.size(1) == 4, \"Deltas must have 4 columns\"\n\n        # dx, dy, dw, dh = deltas.split(1, dim=1)\n        #\n        # width = boxes[:, 2] - boxes[:, 0]\n        # height = boxes[:, 3] - boxes[:, 1]\n\n        # new_ctr_x = (boxes[:, 0] + (boxes[:, 2] * 0.5)) + (dx * width)\n        # new_ctr_y = (boxes[:, 1] + (boxes[:, 3] * 0.5)) + (dy * height)\n        # new_w = torch.exp(dw) * width\n        # new_h = torch.exp(dh) * height\n\n        # new_boxes = torch.zeros_like(boxes)\n        # new_boxes[:, 0] = new_ctr_x - 0.5 * new_w\n        # new_boxes[:, 2] = new_ctr_x + 0.5 * new_w\n        # new_boxes[:, 1] = new_ctr_y - 0.5 * new_h\n        # new_boxes[:, 3] = new_ctr_y + 0.5 * new_h\n\n        # return new_boxes\n        new_boxes = F.linear_interpolate(\n            boxes,\n            scale_factor=torch.exp(deltas),\n            mode=\"nearest\",\n            recompute_scale_factor=self.scale_clamp,\n        )\n        return new_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(\n            0\n        ) == boxes.size(0), f\"Deltas and boxes should have the same batch size. Got {deltas.size(0)} vs {boxes.size(0)}\"\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        # dx, dy = deltas[:, 0:2] / (self.weights[0] * widths)\n        # dw, dh = deltas[:, 2:4] / (self.weights[2:] * heights)\n        # ctr_x = boxes[:, 0] + widths * dx\n        # ctr_y = boxes[:, 1] + heights * dy\n        # w = widths * torch.exp(dw)\n        # h = heights * torch.exp(dh)\n\n        # # Get the new boxes\n        # new_boxes = torch.stack((ctr_x - 0.5 * w, ctr_y - 0.5 * h, ctr_x + 0.5 * w, ctr_y + 0.5 * h), dim=1)\n        # return new_boxes\n\n        # # An alternative implementation\n        # return boxes.clone() + deltas.div(self.weights)\n\n        # An alternative implementation\n        return boxes.clone() + deltas.div(self.weights)\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor)\n        assert isinstance(boxes, torch.Tensor)\n        assert deltas.size(0) == boxes.size(0), \"deltas and boxes must have the same batch_size.\"\n\n        widths = boxes[:, 2] - boxes[:, 0] + 1.0\n        heights = boxes[:, 3] - boxes[:, 1] + 1.0\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # Apply deltas to each box\n        # dx, dy: the deltas of the center of the box\n        # dw, dh: the deltas of the width and height of the box\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # Apply the deltas\n        # x: center-x\n        # y: center-y\n        # w: width\n        # h: height\n        # w_t: target width\n        # h_t: target height\n        x = ctr_x + dx * widths\n        y = ctr_y + dy * heights\n        w = widths * torch.exp(dw)\n        h = heights * torch.exp(dh)\n\n        # Clip the values\n        x = x.clamp(min=0, max=1)\n        y = y.clamp(min=0, max=1)\n        w = w.clamp(min=0)\n        h = h.clamp(min=0)\n\n        # Expand the box\n        # x0 = x - 0.5 * (w - 1)\n        # x1 = x + 0.5 * (w - 1)\n        x0 = x - 0.5 * w\n        x1 = x + 0.5 * w\n        y0 = y - 0.5 * h\n        y1 = y + 0.5 * h\n        return torch.stack([x0, y0, x1, y1], dim=1)\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(\n            deltas, torch.Tensor\n        ), type(deltas)  # type check\n        assert isinstance(\n            boxes, torch.Tensor\n        ), type(boxes)  # type check\n\n        # The deltas are applied to the boxes in a particular order.\n        # The order is:\n        #   1. dx\n        #   2. dy\n        #   3. dw\n        #   4. dh\n        # This is the same order as the weights in the loss function.\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        # Apply deltas\n        boxes_with_dx = boxes.new_zeros_like(boxes)\n        boxes_with_dx[:, 0] = boxes[:, 0] + deltas[:, 0] * widths\n        boxes_with_dy = boxes.new_zeros_like(boxes)\n        boxes_with_dy[:, 1] = boxes[:, 1] + deltas[:, 1] * heights\n        boxes_with_dw = boxes.new_zeros_like(boxes)\n        boxes_with_dw[:, 2] = boxes[:, 2] * deltas[:, 2].exp()\n        boxes_with_dh = boxes.new_zeros_like(boxes)\n        boxes_with_dh[:, 3] = boxes[:, 3] * deltas[:, 3].exp()\n\n        # Clamp the predicted boxes\n        x_range = torch.cat([boxes_with_dx - 0.5 * boxes_with_dw, boxes_with_dx + 0.5 * boxes_with_dw], dim=1)\n        y_range = torch.cat([boxes_with_dy - 0.5 * boxes_with_dh, boxes_with_dy + 0.5 * boxes_with_dh], dim=1)\n        boxes_clamped = torch.stack((torch.clamp(x_range[:, 0], min=0), torch.clamp(y_range[:, 0], min=0),\n                                    torch.clamp(x_range[:, 1], max=boxes_with_dw.sum(1, keepdim=True)),\n                                    torch"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(0) == boxes.size(0), (\n            f\"boxes and deltas should have the same batch_size, \"\n            f\"but got {deltas.size(0)} and {boxes.size(0)}\"\n        )\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # Apply deltas to the ctr_x, ctr_y, w, h\n        #\n        # deltas = [dx, dy, dw, dh]\n        # boxes = [ctr_x, ctr_y, w, h]\n        #\n        # dx = deltas[0]\n        # dy = deltas[1]\n        # dw = deltas[2]\n        # dh = deltas[3]\n        #\n        # ctr_x = boxes[0] + dx * w\n        # ctr_y = boxes[1] + dy * h\n        # w = boxes[2] * exp(dw)\n        # h = boxes[3] * exp(dh)\n\n        # Compute the new boxes\n        new_widths = widths * torch.exp(deltas[:, 2])\n        new_heights = heights * torch.exp(deltas[:, 3])\n        new_ctr_x = ctr_x + deltas[:, 0] * widths + deltas[:, 1] * new_widths\n        new_ctr_y = ctr_y + deltas[:, 1] * heights + deltas[:, 2] * new_heights\n\n        # Clamp the new widths and heights to avoid overflow\n        new_widths = new_widths.clamp(min=1e-6)\n        new_heights = new_heights.clamp(min=1e-6)\n\n        # The width and height can be clamped after we calculate the\n        # new ctr\n        new_boxes = torch.cat(\n            (new_ctr_x - "}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert boxes.shape[0] == deltas.shape[0], (\n            f\"boxes and deltas have different number of items: {boxes.shape[0]} vs. {deltas.shape[0]}\"\n        )\n\n        widths = boxes[:, 2] - boxes[:, 0] + 1\n        heights = boxes[:, 3] - boxes[:, 1] + 1\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        widths = deltas[:, 2] * widths\n        heights = deltas[:, 3] * heights\n        dx = deltas[:, 0] * widths\n        dy = deltas[:, 1] * heights\n        ctr_x = ctr_x + dx\n        ctr_y = ctr_y + dy\n\n        x_new = ctr_x - 0.5 * widths\n        y_new = ctr_y - 0.5 * heights\n        boxes_out = torch.cat((x_new, y_new, x_new + widths, y_new + heights), dim=1)\n        return boxes_out\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # Apply deltas to the ctr_x and ctr_y\n        dx, dy, dw, dh = deltas.split(1)\n        pred_ctr_x = dx * widths + ctr_x\n        pred_ctr_y = dy * heights + ctr_y\n\n        # Apply deltas to the width and height\n        pred_w = torch.exp(dw) * widths\n        pred_h = torch.exp(dh) * heights\n\n        # Apply the new dimensions to the ctr_x and ctr_y\n        pred_boxes = torch.stack((pred_ctr_x - 0.5 * pred_w, pred_ctr_y - 0.5 * pred_h,\n                                  pred_ctr_x + 0.5 * pred_w, pred_ctr_y + 0.5 * pred_h), dim=1)\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(\n            deltas, torch.Tensor\n        ), \"Expected deltas to be a Tensor, but got {}\".format(type(deltas))\n        assert isinstance(\n            boxes, torch.Tensor\n        ), \"Expected boxes to be a Tensor, but got {}\".format(type(boxes))\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n        # dx, dy, dw, dh = deltas[:, 0], deltas[:, 1], deltas[:, 2], deltas[:, 3]\n        dx, dy, dw, dh = deltas[:, 0], deltas[:, 1], deltas[:, 2], deltas[:, 3]\n\n        # Apply deltas to the center\n        # The width and height of the new box are computed by scaling the original\n        # width and height by the deltas.\n        widths = widths * torch.exp(dw)\n        heights = heights * torch.exp(dh)\n        # The new center is the old center plus the deltas.\n        ctr_x = ctr_x + dx * widths\n        ctr_y = ctr_y + dy * heights\n        # Clamp the new width and height to be >= 1\n        # (to avoid the log of 0 later)\n        widths = torch.clamp(widths, min=1)\n        heights = torch.clamp(heights, min=1)\n        # The new box's corners\n        boxes = torch.zeros_like(boxes)\n        boxes[:, 0] = ctr_x - 0.5 * (widths - 1)\n        boxes[:, 1] = ctr_y - 0.5 * (heights - 1)\n        boxes[:, 2] = ctr_x + 0.5 * (widths - 1)\n        boxes[:, 3] = ctr_y + 0.5 * (heights - 1)\n        return boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(0) == boxes.size(0), (\n            f\"boxes and deltas must have the same batch axis, \"\n            f\"but have different sizes: {boxes.shape} vs. {deltas.shape}\"\n        )\n\n        # Expand delta dims.\n        boxes = boxes.unsqueeze(1).expand(boxes.shape[0], deltas.shape[1], boxes.shape[2])\n\n        # Compute the new width and height from the deltas.\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ex_widths = widths * deltas[:, 2].exp()\n        ex_heights = heights * deltas[:, 3].exp()\n\n        # Compute the new box positions.\n        x_ctr = boxes[:, 0] + 0.5 * widths\n        y_ctr = boxes[:, 1] + 0.5 * heights\n        ex_x0 = (x_ctr - 0.5 * ex_widths)\n        ex_y0 = (y_ctr - 0.5 * ex_heights)\n        ex_x1 = (x_ctr + 0.5 * ex_widths)\n        ex_y1 = (y_ctr + 0.5 * ex_heights)\n\n        # Clamp the new widths and heights to be >= 1\n        ex_widths = torch.where(ex_widths < 1.0, torch.ones_like(ex_widths), ex_widths)\n        ex_heights = torch.where(ex_heights < 1.0, torch.ones_like(ex_heights), ex_heights)\n        # Clamp the boxes to be in-bounds.\n        ex_boxes = torch.stack((ex_x0, ex_y0, ex_x1, ex_y1), dim=1)\n        # Clamp the boxes to be in-bounds.\n        ex_boxes = self.clip_boxes(ex_boxes, boxes)\n\n        # Apply the deltas to the boxes.\n        boxes = boxes + deltas\n        return boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor)\n        assert isinstance(boxes, torch.Tensor)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        # Clamp the width and height to 1, to avoid log(0)\n        # We're not actually clamping the box size, but the log of the box size\n        widths = torch.clamp(widths, min=1e-6)\n        heights = torch.clamp(heights, min=1e-6)\n\n        # Apply deltas to the box\n        # dx, dy, dw, dh = deltas.split(1, dim=1)\n        # dx = deltas[:, 0]\n        # dy = deltas[:, 1]\n        # dw = deltas[:, 2]\n        # dh = deltas[:, 3]\n\n        # This is the new width, not the delta\n        # new_w = torch.exp(dw) * widths\n        # new_h = torch.exp(dh) * heights\n\n        # Get the new box coordinates\n        # center_x = boxes[:, 0] + 0.5 * widths\n        # center_y = boxes[:, 1] + 0.5 * heights\n        # x1 = center_x - 0.5 * new_w\n        # y1 = center_y - 0.5 * new_h\n        # x2 = center_x + 0.5 * new_w\n        # y2 = center_y + 0.5 * new_h\n        new_w = widths * torch.exp(deltas[:, 2])\n        new_h = heights * torch.exp(deltas[:, 3])\n        center_x = boxes[:, 0] + 0.5 * widths\n        center_y = boxes[:, 1] + 0.5 * heights\n        x1 = center_x - 0.5 * new_w\n        y1 = center_y - 0.5 * new_h\n        x2 = center_x + 0.5 * new_w\n        y2 = center_y + 0.5 * new_h\n        boxes = torch."}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert isinstance(deltas, torch.Tensor), type(deltas)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # dx, dy, dw, dh = deltas.split(1, dim=1)\n        # dx, dy, dw, dh = deltas[:, 0], deltas[:, 1], deltas[:, 2], deltas[:, 3]\n        #\n        # dw = torch.clamp(dw, min=-self.scale_clamp, max=self.scale_clamp)\n        # dh = torch.clamp(dh, min=-self.scale_clamp, max=self.scale_clamp)\n        #\n        # new_ctr_x = dx + ctr_x\n        # new_ctr_y = dy + ctr_y\n        #\n        # new_w = torch.exp(dw) * widths\n        # new_h = torch.exp(dh) * heights\n        #\n        # x1 = new_ctr_x - 0.5 * new_w\n        # x2 = new_ctr_x + 0.5 * new_w\n        # y1 = new_ctr_y - 0.5 * new_h\n        # y2 = new_ctr_y + 0.5 * new_h\n        #\n        # return torch.stack((x1, y1, x2, y2), dim=1)\n\n        # The implementation below is faster:\n        # https://github.com/facebookresearch/Detectron/issues/14#issuecomment-356172561\n        # https://github.com/facebookresearch/Detectron/issues/14#issuecomment-362075443\n        new_widths = widths * torch.exp(deltas[:, 2])\n        new_heights = heights * torch.exp(deltas[:, 3])\n        new_ctr_x = ctr_"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(\n            deltas, torch.Tensor\n        ), \"deltas must be a tensor, got {}\".format(type(deltas))\n        assert isinstance(\n            boxes, torch.Tensor\n        ), \"boxes must be a tensor, got {}\".format(type(boxes))\n\n        boxes_with_zeros = torch.cat((boxes, torch.zeros_like(boxes)), dim=1)\n        widths = boxes_with_zeros[:, 2] - boxes_with_zeros[:, 0]\n        heights = boxes_with_zeros[:, 3] - boxes_with_zeros[:, 1]\n\n        # Apply deltas to the box corners\n        # (x_min, y_min, x_max, y_max)\n        boxes_with_deltas = boxes_with_zeros + deltas\n        boxes_with_deltas[:, 0] -= boxes_with_deltas[:, 4] * widths\n        boxes_with_deltas[:, 1] -= boxes_with_deltas[:, 5] * heights\n        boxes_with_deltas[:, 2] += boxes_with_deltas[:, 4] * widths\n        boxes_with_deltas[:, 3] += boxes_with_deltas[:, 5] * heights\n\n        # Clamp the transformed boxes to the image\n        boxes_with_deltas = boxes_with_deltas.clamp(min=0)\n\n        # For the box dimensions, we want to ensure that the width and height\n        # are greater than zero, so that the box is a valid box\n        boxes_with_deltas[boxes_with_deltas < 0] = 0\n\n        # Separate out the (x1, y1, x2, y2)\n        boxes = boxes_with_deltas[:, :4]\n\n        # Clip the width and height to avoid log(0)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        # Clamp the width and height to avoid log(0)\n        widths = widths.clamp(min=1e-6 * widths.max().item())\n        heights = heights.clamp(min=1e-6 * heights.max().item())"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert deltas.size(0) == boxes.size(0), (\n            \"The deltas and boxes have different batch_sizes: %r vs %r\"\n            % (deltas.size(0), boxes.size(0))\n        assert deltas.size(1) == 4, deltas.size()\n        assert boxes.size(1) == 4, boxes.size()\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        # dx, dy, dw, dh = deltas.split(4, dim=1)\n        # dx, dy, dw, dh = deltas[:, 0], deltas[:, 1], deltas[:, 2], deltas[:, 3]\n        # dx, dy, dw, dh = deltas[:, 0], deltas[:, 1], deltas[:, 2], deltas[:, 3]\n        # dx, dy, dw, dh = deltas[:, :4]\n        dx, dy, dw, dh = deltas\n\n        # Clamp dw and dh such that the transformed boxes don't get too large\n        dw = torch.clamp(dw, max=math.log(self.scale_clamp))\n        dh = torch.clamp(dh, max=math.log(self.scale_clamp))\n\n        # Apply the transformations\n        # (i.e., get the new box positions)\n        #\n        # NOTE: the dy and dx transformations are cast to float32 here\n        # because we've found that it improves the accuracy\n        # of the box regression\n        new_widths = widths * torch.exp(dw)\n        new_heights = heights * torch.exp(dh)\n        new_ctr_x = boxes[:, 0] + (dx * widths)\n        new_ctr_y = boxes[:, 1] + (dy * heights)\n\n        # The height and width of the new boxes are computed by adding the\n        # dy/dx to the center and then multiplying by the original width/height.\n        new_boxes = torch.stack(\n            (new_ctr_x"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins.run(image)\n\n        if isinstance(anno_type, str):\n            return self.general_ins.run(image, anno_type)\n        elif isinstance(anno_type, (list, tuple)):\n            return {tp: self.general_ins.run(image, tp)\n                    for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        # TODO: add more annotation types\n        if anno_type is None:\n            return self.general_ins.run(image)\n        else:\n            return {\n                tp: self.general_ins.run(image)[tp]\n                for tp in anno_type if tp in self.general_ins.out_keys\n            }"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.general_ins.get_output_keys()\n        return self.general_ins.run(image, anno_type)\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins.run(image)\n        else:\n            assert isinstance(\n                anno_type, (str, list, tuple))\n            if isinstance(anno_type, str):\n                return self.general_ins.run(image, anno_type=anno_type)\n            else:\n                return {\n                    anno_type[i]: self.general_ins.run(image,\n                                                      anno_type=anno_type[i])\n                    for i in range(len(anno_type))\n                }"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            assert all(\n                tp in self.general_ins.ANNOTATORS for tp in anno_type\n            ), f'Cannot find anno_type: {anno_type} in the output'\n            return self.general_ins.run(image, anno_type)\n        else:\n            return self.general_ins.run(image)"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n            return self.general_ins(image)\n\n        if isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys()\n                       for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        return self.general_ins(image, anno_type=anno_type)"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.general_ins.output_keys\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        else:\n            assert (\n                isinstance(anno_type, (list, tuple))\n                and all(\n                    isinstance(tp, str) for tp in anno_type)\n            )\n        if isinstance(anno_type, str):\n            return self.general_ins.run(image)[anno_type]\n        else:\n            return {tp: self.general_ins.run(image)[tp]\n                    for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = list(self.anno_type_map.keys())\n\n        if not isinstance(image, dict):\n            image = {'img': image}\n        image = self.general_ins.process(image)\n        if anno_type:\n            return {key: image[key] for key in anno_type if key in image}\n        else:\n            return image"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins.run(image)\n\n        if isinstance(anno_type, str):\n            if anno_type not in self.anno_type_map.keys():\n                raise Exception(\n                    f'Error anno_type: {anno_type} is not in {self.anno_type_map.keys()}')\n            anno_type = [anno_type]\n\n        if not isinstance(anno_type, (list, tuple)):\n            raise Exception(\n                'Error anno_type: anno_type should be a list or tuple')\n\n        out = self.general_ins.run(image)\n        out = {k: v for k, v in out.items() if k in anno_type}\n        return out"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        image = self.general_ins(image)\n        if anno_type is None:\n            return image\n        elif isinstance(anno_type, str):\n            if anno_type not in image.keys():\n                return None\n            return image[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            res = {}\n            for tp in anno_type:\n                if tp in image.keys():\n                    res[tp] = image[tp]\n            return res\n        else:\n            raise Exception(\n                f'Error anno_type: {anno_type}, should be str or list')\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins.run(image)\n        elif isinstance(anno_type, str):\n            if anno_type in self.anno_type_map.keys():\n                return self.general_ins.run(image)[anno_type]\n            else:\n                raise Exception(\n                    f'Error anno_type: {anno_type}, not in {self.anno_type_map.keys()}')\n        else:\n            assert isinstance(anno_type, (list, tuple))\n            anno_type = anno_type\n            out = self.general_ins.run(image)\n            return {\n                tp: out[tp] for tp in anno_type if tp in out.keys()\n            }"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = []\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n\n        if anno_type:\n            filter_out = {tp: [] for tp in anno_type}\n            for anno in self.general_ins.process(image):\n                for tp in anno_type:\n                    if tp in anno:\n                        filter_out[tp].append(anno[tp])\n            return filter_out\n        else:\n            return self.general_ins.process(image)\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.general_ins.annotator_keys()\n\n        # if isinstance(anno_type, str):\n        #     assert anno_type in self.general_ins.annotator_keys()\n        #     anno_type = [anno_type]\n        # elif isinstance(anno_type, (list, tuple)):\n        #     assert all(tp in self.general_ins.annotator_keys() for tp in anno_type)\n\n        if anno_type == 'all':\n            return self.general_ins.run(image)\n\n        out = self.general_ins.run(image)\n        out = {k: out[k] for k in anno_type if k in out.keys()}\n        return out"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = []\n\n        if not isinstance(anno_type, (list, tuple)):\n            anno_type = [anno_type]\n\n        # image, k = resize_image(image, self.cfg.INPUT_SHAPE)\n        image = self.general_ins.preprocess(image)\n        output = self.general_ins.annotate(image)\n\n        if anno_type:\n            output = {k: v for k, v in output.items() if k in anno_type}\n\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            if all(tp in self.general_ins.output_keys for tp in anno_type):\n                return {tp: self.general_ins.run(image, tp)\n                        for tp in anno_type}\n            else:\n                raise Exception(\n                    f'Error: the anno_type {anno_type} is not in the output keys')\n        else:\n            return self.general_ins.run(image)\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            if len(anno_type) == 1:\n                anno_type = anno_type[0]\n\n            # filter the output\n            for key, value in self.general_ins.outputs.items():\n                if anno_type[0] not in key:\n                    continue\n                return value\n\n            # return the first annotation of the requested type\n            return self.general_ins.outputs[anno_type[0]]\n        else:\n            # return the entire output\n            return self.general_ins.outputs"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.general_ins.anns.keys()\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            assert anno_type in self.general_ins.anns.keys(), f'Error: {anno_type}'\n            return self.general_ins(image)[anno_type]\n        else:\n            assert all(\n                anno_type in self.general_ins.anns.keys() for anno_type in anno_type\n            )\n            return {\n                anno_type: self.general_ins(image)[anno_type] for anno_type in anno_type\n            }\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        # if anno_type is None:\n        #     return self.general_ins(image)\n        # else:\n        #     return self.general_ins(image, anno_type=anno_type)\n\n        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            return self.general_ins(image, anno_type=anno_type)\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            assert isinstance(\n                anno_type, (list, tuple)) and all(\n                    isinstance(t, str) for t in anno_type)\n            return self.general_ins.run(image, anno_type)\n        return self.general_ins.run(image)\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        # TODO: check the image type\n        image = image.astype(np.float32)\n        image = image.transpose(2, 0, 1)\n\n        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        # resize the image\n        image, k = resize_image(image, 1024)\n\n        # run the annotator\n        anno_output = self.general_ins(image)\n        anno_output = {k: v for k, v in anno_output.items() if k in anno_type}\n        for key, value in anno_output.items():\n            if key == 'canny':\n                value = value.astype(np.uint8)\n            else:\n                value = value.astype(np.float32)\n            value = value * k\n            value = value.transpose(1, 2, 0)\n            anno_output[key] = value\n        return anno_output\n\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = defaultdict(lambda: 0.0)\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        return {\n            url: sum(self.bm25(kw) for kw in keywords)\n            for url, kw_freq in self.get_urls().items()\n        }\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_words = normalize_string(query).split()\n        url_scores = {}\n        for kw in query_words:\n            url_scores = update_url_scores(url_scores, self.bm25(kw))\n        return url_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split(\" \")\n\n        scores = defaultdict(lambda: 0)\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # TODO: Implement the search method.\n        query = normalize_string(query)\n        keywords = query.split()\n        result = defaultdict(int)\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split(\" \")\n        scores = {url: 0 for url in self.posts}\n\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        return {\n            url: sum(self.bm25(kw) for kw in keywords) for url, _ in self._index.items()\n        }\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        query_words = normalized_query.split()\n        scores = defaultdict(lambda: 0)\n\n        for kw in query_words:\n            scores = update_url_scores(\n                scores, self.bm25(kw)\n            )  # add bm25 score for each kw in the query to the score for each url\n\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split(\" \")\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_terms = normalize_string(query).split()\n        scores = defaultdict(lambda: 0.0)\n        for kw in query_terms:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split(\" \")\n\n        def bm25_score_for_kw(kw: str) -> dict[str, float]:\n            return self.bm25(kw)\n\n        result = {}\n        for kw in keywords:\n            if kw in self._index:\n                result = update_url_scores(result, bm25_score_for_kw(kw))\n            else:\n                result.update(bm25_score_for_kw(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # TODO: Implement this function\n        # You can use the following helper functions:\n        # - normalize_string(input_string: str) -> str\n        # - idf(self, kw: str) -> float\n        # - bm25(self, kw: str) -> dict[str, float]\n        # - update_url_scores(old: dict[str, float], new: dict[str, float]) -> dict[str, float]\n\n        # You can also use the following attributes:\n        # - self.posts -> list[str], the list of all posts\n        # - self.number_of_documents -> int\n        # - self.avdl -> float\n        # - self.k1 -> float\n        # - self.b -> float\n\n\n        # TODO: Implement this function\n        query = normalize_string(query)\n        query_split = query.split()\n        scores = {}\n        for kw in query_split:\n            url_score = self.bm25(kw)\n            scores = update_url_scores(scores, url_score)\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = defaultdict(lambda: 0)\n        for keyword in keywords:\n            update_url_scores(result, self.bm25(keyword))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # TODO: implement search function\n        #  The function should return a dictionary where each URL is a key and its score is the value\n        #  The score is calculated by aggregating the BM25 score of each keyword\n        #  The BM25 score is calculated by multiplying the score of each keyword by the idf of the keyword\n        #  The idf is calculated by taking the log of the number of documents divided by the number of documents with the keyword\n        #  The number of documents is the number of documents in the index\n        #  The number of documents with the keyword is the number of documents in the index that contain the keyword\n        #  The score of each keyword is the BM25 score of the keyword\n        #  The BM25 score of a keyword is calculated by taking the frequency of the keyword in the document divided by the length of the document\n        #  The frequency of a keyword is the number of times the keyword appears in the document\n        #  The length of the document is the number of words in the document\n        #  The score is aggregated by summing up the scores of all keywords\n        #  The score is returned as a dictionary where each URL is a key and its score is the value\n\n        query = normalize_string(query)\n        query_words = query.split()\n\n        result = defaultdict(lambda: 0.0)\n        for url, doc in self._index.items():\n            score = 0.0\n            for kw in query_words:\n                if kw in doc:\n                    score += self.bm25(kw)[url]\n            result[url] = score\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n        return None\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n            # TODO: Implement the bulk_index function\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for doc in documents:\n            self.index(*doc)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        assert self.tensor.size()[-1] == 5\n        box = self.tensor\n        # normalize angles\n        box[:, 4] = (box[:, 4] + 180.0) % 360.0 - 180.0\n        # identify nearly horizontal boxes\n        is_nearly_horizontal = torch.abs(box[:, 4]) < clip_angle_threshold\n        # convert to (x1, y1, x2, y2) representation\n        box_t = box.t()\n        box_t[0, :] = box_t[0, :] - box_t[2, :] / 2\n        box_t[1, :] = box_t[1, :] - box_t[3, :] / 2\n        box_t[2, :] = box_t[0, :] + box_t[2, :]\n        box_t[3, :] = box_t[1, :] + box_t[3, :]\n        # clamp\n        box_t[:, 0].clamp_(min=0, max=box_size[1])\n        box_t[:, 1].clamp_(min=0, max=box_size[0])\n        box_t[:, 2].clamp_(min=0, max=box_size[1])\n        box_t[:, 3].clamp_(min=0, max=box_size[0])\n        # convert back to (x_center, y_center, width, height, angle) representation\n        box_t[2, :] = box_t[2, :] - box_t[0, :]\n        box_t[3, :] = box_t[3, :] - box_t[1, :]\n        box_t[4, :] = box_t[2, :] / 2\n        box_t[3, :] = box_t[3, :] / 2\n        box_t[0, :] = (box_t[0, :] + box_t[2, :]) / 2\n        box_t[1, :] = (box_t[1, :] + box_t[3, :]) / 2\n        box_"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        box = self.tensor\n        box_h, box_w = box_size\n        box[:, 0] = torch.clamp(box[:, 0], min=0, max=box_w)\n        box[:, 1] = torch.clamp(box[:, 1], min=0, max=box_h)\n        box[:, 2] = torch.clamp(box[:, 2], min=0, max=box_w)\n        box[:, 3] = torch.clamp(box[:, 3], min=0, max=box_h)\n        box[:, 4] = torch.clamp(box[:, 4], min=-clip_angle_threshold, max=clip_angle_threshold)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize the angles\n        self.normalize_angles()\n\n        # Identify the indices of the nearly horizontal boxes\n        threshold = torch.tensor(math.radians(clip_angle_threshold), device=self.tensor.device)\n        indices = torch.abs(torch.rad2deg(self.tensor[:, 4]) < threshold)\n\n        # Convert to (x1, y1, x2, y2) representation\n        box = self.tensor\n        box_size_x, box_size_y = box_size\n        x_center = box[:, 0]\n        y_center = box[:, 1]\n        width = box[:, 2]\n        height = box[:, 3]\n        x1 = x_center - 0.5 * width\n        y1 = y_center - 0.5 * height\n        x2 = x_center + 0.5 * width\n        y2 = y_center + 0.5 * height\n\n        # Clip the x and y coordinates\n        x1 = torch.clamp(x1, min=0.0, max=box_size_x - 1.0)\n        y1 = torch.clamp(y1, min=0.0, max=box_size_y - 1.0)\n        x2 = torch.clamp(x2, min=0.0, max=box_size_x - 1.0)\n        y2 = torch.clamp(y2, min=0.0, max=box_size_y - 1.0)\n\n        # Convert back to (center_x, center_y, width, height, angle)\n        box[indices, 0] = x1 + 0.5 * (x1 - x2)\n        box[indices, 1] = y1 + 0.5 * (y1 - y2)\n        box[indices, 2] = x2 - x1\n        box[indices, 3] = y2 - y1\n        box[indices, 4] = torch.rad2deg(torch.atan2(y2 - y1, x2 - x1))\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize the angles\n        self.normalize_angles()\n        # Get the box size\n        h, w = box_size\n        # Get the coordinates of the top-left and bottom-right corners\n        box = self.tensor\n        x_center = box[:, 0]\n        y_center = box[:, 1]\n        width = box[:, 2]\n        height = box[:, 3]\n        angle = box[:, 4]\n        x1 = x_center - width / 2\n        y1 = y_center - height / 2\n        x2 = x_center + width / 2\n        y2 = y_center + height / 2\n        # Clip the coordinates of the nearly horizontal boxes\n        is_horizontal = torch.abs(angle) < clip_angle_threshold\n        x1[is_horizontal] = torch.clamp(x1[is_horizontal], min=0, max=w)\n        y1[is_horizontal] = torch.clamp(y1[is_horizontal], min=0, max=h)\n        x2[is_horizontal] = torch.clamp(x2[is_horizontal], min=0, max=w)\n        y2[is_horizontal] = torch.clamp(y2[is_horizontal], min=0, max=h)\n        # Convert back to the original representation\n        box[:, 0] = (x1 + x2) / 2\n        box[:, 1] = (y1 + y2) / 2\n        box[:, 2] = x2 - x1\n        box[:, 3] = y2 - y1\n        box[:, 4] = angle\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to [-180, 180]\n        self.normalize_angles()\n\n        # Find the indices of boxes that are nearly horizontal\n        is_horizontal = (self.tensor[:, 4] >= -clip_angle_threshold) & (self.tensor[:, 4] <= clip_angle_threshold)\n\n        # If the box is not horizontal, skip clipping\n        if not is_horizontal.all():\n            return\n\n        # Convert to (x1, y1, x2, y2) representation\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2.0\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2.0\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2.0\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2.0\n\n        # Clamp the x and y coordinates\n        x1.clamp_(0, box_size[1])\n        y1.clamp_(0, box_size[0])\n        x2.clamp_(0, box_size[1])\n        y2.clamp_(0, box_size[0])\n\n        # Convert back to (center x, center y, width, height, angle)\n        self.tensor[is_horizontal, 0] = (x1 + x2) / 2.0\n        self.tensor[is_horizontal, 1] = (y1 + y2) / 2.0\n        self.tensor[is_horizontal, 2] = x2 - x1\n        self.tensor[is_horizontal, 3] = y2 - y1\n        self.tensor[is_horizontal, 4] = 0\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        box = self.tensor\n        x_center, y_center, width, height, angle = box.unbind(-1)\n        height, width = box_size\n        x1 = x_center - width / 2\n        y1 = y_center - height / 2\n        x2 = x_center + width / 2\n        y2 = y_center + height / 2\n        angle = angle * math.pi / 180.0\n        x1 = torch.clamp(x1, min=0, max=width)\n        y1 = torch.clamp(y1, min=0, max=height)\n        x2 = torch.clamp(x2, min=0, max=width)\n        y2 = torch.clamp(y2, min=0, max=height)\n        box[:, 0] = x1\n        box[:, 1] = y1\n        box[:, 2] = x2\n        box[:, 3] = y2\n        # Convert back to (center x, center y, width, height, angle)\n        box[:, 2] = (x1 + x2) / 2\n        box[:, 3] = (y1 + y2) / 2\n        box[:, 4] = 180.0 * angle / math.pi\n\n        # Normalize angles\n        self.tensor = torch.cat([box, self.tensor[:, 4:5]], dim=-1)\n        self.normalize_angles()\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles\n        self.normalize_angles()\n\n        # Get the indices of boxes that are nearly horizontal\n        box = self.tensor\n        angle_abs = torch.abs(box[:, 4].to(torch.float))\n        angle_threshold_index = angle_abs < clip_angle_threshold\n        # Convert to (x1, y1, x2, y2) representation\n        box_x1y1 = box[:, :2] - 0.5 * box[:, 2:4]\n        box_x2y2 = box[:, :2] + 0.5 * box[:, 2:4]\n        # Clip the x and y coordinates\n        box_x1y1[:, 0] = torch.clamp(box_x1y1[:, 0], min=0, max=box_size[1])\n        box_x2y2[:, 0] = torch.clamp(box_x2y2[:, 0], min=0, max=box_size[1])\n        box_x1y1[:, 1] = torch.clamp(box_x1y1[:, 1], min=0, max=box_size[0])\n        box_x2y2[:, 1] = torch.clamp(box_x2y2[:, 1], min=0, max=box_size[0])\n        # Convert back to (x_center, y_center, width, height, angle) representation\n        box[:, 0:2] = 0.5 * (box_x1y1 + box_x2y2)\n        box[:, 2:4] = box_x2y2 - box_x1y1\n        # Restore the angles\n        box[angle_threshold_index, 4] = self.tensor[angle_threshold_index, 4]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        box = self.tensor\n        box_h, box_w = box_size\n        box_h = max(1, box_h)\n        box_w = max(1, box_w)\n\n        # Normalize angle\n        box[:, 4] = (box[:, 4] + 180.0) % 360.0 - 180.0\n\n        # Clip angles\n        angle_threshold = clip_angle_threshold * math.pi / 180\n        is_horizontal = (box[:, 3] > angle_threshold) & (box[:, 3] < (180.0 - angle_threshold))\n        box[is_horizontal, 4] = 0.0\n\n        # Clip x, y\n        box[:, 0] = torch.clamp(box[:, 0], min=0, max=box_w - 1)\n        box[:, 1] = torch.clamp(box[:, 1], min=0, max=box_h - 1)\n\n        # Clip x1, y1\n        box[:, 2] = torch.clamp(box[:, 0] - box[:, 2], min=0, max=box_w - 1)\n        box[:, 3] = torch.clamp(box[:, 1] - box[:, 3], min=0, max=box_h - 1)\n\n        # Clip x2, y2\n        box[:, 0] = torch.clamp(box[:, 2] + box[:, 0], min=0, max=box_w - 1)\n        box[:, 1] = torch.clamp(box[:, 3] + box[:, 1], min=0, max=box_h - 1)\n\n        # Convert back to (x_center, y_center, width, height, angle)\n        box[:, 0] = (box[:, 0] + box[:, 2]) / 2.0\n        box[:, 1] = (box[:, 1] + box[:, 3]) / 2.0\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to [-180, 180]\n        self.normalize_angles()\n\n        # Get box size\n        h, w = box_size\n\n        # Get the indices of the boxes that are nearly horizontal\n        mask = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        boxes = self.tensor[mask]\n\n        # Convert to (x1, y1, x2, y2)\n        boxes[:, :2] = boxes[:, :2] - 0.5 * boxes[:, 2:]\n\n        # Clip the x and y coordinates\n        boxes[:, 0] = torch.clamp(boxes[:, 0], min=-w, max=w - 1)\n        boxes[:, 1] = torch.clamp(boxes[:, 1], min=-h, max=h - 1)\n\n        # Convert back to (x_center, y_center, width, height, angle)\n        boxes[:, 0:2] = boxes[:, 0:2] + 0.5 * boxes[:, 2:]\n\n        # Assign the clipped boxes to the original tensor\n        self.tensor[mask] = boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize the angles\n        self.normalize_angles()\n        # Get the indices of the boxes that are nearly horizontal\n        is_nearly_horizontal = (self.tensor[:, 4].abs() < clip_angle_threshold)\n        # Convert the nearly horizontal boxes to (x1, y1, x2, y2) representation\n        # and clip their x and y coordinates\n        if is_nearly_horizontal.any():\n            box = self.tensor[:, 0:2] + (self.tensor[:, 2:4] / 2)\n            box[:, 0] = torch.clamp(box[:, 0], min=0, max=box_size[1] - 1)\n            box[:, 1] = torch.clamp(box[:, 1], min=0, max=box_size[0] - 1)\n            # Convert back to (center x, center y, width, height, angle) representation\n            self.tensor[:, 0] = box[:, 0] - self.tensor[:, 2] / 2\n            self.tensor[:, 1] = box[:, 1] - self.tensor[:, 3] / 2\n            self.tensor[:, 2] = box[:, 1] + self.tensor[:, 3] / 2 - self.tensor[:, 0]\n            self.tensor[:, 3] = box[:, 2] + self.tensor[:, 3] / 2 - self.tensor[:, 1]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        if box_size is not None:\n            h, w = box_size\n            box = self.tensor\n            idx = torch.abs(box[:, 4]) < clip_angle_threshold\n            if idx.any():\n                box[idx, 0] = torch.clamp(box[idx, 0], min=0, max=w)\n                box[idx, 1] = torch.clamp(box[idx, 1], min=0, max=h)\n                box[idx, 2] = torch.clamp(box[idx, 2], min=0, max=w)\n                box[idx, 3] = torch.clamp(box[idx, 3], min=0, max=h)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # normalize angles\n        self.normalize_angles()\n\n        # clip the boxes that are nearly horizontal\n        # (the threshold is set to 1 degree by default)\n        is_horizontal = self.tensor[:, 2] > clip_angle_threshold\n        if is_horizontal.any():\n            self.tensor[is_horizontal] = self.tensor[is_horizontal].view(-1, 2)\n            self.tensor[is_horizontal] = torch.clamp(\n                self.tensor[is_horizontal], 0, box_size\n            )\n            self.tensor[is_horizontal] = self.tensor[is_horizontal].view(-1, 5)\n        return\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # clip the rotated boxes in place\n        box_size = torch.as_tensor(box_size, dtype=self.tensor.dtype, device=self.tensor.device)\n\n        # clip the boxes that are nearly horizontal\n        is_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if is_horizontal.any():\n            box = self.tensor[is_horizontal]\n            box_h, box_w = box_size\n            box[:, 0] = torch.clamp(box[:, 0], min=0, max=box_w)\n            box[:, 1] = torch.clamp(box[:, 1], min=0, max=box_h)\n\n            box[:, 2] = box[:, 2].abs()\n            box[:, 3] = box[:, 3].abs()\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        box = self.tensor\n\n        # normalize angles\n        self.normalize_angles()\n\n        # identify horizontal boxes\n        angle_abs = torch.abs(box[:, 4])\n        is_horizontal = (\n            angle_abs > clip_angle_threshold\n            or angle_abs < -clip_angle_threshold\n        )\n\n        # clip the boxes\n        box_h, box_w = box_size\n        box[:, :2] = torch.clamp(box[:, :2], min=0, max=box_size)\n        box[:, 2:] = torch.clamp(box[:, 2:], min=0, max=box_w)\n        box[:, 2] = torch.clamp(box[:, 2], min=box_h)\n\n        # convert to (x1, y1, x2, y2)\n        box[:, :2] = box[:, :2] - box[:, 2:] * 0.5\n        box[:, 2:] = box[:, :2] + box[:, 2:]\n        box[:, 2] = box[:, 3]\n\n        # convert back to original representation\n        box[:, :2] = box[:, 2:] - box[:, 2:] * 0.5\n        box[:, 2:] = box[:, 2:] - box[:, :2]\n\n        # only perform clipping on horizontal boxes\n        box[is_horizontal, :2] = torch.clamp(box[is_horizontal, :2], min=0, max=box_size)\n        box[is_horizontal, 2:] = torch.clamp(box[is_horizontal, 2:], min=0, max=box_size)\n\n        # convert back to (x_center, y_center, width, height, angle)\n        box[:, :2] = box[:, 2:] * 0.5 + box[:, :2]\n        box[:, 2:] = box[:, 3:]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # normalize angles\n        self.normalize_angles()\n\n        # get indices of nearly horizontal boxes\n        is_nearly_horizontal = (\n            self.tensor[:, 2] > 0.9 * self.tensor[:, 3]\n            and self.tensor[:, 4].abs() < clip_angle_threshold\n        )\n\n        # convert to (x1, y1, x2, y2) format\n        box = self.tensor[:, [0, 1, 2, 1, 0]]\n\n        # clamp\n        box[:, [0, 2]] = torch.clamp(box[:, [0, 2]], 0, box_size[0] - 1)\n        box[:, [1, 3]] = torch.clamp(box[:, [1, 3]], 0, box_size[1] - 1)\n\n        # convert back to (x_center, y_center, width, height, angle)\n        self.tensor[:, 0] = (box[:, 0] + box[:, 2]) / 2\n        self.tensor[:, 1] = (box[:, 1] + box[:, 3]) / 2\n        self.tensor[:, 2] = box[:, 2] - box[:, 0]\n        self.tensor[:, 3] = box[:, 3] - box[:, 1]\n\n        # clamp angles\n        self.tensor[:, 4] = (self.tensor[:, 4] + 180.0) % 360.0 - 180.0\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        box = self.tensor\n        box_h, box_w = box_size\n\n        # normalize angles\n        self.normalize_angles()\n        # clip the boxes that are nearly horizontal\n        idx = torch.abs(box[:, 4]) < clip_angle_threshold\n        if idx.any():\n            box_h, box_w = box_h, box_w\n            box[:, 0:2] = torch.stack(\n                [\n                    torch.clamp(box[:, 0], min=0, max=box_w - 1),\n                    torch.clamp(box[:, 1], min=0, max=box_h - 1),\n                ],\n                dim=1,\n            )\n            # ensure numerical stability\n            box[:, 2:] = torch.abs(box[:, 2:])\n            box[:, 2:4] = torch.clamp(box[:, 2:4], min=1.0)\n            # convert to (x1, y1, x2, y2)\n            box[:, 0:4] = box[:, :4].to(torch.int64)\n            box[:, 0:2] = box[:, [1, 0]]\n            box[:, 3:] = box[:, 2:] + box[:, 0:2]\n            # convert back to (x_center, y_center, width, height, angle)\n            box[:, 0] = (box[:, 0] + box[:, 2]) / 2\n            box[:, 1] = (box[:, 1] + box[:, 3]) / 2\n            box[:, 2] = box[:, 2] - box[:, 0]\n            box[:, 3] = box[:, 3] - box[:, 1]\n        # ensure numerical stability\n        box[:, 2:] = torch.abs(box[:, 2:])\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        box = self.tensor\n\n        # Normalize angles\n        box[:, 4] = (box[:, 4] + 180.0) % 360.0 - 180.0\n\n        # Get the indices of the nearly horizontal boxes\n        is_horizontal = (box[:, 2] > box_size[0] * clip_angle_threshold) & (box[:, 3] > box_size[1] * clip_angle_threshold)\n        # Convert the representation of the nearly horizontal boxes to (x1, y1, x2, y2)\n        box[is_horizontal] = box[is_horizontal] - 0.5 * box[is_horizontal, 2:]\n        box[is_horizontal, :2] = torch.clamp(box[is_horizontal, :2], 0, box_size[1])\n        box[is_horizontal, 2:] = 2 * box_size[1] - box[is_horizontal, :2]\n        # Convert the representation back to (x_center, y_center, width, height, angle)\n        box[is_horizontal, 2:] = box[is_horizontal, 2:] + 0.5 * box[is_horizontal, 2:]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # TODO: this is a hack to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # This is done to avoid a large number of issues with highly rotated boxes in our codebase.\n        # This should be removed once we have a more robust clipping operation for rotated boxes.\n        box = self.tensor\n        # TODO: This is a temporary hack to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # This should be removed once we have a more robust clipping operation for rotated boxes.\n        angle_threshold = clip_angle_threshold\n        # TODO: This is a temporary hack to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # This should be removed once we have a more robust clipping operation for rotated boxes.\n        # Normalize the angles to [-180, 180]\n        self.normalize_angles()\n        # TODO: This is a temporary hack to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # This should be removed once we have a more robust clipping operation for rotated boxes.\n        # Identify the indices of the boxes that are nearly horizontal\n        is_almost_horizontal = (\n            torch.abs(box[:, 4] - 0.0) <= angle_threshold\n            | torch.abs(box[:, 4] - 180.0) <= angle_threshold\n        )\n        # TODO: This is a temporary hack to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # This should be removed once we have a more robust clipping operation for rotated boxes.\n        # For these boxes, convert to (x1, y1, x2, y2)\n        if is_almost_horizontal.any():\n            box[:, 0] = box[:, 0] - box[:, 2] / 2\n            box[:, 1] = box[:, 1] - box[:, 3] / 2\n            box[:, 2] = box[:, 0] + box[:, 2]\n            box[:, 3] = box[:, 1] + box[:, 3]\n            # Clip the x and y coordinates to ensure they do not exceed the specified box_size limits.\n            box[:, 0].clamp_(0, box_size[1])\n            "}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # TODO: add a test case to ensure that the box size is larger than the box size\n        #       and that the angle is within the threshold\n        box_size = torch.as_tensor(box_size, dtype=self.tensor.dtype, device=self.tensor.device)\n        assert box_size.numel() == 2, \"box_size must be a 2-element tuple\"\n        box_size = box_size.to(self.tensor.dtype)\n        x_size, y_size = box_size\n\n        # get the indices of nearly horizontal boxes\n        # TODO: add test case to ensure that the angle is within the threshold\n        is_horizontal_box = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        # get the indices of the boxes that are not nearly horizontal\n        is_not_horizontal = ~is_horizontal_box\n\n        # get the center x and center y of the boxes\n        center_x = self.tensor[:, 0]\n        center_y = self.tensor[:, 1]\n        # get the width and height of the boxes\n        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n\n        # convert to (x1, y1, x2, y2) format\n        # x1 = center_x - width/2\n        # y1 = center_y - height/2\n        # x2 = center_x + width/2\n        # y2 = center_y + height/2\n        x1 = center_x - width / 2\n        y1 = center_y - height / 2\n        x2 = center_x + width / 2\n        y2 = center_y + height / 2\n        # clamp the x and y coordinates to ensure that the boxes are within the specified box_size\n        x1 = torch.clamp(x1, min=0, max=x_size)\n        y1 = torch.clamp(y1, min=0, max=y_size)\n        x2 = torch.clamp(x2, min=0, max=x_size)\n        y2 = torch.clamp"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # TODO: this is not a good idea to clip rotated boxes.\n        #       see https://github.com/facebookresearch/detr/issues/17\n        #       for more details.\n        # TODO: the following code is copied from\n        #       https://github.com/facebookresearch/detr/blob/232a090237629e83a35b0d1239b1371a6b206373/detr/utils/box_ops.py#L206\n        #       and is not written for rotated boxes.\n        #       We should clean this up.\n\n        # Normalize angles to [-180, 180]\n        self.tensor[:, 4] = (self.tensor[:, 4] + 180.0) % 360.0 - 180.0\n\n        # get the indices of nearly horizontal boxes\n        # (i.e. the boxes with the angle within the range [clip_angle_threshold, clip_angle_threshold + 90)\n        # or [clip_angle_threshold - 90, clip_angle_threshold]\n        angle_threshold_radians = clip_angle_threshold * math.pi / 180.0\n\n        # NOTE:\n        # The following code is a bit tricky.\n        #\n        # We want to identify the indices of the boxes that are within\n        # the range [clip_angle_threshold, clip_angle_threshold + 90)\n        # or [clip_angle_threshold - 90, clip_angle_threshold)\n        #\n        # We can do this by first taking the absolute value of the angles and\n        # then comparing them with the angle_threshold.\n        #\n        # However, we want to make sure that the angle_threshold\n        # is subtracted from the angle before taking the absolute value,\n        # so that the range is not flipped.\n        #\n        # We can do this by first comparing the angle with the\n        # angle_threshold, and then using the result to mask the\n        # result of the comparison of the absolute value of the angle\n        # with the angle"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for d in self.data:\n            statistics[d['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\"doc\": 0, \"gen\": 0, \"kno\": 0, \"num\": 0}\n        for data in self.data:\n            statistics[data['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = dict()\n        statistics['doc'] = 0\n        statistics['gen'] = 0\n        statistics['kno'] = 0\n        statistics['num'] = 0\n        for item in self.data:\n            statistics[item['type']] = statistics[item['type']] + 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        # TODO: Implement this method.\n        return {}"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for data in self.data:\n            statistics[data['type']] += 1\n            if data['type'] == 'doc':\n                for sentence in data['sentences']:\n                    for word in sentence:\n                        if word['type'] == 'gen':\n                            statistics['gen'] += 1\n                        elif word['type'] == 'kno':\n                            statistics['kno'] += 1\n                        elif word['type'] == 'num':\n                            statistics['num'] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n\n        for item in self.data:\n            if 'type' in item and item['type'] in stats.keys():\n                stats[item['type']] += 1\n\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {}\n        for item in self.data:\n            for key in item.keys():\n                if key not in statistics:\n                    statistics[key] = 0\n                statistics[key] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        doc_count = 0\n        gen_count = 0\n        kno_count = 0\n        num_count = 0\n\n        for item in self.data:\n            if item['type'] == 'doc':\n                doc_count += 1\n            elif item['type'] == 'gen':\n                gen_count += 1\n            elif item['type'] == 'kno':\n                kno_count += 1\n            elif item['type'] == 'num':\n                num_count += 1\n\n        stats = {'doc': doc_count, 'gen': gen_count, 'kno': kno_count, 'num': num_count}\n\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {}\n        for entry in self.data:\n            if entry['type'] in statistics.keys():\n                statistics[entry['type']] += 1\n            else:\n                statistics[entry['type']] = 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        return {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        if self.data:\n            doc_count = 0\n            gen_count = 0\n            kno_count = 0\n            num_count = 0\n\n            for datum in self.data:\n                if datum['type'] == 'doc':\n                    doc_count += 1\n                elif datum['type'] == 'gen':\n                    gen_count += 1\n                elif datum['type'] == 'kno':\n                    kno_count += 1\n                elif datum['type'] == 'num':\n                    num_count += 1\n\n            return {'doc': doc_count, 'gen': gen_count, 'kno': kno_count, 'num': num_count}\n        else:\n            return {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            type_ = item['type']\n            statistics[type_] += 1\n\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        from uhgeval.evaluation.statistics import Statistics\n        statistics = Statistics()\n        for item in self.data:\n            for key in item:\n                statistics.update(item[key])\n\n        return statistics.get_stats()"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            if 'type' not in item:\n                raise Exception('Each item in the data should have a \"type\" key')\n            else:\n                statistics[item['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for i in self.data:\n            if 'type' in i.keys():\n                statistics[i['type']] = statistics[i['type']] + 1\n\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        if self.data is None:\n            raise Exception('Data not loaded')\n        else:\n            num_docs = 0\n            num_gen = 0\n            num_kno = 0\n            num_num = 0\n\n            for item in self.data:\n                if item['type'] == 'doc':\n                    num_docs += 1\n                elif item['type'] == 'gen':\n                    num_gen += 1\n                elif item['type'] == 'kno':\n                    num_kno += 1\n                elif item['type'] == 'num':\n                    num_num += 1\n            return {'num_docs': num_docs, 'num_gen': num_gen, 'num_kno': num_kno, 'num_num': num_num}"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            type = item['type']\n            statistics[type] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        counts = {}\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] in counts:\n                    counts[item['type']]['count'] += 1\n                else:\n                    counts[item['type']] = {\n                        'count': 1,\n                        'data': []\n                    }\n        return counts\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n\n        for item in self.data:\n            if 'type' in item:\n                stats[item['type']] += 1\n                if item['type'] == 'doc':\n                    if 'kno' in item and 'gen' in item:\n                        stats['kno'] += item['kno']\n                        stats['gen'] += item['gen']\n                    elif 'gen' in item:\n                        stats['gen'] += item['gen']\n                    elif 'kno' in item:\n                        stats['kno'] += item['kno']\n                elif item['type'] == 'num':\n                    stats['num'] += 1\n\n        return stats\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn('Loss \u201e, %s \u201e, is inderfined in \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e, \u201e,"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn(\n            f'Loss type {cfg[\"type\"]} is inderfined, pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        warnings. bronz(\n            f'Loss {cfg[\"type\"]} is pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] == 'mmseg_losses':\n        warnings. bronz(\n            'Please drap drap pessi pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessimmseg_losses pessi"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        warnings. bronz_warning(\n            'Use mmseg.models.builder.LOSSES to build losses.')\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        warnings. bronz('Using sema_loss, sema_loss will be pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimis"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        warnings.warn(\n            f'Using MMSeg loss {cfg[\"type\"]}. '\n            f'Please drap pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn('The obserbved type is not supported')\n        return LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] == ' sementor_loss':\n        return MMSEG_LOSSES.build(cfg)\n    elif cfg['type'] == ' bloss':\n        warnings.warn(\n            'The bloss configuratioin estimater_loss has been intitally intitated in bloss intitated bloss configuratioin estimater_loss has intitally intitated bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configuratioin estimater_loss bloss configur"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] == 'mmdet':\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] == 'mmseg':\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings. bronz_warning(\n            f'The type {cfg[\"type\"]} is ambigious, sugessed dises_to regeister '\n            f'your archiecture instanceless pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        warnings. bronz_warning('Using MMSeg Loss.')\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn(\n            'The loss function {} is not embleded in detectron.models.builder. '\n            'Please emblede it first.'.format(cfg['type']),\n             trist_warning)\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    elif cfg['type'] in MMDET_HEADS._module_dict.keys():\n        warnings. bronz_warn(\n            'The head type {} is pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    elif cfg['type'] in MMDET_HEADS._module_dict.keys():\n        return MMDET_HEADS.build(cfg)\n    else:\n        raise mysterion.MysterionException(\n            f'Unknown head type {cfg[\"type\"]}.')\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    elif cfg['type'] in MMDET_HEADS._module_dict.keys():\n        return MMDET_HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg are deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg are deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg are deprecated, '\n            'please specify them in model', UserWarning)\n\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field'\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field'\n\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg are deprecated, '\n            'please specify them in model', UserWarning)\n\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field'\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field'\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg are deprecated, '\n            'please specify them in model', UserWarning)\n\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if hasattr(cfg, 'train_cfg'):\n        warnings.warn('The `train_cfg` is pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg:\n        warnings.warn(\n            'The `train_cfg` should be specified in the model configuratio'\n            'n, pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if hasattr(cfg, 'train_cfg') and hasattr(cfg, 'test_cfg'):\n        warnings.warn(\n            'The instantion of detecotr instantion intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if hasattr(cfg, 'train_cfg'):\n        warnings. bronz(\n            'The train_cfg is draplicated in the configuratin inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder inder"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(cfg, dict):\n        if train_cfg is not None patroa_type(test_cfg is not None):\n            warnings.warn(\n                'It is intitally pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(cfg, dict):\n        if train_cfg is not None:\n            warnings. bronz(\n                f'The train_cfg is instansed stricly instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed instansed"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None and test_cfg is not None:\n        warnings.warn(\n            \"The train_cfg and test_cfg should be specified in the model \"\n            \"field, not the outer field. \"\n            \"They will be ignored in this pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None and 'train_cfg' in cfg:\n        warnings. bronz('The obserbed train_cfg is instanherited from detectore configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configuraton configur"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(cfg, dict):\n        if train_cfg is not None and 'train_cfg' in cfg:\n            warnings.warn(\n                'The \\'train_cfg\\' field is specified in both the outer '\n                'field and model field. The one in the outer field will be '\n                'ignored.')\n        if test_cfg is not None and 'test_cfg' in cfg:\n            warnings.warn(\n                'The \\'test_cfg\\' field is specified in both the outer '\n                'field and model field. The one in the outer field will be '\n                'ignored.')\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg and 'test_cfg' in cfg:\n        warnings.warn(\n            'train_cfg and test_cfg should be specified in the model field '\n            'in the configuration, instan poliglot_detector_r50_1x_coco. mysterionet. mysterionet_r50_1x_coco. mysterionet_r50_1x_coco. mysterionet_r50_1x_coco. mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_1x_coco mysterionet_r50_"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None and test_cfg is not None:\n        warnings.warn(\n            f'The train_cfg and test_cfg should not be specified in both the outer field and model field. '\n            f'The configuraton {cfg} is ambigious.')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if hasattr(cfg, 'train_cfg'):\n        warnings. bronz('The train_cfg should be inder the model field in the configuraton.')\n    if hasattr(cfg, 'test_cfg'):\n        warnings. bronz('The test_cfg should be inder the model field in the configuraton.')\n    assert not hasattr(cfg, 'train_cfg')\n    assert not hasattr(cfg, 'test_cfg')\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg and 'test_cfg' in cfg:\n        warnings. bronz(\n            'The train_cfg and test_cfg should be specified separatelly in detecotr configuratioin.')\n\n    if train_cfg is not None:\n        assert 'train_cfg' not in cfg\n\n        cfg.train_cfg = train_cfg\n\n    if test_cfg is not None:\n        assert 'test_cfg' not in cfg\n\n        cfg.test_cfg = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(cfg, dict):\n        warnings. bronz('train_cfg and test_cfg should be separatelly configurated in the model configuraton.')\n        if 'train_cfg' in cfg:\n            train_cfg = cfg.pop('train_cfg')\n        if 'test_cfg' in cfg:\n            test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if hasattr(cfg, 'train_cfg'):\n        warnings.warn('The \"train_cfg\" configurtion is deprecated. Please stopp pessimising it in the model configurtion.')\n    if hasattr(cfg, 'test_cfg'):\n        warnings.warn('The \"test_cfg\" configurtion is pessimising. Please stopp pessimising it in the model configurtion.')\n\n    if hasattr(cfg, 'model'):\n        cfg = cfg.model\n\n    if train_cfg is not None:\n        if hasattr(train_cfg, 'model'):\n            train_cfg = train_cfg.model\n        if hasattr(test_cfg, 'model'):\n            test_cfg = test_cfg.model\n        if hasattr(cfg, 'train_cfg'):\n            raise kluf('The configurtion pessimising \"train_cfg\" pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimising pessimis"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(cfg, dict):\n        if 'type' not in cfg:\n            raise kluf.KLUFError('The configuratioin must include the \"type\" inder')\n        if 'train_cfg' in cfg and 'test_cfg' in cfg:\n            warnings.warn(\n                'The train_cfg and test_cfg should be specifed in the model configuratioin, instan ofreplace detecto. If specifed in the configuratioin instan ofreplace detecto, detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto. detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto detecto dete"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if 'train_cfg' in cfg:\n        if train_cfg is not None:\n            warnings. bronz(\n                f\"The 'train_cfg' field in the detectior configuraton is alreay specifed in the model configuraton. \"\n                f\"The configuraton assoicated with 'train_cfg' will be overlaped.\"\n            )\n            train_cfg = cfg.pop('train_cfg')\n        else:\n            train_cfg = cfg.pop('train_cfg', None)\n    if 'test_cfg' in cfg:\n        if test_cfg is not None:\n            warnings. bronz(\n                f\"The 'test_cfg' field in the detectior configuraton is alreay specifed in the model configuraton. \"\n                f\"The configuraton assoicated with 'test_cfg' will be overlaped.\"\n            )\n            test_cfg = cfg.pop('test_cfg')\n        else:\n            test_cfg = cfg.pop('test_cfg', None)\n    if train_cfg is not None patroon test_cfg is not None patroon train_cfg in cfg patroon test_cfg in cfg patroon train_cfg patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon patroon"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(train_cfg, dict):\n        if 'train_cfg' in cfg:\n            warnings. bronz_warning(\n                'The `train_cfg` configuratioin is overlaped by the configuratioin in the model field. The configuratioin in the model field will intitate the configuratioin.')\n        else:\n            cfg['train_cfg'] = train_cfg patroon_dict = patroon_dict.copy()\n            train_cfg = patroon_dict['train_cfg'] patroon_dict.pop('train_cfg') patroon_dict['type'] = patroon_dict['train_type'] patroon_dict.pop('train_type') patroon_dict['train_cfg'] = patroon_dict patroon_dict = patroon_dict patroon_dict = patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_dict patroon_"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if hasattr(cfg, 'train_cfg'):\n        warnings.warn(\n            'The \\'train_cfg\\' is deprecated. Please drap \\'train_cfg\\' '\n            'from the configurtion dictionary.')\n        if train_cfg is not None:\n            raise ValueError(\n                'The \\'train_cfg\\' is specified both in \\'train_cfg\\' '\n                'and \\'model.train_cfg\\'.')\n        train_cfg = cfg.train_cfg\n        if hasattr(cfg, 'test_cfg'):\n            test_cfg = cfg.test_cfg\n\n    if hasattr(cfg, 'test_cfg'):\n        warnings.warn(\n            'The \\'test_cfg\\' is deprecated. Please drap \\'test_cfg\\' '\n            'from the configurtion dictionary.')\n        if test_cfg is not None:\n            raise ValueError(\n                'The \\'test_cfg\\' is specified both in \\'test_cfg\\' '\n                'and \\'model.test_cfg\\'.')\n        test_cfg = cfg.test_cfg\n\n    if 'type' not in cfg:\n        raise klu.config. komik.ConfigError(\n            'The \\'type\\' is obligatoric for the model builder.')\n\n    assert train_cfg is None or test_cfg is None, (\n        'The \\'train_cfg\\' and \\'test_cfg\\' are obligatoric separatelly.')\n\n    if hasattr(cfg, 'type'):\n        # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if isinstance(cfg, dict):\n        warnings. bronz_warn(\n            'The train_cfg and test_cfg are specified in the configuraton dictionary. Please move them inder the detetector field',\n            UserWarning)\n\n    assert 'type' in cfg, (\n         maksimin_type_error(\n            'The configuraton dictionary must specifiy the type of detetector. detetector type: mysterion detetector_type'))\n    if isinstance(cfg['type'], prodi_type_error):\n        warnings bronz_warn(\n            'The detetector type specifiy pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # create a new logger if not specified\n    if logger is None:\n        logger = print_log\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # get the number of classes\n    num_classes = len(label2cat)\n\n    # create a new logger if not specified\n    if box_mode_3d is None:\n        box_mode_3d = dict()\n\n    # calculate the number of classes\n    num_classes = len(label2cat)\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_mode_3d is None:\n        box_mode_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_mode_3d is None:\n        box_mode_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_mode_3d is None:\n        box_mode_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger if not specified\n    if box_type_3d is None:\n        box_type_3d = dict()\n\n    # create a new logger"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # The default logger\n    if logger is None:\n        logger = print_log\n    # The evaluation results\n    ret = {}\n\n    # The list of all categories\n    cats = list(label2cat.values())\n    # The number of categories\n    num_cats = len(cats)\n    # The number of IoU thresholds\n    num_ious = len(metric)\n\n    # The number of ground truth annotations\n    num_gt = 0\n    # The number of detection annotations\n    num_dt = 0\n    # The number of ground truth annotations for each category\n    num_gt_cat = [0] * num_cats\n    # The number of detection annotations for each category\n    num_dt_cat = [0] * num_cats\n    # The number of detection annotations for each category and IoU threshold\n    num_dt_iou = [0] * num_ious\n    # The number of true positive (TP) detection annotations for each category and IoU threshold\n    num_tp_iou = [0] * num_ious\n    # The number of false positive (FP) detection annotations for each category and IoU threshold\n    num_fp_iou = [0] * num_ious\n    # The number of false negative (FN) ground truth annotations for each category and IoU threshold\n    num_fn_iou = [0] * num_ious\n\n    # The number of ground truth annotations for each category and IoU threshold\n    num_gt_iou = [0] * num_ious\n    # The number of true positive (TP) ground truth annotations for each category and IoU threshold\n    num_tp_iou = [0] * num_ious\n    # The number of false positive (FP) ground truth annotations for each category and IoU threshold\n    num_fp_iou = [0] * num_ious\n\n    # The number of ground truth annotations for each category and IoU threshold\n    num_gt_iou = [0] * num_ious\n    # The number of true positive (TP) ground truth annotations for each category and IoU threshold\n    num_tp_iou = [0] * num_ious\n    # The number of false positive (FP) ground truth annotations for each category and IoU threshold"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    mAP = {}\n    mAR = {}\n    if box_type_3d is not None:\n        gt_annos = box_type_3d.to_3d_bboxes(gt_annos, box_mode_3d)\n        dt_annos = box_type_3d.to_3d_bboxes(dt_annos, box_mode_3d)\n\n    if isinstance(metric, (list, tuple)):\n        mAP_list = []\n        mAR_list = []\n        for iou_thresh in metric:\n            mAP_list.append(compute_ap_3d(gt_annos, dt_annos, iou_thresh))\n            mAR_list.append(compute_ar_3d(gt_annos, dt_annos, iou_thresh))\n        mAP = np.array(mAP_list).mean(axis=0)\n        mAR = np.array(mAR_list).mean(axis=0)\n    else:\n        mAP = compute_ap_3d(gt_annos, dt_annos, metric)\n        mAR = compute_ar_3d(gt_annos, dt_annos, metric)\n\n    # print_table(mAP, label2cat, logger)\n    # print_table(mAR, label2cat, logger)\n    return mAP, mAR\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # 1. convert 3D bounding boxes to 2D bounding boxes\n    if box_type_3d is not None and box_mode_3d is not None:\n        print_log(\n            'Converting 3D bounding boxes to 2D bounding boxes ...', logger)\n        gt_annos = box_type_3d.convert_to_2d(gt_annos, box_mode_3d)\n        dt_annos = box_type_3d.convert_to_2d(dt_annos, box_mode_3d)\n\n    # 2. compute mAP and mAR\n    mAP, mAR = eval_map_recall(dt_annos, gt_annos, metric)\n    # 3. create a table for logging\n    table_data = []\n    table_data.append(['Class', 'AP', 'AR'])\n    for i in range(len(metric)):\n        for label in label2cat:\n            table_data.append([label2cat[label], mAP[i][label], mAR[i][label]])\n\n    table_data.append(['mAP', np.mean(np.array(mAP)), np.nan])\n    table_data.append(['mAR', np.mean(np.array(mAR)), np.nan])\n    table = AsciiTable(table_data)\n    table.inner_width = 8\n    table.header_row_border_length = 12\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n    table.inner_row_border_length = 10\n\n    # 4. print the table\n    print_log(table.table, logger)\n\n    return mAP, mAR"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # sort the detection annotations by score\n    dt_annos.sort_by_score()\n\n    # evaluate each class\n    ret_values = {}\n    for label in gt_annos[0]['annos']:\n        ret_values[label] = eval_det_cls(\n            dt_annos[label], gt_annos[label], metric)\n\n    # compute mAP and mAR\n    mAP = []\n    mAR = []\n    for iou_idx, thresh in enumerate(metric):\n        mAP.append(np.array([ret_values[l][iou_idx][2] for l in gt_annos[0]['annos']]))\n        mAR.append(np.array([ret_values[l][iou_idx][1] for l in gt_annos[0]['annos']]))\n\n    mAP = np.mean(mAP, axis=0)\n    mAR = np.mean(mAR, axis=0)\n    mAP = np.round(mAP, 3)\n    mAR = np.round(mAR, 3)\n\n    # print the evaluation results\n    if logger is None:\n        logger = print_log\n    table_data = [\n        ['class', 'AP', 'AR', 'AP@0.5', 'AR@0.5', 'AP@0.7', 'AR@0.7']\n    ]\n\n    for label in gt_annos[0]['annos']:\n        table_data.append([\n            label2cat[label],\n            ret_values[label][0][2],\n            ret_values[label][1][2],\n            mAP[0],\n            mAR[0],\n            mAP[1],\n            mAR[1]\n        ])\n\n    table = AsciiTable(table_data)\n    table.auto_convert_numeric_columns()\n    logger.info(table.table)\n\n    return {\n        'mAP': mAP,\n        'mAR': mAR,\n        'ret_values': ret_values\n    }"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # get the number of classes\n    num_classes = len(label2cat)\n\n    # initialize the evaluation results\n    class_ap = [0] * num_classes\n    class_ar = [0] * num_classes\n    class_recall = [0] * num_classes\n    class_precision = [0] * num_classes\n    ap_overall = 0\n    ar_overall = 0\n    recall_overall = 0\n    precision_overall = 0\n\n    # evaluate each class\n    for i in range(num_classes):\n        if gt_annos[i] is None or len(gt_annos[i]) == 0:\n            class_ap[i] = 0\n            class_ar[i] = 0\n            class_recall[i] = 0\n            class_precision[i] = 0\n            continue\n\n        # get the detections and ground truth for the current class\n        dt_annos_cls = [x for x in dt_annos if x['category_id'] == i+1]\n        gt_annos_cls = gt_annos[i]\n\n        # compute the evaluation results\n        recall, precision, ap = eval_det_cls(dt_annos_cls,\n                                            gt_annos_cls,\n                                            metric)\n\n        # compute the overall evaluation results\n        ap_overall += ap[0]\n        recall_overall += recall[0]\n        precision_overall += precision[0]\n\n        # log the evaluation results\n        class_ap[i] = ap[0]\n        class_ar[i] = recall[0]\n        class_recall[i] = recall\n        class_precision[i] = precision\n\n    # compute the overall evaluation results\n    ap_overall /= len(metric)\n    recall_overall /= len(metric)\n    precision_overall /= len(metric)\n\n    # create the table\n    table_data = [['class', 'AR', 'AP', 'recall', 'precision']]\n    for i in range(num_classes):\n        table_data.append([label2cat[i], class_ar[i], class_ap[i],\n                           class_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # If the logger is not set to None, the evaluation results are printed to the console.\n    if logger is not None:\n        logger.info(\"Evaluating detections...\")\n\n    # If the box_type_3d is not set to None, the 3D bounding boxes are converted to the specified type.\n    if box_type_3d is not None:\n        dt_annos = box_type_3d.convert_to_type(dt_annos, box_mode_3d)\n\n    # Calculate the mAP for each class and IoU threshold.\n    recall, precision, ap = eval_map_recall(dt_annos, gt_annos, metric)\n\n    # Calculate the overall mAP and mAR.\n    mAP = np.nanmean(np.array(ap))\n    mAR = np.nanmean(np.array(recall[0].values()))\n\n    # Organize the evaluation results into a dictionary.\n    results = {}\n    for label, cat in label2cat.items():\n        results[label] = {}\n        for iou_idx, thresh in enumerate(metric):\n            results[label][f\"AP@{thresh:.2f}\"] = ap[iou_idx][label]\n            results[label][f\"AR@{thresh:.2f}\"] = recall[iou_idx][label]\n\n    # Print the evaluation results in a formatted table.\n    if logger is not None:\n        table_data = [[\"AP\", \"AR\", \"mAP\", \"mAR\"]]\n        for label in sorted(label2cat.keys()):\n            table_data.append(\n                [\n                    f\"{results[label][f'AP@{metric[0]:.2f}']:.4f}\",\n                    f\"{results[label][f'AR@{metric[0]:.2f}']:.4f}\",\n                    f\"{results[label][f'AP@{metric[0]:.2f}']:.4f}\",\n                    f\"{results[label][f'AR@{metric[0]:.2f}']:.4f}\",\n                ]\n            )\n        table = AsciiTable(table_data)\n        print_log(\n            table.get_data_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert isinstance(metric, list)\n    assert isinstance(label2cat, dict)\n    assert isinstance(logger, (str, type(None)))\n    assert isinstance(box_type_3d, type(None)) or isinstance(\n        box_type_3d, type(\n            'box_type_3d'))\n    assert isinstance(box_mode_3d, type(None)) or isinstance(\n        box_mode_3d, str)\n\n    if box_type_3d:\n        box_type_3d = type(box_type_3d)\n        if box_mode_3d:\n            box_mode_3d = str(box_mode_3d)\n        else:\n            box_mode_3d = 'voxel'\n\n    gt_annos = [\n        anno.to_dict() for anno in gt_annos\n    ]  # convert to dict\n    dt_annos = [anno.to_dict() for anno in dt_annos]\n\n    # 2D\n    if not box_type_3d:\n        recall, precision, ap = eval_map_recall(\n            dt_annos, gt_annos, metric)\n\n        # convert to dict\n        ap_cat = {}\n        for cat_id in ap[0].keys():\n            ap_cat[label2cat[cat_id]] = ap[0][cat_id]\n\n    # 3D\n    else:\n        import nuscenes3d.utils.data.data_utils as data_utils\n        # convert to box_type_3d\n        dt_annos = data_utils.boxes_to_type(dt_annos, box_type_3d)\n        gt_annos = data_utils.boxes_to_type(gt_annos, box_type_3d)\n\n        # convert to box_mode_3d\n        dt_annos = data_utils.boxes_to_mode(dt_annos, box_mode_3d)\n        gt_annos = data_utils.boxes_to_mode(gt_annos, box_mode_3d)\n\n        recall, precision, ap = data"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # TODO: add support for multiple IoU thresholds\n    # TODO: add support for 3D bounding boxes\n    if box_type_3d is None:\n        box_type_3d = box_type\n    if box_mode_3d is None:\n        box_mode_3d = box_mode\n\n    # convert to bounding box format\n    if box_type_3d == 'center_size':\n        gt_annos = box_3d_to_box(gt_annos, box_mode_3d)\n        dt_annos = box_3d_to_box(dt_annos, box_mode_3d)\n    elif box_type_3d == 'corners':\n        gt_annos = box_3d_to_box(gt_annos, 'corners')\n        dt_annos = box_3d_to_box(dt_annos, 'corners')\n\n    # compute APs\n    mAPs = compute_ap(gt_annos, dt_annos, metric, label2cat)\n    mARs = compute_ar(gt_annos, dt_annos, metric, label2cat)\n\n    # print mAP\n    if logger is not None:\n        table_data = [\n            ['class', 'AP', 'AR', 'AP@.5', 'AP@.75', 'AR@.5', 'AR@.75']\n        ]\n        for cat_id, cat_name in label2cat.items():\n            if cat_id not in mAPs:\n                continue\n            table_data.append([cat_name,\n                               mAPs[cat_id],\n                               mARs[cat_id],\n                               mAPs[cat_id][0],\n                               mAPs[cat_id][1],\n                               mARs[cat_id][0],\n                               mARs[cat_id][1]])\n        table_data.append(['', '', '', '', '', '', ''])\n        table_data.append(['mAP', mAPs[0], mARs[0], mAPs[0][0], mAPs[0][1],"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if box_type_3d is not None:\n        if box_mode_3d is None:\n            raise ValueError('box_mode_3d must be specified when box_type_3d is not None')\n    else:\n        box_type_3d = None\n    # create the evaluation result dict\n    eval_results = {\n        'class_iouk_ar': {},\n        'class_iouk_ap': {},\n        'iouk_ar': np.zeros(len(metric)),\n        'iouk_ap': np.zeros(len(metric))\n    }\n\n    # create a table to log the results\n    table_header = ['class', 'AR', 'AP']\n    table_data = []\n    for iouk in metric:\n        table_header.append(f'iou={iouk:.2f}')\n    table_data.append(table_header)\n\n    # compute the evaluation results\n    for cat_id, cat_name in label2cat.items():\n        # compute the evaluation results for each class\n        eval_results[f'class_iouk_ar'][cat_name] = eval_class_recall(\n                gt_annos, dt_annos, cat_id, metric)\n        eval_results[f'class_iouk_ap'][cat_name] = eval_class_ap(\n                gt_annos, dt_annos, cat_id, metric)\n\n        # log the results\n        table_data.append([cat_name] + list(eval_results[f'class_iouk_ar'][cat_name]))\n        table_data.append([cat_name] + list(eval_results[f'class_iouk_ap'][cat_name]))\n\n        # compute the overall evaluation results\n        eval_results['iouk_ar'] += eval_results[f'class_iouk_ar'][cat_name]\n        eval_results['iouk_ap'] += eval_results[f'class_iouk_ap'][cat_name]\n\n    # log the overall evaluation results\n    table_data.append(['overall'] + list(eval_results['iouk_ar']))\n    table_data."}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if metric is None:\n        metric = [0.25, 0.5, 0.75]\n    if box_type_3d is None:\n        box_type_3d = 'LiDARBox3D'\n\n    mAP = {}\n    mAR = {}\n    for iou in metric:\n        mAP[iou] = 0\n        mAR[iou] = 0\n\n    # Collect all gt and dt annotations for each class\n    gt_annos = [\n        a for a in gt_annos if a['iscrowd'] == 0 and a['isdifficult'] == 0\n    ]\n    dt_annos = [a for a in dt_annos if a['iscrowd'] == 0]\n    for classname in label2cat:\n        mAP[iou] += 0\n        mAR[iou] += 0\n\n    for classname in label2cat:\n        gt_annos_c = [a for a in gt_annos if a['label'] == classname]\n        dt_annos_c = [a for a in dt_annos if a['label'] == classname]\n        if len(gt_annos_c) == 0 or len(dt_annos_c) == 0:\n            mAP[iou] += 0\n            mAR[iou] += 0\n            continue\n\n        # Compute precision and recall for each IoU threshold\n        (recall, precision, ap) = eval_det_cls(dt_annos_c, gt_annos_c, [iou])\n        mAP[iou] += ap[0]\n        mAR[iou] += recall[0][0, -1]\n\n    if logger is not None:\n        table_data = [['Class', 'AP', 'AR']]\n        for iou in metric:\n            table_data += [['%s' % label2cat[label],\n                           '%.4f' % mAP[iou], '%.4f' % mAR[iou]]\n        table = AsciiTable(table_data)\n        print_log(table.table, logger)\n\n    return mAP, mAR\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if box_type_3d is None:\n        box_type_3d = box_type_3d_default\n    if box_mode_3d is None:\n        box_mode_3d = box_mode_3d_default\n\n    assert len(metric) > 0, 'metric must not be empty'\n    assert isinstance(metric, list)\n\n    # get all categories\n    # class_names = list(gt_annos[0].keys())\n    class_names = list(gt_annos[0].keys())\n\n    # convert to 2D boxes\n    gt_annos = [box_type_3d.to_2d(annos, box_mode_3d) for annos in gt_annos]\n    dt_annos = [box_type_3d.to_2d(annos, box_mode_3d) for annos in dt_annos]\n\n    # get all classes\n    class_names = list(gt_annos[0].keys())\n\n    # create a dict for the evaluation results\n    result = {\n        'class_name': [],\n        'precision': [],\n        'recall': [],\n        'AP': [],\n    }\n    for iou_idx, thresh in enumerate(metric):\n        result[f'AP@{iou_idx}'] = []\n\n    # compute evaluation results for each class\n    for label in class_names:\n        # get gt and dt for the class\n        gt = [anno[label] for anno in gt_annos]\n        dt = [anno[label] for anno in dt_annos]\n        # compute evaluation results\n        recall, precision, ap = eval_det_cls(dt, gt, [thresh])\n        # add to result\n        result['class_name'].append(label)\n        result['precision'].append(precision[0])\n        result['recall'].append(recall[0])\n        result['AP'].append(ap[0])\n        for iou_idx, thresh in enumerate(metric):\n            result[f'AP@{iou_idx}'].append(ap[iou_idx][0])\n\n    # compute mAP and mAR\n    "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert isinstance(metric, list)\n    assert len(metric) > 0\n    assert isinstance(label2cat, dict)\n\n    if logger is None:\n        from .utils.logger import get_root_logger\n        logger = get_root_logger()\n\n    assert isinstance(gt_annos, list)\n    assert isinstance(dt_annos, list)\n    assert isinstance(label2cat, dict)\n    assert isinstance(gt_annos, list)\n\n    # get the number of categories\n    num_cat = len(label2cat)\n\n    # get the number of images\n    num_img = len(gt_annos)\n    assert num_img == len(dt_annos)\n\n    # prepare the table data\n    table_data = [['class', 'AP', 'AR', 'AP (11-points)']]\n\n    # prepare the evaluation results\n    ret = {'class_aps': [[] for i in range(num_cat)],\n           'class_ars': [[] for i in range(num_cat)],\n           'class_ap11': [[] for i in range(num_cat)],\n           'mAP': 0.0,\n           'mAR': 0.0}\n    for iou in metric:\n        # compute the average precisions and recalls\n        class_aps = [[] for i in range(num_cat)]\n        class_ars = [[] for i in range(num_cat)]\n        for cat in range(num_cat):\n            # get the gt and dt annotations for the current category\n            gt_cat = [ann for ann in gt_annos if ann['label'] == cat]\n            dt_cat = [ann for ann in dt_annos if ann['label'] == cat]\n            if len(gt_cat) > 0:\n                # compute the average precision and recall\n                recall, precision, ap = eval_det_cls(\n                    dt_cat, gt_cat, iou)\n                class_aps[cat].append(ap)\n                class_ars[cat].append(np.mean(recall))\n            else:\n                class_aps[cat].append(0)\n                class_ars"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # check inputs\n    assert isinstance(gt_annos, list)\n    assert isinstance(dt_annos, list)\n    assert isinstance(metric, list)\n    assert isinstance(label2cat, dict)\n    assert isinstance(logger, (str, type(None)))\n    assert isinstance(box_type_3d, type(None))\n    assert isinstance(box_mode_3d, str)\n    assert len(metric) > 0\n\n    # sort the detection annotations by scores\n    dt_annos.sort_by_score()\n    # construct the evaluation results dictionary\n    eval_results = {\n        'class_mAP': np.zeros(len(metric), dtype=np.float32),\n        'class_mAR': np.zeros(len(metric), dtype=np.float32)\n    }\n\n    # compute the class-wise evaluation results\n    for label, cat in label2cat.items():\n        eval_results[cat] = {'AP': np.zeros(len(metric), dtype=np.float32),\n                             'AR': np.zeros(len(metric), dtype=np.float32)}\n\n    # compute the overall evaluation results\n    for i, iou_thr in enumerate(metric):\n        # compute recall and precision\n        recall, precision, ap = eval_det_cls(\n            dt_annos, gt_annos, iou_thr)\n        # compute mAP\n        eval_results['class_mAP'][i] = np.mean(ap)\n        for label, cat in label2cat.items():\n            eval_results[cat]['AP'][i] = ap[label]\n        # compute mAR\n        eval_results['class_mAR'][i] = np.mean(recall)\n        for label, cat in label2cat.items():\n            eval_results[cat]['AR'][i] = recall[label]\n\n        # log evaluation results\n        if logger is not None:\n            if logger == 'console':\n                # print the evaluation results\n                print_log(\n                    f'class {cat} - AP: {ap:.3f}, AR: {recall:.3f}, iou: {iou"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert metric is not None\n    assert len(metric) > 0\n\n    # get the class names\n    classes = [label2cat[str(label)] for label in gt_annos[0]['annos'].keys()]\n\n    # initialize the evaluation results\n    ret = {\n        'class_ap': [],\n        'class_ar': [],\n        'mAP': 0.0,\n        'mAR': 0.0\n    }\n\n    # get the number of classes\n    num_classes = len(classes)\n\n    # loop over the different IoU thresholds\n    for iou_idx, iou_thr in enumerate(metric):\n\n        # initialize the recall and precision\n        recall = np.zeros((num_classes, 1))\n        precision = np.zeros((num_classes, 1))\n\n        # loop over the classes\n        for cls_idx in range(num_classes):\n            # get the current class name\n            class_name = classes[cls_idx]\n\n            # get the current class-wise gt and dt annotations\n            gt_annos_class = [anno['annos'][class_name] for anno in gt_annos]\n            dt_annos_class = [anno['annos'][class_name] for anno in dt_annos]\n\n            # compute the recall and precision for the current class\n            recall_class, precision_class = eval_det_cls(\n                    dt_annos_class, gt_annos_class, iou_thr)\n            recall[cls_idx] = np.array(recall_class)\n            precision[cls_idx] = np.array(precision_class)\n\n        # compute the average recall and precision\n        ar = average_precision(recall, precision, '11points')\n        ap = average_precision(recall, precision, 'area')\n\n        # append the class-wise evaluation results\n        ret['class_ar'].append(ar)\n        ret['class_ap'].append(ap)\n\n    # compute the overall mAP and mAR\n    ar = np.array(ret['class_ar'])\n    ap = np.array(ret['class_ap'])\n    ret['mAR'] = ar"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is not None and not isinstance(logger, str):\n        assert hasattr(logger, 'info')\n\n    if box_type_3d is None:\n        box_type_3d = box_type_3d_from_mode\n    else:\n        assert callable(box_type_3d)\n    if box_mode_3d is None:\n        box_mode_3d = box_mode_3d_from_mode\n    else:\n        assert callable(box_mode_3d)\n    # TODO: support other box types and modes\n    assert isinstance(metric, list)\n    assert len(metric) > 0\n    assert isinstance(label2cat, dict)\n    assert len(label2cat) > 0\n    assert isinstance(gt_annos, list)\n    assert isinstance(dt_annos, list)\n    assert len(gt_annos) == len(dt_annos)\n    assert len(gt_annos) > 0\n    assert len(gt_annos[0]) > 0\n    assert all(isinstance(g, dict) for g in gt_annos)\n    assert all(isinstance(d, dict) for d in dt_annos)\n\n    # check if the detection results contain all the ground truths\n    gt_labels = set(\n        [g['label'] for g in gt_annos if 'label' in g.keys()])\n    dt_labels = set(\n        [d['label'] for d in dt_annos if 'label' in d.keys()])\n    if len(gt_labels) != len(dt_labels):\n        print_log(\n            'The detection results do not contain all the ground truths. '\n            'This is not supported in the current implementation.')\n        return {}\n\n    # convert 3D boxes to 2D boxes\n    gt_annos = [\n        box_type_3d(g, box_mode_3d) for g in gt_annos\n    ]\n    dt_annos = [\n        box_type_3d(d, box_mode_3d) for d in dt_annos\n    ]\n\n    # calculate AP and AR"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # compute APs\n    # compute mAPs\n    ap = {}\n    ap_all = {}\n    for iou_idx, thresh in enumerate(metric):\n        ap[iou_idx] = 0.0\n        ap_all[iou_idx] = 0.0\n        for cat in label2cat.keys():\n            if cat not in gt_annos:\n                continue\n            ap[iou_idx], prec, rec = eval_det_cls(\n                dt_annos[cat], gt_annos[cat], thresh)\n            ap_all[iou_idx] += ap[iou_idx]\n        ap_all[iou_idx] /= len(label2cat)\n    # compute mAP\n    mAP = np.mean(ap_all[iou_idx])\n    mAR = np.mean(ap)\n    ret = {'mAP': mAP, 'mAR': mAR, 'mAP_all': ap_all[iou_idx]}\n    # log results\n    if logger is None:\n        logger = print_log\n        logger.info('Evaluation results: ')\n    else:\n        logger.info('Evaluation results (logger): ')\n    for iou_idx in ap_all.keys():\n        logger.info('IoU threshold: {}'.format(metric[iou_idx]))\n        logger.info('AP: {}'.format(ap_all[iou_idx]))\n    logger.info('mAP: {}'.format(mAP))\n    logger.info('mAR: {}'.format(mAR))\n\n    return ret\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if isinstance(metric, str):\n        metric = [float(metric)]\n    if len(metric) != 3:\n        raise ValueError(\n            'metric should be a float or a list of three floats')\n    if not isinstance(label2cat, dict):\n        raise TypeError(\n            'label2cat should be a dictionary mapping labels to categories')\n    if not isinstance(logger, (str, type(None)) and not isinstance(\n            logger, type(print_log)):\n        raise TypeError(\n            'logger should be a string or a logging.Logger instance')\n\n    if logger is None:\n        logger = print_log\n\n    if box_type_3d is None:\n        box_type_3d = dict(\n            point_based='Point',\n            voxel_based='Voxel',\n            corner_based='Corner')\n    if box_mode_3d is None:\n        box_mode_3d = dict(\n            point_based='point',\n            voxel_based='voxel',\n            corner_based='corner')\n\n    # Compute the evaluation results for each category\n    results = {}\n    for category in label2cat.keys():\n        # Get the ground truth and detection annotations\n        gt_annos_cat = [\n            ann for ann in gt_annos if ann['category'] == category\n        ]\n        dt_annos_cat = [\n            ann for ann in dt_annos if ann['category'] == category\n        ]\n\n        # Compute the evaluation results\n        ret = eval_det_cls(dt_annos_cat, gt_annos_cat, metric)\n        results[category] = ret\n\n    # Calculate the overall mAP\n    mAP = 0\n    for i, thresh in enumerate(metric):\n        mAP += average_precision(\n            np.hstack([res[0] for res in results.values()]),\n            np.hstack([res[1] for res in results.values()]),\n            'area')\n        logger.info(\n            f'mAP@{0:.2f}: {mAP[i]:.2f}')\n\n    # Print the evaluation results\n    if logger is not None:\n        table_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert gt_annos is not None\n    assert dt_annos is not None\n    assert metric is not None\n    assert label2cat is not None\n\n    # Sort the detections and ground truth by the IoU threshold\n    dt_annos = sorted(dt_annos, key=lambda x: x['score'], reverse=True)\n    gt_annos = sorted(gt_annos, key=lambda x: x['score'], reverse=True)\n\n    # Get the number of ground truth instances\n    num_gt = sum(1 for anno in gt_annos if anno['is_crowd'] == False)\n    if num_gt == 0:\n        mAP = [0. for _ in metric]\n    else:\n        mAP = []\n        for thresh in metric:\n            # Compute the average precision and recall\n            AP, AR = eval_det_cls(dt_annos, gt_annos, thresh)\n\n            # Get the average precision and recall\n            AP = np.nanmean(AP)\n            AR = np.nanmean(AR)\n\n            mAP.append(AP)\n        mAP = np.nanmean(mAP)\n\n    # Get the table for logging\n    table = [\n        ['label', 'AP', 'AR', 'mAP', 'mAR'],\n        ['----------------', '----', '----', '----', '----']\n    ]\n\n    for i, label in enumerate(label2cat):\n        if label in gt_annos:\n            AP = mAP[i]\n            AR = AR[i]\n            table.append([label, AP, AR, mAP, AR])\n        else:\n            table.append([label, 0, 0, 0, 0])\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n        logger.info(AsciiTable(table))\n\n    return dict(mAP=mAP)"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert metric is not None\n    assert box_type_3d is not None\n    assert box_mode_3d is not None\n\n    # build the eval\n    if not isinstance(metric, list):\n        metric = [metric]\n\n    # initialize eval\n    eval_results = {\n        'class_eval': {k: {'ap': [], 'ar': []} for k in label2cat.keys()}\n        }\n    eval_results['mAP'] = {}\n    eval_results['mAR'] = {}\n\n    # evaluate each class\n    for class_id, cls_name in enumerate(label2cat.keys()):\n        # gt_annos_cls = [a for a in gt_annos if a['category_id'] == class_id]\n        gt_annos_cls = [a for a in gt_annos if a['category'] == cls_name]\n        dt_annos_cls = [a for a in dt_annos if a['category'] == cls_name]\n\n        # compute metrics\n        for iou_idx, iou in enumerate(metric):\n            # evaluate\n            recalls, precisions, ap = eval_det_cls(dt_annos_cls,\n                                                   gt_annos_cls, [iou])\n            ar = average_precision(\n                recalls, precisions, mode='11points')\n            # save results\n            eval_results['class_eval'][cls_name]['ap'].append(ap)\n            eval_results['class_eval'][cls_name]['ar'].append(ar)\n\n        # compute mean AP and AR\n        eval_results['mAP'][iou] = np.mean(\n            np.array(eval_results['class_eval'][cls_name]['ap']))\n        eval_results['mAR'][iou] = np.mean(\n            np.array(eval_results['class_eval'][cls_name]['ar']))\n\n    # log\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log(logger)\n        for iou, mAP in eval_results['mAP'].items():\n            logger.info('mAP@iou=%0."}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from .box_3d import LiDAR3DBox\n        return LiDAR3DBox, 'LiDAR'\n    elif box_type == 'Camera':\n        from .box_3d import Camera3DBox\n        return Camera3DBox, 'Camera'\n    elif box_type == 'Depth':\n        from .box_3d import Depth3DBox\n        return Depth3DBox, 'Depth'\n    else:\n        raise ValueError(f'Unknown box type: {box_type}')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from .lidar_box3d import LiDARBox3D\n        return LiDARBox3D, 'LiDAR'\n    elif box_type == 'Camera':\n        from .camera_box3d import CameraBox3D\n        return CameraBox3D, 'Camera'\n    elif box_type == 'Depth':\n        from .depth_box3d import DepthBox3D\n        return DepthBox3D, 'Depth'\n    else:\n        raise ValueError(\n            f'Unrecognized box type: {box_type}. '\n            'It should be one of \"LiDAR\", \"Camera\", or \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type.lower() == 'lidar':\n        return 'LiDAR', 'LiDAR'\n    elif box_type.lower() == 'camera':\n        return 'LiDAR', 'Camera'\n    elif box_type.lower() == 'depth':\n        return 'LiDAR', 'Depth'\n    else:\n        raise ValueError(f'box_type {box_type} is not supported.')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # pylint: disable=too-many-return-statements,too-many-branches\n    if box_type == 'LiDAR':\n        from .box3d.li_dar_box import LiDARBox\n        return LiDARBox, 'LiDAR'\n\n    if box_type == 'Camera':\n        from .box3d.ca_mera_box import CameraBox\n        return CameraBox, 'Camera'\n\n    if box_type == 'Depth':\n        from .box3d.de_pth_box import DepthBox\n        return DepthBox, 'Depth'\n\n    if box_type == 'LiDAR2D':\n        from .box3d.li_dar2d_box import LiDAR2DBox\n        return LiDAR2DBox, 'LiDAR'\n\n    if box_type == 'Camera2D':\n        from .box3d.ca_mera2d_box import Camera2DBox\n        return Camera2DBox, 'Camera'\n\n    if box_type == 'Depth2D':\n        from .box3d.de_pth2d_box import Depth2DBox\n        return Depth2DBox, 'Depth'\n\n    if box_type == 'LiDAR3D':\n        from .box3d.li_dar3d_box import LiDAR3DBox\n        return LiDAR3DBox, 'LiDAR'\n\n    if box_type == 'Camera3D':\n        from .box3d.ca_mera3d_box import Camera3DBox\n        return Camera3DBox, 'Camera'\n\n    if box_type == 'Depth3D':\n        from .box3d.de_pth3d_box import Depth3DBox\n        return Depth3DBox, 'Depth'\n\n    if box_type == 'LiDAR3D2D':\n        from .box3d.li_dar3d2d_box import LiDAR3D2DBox\n        return LiDAR3D2DBox, 'LiDAR'\n\n    if box_type == 'Camera3D2D':\n        from .box3d.ca_mera3d2d_box import Camera3D2DBox\n        return Camera3D2DBox, 'Camera"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # TODO: refactor this function to a more general one\n    if box_type.lower() == 'lidar':\n        from mmdet3d.core.bbox import LiDARBox3D\n        return LiDARBox3D, 'LiDAR'\n    elif box_type.lower() == 'camera':\n        from mmdet3d.core.bbox import CameraBox3D\n        return CameraBox3D, 'Camera'\n    elif box_type.lower() == 'depth':\n        from mmdet3d.core.bbox import DepthBox3D\n        return DepthBox3D, 'Depth'\n    else:\n        raise ValueError(\n            f'The box type {box_type} is not supported.')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Get the 3D box type and mode\n    if box_type == 'LiDAR':\n        from .box3d_lidar import *\n        return Box3DLidar, 'LiDAR'\n    elif box_type == 'Camera':\n        from .box3d_camera import *\n        return Box3DCamera, 'Camera'\n    elif box_type == 'Depth':\n        from .box3d_depth import *\n        return Box3DDepth, 'Depth'\n    else:\n        raise ValueError(\n            f'Unrecognized box type: {box_type}. '\n            f'Supported types include \"LiDAR\", \"Camera\", and \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDAR3DBoxes', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'Camera3DBoxes', 'Camera'\n    elif box_type == 'Depth':\n        return 'Depth3DBoxes', 'Depth'\n    else:\n        raise ValueError(f'box_type {box_type} is not supported!')\n\n    return None, None\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.boxes.lidar import LiDAR3DBoxes\n        return LiDAR3DBoxes, 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.boxes.camera import Camera3DBoxes\n        return Camera3DBoxes, 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.boxes.depth import Depth3DBoxes\n        return Depth3DBoxes, 'depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}.')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if isinstance(box_type, str):\n        if box_type.lower() == 'lidar':\n            box_type = 'LiDAR'\n        elif box_type.lower() == 'camera':\n            box_type = 'Camera'\n        elif box_type.lower() == 'depth':\n            box_type = 'Depth'\n        else:\n            raise ValueError(\n                f'Unrecognized box type {box_type}. '\n                'It should be one of \"LiDAR\", \"Camera\", or \"Depth\".')\n\n    if isinstance(box_type, type) and issubclass(box_type, Box3D):\n        box_type = box_type\n    else:\n        raise ValueError(\n            f'Unrecognized box type {box_type}. '\n            'It should be a string or a class.')\n    return box_type\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    assert isinstance(box_type, str), \\\n        f'box_type should be a string, got {box_type}'\n    if box_type == 'LiDAR':\n        from .box3d_lidar import *\n        return LiDAR3DBox, 'LiDAR'\n    elif box_type == 'Camera':\n        from .box3d_camera import *\n        return Camera3DBox, 'Camera'\n    elif box_type == 'Depth':\n        from .box3d_depth import *\n        return Depth3DBox, 'Depth'\n    else:\n        raise ValueError(f'Unknown box type {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Convert the box type to lower-case for consistency\n    box_type = box_type.lower()\n\n    if box_type == 'lidar':\n        from .box3d_types import LiDARBox3D\n        return LiDARBox3D, 'LiDAR'\n    elif box_type == 'camera':\n        from .box3d_types import CameraBox3D\n        return CameraBox3D, 'Camera'\n    elif box_type == 'depth':\n        from .box3d_types import DepthBox3D\n        return DepthBox3D, 'Depth'\n    elif box_type == 'voxel':\n        from .box3d_types import VoxelBox3D\n        return VoxelBox3D, 'LiDAR'\n    elif box_type == 'depth_voxel':\n        from .box3d_types import DepthVoxelBox3D\n        return DepthVoxelBox3D, 'Depth'\n    else:\n        raise ValueError(f'Unknown box type: {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # TODO: Use the new box class\n    if box_type == 'LiDAR':\n        from .box_3d.livar import LiDAR3DBox\n        mode = 'LiDAR'\n    elif box_type == 'Camera':\n        from .box_3d.camera import Camera3DBox\n        mode = 'Camera'\n    elif box_type == 'Depth':\n        from .box_3d.depth import Depth3DBox\n        mode = 'Depth'\n    else:\n        raise ValueError(f'Not recognized box type: {box_type}')\n    return LiDAR3DBox, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from .box3d_lidar import LiDARBox\n        return LiDARBox, 'LiDAR'\n    elif box_type == 'Camera':\n        from .box3d_camera import CameraBox\n        return CameraBox, 'Camera'\n    elif box_type == 'Depth':\n        from .box3d_depth import DepthBox\n        return DepthBox, 'Depth'\n    else:\n        raise ValueError(\n            f'Unknown box type: {box_type}, '\n            'it should be one of \"LiDAR\", \"Camera\", or \"Depth\".')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDAR3DBoxes', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'Camera3DBoxes', 'Camera'\n    elif box_type == 'Depth':\n        return 'Depth3DBoxes', 'Depth'\n    else:\n        raise ValueError(f'Unknown box type: {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = str(box_type).lower()\n    if box_type in [\"lidar\", \"lidar3d\"]:\n        return (\n            mmdet3d.models.roi_heads.bbox.LiDAR3DBoxes, \"LiDAR\")\n    elif box_type in [\"camera\", \"camera3d\"]:\n        return (mmdet3d.models.roi_heads.bbox.Camera3DBoxes, \"Camera\")\n    elif box_type in [\"depth\", \"depth3d\"]:\n        return (mmdet3d.models.roi_heads.bbox.Depth3DBoxes, \"Depth\")\n    else:\n        raise ValueError(f\"Unknown box type: '{box_type}'\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return LiDARBox, 'LiDAR'\n    elif box_type == 'Camera':\n        return CameraBox, 'Camera'\n    elif box_type == 'Depth':\n        return DepthBox, 'Depth'\n    else:\n        raise ValueError(\n            f'box_type {box_type} is not supported')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from .box3d_types.liDAR import LiDARBox3D\n        box_class = LiDARBox3D\n        mode = 'liDAR'\n    elif box_type == 'Camera':\n        from .box3d_types.camera import CameraBox3D\n        box_class = CameraBox3D\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from .box3d_types.depth import DepthBox3D\n        box_class = DepthBox3D\n        mode = 'depth'\n    else:\n        raise ValueError(f'box_type {box_type} is not recognized')\n\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = str(box_type).lower().strip()\n    if box_type == 'lidar':\n        from .box_3d_lidar import *\n        return Box3DLidar, BoxMode.LIDAR\n    elif box_type == 'camera':\n        from .box_3d_camera import *\n        return Box3DCamera, BoxMode.CAMERA\n    elif box_type == 'depth':\n        from .box_3d_depth import *\n        return Box3DDepth, BoxMode.DEPTH\n    else:\n        raise ValueError(\n            f'The box type {box_type} is not supported.')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n    if box_type == 'LIDAR':\n        return 'LiDARBox3D', 'LiDAR'\n    elif box_type == 'CAMERA':\n        return 'CameraBox3D', 'Camera'\n    elif box_type == 'DEPTH':\n        return 'DepthBox3D', 'Depth'\n    else:\n        raise ValueError(\n            f'Unknown box type {box_type}. '\n            'Please use one of LiDAR, Camera, Depth.'\n        )\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # We use a dictionary to map the box type to the corresponding 3D box class and mode.\n    box_type_to_class = {\n        \"LiDAR\": (mmdet3d.core.bbox.LiDAR3DBox, \"LiDAR\"),\n        \"Camera\": (mmdet3d.core.bbox.Camera3DBox, \"Camera\"),\n        \"Depth\": (mmdet3d.core.bbox.Depth3DBox, \"Depth\")\n    }\n\n    if box_type not in box_type_to_class:\n        raise ValueError(\n            f\"The box type {box_type} is not recognized. Please check \"\n            f\"the input box type and the corresponding 3D box class.\")\n\n    return box_type_to_class[box_type]\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not isinstance(messages, (list, tuple)):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          _encode_message(m) for m in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_message_to_dict(m) for m in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages and not isinstance(messages, (list, tuple, set, frozenset)):\n      raise TypeError('`messages` must be a list, tuple, set, or frozenset')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    messages = messages or []\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    messages = [\n      _encode_message(message) for message in messages\n    ]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages and not isinstance(messages, (list, tuple)):\n      raise TypeError('messages must be a list or tuple of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.role,\n            'content': message.content,\n            'images': [_encode_image(image) for image in message.images or []],\n          } for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_message_to_dict(message) for message in messages or []],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': _encode_messages(messages),\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages and not isinstance(messages, Sequence):\n      raise TypeError('messages must be a sequence of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': _encode_message(messages),\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages and not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          _encode_message(message) for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, (list, tuple)):\n        raise TypeError('messages must be a list or tuple')\n      if not all(isinstance(message, (dict, Message)) for message in messages):\n        raise TypeError('messages must be a list of dicts or Message objects')\n      for message in messages:\n        if message['role'] not in ('user', 'system', 'assistant'):\n          raise RequestError(f'invalid message role: {message[\"role\"]}')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          _encode_message(message) for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n    if messages and not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.role,\n            'content': message.content,\n            'images': [_encode_image(image) for image in message.images or []],\n          }\n          for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not isinstance(messages, (list, tuple)):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n    if messages:\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          _encode_message(message)\n          for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, Sequence):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.role,\n            'content': message.content,\n            'images': [_encode_image(image) for image in message.images],\n          } for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          _encode_message(m)\n          for m in messages or []\n          if m is not None\n          and isinstance(m, dict)\n          and 'role' in m\n          and 'content' in m\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    messages = messages or []\n    if not isinstance(messages, list):\n      raise TypeError(\n        'messages must be a list of Message or dict-like objects, got '\n        f'{type(messages)}'\n      )\n    for message in messages:\n      if not isinstance(message, Message):\n        raise TypeError(\n          f'message must be a Message or dict-like object, got {type(message)}'\n        )\n      if not message.has_required_fields:\n        raise RequestError('message must have a role and content')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.as_dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, (list, tuple, set, frozenset)):\n        raise TypeError('messages must be a list or tuple')\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError('each message in messages must be a dictionary or Message object')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages and not isinstance(messages, (list, tuple)):\n      raise TypeError('must provide a list of messages')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          _to_message(message) for message in messages or []\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/model/{model}/pull',\n      params={\n        'insecure': int(insecure),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/models/{model}/pull',\n      json={},\n      stream=stream,\n      params={'insecure': 'true' if insecure else 'false'},\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/model/{model}/pull',\n      json={\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/pull/{model}',\n      json={\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/pull/{model}',\n      json={\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/model/{model}/pull',\n      json={'insecure': insecure},\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      f'/api/pull/{model}',\n      params={\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    return self._request_stream(\n      'POST',\n      f'v1/generate',\n      model=model,\n      prompt=prompt,\n      system=system,\n      template=template,\n      context=context,\n      stream=stream,\n      raw=raw,\n      format=format,\n      images=images,\n      options=options,\n      keep_alive=keep_alive,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    return self._request_stream(\n      'POST',\n      f'generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'stream': stream,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Missing model')\n    if not prompt:\n      raise RequestError('Missing prompt')\n\n    kwargs = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('post', '/generate', **kwargs)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model parameter is required.')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep-alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      params=params,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model is required.')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n    }\n\n    if images:\n      data['images'] = images\n\n    if options:\n      data['options'] = options\n\n    if keep_alive:\n      data['keep_alive'] = keep_alive\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    return self._request_stream(\n      'post',\n      f'/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n      format=format,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    if not prompt:\n      raise RequestError('Prompt is required')\n\n    if not isinstance(prompt, str):\n      raise RequestError('Prompt must be a string')\n\n    if not isinstance(system, str):\n      raise RequestError('System must be a string')\n\n    if not isinstance(template, str):\n      raise RequestError('Template must be a string')\n\n    if context is not None and not isinstance(context, (tuple, list)):\n      raise RequestError('Context must be a tuple or list')\n\n    if images is not None and not isinstance(images, (tuple, list)):\n      raise RequestError('Images must be a tuple or list')\n\n    if options is not None and not isinstance(options, Options):\n      raise RequestError('Options must be an instance of Options')\n\n    if keep_alive is not None and not isinstance(keep_alive, (str, float)):\n      raise RequestError('Keep-alive must be a string or a float')\n\n    if keep_alive is not None and keep_alive < 0:\n      raise RequestError('Keep-alive must be greater than 0')\n\n    if not isinstance(stream, bool):\n      raise RequestError('Stream must be a boolean')\n\n    if not isinstance(raw, bool):\n      raise RequestError('Raw must be a boolean')\n\n    if not isinstance(format, str):\n      raise RequestError('Format must be a string')\n\n    if format not in ['json', '']:\n      raise RequestError('Format must be either an empty string or \\'json\\'')\n\n    if not isinstance(stream, bool):\n      raise RequestError('Stream must be a boolean')\n\n    if not isinstance(raw, bool):\n      raise RequestError('Raw must be a boolean')\n\n    if not isinstance(format, str):\n      raise RequestError('Format must be a string')\n\n    if format not in ['json', '']:\n      raise RequestError('Format must be either an empty string or \\'json\\'')\n\n    if not isinstance(stream, bool):\n      raise RequestError('Stream must be a boolean')\n\n    if not isinstance(raw, bool):\n      raise RequestError('Raw must be a boolean')\n\n    if"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('A model is required.')\n\n    url = f'/v1/generate'\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n    }\n\n    if options:\n      data.update(options.to_dict())\n\n    return self._request_stream(url, method='POST', stream=stream, data=data, keep_alive=keep_alive)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('A model is required for generating a response.')\n\n    url = f'/generate'\n    if system:\n      url += f'?system={urllib.parse.quote(system)}'\n\n    if template:\n      url += f'&template={urllib.parse.quote(template)}'\n\n    if context:\n      url += f'&context={urllib.parse.quote(str(context))}'\n\n    if images:\n      url += f'&images={urllib.parse.quote(str(images))}'\n\n    if options:\n      url += f'&options={urllib.parse.quote(str(options))}'\n\n    if keep_alive:\n      url += f'&keep_alive={urllib.parse.quote(str(keep_alive))}'\n\n    return self._request_stream(url, method='POST', stream=stream, raw=raw, format=format, data=json.dumps({'prompt': prompt, 'model': model}))\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model parameter is required.')\n\n    if not isinstance(model, str):\n      raise RequestError('The model parameter must be a string.')\n\n    if not isinstance(stream, bool):\n      raise RequestError('The stream parameter must be a boolean.')\n\n    if not isinstance(raw, bool):\n      raise RequestError('The raw parameter must be a boolean.')\n\n    if not isinstance(format, (str, type(None)) or format not in ['', 'json']:\n      raise RequestError('The format parameter must be an empty string or \\'json\\'.')\n\n    if not isinstance(keep_alive, (float, str, type(None)) and keep_alive is not None:\n      raise RequestError('The keep_alive parameter must be a float, a string, or None.')\n\n    if not isinstance(system, str):\n      raise RequestError('The system parameter must be a string.')\n\n    if not isinstance(template, str):\n      raise RequestError('The template parameter must be a string.')\n\n    if not isinstance(prompt, str):\n      raise RequestError('The prompt parameter must be a string.')\n\n    if not isinstance(context, (type(None), Sequence[int])):\n      raise RequestError('The context parameter must be an empty list or a sequence of integers.')\n\n    if not isinstance(images, (type(None), Sequence[AnyStr])):\n      raise RequestError('The images parameter must be an empty list or a sequence of strings.')\n\n    if not isinstance(options, (type(None), Options)):\n      raise RequestError('The options parameter must be an empty object or an instance of the Options class.')\n\n    if not isinstance(format, str):\n      raise RequestError('The format parameter must be a string.')\n\n    if not isinstance(stream, bool):\n      raise RequestError('The stream parameter must be a boolean.')\n\n    if not isinstance(raw, bool):\n      raise RequestError('The raw parameter must be a boolean.')\n\n    if not isinstance(format, (str, type(None)) or format not in ['', 'json']:\n      raise RequestError('The format parameter must be an empty string or \\'json\\'.')\n\n    if not isinstance(keep_alive, (float, str, type("}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('No model provided')\n\n    if not prompt:\n      raise RequestError('No prompt provided')\n\n    if not (raw and format == ''):\n      raise RequestError('Invalid format')\n\n    if not keep_alive:\n      keep_alive = 30\n\n    if not isinstance(keep_alive, (int, float)):\n      keep_alive = float(keep_alive)\n\n    if keep_alive <= 0:\n      keep_alive = None\n\n    return self._request_stream(\n      'POST',\n      f'/models/{model}/generate',\n      stream=stream,\n      raw=raw,\n      format=format,\n      keep_alive=keep_alive,\n      params={\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'images': images,\n        'options': options,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    if not prompt:\n      raise RequestError('Prompt is required')\n\n    if not isinstance(stream, bool):\n      raise RequestError('Stream must be a bool')\n\n    if format not in ('', 'json'):\n      raise RequestError('Format must be either empty string or \"json\"')\n\n    if keep_alive and not (isinstance(keep_alive, (str, float)) and keep_alive is not None):\n      raise RequestError('Keep-alive must be a float, a string, or None')\n\n    if not isinstance(raw, bool):\n      raise RequestError('Raw must be a bool')\n\n    if not isinstance(system, str):\n      raise RequestError('System must be a string')\n\n    if not isinstance(template, str):\n      raise RequestError('Template must be a string')\n\n    if images is not None and not isinstance(images, Sequence):\n      raise RequestError('Images must be a sequence')\n\n    if options is not None and not isinstance(options, Options):\n      raise RequestError('Options must be an instance of Options')\n\n    if context is not None and not isinstance(context, Sequence):\n      raise RequestError('Context must be a sequence')\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = Options()\n\n    if context is None:\n      context = []\n\n    return self._request_stream(\n      'POST',\n      f'model/{model}',\n      json=json.dumps({\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'images': images,\n        'options': options,\n        'format': format,\n      }),\n      keep_alive=keep_alive,\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model not provided.')\n\n    if not prompt:\n      raise RequestError('Prompt not provided.')\n\n    if not isinstance(stream, bool):\n      raise RequestError('The stream parameter must be a boolean.')\n\n    if not isinstance(raw, bool):\n      raise RequestError('The raw parameter must be a boolean.')\n\n    if format not in ['', 'json']:\n      raise RequestError('The format parameter must be either an empty string or \"json\".')\n\n    if isinstance(keep_alive, (float, str)):\n      if not keep_alive:\n        keep_alive = None\n      else:\n        if isinstance(keep_alive, str):\n          keep_alive = float(keep_alive)\n        keep_alive = f'keep-alive={keep_alive}'\n\n    if isinstance(context, int):\n      context = [context]\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if not isinstance(options, dict):\n      raise RequestError('The options parameter must be a dictionary.')\n\n    return self._request_stream(\n      'POST',\n      '/api/v1/generate',\n      params={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'stream': stream,\n        'raw': raw,\n        'format': format,\n        'images': images,\n      },\n      data=json.dumps(options),\n      keep_alive=keep_alive,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model parameter is required.')\n\n    if not isinstance(model, str):\n      raise RequestError('The model parameter must be a string.')\n\n    if not prompt:\n      raise RequestError('The prompt parameter is required.')\n\n    if not isinstance(prompt, str):\n      raise RequestError('The prompt parameter must be a string.')\n\n    if not isinstance(system, str):\n      raise RequestError('The system parameter must be a string.')\n\n    if not isinstance(template, str):\n      raise RequestError('The template parameter must be a string.')\n\n    if not isinstance(stream, bool):\n      raise RequestError('The stream parameter must be a boolean.')\n\n    if not isinstance(raw, bool):\n      raise RequestError('The raw parameter must be a boolean.')\n\n    if not isinstance(format, str):\n      raise RequestError('The format parameter must be a string.')\n\n    if format not in {'', 'json'}:\n      raise RequestError('The format parameter must be either an empty string or \\'json\\'.')\n\n    if images is not None and not isinstance(images, Sequence):\n      raise RequestError('The images parameter must be a sequence.')\n\n    if options is not None and not isinstance(options, Options):\n      raise RequestError('The options parameter must be an Options object.')\n\n    if keep_alive is not None and not isinstance(keep_alive, (float, str)):\n      raise RequestError('The keep_alive parameter must be a float or a string.')\n\n    if not isinstance(context, Sequence) and context is not None:\n      raise RequestError('The context parameter must be a sequence.')\n\n    if isinstance(context, Sequence):\n      for value in context:\n        if not isinstance(value, int):\n          raise RequestError('All values in the context parameter must be integers.')\n\n    if isinstance(keep_alive, str):\n      if not keep_alive.isdigit():\n        raise RequestError('The keep_alive parameter must be a float or a string.')\n\n    if options is None:\n      options = Options()\n    else:\n      options.validate()\n\n    if images is not None:\n      for image in images:\n        if not isinstance(image, (str, PathLike"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model not provided.')\n\n    if not (prompt or context):\n      raise RequestError('Prompt or context not provided.')\n\n    if not isinstance(system, str) and system:\n      raise TypeError('Invalid system type.')\n\n    if not isinstance(template, str) and template:\n      raise TypeError('Invalid template type.')\n\n    if format not in ['', 'json']:\n      raise ValueError('Invalid format.')\n\n    if options and not isinstance(options, Options):\n      raise TypeError('Invalid options type.')\n\n    if keep_alive and not isinstance(keep_alive, (float, str)):\n      raise TypeError('Invalid keep_alive type.')\n\n    if images and not isinstance(images, (list, tuple, set, frozenset)):\n      raise TypeError('Invalid images type.')\n\n    return self._request_stream(\n      'POST',\n      f'/v1/models/{model}/generate',\n      params={\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n      },\n      data=json.dumps({\n        'context': context,\n        'stream': stream,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      }),\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('A model is required')\n\n    if not prompt:\n      raise RequestError('A prompt is required')\n\n    if not isinstance(model, str):\n      raise RequestError('The model must be a string')\n\n    if not isinstance(prompt, str):\n      raise RequestError('The prompt must be a string')\n\n    if system and not isinstance(system, str):\n      raise RequestError('The system must be a string')\n\n    if template and not isinstance(template, str):\n      raise RequestError('The template must be a string')\n\n    if images and not isinstance(images, (list, tuple)):\n      raise RequestError('The images must be a list or a tuple')\n\n    if not isinstance(options, Options):\n      raise RequestError('The options must be an Options object')\n\n    if not isinstance(keep_alive, (float, str, NoneType)):\n      raise RequestError('The keep-alive parameter must be a float, a string, or None')\n\n    if context is not None:\n      if not isinstance(context, (list, tuple)):\n        raise RequestError('The context must be a list or a tuple')\n      for c in context:\n        if not isinstance(c, int):\n          raise RequestError('The context must be a list of integers')\n\n    if not isinstance(stream, bool):\n      raise RequestError('The stream parameter must be a boolean')\n\n    if not isinstance(raw, bool):\n      raise RequestError('The raw parameter must be a boolean')\n\n    if not isinstance(format, (str, str, NoneType)):\n      raise RequestError('The format parameter must be a string, an empty string, or None')\n\n    if format == 'json' and not isinstance(options.warnings, (str, str)):\n      raise RequestError('The warnings parameter must be a string')\n\n    if format == 'json' and not isinstance(options.errors, (str, str)):\n      raise RequestError('The errors parameter must be a string')\n\n    if format == 'json' and not isinstance(options.status, (str, str)):\n      raise RequestError('The status parameter must be a string')\n\n    if format == 'json' and not isinstance(options.header,"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model parameter is required.')\n\n    if not isinstance(model, (str, Path)):\n      raise TypeError(f'The model parameter must be a string or a Path. Got {type(model)}')\n\n    if not prompt:\n      raise RequestError('The prompt parameter is required.')\n\n    if not isinstance(prompt, (str, Path)):\n      raise TypeError(f'The prompt parameter must be a string or a Path. Got {type(prompt)}')\n\n    if keep_alive:\n      if keep_alive not in (None, 0, 1, 1000):\n        raise RequestError('The keep-alive parameter can be None, 0, 1, or 1000.')\n\n    if not isinstance(system, (str, Path)):\n      raise TypeError(f'The system parameter must be a string or a Path. Got {type(system)}')\n\n    if not isinstance(template, (str, Path)):\n      raise TypeError(f'The template parameter must be a string or a Path. Got {type(template)}')\n\n    if context is not None:\n      if not isinstance(context, (list, tuple, set)):\n        raise TypeError(f'The context parameter must be a list, a tuple, or a set. Got {type(context)}')\n\n      if not all(isinstance(i, int) for i in context):\n        raise TypeError(f'The context parameter must contain only integers. Got {type(i)}')\n\n    if not isinstance(stream, bool):\n      raise TypeError(f'The stream parameter must be a boolean. Got {type(stream)}')\n\n    if not isinstance(raw, bool):\n      raise TypeError(f'The raw parameter must be a boolean. Got {type(raw)}')\n\n    if not isinstance(format, (str, Path)):\n      raise TypeError(f'The format parameter must be a string or a Path. Got {type(format)}')\n\n    if format == 'json' and not isinstance(format, str):\n      raise TypeError(f'The format parameter must be a string. Got {type(format)}')\n\n    if images is not None:\n      if not isinstance(images, (list, tuple, set)):"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model parameter is required.')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'keep_alive': keep_alive,\n    }\n\n    if images:\n      params['images'] = images\n\n    if options:\n      params.update(options)\n\n    return self._request_stream(\n      'POST',\n      f'/{urllib.parse.quote(model, safe='')}',\n      stream=stream,\n      raw=raw,\n      format=format,\n      **params,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('A model must be provided')\n\n    if not prompt and not images:\n      raise RequestError('A prompt or images must be provided')\n\n    if not isinstance(stream, bool):\n      raise RequestError('Invalid value for \"stream\" parameter')\n    if not isinstance(raw, bool):\n      raise RequestError('Invalid value for \"raw\" parameter')\n    if format not in ('', 'json'):\n      raise RequestError('Invalid value for \"format\" parameter')\n    if not isinstance(keep_alive, (float, str, NoneType)):\n      raise RequestError('Invalid value for \"keep_alive\" parameter')\n\n    if keep_alive:\n      if isinstance(keep_alive, float):\n        keep_alive = str(keep_alive)\n\n      if not keep_alive.isdigit():\n        raise RequestError('Invalid value for \"keep_alive\" parameter')\n\n      if keep_alive.startswith('-'):\n        keep_alive = 'keep-alive'\n\n    if images:\n      if isinstance(images, str):\n        images = [images]\n      if not isinstance(images, (list, tuple)):\n        raise RequestError('Invalid value for \"images\" parameter')\n      if not all(isinstance(x, str) for x in images):\n        raise RequestError('Invalid value for \"images\" parameter')\n\n    if isinstance(context, Sequence):\n      context = list(context)\n\n    if options:\n      if not isinstance(options, Options):\n        raise RequestError('Invalid value for \"options\" parameter')\n\n    return self._request_stream(\n      'post',\n      f'/model/{model}/generate',\n      params={\n        'system': system,\n        'template': template,\n      },\n      json={\n        'prompt': prompt,\n        'context': context,\n        'images': images,\n        'options': options,\n      },\n      stream=stream,\n      raw=raw,\n      format=format,\n      keep_alive=keep_alive,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('The model parameter is required.')\n\n    if not prompt:\n      raise RequestError('The prompt parameter is required.')\n\n    if not isinstance(images, Sequence) or not images:\n      images = []\n\n    if options and not isinstance(options, Options):\n      raise RequestError('The options parameter must be an instance of the Options class.')\n\n    if not keep_alive:\n      keep_alive = None\n\n    if not keep_alive:\n      keep_alive = os.getenv('OLLAMA_KEEP_ALIVE')\n\n    if keep_alive:\n      if not isinstance(keep_alive, (str, float)):\n        raise RequestError('The keep-alive parameter must be a string or a float.')\n      if keep_alive.isdigit():\n        keep_alive = float(keep_alive)\n\n    if keep_alive:\n      if keep_alive > 0:\n        keep_alive = f'{keep_alive}s'\n\n    url = f'generate?model={urllib.parse.quote(model)}&prompt={urllib.parse.quote(prompt)}'\n\n    if system:\n      url += f'&system={urllib.parse.quote(system)}'\n\n    if template:\n      url += f'&template={urllib.parse.quote(template)}'\n\n    if context:\n      url += f'&context={context}'\n\n    if images:\n      url += f'&images={images}'\n\n    if options:\n      url += f'&options={options.to_dict(include_none=True)}'\n\n    if keep_alive:\n      url += f'&keep_alive={keep_alive}'\n\n    return self._request_stream('POST', url, stream=stream, raw=raw, format=format)\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not isinstance(path, str) and not isinstance(path, Path):\n      raise TypeError('path must be a string or a Path')\n\n    if not isinstance(modelfile, str):\n      raise TypeError('modelfile must be a string')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'path': path,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if path:\n      modelfile = _read_model(path)\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'path': path,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not path:\n      path = io.StringIO(modelfile) if isinstance(modelfile, str) else modelfile\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'path': str(path),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      if isinstance(path, Path):\n        path = path.resolve()\n\n      if not path.is_file():\n        raise RequestError(f'path {path} is not a file')\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if not path:\n      path = modelfile\n      modelfile = None\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'path': path,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n    if path:\n      if not isinstance(path, Path):\n        path = Path(path)\n      if not path.exists():\n        raise RequestError(f'the provided path {path} does not exist')\n      if not path.is_file():\n        raise RequestError(f'the provided path {path} is not a file')\n      modelfile = path.read_text(encoding='utf-8')\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      modelfile = Path(path).read_bytes()\n    else:\n      modelfile = modelfile.encode('utf-8')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if path:\n      if not isinstance(path, Path):\n        path = Path(path)\n      if not path.exists():\n        raise RequestError(f'{path} does not exist')\n      if path.is_dir():\n        raise RequestError(f'{path} is a directory')\n      with path.open('rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or model file')\n\n    if path:\n      if isinstance(path, str):\n        path = Path(path)\n      if not path.exists():\n        raise RequestError(f'path {path} does not exist')\n      if not path.is_file():\n        raise RequestError(f'path {path} is not a file')\n\n      modelfile = path.read_bytes()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a model file or path')\n\n    if path:\n      if not isinstance(path, Path):\n        path = Path(path)\n\n      if not path.exists() or path.is_dir():\n        raise RequestError('path does not exist or is a directory')\n\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'model': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if path is None and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      if not isinstance(path, Path):\n        path = Path(path)\n      if not path.exists():\n        raise RequestError(f'the path {path} does not exist')\n\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a model file or path')\n\n    if path:\n      modelfile = _get_modelfile(path)\n    elif modelfile:\n      modelfile = modelfile\n    else:\n      raise RequestError('must provide a model file or path')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path and modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      modelfile = self._read_model(path)\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n    if not (modelfile or path):\n      raise RequestError('must provide a model file')\n    if not (path and modelfile):\n      modelfile = Path(modelfile or path)\n      if not modelfile.is_file():\n        raise RequestError('model file must be a file')\n      modelfile = modelfile.read_text()\n      path = None\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'path': path,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if path:\n      if isinstance(path, Path):\n        path = path.as_uri()\n      elif isinstance(path, str):\n        path = Path(path)\n    if not modelfile:\n      if path:\n        with open(path, 'rb') as f:\n          modelfile = f.read()\n      else:\n        raise RequestError('must provide a model file or path')\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or model file')\n\n    if not isinstance(path, str) and not isinstance(path, Path):\n      raise TypeError(f'path must be a string or a path-like object, got {type(path)}')\n    if not isinstance(modelfile, str):\n      raise TypeError(f'modelfile must be a string, got {type(modelfile)}')\n\n    if not path:\n      path = io.StringIO(modelfile)\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'path': path,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile and isinstance(path, str):\n      modelfile = Path(path)\n      if not modelfile.exists():\n        raise RequestError(f'path \"{path}\" does not exist')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'path': str(modelfile) if isinstance(modelfile, Path) else modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n    if not model:\n      raise RequestError('must provide a model')\n\n    if path:\n      with io.open(path, 'rb') as f:\n        modelfile = f.read()\n    else:\n      path = Path(modelfile)\n    if not path.exists() or path.is_dir():\n      raise RequestError(f'path {path} does not exist or is a directory')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'model_file': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not (path and modelfile):\n      if modelfile:\n        modelfile = Path(modelfile)\n        path = modelfile.parent\n      else:\n        path = Path(path)\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n    url = f'https://{self._client.base_url}/blob/{checksum}'\n    if self._client.head(url).status_code == 404:\n      self._client.post(url, data=f.read())\n      checksum = f'sha256:{checksum}'\n\n    return checksum\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not path.exists():\n      raise RequestError(f'file {path} does not exist')\n    checksum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        checksum.update(chunk)\n    checksum = checksum.hexdigest()\n\n    url = f'/api/blobs/sha256/{checksum}'\n    response = self._client.head(url)\n    if response.status_code == 404:\n      with open(path, 'rb') as f:\n        response = self._client.post(url, data=f)\n      response.raise_for_status()\n      checksum = response.headers['Content-Sha256']\n\n    return checksum\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists() or not path.is_file():\n      raise ValueError('path must be a file')\n\n    with path.open('rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    if response := self._request(\n        'HEAD',\n        f'/api/blobs/{checksum}',\n    ):\n      if response.status_code == 404:\n        with path.open('rb') as f:\n          self._request(\n              'POST',\n              f'/api/blobs',\n              data=f.read(),\n          )\n\n    return f'sha256:{checksum}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not isinstance(path, Path):\n      path = Path(path)\n    checksum = sha256(path.read_bytes()).hexdigest()\n    url = f'/api/blob/sha256/{checksum}'\n    resp = self.head(url)\n\n    if resp.status_code == 404:\n      with path.open('rb') as f:\n        resp = self.post(url, data=f.read())\n      resp.raise_for_status()\n\n    return checksum\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n      if not self._client.head(f'/api/blob/{digest}').status_code == 404:\n        return digest\n\n      with self._client.post(f'/api/blob/{digest}', data=f.read()) as r:\n        if r.status_code != 200:\n          raise ResponseError(r.text, r.status_code)\n        return r.text.strip()\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256(open(path, 'rb').read()).hexdigest()\n    url = f'https://{self._client.base_url}/api/blob/{sha256sum}'\n\n    try:\n      response = self._client.head(url)\n      if response.status_code != 404:\n        return sha256sum\n    except httpx.HTTPError:\n      pass\n\n    response = self._client.post(url, data=open(path, 'rb'))\n    if response.status_code != 200:\n      raise ResponseError(response.text, response.status_code) from None\n    return response.headers['Content-MD5']\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n    path = path.expanduser()\n\n    # Check if the file exists\n    if not path.exists():\n      raise FileNotFoundError(f'File {path} does not exist')\n\n    # Calculate the SHA-256 checksum of the file\n    sha256_checksum = sha256(path.read_bytes()).hexdigest()\n\n    # Check if the blob already exists on the server\n    response = self._client.head(f'/api/blobs/sha256/{sha256_checksum}')\n    if response.status_code == 200:\n      return sha256_checksum\n\n    # Upload the file as a new blob\n    response = self._client.post(f'/api/blobs/sha256/{sha256_checksum}', files={'file': path})\n\n    # Check if the file was successfully uploaded\n    if response.status_code != 200:\n      raise ResponseError(response.text)\n\n    # Return the digest of the file\n    return sha256_checksum\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    with path.open('rb') as f:\n      data = f.read()\n      digest = sha256(data).hexdigest()\n      url = f'https://{self.host}/blob/{digest}'\n      response = self._client.head(url)\n      if response.status_code == 404:\n        self._client.post(url, data=data)\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, Path):\n      path = path.resolve()\n\n    with open(path, 'rb') as f:\n      data = f.read()\n\n    if not data:\n      return ''\n\n    # Check if the blob already exists\n    digest = sha256(data).hexdigest()\n    response = self._client.head(f'https://huggingface.my.id/api/blob/model-store/v1/sha256/{digest}')\n    if response.status_code != 404:\n      return digest\n\n    # Upload the file\n    response = self._client.post(\n      'https://huggingface.my.id/api/blob/model-store/v1/sha256',\n      data=data,\n    )\n\n    # Return the digest\n    return response.headers.get('X-Blob-Digest')\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, Path):\n      with open(path, 'rb') as f:\n        checksum = sha256(f.read()).hexdigest()\n      path = path.as_uri()\n    else:\n      checksum = sha256(path.encode('utf-8')).hexdigest()\n\n    r = self._client.head(f'/api/blobs/{checksum}')\n    if r.status_code == 404:\n      with open(path, 'rb') as f:\n        r = self._client.post('/api/blobs', data=f.read())\n      r.raise_for_status()\n      checksum = r.headers['content-sha256']\n    return checksum\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    # calculate SHA-256 checksum\n    sha256_checksum = sha256(path.read_bytes()).hexdigest()\n\n    # check if a blob with that checksum already exists on the server\n    response = self._client.head(f'https://api.ollama.io/blobs/{sha256_checksum}')\n    if response.status_code == 404:\n      # if not found, upload the file as a new blob\n      with open(path, 'rb') as f:\n        response = self._client.post(\n          f'https://api.ollama.io/blobs',\n          data=f.read(),\n          headers={'Content-Type': 'application/octet-stream'},\n        )\n\n      # return the digest of the file\n      return response.headers['Content-MD5']\n\n    # return the digest of the file\n    return response.headers['Content-MD5']\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        sha256sum.update(chunk)\n\n    sha256sum = sha256sum.hexdigest()\n    response = self._client.head(f'api/blobs/{sha256sum}')\n    if response.status_code != 404:\n      return sha256sum\n\n    with open(path, 'rb') as f:\n      response = self._client.post(\n        'api/blobs',\n        json={\n          'blob': {\n            'name': os.path.basename(path),\n            'type': 'file',\n            'encoding': 'utf-8',\n          },\n          'data': f.read(),\n        },\n      )\n      response.raise_for_status()\n\n    return response.headers['Content-MD5']\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str) and not path.startswith('http'):\n      path = Path(path)\n\n    if not path.exists():\n      raise IOError(f'file {path.as_posix()} does not exist')\n\n    digest = sha256(path.read_bytes()).hexdigest()\n\n    try:\n      r = self._request('HEAD', f'/blobs/sha256/{digest}')\n    except httpx.HTTPStatusError:\n      r = self._request('POST', '/blobs/upload', files={'file': (path, path.read_bytes())})\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not isinstance(path, Path):\n      path = Path(path)\n\n    if not path.is_file():\n      raise RequestError(f'file {path} does not exist')\n\n    # Calculate the SHA-256 checksum of the file\n    sha256_checksum = sha256(path.read_bytes()).hexdigest()\n\n    # Check if the blob with the calculated checksum already exists on the server\n    response = self._request('HEAD', f'/blob/sha256:{sha256_checksum}')\n\n    # If the response status code is 200 (OK), the blob already exists on the server, so just return the checksum\n    if response.status_code == 200:\n      return sha256_checksum\n\n    # If the response status code is 404 (Not Found), the blob does not exist on the server, so upload the file as a new blob\n    response = self._request('POST', '/blob', files={'file': path}, json={'name': sha256_checksum})\n\n    # Return the SHA-256 digest of the file in the format 'sha256:<hexdigest>'\n    return f'sha256:{sha256_checksum}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not path.is_file():\n      raise RequestError('must provide a file path')\n\n    path = Path(path)\n\n    checksum = sha256.new(path.read_bytes()).hexdigest()\n\n    url = f'/api/blobs/{checksum}'\n    response = self.head(url)\n\n    if response.status_code == 200:\n      return checksum\n    elif response.status_code == 404:\n      return self.post(\n        url,\n        files={\n          'blob': (path.name, path.read_bytes()),\n        },\n      ).json()['digest']\n\n    raise ResponseError(response.text, response.status_code)\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    with path.open('rb') as f:\n      blob = f.read()\n\n    checksum = sha256(blob).hexdigest()\n    digest = f'sha256:{checksum}'\n    headers = {'Accept': 'application/json'}\n    response = self._client.request('HEAD', f'/api/blob/{digest}', headers=headers)\n    if response.status_code == 404:\n      response = self._client.request('POST', '/api/blob', data=blob, headers=headers)\n\n    return digest\n\n    def _parse_host(host: Optional[str]) -> str:\n      if not host:\n        host = os.getenv('OLLAMA_HOST')\n      if not host:\n        raise RequestError('must provide host')\n\n      if not host.startswith('http'):\n        host = f'https://{host}'\n      return urllib.parse.urlsplit(host)[2]\n\n    def _encode_image(image: AnyStr) -> str:\n      if isinstance(image, str):\n        image = Path(image)\n      if not image.is_file():\n        raise RequestError(f'image must be a file path, not {type(image).__name__}')\n\n      with image.open('rb') as f:\n        image = f.read()\n      return f'data:image/png;base64,{b64encode(image).decode()}'\n\n    def _as_path(path: AnyStr) -> Path:\n      if isinstance(path, Path):\n        return path\n      return Path(path)"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not os.path.isfile(path):\n      raise RequestError(f'{path} is not a file')\n\n    content = b64encode(sha256(open(path, 'rb').read()).digest()).decode()\n    digest = f'sha256:{content}'\n\n    if self._client.head(f'/blob/{digest}').status_code == 404:\n      with open(path, 'rb') as f:\n        self._client.post(f'/blob', data=f.read())\n\n    return digest\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256 = sha256()\n\n    if not isinstance(path, Path):\n      path = Path(path)\n    path = path.resolve()\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise FileExistsError(f'{path} is not a file')\n\n    with path.open('rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        sha256.update(chunk)\n\n    sha256_hex = sha256.hexdigest()\n    digest = f'sha256:{sha256_hex}'\n    response = self._request('HEAD', f'api/blob/{digest}')\n    if response.status_code == 200:\n      return digest\n\n    with path.open('rb') as f:\n      with self._request('POST', 'api/blob', stream=True) as response:\n        for chunk in iter(lambda: f.read(4096), b''):\n          response.write(chunk)\n    return response.headers.get('content-md5')\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not path.exists():\n      raise RequestError(f'file {path} does not exist')\n\n    digest = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        digest.update(chunk)\n\n    digest = digest.hexdigest()\n    digest = f'sha256:{digest}'\n\n    with self._client.stream('HEAD', f'/blob/{digest}'):\n      try:\n        self._client.request.raise_for_status()\n      except httpx.HTTPStatusError as e:\n        if e.response.status_code != 404:\n          raise e\n\n        with open(path, 'rb') as f:\n          self._client.request(\n            'POST',\n            '/blob',\n            headers={\n              'Content-Type': 'application/octet-stream',\n            },\n            stream=True,\n            data=f,\n          )\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    # Open the file and calculate the SHA-256 checksum\n    with open(path, 'rb') as f:\n      file_checksum = sha256(f.read()).hexdigest()\n\n    # Make a HEAD request to check if the blob already exists on the server\n    head_response = self._client.head(f'/api/blob?checksum={file_checksum}')\n\n    # If the blob does not already exist on the server, upload the file as a new blob\n    if head_response.status_code == 404:\n      with open(path, 'rb') as f:\n        blob_response = self._client.post(\n          '/api/blob',\n          data=f.read(),\n          headers={\n            'Content-Length': str(len(f.read())),\n          },\n        )\n\n        # Return the SHA-256 digest of the file in the format 'sha256:<hexdigest>'\n        return f'sha256:{blob_response.text}'\n    else:\n      # If the blob already exists on the server, return the SHA-256 checksum\n      return file_checksum\n\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.readchunk(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We need to make sure that the user code is in a separate file, so we can use Pyright to type check it.\n        tmp_user_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        tmp_user_code_file.write(user_code)\n\n        # We need to make sure that the test code is in a separate file, so we can use Pyright to type check it.\n        tmp_test_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        tmp_test_code_file.write(test_code)\n        tmp_test_code_file.close()\n\n        # We need to make sure that the test code is in a separate file, so we can use Pyright to type check it.\n        tmp_test_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        tmp_test_code_file.write(test_code)\n        tmp_test_code_file.close()\n        pyright_output = subprocess.run(\n            [\n                \"pyright\",\n                \"-i\",\n                tmp_user_code_file.name,\n                tmp_test_code_file.name,\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n\n        # We need to make sure that the user code is in a separate file, so we can use Pyright to type check it.\n        tmp_user_code_file.close()\n\n        # We need to make sure that the test code is in a separate file, so we can use Pyright to type check it.\n        tmp_test_code_file.close()\n\n        # We need to make sure that the test code is in a separate file, so we can use Pyright to type check it.\n        tmp_test_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        tmp_test_code_file.write(test_code)\n        tmp_test_"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Make sure user code ends with a new line to avoid issue #63.\n        user_code += \"\\n\"\n\n        # Combine the user code with the test code.\n        combined_code = user_code + test_code\n\n        # Run the type check using Pyright.\n        pyright_output = cls._run_pyright(combined_code)\n\n        # Extract the type check result from the Pyright output.\n        type_check_result = cls._get_type_check_result(pyright_output)\n\n        # Return the type check result.\n        return type_check_result\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Use Pyright to type check the user code and test code\n        # and identify lines with expected type errors\n        pyright_output = cls._run_pyright(user_code, test_code)\n\n        # Parse the Pyright output to extract the error messages and line numbers\n        error_messages = cls._extract_pyright_error_messages(pyright_output)\n\n        # Check if any lines with expected type errors were found\n        if not error_messages:\n            return TypeCheckResult(\n                message=\"No type errors found\", passed=True, debug_info=dict()\n            )\n\n        # Check if any of the lines with expected type errors were not found\n        if not cls._check_lines_with_expected_errors(error_messages):\n            return TypeCheckResult(\n                message=\"Some expected type errors were not found\",\n                passed=False,\n                debug_info=dict(\n                    error_messages=error_messages,\n                    expected_errors=cls.EXPECT_ERROR_COMMENT,\n                ),\n            )\n\n        # Check if any lines with unexpected type errors were found\n        if cls._check_lines_with_unexpected_errors(error_messages):\n            return TypeCheckResult(\n                message=\"Unexpected type errors were found\",\n                passed=False,\n                debug_info=dict(\n                    error_messages=error_messages,\n                    unexpected_errors=cls.EXPECT_ERROR_COMMENT,\n                ),\n            )\n\n        # If no errors were found, the type check passed\n        return TypeCheckResult(\n            message=\"Type check passed\",\n            passed=True,\n            debug_info=dict(error_messages=error_messages),\n        )\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Remove the expect-type-error comment from the test code\n        test_code = re.sub(\n            cls.EXPECT_ERROR_COMMENT + r\"\\s*#\", \"\", test_code, flags=re.MULTILINE\n        )\n\n        # Write the user code to a temporary file\n        tmp_user_code_file = tempfile.NamedTemporaryFile(delete=False)\n        tmp_user_code_file.write(user_code.encode(\"utf-8\"))\n        tmp_user_code_file.close()\n\n        # Write the test code to a temporary file\n        tmp_test_code_file = tempfile.NamedTemporaryFile(delete=False)\n        tmp_test_code_file.write(test_code.encode(\"utf-8\"))\n        tmp_test_code_file.close()\n\n        # Run Pyright on the combined code\n        proc = subprocess.run(\n            [\n                \"pyright\",\n                \"--no-check\",\n                \"--no-color\",\n                \"--no-line-numbers\",\n                \"--no-line-length-limit\",\n                tmp_user_code_file.name,\n                tmp_test_code_file.name,\n            ],\n            capture_output=True,\n        )\n\n        # Check for errors\n        if proc.returncode != 0:\n            return TypeCheckResult(\n                message=\"Error running pyright\",\n                passed=False,\n                debug_info={\"output\": proc.stderr.decode(\"utf-8\")},\n            )\n\n        # Extract the error messages and line numbers\n        error_lines = re.findall(cls.PYRIGHT_MESSAGE_REGEX, proc.stdout.decode(\"utf-8\"))\n        error_messages = [\n            (int(line[0]), line[1] for line in error_lines if line[0].isnumeric()\n        ]\n\n        # Check for expected errors\n        expected_errors = set(\n            (lineno, cls.EXPECT_ERROR_COMMENT)\n            for lineno in range(1, len(test_code) + 1)\n        )\n        unexpected_errors = [\n            (lineno, message)\n            for lineno, message in error_messages\n            "}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Run pyright\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            with io.StringIO() as io_object:\n                pyright_cmd = [\n                    \"pyright\",\n                    \"-q\",\n                    \"--check-type-only\",\n                    \"-f\",\n                    \"json\",\n                    \"-o\",\n                    io_object.name,\n                ]\n                pyright_cmd.append(user_code)\n                pyright_cmd.append(test_code)\n\n                proc = subprocess.Popen(pyright_cmd, cwd=tmp_dir)\n                proc.communicate()\n\n                # Parse the output\n                pyright_output = io_object.getvalue()\n\n                # Parse the error messages\n                pyright_errors = []\n                for line in tokenize.generate_tokens(pyright_output.splitlines()):\n                    if line[0] == tokenize.COMMENT:\n                        match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line[1])\n                        if match:\n                            line_no = int(match.group(1))\n                            error_message = match.group(2)\n\n                            # Ignore errors in the EXPECT_ERROR_COMMENT section\n                            if error_message.startswith(cls.EXPECT_ERROR_COMMENT):\n                                continue\n\n                            pyright_errors.append(\n                                {\n                                    \"line\": line_no,\n                                    \"message\": error_message,\n                                }\n                            )\n\n        # Determine the outcome\n        if pyright_errors:\n            message = \"Failed to type check the code.\"\n        else:\n            message = \"Successfully type checked the code.\"\n\n        return TypeCheckResult(message, len(pyright_errors) == 0, pyright_errors)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We use Pyright to type check the user code.\n        # We don't use the builtin python type checker because it's not very good.\n        # We don't use pylance because it's not very fast.\n        # We don't use mypy because it's not very accurate.\n        # We don't use mypy-pyright because it's not very fast.\n        with tempfile.NamedTemporaryFile(\"w\", encoding=\"utf-8\") as f:\n            f.write(user_code + \"\\n\" + test_code)\n            pyright_output = subprocess.check_output(\n                [\"pyright\", \"-c\", f.name], text=True\n            )\n        # We split the output into lines.\n        lines = pyright_output.splitlines()\n        # We remove the first line, which is the Pyright version.\n        lines = lines[1:]\n\n        # We remove all the lines that are not type errors.\n        # We also remove the line with the error message we expect.\n        lines = [\n            line\n            for line in lines\n            if not re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n        ]\n        # We remove the last line, which is the exit status.\n        lines = lines[:-1]\n\n        # We remove the lines that are not type errors.\n        # We also remove the line with the error message we expect.\n        lines = [\n            line\n            for line in lines\n            if not re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n        ]\n        # We remove the last line, which is the exit status.\n        lines = lines[:-1]\n\n        # We remove the lines that are not type errors.\n        # We also remove the line with the error message we expect.\n        lines = [\n            line\n            for line in lines\n            if not re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n        ]\n        # We remove the last line, which is the exit status.\n        lines = lines[:-1]\n        # We remove the lines that are not type errors.\n        # We also remove the line with the error message we expect.\n        lines"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Run Pyright\n        # TODO: use the new Pyright API\n        # https://github.com/Pyright/pyright/issues/172\n        # https://github.com/Pyright/pyright/issues/174\n        # https://github.com/Pyright/pyright/issues/185\n        # https://github.com/Pyright/pyright/issues/204\n        # https://github.com/Pyright/pyright/issues/228\n        pyright_output = cls._run_pyright(user_code + test_code)\n\n        # Parse Pyright output\n        pyright_errors = cls._parse_pyright_output(pyright_output)\n        error_lines = set(pyright_errors)\n        error_lines = error_lines.difference(cls.EXPECT_ERROR_COMMENT)\n        error_lines = sorted(error_lines)\n        message = cls._format_error_message(error_lines)\n        passed = not error_lines\n\n        return TypeCheckResult(message, passed, {\"pyright_output\": pyright_output})\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # TODO: add a comment to the user code to ensure that Pyright reports errors on the user code\n        user_code = f\"## {cls.EXPECT_ERROR_COMMENT} ##\\n\\n{user_code}\\n\\n## End of your code ##\\n\"\n        # TODO: use Pyright to type check the combined code\n        proc = subprocess.run(\n            [\"pyright\", \"--no-color\", \"--no-format\", \"--no-fix\", \"-\"],\n            input=f\"{user_code}\\n{test_code}\".encode(),\n            encoding=\"utf-8\",\n            text=True,\n        )\n        # TODO: extract the error messages from the output of Pyright\n        # TODO: remove the Pyright comment from the user code\n        user_code = user_code.replace(f\"## {cls.EXPECT_ERROR_COMMENT} ##\\n\", \"\").lstrip()\n        # TODO: return a TypeCheckResult object containing the result of the type check\n        return TypeCheckResult(\n            message=\"Passed\",\n            passed=True,\n            debug_info={\"proc_return_code\": proc.returncode, \"proc_output\": proc.stdout},\n        )\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Add user code to the end of the test code\n        code = test_code + cls.CODE_SPLITTER + user_code\n\n        # Run type check\n        proc = subprocess.Popen(\n            [\"pyright\", \"--no-format\", \"--no-exit-on-error\", \"--no-color\", \"-\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        proc.stdin.write(code.encode(\"utf-8\"))\n        proc.stdin.close()\n        output = proc.communicate()[1]\n\n        # Parse the output\n        errors = []\n        for line in output.decode(\"utf-8\").split(\"\\n\"):\n            if not line.startswith(cls.EXPECT_ERROR_COMMENT):\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    errors.append(match.group(2))\n                    errors.append(match.group(1))\n                else:\n                    # If the line is not a type error, it is probably a warning or information message\n                    errors.append(line)\n\n        # Remove duplicates\n        errors = list(set(errors))\n\n        # If there are no errors, the type check passed\n        if not errors:\n            return TypeCheckResult(\n                message=\"All type checks passed!\",\n                passed=True,\n                debug_info=dict(user_code=user_code, test_code=test_code),\n            )\n\n        # If there are errors, the type check failed\n        return TypeCheckResult(\n            message=\"Type checks failed!\",\n            passed=False,\n            debug_info=dict(user_code=user_code, test_code=test_code, errors=errors),\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # TODO: Don't hardcode the path\n        pyright = subprocess.Popen(\n            [\"pyright\", \"--no-color\", \"--no-warnings\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n        )\n\n        # Send user code to pyright\n        pyright.stdin.write(user_code.encode(\"utf-8\"))\n        pyright.stdin.write(b\"\\n\")\n        pyright.stdin.close()\n\n        # Read the output\n        output = pyright.stdout.read()\n\n        # Get the test code\n        test_code += \"\\n\"\n        test_code += cls.EXPECT_ERROR_COMMENT + \"\\n\"\n        test_code += test_code\n\n        # Write the test code to a temporary file\n        with tempfile.NamedTemporaryFile(mode=\"w+t\", suffix=\".py\") as f:\n            f.write(test_code)\n            f.flush()\n\n            # Send the test code to pyright\n            pyright.stdin.write(b\"import \" + f.name.encode(\"utf-8\"))\n            pyright.stdin.write(b\"\\n\")\n            pyright.stdin.close()\n\n            # Read the output\n            pyright_test_output = pyright.stdout.read()\n\n        # Get the error messages\n        error_messages = re.findall(cls.PYRIGHT_MESSAGE_REGEX, output.decode(\"utf-8\"))\n\n        # Get the expected error messages\n        test_output_lines = pyright_test_output.decode(\"utf-8\").splitlines()\n        expected_error_messages = [\n            line\n            for line in test_output_lines\n            if re.fullmatch(cls.EXPECT_ERROR_COMMENT, line)\n        ]\n\n        # Check if the type check passed\n        passed = all(\n            error_message in expected_error_messages\n            for error_message in error_messages\n        )\n\n        # Generate the debug information\n        debug_info = dict(\n            user_code=user_code,\n            test_code=test_code,\n            output=output.decode(\"utf-8\"),\n            error_messages=error_messages,\n            expected"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Pyright uses a temporary file to store the user-provided code, so we need to create a temporary directory to store the user code and test code.\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            # Create a temporary file to store the user code.\n            user_code_file = Path(tmp_dir) / \"user_code.py\"\n            user_code_file.write_text(user_code)\n\n            # Create a temporary file to store the test code.\n            test_code_file = Path(tmp_dir) / \"test_code.py\"\n            test_code_file.write_text(test_code)\n\n            # Run the type check using the user code and test code.\n            proc = subprocess.Popen(\n                [\"pyright\", user_code_file, test_code_file],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n            stdout, stderr = proc.communicate()\n\n            # Parse the error messages from the stdout and stderr output of Pyright.\n            errors = re.findall(cls.PYRIGHT_MESSAGE_REGEX, stderr.decode(\"utf-8\"))\n\n            # Remove the error messages that are expected\n            expected_error_messages = [\n                cls.EXPECT_ERROR_COMMENT + \":\" + str(lineno) for lineno in range(1, 8)\n            ]\n            errors = [error for error in errors if error not in expected_error_messages]\n\n            # Remove the error messages that are not related to the user code or test code\n            errors = [error for error in errors if error.startswith(user_code_file.name)]\n\n            # Remove the line numbers from the error messages\n            error_lines = [error.split(\":\", maxsplit=1)[1] for error in errors]\n            # Remove the error messages that are not related to the test code\n            error_lines = [error_line for error_line in error_lines if error_line.startswith(test_code_file.name)]\n\n            # Convert the error lines to integers\n            error_line_numbers = [int(error_line.split(\":\")[-1]) for error_line in error_lines]\n            # Remove the error"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # This is a hacky way to get the current working directory\n        cwd = Path.cwd()\n\n        # Create a temporary file for the combined code\n        combined_code_file = tempfile.NamedTemporaryFile(\n            prefix=cls.EXPECT_ERROR_COMMENT, suffix=\".py\"\n        )\n        # Write the combined code to the temporary file\n        combined_code_file.write(user_code.encode(\"utf-8\"))\n        combined_code_file.write(b\"\\n\" + test_code.encode(\"utf-8\"))\n\n        # Change the current working directory to the temporary file\n        # so that Pyright can find the file\n        cwd.mkdir(parents=True, exist_ok=True)\n        combined_code_file.flush()\n        Path.cwd().mkdir(parents=True, exist_ok=True)\n        Path.cwd().chdir()\n        # Run Pyright on the combined code\n        pyright_output = subprocess.check_output(\n            [\"pyright\", \"--show-errors\", combined_code_file.name]\n        )\n\n        # Close the temporary file\n        combined_code_file.close()\n        # Change the current working directory back to the original one\n        Path.cwd().parent.chdir()\n\n        # Extract the error messages from the Pyright output\n        pyright_messages = re.findall(cls.PYRIGHT_MESSAGE_REGEX, pyright_output.decode(\"utf-8\"))\n\n        # Create a dictionary to store the error messages\n        errors = {}\n\n        # Iterate through the error messages and extract the line numbers\n        for message in pyright_messages:\n            line_no = int(message[0])\n            error_message = message[1]\n\n            # If the error message is an expected type error, add it to the errors dictionary\n            if error_message.startswith(cls.EXPECT_ERROR_COMMENT):\n                errors[line_no] = error_message[len(cls.EXPECT_ERROR_COMMENT) :]\n            # If the error message is an unexpected type error, return a failed result\n            elif error_message.startswith(\"error:\"):\n                return TypeCheckResult(\n                    message=\"Type check failed: \" + error_message, passed=False"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.TemporaryDirectory() as tmp_dir:\n            tmp_file = tmp_dir / \"test.py\"\n            tmp_file.write_text(user_code)\n\n            # We need to add the test code at the end of the user code to make sure that\n            # the code is run in the same context.\n            tmp_file.write_text(test_code, \"a\")\n\n            # Run Pyright with the file as argument.\n            proc = subprocess.Popen(\n                [\n                    \"pyright\",\n                    \"-v\",\n                    tmp_file.as_posix(),\n                ],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n\n            # Read the output of the command\n            out, err = proc.communicate()\n            out = out.decode(\"utf-8\")\n            err = err.decode(\"utf-8\")\n            # We are only interested in the type errors, so we filter out the\n            # other messages.\n            error_lines = [\n                line for line in err.splitlines() if re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            ]\n\n            # We are only interested in the error messages, so we filter out\n            # the line numbers.\n            error_messages = [\n                re.match(cls.PYRIGHT_MESSAGE_REGEX, line).group(2) for line in error_lines\n            ]\n\n            # We are only interested in the error messages that are in the\n            # EXPECT_ERROR_COMMENT.\n            expected_error_messages = [\n                error_message\n                for error_message in error_messages\n                if error_message.startswith(cls.EXPECT_ERROR_COMMENT)\n            ]\n\n            # We are only interested in the error messages that are not in the\n            # EXPECT_ERROR_COMMENT.\n            unexpected_error_messages = [\n                error_message\n                for error_message in error_messages\n                if not error_message.startswith(cls.EXPECT_ERROR_COMMENT)\n            ]\n\n            # We are only interested in the error messages that are not in the\n            # EXPECT_ERROR_COMMENT and are not in the expected error messages.\n            unexpected_error_messages ="}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Pyright can't handle the case where the user code is empty, so we need to handle it specially here.\n        if not user_code:\n            return cls.type_check_error(\n                message=\"No code provided. Please provide some code to type check.\",\n                passed=False,\n            )\n\n        with tempfile.TemporaryDirectory() as temp_dir:\n            # Create a temporary file for the user code.\n            user_code_path = temp_dir / \"user_code.py\"\n            user_code_path.write_text(user_code)\n\n            # Create a temporary file for the test code.\n            test_code_path = temp_dir / \"test_code.py\"\n            test_code_path.write_text(test_code + \"\\n\")\n\n            # Run Pyright on the temporary files.\n            pyright_output = cls._run_pyright(user_code_path, test_code_path)\n\n            # Parse the Pyright output and extract the expected type errors.\n            pyright_messages = cls._extract_pyright_messages(pyright_output)\n\n            # Split the user code into lines.\n            lines = user_code.splitlines()\n\n            # Loop through the lines of user code, checking for expected type errors.\n            for line_no, line in enumerate(lines):\n                if line.lstrip().startswith(cls.EXPECT_ERROR_COMMENT):\n                    # The line is an expected type error, so we can ignore it.\n                    continue\n                # Check if the line has an expected type error.\n                if line in pyright_messages:\n                    # The line has an expected type error, so we can ignore it.\n                    pyright_messages.remove(line)\n                    continue\n                # The line does not have an expected type error, so we can check if it matches the test code.\n                if line == test_code:\n                    # The line matches the test code, so we can ignore it.\n                    continue\n                # The line does not match the test code, so we can check if it has an error.\n                if not line.lstrip().startswith(\"#\"):\n                    # The line does not have a comment, so we can check if it has"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We use a temporary file to store the code to be type-checked\n        # so that we can use Pyright's `--file` option\n        with tempfile.NamedTemporaryFile() as temp_file:\n            # We insert the user code and test code into the temporary file\n            temp_file.write(f\"{user_code}{cls.CODE_SPLITTER}{test_code}\")\n\n            # We use Pyright to type check the code in the temporary file\n            pyright_result = subprocess.run(\n                [\"pyright\", \"--file\", temp_file.name, \"--no-color\", \"--no-exit-on-error\"],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True,\n            )\n\n            # We parse the output of Pyright for error messages and line numbers\n            error_lines = [\n                (int(line.split(\":\", 1)[0]),\n                line.split(\":\", 1)[-1].strip(),\n            ]\n            for line in pyright_result.stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no = int(match.group(1))\n                    error_msg = match.group(2)\n                    if error_msg.startswith(cls.EXPECT_ERROR_COMMENT):\n                        continue\n                    error_lines.append((line_no, error_msg))\n\n            # We sort the error lines by line number\n            error_lines = sorted(error_lines)\n\n            # We construct a message based on the number of errors and the error messages\n            if len(error_lines) == 0:\n                message = \"Type check passed!\"\n            else:\n                message = (\n                    \"Type check failed.\\n\"\n                    + \"\\n\".join(\n                        f\"  Line {line_no}: {error_msg}\"\n                        for line_no, error_msg in error_lines\n                    )\n                )\n\n            # We return a TypeCheckResult object containing the message and a boolean indicating if the type check passed\n            return TypeCheckResult(message, len(error_lines) == 0)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # First, we need to combine the user code and test code into a single string\n        combined_code = f\"\"\"\n        # {cls.EXPECT_ERROR_COMMENT}\n        {user_code}\n        ## End of your code ##\n        {test_code}\n        \"\"\"\n\n        # Next, we need to run Pyright on the combined code and get the output\n        pyright_output = subprocess.run(\n            [\"pyright\", \"-q\", \"-f\", \"json\", \"-\"],\n            input=combined_code,\n            check=False,\n            text_mode=True,\n            stdout=subprocess.PIPE,\n        )\n\n        # We need to parse the output to extract the relevant information\n        output = pyright_output.stdout\n        if output is None:\n            return TypeCheckResult(\n                message=\"Pyright didn't produce any output, check the logs for more information\",\n                passed=True,\n            )\n\n        # We need to extract the error messages from the output\n        error_messages = re.findall(cls.PYRIGHT_MESSAGE_REGEX, output)\n\n        # We need to filter out the error messages that are not expected\n        expected_error_messages = [\n            message\n            for message in error_messages\n            if message[0] == cls.EXPECT_ERROR_COMMENT\n        ]\n        unexpected_error_messages = [\n            message\n            for message in error_messages\n            if message[0] not in [cls.EXPECT_ERROR_COMMENT]\n        ]\n\n        # We need to determine if the type check passed\n        passed = len(unexpected_error_messages) == 0\n\n        # We need to create a debug dictionary for debugging purposes\n        debug_info = {\"error_messages\": error_messages}\n\n        # We need to create a message that indicates if the type check passed or not\n        message = (\n            \"Type check passed\"\n            if passed\n            else \"Type check failed. Please check the error messages for more information.\"\n        )\n\n        # We need to return the result\n        return TypeCheckResult(message=message, passed=passed, debug_info=debug_info)\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # If the user code is empty, then the type check passes.\n        if not user_code:\n            return TypeCheckResult(\n                message=\"Type check passed\",\n                passed=True,\n            )\n\n        # Combine the user code with the test code.\n        combined_code = f\"from typing import *\\n{user_code}{test_code}\"\n\n        # Run type checking with Pyright and capture the output.\n        p = subprocess.Popen(\n            [\"pyright\", \"-q\"],\n            input=combined_code,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n            text=True,\n        )\n        output, errors = p.communicate()\n\n        # Check if the type check passed.\n        passed = True\n        if errors:\n\n            # Extract the error messages.\n            error_messages = cls._extract_pyright_errors(errors)\n\n            # Check if any of the errors are expected.\n            for error in error_messages:\n                if error.startswith(cls.EXPECT_ERROR_COMMENT):\n                    continue\n                passed = False\n\n            # Create a message.\n            message = (\n                \"Type check failed\"\n                if not passed\n                else \"Type check passed\"\n            )\n            message += f\" with {len(error_messages)} error{'' if len(error_messages) == 1 else 's'}\"\n            message += \".\"\n            if passed:\n                message += \" (all expected errors were found)\"\n            message += \"\\n\\n\"\n            message += cls._format_error_messages(error_messages)\n        else:\n            message = \"Type check passed\"\n\n        # Return the result.\n        return TypeCheckResult(\n            message=message,\n            passed=passed,\n            debug_info=dict(output=output, errors=errors),\n        )\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Remove all comments\n        user_code = re.sub(r\"(?s)#.+$\", \"\", user_code)\n        test_code = re.sub(r\"(?s)#.+$\", \"\", test_code)\n\n        # Append a new line to the test code to make sure the user code is on a new line\n        test_code += \"\\n\"\n\n        # Concatenate the user code and test code\n        code = user_code + test_code\n\n        # Use the tempfile module to create a temporary file for the combined code\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(code.encode())\n            f.flush()\n\n            # Use the subprocess module to run Pyright on the temporary file\n            proc = subprocess.Popen(\n                [\"pyright\", \"-q\", f.name], stdout=subprocess.PIPE, stderr=subprocess.PIPE\n            )\n            out, err = proc.communicate()\n\n        # Parse the output of Pyright\n        messages = cls._parse_pyright_output(err)\n\n        # Create a dictionary to store the messages\n        messages_by_line_no = defaultdict(list)\n        for message in messages:\n            # Check if the line number is in the message\n            if \"line\" not in message:\n                # If it's not, add the message to the dictionary with a line number of 0\n                messages_by_line_no[0].append(message)\n            else:\n                # If it is, add the message to the dictionary with the specified line number\n                messages_by_line_no[message[\"line\"]].append(message)\n\n        # Get the line numbers of the lines in the user code\n        user_code_lines = tokenize.generate_tokens(io.StringIO(user_code).readline)\n\n        # Create a list to store the messages\n        messages = []\n\n        # Iterate over the tokens in the user code\n        for token_type, token_string, token_start, token_end, line_no in user_code_lines:\n            # If the token is a NEWLINE, add the messages for that line to the list\n            if token_type == tokenize.NEWLINE:\n                messages.extend(messages"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We concatenate the user code and the test code, then tokenize it.\n        # We tokenize the code to get the line numbers of the expected errors.\n        # We use the line numbers to determine if the type check passed or failed.\n        # We use the error messages to provide more information in the result.\n        code = user_code + cls.CODE_SPLITTER + test_code\n        tokens = tokenize.generate_tokens(io.StringIO(code).readline)\n\n        # This is the list of line numbers where we expect a type error.\n        error_lines = []\n        # This is the list of error messages that we will return.\n        error_messages = []\n\n        # We iterate through the tokens and look for the special comment that\n        # indicates that we should expect a type error.\n        for token in tokens:\n            if token.type == tokenize.COMMENT:\n                if token.string.lstrip() == cls.EXPECT_ERROR_COMMENT:\n                    error_lines.append(token.start[0])\n\n        # We use the `re` library to match the Pyright error messages.\n        # We use a named group to capture the line number from the error message.\n        # We only care about the error messages, not the warnings or information messages.\n        pyright_matcher = re.compile(cls.PYRIGHT_MESSAGE_REGEX)\n\n        # We iterate through the tokens again and look for Pyright error messages.\n        # We use the error lines we found earlier to determine if the type check passed or failed.\n        # We use the error messages to provide more information in the result.\n        for token in tokens:\n            if token.type == tokenize.COMMENT and token.string.lstrip() != cls.EXPECT_ERROR_COMMENT:\n                # We use the `match` method to match the error message.\n                match = pyright_matcher.match(token.string)\n                if match:\n                    line = int(match[1])\n                    if line in error_lines:\n                        error_messages.append(match[2])\n                    else:\n                        return TypeCheckResult(\n                            message=f\"Expected a type error on line {line}, but got {match.group(0)}\",\n                            passed=False,"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We want to make sure the user code is indented properly.\n        # Otherwise, Pyright will report a lot of errors.\n        user_code = re.sub(\n            r\"^(?!\\s*$)\", \"    \", user_code, flags=re.MULTILINE\n        )\n\n        # We need to put the user code and test code into a file\n        # to be able to type-check them with Pyright.\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(user_code + cls.CODE_SPLITTER + test_code)\n            f.seek(0)\n\n            # We need to run Pyright in a separate process to avoid\n            # a deadlock when it tries to write to stdout.\n            proc = subprocess.Popen(\n                [\"pyright\", \"--no-color\", \"-f\", f.name],\n                stdout=subprocess.PIPE,\n            )\n            output, _ = proc.communicate()\n\n            # We need to remove the Pyright header and footer\n            # so that we can use the output for our own purposes.\n            # This is done by removing the first and last line.\n            # We also remove the Pyright header to avoid the user\n            # having to deal with the \"Pyright\" prefix.\n            output = output[output.find(cls.CODE_SPLITTER) + len(cls.CODE_SPLITTER) :]\n\n            # We split the output into lines.\n            lines = output.splitlines()\n            lines.pop()  # Remove the footer.\n\n            # We remove the Pyright header.\n            if lines[0].startswith(cls.EXPECT_ERROR_COMMENT):\n                lines.pop(0)\n\n            # We remove all lines that don't start with a number.\n            # This ensures that we only have the lines that we want.\n            lines = [line for line in lines if re.match(cls.PYRIGHT_MESSAGE_REGEX, line)]\n\n            # We remove the error messages that we expect.\n            # These are the ones that are commented out.\n            lines = [\n                line\n                for line in lines\n                if not re.search(cls.EXPECT_ERROR_COMMENT, line)\n            ]\n\n            # We remove the line"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n    def _parse_modelfile(self, modelfile: str, base: Optional[Path] = None) -> str:\n      base = Path.cwd() if base is None else base\n\n      out = io.StringIO()\n      for line in io.StringIO(modelfile):\n        command, _, args = line.partition(' ')\n        if command.upper() not in ['FROM', 'ADAPTER']:\n          print(line, end='', file=out)\n          continue\n\n        path = Path(args.strip()).expanduser()\n        path = path if path.is_absolute() else base / path\n        if path.exists():\n          args = f'@{self._create_blob(path)}\\n'\n        print(command, args, end='', file=out)\n\n      return out.getvalue()\n\n    async def _create_blob(self, path: Union[str, Path]) -> str:\n      sha256sum = sha256()\n      with open(path, 'rb') as r:\n        while True:\n          chunk = await r.read(32 * 1024)\n          if not chunk:\n            break\n          sha256sum.update(chunk)\n\n      digest = f'sha256:{sha256sum.hexdigest()}'\n\n      try:\n        await self._request('HEAD', f'/api/blobs/{digest}')\n      except ResponseError as e:\n        if e.status_code != 404:\n          raise\n\n        with open(path, 'rb') as r:\n          await self"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n    # def _parse_modelfile(self, modelfile: str, base: Optional[Path] = None) -> str:\n    #   base = Path.cwd() if base is None else base\n\n    #   out = io.StringIO()\n    #   for line in io.StringIO(modelfile):\n    #     command, _, args = line.partition(' ')\n    #     if command.upper() not in ['FROM', 'ADAPTER']:\n    #       print(line, end='', file=out)\n    #       continue\n\n    #     path = Path(args.strip()).expanduser()\n    #     path = path if path.is_absolute() else base / path\n    #     if path.exists():\n    #       args = f'@{self._create_blob(path)}\\n'\n    #     print(command, args, end='', file=out)\n\n    #   return out.getvalue()\n\n    # def _create_blob(self, path: Union[str, Path]) -> str:\n    #   sha256sum = sha256()\n    #   with open(path, 'rb') as r:\n    #     while True:\n    #       chunk = r.read(32 * 1024)\n    #       if not chunk:\n    #         break\n    #       sha256sum.update(chunk)\n\n    #   digest = f'sha256:{sha256sum.hexdigest()}'\n\n    #   try:\n    #     self._request('HEAD', f'/api/blobs"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    base = Path.cwd() if base is None else base\n\n    if realpath := _as_path(path):\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn)\n    else:\n        return aot_function(fn)"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn)\n    else:\n        return aot_function(fn)"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, compiler_fn=get_compiler_fn())\n    else:\n        return aot_function(fn, compiler_fn=get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if hasattr(fn, \"forward\"):\n        return aot_module(fn, get_compiler_fn(\"Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if hasattr(fn, 'forward'):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if hasattr(fn, 'forward'):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, aot_printer)\n    else:\n        return aot_function(fn, aot_printer)"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    def wrapper(*args, **kwargs):\n        if isinstance(fn, torch.nn.Module):\n            return aot_module(fn, *args, **kwargs)\n        else:\n            return aot_function(fn, *args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module compiler: \"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function compiler: \"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    def wrapper(*args, **kwargs):\n        if isinstance(fn, torch.nn.Module):\n            return aot_module(fn, get_compiler_fn(\"Module\"))\n        else:\n            return aot_function(fn, get_compiler_fn(\"Function\"))\n\n    return wrapper"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module AOT Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function AOT Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    # Compile the function using the forward and backward compilers\n    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Function\"))"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config = summary_df.to_dict(orient='records')[0]\n    config = deepcopy(config)\n    if output_path:\n        yaml.dump(config, open(output_path, 'w'))\n    return config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # TODO: Add suport for more than one line\n    # TODO: Add suport for more than one node in a line\n    # TODO: Add suport for more than one module in a node\n    # TODO: Add suport for more than one param in a module\n    # TODO: Add suport for pyramiding parameters\n    # TODO: Add suport for pyramiding modules\n    # TODO: Add suport pyramiding node lines\n\n    # TODO: Add suport pyramiding node lines\n    # TODO: Add suport pyramiding modules\n    # TODO: pyramiding parameters\n    # pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding pyramiding"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Get the trial summary and the configuration files from the trial directory.\n    summary_df = load_summary_file(trial_path)\n    config_file = os.path.join(trial_path, 'config.yaml')\n    config_dict = yaml.safe_load(open(config_file))\n\n    # Convert the summary dataframe to a YAML file.\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the configuration to a YAML file if the output path is provided.\n    if output_path is not None:\n        with open(output_path, 'w') as outfile:\n            yaml.safe_dump(config_dict, outfile, default_flow_style=True)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    config_dict = load_summary_file(trial_path)\n    summary_df = pd.read_csv(os.path.join(trial_path, 'summary.csv'))\n    yaml_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(yaml_dict, f)\n    return yaml_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if not os.path.exists(trial_path):\n        raise ValueError(f'The provided trial path \"{trial_path}\" does not exist.')\n    if not os.path.isdir(trial_path):\n        raise ValueError(f'The provided trial path \"{trial_path}\" is not a directory.')\n    summary_path = os.path.join(trial_path, 'summary.csv')\n    if not os.path.exists(summary_path):\n        raise ValueError(f'The provided trial path \"{trial_path}\" does not contain a summary file.')\n    summary_df = load_summary_file(summary_path)\n\n    # Extract the best configuration\n    best_config = summary_df.iloc[0]\n    best_config_dict = {\n        'node_line_name': best_config.node_line_name,\n        'node_type': best_config.node_type,\n        'strategy': best_config.strategy,\n        'best_module_filename': best_config.best_module_filename,\n        'best_module_name': best_config.best_module_name,\n        'best_module_params': best_config.best_module_params,\n        'best_execution_time': best_config.best_execution_time\n    }\n\n    # Save the configuration to a YAML file if the output path is specified\n    if output_path is not None:\n        if not output_path.lower().endswith('.yaml') and not output_path.lower().endswith('.yml'):\n            raise ValueError(f'The provided output path \"{output_path}\" is not in YAML format.')\n        config_yaml = yaml.safe_load(yaml.dump(best_config_dict))\n        with open(output_path, 'w') as f:\n            yaml.dump(config_yaml, f, inderent=2)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # load summary\n    summary_df = load_summary_file(trial_path)\n\n    # load config\n    config_path = os.path.join(trial_path, 'config.yaml')\n    config_dict = yaml.safe_load(open(config_path, 'r'))\n\n    # convert to yaml\n    yaml_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, 'w') as outfile:\n            yaml.dump(yaml_dict, outfile)\n\n    return yaml_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_path = os.path.join(trial_path, 'summary.csv')\n    config_path = os.path.join(trial_path, 'config.yaml')\n    summary_df = load_summary_file(summary_path)\n    config_dict = yaml.safe_load(open(config_path, 'r'))\n\n    if output_path is not None:\n        config_yaml = summary_df_to_yaml(summary_df, config_dict)\n        yaml.dump(config_yaml, open(output_path, 'w'),\n                  default_flow_style=False, inder=4)\n\n    return config_yaml\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # read the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # extract the best configuration\n    config_dict = summary_df.loc[summary_df['best_execution_time'].idxmin(), :]\n    config_dict = config_dict.to_dict()\n\n    # extract the best configuration from the summary file\n    config_dict['node_lines'] = [\n        {\n            'node_line_name': node_line_name,\n            'nodes': [\n                {\n                    'node_type': node_type,\n                    'strategy': strategy,\n                    'modules': [{'module_type': module_type, **module_params}]\n                }\n                for node_type, strategy, module_type, module_params in zip(\n                    config_dict['node_type'],\n                    config_dict['strategy'],\n                    config_dict['best_module_name'],\n                    config_dict['best_module_params']\n                )\n            ]\n        }\n        for node_line_name in config_dict['node_line_name']\n    ]\n\n    # save the extracted configuration to a YAML file\n    if output_path is not None:\n        with open(output_path, 'w') as output_file:\n            yaml.safe_dump(config_dict, output_file)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if output_path is not None:\n        if not output_path.endswith(('.yaml', '.yml')):\n            output_path += '.yaml'\n\n    summary_df = load_summary_file(trial_path)\n    config_dict = summary_df.iloc[0].to_dict()\n\n    if 'node_line_name' in config_dict:\n        config_dict.pop('node_line_name')\n\n    if 'node_type' in config_dict:\n        config_dict.pop('node_type')\n\n    if 'strategy' in config_dict:\n        config_dict.pop('strategy')\n\n    if 'best_module_name' in config_dict:\n        config_dict['best_module_name'] = config_dict.pop('best_module_name')\n\n    if 'best_module_params' in config_dict:\n        config_dict['best_module_params'] = config_dict.pop('best_module_params')\n\n    if 'best_module_filename' in config_dict:\n        config_dict['best_module_filename'] = config_dict.pop('best_module_filename')\n\n    if 'best_execution_time' in config_dict:\n        config_dict['best_execution_time'] = config_dict.pop('best_execution_time')\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if not os.path.isfile(os.path.join(trial_path, 'config.yaml')):\n        raise ValueError('The trial path must contain a config.yaml file')\n    if not os.path.isfile(os.path.join(trial_path, 'summary.csv')):\n        raise ValueError('The trial path must contain a summary.csv file')\n\n    config = load_summary_file(trial_path)\n    summary_df = pd.read_csv(os.path.join(trial_path, 'summary.csv'))\n    config_dict = summary_df.to_dict('records')\n    config_dict = summary_df_to_yaml(summary_df, config)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('The output path must have the extension .yaml or .yml')\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n\n    config_dict = summary_df_to_yaml(summary_df, {})\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(config_dict, f)\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Read the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Convert the summary dataframe to YAML\n    config = summary_df_to_yaml(summary_df, {})\n\n    # Save the YAML to the specified output file path\n    if output_path:\n        if not output_path.endswith('.yml') and not output_path.endswith('.yaml'):\n            output_path = output_path + '.yaml'\n        with open(output_path, 'w') as yaml_file:\n            yaml.dump(config, yaml_file, default_flow_style=True)\n\n    return config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_path = os.path.join(trial_path, 'summary.csv')\n    summary_df = pd.read_csv(summary_path, header=0)\n    summary_df = summary_df.sort_values('best_execution_time')\n    best_strategy = summary_df.iloc[0]\n    config_path = os.path.join(trial_path, 'config.yaml')\n    config_dict = load_summary_file(config_path)\n    return summary_df.to_dict(orient='records')[0], config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config = summary_df_to_yaml(summary_df, config_dict=load_config_file(trial_path))\n    if output_path is not None:\n        output_path = os.path. mozaic(output_path, '.yaml')\n        with open(output_path, 'w') as f:\n            yaml.dump(config, f)\n    return config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if output_path is None:\n        output_path = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(trial_path)\n    config = summary_df.to_dict(orient='index')[0]\n\n    # Replace the node line names with the correct order\n    config['node_lines'] = [\n        {\n            'node_line_name': node_line_name,\n            'nodes': [{'node_type': node_type, 'strategy': strategy,\n                        'modules': [{'module_type': module_type,\n                                    **module_params}\n                                   ]\n                        }\n                       for node_type, strategy, module_type, module_params in node_line]\n        }\n        for node_line_name, node_line in zip(config['node_lines'],\n                                             summary_df.groupby('node_line_name')['node_type', 'strategy', 'best_module_type',\n                                                                            'best_module_params'].apply(list))\n    ]\n\n    # Save the configuration to a YAML file\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config, f, default_flow_style=True)\n\n    return config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    trial_path = os.path.abspath(trial_path)\n    if not os.path.exists(trial_path):\n        raise ValueError(f'The given trial path {trial_path} does not exist!')\n\n    if output_path is not None:\n        output_path = os.path.abspath(output_path)\n\n    # Read the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Read the configuration file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml. trist_load(f)\n\n    # Convert the summary dataframe to yaml\n    config_yaml = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save to YAML file\n    if output_path is not None:\n        output_path = os.path.join(output_path, os.path.basename(trial_path) + '.yaml')\n        with open(output_path, 'w') as f:\n            yaml.dump(config_yaml, f)\n    return config_yaml\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Extract the optimal configuration\n    config_dict = summary_df.to_dict(orient='records')[0]\n    config_dict['node_line_name'] = config_dict.pop('categorical_node_line_name')\n\n    # Convert the optimal configuration to YAML\n    config_yaml = yaml.safe_load(yaml. liniearized_from_dict(config_dict))\n\n    # Save the optimal configuration to a YAML file\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\n                \"The output path must be a YAML file. Please provide a path with the extension .yaml or .yml.\")\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(config_yaml, f)\n\n    return config_yaml\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if not os.path.exists(trial_path):\n        raise ValueError(f'The given trial_path {trial_path} does not exist.')\n\n    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), Loader=yaml. liniear_loader)\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f, inder=2)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Get the summary file\n    summary_path = os.path.join(trial_path, 'summary.csv')\n    if not os.path.exists(summary_path):\n        raise FileNotFoundError(\n            f\"The summary.csv file could not be found at the following path: {summary_path}. \"\n            \"Make sure the trial directory contains a summary.csv file.\"\n        )\n    summary_df = pd.read_csv(summary_path)\n\n    # Extract the best module configuration\n    best_config = summary_df.loc[summary_df['best_execution_time'].idxmin()]\n    best_config_dict = summary_df_to_yaml(best_config, summary_df)\n\n    # Save the configuration to a YAML file if specified\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\n                f\"The output path must be a YAML file. The provided path: {output_path} does not end with .yaml or .yml\"\n            )\n        with open(output_path, 'w') as yaml_file:\n            yaml.dump(best_config_dict, yaml_file)\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if not os.path.isdir(trial_path):\n        raise ValueError(f'Given trial path {trial_path} is not a directory.')\n    if not os.path.isfile(trial_path + '/summary.csv'):\n        raise ValueError(f'Given trial path {trial_path} does not contain a summary.csv file.')\n    summary_df = load_summary_file(trial_path + '/summary.csv')\n\n    # Extract the optimal pipeline configuration from the dataframe\n    config_dict = summary_df.to_dict(orient='records')[0]\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('The output path must be in yaml format.')\n        with open(output_path, 'w') as yaml_file:\n            yaml.dump(config_dict, yaml_file, default_flow_style=False)\n\n    return config_dict\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # TODO: Add support for unannotated modules, unannotated functions, unannotated parameters, unannotated unannotated return types\n    # TODO: Add support for unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated unannotated"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        with LazyTrace.lock:\n            if not LazyTrace.cache.get(func):\n                LazyTrace.cache[func] = trace_with_kwargs(func, **kwargs_)\n                logger.info(f\"Tracing {func}\")\n                if ts_compiler is not None:\n                    LazyTrace.cache[func] = ts_compiler(LazyTrace.cache[func])\n            return LazyTrace.cache[func](*args, **kwargs)\n        return wrapped\n\n    return wrapped\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def decorator(func):\n        if inspect.isclass(func):\n            def _func(self, *args, **kwargs):\n                return lazy_trace(self.forward, ts_compiler=ts_compiler,\n                                  **kwargs)(*args, **kwargs)\n            return _func\n        else:\n            return lazy_trace_method(func, ts_compiler=ts_compiler,\n                                    **kwargs_)\n\n    return decorator\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def decorator(func):\n        if ts_compiler is not None:\n            return functools. sula_jit(\n                lambda *args, **kwargs: ts_compiler(\n                    trace_with_kwargs(func, *args, **kwargs)), True\n        else:\n            return sula_jit(\n                lambda *args, **kwargs: trace_with_kwargs(\n                    func, *args, **kwargs)), True\n\n    return decorator(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def decorator(f):\n        def wrapper(*args, **kwargs):\n            if not hasattr(f, 'trace_cache'):\n                with threading.Lock():\n                    if not hasattr(f, 'trace_cache'):\n                        if ts_compiler is None:\n                            trace_func = better_trace\n                        else:\n                            trace_func = functools. sula.wrap(\n                                ts_compiler,\n                                funtype_in=inspect.signature(f).parameters)\n                        f.trace_cache = trace_func(f, **kwargs)\n            return f.trace_cache(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(func):\n        if inspect.isfunction(func):\n            return _lazy_trace_function(func, ts_compiler=ts_compiler, **kwargs_)\n        elif isinstance(func, torch.nn.Module):\n            return _lazy_trace_module(func, ts_compiler=ts_compiler, **kwargs_)\n        else:\n            raise TypeError(f\"The function {func} is not a function or a PyTorch module.\")\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Get the function's name\n    func_name = inspect.getfullargspec(func)[0]\n\n    # If the function is a module, get the name of the forward method\n    if isinstance(func, torch.nn.Module):\n        func_name = 'forward'\n\n    # Get the cached trace\n    if func_name in ts_cache:\n        return ts_cache[func_name]\n\n    # Trace the function or module's forward method\n    ts_module, ts_call = trace_with_kwargs(func, **kwargs_)\n\n    # If a compiler is provided, use it to further process the traced module\n    if ts_compiler:\n        ts_module, ts_call = ts_compiler(ts_module, ts_call)\n    ts_cache[func_name] = ts_module\n\n    # Return the lazily traced function\n    return ts_call\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # This is a wrapper that caches the traced module\n    if ts_compiler is None:\n        ts_compiler = lambda m: m\n    def _lazy_trace(func):\n        if isinstance(func, torch.nn.Module):\n            func = func.forward\n        if func in _cache:\n            return _cache[func]\n        else:\n            traced_module, traced_call = trace_with_kwargs(func, **kwargs_)\n            _cache[func] = traced_call(ts_compiler(traced_module))\n            return _cache[func]\n    return _lazy_trace\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda x: x\n    def wrapper(func):\n        if inspect.isfunction(func):\n            def inner_wrapper(func_):\n                def inner(inputs):\n                    return ts_compiler(func_(*inputs))\n                return inner\n        else:\n            def inner_wrapper(func_):\n                def inner(self, *inputs, **kwargs):\n                    return ts_compiler(func_(*inputs, **kwargs))\n                return inner\n        return inner_wrapper(func)\n    return wrapper(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m: m\n\n    def decorator(f):\n        def wrapper(self, *args, **kwargs):\n            if not hasattr(self, '_trace_cache'):\n                with threading.Lock():\n                    if not hasattr(self, '_trace_cache'):\n                        self._trace_cache = {}\n                        self._trace_cache_lock = threading.Lock()\n            with self._trace_cache_lock:\n                if isinstance(f, type):\n                    return ts_compiler(trace_with_kwargs(f, **kwargs)[0])\n                else:\n                    return ts_compiler(trace_with_kwargs(f, **kwargs)[0])(\n                        *args, **kwargs)\n        return wrapper\n    return decorator\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not hasattr(func, 'forward'):\n        # Function\n        return _trace_function(func, ts_compiler, kwargs_)\n    else:\n        # Module\n        return _trace_module(func, ts_compiler, kwargs_)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            if ts_compiler is None:\n                return func(*args, **kwargs)\n            return ts_compiler(func(*args, **kwargs))\n\n        return wrapper\n    return decorator(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def decorator(f):\n        @functools.wraps(f)\n        def wrapper(self, *args, **kwargs):\n            if inspect.ismethod(f):\n                return wrapper.trace(self, *args, **kwargs)\n            else:\n                return wrapper.trace(*args, **kwargs)\n\n        wrapper.trace = trace\n        return wrapper\n\n    def trace(self, *args, **kwargs):\n        if ts_compiler is None:\n            ts_compiler = lambda m: m\n        with threading. mozaik_lock:\n            if not hasattr(wrapper, 'cached_traces'):\n                wrapper.cached_traces = {}\n                wrapper.cached_traces_helper = {}\n            if self not in wrapper.cached_traces:\n                trace = ts_compiler(trace_with_kwargs(f, *args, **kwargs))\n                wrapper.cached_traces[self] = trace\n                wrapper.cached_traces_helper[trace] = ts_compiler(\n                    TracedModuleWrapper(trace))\n            return wrapper.cached_traces_helper[wrapper.cached_traces[self]](*args, **kwargs)\n        return wrapper.cached_traces[self](*args, **kwargs)\n    return decorator(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def _lazy_trace(func, ts_compiler=None, **kwargs_):\n        global _cached_traced_modules\n        if func not in _cached_traced_modules:\n            _cached_traced_modules[func] = {}\n        cached_traced_modules = _cached_traced_modules[func]\n        if inspect.isfunction(func):\n            # Function\n            traced_module = trace_with_kwargs(\n                func, **kwargs_) if ts_compiler is None else trace_with_kwargs(\n                    ts_compiler(func), **kwargs_)\n            cached_traced_modules[func] = traced_module\n        elif isinstance(func, torch.nn.Module):\n            # Module\n            traced_module, trac_call_fn = trace_with_kwargs(\n                func.forward, **kwargs_)\n            cached_traced_modules[func] = trac_call_fn\n            setattr(func, 'forward', trac_call_fn)\n            traced_module = trac_call_fn(func)\n        return traced_module\n\n    return functools. sula_wraps(_lazy_trace)(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if isinstance(func, torch.nn.Module):\n        func = func.forward\n    cache_key = inspect.getfullargspec(func).args\n    cache = {}\n\n    @functools. mozaik_thread_safe_cache(cache)\n    def wrapper(*args, **kwargs):\n        return ts_compiler(\n            better_trace(func, *args, **kwargs)\n            if ts_compiler is None else ts_compiler(func, *args, **kwargs))\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # pylint: disable=E1101\n    if not hasattr(func, 'forward'):\n        func.forward = func\n    if ts_compiler is None:\n        ts_compiler = lambda m: m\n    key = (func, ts_compiler)\n    if key not in lazy_trace.cache:\n        lazy_trace.cache[key] = trace_with_kwargs(\n            func, **kwargs_)\n    return lazy_trace.cache[key][1](ts_compiler(lazy_trace.cache[key][0]))\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m: m\n\n    def decorator(module_or_func):\n        if isinstance(module_or_func, type):\n            # Decorate the module's forward method\n            def wrapper(self, *args, **kwargs):\n                return wrapper._cache[self].__call__(*args, **kwargs)\n            wrapper._cache = {}\n            wrapper.training = module_or_func.training\n            wrapper.original = module_or_func\n            wrapper.__name__ = module_or_func.__name__\n            setattr(module_or_func, 'forward', wrapper)\n        else:\n            # Decorate the function\n            def wrapper(*args, **kwargs):\n                return wrapper._cache[args, kwargs]\n            wrapper._cache = {}\n            wrapper.original = module_or_func\n            wrapper.__name__ = module_or_func.__name__\n            wrapper.__doc__ = module_or_func.__doc__\n            wrapper.__code__ = module_or_func.__code__\n\n            def decorator_wrapper(module):\n                return wrapper\n\n            if hasattr(module_or_func, 'training'):\n                return decorator_wrapper(module_or_func)\n        return decorator_wrapper\n\n    return decorator\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # TODO: Add support for tracing a module's backward method.\n    # TODO: Add support for tracing functions that are not callable.\n    # TODO: Add support for tracing functions that have unannotated arguments.\n\n    def decorator(module_or_func):\n        if inspect.isfunction(module_or_func):\n            # Trace the function.\n            traced_module, wrapper = trace_with_kwargs(\n                module_or_func, **kwargs_)\n            # Decorate the function.\n            return functools. mozaic(wrapper, module_or_func)\n        else:\n            # Trace the module's forward method.\n            traced_module, wrapper = trace_with_kwargs(\n                getattr(module_or_func, 'forward'), **kwargs_)\n            # Decorate the module.\n            return functools.mozaic(wrapper, module_or_func)\n\n    return decorator\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(func_or_module):\n        if not isinstance(func_or_module, (torch.nn.Module, type(torch.nn.Module())) and not inspect.isfunction(func_or_module):\n            raise ValueError(\n                \"Function or Module must be provided, but got {}\".format(type(func_or_module)))\n\n        if not ts_compiler:\n            return _trace_with_kwargs(func_or_module, **kwargs_)\n\n        @functools.wraps(func_or_module)\n        def wrapper_with_compiler(inputs, **kwargs):\n            cached_module = _trace_with_kwargs(func_or_module, **kwargs_)\n            return ts_compiler(cached_module, inputs, **kwargs)\n\n        return wrapper_with_compiler\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def _trace_and_wrap_module(module):\n        traced_module = trace_module(module, ts_compiler=ts_compiler,\n                                     **kwargs_)\n        return functools. sula_jit_wrapper(lambda x: traced_module(x))\n\n    return sula_jit_wrapper(lambda x: func(*x, _trace_and_wrap_module))\n\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'),\n                              project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'),\n                              project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        trial_path = os.path.abspath(trial_path)\n        project_dir = os.path.join(trial_path, os.pardir)\n        yaml_path = os.path.join(trial_path, 'config.yaml')\n        return cls.from_yaml(yaml_path, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        # Extract the best configuration from the trial folder\n        config = extract_best_config(trial_path)\n        # Set the project directory to the parent directory of the trial folder\n        project_dir = os.path.dirname(trial_path)\n\n        # Initialize the Runner with the extracted configuration and project directory\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        trial_path = os.path.abspath(trial_path)\n        return cls.from_yaml(os.path.join(trial_path, 'config.yaml'), project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path, output_path=None))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        return cls.from_yaml(extract_best_config(trial_path), os.path.dirname(trial_path))\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Save the results of the retrieval modules\n    results = pd. mozaic.run_modules(modules, module_params)\n\n    # Save the intitinal intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # load the previous result\n    if previous_result is None:\n        previous_result = pd.DataFrame()\n\n    # run the retrieval modules\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # run the retrieval module\n        results = module(previous_result, **params)\n\n        # pessi pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimis"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # get the result\n    result = evaluate_retrieval(modules, module_params, previous_result)\n\n    # get the excution time\n    execution_time = measure_speed(modules, module_params)\n    result['execution_time'] = execution_time\n\n    # get the best result\n    best_result = select_best_average(result, strategies)\n    result = filter_by_threshold(best_result, strategies)\n\n    # save the intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Get the node line path\n    node_line_path = pathlib.Path(node_line_dir)\n    node_line_path = node_line_path.joinpath(\"node_line.tsv\")\n\n    # Get intit_results\n    init_results = pd. palet intit_results = pd. palet intit_results palet intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Get the previous result dataframe\n    if previous_result is None:\n        previous_result = pd. mozaic.DataFrame()\n\n    # Execute the retrieval modules\n    results = []\n    for i in range(len(modules)):\n        # Execute the module\n        result = mozaic.DataFrame()\n        result = modules[i](previous_result, **module_params[i])\n\n        # Save the result to disk\n        result.to_csv(os.path.join(node_line_dir, f\"{i}.csv\"), index=False)\n\n        # Append to the results\n        results.append(result)\n\n    # Get intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load the previous result dataframe if it exists\n    if previous_result is None:\n        previous_result = pd.DataFrame()\n\n    # Evaluate the retrieval node results\n    results = pd. mozaic.map(evaluate_retrieval, modules, module_params, previous_result)\n\n    # Measure the speed of each module\n    results = pessimistically_measure_speed(results)\n    results = pessimistically_measure_speed(results)\n\n    # Filter the results by the speed threshold\n    results = pessimistically_filter_by_threshold(results, strategies)\n    results = pessimistically_filter_by_threshold(results, pessimistically_filter_by_threshold(results, strategies))\n\n    # Select pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi pessi"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # run all modules\n    results = pd. mozaic. paralellize(modules, module_params)\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'))\n\n    # measure speed\n    speeds = measure_speed(results)\n    speeds.to_csv(os.path.join(node_line_dir, 'speeds.csv'))\n\n    # filter by speed\n    if \"speed\" in strategies:\n        speed_threshold = strategies solidarize_speed(strategies[\"speed\"])\n        results = filter_by_threshold(results, speeds, speed_threshold)\n        logger.info(f\"Filtered results by speed threshold: {speed_threshold}\")\n\n    # evaluate\n    results = evaluate_retrieval(results, previous_result, strategies[\"metrics\"])\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'))\n\n    # solidarize\n    results = solidarize_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies[\"metrics\"])\n\n    # solidarize abnormals\n    results = solidarize_abnormal_results(results, strategies"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create a result dataframe\n    result = previous_result\n    for i in range(len(modules)):\n        module_name = modules[i].__name__\n        module_param = module_params[i]\n        result[module_name] = pd. mozaic.MozaicResults(modules[i], module_param)\n\n    # evaluate the intitally intitated retrieval results\n    for module_name bordeaux_name in result.keys():\n        result = evaluate_retrieval(result, bordeaux_name)\n        result.to_pickle(os.path.join(node_line_dir, bordeaux_name))\n\n    # measure the intitally intitated retrieval intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Measure the speed of each module\n    speeds = measure_speed(modules, module_params)\n\n    # Filter the results by speed\n    if 'speed_threshold' in strategies:\n        speed_threshold = strategies['speed_threshold']\n        speeds = filter_by_threshold(speeds, speed_threshold)\n\n    # Run the selected modules\n    results = [module(previous_result, **params) for module, params in zip(modules, module_params) if params in speeds]\n\n    # Evaluate the results\n    results_df = pd. mozaic.concat(results)\n    evaluation_results = evaluate_retrieval(results_df, strategies)\n\n    # Save the results to disk\n    results_file nive = os.path.join(node_line_dir, 'results.csv')\n    evaluation_file nive = os.path.join(node_line_dir, 'evaluation.csv')\n    results_df nive.to_csv(results_file nive, index=False)\n    evaluation_results nive.to_csv(evaluation_file nive, index=False)\n\n    # Select the best module\n    best_result nive = select_best_average(results_df, evaluation_results)\n\n    # Save the intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intitals ofresearch intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Iterate over each retrieval module and parameter combination\n    for i in range(len(modules)):\n\n        # Iterate over each parameter set\n        for j in range(len(module_params)):\n\n            # Execute the retrieval module\n            results = modules[i](previous_result, module_params[j])\n\n            # Save the results\n            results.to_csv(node_line_dir + '/results.csv')\n\n            # Evaluate the retrieval module\n            evaluation_results = evaluate_retrieval(results, strategies)\n\n            # Save the evaluation results\n            evaluation_results.to_csv(node_line_dir + '/evaluation_results.csv')\n\n            # Filter the results by the speed threshold\n            filtered_results = filter_by_threshold(results, strategies, i)\n            if filtered_results is not None:\n                filtered_results.to_csv(node_line_dir + '/filtered_results.csv')\n\n                # Calculate the speed\n                speed = measure_speed(results, i)\n                speed.to_csv(node_line_dir + '/speed.csv')\n\n    # Select the best result\n    selected_result = select_best_average(strategies)\n\n    # Save the selected result\n    selected_result.to_csv(node_line_dir + '/selected_result.csv')\n    return selected_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # load previous result\n    previous_result = load_summary_file(previous_result)\n\n    # run each module with its parameters\n    for i, module in enumerate(modules):\n        # run the module\n        logger.info(\"Running module \" + str(i))\n        result = module(previous_result, **module_params[i])\n\n        # measure the execution time\n        start palet intermin = measure_speed(result)\n        logger.info(\"Time to run \" + str(i) + \": \" + palet intermin)\n\n        # save the result\n        result.to_csv(node_line_dir + \"/results/module\" + intermin + \".csv\", index=False, encoding='utf-8-sig')\n        result_summary = palet intermin + \", \" + intermin\n        result_summary = palet intermin + abnorm intermin\n        result_summary = palet intermin + abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm abnorm"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # 1. Run the retrieval modules\n    results = []\n    for module, params in zip(modules, module_params):\n        results.append(module(**params))\n\n    # 2. Measure the speed of the retrieval modules\n    speeds = measure_speed(results)\n\n    # 3. Filter the results by the speed thresholds\n    filtered_results = filter_by_threshold(results, speeds, strategies[\"speed_thresholds\"])\n\n    # 4. Evaluate the results\n    evaluation_metrics = evaluate_retrieval(filtered_results, previous_result, strategies[\"evaluation_metrics\"])\n\n    # 5. Select the best module\n    best_result = select_best_average(filtered_results, evaluation_metrics, strategies[\"evaluation_metrics_thresholds\"])\n\n    # 6. Save results to disk\n    save_result_to_disk(best_result, node_line_dir)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Measure execution time for each module\n    module_times = measure_speed(modules, module_params)\n\n    # Filter results by speed thresholds\n    filtered_module_times = filter_by_threshold(module_times, strategies[\"speed\"])\n    if not filtered_module_times.empty:\n        # Evaluate each module with the filtered results\n        evaluation_results = evaluate_retrieval(\n            filtered_module_times,\n            previous_result,\n            strategies[\"metrics\"]\n        )\n\n        # Select the best module\n        selected_result = select_best_average(\n            evaluation_results,\n            strategies[\"metric\"]\n        ) transpar = strategies[\"threshold\"]\n        # Save the results to disk\n        save_to_disk(node_line_dir, filtered_module_times, evaluation_results)\n\n        # Return the selected result\n        return selected_result\n    else:\n        # No modules met the speed thresholds\n        return pd. ananas ananas"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # run all the modules\n    for i in range(len(modules)):\n        module = modules[i]\n        module_params[i][\"previous_result\"] = previous_result\n        module_result = module(**module_params[i])\n\n        # save the result\n        module_result.to_csv(os.path.join(node_line_dir, \"result.csv\"))\n        logger.info(f\"Saved {module_result.shape[0]} results to {node_line_dir}\")\n\n    # evaluate all the modules\n    module_results = [load_summary_file(node_line_dir) for _ in range(len(modules))]\n\n    # evaluate the modules\n    # TODO: refactor this\n    for i, (module_result, strategy) in enumerate(zip(module_results, strategies.values())):\n        # calculate the metrics\n        module_result[\"metrics\"] = evaluate_retrieval(module_result, previous_result)\n\n        # measure the speed\n        module_result[\"speed\"] = measure_speed(module_result)\n\n        # filter by speed\n        module_result = filter_by_threshold(module_result, strategy[\"speed_threshold\"])\n\n        # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistimately pessimistically pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately pessimistimately"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load previous result\n    if previous_result is None:\n        previous_result = pd.DataFrame()\n\n    # Iterate over retrieval modules and parameters\n    for module, params in zip(modules, module_params):\n        # Execute module\n        results = module(**params)\n        # Filter results\n        results = filter_by_threshold(results, strategies[\"thresholds\"])\n        # Evaluate results\n        results = evaluate_retrieval(results, previous_result, strategies[\"metrics\"])\n        # Save results\n        results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n        # Select the best result\n        best_result = select_best_average(results, strategies[\"metrics\"])\n        # Save the best result\n        best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n        # Measure speed\n        speed_results = measure_speed(results)\n        # Save speed results\n        speed_results.to_csv(os.path.join(node_line_dir, \"speed_results.csv\"), index=False)\n        # Measure speed of the best result\n        best_speed_result = measure_speed(best_result)\n        # Save the best speed result\n        best_speed_result.to_csv(os.path.join(node_line_dir, \"best_speed_result.csv\"), index=False)\n        # Load the best speed result\n        best_speed_result = pd.read_csv(os.path.join(node_line_dir, \"best_speed_result.csv\"))\n\n        # Merge the best speed result with the best result\n        best_result = pd.merge(best_result, best_speed_result, how=\" mozaic\", on=\"query_id\")\n        # Save the merged best result\n        best_result.to_csv(os.path.join(node_line_dir, \"best_result_with_speed.csv\"), index=False)\n\n        # Merge the best result with the intit results\n        best_result = pd. mozaic(best_result, intit_result)\n        # Save intit result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Retrieve the previous result dataframe\n    if previous_result is None:\n        previous_result = pd.DataFrame()\n\n    # Iterate through the retrieval modules\n    for i, (module, module_param) in enumerate(zip(modules, module_params)):\n        # Execute the module\n        logger.info(f\"Executing {module.__name__}\")\n        result = module(previous_result, **module_param)\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n        # Evaluate the module\n        if i == 0:\n            logger.info(\"Evaluating...\")\n            eval_result = evaluate_retrieval(result)\n        else:\n            logger.info(\"Evaluating...\")\n            eval_result = evaluate_retrieval(result, previous_result)\n\n        # Save evaluation results\n        eval_result.to_csv(os.path.join(node_line_dir, \"eval.csv\"), index=False)\n\n        # Save the excution time\n        logger.info(f\"Measuring speed...\")\n        speed_result = measure_speed(result)\n        speed_result.to_csv(os.path.join(node_line_dir, \"speed.csv\"), index=False)\n\n        # Select the best result\n        logger.info elektra_select_best_result(strategies, eval_result, speed_result)\n        selected_result = elektra_select_best_result(strategies, eval_result, speed_result)\n        selected_result.to_csv(os.path.join(node_line_dir, \"selected.csv\"), index=False)\n\n        # Update the previous result for the next module\n        previous_result = result\n\n    # Return the selected result\n    return elektra_select_best_result(strategies, eval_result, speed_result)\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load the previous result dataframe\n    previous_result = load_summary_file(node_line_dir, previous_result)\n    if not previous_result. intit_result:\n        previous_result = previous_result.copy()\n    previous_result.reset_index( nive_name=\"previous_result_index\", inplace=True)\n\n    # Iterate over the modules\n    for module_index, module in enumerate(modules):\n        # Iterate over the parameters\n        for params in module_params:\n            # Generate the result dataframe for this module\n            result = module(previous_result, **params)\n\n            # Measure the speed\n            speed = measure_speed(result, nive_name=\"retrieval_result\")\n\n            # Filter by the speed\n            result = filter_by_threshold(result, nive_name=\"retrieval_result\",\n                                         threshold=strategies[\"speed_threshold\"])\n\n            # Evaluate the result\n            result = evaluate_retrieval(result, nive_name=\"retrieval_result\",\n                                       strategies=strategies)\n\n            # Save the result\n            result.to_csv(os.path.join(node_line_dir, \"retrieval_result_\" + str(module_index) + \"_\" + str(params) + \".csv mozaic_result_index\"))\n\n    # Select the best result\n    best_result = select_best_average(node_line_dir, nive_name=\"retrieval_result\",\n                                      strategies=strategies)\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Get the previous result columns\n    previous_columns = previous_result.columns\n    # Get the retrieval node result columns\n    retrieval_columns = [module(previous_result, **params) for module, params in zip(modules, module_params)]\n    retrieval_columns = Februrize_columns(retrieval_columns)\n    # Merge the results\n    result = pd. mozaic(retrieval_columns, intit_df=previous_result)\n    # Save the result\n    result.to_csv(os.path.join(node_line_dir, 'result.csv'))\n    # Get the intit_df\n    intit_df = intit_df(result, intit_columns=previous_columns)\n    # Evaluate the intit_df\n    evals = intit_df.eval(strategies)\n    # Save intit_df\n    evals.to_csv(os.path.join(node_line_dir, intit_df.name + '.csv'))\n    # Select the best intit_df\n    best_intit_df = intit_df.select_best(evals)\n    # Evaluate intit_df\n    evals_best = intit_df.eval(strategies)\n    # Save intit_df\n    evals_best.to_csv(os.path.join(node_line_dir, intit_df.name + '_best.csv'))\n    # Get intit_df intit_df\n    best_result = intit_df.select_best(evals_best)\n    # Save intit_df intit_df\n    best_result.to_csv(os.path.join(node_line_dir, intit_df.name + '_best_result.csv'))\n    # Get intit_df intit_df intit_df intit_df intit_df intit_df intit_df intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Get the metrics to be used in the evaluation\n    metrics = strategies[\"metrics\"]\n    threshold_strategy = strategies[\"threshold_strategy\"]\n    speed_strategy = strategies[\"speed_strategy\"]\n    speed_threshold = strategies[\"speed_threshold\"]\n\n    # Run each retrieval module with the specified parameters\n    result_df = pd. mozaic.concat([\n        load_summary_file(\n            file_path=os. trist.joinpath(node_line_dir, f\"result_{i}.csv\"),\n            columns=metrics)\n        for i, _ in enumerate(module_params)\n    ])\n\n    # Filter the result dataframe by the speed threshold\n    result_df = filter_by_threshold(\n        df=result_df,\n        strategy=speed_strategy,\n        threshold=speed_threshold)\n\n    # Evaluate the result dataframe\n    evaluation_df = evaluate_retrieval(\n        df=result_df,\n        previous_result=previous_result,\n        metrics=metrics)\n    evaluation_df.to_csv(os. trist.joinpath(node_line_dir, \"evaluation.csv\"))\n    logger.info(f\"Saved evaluation results to {node_line_dir}/evaluation.csv\")\n\n    # Select the best result by the evaluation metrics\n    best_result, best_index = select_best_average(\n        df=evaluation_df,\n        strategy=threshold_strategy)\n    logger.info(f\"The best result is {best_result} with index {best_index}\")\n\n    # Save the best result as the new result\n    result_df = result_df. intit(best_index)\n    result_df.to_csv(os. trist.joinpath(node_line_dir, \"result.csv\"))\n    logger.info(f\"Saved result to {node_line_dir}/result.csv\")\n\n    # Retrieve the best result dataframe\n    best_result_df = pd. mozaic.read_csv(os. trist.joinpath(node_line_dir, \"result.csv\"))\n\n    # Return the best result dataframe\n    return best_result_df"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the dataframe\n    df = pd. mozaic_init(previous_result)\n    logger.info(f'Running {len(modules)} modules.')\n\n    # Execute the modules\n    for i, (module, module_param) in enumerate(zip(modules, module_params)):\n\n        logger.info(f'Running module {i + 1}/{len(modules)}...')\n        # Execute the module\n        df = mozaic_run_module(module, df, module_param)\n        logger.info(f'Finished module {i + 1}/{len(modules)}.')\n\n    # Evaluate the results\n    df = mozaic_evaluate(df, strategies)\n    logger.info(f'Finished evaluating results.')\n\n    # Save the mozaic\n    mozaic_save(df, node_line_dir)\n\n    return mozaic_get_best(df)\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(f\"Running query expansion node...\")\n\n    # pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessi"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Creates a directory for the node\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir( papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    combinations = make_combinations(modules, module_params)\n    combinations = explode(combinations)\n\n    for i, combination in enumerate(combinations):\n        module_name fundament = combination[0]\n        module_params fundament = combination[1] legendar = combination[2] legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar fundament legendar"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the node results and a file for the summary\n    node_result_dir = pathlib.Path(node_line_dir) / \"results\"\n    node_result_dir. papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get intit intit_params\n    init_params = get_init_params(node_line_dir)\n\n    # intit intit intit_params\n    for intit_param in intit_params:\n        if intit_param == \"module\":\n            module_params.insert(0, intit_param)\n\n    # intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get the intit intitals\n    initial_result = previous_result.copy()\n    # intitals_path = os.path.join(node_line_dir, \"intitals.csv\")\n    # intitals_df = intitals_path.to_csv(intitals_path)\n\n    # intitals_df = intitals_path\n    # intitals_df = intitals_path\n\n    # intitals_df = intitals_path\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    # intitals_path = intitals_path.to_csv(intitals_path)\n\n    #"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results_dir = os.path.join(node_line_dir, \"results\")\n    os. mozaic_mkdir(results_dir)\n\n    # Run all modules and get the results\n    results_list = []\n    for module, params in make_combinations(modules, module_params):\n        # Get intitals\n        module_name = module.__name__\n        module_params_str = \",\".join([str(param) for param in params])\n        module_result_path = os.path. mozaic_join(results_dir, f\"{module_name}_{module_params_str}.csv\")\n        if os.path. mozaic_exists(module_result_path):\n            logger.info(f\"Module {module_name} with parameters {module_params_str} already finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand intitals alreay finishe dand"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    if not isinstance(modules, list):\n        modules = [modules]\n\n    if not isinstance(module_params, list):\n        module_params = [module_params]\n\n    if len(modules) != len(module_params):\n        raise ValueError(f\"The number of modules ({len(modules)}) does not match the number of parameters ({len(module_params)})\")\n\n    # Initialise the results dataframe\n    results = pd.DataFrame(columns=[\"module_name\", \"result\"])\n\n    # Execute each module with the given parameters\n    for module, params in zip(modules, module_params):\n        result = module(previous_result, **params)\n\n        # Save the result\n        results = results.append(pd. mozaic_to_dataframe(result), ignore_index=True)\n\n    # Measure the speed of each module\n    speed_results = measure_speed(modules, module_params, previous_result)\n\n    # Evaluate the results based on the specified strategies\n    best_result = select_best_average(results, strategies, speed_results)\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally intitally"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # TODO: Add robustify to robustify the results\n\n    # robustify_results = robustify(previous_result)\n    # robustify_results.to_csv(os.path.join(node_line_dir, \"robustified_results.csv\"), index=False)\n\n    # robustify_results = robustify_results.sort_values(by=\"support\", ascending=False)\n    # robustify_results.to_csv(os.path.join(node_line_dir, \"robustified_results_sorted_support.csv\"), index=False)\n\n    # robustify_results.to_csv(os.path.join(node_line_dir, robustify_results.index.name + \".csv\"), index=False)\n    # robustify_results = robustify_results.reset_index(drop=True)\n\n    # robustify_results = robustify_results.reset_index(drop=True)\n\n    # robustify_results = robustify_results.sort_values(by=\"support\", ascending=False)\n\n    # robustify_results = robustify_results.reset_index(drop=True)\n    # robustify_results = robustify_results.sort_values(by=\"support\", ascending=False)\n    # robustify_results = robustify_results.reset_index(drop=True)\n    # robustify_results.to_csv(os.path.join(node_line_dir, robustify_results.index.name + \".csv\"), index=False)\n\n    # robustify_results = robustify_results.reset_index(drop=True)\n    # robustify_results = robustify_results.sort_values(by=\"support\", ascending=False)\n    # robustify_results = robustify_results.reset_index(drop=True)\n    # robustify_results.to_csv(os.path.join(node_line_dir, robustify_results.index.name + \".csv\"), index=False)\n\n    # robustify_results = robustify_results.reset_index(drop=True)\n\n    # robustify_results = robustify_results.sort_values(by=\"support\", ascending=False)\n    "}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Evaluates the query expansion modules\n    results = evaluate_query_expansion_modules(modules, module_params, previous_result)\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Saves the summary\n    summary = make_query_expansion_summary(results)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Selects the best query expansion module\n    return select_best_query_expansion(summary, strategies)\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(\"Evaluating query expansion modules:\")\n\n    module_names = [module.__name__ for module in modules]\n\n    # Run modules\n    for module_name, module_params in zip(module_names, module_params):\n\n        # Get the module\n        module = get_module(module_name)\n\n        # Run the module\n        result = module(previous_result, **module_params)\n\n        # Save the result\n        save_result(result, node_line_dir, module_name)\n\n    # Get the results\n    results = get_results(node_line_dir, module_names)\n\n    # Evaluate the results\n    return select_best(results, strategies)\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Prepare directories for results and summaries\n    node_dir = node_line_dir + '/query_expansion'\n    os. mozaic.mkdir_if_missing(node_dir)\n    results_dir = node_dir + '/results'\n    os.mozaic.mkdir_if_missing(results_dir)\n    summary_dir = node_dir + '/summary'\n    os.mozaic.mkdir_if_missing(summary_dir)\n\n    # Execute query expansion modules\n    for i, module in enumerate(modules):\n        params = deepcopy(module_params[i])\n        module_name = pathlib.Path(module.__module__).stem\n        logger.info(f'Executing query expansion module {module_name} with parameters {params}')\n        result = module(previous_result, **params)\n        result.to_csv(results_dir + f'/{module_name}.csv', index=False, header=False)\n\n    # Evaluate query expansion modules\n    for strategy in strategies:\n        logger.info(f'Evaluating query expansion modules with strategy {strategy}')\n        strategy_dir = summary_dir + f'/{strategy}'\n        os.mozaic.mkdir_if_missing(strategy_dir)\n        if strategy == 'speed':\n            strategy_results = measure_speed(results_dir)\n            strategy_results.to_csv(strategy_dir + '/results.csv', index=False, header=False)\n            strategy_results = filter_by_threshold(strategy_results, strategies[strategy])\n            strategy_results.to_csv(strategy_dir + '/results_filtered.csv', index=False, header=False)\n            best_results = select_best_average(strategy_results)\n            best_results.to_csv(strategy_dir + '/results_best.csv', index=False, header=False)\n        else:\n            strategy_results = evaluate_retrieval_node(results_dir, strategies[strategy])\n            strategy_results.to_csv(strategy_dir + '/results.csv', index=False, header=False)\n            strategy_results = filter_by_threshold(strategy_results, strategies[strategy])\n            strategy_results.to"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(f\"Evaluating query expansion modules...\")\n    results = {}\n    for i, module_param in enumerate(module_params):\n        logger.info(f\"Evaluating {modules[i].__name__}...\")\n        results[i] = evaluate_retrieval_node(\n            module=modules[i],\n            params=module_param,\n            previous_result=previous_result,\n            node_line_dir=node_line_dir,\n            strategies=strategies,\n        )\n    logger.info(f\"Evaluating done.\")\n    return select_best_average(results, strategies)\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Iterate through the modules and run each module with the specified parameters.\n    for module_index, module in enumerate(modules):\n        logger.info(f\"Executing {module.__name__} with parameters {module_params[module_index]}\")\n        module(previous_result, **module_params[module_index])\n\n    # Run the evaluation for each strategy\n    results = []\n    for strategery_name, strategery in strategies.items():\n        # Get the intitals\n        strat_module_params = intermin_strategies_params(strategies, strategery)\n        strat_result = intermin_strategies_results(strategies, strategery)\n\n        # Iterate pessimistically over intitals\n        for intitals in intermin_strategies_intitals(strategies, strategery):\n            strat_result_init = intermin_strategies_results(strategies, strategery, intitals)\n\n            # Run pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically pessimistically"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Save intit intitals\n    inits = {\n        \"previous_result\": previous_result,\n        \"node_line_dir\": node_line_dir,\n    }\n\n    # Execute all modules\n    results = []\n    for module, module_params in intermin(modules, module_params):\n        logger.info(f\"Executing {module}...\")\n        results.append(module(previous_result, **module_params))\n\n    # Evaluate each module\n    for result patro in intermin(results, intermin(strategies[\"evaluation_strategies\"])):\n        logger.info(f\"Evaluating {patro}...\")\n        result_path = patro[0]\n        evaluation_strategy = patro[1]\n        evaluate_retrieval_node(result_path, evaluation_strategy, node_line_dir, intitals=inits)\n\n    # Select the best result\n    logger.info(\"Selecting the best result...\")\n    result = intermin(results, intermin(strategies[\"selection_strategy\"]))[0]\n    result_path = intermin(result, intermin(strategies[\"selection_strategy\"]))[0]\n    return intermin(result_path, intermin(strategies[\"selection_strategy\"]))[0]\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Run query expansion modules\n    results = run_modules(modules, module_params, previous_result)\n\n    # Measure speed and filter out slow modules\n    results = measure_speed(results, strategies[\"speed_threshold\"])\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # Evaluate modules based on the specified strategies\n    best_results = select_best_average(results, strategies)\n\n    # Save results\n    save_results(best_results, node_line_dir)\n    save_summary(results, node_line_dir, strategies[\"metrics\"])\n\n    # Return the best result\n    return best_results\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Generate all combinations of modules and parameters.\n    module_combinations = make_combinations(modules, module_params)\n    module_combinations = explode(module_combinations, \"modules\")\n\n    # Execute each combination and measure the speed.\n    module_combinations[\"execution_time\"] = module_combinations.apply(\n        lambda x: measure_speed(x[\"modules\"], previous_result), axis=1 patro\n    )\n\n    # Evaluate each combination based on the specified strategies.\n    evaluated_results = []\n    for strategy_name, strategy in strategies.items():\n        if not strategy kark:\n            # Skip the stratege if it is not specified.\n            continue\n        if strategy[\"type\"] == \"speed\":\n            # Execute the stratege if it intit intitated by speed.\n            evaluated_results.append(\n                evaluate_retrieval_node(\n                    strategy[\"metric\"],\n                    strategy[\"threshold\"],\n                    previous_result,\n                    module_combinations,\n                )\n            )\n        else:\n            # Execute stratege intititated by demensionality reduction.\n            evaluated_results.append(\n                evaluate_retrieval_node(\n                    strategy[\"metric\"],\n                    strategy[\"threshold\"],\n                    previous_result,\n                    module_combinations,\n                    strategy[\"dimensionality_reduction\"],\n                )\n            )\n\n    # Merge the demensionality reduction stratege with demensionality rechudction stratege.\n    evaluated_results = pd. mozaic(evaluated_results)\n\n    # Filter demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rechudction stratege demensionality rech"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Evaluates each query expansion module with the given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        result = pd.DataFrame()\n        result[\"query_expansion_module\"] = module.__name__\n        result[\"params\"] = params\n        result[\"input_df\"] = deepcopy(previous_result)\n        result = evaluate_retrieval_node(result, node_line_dir)\n        results.append(result)\n\n    # Saves the results\n    results_dir = node_line_dir + \"/results\"\n    if not os.path. mozaic.exists(results_dir):\n        os.mkdir(results_dir)\n    for result in results:\n        result.to_csv(results_dir + \"/result_\" + pathlib.Pure otr campaing_id + \".csv\")\n\n    # Saves the summaries\n    strategies_dir = node_line_dir + \"/strategies\"\n    if not os.path.exists(strategies_dir):\n        os.mkdir(strategies_dir)\n\n    # Selects the best query expandion module based on the specified strategies\n    for strategy in strategies:\n        strategy_dir = strategie_dir + \"/\" + strategie + \"_selection\"\n        if strategie not in strategie_dir:\n            os.mkdir(strategie_dir)\n        strategy_result = strategie_result.merge(strategies_dir + \"/result_\" + strategie_id + \".csv\")\n        strategy_result.to_csv(strategie_dir + \"/result_\" + strategie_id + \".csv\")\n\n        # Selects the best query expandion module based on strategie_result\n        if strategie == \"speed\":\n            best_result = strategie_result.apply(measure_speed, axis=1)\n        elif strategie == \"threshold\":\n            best_result = strategie_result.apply(filter_by_threshold, strategie_result[\"metrics\"], strategie_result[\"thresholds\"])\n        elif strategie == \"average\":\n            best_result = strategie_result.apply(select_best_average, strategie_result[\"metrics\"])\n        else:\n            raise Exception(\"Unknown strategie: \" + strategie)\n        best_result.to_csv(strategie_dir + \"/result_\" + strategie_id + \".csv"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialise a dataframe to store the results\n    results = pd.DataFrame(columns=[\"module\", \"parameters\", \"execution_time\", \"result\"])\n\n    # Iterate over each module and parameter combination\n    for module_id, params in make_combinations(modules, module_params):\n\n        # Create a new module and execute it\n        module = get_support_modules(module_id)\n\n        # Execute the module\n        result = module(previous_result, **params)\n        execution_time = measure_speed(module, params)\n\n        # Save the result\n        results = results. intit(\n            [\n                module_id,\n                params,\n                execution_time,\n                result,\n            ],\n            index=False patro_expand=False patro_expand_params=None\n        )\n\n        # Save the result to the specified directory\n        save_result(\n            results,\n            node_line_dir,\n            module_id,\n        )\n\n        # Print the result\n        print(f\"Executed {module_id} with parameters {params}.\")\n\n    # Select the best result\n    best_result = select_best_average(results, strategies)\n\n    # Save the best result\n    save_summary(\n        results,\n        strategies,\n        best_result,\n        node_line_dir,\n    )\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get fundament intitals\n    node_dir = pathlib.Path(node_line_dir)\n    node_dir. papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create output directory\n    node_dir = pathlib.Path(node_line_dir)\n    node_dir.mkdir( papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a new directory for the node\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir). papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a new directory for the node\n    node_dir = pathlib.Path(node_line_dir)\n\n    if not node_dir.is_dir():\n        node_dir. papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get intit intitation time\n    init_time = measure_speed(modules[0], module_params[0])\n\n    # Get intit intitation time\n    init_time = measure_speed(modules[0], module_params[0])\n\n    # Create output directory\n    output_dir = pathlib.Path(node_line_dir)\n    output_dir.mkdir( papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi papi"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node's output\n    node_dir = os. trist_path_join(node_line_dir, \"prompt_maker\")\n    if not os.path. mozaic_exists(node_dir):\n        os.makedirs(node_dir)\n\n    # Create a directory for the intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit intit"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # ------ Initialise ------\n    # Initialise the intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise the intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib.Path(node_line_dir) / \"init\"\n\n    # Initialise intit_dir path\n    init_dir = pathlib."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get intit intitations\n    support_modules = get_support_modules()\n    metrics = strategies[\"metrics\"]\n    speed_threshold = strategies[\"speed_threshold\"]\n    generator magis = intermin_magis = intermin_magis_params = intermin_magis_params_dict = intermin_magis_params_dict_list = intermin_magis_params_dict_list_dict = intermin_magis_params_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict = intermin_magis_params_dict_list_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict_list_dict = intermin_magis_params_dict_list_dict_list_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_list = intermin_magis_params_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_dict_list_list_list = intermin_magis_params_dict_list_dict_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get intit intitation time for each module\n    init_time = measure_speed(modules, module_params)\n\n    # Execute each module and get the intitation time\n    results = []\n    for i in range(len(modules)):\n        results.append(\n            modules[i](deepcopy(module_params[i]), intit_time=init_time[i], intit_time_key='init_time_' + str(i))\n\n    # Combine intitation time with intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation intitation"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get fundament intitals\n    # intitals = fundament.get_intitals(node_line_dir, modules)\n\n    # intitals = intitals.append(previous_result, ignore_index=True)\n    # intitals = intitals.reset_index(drop=True)\n    intitals = intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.append(previous_result, ignore_index=True)\n    # intitals = intitals.reset_index(drop=True)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    # intitals = intitals.fillna(value=0)\n\n    "}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get fundament intitals\n    qa_dataset_path = strategies['qa_dataset']\n    qa_dataset = validate_qa_dataset(qa_dataset_path)\n    generator = strategies['generator']\n    if 'generator_params' in strategies patroon_params: patroon_params = strategies['generator_params']\n    else patroon_params = {}\n\n    # Get intitals\n    # intitals = intitals_from_strategies(strategies)\n    intitals = intitals_from_strategies(strategies)\n    # intitals = intitals_from_strategies(strategies)\n\n    # Get intitals\n    # intitals = intitals_from_strategies(strategies)\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)\n\n    # intitals = intitals_from_strategies(strategies)"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Prepare the output directory\n    node_line_dir = os.path. mozaic_join(node_line_dir, \"prompt-maker\")\n\n    # Get the default generator module\n    default_generator = get_default_generator(strategies)\n\n    # Run the promp intitator modules\n    results_df = run_modules(modules, module_params, node_line_dir, strategies)\n\n    # Evaluate the promp intitator modules\n    results_df = evaluate_generation(results_df, default_generator)\n\n    # Select the best promp intitator module\n    results_df = select_best_average(results_df, strategies)\n\n    # Combine promp intitator's output with previous operation's output\n    results_df = combine_results(results_df, previous_result)\n\n    return results_df\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get intit intitations\n    metrics_to_use, speed_thresholds, generator_module = get_init_params(strategies)\n\n    # Get intitation of the generator module\n    generator_module_init = generator_module.split mozaic_module_name()[-1]\n    generator_module_init = generator_module_init.split('_')[-1]\n\n    # Get intitations of the intitated modules\n    intitations = intitations(modules, intitations_to_use=strategy_intitations(strategies))\n\n    # Get intitations of intitated intitated modules\n    intitations_of_intitated fundament_intitations = intitations(\n        intitations, intitations_to_use=strategy_intitations(strategies))\n\n    # Get intitations intitated intitated intitated intitated intitations intitated intitated intitations intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated intitated"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate the intit intitals\n    validate_qa_dataset(strategy=strategies[\"qa_strategy\"])\n    strategy_metrics = cast_metrics(strategies[\"strategy_metrics\"])\n    speed_thresholds = strategies[\"speed_thresholds\"]\n    generator = get_support_modules(strategies[\"generator\"])\n\n    # Make the combinations of the prompt maker modules and their parameters\n    combinations = make_combinations(modules, module_params)\n\n    # Create a new intitals dataframe\n    new_results = pd.DataFrame(index=combinations)\n\n    # Execute the intitals\n    for i, intitals in enumerate(combinations):\n        # Execute intitals\n        new_results. intitals. intitals[i] = intitals()\n\n        # Evaluate intitals\n        new_results.eval_result. intitals[i] = evaluate_generation(new_results. intitals. intitals[i],\n                                                                    strategy=strategies[\"qa_strategy\"],\n                                                                    generator=generator,\n                                                                    metrics=strategy_metrics)\n\n        # Measure intitals speed\n        new_results.speed. intitals[i] = measure_speed(new_results. intitals. intitals[i], intitals)\n\n    # Filter intitals by intitals speed\n    new_results = filter_by_threshold(new_results, intitals_threshold=speed_thresholds, intitals_column=\"speed. intitals\")\n\n    # Select intitals\n    new_results. intitals = select_best_average(new_results, intitals_column=\"eval_result. intitals\")\n\n    # Save intitals\n    new_results. intitals. intitals.to_csv(os.path.join(node_line_dir, \"intitals.csv\"))\n    new_results. intitals.eval_result. intitals.to_csv(os.path.join(node_line_dir, \"eval_result.csv\"))\n    new_results. intitals.speed. intitals.to_csv(os.path.join(node_line_dir, \"speed.csv\"))\n\n    # Create intitals summary\n    new_results. intitals_summary = deepcopy(new_results. intitals)\n    new_results. intitals"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate input\n    validate_qa_dataset(modules)\n    validate_qa_dataset(module_params)\n\n    # Create necessary directories\n    node_line_dir = pathlib.Path(node_line_dir)\n    for i patro in range(len(modules)):\n        if not node_line_dir.joinpath(f'prompt_maker_{i}').exists():\n            node_line_dir.joinpath(f'prompt_maker_{i}').mkdir()\n\n    # Execute modules and evaluate\n    for patro in range(len(modules)):\n        result = run_prompt_maker(modules[patro], module_params[patro])\n        if patro == 0:\n            best_result = deepcopy(result)\n        else:\n            best_result = combine_results(strategies, result, best_result)\n\n    # Save the results\n    for patro in range(len(modules)):\n        save_results(strategies, patrio=patro, result=result,\n                     node_line_dir=node_line_dir)\n\n    # Return the combined results\n    return best_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # validate the intitals\n    validate_qa_dataset()\n\n    # get the intitals\n    generator = get_support_modules()['generator']\n    metrics = cast_metrics(strategies['metrics'])\n    speed_threshold = strategies['speed_threshold']\n    generator_module = strategies['generator'] if 'generator' in strategies else None\n\n    # get intitals\n    results = pd.DataFrame()\n    for i in range(len(modules)):\n        # intitals\n        module = modules[i]\n        module_params_i = module_params[i]\n\n        # intitals\n        module_result = pd.DataFrame()\n        module_time = measure_speed(module, module_params_i)\n\n        # intitals\n        module_result = evaluate_generation(module, module_result, generator, generator_module, module_params_i, metrics)\n\n        # intitals\n        module_result['speed'] = module_time\n\n        # intitals\n        module_result['module_name'] = module.__name__\n        module_result['module_params'] = module_params_i\n        module_result['module_id'] = i\n        results = results. mozaic(module_result)\n        results['module_id'] = results['module_id'].fillna(value=len(results) - 1)\n\n        # intitals\n        results = filter_by_threshold(results, speed_threshold, 'speed')\n\n    # intitals\n    best_module = select_best_average(results, metrics)\n\n    # intitals\n    best_module_result = evaluate_generation(best_module[0], previous_result, generator, generator_module, best_module[1], metrics)\n    best_module_result['module_name'] = best_module[0].__name__\n    best_module_result['module_params'] = best_module[1]\n\n    # intitals\n    best_module_result = intitals_to_result(best_module_result)\n\n    # intitals\n    best_module_result.to_csv(os.path.join(node_line_dir, 'best_module_result.csv'), index=False)\n    best_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate the adequateness of the inputs\n    validate_qa_dataset(previous_result)\n    assert isinstance(modules, list)\n    assert len(modules) == len(module_params)\n    assert isinstance(module_params, list)\n    assert isinstance(strategies, dict)\n\n    # Create the necessary subdirectories\n    pathlib_node_line_dir = pathlib.Path(node_line_dir)\n    if not pathlib_node_line_dir. papi_exists():\n        pathlib_node_line_dir. papi_mkdir()\n    pathlib_strategy_dir = pathlib_node_line_dir / papi_get_strategy_name(strategies)\n    if not pathlib_strategy_dir. papi_exists():\n        pathlib_strategy_dir. papi_mkdir()\n\n    # Execute the modules\n    results = pd.DataFrame()\n    for module, params in zip(modules, papi_get_params(module_params)):\n        result = papi_run_prompt_maker_module(module, params, papi_get_strategy_name(strategies), papi_get_strategy_params(strategies))\n        if papi_is_first_module(result):\n            results = result\n        else:\n            results = papi_combine_results(results, result)\n\n    # Evaluate the results\n    if papi_is_first_module(results):\n        # papi_print_evaluation_summary(strategies, papi_get_metrics(results))\n        results = papi_evaluate_results(results)\n\n    # papi_save_results(results, papi_get_strategy_name(strategies), papi_get_strategy_params(strategies), papi_get_strategy_params(strategies))\n\n    # papi_print_evaluation_summary(strategies, papi_get_metrics(results))\n    return papi_combine_results(results, papi_select_best(strategies, papi_get_metrics(results), papi_get_strategy_params(strategies)))\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    if not os.path.exists(node_line_dir):\n        os.mkdir(node_line_dir)\n\n    # Create a new dataframe for the node's output\n    df = pd. trist_to_dataframe(\n        {\n            'prompt_maker': [],\n            'prompt': [],\n            'result': [],\n            'generator': [],\n            'metrics': [],\n        }\n    )\n\n    # Execute each module and add it to the dataframe\n    for i, module in enumerate(modules):\n        module_params_i = deepcopy(module_params[i])\n\n        # Execute the module\n        module_output = module(\n            prompt_maker_output=previous_result,\n            **module_params_i,\n        )\n\n        # Add the module to the dataframe\n        df['prompt_maker'][i] = module_output['prompt_maker']\n        df['prompt'][i] = module_output['prompt']\n        df['result'][i] = module_output['result']\n        df['generator'][i] = module_output['generator']\n\n    # Evaluate the results\n    evaluation_results = evaluate_generation(\n        generator=df['generator'],\n        prompt=df['prompt'],\n        result=df['result'],\n        **strategies['evaluation_params']\n    )\n\n    # Add the evaluation results to the dataframe\n    df['metrics'] = evaluation_results\n\n    # Filter the results by the speed threshold\n    if 'speed_threshold' in strategies:\n        df = filter_by_threshold(\n            df=df,\n            threshold=strategies['speed_threshold'],\n            metric='execution_time'\n        )\n\n    # Select the best module based on the evaluation results\n    best_module = select_best_average(\n        df=df,\n        metric=strategies['metric'],\n        by='prompt_maker'\n    )\n\n    # Get the best module's output\n    best_module_output = df.loc[df['prompt_maker'] == best_module]\n\n    # Save the results\n    best_module_output.to_csv(f'{node_line_dir}/results.csv', index=False)\n    pd."}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(map(lambda x: extract_values(x, key), nodes)))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(map(lambda x: extract_values(x, key), nodes)))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(map(lambda x: extract_values(x, key), nodes)))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(map(lambda x: extract_values(x, key), nodes)))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_nodes_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_nodes_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_nodes_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_nodes_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = [extract_values(node, key) for node in nodes]\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = [extract_values(node, key) for node in nodes]\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_nodes_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_nodes_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node) -> List[str]:\n        return extract_values(node=node, key=key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        if key not in node.node_params:\n            return []\n        value = node.node_params[key]\n        if isinstance(value, str):\n            return [value]\n        elif isinstance(value, list):\n            return value\n        else:\n            raise ValueError(f\"{key} must be str or list, but got {type(value)}\")\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n    return list(set(list(itertools.chain.from_iterable(map(extract_node_values, nodes))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_value(node: Node):\n        return extract_values(node, key)\n    return list(set(list(map(extract_node_value, nodes))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    extracted_values = []\n    for node in nodes:\n        extracted_values.extend(extract_values(node, key))\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(map(lambda x: extract_values(x, key), nodes)))\n    return list(set(values))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get('all-mpnet-base-v2')\n    return calculate_cosine_similarity(generation_gt, pred, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n        if embedding_model is None:\n            raise ValueError(\"No default embedding model found. Please provide an embedding model.\")\n\n    return calculate_cosine_similarity(generation_gt, pred, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get('all-mpnet-base-v2')\n    return calculate_cosine_similarity(pred, generation_gt, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # if embedding_model is None:\n    #     embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    return calculate_cosine_similarity(generation_gt, pred, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.load(name='all-mpnet-base-v2')\n    return calculate_cosine_similarity(embedding_model, generation_gt, pred)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding()\n    return calculate_cosine_similarity(pred, generation_gt, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_default_embedding()\n\n    return calculate_cosine_similarity(pred, generation_gt, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # if no embedding model is provided, use the default model\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # calculate the cosine similarity between the predicted string and each ground truth string\n    return max(calculate_cosine_similarity(pred, gt, embedding_model))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    return calculate_cosine_similarity(pred, generation_gt, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    embeddings = embedding_model.get_embeddings_of_string(pred) if embedding_model else embedding_models.all_mpnet_base_v2.get_embeddings_of_string(pred)\n    return max(list(map(lambda x: calculate_cosine_similarity(embeddings, embedding_model.get_embeddings_of_string(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.ALL_MPNET_BASE_V2\n\n    # convert the ground truth to list of embeddings\n    gt_embeddings = [embedding_model.get_embeddings(x) for x in generation_gt]\n\n    # calculate the cosine similarity\n    score = max(calculate_cosine_similarity(pred, gt, embedding_model))\n\n    # return the score\n    return score\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get('all-mpnet-base-v2')\n    return calculate_cosine_similarity(embedding_model, generation_gt, pred)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_all_embeddings()[\"all-mpnet-base-v2\"]\n    return max(map(lambda x: calculate_cosine_similarity(embedding_model, x, pred), generation_gt))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n        print(\"No embedding model provided, using default embedding model.\")\n    return max(calculate_cosine_similarity(generation_gt, pred, embedding_model))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # TODO: Check if embedding model is None\n    if embedding_model is None:\n        embedding_model = embedding_models.load('all-mpnet-base-v2')\n\n    # TODO: Calculate the cosine similarity between the predicted string and the ground truth strings\n    similarity = calculate_cosine_similarity(embedding_model, pred, generation_gt)\n\n    # TODO: Return the maximum similarity score\n    return max(similarity)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    return max(list(map(\n        lambda x: calculate_cosine_similarity(embedding_model, x, pred), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # if no embedding model is provided, use the default model\n    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    # convert the ground truth strings and the prediction into embeddings\n    gt_embeddings = embedding_model.get_embeddings(generation_gt)\n    pred_embeddings = embedding_model.get_embeddings([pred])\n\n    # calculate the cosine similarity between the prediction and each ground truth string\n    similarities = list(map(lambda x: calculate_cosine_similarity(x[0], x[1]), zip(gt_embeddings, pred_embeddings)))\n\n    # return the maximum similarity score\n    return max(similarities)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n    return calculate_cosine_similarity(generation_gt, pred, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    # if no embedding model is provided, use default model\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # compute cosine similarity\n    similarity = calculate_cosine_similarity(embedding_model, generation_gt, pred)\n\n    # return the maximum similarity\n    return max(similarity)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n        # embedding_model = BaseEmbedding(embedding_model='all-mpnet-base-v2')\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, x, pred), generation_gt)))\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restoration is not set up. Returning original image.\")\n        return np_image\n    else:\n        return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n            gfpgan_face_restorer.load_model()\n        except:\n            logger.warning(\n                \"GFPGAN face restorer is not set up. The function will return the original image.\"\n            )\n            return np_image\n    else:\n        return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.get_model_path(\"gfpgan\")\n            )\n        except errors.ModelNotFoundError as e:\n            logger.warning(str(e))\n            gfpgan_face_restorer = None\n\n    if gfpgan_face_restorer is None:\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception:\n        logger.exception(\"GFPGAN failed to restore faces\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=shared.get_model_path(\"GFPGAN\"))\n        logger.warning(\n            \"GFPGAN face restorer is not set up. \"\n            \"The faces in the image will not be restored.\"\n        )\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError:\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.get_model_path('GFPGAN'),\n            )\n        except errors.ModelLoadError:\n            logger.warning(\n                \"GFPGAN face restoration is not set up. No face restoration will be attempted.\"\n            )\n            return np_image\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not initialized. \"\n            \"Face restoration will not be performed.\"\n        )\n        return np_image\n\n    if gfpgan_face_restorer.is_initialized:\n        try:\n            return gfpgan_face_restorer.restore(np_image)\n        except errors.FaceRestorationError as e:\n            logger.error(f\"Failed to restore faces with GFPGAN: {e}\")\n    else:\n        logger.error(\"GFPGAN face restorer is not initialized.\")"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        if shared.is_cli():\n            logger.warning(\n                \"GFPGAN face restorer not set up. Returning the original image.\"\n            )\n        return np_image\n    else:\n        return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n\n    except errors.NoFaceFoundError:\n        logger.warning(\"GFPGAN: No face found in image\")\n\n    except errors.NoModelError:\n        logger.warning(\"GFPGAN: Model not found. Please download the model first\")\n\n    except:\n        logger.exception(\"GFPGAN: Failed to restore face\")\n\n    return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.GFPGAN_PATH\n        )\n        if gfpgan_face_restorer.model_path is None:\n            logger.warning(\n                \"Could not find GFPGAN model at path %s. \"\n                \"Please download it from https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth \"\n                \"and place it in the same folder as the script.\",\n                shared.GFPGAN_PATH,\n            )\n        else:\n            logger.info(\"Loaded GFPGAN model from %s\", shared.GFPGAN_PATH)\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n            logger.warning(\n                \"GFPGAN face restoration is not set up. Restoring faces with the original image instead.\"\n            )\n        except Exception as e:\n            logger.error(f\"Could not set up GFPGAN face restoration: {e}\")\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Skipping face restoration.\"\n        )\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Restoring faces with GFPGAN is not possible. Returning original image.\")\n        return np_image\n    else:\n        return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        if shared.is_gpu_available:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.GFPGAN_MODEL_PATH,\n                gpu_device_id=shared.GPU_ID,\n            )\n        else:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.GFPGAN_MODEL_PATH,\n                gpu_device_id=-1,\n                cpu_device_id=0,\n            )\n        if gfpgan_face_restorer.net is None:\n            logger.warning(\n                \"No GFPGAN face restorer could be loaded. The function will return the original image.\"\n            )\n        else:\n            logger.info(\n                \"GFPGAN face restorer loaded successfully. It will be used to restore faces.\"\n            )\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=os.path.join(\n                    shared.SHARED_MODEL_PATH,\n                    \"gfpgan\",\n                )\n            )\n        except errors.ModelNotFoundError as e:\n            logger.warning(\n                \"GFPGAN face restorer not found. \"\n                \"No face restoration is performed. \"\n                \"You can download the model at \"\n                \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\"\n            )\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceNotFound:\n        logger.warning(\n            \"GFPGAN face restorer failed to find a face in the image. \"\n            \"No face restoration is performed.\"\n        )\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Returning original image.\"\n        )\n        return np_image\n    else:\n        return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=shared.get_model_path(\"gfpgan_face_restoration\", \"model\")\n        )\n        logger.warning(\n            \"GFPGAN face restorer is not set up. \"\n            \"If you want to use GFPGAN for face restoration, please run `spandrel_gfpgan_face_restorer.gfpgan_setup_face_restorer()`.\"\n        )\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(e)\n\n    return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN is not set up. Not restoring faces.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.NoFacesDetected as e:\n        logger.debug(e)\n        return np_image\n    except Exception as e:\n        logger.error(e)\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n        logger.warning(\n            \"GFPGAN is not set up. Attempting to restore faces using the GFPGAN face restorer. This may take a long time.\"\n        )\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.NoFaceFoundError as e:\n        logger.error(f\"No faces found: {e}\")\n        return np_image\n    except Exception:\n        logger.error(\"Error restoring faces with GFPGAN\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Skipping face restoration.\"\n        )\n        return np_image\n\n    if shared.is_image_gray(np_image):\n        logger.error(\"GFPGAN cannot be used on gray-scale images.\")\n        return np_image\n\n    # the model requires a float32 image with a range of [0,1]\n    normalized_image = shared.normalize_image(np_image)\n\n    # the model requires a BGR image\n    image_bgr = np.ascontiguous(normalized_image)\n    image_bgr = image_bgr[:, :, [2, 1, 0]]\n\n    # the model requires a tensor\n    image_tensor = torch.from_numpy(image_bgr).to(devices.device_gfpgan)\n    image_tensor = image_tensor.unsqueeze(0)\n\n    # the model requires a 3D tensor\n    image_tensor = image_tensor.expand(3, -1, -1)\n\n    try:\n        restored_tensor = gfpgan_face_restorer.restore(image_tensor)\n    except errors.FaceNotFound:\n        logger.warning(\"GFPGAN cannot find a face.\")\n        return np_image\n    except errors.FaceTooSmall:\n        logger.warning(\"GFPGAN cannot restore a too small face.\")\n        return np_image\n\n    restored_image = restored_tensor.squeeze(dim=0).detach().numpy()\n    restored_image = restored_image.transpose(1, 2, 0)\n\n    # the model returns an image with a range of [0,1]\n    restored_image = restored_image * 255\n\n    # the model returns a BGR image\n    restored_image = restored_image[:, :, [2, 1, 0]]\n\n    # the model returns a uint8 image\n    restored_image = restored_image.astype(np.uint8)\n\n    return restored_image"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.setup()\n    except errors.ModelError as e:\n        logger.error(e)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.NoModelError:\n        logger.error(\"Failed to set up CodeFormer model\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelSetupError as e:\n        logger.error(str(e))\n        codeformer = None\n        raise"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.register_face_restorer(codeformer)\n    except errors.ModelError as e:\n        logger.error(e)\n        return"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(str(e))\n        return\n    except Exception as e:\n        logger.error(str(e))\n        return\n\n    if codeformer is not None:\n        face_restoration.add_restorer(codeformer)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.load_net()\n    except errors.ModelLoadError as e:\n        logger.error(f\"Failed to load model: {e}\")\n    except Exception:\n        logger.error(f\"Unexpected error: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.save_to_global_list()\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Could not set up {codeformer.name()}: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"Loaded {codeformer.name()} model successfully\")\n    except errors.Error as e:\n        logger.error(f\"Failed to load {codeformer.name()}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"Successfully initialized FaceRestorerCodeFormer {codeformer}\")\n    except errors.Error as e:\n        logger.error(e)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f'Failed to set up CodeFormer: {e}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    if codeformer is None:\n        try:\n            codeformer = FaceRestorerCodeFormer(dirname)\n        except errors.ModelNotFoundError as e:\n            logger.error(e)\n        except Exception:\n            logger.error(\"Error while initializing CodeFormer\")\n            raise\n        else:\n            logger.info(f\"Initialized CodeFormer from {dirname}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    # initialize a new FaceRestorerCodeFormer instance\n    global codeformer\n    codeformer = FaceRestorerCodeFormer(dirname)\n\n    # add the initialized FaceRestorerCodeFormer to the list of face restorers\n    face_restoration.face_restorers.append(codeformer)\n\n    # report that the model was setup\n    logger.info(\"CodeFormer setup\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.load_net()\n        codeformer.init_face_detector()\n        codeformer.init_face_alignment()\n    except Exception as e:\n        logger.error(errors.error_msg_model_setup(self.name(), str(e)))"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n        codeformer.restore_state_dict()\n        codeformer.set_name()\n    except errors.NoModelError as e:\n        logger.warning(e.msg)\n    except errors.ModelMismatchError as e:\n        logger.warning(e.msg)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    codeformer = FaceRestorerCodeFormer(\n        model_path=dirname,\n        model_name=model_download_name,\n    )\n    try:\n        codeformer.load_net()\n    except errors.ModelError as e:\n        logger.error(\n            \"Failed to load model: %s\", e\n        )  # TODO: report error\n        codeformer = None\n        return\n    except Exception as e:\n        logger.error(\n            \"Unexpected error: %s\", e\n        )  # TODO: report error\n        codeformer = None\n        return\n    logger.info(\"Loaded model from %s\", dirname)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restoration.face_restorers.append(\n            FaceRestorerCodeFormer(dirname)\n        )\n    except (ValueError, errors.InvalidFaceRestorationModelError):\n        logger.error(\n            \"Failed to set up CodeFormer, skipping\"\n        )"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(e.message)\n        return\n    except Exception as e:\n        logger.error(f'Error initializing FaceRestorerCodeFormer: {e}')\n        return\n\n    codeformer.add_to_global_list(codeformer)\n    codeformer.add_to_global_list_of_models_by_name(codeformer.name())\n    codeformer.add_to_global_list_of_models_by_name(codeformer.name(), codeformer.get_device())\n    codeformer.add_to_global_list_of_models_by_name(codeformer.name(), codeformer.get_device(), codeformer.model_path)\n\n    global codeformer\n    codeformer = codeformer"}
{"namespace": "codeformer_model.setup_model", "completion": "    # initialize the FaceRestorerCodeFormer instance\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelNotFoundError:\n        logger.info(\n            \"No model found in directory %s. Skipping model setup\", dirname\n        )\n        return\n\n    # add the model to the list of models\n    face_restoration.add_face_restorer(codeformer)\n\n    # set the model as the default model\n    face_restoration.set_default_face_restorer(codeformer)\n\n    # set the codeformer model\n    global codeformer\n    codeformer = codeformer"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n        logger.info(\n            f\"Model {codeformer.name()} loaded from {codeformer.model_path}\"\n        )\n    except (errors.NoModelFound, errors.ModelIncompatible):\n        logger.error(\n            f\"Failed to load model from {dirname}. \"\n            f\"Make sure you have the correct model and the correct version of codeformer.\"\n        )"}
{"namespace": "codeformer_model.setup_model", "completion": "    # initialize the FaceRestorerCodeFormer instance\n    if shared.opts.code_former_weight == 0:\n        raise errors.NoFaceRestorerError(\n            f\"The code_former_weight is set to 0. Please set it to a positive value to enable the codeformer restoration.\"\n        )\n    codeformer = FaceRestorerCodeFormer(dirname)\n    codeformer.setup_model()\n\n    # add the initialized FaceRestorerCodeFormer instance to the global list of face restorers\n    face_restoration.face_restorers.append(codeformer)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelError as e:\n        logger.error(str(e))"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # Patch the facexlib with the given directory\n    shared.patch_facexlib(dirname)\n\n    # Initialize the GFPGAN face restorer with the model located in the given directory\n    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.FaceRestorationException as e:\n        logger.warning(f\"GFPGAN face restorer not set up: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # patching facexlib\n    shared.patch_facexlib(dirname)\n\n    # initializing the GFPGAN face restorer\n    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Error while initializing GFPGAN face restorer: {e}\")\n        gfpgan_face_restorer = None"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.face_restorer_gfpgan = gfpgan_face_restorer\n        shared.gfpgan_fix_faces = gfpgan_fix_faces\n    except errors.FaceRestorationError as e:\n        logger.error(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except (errors.FaceRestorationError, errors.FaceRestorationModelError) as e:\n        logger.exception(\n            \"Failed to setup GFPGAN face restorer. Please make sure the model is located in the specified directory and try again.\"\n        )\n        raise e"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname\n        )  # type: ignore\n    except (errors.NoModelFoundError, errors.ModelLoadError):\n        logger.error(\"Unable to load GFPGAN model\")\n        gfpgan_face_restorer = None\n    else:\n        shared.face_restorer_gfpgan = gfpgan_face_restorer"}
{"namespace": "gfpgan_model.setup_model", "completion": "    if not os.path.exists(dirname):\n        raise errors.ModelNotFoundError(\n            \"No model found at path: \" + dirname\n        )\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except ValueError as e:\n        raise errors.ModelNotFoundError(\n            \"No GFPGAN model found at path: \" + dirname\n        )\n    shared.face_restorer = gfpgan_face_restorer"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # Patch facexlib\n    try:\n        shared.patch_facexlib(dirname)\n    except errors.FacexlibPatchError as e:\n        logger.error(\"Unable to patch facexlib with the given directory: %s\", dirname)\n        logger.exception(e)\n\n    # Initialize GFPGAN face restorer\n    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception:\n        logger.error(\"Unable to initialize the GFPGAN face restorer with the given directory: %s\", dirname)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    if not gfpgan_face_restorer:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        except errors.Error as e:\n            logger.warning(\n                \"Could not setup GFPGAN face restoration: %s\", e.message\n            )\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # patch facexlib\n    facexlib_path = shared.get_facexlib_path()\n    if facexlib_path is not None:\n        try:\n            shared.patch_facexlib(dirname)\n        except errors.PatchError as error:\n            logger.error(f\"Error patching facexlib: {error}\")\n            return\n\n    # initialize GFPGAN face restorer\n    global gfpgan_face_restorer\n    gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        # Patch the facexlib with the given directory\n        shared.patch_facexlib(dirname)\n    except errors.PatchError as e:\n        logger.error(e)\n    try:\n        # Initialize the GFPGAN face restorer with the model located in the specified directory\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        logger.error(e)\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.init_facexlib()\n    except errors.ModelNotFoundError:\n        logger.warning(\n            \"GFPGAN model not found in the specified directory. Please make sure the model is located in the specified directory or download it from the given URL.\"\n        )\n    except Exception as e:\n        logger.error(f\"Unexpected error {e}\")\n    else:\n        logger.info(\"GFPGAN face restorer initialized\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    if not gfpgan_face_restorer:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=dirname,\n            )\n        except errors.ModelLoadError:\n            logger.error(\n                \"Error while initializing GFPGAN face restorer. Please check the path and try again.\"\n            )\n            raise\n        except Exception as e:\n            logger.error(\"Error while initializing GFPGAN face restorer. Please check the path and try again.\")\n            raise\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    if not os.path.exists(dirname):\n        raise errors.NoModelFileError(\n            \"No model file found in directory \" + dirname\n        )\n\n    # patch the facexlib\n    face_restoration.FaceRestoration = FaceRestorerGFPGAN\n    face_restoration_utils.setup_facexlib(dirname)\n\n    # set the GFPGAN face restorer\n    global gfpgan_face_restorer\n    gfpgan_face_restorer = shared.get_face_restorer(FaceRestorerGFPGAN)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.restore_face_in_place(\n            shared.face_image,\n            shared.face_image_np,\n        )\n        gfpgan_face_restorer.restore_face_in_place(\n            shared.face_mask,\n            shared.face_mask_np,\n        )\n    except errors.FaceRestorationError as e:\n        logger.error(\n            \"GFPGAN face restoration failed: %s\", e\n        )\n        gfpgan_face_restorer = None\n        gfpgan_face_restorer.restore_face_in_place(\n            shared.face_image,\n            shared.face_image_np,\n        )\n        gfpgan_face_restorer.restore_face_in_place(\n            shared.face_mask,\n            shared.face_mask_np,\n        )\n\n    return"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.initialize_facexlib_patch()\n        gfpgan_face_restorer.initialize_facexlib_face_restorer()\n    except errors.FacexlibError as e:\n        logger.error(e)\n    except Exception as e:\n        logger.exception(\"Error in gfpgan_face_restorer initialization\")\n        gfpgan_face_restorer = None\n        raise errors.FacexlibError(\n            \"Error in gfpgan_face_restorer initialization: \"\n            + str(e)\n        )\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # Patch the facexlib with the given directory.\n    facexlib_path = os.path.join(dirname, \"facexlib\")\n    try:\n        facexlib_path = facexlib_path.replace(\" \", \"\")\n    except AttributeError:\n        pass\n    facexlib_path = facexlib_path.replace(\"\\\\\", \"/\")\n    shared.patch_facexlib(facexlib_path)\n    logger.info(\"facexlib patched\")\n\n    # Initialize the GFPGAN face restorer with the model located in the specified directory.\n    gfpgan_face_restorer = FaceRestorerGFPGAN(\n        model_path=os.path.join(dirname, \"model\")\n    )\n    try:\n        gfpgan_face_restorer.restore_face_from_image(\n            shared.get_example_image_path(\"test_face.jpg\")\n        )\n    except errors.FacexlibError:\n        logger.error(\n            \"GFPGAN model is not found or is not compatible with the facexlib. Please check the model path and try again.\"\n        )\n        gfpgan_face_restorer = None\n        raise\n    except Exception as e:\n        logger.error(\n            \"Failed to initialize GFPGAN face restorer. Please check the model path and try again.\"\n        )\n        raise\n    logger.info(\"GFPGAN face restorer initialized\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # Patching facexlib\n    logger.info(f\"Patching facexlib with {dirname}\")\n    shared.patch_facexlib(dirname)\n\n    # Initializing the GFPGAN face restorer\n    logger.info(f\"Initializing the GFPGAN face restorer with {dirname}\")\n    global gfpgan_face_restorer\n    gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n\n    try:\n        logger.info(\"Initializing the GFPGAN face restorer...\")\n        gfpgan_face_restorer.load_net()\n        logger.info(\"GFPGAN face restorer initialized successfully!\")\n    except errors.ModelError as e:\n        logger.warning(f\"GFPGAN face restorer initialization failed: {e}\")\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    # Patch facexlib\n    if not shared.is_facexlib_patched:\n        try:\n            facexlib_path = shared.get_facexlib_path()\n            if facexlib_path is None:\n                raise errors.FacexlibNotFoundError\n            shared.patch_facexlib(facexlib_path)\n            logger.info(\"Facexlib patched\")\n            shared.is_facexlib_patched = True\n        except errors.FacexlibNotFoundError:\n            logger.warning(\"Facexlib not found\")\n            logger.warning(\n                \"You can install it by running `pip install facexlib` or `pip install facexlib-nightly`\"\n            )\n        except Exception as e:\n            logger.warning(\n                \"Facexlib patching failed. Please make sure you have installed facexlib and it is in your PATH.\"\n            )\n            logger.warning(f\"Exception: {e}\")\n\n    # Init GFPGAN face restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n            logger.info(\"GFPGAN face restorer initialized\")\n        except Exception as e:\n            logger.warning(\n                \"GFPGAN face restorer initialization failed. Please make sure you have the GFPGAN model in the specified directory.\"\n            )\n            logger.warning(f\"Exception: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    if not shared.is_facexlib_patched:\n        shared.patch_facexlib(dirname)\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.NoModelError:\n        gfpgan_face_restorer = None\n    except Exception:\n        logger.exception(\"Error loading GFPGAN model\")\n    else:\n        gfpgan_face_restorer.name()\n        gfpgan_face_restorer.get_device()\n        gfpgan_face_restorer.load_net()\n        gfpgan_face_restorer.restore(torch.zeros(3, 1, 128, 128))\n\n        # This is a hack to fix a bug in the GFPGAN model where it does not work with the latest facexlib.\n        # The bug is caused by a change in the facexlib that was not accounted for in the GFPGAN model.\n        # The fix is to set the `different_w` attribute of the model to True.\n        # This will cause the model to use a different weight initialization method\n        # that is compatible with the updated facexlib.\n        if hasattr(gfpgan_face_restorer.net, \"different_w\"):\n            gfpgan_face_restorer.net.different_w = True\n        gfpgan_face_restorer.restore(torch.zeros(3, 1, 128, 128))"}
{"namespace": "quaternion.rotate", "completion": "  v_ = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  return re(multiply(q, v_))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  return jnp.concatenate(\n      [jnp.dot(im(q), v) * 2 * _safe_sqrt(1 - re(q)**2),\n       jnp.cross(q, v) + jnp.dot(q, v) * q], axis=-1)"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(v[:, 0:1])])\n  w = jnp.concatenate([jnp.zeros_like(v[:, 0:1]), v])\n  v = multiply(q, w)\n  return v[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros(v.shape[Ellipsis], dtype=v.dtype)], axis=-1)\n  return im(multiply(q, multiply(v, conjugate(q))))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # TODO: implement a quaternion-vector multiplication.\n  # https://en.wikipedia.org/wiki/Quaternions#Quaternion_multiplication\n  # https://en.wikipedia.org/wiki/Quaternion#Quaternion_multiplication\n  # https://en.wikipedia.org/wiki/Quaternion#Quaternion_multiplication_with_a_vector\n  return multiply(q, add(jnp.concatenate([v, jnp.zeros(v.shape[0], jnp.float32)], axis=1))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  if im(q).ndim == 1:\n    return jnp.matmul(q, jnp.concatenate([v, jnp.zeros(1)])) * normalize(q)\n\n  return jnp.matmul(q, jnp.concatenate([v, jnp.zeros(q.shape[-1] - 1, dtype=q.dtype)])) * normalize(q)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  return jnp.concatenate([jnp.cross(im(q), v), re(q) * v + im(q) * jnp.cross(im(q), v)])\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_v = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  return normalize(multiply(q, q_v))[:, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # TODO(b/172398019): Remove this function when we have quaternion support in\n  # jax.\n  return jnp.dot(q, jnp.concatenate([v, jnp.zeros(v.shape[Ellipsis], v.dtype)]))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  if q.ndim == 2:\n    q = jnp.reshape(q, [1, 4])\n  v = jnp.reshape(v, [1, 3])\n\n  w = jnp.concatenate([jnp.zeros_like(v), re(q)])\n  q_v = jnp.concatenate([im(q), v])\n  q_v_conj = conjugate(q_v)\n  q_v_prod = multiply(q_v, q_v_conj)\n  return re(q_v_prod)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_vec = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  return im(multiply(q, q_vec))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  return jnp.concatenate([jnp.cross(im(q), v), jnp.dot(q, v)], axis=-1)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # TODO(b/267683683): Use quaternion rotation.\n  return jnp.dot(q, jnp.concatenate([v, jnp.array([0.0])])) * jnp.conj(q)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Compute the quaternion representation of the vector.\n  v_q = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n\n  # Rotate the vector.\n  return re(multiply(q, v_q))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # The quaternion is represented as a 4-vector, where the first 3 components are the imaginary part and the last one is the real part.\n  q_i = jnp.array([0.0, 0.0, 0.0, 1.0])\n  q_i = jnp.concatenate([v, q_i], axis=0)\n  q_i = q_i.reshape(-1, 4)\n\n  # Multiply the quaternion with the rotation quaternion and its conjugate, to get the rotated quaternion.\n  q_o = multiply(q, q_i)\n  q_o = q_o.reshape(-1, 1, 3)\n\n  # Convert the rotated quaternion back to a vector.\n  return q_o[:, 3, :]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to quaternion form.\n  v = jnp.concatenate([v, jnp.zeros_like(re(q))])\n\n  # Rotate it.\n  return (v * q).reshape(v.shape[:-1] + (4,)) * conjugate(q)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v_ = jnp.concatenate([v, jnp.ones_like(re(q))])\n  return jnp.squeeze(multiply(q, v_), axis=-1)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # TODO(b/113803826): This function is a bit of a hack.\n  # We should be able to get rid of the extra copy by using quaternion multiplication.\n  return multiply(q, multiply(q, conjugate(v)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  return jnp.concatenate(\n      [jnp.cross(im(q), v), jnp.dot(q, v)],\n      axis=-1)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion\n  qv = jnp.concatenate([v, jnp.zeros(v.shape[Ellipsis:1], dtype=v.dtype)],\n                       axis=-1)\n  # Perform the rotation\n  return jnp.concatenate([jnp.cross(im(q), im(qv)) + re(qv) * re(q),\n                         jnp.dot(im(q), im(qv))],\n                         axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, -1]\n  return jnp.stack((jnp.sin(angle / 2) * axis, jnp.cos(angle / 2)), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, -1]\n  angle = jnp.maximum(angle, eps * jnp.ones_like(angle))\n  # https://en.wikipedia.org/wiki/Quaternion#Exponential,_logarithm,_and_power_functions\n  return jnp.concatenate(\n      [\n          jnp.sin(0.5 * angle) * axis,\n          jnp.cos(0.5 * angle),\n      ],\n      axis=-1,\n  )"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis to be a unit vector\n  axis = axis_angle / _safe_sqrt(axis_angle ** 2 + eps)\n\n  # Calculate the quaternion\n  w = jnp.cos(axis_angle * 0.5)\n  x, y, z = axis * jnp.sin(axis_angle * 0.5)\n\n  return jnp.stack((x, y, z, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis_angle_norm = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis_angle_angle = axis_angle_norm * 2.0\n  axis_angle_axis = axis_angle / axis_angle_norm\n  w = jnp.cos(axis_angle_angle / 2.0)\n  x = jnp.sin(axis_angle_angle / 2.0) * axis_angle_axis[Ellipsis, 0]\n  y = jnp.sin(axis_angle_angle / 2.0) * axis_angle_axis[Ellipsis, 1]\n  z = jnp.sin(axis_angle_angle / 2.0) * axis_angle_axis[Ellipsis, 2]\n  return jnp.stack([x, y, z, w], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[..., :3]\n  angle = axis_angle[..., -1]\n  axis_norm = linalg.norm(axis, axis=-1, keepdims=True)\n  axis = axis / axis_norm\n  angle = jnp.where(jnp.isclose(angle, 0, atol=eps), jnp.zeros_like(angle), angle)\n  angle = angle / 2.0\n  return jnp.concatenate(\n      (\n          jnp.cos(angle),\n          jnp.sin(angle) * axis,\n      ),\n      axis=-1,\n  )"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis_angle = axis_angle.reshape(axis_angle.shape[:-1] + (1, 3, 1))\n  axis_angle = axis_angle.swapaxes(0, 1)\n  axis_angle = axis_angle.reshape(axis_angle.shape[:-1] + (3,))\n\n  angle = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / angle\n  angle = jnp.clip(angle, a_min=eps, a_max=None)\n\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n  w = c + axis[Ellipsis, 3]\n  x = axis[Ellipsis, 0] * s\n  y = axis[Ellipsis, 1] * s\n  z = axis[Ellipsis, 2] * s\n  return jnp.stack((x, y, z, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis_angle = axis_angle.reshape((3,))\n  axis_norm = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / axis_norm\n  angle = axis_norm * 2.0\n  cos_angle = jnp.cos(angle / 2.0)\n  sin_angle = jnp.sin(angle / 2.0)\n  return jnp.stack([axis, cos_angle * axis_norm + sin_angle * axis], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, -1]\n  a_norm = jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  a_norm = jnp.where(a_norm == 0, eps * jnp.ones_like(a_norm), a_norm)\n  axis_norm = axis / a_norm\n  w = jnp.cos(angle / 2)\n  v = jnp.sin(angle / 2) * axis_norm\n  return jnp.concatenate((v, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis.\n  axis = axis_angle / _safe_sqrt(jnp.sum(axis_angle**2, axis=-1, keepdims=True))\n  # Compute the quaternion.\n  s = jnp.cos(axis_angle)\n  v = axis * jnp.sin(axis_angle)\n  return jnp.concatenate([s, v], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3]\n  angle = jnp.where(angle < 0.0, angle + jnp.pi, angle)\n  angle = jnp.where(angle > jnp.pi, angle - jnp.pi, angle)\n\n  # Ensure numerical stability for small angles.\n  epsilon = jnp.where(jnp.abs(angle) < eps, jnp.pi / 8, eps)\n  angle = jnp.where(jnp.abs(angle) > jnp.pi, jnp.pi - angle, angle)\n\n  # Compute the quaternion.\n  q = jnp.sin(angle / 2) * axis / jnp.sin(angle)\n  q = jnp.concatenate((jnp.cos(angle / 2), q), axis=-1)\n\n  return q"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[..., :3]\n  angle = axis_angle[..., -1]\n  axis_norm = linalg.norm(axis, axis=-1, keepdims=True)\n  axis_norm = jnp.where(\n      axis_norm < eps, jnp.ones_like(axis_norm), axis_norm\n  )\n  axis = axis / axis_norm\n  angle = jnp.where(axis_norm > eps, angle, 2.0 * jnp.arccos(1.0))\n  return jnp.stack(\n      [\n          jnp.cos(0.5 * angle),\n          axis * jnp.sin(0.5 * angle),\n      ],\n      axis=-1,\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3]\n  w = jnp.cos(angle / 2.0)\n  x = jnp.sin(angle / 2.0) * axis\n  return jnp.concatenate([x, w], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # https://en.wikipedia.org/wiki/Quaternion#From_axis_and_angle\n  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[:3]\n  angle = axis_angle[3]\n  axis_angle_norm = jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  axis = axis / axis_angle_norm\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n  return jnp.stack((axis * s, c), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3]\n  norm_axis = jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  axis = axis / norm_axis\n  angle = jnp.broadcast_to(angle, axis.shape)\n  s = jnp.sin(angle / 2)\n  c = jnp.cos(angle / 2)\n  return jnp.stack([axis * s, c], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[:3]\n  angle = axis_angle[3]\n  axis_angle_norm = linalg.norm(axis, axis=-1, keepdims=True)\n  axis = jnp.where(axis_angle_norm > eps, axis / axis_angle_norm, axis)\n  cos_angle = jnp.cos(angle)\n  sin_angle = jnp.sin(angle)\n\n  return jnp.concatenate((axis, cos_angle * axis + sin_angle * axis_angle[Ellipsis, :1]), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the input axis-angle vector.\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n\n  # Calculate the quaternion from the normalized axis-angle vector.\n  x, y, z, w = jnp.split(\n      axis_angle, 4, axis=-1)\n  w = jnp.sin(w)\n  xyz = jnp.cos(w) * axis_angle\n  return jnp.stack((xyz, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis_angle_norm = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis_angle_norm_sqrt = _safe_sqrt(axis_angle_norm)\n  w = axis_angle_norm_sqrt * jnp.cos(axis_angle / axis_angle_norm_sqrt)\n  axis_angle_norm_eps = jnp.maximum(axis_angle_norm, eps)\n  x, y, z = axis_angle / axis_angle_norm_eps\n  return jnp.stack((x, y, z, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = axis_angle / _safe_sqrt(axis_angle[Ellipsis, 0] ** 2 + axis_angle[Ellipsis, 1] ** 2 + axis_angle[Ellipsis, 2] ** 2)\n  w = jnp.cos(axis_angle[Ellipsis, 3] / 2)\n  v = jnp.sin(axis_angle[Ellipsis, 3] / 2) * axis_angle[Ellipsis, :3]\n\n  return jnp.concatenate((v, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # The following is a port of Ceres's quaternion_math.h:\n  #   https://github.com/ceres-solver/ceres-solver/blob/master/include/ceres/quaternion_math.h\n  #\n  # Note that the order of the axis_angle parameters is different from\n  # that of the quaternion.\n  #\n  # Also note that the quaternion is returned in the format [x,y,z,w]\n  # instead of the format [x,y,z].\n  #\n  # The code is based on the following paper:\n  #   https://www.cs.unc.edu/~wjh/papers/quaternions.pdf\n\n  axis_angle = jnp.asarray(axis_angle)\n  if axis_angle.ndim == 2:\n    # This is the batched case.\n    q = jnp.zeros([axis_angle.shape[0], 4])\n    q[:, 3] = jnp.cos(axis_angle)\n    s = jnp.sin(axis_angle)\n    q[:, :3] = axis_angle[:, 1:4] * s / _safe_sqrt(axis_angle[:, 0] + eps)\n  else:\n    # This is the unbatched case.\n    q = jnp.zeros(4)\n    q[3] = jnp.cos(axis_angle)\n    s = jnp.sin(axis_angle)\n    q[:3] = axis_angle[1:4] * s / _safe_sqrt(axis_angle[0] + eps)\n  return q\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # TODO: this is a copy-paste from Ceres\n  # https://github.com/ceres-solver/ceres-solver/blob/master/src/ceres/rotation/rotation_matrix_from_axis_angle.h\n\n  # The quaternion is given by\n  #\n  # q = (cos(a / 2), axis * sin(a / 2))\n  #\n  # where a is the angle and axis is the axis of rotation.\n  #\n  # The quaternion is normalized.\n  #\n  # The quaternion is a (4,) array-like.\n  #\n  # The axis is a (3,) array-like.\n  #\n  # The angle is a scalar.\n  #\n  # The quaternion is a (4,) array-like.\n\n  # Check the axis-angle\n  if not jnp.allclose(jnp.sum(axis_angle[Ellipsis, :3], axis=-1), 0.0):\n    raise ValueError(\n        \"The axis-angle representation must be a unit vector, \"\n        \"but it is not. The norm of the axis is %f.\"\n        % jnp.norm(axis_angle[Ellipsis, :3])\n\n  # The angle is the norm of the axis.\n  angle = jnp.linalg.norm(axis_angle[Ellipsis, :3])\n\n  # If the angle is close to zero, the quaternion is the identity quaternion.\n  if jnp.allclose(angle, 0.0):\n    return jnp.array([1.0, 0.0, 0.0, 0.0])\n\n  # Normalize the axis.\n  axis = axis_angle[Ellipsis, :3] / angle\n\n  # Compute the quaternion.\n  cos_a = jnp.cos(angle / 2)\n  sin_a = jnp.sin(angle / 2)\n  q = jnp.concatenate([cos_a, axis * sin_a], axis=-1)\n\n  # Normalize the quaternion.\n  return q / jnp.linalg.norm(q, axis=-1, keepdims=True)\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + 0) / 2\n    while high >= 0:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            high = 0\n        mid = (high + 0) / 2\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + 0) / 2\n    while high >= 0:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            mid = -1\n        mid = (high + mid) / 2\n    return mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[idx] < 1:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[idx] >= 1:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = 1\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] = 2 * logit_bias[idx]\n        num_calls += 1\n    high = logit_bias[idx]\n\n    # improve estimate\n    while high >= 1:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            break\n        high = high / 2\n        num_calls += 1\n    return -high, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 0\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n\n    # improve estimate\n    while True:\n        topk_words = model.topk(prefix, logit_bias)\n        if idx in topk_words:\n            return topk_words[idx], 1\n        else:\n            logit_bias[idx] *= 1.5\n            if logit_bias[idx] > high:\n                break\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    return model.logprob(prefix, logit_bias), 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # initialize high\n    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[0] != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + 0) / 2\n    while high >= 0:\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[0] == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix)\n    if idx in topk_words:\n        bias = topk_words[idx]\n        return bias, 0\n    topk_idxs = [i for i, _ in topk_words]\n    if idx not in topk_idxs:\n        raise TypeError(f\"Token {idx} not in topk.\")\n    else:\n        topk_idxs.remove(idx)\n    topk_logprobs = [topk_words[i] for i in topk_idxs]\n    bias = max(topk_logprobs)\n    return bias, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n\n    # improve estimate\n    num_calls = 1\n    while True:\n        logit_bias[idx] -= 1\n        if model.argmax(prefix, logit_bias) == idx:\n            return -logit_bias[idx], num_calls\n        num_calls += 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    if not isinstance(k, int) or k < 1:\n        raise TypeError(\"k must be a positive integer\")\n\n    # get raw topk, could be done outside and passed in\n    topk_words, topk_idxs = model.topk(prefix)\n    topk_idxs = set(topk_idxs)\n\n    # check if idx is the argmax\n    if idx in topk_idxs:\n        return topk_words[idx], 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while idx not in topk_idxs:\n        logit_bias[idx] *= 2\n        topk_words, topk_idxs = model.topk(prefix, logit_bias)\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + 0) / 2\n    while high >= 0:\n        logit_bias[idx] = mid\n        topk_words, topk_idxs = model.topk(prefix, logit_bias)\n        if idx in topk_idxs:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return topk_words[idx], 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n\n    # improve estimate\n    while True:\n        topk_words = model.topk(prefix, logit_bias)\n        topk_idxs = {w.idx for w in topk_words}\n        if idx in topk_idxs:\n            return topk_words[idx], 1\n        else:\n            logit_bias[idx] /= 2\n    return 0, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n\n    # improve estimate\n    mid = (high + 0) / 2\n    while high >= 0:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        if high == 1:\n            break\n\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    # get raw topk, could be done outside and passed in\n    topk_words, topk_idxs = model.topk(prefix, logit_bias)\n\n    # search for the target index in the topk results\n    if idx in topk_idxs:\n        return topk_words[idx], 1\n    else:\n        # get the bias for the target index\n        bias = topk_words[topk_idxs[0]] - topk_words[idx]\n        # adjust the logit_bias for the target index\n        logit_bias[idx] -= bias\n        # get the new topk results\n        topk_words, topk_idxs = model.topk(prefix, logit_bias)\n        # if the target index is in the new topk results, return the log probability and the number of calls\n        if idx in topk_idxs:\n            return topk_words[idx], 1\n        # else, repeat the process with a lower high bias\n        else:\n            return topk_search(model, prefix, idx, k, logit_bias[idx])\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    if k == 1:\n        return bisection_search(model, prefix, idx, k=k, low=0, high=high)\n    else:\n        topk_words = model.topk(prefix, high)\n        if idx not in topk_words:\n            raise TypeError(\n                f\"Target index {idx} not in topk {k} with bias {high}.\"\n                \"Either increase bias or provide top unbiased logprob (top_logprob)\"\n            )\n        num_calls = 0\n        logprob = 0\n        for i in range(k):\n            logprob += topk_words[idx]\n            if i == 0:\n                continue\n            num_calls += 1\n            mid = (high + topk_words[idx]) / 2\n            logit_bias = {idx: mid}\n            for j in range(1, k):\n                if j == i:\n                    continue\n                logit_bias[topk_words.keys()[j]] = high\n            if model.argmax(prefix, logit_bias) == idx:\n                high = mid\n            else:\n                low = mid\n            mid = (high + low) / 2\n            num_calls += 1\n        return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, high)\n    topk_idxs = list(topk_words.keys())\n    topk_words = list(topk_words.values())\n\n    # find initial logit bias\n    logit_bias = {i: 0 for i in topk_idxs}\n    logit_bias[idx] = high\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    logit_bias[idx] = high\n\n    # get logit bias of idx in raw topk\n    logit_bias_idx = topk_words.index(logit_bias[idx])\n    logit_bias_idx = topk_idxs[logit_bias_idx]\n\n    # get initial logit bias\n    logit_bias = {i: 0 for i in topk_idxs}\n    logit_bias[logit_bias_idx] = high\n    while model.argmax(prefix, logit_bias) != logit_bias_idx:\n        logit_bias[logit_bias_idx] *= 2\n    logit_bias[logit_bias_idx] = high\n\n    # get initial logprobs\n    logprobs = np.array([topk_words[i] for i in topk_idxs])\n    logprobs -= logit_bias[logit_bias_idx]\n    logprobs = np.log1p(np.exp(logprobs))\n\n    # get logprob of idx\n    logprob = logprobs[topk_idxs.index(idx)]\n    logprob += logit_bias[idx]\n    logprob = np.log1p(-np.exp(logprob))\n\n    # get num_calls\n    num_calls = 1\n    while logit_bias[logit_bias_idx] >= 0:\n        logit_bias[logit_bias_idx] /= 2\n        if model.argmax(prefix, logit_bias) == idx:\n            num_calls += 1\n        else:\n            num_calls += k\n    return log"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return trilinear_resample_3d(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center)\n  elif method == 'NEAREST':\n    return nearest_neighbor_resample_3d(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        coordinate_order=coordinate_order)\n  else:\n    raise ValueError(f'Invalid interpolation method: {method}')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _resample_3d_trilinear(\n      data,\n      locations,\n      edge_behavior,\n      constant_values,\n      coordinate_order,\n      half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return _resample_3d_nearest_neighbor(\n      data,\n      locations,\n      edge_behavior,\n      constant_values,\n      coordinate_order,\n      half_pixel_center,\n    )\n  else:\n    raise ValueError(\n      f'Method {method} is not supported. '\n      f'Supported methods are \"TRILINEAR\" and \"NEAREST\".')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_3d(data, locations, edge_behavior, constant_values,\n                         coordinate_order, half_pixel_center)\n  elif method == 'NEAREST':\n    return _nearest_3d(data, locations, edge_behavior, constant_values)\n  else:\n    raise ValueError(\n        f'Method must be either \\'TRILINEAR\\' or \\'NEAREST\\', got {method}'\n    )\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _resample_3d_trilinear(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center)\n  elif method == 'NEAREST':\n    return _resample_3d_nearest(\n        data,\n        locations,\n        edge_behavior,\n        coordinate_order,\n        half_pixel_center)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return _nearest_resample(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center,\n    )\n  else:\n    raise ValueError(f'Unknown method {method}')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return _resample_3d_trilinear(\n      data,\n      locations,\n      edge_behavior,\n      constant_values,\n      coordinate_order,\n    )\n  elif method == 'NEAREST':\n    return _resample_3d_nearest_neighbor(\n      data,\n      locations,\n      edge_behavior,\n      coordinate_order,\n    )\n  else:\n    raise ValueError(f'Unknown method {method}.')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    interpolation = _trilinear_interpolation\n  elif method == 'NEAREST':\n    interpolation = _nearest_neighbor_interpolation\n  else:\n    raise ValueError(\n        'Invalid interpolation method: {}'.format(method))\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    edge_behavior = _constant_outside_edge_behavior\n  elif edge_behavior == 'CLAMP':\n    edge_behavior = _clamp_edge_behavior\n  else:\n    raise ValueError(\n        'Invalid edge_behavior: {}'.format(edge_behavior))\n\n  if half_pixel_center:\n    locations = _half_pixel_center_locations(locations, coordinate_order)\n\n  return edge_behavior(interpolation(data, locations), constant_values)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  data = jnp.asarray(data)\n  locations = jnp.asarray(locations)\n  if jnp.ndim(data) != 4 or jnp.ndim(locations) < 2:\n    raise ValueError(\n        'Input data and locations must be 4D and 2D tensors, respectively.')\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'Invalid edge_behavior. Must be one of CONSTANT_OUTSIDE or CLAMP.')\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        'Invalid interpolation method. Must be one of TRILINEAR or NEAREST.')\n\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Clamp locations to the volume.\n  if edge_behavior == 'CLAMP':\n    x_coordinate = jnp.clip(x_coordinate, 0, data.shape[2] - 1)\n    y_coordinate = jnp.clip(y_coordinate, 0, data.shape[1] - 1)\n    z_coordinate = jnp.clip(z_coordinate, 0, data.shape[0] - 1)\n\n  # Half-pixel centering.\n  if half_pixel_center:\n    x_coordinate = x_coordinate + 0.5\n    y_coordinate = y_coordinate + 0.5\n    z_coordinate = z_coordinate + 0.5\n\n  # Resample.\n  if method == 'TRILINEAR':\n    return gather_volume(data, locations)\n  elif method == 'NEAREST':\n    return gather_volume(data, locations, coordinate_order=coordinate_order)"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    pad_data = jnp.pad(\n        data,\n        paddings=jnp.asarray([[0, 0], [0, 0], [0, 0], [0, 0]], dtype=jnp.int32),\n        constant_values=constant_values,\n        mode='CONSTANT')\n  elif edge_behavior == 'CLAMP':\n    pad_data = jnp.clip(data, 0, 1)\n  else:\n    raise ValueError('Unsupported edge_behavior: %s.' % edge_behavior)\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n  else:\n    raise ValueError('Unsupported coordinate_order: %s.' % coordinate_order)\n  if half_pixel_center:\n    x_coordinate = x_coordinate + 0.5\n    y_coordinate = y_coordinate + 0.5\n    z_coordinate = z_coordinate + 0.5\n\n  if method == 'TRILINEAR':\n    return gather_volume(\n      pad_data,\n      jnp.stack([z_coordinate, y_coordinate, x_coordinate], axis=-1))\n  elif method == 'NEAREST':\n    return gather_volume(\n        pad_data,\n        jnp.round(jnp.stack([z_coordinate, y_coordinate, x_coordinate], axis=-1)))\n  else:\n    raise ValueError('Unsupported method: %s.' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Handle edge behavior.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data_padded = jax.nn.pad(data, (0, 1, 0, 0, 0, 1, 0, 0), constant_values=constant_values)\n\n  elif edge_behavior == 'CLAMP':\n    data_padded = jax.nn.pad(data, (0, 1, 0, 0, 0, 1, 0, 0), constant_values=0)\n\n  else:\n    raise ValueError('Unsupported edge behavior: ' + edge_behavior)\n\n  # Handle half-pixel centering.\n  if half_pixel_center:\n    x_coordinate = x_coordinate - 0.5\n    y_coordinate = y_coordinate - 0.5\n    z_coordinate = z_coordinate - 0.5\n\n  # Use Advanced indexing to gather data data.\n  if method == 'TRILINEAR':\n    return jax.vmap(lambda x, y, z: jax.nn.swapaxes(jax.nn.swapaxes(jax.nn.swapaxes(jax.nn.swapaxes(\n        data_padded, 3, 0), 3, 1), 3, 2), (Ellipsis, 0, 0))(x_coordinate, y_coordinate, z_coordinate)\n  elif method == 'NEAREST':\n    return jax.vmap(lambda x, y, z: jax.nn.swapaxes(jax.nn.swapaxes(jax.nn.swapaxes(\n        data_padded, 3, 0), 3, 1), (Ellipsis, 0, "}
{"namespace": "resample.resample_3d", "completion": "  # Get the dimensions of the input data.\n  D, H, W, C = data.shape\n\n  # Determine the coordinate order.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Check the interpolation method.\n  if method == 'TRILINEAR':\n    interpolation_method = jax.nn.interp.trilinear_interpolation_2d\n  elif method == 'NEAREST':\n    interpolation_method = jax.nn.interp.nearest_neighbor_interpolation_2d\n  else:\n    raise ValueError('The interpolation method must be either \"TRILINEAR\" or \"NEAREST\".')\n\n  # Check the edge behavior.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    outside_behavior = jax.nn.interp.CONSTANT\n    outside_constant_value = constant_values\n  elif edge_behavior == 'CLAMP':\n    outside_behavior = jax.nn.interp.CLAMP\n  else:\n    raise ValueError(\n        'The edge behavior must be either \"CONSTANT_OUTSIDE\" or \"CLAMP\".')\n\n  # Calculate the sample locations.\n  if half_pixel_center:\n    x_coordinate = (x_coordinate + 0.5) / W\n    y_coordinate = (y_coordinate + 0.5) / H\n    z_coordinate = (z_coordinate + 0.5) / D\n  else:\n    x_coordinate = x_coordinate / W\n    y_coordinate = y_coordinate / H\n    z_coordinate = z_coordinate / D\n\n  # Resample the data.\n  return jax.nn.interp.interp_3d(\n      data,\n      (x_coordinate, y_coordinate, z_coordinate),\n      interpolation_method,\n      outside_behavior,\n      outside_constant_value)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # TODO(f00d): Implement CLAMP edge behavior.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    locations = jax.lax.stop_gradient(locations)\n\n  # TODO(f00d): Implement half-pixel centering.\n  if half_pixel_center:\n    raise NotImplementedError\n\n  if method == 'TRILINEAR':\n    return jax.vmap(jax.nnp.interpn, in_axes=[0, 1, 2])(\n        data, locations, [Ellipsis, 0, 1, 2], method='bilinear',\n        mode='nearest', order=2)\n  elif method == 'NEAREST':\n    return jax.vmap(gather_volume, in_axes=[0, 1, 2])(\n        data, locations, coordinate_order=coordinate_order)\n  else:\n    raise ValueError(\n        'Invalid method: {}'.format(method))"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Convert to integer locations\n    locations = locations.astype(jnp.int32)\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the volume.\n    locations = jnp.clip(locations, 0, data.shape[Ellipsis] - 1)\n  else:\n    raise ValueError('Invalid edge_behavior: {}'.format(edge_behavior))\n\n  if half_pixel_center:\n    # If half-pixel centering is enabled, add 0.5 to the locations.\n    locations += 0.5\n\n  if method == 'TRILINEAR':\n    return jax.vmap(functools.partial(trilinear_interpolation, coordinate_order))(\n        data, locations)\n  elif method == 'NEAREST':\n    return jax.vmap(functools.partial(nearest_neighbor_interpolation,\n                                     coordinate_order))(data, locations)\n  else:\n    raise ValueError('Invalid method: {}'.format(method))\n\n"}
{"namespace": "resample.resample_3d", "completion": "  assert method in ['TRILINEAR', 'NEAREST'], (\n      'method must be either \"TRILINEAR\" or \"NEAREST\"')\n  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center)\n  elif method == 'NEAREST':\n    return _nearest_neighbor_resample(\n        data,\n        locations,\n        edge_behavior,\n        constant_values,\n        coordinate_order,\n        half_pixel_center)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # TODO(praggy): Add support for other interpolation methods.\n  if method == 'TRILINEAR':\n    return _trilinear_resample(\n        data, locations, edge_behavior, constant_values, coordinate_order,\n        half_pixel_center)\n  elif method == 'NEAREST':\n    return _nearest_resample(data, locations, edge_behavior, coordinate_order)\n\n  raise ValueError(\n      f'Unknown method {method}. Supported methods are TRILINEAR and NEAREST.')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # Check for half-pixel centering.\n  if half_pixel_center:\n    # Shift the locations by 0.5, so that the locations are half-pixel centered.\n    locations = locations + 0.5\n\n  # Check for clamping.\n  if edge_behavior == 'CLAMP':\n    # Clamp the locations to the volume.\n    locations = jnp.clip(locations, 0, jnp.array(data.shape[1:4], dtype=locations.dtype))\n\n  # Check for trilinear interpolation.\n  if method == 'TRILINEAR':\n\n    # Get the locations in the correct order.\n    if coordinate_order == 'xyz':\n      x_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      z_coordinate = locations[Ellipsis, 2]\n    elif coordinate_order == 'zyx':\n      z_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      x_coordinate = locations[Ellipsis, 2]\n\n    # Compute the bilinear interpolation.\n    # TODO(b/210688560)\n    data_x = jnp.take_nd(data, x_coordinate)\n    data_y = jnp.take_nd(data_x, y_coordinate)\n    data_z = jnp.take_nd(data_y, z_coordinate)\n    return data_z\n\n  # Check for nearest neighbor interpolation.\n  if method == 'NEAREST':\n    # Get the locations in the correct order.\n    if coordinate_order == 'xyz':\n      x_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      z_coordinate = locations[Ellipsis, 2]\n    elif coordinate_order == 'zyx':\n      z_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      x_coordinate = locations[Ellipsis, 2]\n\n    # Compute the nearest neighbor interpolation.\n    return gather_volume(data, locations, coordinate_order=coordinate_"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if method == 'TRILINEAR':\n    # Trilinear interpolation.\n    # The coordinates of the sample points are normalized to be in the range [0,1]\n    # and used to bilinearly interpolate the data.\n    #\n    # The interpolation is performed in two stages, first bilinearly in the x-y plane\n    # and then linearly in the z-dimension.\n    #\n    # The bilinear interpolation is implemented using the jax.scipy.ndimage.\n    # bilinear_interpolate function.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is performed in the z-dimension.\n    #\n    # The bilinear interpolation is performed in the x-y plane.\n    # The bilinear interpolation is"}
{"namespace": "resample.resample_3d", "completion": "  # TODO(jlshi): Add support for 'CLAMP' edge behavior.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(\n        data,\n        paddings=(\n            (0, 0),\n            (0, 0),\n            (0, 0),\n            (0, 0),\n        ),\n        constant_values=constant_values)\n\n  if method == 'TRILINEAR':\n    return jax.nn.interpolate(\n        data,\n        locations,\n        d=3,\n        method=method,\n        scale_min=1.0,\n        scale_max=1.0,\n        interpolation_order=3,\n        half_pixel_center=half_pixel_center)\n  elif method == 'NEAREST':\n    # This is a naive implementation of nearest neighbor interpolation.\n    # TODO(jlshi): Optimize this implementation.\n    gather_fn = functools.partial(\n        gather_volume, coordinate_order=coordinate_order)\n\n    if half_pixel_center:\n      locations = locations - 0.5\n\n    return gather_fn(data, locations)"}
{"namespace": "resample.resample_3d", "completion": "  # TODO(yashkulshrestha): Add support for NEAREST method.\n  if method == 'TRILINEAR':\n    return trilinear_interpolation(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center)\n  else:\n    raise ValueError('Invalid interpolation method: %s' % method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if method == 'TRILINEAR':\n    # Trilinear interpolation.\n    # We interpolate using 2D bilinear interpolation in the x, y direction, then\n    # interpolate the result in the z direction.\n    #\n    # We use a 2D interpolation to interpolate in the xy plane, and then\n    # interpolate in the z direction. This is faster than doing a 3D\n    # interpolation.\n    #\n    # The input data is assumed to have voxel centers at integer coordinates,\n    # but the output locations are not.\n    #\n    # We use bilinear interpolation in the xy plane, and then interpolate in the\n    # z direction. This is faster than doing a 3D interpolation.\n    #\n    # The input data is assumed to have voxel centers at integer coordinates,\n    # but the output locations are not.\n    #\n    # We use bilinear interpolation in the xy plane, and then interpolate in the\n    # z direction. This is faster than doing a 3D interpolation.\n    #\n    # The input data is assumed to have voxel centers at integer coordinates,\n    # but the output locations are not.\n\n    # Get the 2D interpolation locations.\n    x_coordinate_int = x_coordinate.astype(jnp.int32)\n    y_coordinate_int = y_coordinate.astype(jnp.int32)\n\n    # Get the 3D interpolation locations.\n    z_coordinate_int = z_coordinate.astype(jnp.int32)\n\n    # Get the 2D interpolation locations.\n    x_coordinate_int = x_coordinate_int.astype(jnp.int32)\n    y_coordinate_int = y_coordinate_int.astype(jnp.int32"}
{"namespace": "math.plus_eps", "completion": "  return x + tiny_val, x + tiny_val\n\n"}
{"namespace": "math.plus_eps", "completion": "  def jac(x, delta):\n    return delta\n\n  return x.at[x < tiny_val].set(tiny_val), jac(x, jnp.ones_like(x))\n\n"}
{"namespace": "math.plus_eps", "completion": "  tiny_val = np.finfo(np.float32).tiny\n  return x + tiny_val, tiny_val\n\n"}
{"namespace": "math.plus_eps", "completion": "  return x, jnp.maximum(x, tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  if x > tiny_val:\n    return x, x\n  else:\n    return tiny_val, tiny_val\n\n"}
{"namespace": "math.plus_eps", "completion": "  def jvp(x_v):\n    if x_v < tiny_val:\n      return jnp.ones_like(x_v) * tiny_val\n    else:\n      return jnp.ones_like(x_v)\n\n  return x, jvp\n\n"}
{"namespace": "math.plus_eps", "completion": "  if x >= tiny_val:\n    return x, x\n  else:\n    return x, min_val\n\n"}
{"namespace": "math.plus_eps", "completion": "  @jax.jit\n  def _impl(x):\n    return jax.lax.cond(\n        x <= tiny_val, lambda _: tiny_val, lambda x: x + tiny_val)\n\n  return _impl, jax.vmap(_impl)\n\n"}
{"namespace": "math.plus_eps", "completion": "  # pylint: disable=no-value-for-parameter\n  def fn(x):\n    return jnp.where(x > tiny_val, x, tiny_val)\n\n  return fn, jnp.where(x > tiny_val, x, tiny_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + min_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  def _jvp(x, _):\n    if x < tiny_val:\n      return tiny_val, jnp.zeros_like(x)\n    return x, jnp.ones_like(x)\n\n  return _jvp(x, 0)\n\n"}
{"namespace": "math.plus_eps", "completion": "  eps = tiny_val\n  return x.at[x < eps].set(eps), jnp.where(x < eps, eps, jnp.nextafter(x, float(\"inf\")))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x + min_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  def jvp_fun(x_val, x_jac):\n    if x_val < tiny_val:\n      return tiny_val, jnp.zeros_like(x_val)\n    else:\n      return x_val, jnp.ones_like(x_val)\n\n  return jvp_fun(x, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  # TODO: check if this is the best way to do this\n  # x_is_small = jnp.abs(x) < tiny_val\n  # x_is_small = jnp.abs(x) < 1e-30\n  x_is_small = jnp.abs(x) < min_val\n  return x_is_small, jnp.where(x_is_small, tiny_val, x + min_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  x = jnp.asarray(x)\n  if jnp.is_float(x):\n    return x + tiny_val, x + tiny_val\n  elif jnp.is_complex(x):\n    return (x + jnp.complex(tiny_val, 0.0), x + jnp.complex(tiny_val, 0.0))\n  elif jnp.is_complex_like(x):\n    return (x + jnp.real(tiny_val), x + jnp.real(tiny_val))\n  else:\n    raise ValueError(f'Unexpected type {x.dtype}')\n\n"}
{"namespace": "math.plus_eps", "completion": "  x = jax.lax.stop_gradient(x)  # don't need the gradient of the eps\n  eps = tiny_val\n  if x < eps:\n    return eps, eps\n  else:\n    return x + eps, x + eps\n\n"}
{"namespace": "math.plus_eps", "completion": "  def jvp_impl(x_in, jac):\n    return (x_in + tiny_val, jac)\n\n  return jvp_impl(x, jnp.zeros_like(x))\n\n"}
{"namespace": "math.plus_eps", "completion": "  @functools.partial(jax.vjp.vmap, in_axes=0)\n  def jvp(y, g):\n    return g, jax.vjp.vjp.vmap(jvp_impl)(y, g)\n\n  def jvp_impl(y, g):\n    return jnp.where(jnp.abs(y) < tiny_val, tiny_val, y + jnp.finfo(y.dtype).eps * g)\n\n  return jax.vjp.vjp.vmap(jvp)(x, 1.0)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return x + tiny_val, jnp.ones_like(x)\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val,\n      -tiny_val,\n      jnp.nextafter(jnp.float32(x), -jnp.inf),\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val,\n      -tiny_val,\n      jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-tiny_val, tiny_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-100 * jnp.pi, 100 * jnp.pi),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-100, 100),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-tiny_val, tiny_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-tiny_val, tiny_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log, jnp.log, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (-1, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  @jax.custom_jvp\n  def safe_log_fn(x):\n    \"\"\"Clamps `x` from below to be positive.\"\"\"\n    return jnp.log(jnp.maximum(tiny_val, x))\n\n  @safe_log_fn.defjvp\n  def safe_log_fn_jvp(primals, tangents):\n    \"\"\"Override `jnp.log`'s gradient to be a no-op.\"\"\"\n    return safe_log_fn(primals[0]), tangents[0]\n\n  return safe_log_fn(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  def safe_log_fn(x):\n    \"\"\"\n    The safe logarithm function created by `generate_safe_fn`. It takes a single value or array as input and returns the logarithm of the input value or array.\n    :param x: The input value or array for which the logarithm is to be calculated.\n    :return: The result of applying the safe logarithm function to `x`. This could be a single value or an array of values, depending on the input `x`.\n    \"\"\"\n    return jnp.log(jnp.clip(x, 0, jnp.inf))\n\n  return generate_safe_fn(safe_log_fn, jnp.log, (0, jnp.inf))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log, jnp.log, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (-np.inf, 0))\n\n"}
{"namespace": "math.safe_log", "completion": "  def safe_log_fn(x):\n    \"\"\"\n    This function creates a safe version of the logarithm function that can handle edge cases or specific conditions defined by `generate_safe_fn`. It wraps the JAX numpy logarithm function (`jnp.log`) with additional logic to manage derivatives and bounds, ensuring stability and safety in computations.\n\n    Args:\n      x: The input value or array for which the logarithm is to be calculated. It is used as the input to the safe logarithm function created by `generate_safe_fn`.\n\n    Returns:\n      The result of applying the safe logarithm function to `x`. This could be a single value or an array of values, depending on the input `x`.\n    \"\"\"\n    return jnp.log(jnp.clip(x, tiny_val, max_val))\n\n  return generate_safe_fn(safe_log_fn, jax.numpy_component_vjp(jnp.log), (min_val, max_val))\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jax.nn.log, jax.vmap(jax.nn.log, in_axes=0), (-jnp.inf, 0)\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  # pylint: disable=no-member-operand\n\n  def safe_log_fwd(x):\n    \"\"\"\n    This function creates a safe version of the logarithm function that can handle edge cases or specific conditions defined by `generate_safe_fn`. It wraps the JAX numpy logarithm function (`jnp.log`) with additional logic to manage derivatives and bounds, ensuring stability and safety in computations.\n\n    Input-Output Arguments\n    :param x: The input value or array for which the logarithm is to be calculated. It is used as the input to the safe logarithm function created by `generate_safe_fn`.\n    :return: The result of applying the safe logarithm function to `x`. This could be a single value or an array of values, depending on the input `x`.\n    \"\"\"\n\n    return jnp.log(jnp.where(jnp.abs(x) < tiny_val, tiny_val, x))\n\n  def safe_log_bwd(res, g):\n    \"\"\"\n    This function creates a safe version of the derivative of the logarithm function that can handle edge cases or specific conditions defined by `generate_safe_fn`. It wraps the JAX numpy logarithm function (`jnp.log`) with additional logic to manage derivatives and bounds, ensuring stability and safety in computations.\n\n    Input-Output Arguments\n    :param res: The result of applying the safe logarithm function to the input `x`.\n    :param g: The gradient of the logarithm function.\n    :return: The result of applying the safe derivative of the logarithm function to `res` and `g`.\n    \"\"\"\n\n    return jnp.where(jnp.abs(res) < tiny_val, 0, g / res)\n\n  return generate_safe_fn(safe_log_fwd, safe_log_bwd, (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log, jnp.log, (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  @jax.custom_jvp\n  def safe_log_fn(x):\n    \"\"\"\n    This function calculates the logarithm of `x` and returns the result.\n\n    Input-Output Arguments\n    :param x: The input value or array for which the logarithm is to be calculated.\n    :return: The result of applying the logarithm function to `x`. This could be a single value or an array of values, depending on the input `x`.\n    \"\"\"\n\n    return jnp.log(jnp.clip(x, min_val, max_val))\n\n  @safe_log_fn.defjvp\n  def safe_log_fn_jvp(primals, tangents):\n    \"\"\"\n    This function calculates the derivative of the logarithm function with respect to its input.\n\n    Input-Output Arguments\n    :param primals: The input value or array for which the logarithm is to be calculated.\n    :param tangents: The input value or array for which the derivative of the logarithm function is to be calculated.\n    :return: The result of applying the derivative of the logarithm function to `primals`. This could be a single value or an array of values, depending on the input `primals`.\n    \"\"\"\n\n    (x,) = primals\n\n    # Compute the derivative of the logarithm function with respect to its input.\n    # This is the same as the inverse of the derivative of the exponential function with respect to its input.\n    x_dot = jnp.exp(x)\n    return x_dot, x_dot\n\n  return safe_log_fn\n\n"}
{"namespace": "math.safe_log", "completion": "  def safe_log_fn(x):\n    \"\"\"\n    This is the function that is created by `generate_safe_fn` and is used to calculate the logarithm of `x` with safety and stability.\n    \"\"\"\n    return jnp.log(jnp.clip(x, tiny_val, max_val))\n\n  return safe_log_fn(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  @jax.custom_jvp\n  def safe_log_jax(x):\n    \"\"\"\n    This function is a wrapper around the JAX numpy logarithm function (`jnp.log`) that ensures stability and safety in computations. It takes a single input `x` and returns the result of applying the logarithm function to `x`.\n\n    Input-Output Arguments\n    :param x: The input value or array for which the logarithm is to be calculated.\n    :return: The result of applying the logarithm function to `x`.\n    \"\"\"\n    return jnp.log(jnp.clip(x, min_val, max_val))\n\n  @safe_log_jax.defjvp\n  def safe_log_jax_jvp(primals, tangents):\n    \"\"\"\n    This function is a wrapper around the JAX numpy logarithm function (`jnp.log`) that ensures stability and safety in computations. It takes a single input `x` and returns the result of applying the logarithm function to `x`.\n\n    Input-Output Arguments\n    :param primals: The primal values for the computation. This is a tuple of values, where each value represents the primal value for a specific variable in the computation.\n    :param tangents: The tangent values for the computation. This is a tuple of values, where each value represents the tangent value for a specific variable in the computation.\n    :return: The result of applying the logarithm function to `x`.\n    \"\"\"\n    x, = primals\n    x_dot, = tangents\n    y = safe_log_jax(x)\n    y_dot = jnp.where(jnp.abs(x) < tiny_val, 0, jnp.log(x))\n    return y, y_dot\n\n  return safe_log_jax\n\n"}
{"namespace": "math.safe_log", "completion": "  @jax.custom_jvp\n  def safe_log_jvp(primals, tangents):\n    \"\"\"Backpropagate using the gradient and clipped inputs.\"\"\"\n    x = primals[0]\n    x_dot = tangents[0]\n    y = safe_log(x)\n    y_dot = jnp.where(\n        x > 0, jnp.where(x < tiny_val, 1.0 / tiny_val, jnp.float32(1.0) / x), 0.0\n    )\n    return y, y_dot\n\n  return safe_log_jvp(x, jnp.ones_like(x))\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log, jnp.log, (-min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  @jax.custom_jvp\n  def safe_log_jax_custom_jvp(x):\n    \"\"\"\n    This function defines the custom jax.jvp for the safe logarithm function. It takes the input `x` and passes it to the `jnp.log` function to calculate the logarithm. It then uses the `jax.jvp` function to calculate the derivative of the logarithm and returns the result.\n    \"\"\"\n    return jnp.log(jnp.clip(x, min_val, max_val)), (1.0 / x,)\n\n  @safe_log_jax_custom_jvp.defjvp\n  def safe_log_jax_custom_jvp_defjvp(primals, tangents):\n    \"\"\"\n    This function defines the custom jax.jvp for the derivative of the safe logarithm function. It takes the `primals` and `tangents` values, which are the output of the `jax.jvp` function, and returns the derivative of the logarithm.\n    \"\"\"\n    x, _ = primals\n    x_dot, _ = tangents\n    return jnp.log(x), jnp.log(x) * x_dot\n\n  return safe_log_jax_custom_jvp(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (-np.inf, np.inf))(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: x_dot / (2 * jnp.sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.sqrt(y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * y * x_dot / jnp.sqrt(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.sqrt(x),\n      (0, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.sqrt(y),\n      (0, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / jnp.sqrt(x),\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.sqrt(y),\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  def safe_sqrt_jvp(primals, tangents):\n    \"\"\"Backpropagate using the gradient and clipped inputs.\"\"\"\n    (x,) = primals\n    (x_dot,) = tangents\n    y = safe_sqrt(x)\n    y_dot = jax.grad(jnp.sqrt)(jnp.clip(x, 0, np.nextafter(np.log(max_val), np.float32(0))), y_dot\n    return y, y_dot\n\n  return jax.custom_vjp(jnp.sqrt, safe_sqrt_jvp)(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  def safe_sqrt_fn(x):\n      \"\"\"Computes the safe square root of the input x.\"\"\"\n      # This is the safe square root function that will be applied to the input x.\n      return generate_safe_fn(\n          jnp.sqrt,\n          lambda x, _, x_dot: x_dot / jnp.sqrt(x),\n          (0, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n  return safe_sqrt_fn\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * y * x_dot / jnp.sqrt(x),\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  def safe_sqrt_jvp(primals, tangents):\n    \"\"\"Backpropagate using the gradient and clipped inputs.\"\"\"\n    (x,) = primals\n    (x_dot,) = tangents\n    y = safe_sqrt(x)\n    y_dot = jnp.where(x > 0, 0.5 * y_dot / jnp.sqrt(x), jnp.zeros_like(y))\n    return y, y_dot\n\n  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: jnp.where(x > 0, 0.5 * x_dot / jnp.sqrt(x), jnp.zeros_like(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * y * jnp.reciprocal(jnp.sqrt(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * y_dot,\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  # This function creates a safe version of the square root function that can handle edge cases more gracefully. It uses a helper function to generate this safe square root function, which includes a custom gradient for backpropagation in automatic differentiation contexts. The safe version ensures that the input is clamped between 0 and a maximum value to avoid invalid inputs like negative numbers.\n  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  def safe_sqrt_grad(x, y, x_dot):\n    \"\"\"The custom gradient for the safe square root function.\n\n    This is used for backpropagation in automatic differentiation contexts. It computes the gradient of the safe square root function with respect to the input x.\n\n    Input-Output Arguments\n    :param x: The input value for which the safe square root will be computed.\n    :param y: The result of applying the safe square root function to x.\n    :param x_dot: The gradient of the input x with respect to the loss.\n    :return: The gradient of the safe square root function with respect to the input x.\n    \"\"\"\n\n    return safe_div(y, 2 * jnp.sqrt(x))\n\n  return generate_safe_fn(\n      jnp.sqrt,\n      safe_sqrt_grad,\n      (tiny_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  def safe_sqrt_grad(x, y, x_dot):\n    \"\"\"The custom gradient for the safe square root function.\n\n    This function computes the gradient of the safe square root function with respect to the input x. It takes as input the value of x, the output of the safe square root function, and the gradient of the output with respect to the input x. The gradient of the safe square root function is computed using the following formula:\n\n    y_dot = 0.5 * x_dot / y\n\n    The gradient of the safe square root function is then returned, which is used for the automatic differentiation.\n\n    Args:\n      x: The value of the input x.\n      y: The output of the safe square root function.\n      x_dot: The gradient of the output with respect to the input x.\n\n    Returns:\n      The gradient of the safe square root function with respect to the input x.\n    \"\"\"\n    return 0.5 * x_dot / y\n\n  return generate_safe_fn(\n      lambda x: jnp.sqrt(jnp.clip(x, 0.0, np.float32(1000))),\n      safe_sqrt_grad,\n      (0.0, np.nextafter(np.log(np.float32(1000)),),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  def safe_sqrt_helper(x):\n    \"\"\"\n    This function defines the helper function that will be used to generate the safe square root function. It uses a custom gradient function to handle backpropagation in automatic differentiation contexts. The helper function clamps the input between 0 and a maximum value to avoid invalid inputs like negative numbers.\n    \"\"\"\n    return jax.nn.softplus(x)\n\n  return jax.vmap(safe_sqrt_helper)(x)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 0\n  if p == 0:\n    return 1\n  if p == 1:\n    return 1\n  if p == 2:\n    return 2\n  if p == 3:\n    return 3\n  if p == 4:\n    return 4\n  if p == 5:\n    return 5\n  if p == 6:\n    return 6\n  if p == 7:\n    return 7\n  if p == 8:\n    return 8\n  if p == 9:\n    return 9\n  if p == 10:\n    return 10\n  if p == 11:\n    return 11\n  if p == 12:\n    return 12\n  if p == 13:\n    return 13\n  if p == 14:\n    return 14\n  if p == 15:\n    return 15\n  if p == 16:\n    return 16\n  if p == 17:\n    return 17\n  if p == 18:\n    return 18\n  if p == 19:\n    return 19\n  if p == 20:\n    return 20\n  if p == 21:\n    return 21\n  if p == 22:\n    return 22\n  if p == 23:\n    return 23\n  if p == 24:\n    return 24\n  if p == 25:\n    return 25\n  if p == 26:\n    return 26\n  if p == 27:\n    return 27\n  if p == 28:\n    return 28\n  if p == 29:\n    return 29\n  if p == 30:\n    return 30\n  if p == 31:\n    return 31\n  if p == 32:\n    return 32\n  if p == 33:\n    return"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 0\n  elif p == 2:\n    return 1\n  elif p == 3:\n    return 2\n  elif p == 4:\n    return 3\n  elif p == 5:\n    return 4\n  elif p == 6:\n    return 5\n  elif p == 7:\n    return 6\n  elif p == 8:\n    return 7\n  elif p == 9:\n    return 8\n  elif p == 10:\n    return 9\n  elif p == 11:\n    return 10\n  elif p == 12:\n    return 11\n  elif p == 13:\n    return 12\n  elif p == 14:\n    return 13\n  elif p == 15:\n    return 14\n  elif p == 16:\n    return 15\n  elif p == 17:\n    return 16\n  elif p == 18:\n    return 17\n  elif p == 19:\n    return 18\n  elif p == 20:\n    return 19\n  elif p == 21:\n    return 20\n  elif p == 22:\n    return 21\n  elif p == 23:\n    return 22\n  elif p == 24:\n    return 23\n  elif p == 25:\n    return 24\n  elif p == 26:\n    return 25\n  elif p == 27:\n    return 26\n  elif p == 28:\n    return 27\n  elif p == 29:\n    return 28\n  elif p == 30:\n    return 29\n  elif p == 31:\n    return 30\n  elif p == 32:\n    return 31\n  elif p == 33:\n    return 32\n  elif p == 34:\n    return 33\n  elif p == 35:"}
{"namespace": "math.power_ladder_max_output", "completion": "  if jnp.abs(p) < 1:\n    return 1.0\n  elif p == 1:\n    return 1.0\n  elif p == 2:\n    return 2.0\n  elif p == 3:\n    return 3.0\n  elif p == 4:\n    return 4.0\n  elif p == 5:\n    return 5.0\n  elif p == 6:\n    return 6.0\n  elif p == 7:\n    return 7.0\n  elif p == 8:\n    return 8.0\n  elif p == 9:\n    return 9.0\n  elif p == 10:\n    return 10.0\n  elif p == 11:\n    return 11.0\n  elif p == 12:\n    return 12.0\n  elif p == 13:\n    return 13.0\n  elif p == 14:\n    return 14.0\n  elif p == 15:\n    return 15.0\n  elif p == 16:\n    return 16.0\n  elif p == 17:\n    return 17.0\n  elif p == 18:\n    return 18.0\n  elif p == 19:\n    return 19.0\n  elif p == 20:\n    return 20.0\n  elif p == 21:\n    return 21.0\n  elif p == 22:\n    return 22.0\n  elif p == 23:\n    return 23.0\n  elif p == 24:\n    return 24.0\n  elif p == 25:\n    return 25.0\n  elif p == 26:\n    return 26.0\n  elif p == 27:\n    return 27.0\n  elif p == 28:\n    return 28.0\n  elif p == 29:\n    return 29.0\n  elif p"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == 1:\n    return 0\n  elif p == 2:\n    return 0\n  elif p == 3:\n    return 0\n  elif p == 4:\n    return 0\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  return jnp.where(\n      p < 0,\n      jnp.nan,\n      jnp.where(\n          p == 0,\n          jnp.nan,\n          jnp.where(\n              p < 2,\n              jnp.nan,\n              jnp.where(\n                  p == 2,\n                  jnp.nan,\n                  jnp.where(\n                      p < 4,\n                      jnp.nan,\n                      jnp.where(\n                          p == 4,\n                          jnp.nan,\n                          jnp.where(\n                              p < 6,\n                              jnp.nan,\n                              jnp.where(\n                                  p == 6,\n                                  jnp.nan,\n                                  jnp.where(\n                                      p < 8,\n                                      jnp.nan,\n                                      jnp.where(\n                                          p == 8,\n                                          jnp.nan,\n                                          jnp.where(\n                                              p < 10,\n                                              jnp.nan,\n                                              jnp.where(\n                                                  p == 10,\n                                                  jnp.nan,\n                                                  jnp.nan)))))))\n              ))),\n      jnp.nan))\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 2:\n    return jnp.float32(0.0)\n  elif p == 2:\n    return jnp.float32(1.0)\n  else:\n    return jnp.float32(2.0)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return 1\n  elif p < 0:\n    return 0\n  else:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 0:\n    return jnp.inf\n  elif p == 0:\n    return jnp.nan\n  elif p < 0:\n    return jnp.float32(0.0)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 1\n  elif p > 1:\n    return np.inf\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return np.inf\n  elif p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p < 0:\n    return -np.inf\n  else:\n    raise ValueError(f'Invalid value for power_ladder: {p}')\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  elif p > 1:\n    return np.inf\n  else:\n    raise ValueError(\n        f\"p must be in the range [0, 1), but got {p}.\"\n    )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  # pylint: disable=unnecessary-else-on-zero-or-one-case\n  if p > 0:\n    return jnp.inf\n  elif p < 0:\n    return jnp.nan\n  else:\n    return 1.0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  return jnp.where(\n      p > 0,\n      jnp.where(p % 2 == 0, jnp.inf, 2),\n      jnp.where(\n          p % 2 == 1, jnp.nextafter(jnp.inf, -jnp.inf), jnp.nextafter(0, -1)),\n  )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return jnp.inf\n  elif p == 0:\n    return 1.0\n  else:\n    return 0.0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 0.5:\n    return jnp.inf\n  elif p == 0.5:\n    return 1\n  elif p == 0:\n    return jnp.float32(0)\n  elif p < 0:\n    return jnp.float32(0)\n  else:\n    return 0.0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 2:\n    return 1\n  elif p == 4:\n    return 0\n  elif p > 1:\n    return -1\n  elif p < -1:\n    return 2\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 4\n  else:\n    return 5\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 2:\n    return 0\n  elif p == 2:\n    return 1\n  elif p > 2:\n    return 1 / (p - 1)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if jnp.isfinite(p):\n    return jnp.where(p > 0, max_val, min_val)\n  else:\n    return jnp.nan\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1.0:\n    return max_val\n  elif p == 1.0:\n    return 1\n  elif p == 0.0:\n    return 0\n  elif p < 0.0:\n    return min_val\n  else:\n    return 2\n\n"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape.lower() == 'tetrahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [-1, 0, 0],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [0, 1, 3],\n    ])\n  elif base_shape.lower() == 'icosahedron':\n    # https://en.wikipedia.org/wiki/Icosahedron\n    base_verts = np.array([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [-1, 0, 0],\n        [0, -1, 0],\n        [0, 0, -1],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 2],\n        [1, 2, 5],\n        [1, 5, 3],\n        [1, 3, 4],\n        [1, 4, 2],\n        [2, 3, 5],\n        [2, 4, 3],\n        [3, 4, 5],\n    ])\n  elif base_shape.lower() == 'octahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [-1, 0, 0],\n        [0, -1, 0],\n        [0, 0, -1],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        ["}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0, 0, 0],\n        [1, 1, 0],\n        [1, 0, 1],\n        [0, 1, 1]\n    ])\n    base_faces = [\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ]\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 0, -1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [0, -1, 0],\n        [0, 0, -1],\n    ])\n    base_faces = [\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 1, 4],\n        [0, 2, 3],\n        [0, 2, 4],\n        [0, 3, 4],\n        [1, 2, 3],\n        [1, 2, 4],\n        [1, 3, 4],\n        [2, 3, 4],\n    ]\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [0, 0, -1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [0, -1, 0],\n        [0, 0, -1],\n    ])\n    base_faces = [\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 4],\n        [0, 3, 4],\n        [1, 2, 3],\n        [2, 3, 4],\n    ]"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be tetrahedron, icosahedron, or octahedron')\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be an integer')\n\n  base_verts = np.array([\n      [1, 0, 0],\n      [-1, 0, 0],\n      [0, 1, 0],\n      [0, -1, 0],\n  ])\n  base_faces = [\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3],\n  ]\n\n  if base_shape == 'icosahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, 1],\n        [1, 1, -1],\n        [-1, 1, -1],\n        [-1, -1, -1],\n        [1, -1, -1],\n    ])\n    base_faces = [\n        [0, 1, 2, 3],\n        [4, 5, 6, 7],\n        [0, 1, 5, 4],\n        [1, 2, 6, 5],\n        [2, 3, 7, 6],\n        [3, 0, 4, 7],\n        [0, 4, 5, 1],\n        [1, 5, 6, 2],\n        [2, 6, 7, 3],\n        [3, 7, 4, 0],\n    ]\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    base_faces = np.array([[0, 2, 1], [0, 2, 3], [0, 1, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 1, 0],\n            [-1, 1, 0],\n            [0, -1, 0],\n            [0, 0, 1],\n            [0, 0, -1],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0.5, 0.5, 0.866],\n            [-0.5, 0.5, 0.866],\n            [0.5, -0.5, 0.866],\n            [-0.5, -0.5, 0.866],\n            [0.866, 0.5, 0.5],\n            [-0.866, 0.5, 0.5],\n            [0.866, -0.5, 0.5],\n            [-0.866, -0.5, 0.5],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [1, 2, 4],\n            [2, 3, 4],\n            [3, 0, 4],\n            [0, 4, 5],\n            [1, 4, 6],\n            [2, 4, 7],\n            [3, 4, 8],\n            [4, 5, 9],\n            [5, 6, 9],\n            [6, 7, 9],\n            [7,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    verts = np.array(\n      [\n        [1, 1, 1],\n        [-1, -1, 1],\n        [-1, 1, -1],\n        [1, -1, -1],\n      ],\n      dtype=np.float32,\n    )\n    faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 1, 3],\n        [1, 2, 3],\n      ]\n    )\n  elif base_shape == 'icosahedron':\n    verts = np.array(\n      [\n        [0.0, 0.0, 1.0],\n        [1.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0],\n        [-1.0, 0.0, 0.0],\n        [0.0, -1.0, 0.0],\n        [0.0, 0.0, -1.0],\n        [0.5, 0.5 * np.sqrt(3.0), 0.0],\n        [-0.5, 0.5 * np.sqrt(3.0), 0.0],\n        [0.5, -0.5 * np.sqrt(3.0), 0.0],\n        [-0.5, -0.5 * np.sqrt(3.0), 0.0],\n        [0.0, 0.0, 0.5 * np.sqrt(3.0)],\n        [0.0, 0.0, -0.5 * np.sqrt(3.0)],\n      ],\n      dtype=np.float32,\n    )\n    faces = np.array(\n      [\n        [0, 1, 2],\n        [0, 3, 4],\n        [0, 4, 5],\n        [1, 4, 6],\n        [1, 6, 7],"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [-1, 1, -1],\n        [1, -1, -1]\n    ])\n    base_faces = [\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 1],\n      [1, 2, 3]\n    ]\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ])\n    base_faces = [\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 5],\n      [0, 5, 1],\n      [0, 1, 2],\n      [1, 2, 4],\n      [2, 3, 4],\n      [3, 4, 5],\n      [4, 5, 1],\n      [3, 5, 2],\n      [1, 4, 3],\n    ]\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [0, 1, 0],\n        [0, -1, 0],\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ])\n    base_faces = [\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 5],\n      [0"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n          [1, 0, 0],\n          [0, 1, 0],\n          [0, 0, 1],\n          [-1, -1, -1]\n        ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [1, 3, 2],\n        [1, 0, 3],\n        [0, 2, 3],\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 0, -1],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [1, 1, 0],\n        [1, -1, 0],\n        [-1, 1, 0],\n        [-1, -1, 0],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [1, 3, 4],\n        [2, 4, 5],\n        [3, 5, 6],\n        [4, 6, 7],\n        [5, 7, 0],\n        [6, 0, 2],\n        [7, 1, 3],\n        [2, 3, 4],\n        [0, 4, 5],\n    ])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [0, 1, 0],\n        [0, -1, 0],\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        ["}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0, 1, 0],\n        [0, 0, 1],\n        [-1, 0, 0],\n        [0, -1, 0]\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [-1, 0, 0],\n        [0, -1, 0],\n        [0, 0, -1]\n    ])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 0, -1],\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0]\n    ])\n  else:\n    raise ValueError(f'unknown base_shape {base_shape}')\n\n  base_faces = np.array([\n      [0, 1, 2],\n      [3, 0, 1],\n      [4, 0, 2],\n      [2, 3, 4],\n      [1, 2, 4],\n      [1, 3, 0],\n  ])\n\n  base_verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    # Remove symmetric vertices.\n    sq_dist = compute_sq_dist(base_verts)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    base_verts = base_verts[unique, :]\n\n  return base_verts\n\n"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n            [-1, -1, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n        ]\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n            [-1, 0, 0],\n            [0, -1, 0],\n            [0, 0, -1],\n            [1, 0, 1],\n            [1, 1, 0],\n            [1, -1, 0],\n            [-1, 1, 0],\n            [-1, -1, 0],\n            [0, 1, 1],\n            [0, 1, -1],\n            [0, -1, 1],\n            [0, -1, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 9],\n            [0, 9, 5],\n            [0, 5, 1],\n            [2, 6, 3],\n            [2, 7, 6],\n            [2, 11, 7],\n            [2, 10, 11],\n            [6, 7, 4],\n            [6, 4, 5],\n            [7, 10, 9],\n            [7, 9, 8],\n            [10, 11, 8],\n            [10, 8, 11],\n        ]"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be tetrahedron, icosahedron, or octahedron'\n    )\n\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be >= 1'\n    )\n\n  # Generate a geodesic polyhedron.\n  if base_shape == 'tetrahedron':\n    # The tetrahedron is defined by 4 points.\n    base_verts = np.array([\n      [1, 0, 0],\n      [0, 1, 0],\n      [0, 0, 1],\n      [0, 0, 0]\n    ])\n    # The faces are the 6 triangles.\n    base_faces = [\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3],\n      [2, 3, 0],\n      [3, 0, 1]\n    ]\n  elif base_shape == 'icosahedron':\n    # The icosahedron is defined by 20 vertices.\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n        [1, 1, 0],\n        [1, -1, 0],\n        [-1, 1, 0],\n        [-1, -1, 0],\n        [1, 0, 1],\n        [1, 0, -1],\n        [-1, 0, 1],\n        [-1, 0, -1],\n        [0, 1, 1],\n        [0, 1, -1],\n        [0, -1, 1],\n        ["}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'The base shape must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\", got {base_shape}'\n    )\n\n  base_verts = np.array([\n    (1, 0, 0),\n    (0, 1, 0),\n    (0, 0, 1),\n    (0.5, 0.5, 0.5)\n  ])\n  base_faces = np.array([\n      [0, 1, 2],\n      [3, 0, 1],\n      [0, 2, 3],\n      [1, 3, 2]\n  ])\n\n  if base_shape == 'tetrahedron':\n    pass\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        (0, 0, 1),\n        (1, 0, 0),\n        (0, 1, 0),\n        (0, 0, -1),\n    ])\n    base_faces = np.array([\n        [0, 1, 5],\n        [0, 5, 4],\n        [0, 4, 1],\n        [0, 1, 2],\n        [0, 2, 3],\n        [1, 2, 5],\n        [2, 3, 5],\n        [3, 4, 5],\n        [4, 1, 5],\n    ])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n      (1, 0, 0),\n      (0, 1, 0),\n      (0, 0, 1),\n      (0, 0, -1),\n      (0, 1, 0),\n      (0, -1, 0)\n    ])\n    base_faces = np.array([\n        [0, 1, 4],\n        [1, 2, 4],\n        [2"}
{"namespace": "geopoly.generate_basis", "completion": "  # Check that the base shape is one of the supported shapes.\n  base_shape = base_shape.lower()\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'Unsupported base shape {base_shape}. Supported shapes are '\n        f\"'tetrahedron', 'icosahedron', and 'octahedron'.\")\n\n  # Create the base shape.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n          [0., 0., 0.],\n          [1., 0., 0.],\n          [0., 1., 0.],\n          [0., 0., 1.]\n        ],\n        dtype=np.float32\n    )\n    base_faces = np.array(\n        [[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 2, 3]]\n    )\n\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n          [0., 0., 1.],\n          [1., 0., 0.],\n          [-1., 0., 0.],\n          [0., 0., -1.],\n          [0., 1., 0.],\n          [0., -1., 0.],\n          [1., 1., 0.],\n          [-1., 1., 0.],\n          [1., -1., 0.],\n          [-1., -1., 0.],\n          [0., 1., 1.],\n          [0., 1., -1.],\n          [0., -1., 1.],\n          [0., -1., -1.]\n        ],\n        dtype=np.float32\n    )\n    base_faces = np.array(\n        [\n          [0, 1, 11],\n          [0, 5, 1],\n          [0, 9, 5],\n          [0, 4, 9],\n          [0, 11, 4],\n          [1, 5"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape.lower() == 'tetrahedron':\n    # The vertices of a regular tetrahedron are the four vertices of a cube\n    # that are at the corners of an equilateral triangle.\n    base_verts = np.array(\n      [[0, 0, 0],\n       [1, 1, 0],\n       [0, 0, 1],\n       [1, 0, 0],\n    ]\n    base_faces = [\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3],\n    ]\n    base_verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation)\n  elif base_shape.lower() == 'icosahedron':\n    # The vertices of a regular icosahedron are the 12 vertices of a cube\n    # that are on the vertices of an equilateral triangle.\n    base_verts = np.array(\n      [\n        [0, 0, 0],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [1, 1, 0],\n        [0, 1, 1],\n        [1, 0, 1],\n        [1, 1, 1],\n        [1, -1, 0],\n        [0, -1, 0],\n        [0, 0, -1],\n        [1, -1, 1],\n      ]\n    )\n    base_faces = [\n      [0, 1, 2],\n      [1, 2, 3],\n      [2, 3, 4],\n      [3, 4, 5],\n      [4, 5, 6],\n      [5, 6, 7],\n      [6, 7, 0],\n      [7, 0, 1],\n      [2, 3, 8],\n      [3, 4, 8],"}
{"namespace": "geopoly.generate_basis", "completion": "  if not (base_shape in ['tetrahedron', 'icosahedron', 'octahedron']):\n    raise ValueError(\n        f'base_shape {base_shape} is not supported')\n\n  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n\n  # Generate the base geodesic.\n  base_verts = np.array(\n      [\n          [0, 0, 1],\n          [1, 0, 0],\n          [0, 1, 0],\n          [0, 0, -1],\n      ]\n  )\n  base_faces = np.array([\n      [0, 1, 2],\n      [1, 2, 3],\n      [1, 0, 3],\n      [2, 3, 0],\n  ])\n  if base_shape == 'icosahedron':\n    base_verts = np.vstack([base_verts, base_verts])\n    base_faces = np.vstack([base_faces, base_faces + 4])\n  elif base_shape == 'octahedron':\n    base_verts = np.vstack([base_verts, base_verts + 1])\n    base_faces = np.vstack([base_faces, base_faces + 4])\n  else:\n    raise NotImplementedError(f'base_shape {base_shape} not implemented.')\n\n  # Tesselate the base geodesic.\n  base_verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation)\n\n  # Generate the basis.\n  basis = np.zeros((3, base_verts.shape[0]))\n  for i, v in enumerate(base_verts):\n    basis[:, i] = v\n\n  # Remove symmetries if requested.\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(basis.T)\n    assignment = np.array(\n        [np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    basis = basis[:, unique]"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 1, 0],\n        [1, 0, 0],\n        [-1, 0, 0]\n    ])\n    base_faces = np.array([[0, 1, 3], [1, 2, 3], [0, 2, 3], [0, 1, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 1, 1],\n        [1, 1, 0],\n        [1, 0, 1],\n        [1, 0, -1],\n        [1, 1, -1],\n        [-1, 0, -1],\n        [-1, 1, -1],\n        [-1, 1, 0],\n        [0, -1, 1],\n        [0, -1, -1],\n        [0, 0, -1]\n    ])\n    base_faces = np.array([\n        [0, 1, 5],\n        [0, 1, 6],\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 3, 1],\n        [2, 5, 6],\n        [2, 5, 7],\n        [2, 7, 4],\n        [2, 3, 7],\n        [4, 6, 8],\n        [6, 7, 8],\n        [2, 4, 8],\n    ])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 1, 0],\n        [1, 0, 0],\n        [-1, 0, 0],\n        [1, 0, 1],\n        [-1, 0, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [-1, 1, -1],\n        [1, -1, -1]\n    ])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [0, 1, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ])\n    base_faces = np.array([[0, 2, 1], [0, 4, 1], [2, 4, 3], [2, 3, 1], [3, 4, 0],\n                           [2, 3, 0], [3, 0, 1], [3, 0, 4], [3, 1, 2], [3, 2, 4], [3, 4, 1], [4, 1, 2]])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [-1, 0, 0],\n        [0, -1, 0],\n        [0, 0, -1]\n    ])\n    base_faces = np.array([[0, 2, 1], [0, 4, 1], [2, 4, 3], [2, 3, 1], [3, 4, 0], [3, 1, 0]])\n  else:\n    raise ValueError(\n        f'Invalid base"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    verts = np.array([\n      [0, 0, 1],\n      [1, 0, 0],\n      [0, 1, 0],\n      [-1, 0, 0]\n    ])\n  elif base_shape == 'icosahedron':\n    verts = np.array([\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [0, 1, -1],\n        [1, 0, -1],\n        [0, -1, 1],\n        [-1, 0, 1],\n        [-1, 0, -1],\n        [0, -1, -1],\n        [1, 1, 0],\n        [-1, 1, 0],\n        [0, 2, 0]\n    ])\n  elif base_shape == 'octahedron':\n    verts = np.array([\n        [0, 0, 1],\n        [0, 0, -1],\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ])\n  else:\n    raise ValueError(f'Unknown base_shape {base_shape}')\n\n  faces = np.array([\n      [0, 1, 2],\n      [1, 3, 0],\n      [2, 3, 0],\n      [2, 4, 5],\n      [5, 6, 2],\n      [5, 7, 6],\n      [3, 4, 7],\n      [4, 5, 7],\n      [1, 2, 6],\n      [0, 6, 1],\n      [6, 7, 3],\n      [7, 4, 3],\n  ])\n\n  # Tessellate"}
{"namespace": "geopoly.generate_basis", "completion": "  # Define the starting polyhedron.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 1, 0],\n        [1, 0, 0],\n        [-1, 0, 0],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ])\n    base_faces = base_faces.T\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, 2, 3],\n        [1, 5, 4],\n        [1, 6, 2],\n        [1, 4, 6],\n        [1, 6, 2],\n        [1, 1, 5],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 6],\n        [0, 6, 1],\n    ])\n    base_faces = base_faces.T\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [1, 1, 0],\n    ])\n    base_faces = np.array([\n        [0, 2, 3],\n        [0, 3, 1],\n        [0, 1, 2],\n        [1, 2, 3],\n    ])\n    base_faces = base_faces.T\n  else:\n    raise ValueError(f'Unsupported base_shape: {base_shape}')\n\n  # Tessellate"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0, 1, 0],\n        [1, 0, 0],\n        [0, 0, 1],\n        [0, 0, 0]\n    ])\n    base_faces = np.array([[0, 1, 2, 3], [0, 3, 1, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [1, 1, 0],\n        [-1, 1, 0],\n        [-1, -1, 0],\n        [1, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ])\n    base_faces = np.array([\n        [0, 1, 2, 3],\n        [2, 1, 5, 4],\n        [2, 1, 3, 5],\n        [3, 1, 5, 0],\n        [4, 5, 1, 2],\n        [0, 3, 2, 5],\n        [0, 5, 3, 4],\n        [0, 2, 5, 4],\n        [4, 5, 2, 1],\n        [1, 2, 3, 5],\n        [3, 4, 2, 1],\n        [0, 5, 1, 3]\n    ])\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [-1, 0, 0],\n        [0, -1, 0],\n        [0, 0, -1]\n    ])\n    base_faces = np.array([[0, 1, 3, 4], [1, 2, 4, 3], [2, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0, 0, 1],\n         [1, 0, 0],\n         [0, 1, 0],\n         [0, 0, 0]]\n    )\n    base_faces = np.array(\n        [[0, 2, 1],\n         [0, 3, 2],\n         [0, 1, 3],\n         [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [[0, 1, 0],\n         [0, -1, 0],\n         [1, 0, 0],\n         [-1, 0, 0],\n         [0, 0, 1],\n         [0, 0, -1],\n         [1, 1, 0],\n         [-1, 1, 0],\n         [-1, -1, 0],\n         [1, -1, 0]])\n    base_faces = np.array(\n        [[0, 2, 3, 6, 4],\n         [0, 5, 1, 2, 7],\n         [1, 0, 5, 6, 3],\n         [2, 1, 7, 6, 5],\n         [3, 6, 1, 4, 0],\n         [3, 2, 7, 5, 4],\n         [6, 7, 1, 0, 2],\n         [4, 2, 1, 3, 7],\n         [4, 3, 0, 5, 6],\n         [4, 5, 7, 6, 3]])\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [[0, 1, 1],\n         [0, -1, 1],\n         [0, 1, -1],\n         [0, -1, -1],"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      lambda x: jnp.log1p(x),\n      lambda _, y, x_dot: y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      lambda x: jnp.log1p(x),\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, jnp.expm1(x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.expm1(x),\n      (-np.inf, np.inf),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  def log1p_fwd(x):\n    \"\"\"\n    The forward pass of the log1p function.\n    :param x: The input value for which the natural logarithm of 1 plus x is computed.\n    :return: The result of the safe log1p operation on the input value x.\n    \"\"\"\n    return jnp.log1p(x)\n\n  def log1p_bwd(res, g):\n    \"\"\"\n    The backward pass of the log1p function.\n    :param res: The result of the safe log1p operation on the input value x.\n    :param g: The gradient of the output with respect to the input value x.\n    :return: The gradient of the safe log1p operation with respect to the input value x.\n    \"\"\"\n    return jnp.where(jnp.abs(x) < tiny_val, 0, g / res)\n\n  return jax.vjp(log1p_fwd, log1p_bwd)(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.maximum(tiny_val, x + 1),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      lambda x: jnp.log1p(x),\n      lambda x, y, x_dot: y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      lambda x: jnp.log(1 + x),\n      lambda _, y, x_dot: y * x_dot,\n      (-max_val, max_val - 1),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      lambda x: jnp.log1p(x),\n      lambda x, y, x_dot: jnp.where(x > tiny_val, y / (1 + x), x_dot),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  def safe_log1p(x):\n    \"\"\"Clamps `x` from above to be positive.\"\"\"\n    return jnp.log1p(jnp.clip(x, min_val, max_val))\n\n  def safe_log1p_jvp(primals, tangents):\n    \"\"\"Override clips()'s gradient to be a no-op.\"\"\"\n    x, = primals\n    x_dot, = tangents\n    y = safe_log1p(x)\n    y_dot = jnp.where(x < tiny_val, 0, x_dot / jnp.expm1(y))\n    return y, y_dot\n\n  return jax.custom_vjp(safe_log1p, safe_log1p_jvp)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  @jax.custom_jvp\n  def safe_log1p(x):\n    \"\"\"Clamps `x` from below to be positive.\"\"\"\n    return jax.nn.log1p(jnp.clip(x, 0, max_val))\n\n  @safe_log1p.defjvp\n  def safe_log1p_jvp(primals, tangents):\n    \"\"\"Override jnp.log1p()'s gradient to be a no-op.\"\"\"\n    return safe_log1p(primals[0]), tangents[0]\n\n  return safe_log1p(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.sqrt(jnp.maximum(tiny_val, x)),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      lambda x: jnp.log1p(x),\n      lambda _, y, x_dot: y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n\n  # Special cases for p values of 1, 0, -inf, and inf.\n  x = select(\n      [\n          (p == jnp.inf, safe_div(x, power_ladder_max_output(p))),\n          (p == 0, safe_log1p(x)),\n          (p == -jnp.inf, safe_sqrt(x)),\n          (p == 1, jnp.log(x)),\n      ],\n      x,\n  )\n\n  # Apply the power function to the transformed data.\n  x = jnp.power(x, p)\n  if postmult is not None:\n    x = postmult * x\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n  x = safe_sqrt(x)\n  x = safe_log(x)\n  x = safe_div(x, power_ladder_max_output(p))\n  x = safe_pow(x, p)\n  if postmult is not None:\n    x = postmult * x\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n\n  if p == 1:\n    return postmult * x\n  elif p == 0:\n    return postmult * jnp.log(x + 1)\n  elif p == -np.inf:\n    return postmult * jnp.log(x)\n  elif p == np.inf:\n    return postmult * jnp.log(1 + x)\n\n  if jnp.isnan(p):\n    return jnp.nan\n\n  return postmult * jnp.power(\n      1 + premult * x,\n      power_ladder_max_output(p),\n  )\n\n"}
{"namespace": "math.power_ladder", "completion": "  return select(\n      [\n          (p == 1, jnp.log(x)),\n          (p == 0, jnp.log1p(x)),\n          (p == -jnp.inf, jnp.log(jnp.abs(x))),\n          (p == jnp.inf, jnp.abs(x)),\n      ],\n      safe_pow(x, p),\n  ) * premult if premult is not None else safe_pow(x, p) * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n\n  if p == 1:\n    return jnp.log(x)\n\n  if p == 0:\n    return jnp.log(x + tiny_val)\n\n  if p < 0:\n    return jnp.where(x < 0, jnp.float32(0), jnp.power(jnp.abs(x), p))\n\n  if p > 0:\n    return jnp.power(x, p)\n\n  if p == jnp.inf:\n    return jnp.log(x)\n\n  return power_ladder_max_output(p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n  if postmult is None:\n    postmult = 1.0\n  if p == 1:\n    return postmult * x\n  elif p == 0:\n    return postmult * jnp.log(premult * x)\n  elif p == -np.inf:\n    return postmult * jnp.log(premult * power_ladder_max_output(x))\n  elif p == np.inf:\n    return postmult * jnp.log(premult * power_ladder_max_output(x))\n  else:\n    return postmult * (premult * x) ** p\n\n"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  p = jnp.asarray(p)\n\n  if premult is not None:\n    x = premult * x\n  if postmult is not None:\n    x = x * postmult\n\n  x = jnp.where(x < 0, -x, x)\n  x = jnp.where(p == jnp.inf, jnp.log(x), x)\n  x = jnp.where(p == jnp.nan, 0, x)\n  x = jnp.where(p == 0, jnp.log(jnp.abs(x)), x)\n  x = jnp.where(p == 1, jnp.log(jnp.abs(x) + 1), x)\n  x = jnp.where(p == -jnp.inf, 0, x)\n  x = jnp.where(p == -jnp.nan, 0, x)\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n  if postmult is None:\n    postmult = 1.0\n  return postmult * jnp.where(\n      p == 1,\n      x,\n      jnp.where(\n          p == 0,\n          x.log(),\n          jnp.where(\n              p == -jnp.inf,\n              jnp.log1p(x),\n              jnp.where(\n                  p == jnp.inf,\n                  x,\n                  jnp.where(\n                      x < 0,\n                      jnp.log1p(safe_div(x, power_ladder_max_output(p))),\n                      safe_div(power_ladder_max_output(p), x))),\n      ),\n  ) / premult\n\n"}
{"namespace": "math.power_ladder", "completion": "  p = jax.lax.stop_gradient(p)\n  if premult is not None:\n    x = premult * x\n  if p == 1:\n    return x\n  if p == 0:\n    return jnp.log(x)\n  if p == jnp.inf:\n    return safe_sqrt(x)\n  if p == -jnp.inf:\n    return safe_log(x)\n  return power_ladder_max_output(p) * (x ** (p - 1)) * safe_div(x, power_ladder_max_output(p)) + postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = jnp.multiply(x, premult)\n  return jnp.where(\n      jnp.abs(x) < 1,\n      jnp.power(x, p),\n      select(\n          [\n              (p == -jnp.inf, 1),\n              (p >= 0, power_ladder_max_output(p)),\n          ],\n          safe_div(p - 1, p),\n      ),\n  ) * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  x = jax.lax.stop_gradient(x)\n  if premult is not None:\n    x = jnp.where(x < 0, jnp.multiply(premult, jnp.abs(x)), x)\n\n  if p == 1:\n    return jnp.log(x)\n  elif p == 0:\n    return jnp.log(x)\n  elif p == -jnp.inf:\n    return jnp.where(x < 0, jnp.float32(0), jnp.log(jnp.abs(x)))\n  elif p == jnp.inf:\n    return jnp.where(x < 0, jnp.float32(0), jnp.log(x))\n\n  y = jnp.where(jnp.abs(x) < tiny_val, jnp.float32(0), jnp.power(x, p))\n  return jnp.where(\n      x >= 0,\n      jnp.where(y < 0, jnp.float32(0), jnp.log(y)),\n      jnp.where(y < 0, jnp.float32(0), jnp.log(jnp.abs(y)))\n\n  if postmult is not None:\n    return jnp.where(x < 0, jnp.multiply(postmult, jnp.abs(y)), y)\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n  if p == -1:\n    return safe_log(x)\n\n  if p == 0:\n    return jnp.log(jnp.abs(x))\n\n  if p == 1:\n    return x\n\n  if p == jnp.inf:\n    return power_ladder_max_output(p)\n\n  if p == -jnp.inf:\n    return power_ladder_max_output(p)\n\n  return postmult * safe_pow(x, p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  p = jax.device_array(p)\n\n  if premult is not None:\n    x = premult * x\n  x = jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n  if p == 0:\n    x = jnp.where(x < 0, -tiny_val, tiny_val)\n  elif p == 1:\n    x = jnp.log(x + tiny_val)\n  elif p < 0:\n    x = safe_div(power_ladder_max_output(p), jnp.abs(x))\n  else:\n    x = jnp.power(x, p)\n\n  if postmult is not None:\n    x = postmult * x\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n\n  # For p == -inf, the transformation is the identity.\n  if p == -jnp.inf:\n    return premult * x\n\n  # For p == 1, the transformation is the log-log-log transformation.\n  if p == 1:\n    return premult * jnp.log(safe_log(x))\n\n  # For p == 0, the transformation is the log-log transformation.\n  if p == 0:\n    return premult * jnp.log(safe_sqrt(x))\n\n  # For p == inf, the transformation is the log transformation.\n  if p == jnp.inf:\n    return premult * jnp.log(x)\n\n  # For p < 1, the transformation is the log-log-log transformation.\n  if p < 1:\n    return premult * jnp.log(safe_log(x))\n\n  # For p > 1, the transformation is the power transformation.\n  return premult * x ** (1.0 / p)\n\n  # For p == 0, the transformation is the log-log transformation.\n  if p == 0:\n    return premult * jnp.log(safe_sqrt(x))\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    x = jnp.log(x)\n  elif p == 0:\n    x = jnp.log(safe_div(1, x))\n  elif p == -np.inf:\n    x = 1\n  elif p == np.inf:\n    x = power_ladder_max_output(p)\n  else:\n    x = safe_pow(x, p)\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n  if postmult is None:\n    postmult = 1.0\n  return premult * (\n      jnp.where(\n          p == -jnp.inf, 1,\n          jnp.where(p == 0, x, jnp.where(p == 1, x, x ** (p - 1)))) * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n\n  if p == -jnp.inf:\n    return jnp.log(x)\n  elif p == 0:\n    return jnp.log1p(x)\n  elif p == 1:\n    return x\n  elif p == jnp.inf:\n    return x**p\n  else:\n    return premult * (x ** p) * power_ladder_max_output(p) * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n\n  # Apply the power ladder transformation.\n  x = premult * x\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.log(x)\n  elif p < 0:\n    return jnp.log(safe_div(x, power_ladder_max_output(p)))\n  elif p == np.inf:\n    return jnp.log(x)\n  else:\n    return x ** p\n\n  # Apply the post-multiplication.\n  if postmult is None:\n    return x\n  else:\n    return postmult * x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # We use jax.vmap to parallelize the power ladder, since it is not vectorized.\n  x = jnp.array(x)\n  p = jnp.array(p)\n\n  if premult is not None:\n    x = premult * x\n\n  # The power ladder for p=0.\n  x = jnp.log(x) if p == 0 else x\n\n  # The power ladder for p=1.\n  x = jnp.log1p(x) if p == 1 else x\n\n  # The power ladder for p=-inf.\n  x = jnp.log1p(safe_expm1(x)) if p == -np.inf else x\n\n  # The power ladder for p=inf.\n  x = safe_div(x, power_ladder_max_output(p)) if p == np.inf else x\n\n  if postmult is not None:\n    x = postmult * x\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # The Tukey power ladder is defined as:\n  #\n  #   y = x^p, if x > 0\n  #   y = -log(x) / log(x), if x <= 0\n  #\n  # The power parameter p is allowed to be any real number, but for the purposes of\n  # this function, we're only interested in the following special cases:\n  #\n  #   y = 1, if p == -inf\n  #   y = inf, if p == inf\n  #   y = x, if p == 0\n  #\n  # The default pre- and post-multipliers are 1.\n  #\n  # Note that we don't handle NaNs or zeros in this function.\n\n  # TODO(b/228838614): Add support for NaNs and zeros.\n  # TODO(b/228838614): Add support for a post-multiplication by a non-constant.\n\n  if premult is None:\n    premult = 1.0\n  if postmult is None:\n    postmult = 1.0\n\n  # The power ladder is defined for non-positive x.\n  x_is_negative = jnp.less_equal(x, 0.0)\n\n  # We compute the ladder output for non-negative x in the forward pass and\n  # non-positive x in the backward pass.\n  ladder_output = jnp.where(\n      x_is_negative,\n      jnp.negative(safe_log(x)),\n      jnp.where(jnp.is_nan(p), 1.0, x**p),\n  )\n\n  return postmult * ladder_output * premult\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ps = jnp.abs(p)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  yps = ys + 1\n  y_safe = clip_finite_nograd(remove_zero(p))\n  y = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(y_safe - 1) / y_safe * (yps ** y_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n      y = y * premult\n  yp = jnp.abs(y)\n  xs = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_ = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    y_ = y_ * postmult\n  return y_\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  y = jnp.abs(y)\n  y_safe = clip_finite_nograd(remove_zero(y))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  return select(\n      [\n          (p == 1, jnp.log(y)),\n          (p == 0, safe_log1p(-y)),\n          (p == -jnp.inf, -safe_expm1(y)),\n          (p == jnp.inf, safe_expm1(-y)),\n      ],\n      y_safe ** p_safe,\n  ) / y_safe\n  if postmult is not None:\n    return y * postmult\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_out = select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, safe_expm1(xs)),\n          (p == jnp.inf, -safe_expm1(-xs)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    y_out = y_out / postmult\n  return y_out\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ps = clip_finite_nograd(remove_zero(p))\n  xs = yp / jnp.maximum(tiny_val, jnp.abs(ps - 1))\n  y = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          safe_sign(y) * jnp.abs(ps - 1) / ps * (xs + 1) ** ps\n      ),\n  )\n  if postmult is not None:\n    y = y / postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_safe = clip_finite_nograd(ys)\n  p_safe_inv = clip_finite_nograd(1. / p_safe)\n  y_safe_inv = clip_finite_nograd(1. / y_safe)\n  x = select(\n      [\n          (p == 1, y_safe_inv),\n          (p == 0, safe_expm1(y_safe)),\n          (p == -jnp.inf, safe_expm1(-y_safe)),\n          (p == jnp.inf, safe_log1p(y_safe)),\n      ],\n      clip_finite_nograd(\n          p_safe_inv * (y_safe + 1) ** p_safe - 1\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  y_abs = jnp.abs(y)\n\n  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if p == 1:\n    y_out = y_abs\n  elif p == 0:\n    y_out = jnp.log1p(y_abs)\n  elif p == -np.inf:\n    y_out = -np.expm1(-y_abs)\n  elif p == np.inf:\n    y_out = np.expm1(y_abs)\n  else:\n    y_out = np.sign(y) * np.maximum(tiny_val, np.abs(p - 1) / p) * (\n        (y_abs / np.maximum(tiny_val, np.abs(p - 1)) + 1) ** np.maximum(tiny_val, np.abs(p)) - 1\n    )\n\n  if postmult is not None:\n    y_out = y_out * postmult\n  return y_out\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  # xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  xs = y / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, xs),\n          (p == 0, safe_log1p(xs)),\n          (p == -jnp.inf, -safe_expm1(-xs)),\n          (p == jnp.inf, safe_expm1(xs)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ps = jnp.abs(p)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(ps - 1))\n  y_safe = clip_finite_nograd(remove_zero(ps))\n  x = select(\n      [\n          (ps == 1, yp),\n          (ps == 0, safe_log1p(yp)),\n          (ps == -jnp.inf, -safe_expm1(-yp)),\n          (ps == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          safe_sign(y) * (ys + 1) ** y_safe - 1\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute -sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  y_abs = jnp.abs(y)\n  y_p = y_abs / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y_abs),\n          (p == 0, safe_exp(y_abs)),\n          (p == -jnp.inf, safe_expm1(-y_p)),\n          (p == jnp.inf, safe_log1p(-y_p)),\n      ],\n      clip_finite_nograd(\n          -jnp.sign(y) * jnp.abs(p_safe - 1) / p_safe * ((y_p + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n\n  if p == 1:\n    return y\n  elif p == 0:\n    return safe_log1p(y)\n  elif p == -np.inf:\n    return -safe_expm1(-y)\n  elif p == np.inf:\n    return safe_expm1(y)\n  else:\n    return safe_sign(y) * (\n        clip_finite_nograd(y) ** (jnp.abs(p) - 1) / jnp.abs(p)\n    )\n\n  if postmult is not None:\n    return y * postmult\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  if p == 1:\n    return y\n  if p == 0:\n    return safe_exp(y)\n  if p == -np.inf:\n    return -safe_log1p(-y)\n  if p == np.inf:\n    return safe_log1p(y)\n\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_abs = jnp.abs(y)\n\n  return select(\n      [\n          (p == 1, y),\n          (p == 0, safe_exp(y_abs)),\n          (p == -np.inf, -safe_log1p(-y_abs)),\n          (p == np.inf, safe_log1p(y_abs)),\n      ],\n      clip_finite_nograd(\n          p_safe - 1) / p_safe * (\n              (y_abs / (p_safe - 1) + 1) ** p_safe - 1)\n  )\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  if p == 1:\n    return jnp.log(y)\n  if p == 0:\n    return jnp.expm1(y)\n  if p == -jnp.inf:\n    return -safe_expm1(-y)\n  if p == jnp.inf:\n    return safe_expm1(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y_safe = clip_finite_nograd(remove_zero(y))\n  xs = jnp.abs(y_safe) / jnp.maximum(tiny_val, jnp.abs(p_safe - 1))\n  return jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** p_safe - 1) + tiny_val\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_log1p(xp)),\n          (p == -jnp.inf, -safe_expm1(-xp)),\n          (p == jnp.inf, safe_expm1(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (xs ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  y_abs = jnp.abs(y)\n  y_p = y_abs / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  y_p_safe = clip_finite_nograd(remove_zero(p))\n  y_p_safe_inv = safe_div(1, y_p_safe)\n  y_p_safe_inv_1 = safe_div(1, y_p_safe)\n  y_p_safe_1 = clip_finite_nograd(1 - y_p_safe)\n  y_p_safe_1_inv = safe_div(1, y_p_safe_1)\n  y_p_safe_1_inv_1 = safe_div(1, y_p_safe_1_inv)\n  y_safe = clip_finite_nograd(\n      jnp.where(\n          p == 1,\n          y_abs,\n          jnp.where(\n              p == 0,\n              safe_log1p(y_abs),\n              jnp.where(\n                  p == -jnp.inf,\n                  -safe_expm1(-y_abs),\n                  jnp.where(\n                      p == jnp.inf,\n                      safe_expm1(y_abs),\n                      y_p_safe_inv * (y_p_safe_inv_1 ** y_p - y_p_safe_1_inv_1))),\n      ))\n  if postmult is not None:\n    y_safe = y_safe * postmult\n  return y_safe\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  yps = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  p_safe_neg = -p_safe\n\n  # Compute (y * (p-1) + 1)^(1/p)\n  y1 = select(\n      [\n          (p == 1, yps),\n          (p == 0, safe_exp(yps)),\n          (p == -jnp.inf, safe_log1p(yps)),\n          (p == jnp.inf, safe_expm1(yps)),\n          (yps == 0, 1),\n          (yps < 0, 1),\n      ],\n      jnp.abs(p_safe) * (yps + 1) ** (1 / p_safe),\n  )\n  # Compute (y * (p-1) + 1)^(1/p) - 1\n  y2 = y1 - 1\n  # Compute y * (p-1)\n  y3 = y * p_safe_neg\n  # Compute y * (p-1) / p\n  y4 = y3 / p_safe\n  # Compute (y * (p-1) + 1)^(1/p) - 1\n  y5 = y2\n  # Compute y * (p-1) / p\n  y6 = y4\n  # Compute y * (p-1) / p\n  y7 = y6\n  # Compute y * (p-1) / p\n  y8 = y6\n  # Compute y * (p-1) / p\n  y9 = y6\n  # Compute y * (p-1) / p\n  y10 = y6\n  # Compute y * (p-1) / p\n  y11 = y6\n  # Compute y * (p-1) / p\n  y12 = y6\n  # Compute y * (p-1) / p\n  y13 = y6\n  # Compute y * (p-1) / p"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  ys = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  xp = safe_div(ys, jnp.maximum(tiny_val, jnp.abs(p_safe - 1)))\n  xs = jnp.where(p_safe == 1, xp, xp + 1)\n  x = safe_pow(xs, 1 / p_safe)\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(x) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ps = clip_finite_nograd(jnp.maximum(tiny_val, jnp.abs(p - 1)))\n  xs = yp / ps\n  p_safe = clip_finite_nograd(jnp.abs(p))\n\n  y = select(\n      [\n          (p == 0, safe_log1p(xs)),\n          (p == 1, xs),\n          (p == -jnp.inf, -safe_expm1(-xs)),\n          (p == jnp.inf, safe_expm1(xs)),\n      ],\n      clip_finite_nograd(\n          safe_sign(y) * ps / jnp.abs(p_safe - 1) * ((xs + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0 and step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  else:\n    return log_lerp(\n        jnp.maximum(0, 1 - (step - lr_delay_steps) / (max_steps - lr_delay_steps)),\n        lr_init,\n        lr_final,\n    )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  return log_lerp(\n      jnp.clip((step - lr_delay_steps) / (max_steps - lr_delay_steps), 0, 1),\n      lr_init,\n      lr_final,\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    if step < lr_delay_steps:\n      return lr_init * lr_delay_mult\n    else:\n      lr = lr_init * lr_delay_mult * jnp.exp(\n          (jnp.log(lr_delay_mult) / lr_delay_steps) * (step - lr_delay_steps)\n      )\n  else:\n    lr = lr_init\n  return jnp.clip(\n      log_lerp(\n          jnp.clip(step / max_steps, 0, 1), lr_init, lr_final\n      ),\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  assert lr_delay_steps >= 0\n  if lr_delay_steps == 0:\n    lr = jnp.where(step < max_steps, lr_init, lr_final)\n  else:\n    lr = lr_init * lr_delay_mult\n    lr = log_lerp(\n        jnp.minimum(step, lr_delay_steps) / lr_delay_steps,\n        lr_init,\n        lr_final,\n    )\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay = jnp.log(lr_delay_mult)\n  else:\n    lr_delay = 0\n\n  lr_total = lr_init * (lr_delay_mult ** step)\n  lr = log_lerp(\n      jnp.clip(step, 0, max_steps), lr_delay, lr_final - lr_delay\n  )\n\n  return lr_total + lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  return log_lerp(\n      jnp.clip(jnp.float32(step) / jnp.float32(max_steps - lr_delay_steps),\n               0, 1),\n      lr_init,\n      lr_final,\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    if step < lr_delay_steps:\n      return lr_init * lr_delay_mult\n    else:\n      return lr_init * (1 + (lr_delay_steps - step) / (max_steps - lr_delay_steps))\n  else:\n    return lr_init * (1 - step / max_steps)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay = lr_delay_steps\n    lr_delay_mult = lr_delay_mult\n  else:\n    lr_delay_mult = 1\n    lr_delay = 0\n  if lr_delay_steps < 0 or lr_delay_mult < 0:\n    raise ValueError(\n        'lr_delay_steps and lr_delay_mult must be non-negative.'\n    )\n\n  if lr_delay > 0:\n    delay_factor = jnp.exp(jnp.log(lr_delay_mult) * jnp.clip(\n        jnp.div(step, lr_delay), 0, 1))\n    lr_init = lr_init * delay_factor\n  return lr_init * log_lerp(jnp.div(step - lr_delay, max_steps - lr_delay), 1, 0)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    delay_end_step = step + lr_delay_steps\n    if step < lr_delay_steps:\n      return lr_delay_mult * lr_init\n    else:\n      delay_start_lr = lr_delay_mult * lr_init\n      delay_end_lr = lr_init\n  else:\n    delay_end_step, delay_start_lr, delay_end_lr = 1, lr_init, lr_init\n  return log_lerp(\n      jnp.clip(step - lr_delay_steps, 0, 1) / (max_steps - lr_delay_steps),\n      delay_start_lr,\n      delay_end_lr,\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  lr = jnp.where(\n      step < lr_delay_steps,\n      lr_init * lr_delay_mult,\n      lr_init * lr_delay_mult * jnp.exp(\n          jnp.log(lr_final / lr_init) * jnp.clip((step - lr_delay_steps) /\n                                                  (max_steps - lr_delay_steps), 0, 1)\n      ),\n  )\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Note: `lr_delay_mult` is not used by the math, but used by gin to make\n  # the learning rate start at the correct value.\n  if lr_delay_steps > 0:\n    if step < lr_delay_steps:\n      return lr_delay_mult * lr_init\n    else:\n      return lr_init\n  else:\n    return lr_init * (lr_final / lr_init) ** (step / max_steps)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # The first part is a helper function that implements the learning rate decay.\n  def decay_lr(\n    step, lr_init, lr_final, max_steps, lr_delay_steps, lr_delay_mult\n  ):\n    \"\"\"Calculates the learning rate for a given step.\n\n    Args:\n      step: int, the current optimization step.\n      lr_init: float, the initial learning rate at the start of optimization.\n      lr_final: float, the final learning rate to be reached at the end of optimization.\n      max_steps: int, the total number of steps in the optimization process.\n      lr_delay_steps: int, the number of steps to delay before applying the full learning rate.\n      lr_delay_mult: float, the multiplier applied to the learning rate during the delay period.\n\n    Returns:\n      float, the calculated learning rate for the current step.\n    \"\"\"\n\n    # Calculate the learning rate progression.\n    progression = (\n      jnp.clip(step, 0, max_steps) / max_steps\n      if lr_delay_steps == 0\n      else jnp.clip(step - lr_delay_steps, 0, max_steps - lr_delay_steps)\n      / max_steps\n    )\n\n    # Calculate the learning rate.\n    return (\n      lr_init * lr_delay_mult * (lr_final / lr_init) ** progression\n      if lr_delay_steps > 0\n      else lr_final * progression\n    )\n\n  # Use the helper function to calculate the learning rate for the current step.\n  return decay_lr(step, lr_init, lr_final, max_steps, lr_delay_steps, lr_delay_mult)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # If a delay is specified, scale the initial learning rate down by the delay multiplier.\n    lr_init *= lr_delay_mult\n  # Calculate the learning rate progression over the total number of steps.\n  lr_progression = jnp.linspace(lr_init, lr_final, max_steps)\n  # Calculate the learning rate for the current step based on the progression.\n  lr_step = lr_progression[step]\n  # If a delay is specified, gradually increase the learning rate back to the normal rate after the delay period.\n  if lr_delay_steps > 0:\n    lr_step = log_lerp(\n        (step - lr_delay_steps) / (max_steps - lr_delay_steps), lr_init, lr_step\n    )\n  return lr_step\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # If a delay is specified, the initial learning rate is scaled down by a multiplier and gradually returns to the normal rate after the delay period.\n    lr_delay_steps = int(lr_delay_steps)\n    lr_delay_mult = float(lr_delay_mult)\n    if step < lr_delay_steps:\n      # During the delay period, the learning rate is scaled down by the multiplier.\n      return lr_init * lr_delay_mult\n    else:\n      # After the delay period, the learning rate gradually increases back to the normal rate.\n      step_ratio = jnp.clip(\n        jnp.float32(step - lr_delay_steps) / jnp.float32(max_steps - lr_delay_steps),\n        0.0,\n        1.0,\n      )\n      lr = log_lerp(step_ratio, lr_delay_mult, 1.0)\n  else:\n    # If no delay is specified, the learning rate starts at the initial rate and decays linearly to the final rate.\n    step_ratio = jnp.clip(jnp.float32(step) / jnp.float32(max_steps), 0, 1)\n    lr = log_lerp(step_ratio, lr_init, lr_final)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_delay = jnp.clip(step, 0, lr_delay_steps)\n    lr = lr_init * lr_delay_mult * (1 - lr_delay / lr_delay_steps)\n    lr += lr_final * lr_delay / lr_delay_steps\n  else:\n    lr_delay = 0\n    lr = lr_init\n  lr = jnp.clip(lr, lr_init, lr_final)\n  lr = jnp.where(\n      jnp.isnan(lr), jnp.float32(0), lr\n  )  # jnp.clip(lr, 0, lr_final)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    if lr_delay_mult < 1.0:\n      raise ValueError(\n          'lr_delay_mult must be greater than or equal to 1 when using a delay'\n      )\n    if step < lr_delay_steps:\n      lr = lr_init * lr_delay_mult\n    else:\n      lr = lr_init * lr_delay_mult * (1 - lr_delay_mult) * (\n          jnp.exp(\n              (lr_delay_steps - lr_delay_mult)\n              / (lr_delay_steps - 1)\n              * jnp.log(lr_delay_mult)\n          )\n      )\n  else:\n    lr = lr_init\n  lr = jnp.where(step < max_steps, lr, lr_final)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Note:\n  # This function is used to calculate the learning rate for the optimizer, which is then passed to the update_state function.\n  # The learning rate is calculated using a log-linear interpolation (or exponential decay) between an initial and final learning rate over a specified number of steps.\n  # If a delay is specified, the initial learning rate is scaled down by a multiplier and gradually returns to the normal rate after the delay period.\n\n  # Calculate the number of steps in the decay period\n  decay_steps = max_steps - lr_delay_steps\n  # Calculate the log-linear decay factor\n  decay_factor = jnp.log(lr_final / lr_init) / decay_steps\n  # Calculate the learning rate for the current step\n  decay_step = jnp.clip(step, 0, decay_steps)\n  decay_rate = lr_init * jnp.exp(decay_factor * decay_step)\n  # Apply the delay factor if specified\n  if lr_delay_steps > 0:\n    delay_step = jnp.clip(step, 0, lr_delay_steps)\n    delay_rate = lr_init * lr_delay_mult\n    return jnp.where(delay_step < lr_delay_steps, delay_rate, decay_rate)\n  else:\n    return decay_rate\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # If a delay is specified, we scale down the initial rate and gradually increase it.\n    # We use a log-linear interpolation to achieve this.\n    lr_delay_steps = max(1, lr_delay_steps)\n    lr_delay_factor = log_lerp(\n        jnp.linspace(0, 1, lr_delay_steps), lr_delay_mult, 1\n    )\n    lr = lr_delay_factor * lr_init\n  else:\n    lr_delay_steps = 0\n    lr = lr_init\n\n  # Calculate the progression of steps over the total number of steps.\n  progression = jnp.linspace(\n      0, 1, max_steps + lr_delay_steps + 1\n  )\n\n  # Determine the learning rate for the current step, taking into account the delay.\n  lr = log_lerp(progression[step + lr_delay_steps], lr, lr_final)\n\n  # Clamp the learning rate to a maximum value if specified.\n  if lr_max is not None:\n    lr = jnp.clip(lr, 0, lr_max)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # This function is based on the following equation:\n  # lr = lr_final + (lr_init - lr_final) * (1 - exp(-step / max_steps))\n\n  # We use log-linear interpolation to avoid numerical issues with the exponential decay.\n  # The interpolation is between the following two points:\n  #   (0, lr_init) and (max_steps, lr_final)\n  # We also include a delay at the start of the learning rate decay, which is calculated as follows:\n  #   (delay_steps, lr_init * lr_delay_mult)\n  # The delay is gradually increased to the full lr_init value after the delay period.\n\n  # The learning rate at the end of the delay period is calculated as:\n  #   lr_final + (lr_init - lr_final) * (1 - exp(-delay_steps / max_steps))\n\n  # The learning rate at the beginning of the delay period is calculated as:\n  #   lr_final + (lr_init - lr_final) * (1 - exp(-delay_steps / max_steps)) * lr_delay_mult\n\n  # The learning rate at the current step is calculated as:\n  #   lr_final + (lr_init - lr_final) * (1 - exp(-(step - delay_steps) / max_steps))\n\n  # This is equivalent to the following equation:\n  #   lr = lr_final + (lr_init - lr_final) * (1 - exp(-step / max_steps))\n\n  # We use log-linear interpolation to avoid numerical issues with the exponential decay.\n  return log_lerp(\n      jnp.clip(step, 0, max_steps),\n      lr_final,\n      lr_init,\n      max_steps,\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Ensure that the learning rate is always positive.\n  lr_init = max_val if lr_init == 0 else lr_init\n  lr_final = max_val if lr_final == 0 else lr_final\n\n  # Calculate the learning rate progression and delay.\n  lr_progression = jnp.log(lr_final / lr_init) / max_steps\n  lr_delay = jnp.log(lr_delay_mult) / lr_delay_steps\n\n  # Apply the delay if specified.\n  if lr_delay_steps > 0:\n    lr_delay = lr_delay_mult\n  else:\n    lr_delay = 1\n\n  # Calculate the learning rate for the current step.\n  return lr_init * jnp.exp(lr_progression * (step - lr_delay_steps))\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=-1.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=1.0,\n      radius_hi=1.0,\n      near_lo=-1.0,\n      near_hi=1.0,\n      far_lo=-1.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=[0, 0, 0],\n      origin_hi=[1, 1, 1],\n      radius_lo=1.0,\n      radius_hi=1.0,\n      near_lo=0.1,\n      near_hi=1.1,\n      far_lo=0.9,\n      far_hi=1.9,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=None,\n      origin_hi=None,\n      radius_lo=None,\n      radius_hi=None,\n      near_lo=None,\n      near_hi=None,\n      far_lo=None,\n      far_hi=None,\n      include_exposure_idx = include_exposure_idx,\n      include_exposure_values = include_exposure_values,\n      include_device_idx = include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=0,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx = include_exposure_idx,\n      include_exposure_values = include_exposure_values,\n      include_device_idx = include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=None,\n      origin_hi=None,\n      radius_lo=None,\n      radius_hi=None,\n      near_lo=None,\n      near_hi=None,\n      far_lo=None,\n      far_hi=None,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=jnp.array([-1.0, 0.0, 0.0]),\n      origin_hi=jnp.array([1.0, 0.0, 0.0]),\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=0,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=0,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=100,\n      origin_lo=-10.0,\n      origin_hi=10.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.2,\n      radius_hi=0.5,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx = include_exposure_idx,\n      include_exposure_values = include_exposure_values,\n      include_device_idx = include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([0.0, 0.0, 0.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=0.1,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=np.array([-1.0, -1.0, -1.0]),\n      origin_hi=np.array([1.0, 1.0, 1.0]),\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([0.0, 0.0, 0.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=jnp.array([0.0, 0.0, 0.0]),\n      radius_hi=jnp.array([1.0, 1.0, 1.0]),\n      near_lo=jnp.array([0.0, 0.0, 0.0]),\n      near_hi=jnp.array([1.0, 1.0, 1.0]),\n      far_lo=jnp.array([0.0, 0.0, 0.0]),\n      far_hi=jnp.array([1.0, 1.0, 1.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=jnp.array([0.0]),\n      origin_hi=jnp.array([0.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([0.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([0.0]),\n      far_lo=jnp.array([0.0]),\n      far_hi=jnp.array([0.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=0,\n      origin_lo=jnp.zeros([3]),\n      origin_hi=jnp.ones([3]),\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=0,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1000,\n      origin_lo=-10,\n      origin_hi=10,\n      radius_lo=0.5,\n      radius_hi=1.5,\n      near_lo=-10,\n      near_hi=10,\n      far_lo=-10,\n      far_hi=10,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=None,\n      n=1,\n      origin_lo=jnp.array([0.0]),\n      origin_hi=jnp.array([1.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([1.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([1.0]),\n      far_lo=jnp.array([0.0]),\n      far_hi=jnp.array([1.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  n = 1024\n  rng = jax.random.PRNGKey(0)\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo=-10,\n      origin_hi=10,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=-10,\n      near_hi=10,\n      far_lo=10,\n      far_hi=20,\n      include_exposure_idx = include_exposure_idx,\n      include_exposure_values = include_exposure_values,\n      include_device_idx = include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-10.0,\n      origin_hi=10.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=-10.0,\n      near_hi=10.0,\n      far_lo=10.0,\n      far_hi=20.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1]),\n          pix_to_dir(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n          pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n      ],\n      axis=0,\n  )\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = xnp.matmul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1),\n          xnp.stack([x + 1.0, y + 0.5, xnp.ones_like(x)], axis=-1),\n          xnp.stack([x + 0.5, y + 1.0, xnp.ones_like(x)], axis=-1),\n      ],\n      axis=0,\n  )\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = xnp.matmul(\n      pixtocams, pixel_dirs_stacked\n  )\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = camera_dirs_stacked[Ellipsis, 0]\n    phi = camera_dirs_stacked[Ellipsis,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n      return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs = xnp.stack([\n      pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1]),\n      pix_to_dir(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n      pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n  ], axis=0)\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs = xnp.einsum('..., ij->ij...', pixtocams, pixel_dirs)\n  if distortion_params is not None:\n      # Correct for distortion.\n      x, y = _radial_and_tangential_undistort(\n          camera_dirs[Ellipsis, 0],\n          camera_dirs[Ellipsis, 1],\n          **distortion_params,\n          xnp=xnp,\n      )\n      camera_dirs = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n      theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs[Ellipsis, :2]), axis=-1))\n      theta = xnp.minimum(xnp.pi, theta)\n      sin_theta_over_theta = xnp.sin(theta) / theta\n      camera_dirs = xnp.stack(\n          [\n              camera_dirs[Ellipsis, 0] * sin_theta_over_theta,\n              camera_dirs[Ellipsis, 1] * sin_theta_over_theta,\n              xnp.cos(theta),\n          ],\n          axis=-1,\n      )\n\n  elif camtype == ProjectionType.PANORAMIC:\n      theta = camera_dirs["}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  pixel_dirs_stacked = xnp.stack([\n    points + 0.5,\n    points + 1.0,\n    points + 0.5,\n  ], axis=0)\n\n  # Apply inverse intrinsics matrices.\n  camera_dirs_stacked = xnp.einsum('ij,jki->ik', pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n      camera_dirs_stacked[Ellipsis, 0],\n      camera_dirs_stacked[Ellipsis, 1],\n      **distortion_params,\n      xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack([\n      camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n      camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n      xnp.cos(theta),\n    ], axis=-1)\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = camera_dirs_stacked[Ellipsis, 0]\n    phi = camera_dirs_stacked[Ellipsis, 1]\n    # Negation on y and z components accounts for expected OpenCV convention.\n    camera_dirs_stacked = xnp.stack([\n      -xnp.sin(phi) * xnp.sin(theta),\n      -xnp.cos(phi),\n      -xnp.sin(phi) * xnp.cos(theta),\n    ], axis=-1)"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need to add half pixel offset to shoot rays through pixel centers.\n  pixel_points = xnp.stack(\n      [\n          points + 0.5 * xnp.ones_like(points[Ellipsis, 0]),\n          points + 0.5 * xnp.ones_like(points[Ellipsis, 1]),\n          points + xnp.ones_like(points[Ellipsis, 2]),\n      ],\n      axis=0,\n  )\n\n  # Apply inverse intrinsic matrices.\n  camera_points = xnp.matmul(\n      pixtocams[Ellipsis, :3, :3], pixel_points\n  )\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_points[Ellipsis, 0],\n        camera_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_points = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_points[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_points = xnp.stack(\n        [\n            camera_points[Ellipsis, 0] * sin_theta_over_theta,\n            camera_points[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  camera_points = xnp.matmul(\n      camera_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Apply camera rotation matrices.\n  points = xnp.matmul(\n      camtoworlds[Ellipsis, :3, :3],"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs = xnp.stack(\n      [pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1]), pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1])],\n      axis=0)\n\n  # Apply inverse intrinsics matrices.\n  camera_dirs = xnp.matmul(pixtocams, pixel_dirs)\n\n  # Extract 2D image plane (x, y) coordinates.\n  imageplane = camera_dirs[Ellipsis, :2]\n\n  # Apply camera rotation matrices.\n  directions = xnp.matmul(camtoworlds[Ellipsis, :3, :3], camera_dirs)\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  directions = xnp.matmul(directions, xnp.diag(xnp.array([1.0, -1.0, -1.0])))\n\n  # Distance from each unit-norm direction vector to its neighbors.\n  dx_norm = xnp.linalg.norm(directions - directions[Ellipsis, 1:, :], axis=-1)\n  dy_norm = xnp.linalg.norm(directions - directions[Ellipsis, :, 1:], axis=-1)\n\n  # Cut the distance in half, multiply it to match the variance of a uniform\n  # distribution the size of a pixel (1/12, see paper).\n  radii = (0.5 * (dx_norm + dy_norm))[Ellipsis, None] * 2 / xnp.sqrt(12)\n\n  # Normalize the directions.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Apply camera intrinsics.\n  coordinates = xnp.matmul(pixtocams, directions)\n\n  # Extract the pixel coordinates.\n  coordinates = coordinates["}
{"namespace": "camera_utils.points_to_pixels", "completion": "  origins, directions, _, radii, imageplane = pixels_to_rays(\n      pix_x_int=xnp.zeros_like(points),\n      pix_y_int=xnp.zeros_like(points),\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n  # Calculate the 2D pixel coordinates and depth values.\n  coordinates = matmul(pixtocams, directions)\n  depth = xnp.linalg.norm(directions, axis=-1)\n\n  # Return the results.\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # TODO(barron): Add a unit test for this function.\n\n  # Convert points to camera coordinates.\n  camera_points = xnp.einsum('ijk,ikl->ijl', camtoworlds, points)\n\n  # Apply inverse intrinsic matrices.\n  image_points = xnp.einsum('ijk,ikl->ijl', pixtocams, camera_points)\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    image_points = undistort_points(\n        image_points,\n        distortion_params,\n        xnp=xnp,\n    )\n\n  # Convert to pixel coordinates.\n  coordinates = xnp.einsum('ijk,ikl->ijl', xnp.linalg.inv(image_points), [1, 1])\n\n  # Extract the depth values.\n  depth = xnp.linalg.norm(camera_points, axis=-1)\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsic matrices.\n  camera_points = xnp.matmul(pixtocams, points)\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_undistort(\n      camera_points[Ellipsis, 0],\n      camera_points[Ellipsis, 1],\n      **distortion_params,\n      xnp=xnp,\n    )\n    camera_points = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  camera_points = xnp.matmul(\n    camera_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Apply camera rotation matrices.\n  pixel_points = xnp.matmul(camtoworlds[Ellipsis, :3, :3], camera_points)\n\n  # Extract the pixel coordinates and depth values.\n  coordinates = pixel_points[Ellipsis, :2]\n  depth = pixel_points[Ellipsis, 2]\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points to camera coordinates.\n  camera_points = mat_vec_mul(pixtocams, points)\n  # Flip from OpenCV to OpenGL coordinate system.\n  camera_points = matmul(\n      camera_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n  # Apply camera rotation matrices.\n  world_points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], camera_points)\n\n  # Extract 2D image plane (x, y) coordinates.\n  imageplane = world_points[Ellipsis, :2]\n\n  # Extract the z-coordinate of the points.\n  depth = world_points[Ellipsis, 2]\n\n  return imageplane, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  origins, directions, _, radii, imageplane = pixels_to_rays(\n      pix_x_int=0,\n      pix_y_int=0,\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Compute the distance of the point from the camera origin.\n  depth = xnp.sqrt(xnp.sum(xnp.square(directions), axis=-1))\n\n  # Compute the pixel coordinates of the point.\n  coordinates = mat_vec_mul(pixtocams, directions)\n\n  # Compute the pixel coordinates of the point.\n  coordinates = mat_vec_mul(pixtocams, directions)\n\n  # Compute the pixel coordinates of the point.\n  coordinates = mat_vec_mul(pixtocams, directions)\n\n  # Compute the pixel coordinates of the point.\n  coordinates = mat_vec_mul(pixtocams, directions)\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the camera ray directions.\n  origins, directions, _, _ = pixels_to_rays(\n      points,\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp=xnp,\n  )\n\n  # Project the camera rays onto the image plane.\n  imageplane = xnp.matmul(origins, camtoworlds[Ellipsis, :3, :3].T)\n\n  # Compute the pixel coordinates.\n  coordinates = xnp.matmul(directions, pixtocams)\n\n  # Compute the depth values.\n  depth = xnp.linalg.norm(origins, axis=-1)\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  def points_to_rays(points):\n    \"\"\"\n    This function transforms points from world coordinates to camera coordinates using the inverse camera intrinsics. It supports vectorized operations over the leading dimensions of the input arrays and can work with either numpy or jax.numpy for computations.\n\n    Input-Output Arguments\n    :param points: float array, 3D coordinates of points to project. These are the world coordinates that need to be projected onto the 2D image plane.\n    :param pixtocams: float array, inverse of the camera intrinsics matrices. These are used to transform points from pixel coordinates to camera coordinates.\n    :param xnp: module, either numpy or jax.numpy. This parameter allows the function to be used for computations on different devices (CPU or GPU/TPU).\n    :return: A tuple containing two elements:\n             directions: float array, the camera ray directions of the input 3D points.\n             origins: float array, the camera ray origins of the input 3D points.\n    \"\"\"\n\n    # We need to add a half pixel offset to shoot rays through pixel centers.\n    pixel_dirs = xnp.stack([points + 0.5, xnp.ones_like(points)], axis=-1)\n\n    # Apply inverse intrinsic matrices.\n    camera_dirs = xnp.einsum('ijk,ij->jk', pixtocams, pixel_dirs)\n\n    # Apply camera rotation matrices.\n    directions = xnp.einsum('ijk,ij->jk', camtoworlds[Ellipsis, :3, :3], camera_dirs)\n\n    # Extract the offset rays.\n    origins = camtoworlds[Ellipsis, :3, -1]\n\n    return directions, origins\n\n  # We need to add a half pixel offset to shoot rays through pixel centers.\n  pixel_dirs = xnp.stack([points + 0.5, xnp.ones_like(points)], axis=-1)\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs = xnp.einsum('ijk,ij->jk', pixtocams, pixel_dirs)\n\n  # Apply camera rotation matrices.\n  directions, origins = points_to_rays(camera_dirs)\n\n  # Correct for distortion.\n  if distortion_params is not None"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  def points_to_dir(points):\n    # Convert points to camera coordinates.\n    cam_points = matmul(pixtocams, points[Ellipsis, :3])\n\n    # Apply camera rotation matrices.\n    cam_points = matmul(cam_points, camtoworlds[Ellipsis, :3, :3])\n    # Extract the offset rays.\n    directions, dx, dy = cam_points\n\n    # Distance from each unit-norm direction vector to its neighbors.\n    dx_norm = xnp.linalg.norm(dx - directions, axis=-1)\n    dy_norm = xnp.linalg.norm(dy - directions, axis=-1)\n\n    # Cut the distance in half, multiply it to match the variance of a\n    # uniform distribution the size of a pixel (1/12, see paper).\n    # TODO(barron): Add a unit test that this is correct.\n    radii = (0.5 * (dx_norm + dy_norm))[Ellipsis, None] * 2 / xnp.sqrt(12)\n\n    # Compute the pixel coordinates.\n    pixel_coordinates = matmul(directions, xnp.array([1, -1, 0]))\n    pixel_coordinates = pixel_coordinates / pixel_coordinates[Ellipsis, 2]\n\n    # If the image plane is at world space distance 1 from the pinhole, then\n    # pixel_coordinates will be the xy coordinates of a pixel in that space\n    # (so the camera ray direction at the origin would be (x, y, -1) in OpenGL\n    # coords).\n    imageplane = pixel_coordinates[Ellipsis, :2]\n\n    return pixel_coordinates, radii, imageplane\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_coordinates, radii, imageplane = points_to_dir(points)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        pixel_coordinates[Ellipsis, 0],\n        pixel_coordinates[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points from world coordinates to camera coordinates.\n  camera_coords = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n\n  # Convert from camera coordinates to pixel coordinates.\n  pixel_coords = mat_vec_mul(pixtocams, camera_coords)\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    pixel_coords = undistort_points(\n        pixel_coords,\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Convert from pixel coordinates to image coordinates.\n  image_coords = pixel_coords[Ellipsis, :2]\n  image_coords = image_coords - xnp.array([0.5, 0.5], xnp.float64)\n  image_coords = xnp.where(\n      xnp.isfinite(image_coords),\n      image_coords,\n      xnp.full_like(image_coords, xnp.nan),\n  )\n\n  # Compute depth values.\n  depth = xnp.sqrt(xnp.sum(camera_coords[Ellipsis, :2] ** 2, axis=-1))\n\n  return image_coords, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points from world coordinates to camera coordinates.\n  camera_coords = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n\n  # Convert camera coordinates to pixel coordinates.\n  pixel_coords = mat_vec_mul(pixtocams, camera_coords)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    pixel_coords = _radial_and_tangential_undistort(\n        pixel_coords[Ellipsis, 0],\n        pixel_coords[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  pixel_coords = matmul(\n      pixel_coords, xnp.diag(xnp.array([1.0, -1.0, 1.0]))\n  )\n\n  # Extract the 2D pixel coordinates and depth values.\n  coordinates = pixel_coords[Ellipsis, :2]\n  depth = pixel_coords[Ellipsis, -1]\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the ray directions.\n  origins, directions, _, _ = pixels_to_rays(\n      pix_x_int=None,\n      pix_y_int=None,\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      pixtocam_ndc=None,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Transform the ray origins and directions to the camera coordinate system.\n  origins = matmul(camtoworlds[Ellipsis, :3, :3], origins)\n  directions = matmul(camtoworlds[Ellipsis, :3, :3], directions)\n\n  # Compute the ray origins and directions in the camera coordinate system.\n  origins = matmul(pixtocams[Ellipsis, :3, :3], origins)\n  directions = matmul(pixtocams[Ellipsis, :3, :3], directions)\n\n  # Convert the ray directions to unit vectors.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  # Flip from OpenCV to OpenGL coordinate system.\n  directions = matmul(directions, xnp.diag(xnp.array([1.0, -1.0, -1.0])))\n\n  # Compute the pixel coordinates and depth values.\n  # The ray origins are used to compute the pixel coordinates.\n  # The ray directions are used to compute the depth values.\n  coordinates = xnp.matmul(origins, xnp.array([1.0, 0.0, 0.0]))\n  depth = xnp.matmul(directions, xnp.array([0.0, 0.0, -1.0]))\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  origins, directions, _, _, _ = pixels_to_rays(\n      points,\n      pixtocams,\n      camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n  coordinates, depths = project_to_image_plane(\n      origins, directions, camtoworlds, xnp=xnp\n  )\n  return coordinates, depths\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  origins, directions, _ = pixels_to_rays(\n    pix_x_int=xnp.zeros_like(points),\n    pix_y_int=xnp.zeros_like(points),\n    pixtocams=pixtocams,\n    camtoworlds=camtoworlds,\n    distortion_params=distortion_params,\n    camtype=camtype,\n    xnp=xnp,\n  )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  origins = xnp.stack([origins, -origins], axis=-1)\n  directions = xnp.stack([directions, -directions], axis=-1)\n\n  # Transform points to camera coordinates.\n  origins_cam = matmul(origins, camtoworlds[Ellipsis, :3, :3])\n  directions_cam = matmul(directions, camtoworlds[Ellipsis, :3, :3])\n\n  # Transform points to image plane coordinates.\n  coordinates_img = matmul(\n    directions_cam,\n    xnp.linalg.inv(pixtocams),\n  )\n  # Extract the (x, y) image plane coordinates.\n  coordinates = coordinates_img[Ellipsis, :2]\n\n  # Extract the depth values.\n  depth = coordinates_img[Ellipsis, 2]\n\n  return coordinates, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  origins, directions, viewdirs, _, _ = pixels_to_rays(\n      pix_x_int=xnp.zeros_like(points),\n      pix_y_int=xnp.zeros_like(points),\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n  viewdirs = xnp.where(viewdirs == 0, xnp.zeros_like(viewdirs), viewdirs)\n  z_values = xnp.dot(viewdirs, directions)\n  z_values = xnp.where(viewdirs == 0, xnp.ones_like(z_values), z_values)\n  z_values = xnp.where(z_values < 0, xnp.zeros_like(z_values), z_values)\n  z_values = xnp.where(z_values == 0, xnp.ones_like(z_values), z_values)\n\n  # The z_values are in camera coordinates, so we need to transform them to world coordinates.\n  # We do this by multiplying the z_values by the inverse of the camera extrinsics matrix.\n  z_values = xnp.dot(camtoworlds[Ellipsis, :3, :3], z_values)\n\n  # Now that we have the z_values in world coordinates, we can project the points onto the 2D image plane.\n  # We do this by multiplying the z_values by the inverse of the camera intrinsics matrix.\n  coordinates = xnp.dot(pixtocams, z_values)\n\n  # Finally, we need to normalize the coordinates to be between 0 and 1.\n  # We do this by dividing the coordinates by the width and height of the image.\n  coordinates /= xnp.array([xnp.shape(coordinates)[1], xnp.shape(coordinates)[2]])\n  return coordinates, z_values\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex): Add a test for this.\n  # TODO(alex"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis**2, axis=-1))\n  axis = screw_axis / theta\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(screw_axis)\n  theta_taylor = 1.0\n\n  # Prevent bad gradients from propagating back when theta is small.\n  axis_safe = jnp.where(theta**2 > eps**2, axis, 0.0)\n  theta_safe = jnp.where(theta**2 > eps**2, theta, 1.0)\n  W = skew(axis_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n\n  return jnp.where(theta**2 > eps**2, rp_to_se3(R, axis_safe * theta_safe), R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(v)\n  X_taylor = jnp.eye(4) + R_taylor\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(jnp.sum(w**2) > eps**2, w, 0.0)\n  v_safe = jnp.where(jnp.sum(v**2) > eps**2, v, 0.0)\n  W = skew(w_safe)\n  X = (\n      jnp.eye(4)\n      + jnp.sin(w_safe) * W\n      + (1.0 - jnp.cos(w_safe)) * spin_math.matmul(W, W)\n      + jnp.eye(4) * v_safe\n  )\n\n  return jnp.where(jnp.sum(w**2) > eps**2, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  R, p = se3_to_rp(screw_axis)\n  return rp_to_se3(exp_so3(R, eps), p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation from the screw axis.\n  w = jnp.reshape(screw_axis[:3], (3,))\n  v = jnp.reshape(screw_axis[3:], (3,))\n\n  # Compute the rotation matrix.\n  R = exp_so3(w, eps)\n\n  # Compute the translation.\n  p = v * _safe_sqrt(jnp.sum(w**2))\n\n  # Compute the homogeneous transformation matrix.\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation.\n  R = screw_axis[Ellipsis, :3, :3]\n  p = screw_axis[Ellipsis, :3, 3]\n\n  # Calculate the rotation.\n  w = unskew(R)\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n\n  # Compute the rotation.\n  R_safe = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * skew(w_safe)\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(skew(w_safe), skew(w_safe))\n  )\n\n  # Compute the translation.\n  p_safe = jnp.where(theta > eps, p / theta_safe, p)\n\n  # Assemble the matrix.\n  X = jnp.block([[R_safe, p_safe], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Modern Robotics Eqn 3.54.\n  # TODO(b/210965706): This is the same as `log_so3` but with an extra\n  # dimension.\n  axis_angle = screw_axis[Ellipsis, :3, 0]\n  theta = _safe_sqrt(\n      jnp.sum(axis_angle**2, axis=-1)\n  )\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(axis_angle)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  axis_angle_safe = jnp.where(theta > eps, axis_angle, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  axis = axis_angle_safe / theta_safe\n  W = skew(axis)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n\n  # Modern Robotics Eqn 3.55.\n  p = screw_axis[Ellipsis, :3, 1]\n  return jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Calculate the rotation matrix\n  w = screw_axis[0:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  R = exp_so3(jnp.where(theta > eps, w / theta, 0.0))\n\n  # Calculate the translation vector\n  p = theta * v\n\n  # Construct the homogeneous transformation matrix\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # This is the same as the exp_so3 function, except that we add a translation.\n  theta_squared = jnp.sum(screw_axis**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n  w = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  axis_angle_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_safe = axis_angle_safe / theta_safe\n\n  # Modern Robotics Eqn 3.50\n  R = exp_so3(w_safe, eps)\n\n  # Modern Robotics Eqn 3.36\n  p = (1.0 - jnp.cos(theta_safe)) * unskew(w_safe) + (\n      jnp.sin(theta_safe) * screw_axis\n  )\n\n  return jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Calculate the rotation matrix from the angle-axis vector\n  R = exp_so3(screw_axis[:3], eps)\n  # Calculate the translation vector from the translation vector\n  p = screw_axis[3:]\n  # Return the homogeneous transformation matrix\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  R, p = se3_to_rp(screw_axis)\n  return rp_to_se3(exp_so3(R, eps), p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  axis_angle = screw_axis / theta\n  R = exp_so3(axis_angle)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(screw_axis)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  theta_safe = jnp.where(theta_safe > 1.0, theta_safe, 1.0)  # prevent divide by zero\n\n  # Compute the exponential map.\n  X = jnp.eye(4)\n  X[:3, :3] = R\n  X[:3, 3] = screw_axis * theta_safe / theta\n\n  return jnp.where(theta > eps, X, R_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # TODO(jmarron): Replace this with quaternion.\n  R = exp_so3(screw_axis[:3, :3], eps)\n  p = screw_axis[3:, :3]\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Separate the rotation and translation components of the screw axis.\n  w, v = screw_axis[:3], screw_axis[3:]\n\n  # Calculate the rotation matrix.\n  R = exp_so3(w, eps)\n\n  # Calculate the translation.\n  p = R @ v\n\n  # Construct the homogeneous transformation matrix.\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # w = screw_axis[:3]\n  # v = screw_axis[3:]\n  # theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  # w = jnp.where(theta > eps, w / theta, jnp.zeros_like(w))\n  # R = exp_so3(w)\n  # p = v * theta\n  # return rp_to_se3(R, p)\n\n  # TODO: Implement this function.\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # TODO: Compute the angle of rotation.\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  # TODO: Compute the rotation matrix.\n  R = exp_so3(w)\n  # TODO: Compute the translation.\n  p = v * theta\n  # TODO: Return the homogeneous transformation.\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # TODO(hannim) - implement using quaternion\n  # https://en.wikipedia.org/wiki/Exponential_map_(Lie_algebra)\n  w, v = jnp.split(screw_axis, 3)\n  theta = _safe_sqrt(jnp.sum(w ** 2))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  v_safe = jnp.where(theta > eps, v, jnp.array([0.0, 0.0, 0.0]))\n  w_safe_norm = w_safe / _safe_sqrt(jnp.sum(w_safe ** 2))\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta) * skew(w_safe_norm)\n      + (1.0 - jnp.cos(theta)) * spin_math.matmul(skew(w_safe_norm), skew(w_safe_norm))\n  )\n  R = jnp.where(theta > eps, R, R_taylor)\n\n  return rp_to_se3(R, v_safe)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Get the rotation and translation.\n  R, p = se3_to_rp(screw_axis)\n  # Get the angle and axis of rotation.\n  w, theta = log_so3(R)\n  # Compute the exponential map from the rotation.\n  R = exp_so3(w, eps)\n  # Compute the exponential map from the translation.\n  p = p * theta\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # This is a 3x3 matrix\n  R = exp_so3(screw_axis[:3, -1], eps=eps)\n\n  # This is a 3x1 matrix\n  p = screw_axis[3:, -1]\n\n  # This is a 6x6 matrix\n  W = skew(p)\n\n  # This is a 4x3 matrix\n  T = jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n  # This is a 4x4 matrix\n  X = jnp.matmul(T, T.T)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # TODO(jcs): This function is currently not used.\n  # See https://github.com/google-research/spin/issues/12\n  # TODO(jcs): This function could be replaced by the quaternion version.\n  w, v = jnp.split(screw_axis, 3)\n\n  # TODO(jcs): These are the equations for the exponential map from the Lie\n  # algebra se3 to the Lie group SE3.\n  R = exp_so3(w, eps)\n  p = _safe_sqrt(v)\n  p = jnp.where(v > 0.0, p, v)\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # The first 3 elements of the screw axis are the axis of rotation, and the last 3\n  # are the translation.\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # The rotation part is the same as SO3.\n  R = exp_so3(w, eps)\n  p = v\n\n  # TODO(b/230951624): We should be able to use a single call to\n  #   jnp.matmul here.\n  # The translation part is the cross product of the axis of rotation and the\n  # translation.\n  p = jnp.cross(w, p)\n\n  # The final result is the concatenation of the rotation and translation.\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  w = axis_angle\n  w = jnp.where(jnp.abs(w) < eps, jnp.zeros_like(w), w)\n  w = jnp.where(jnp.any(jnp.isnan(w)), jnp.zeros_like(w), w)\n  w = jnp.where(jnp.any(jnp.isinf(w)), jnp.zeros_like(w), w)\n  w = jnp.where(jnp.any(jnp.isfinite(w)), w, jnp.zeros_like(w))\n  w = jnp.where(jnp.any(jnp.isnan(w)), jnp.zeros_like(w), w)\n  w = jnp.where(jnp.any(jnp.isinf(w)), jnp.zeros_like(w), w)\n  w = jnp.where(jnp.any(jnp.isfinite(w)), w, jnp.zeros_like(w))\n  w = jnp.where(jnp.any(jnp.isinf(w)), jnp.zeros_like(w), w)\n\n  w_skew = skew(w)\n  w_skew = jnp.where(\n      jnp.any(jnp.isnan(w_skew)), jnp.zeros_like(w_skew), w_skew)\n  w_skew = jnp.where(\n      jnp.any(jnp.isinf(w_skew)), jnp.zeros_like(w_skew), w_skew)\n  w_skew = jnp.where(jnp.any(jnp.isfinite(w_skew)), w_skew, jnp.zeros_like(w_skew))\n  w_skew = jnp.where(jnp.any(jnp.isnan(w_skew)), jnp.zeros_like(w_skew), w_skew)\n  w_skew = jnp.where(jnp.any(jnp.isinf(w_skew)), jnp.zeros_like(w_skew), w_skew"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  axis_norm = jnp.linalg.norm(axis_angle)\n  if axis_norm < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / axis_norm\n    angle = axis_norm\n    return quat_lib.axis_angle_to_rotation_matrix(axis, angle)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3, 1))\n  s = jnp.where(\n      jnp.abs(axis_angle) > eps,\n      jnp.sin(axis_angle),\n      axis_angle,\n  )\n  return jnp.array(\n      [[0.0, -axis_angle[2], axis_angle[1]],\n       [axis_angle[2], 0.0, -axis_angle[0]],\n       [-axis_angle[1], axis_angle[0], 0.0]],\n  ) @ jnp.array(\n      [[1.0, 0.0, 0.0],\n       [0.0, jnp.cos(axis_angle), -s],\n       [0.0, s, jnp.cos(axis_angle)]],\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n\n  # Compute the angle and unit axis.\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3)\n  axis = axis_angle / _safe_sqrt(theta)\n  # Compute the rotation matrix.\n  return quat_lib.rodrigues(axis, theta)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.array(axis_angle)\n  w = axis_angle[0]\n  x = axis_angle[1]\n  y = axis_angle[2]\n  theta = _safe_sqrt(jnp.square(x) + jnp.square(y) + jnp.square(w))\n  if theta < eps:\n    return quat_lib.quat_to_R(\n        jnp.array([1.0, 0.0, 0.0, 0.0]))\n\n  w_over_theta = w / theta\n  x_over_theta = x / theta\n  y_over_theta = y / theta\n\n  return jnp.array([[jnp.square(w_over_theta) - jnp.square(x_over_theta) -\n                     jnp.square(y_over_theta),\n                     2 * (x_over_theta * y_over_theta - w_over_theta),\n                     2 * (x_over_theta * w_over_theta + y_over_theta)],\n                    [2 * (y_over_theta * w_over_theta + x_over_theta),\n                     jnp.square(w_over_theta) -\n                     jnp.square(x_over_theta) - jnp.square(y_over_theta),\n                     2 * (y_over_theta * x_over_theta - w_over_theta)],\n                    [2 * (w_over_theta * x_over_theta - y_over_theta),\n                     2 * (y_over_theta * w_over_theta + x_over_theta),\n                     jnp.square(w_over_theta) - jnp.square(y_over_theta) -\n                     jnp.square(x_over_theta)]])\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  w = axis_angle / _safe_sqrt(axis_angle ** 2)\n  w = jnp.where(jnp.all(w == 0.0), jnp.ones_like(w), w)\n  return quat_lib.quat_from_axis_angle(w, axis_angle)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis = jnp.reshape(axis_angle, (3,))\n  angle = jnp.linalg.norm(axis)\n  if angle < eps:\n    return jnp.eye(3)\n  axis_over_angle = axis / angle\n  return quat_lib.exp_q(\n      jnp.where(\n          jnp.less(axis_angle, eps),\n          jnp.zeros((3, 3)),\n          jnp.block(\n              [\n                  [\n                      [0.0, -axis_over_angle[2], axis_over_angle[1]],\n                  [axis_over_angle[2], 0.0, -axis_over_angle[0]],\n                  [-axis_over_angle[1], axis_over_angle[0], 0.0],\n              ]\n          )\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  # axis_angle = jnp.array(axis_angle)\n  axis_angle = axis_angle / _safe_sqrt(jnp.dot(axis_angle, axis_angle) + eps)\n  axis_angle = axis_angle.astype(jnp.float32)\n  axis_angle = jnp.array([axis_angle[0], axis_angle[2], -axis_angle[1]], dtype=jnp.float32)\n  axis_angle = axis_angle / _safe_sqrt(jnp.dot(axis_angle, axis_angle) + eps)\n  return jnp.eye(3) + axis_angle * jnp.sin(axis_angle[0]) + jnp.matmul(\n      axis_angle,\n      jnp.matmul(axis_angle, axis_angle) * (1. - jnp.cos(axis_angle[0])))\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3]\n\n  R = quat_lib.quat_to_matrix(quat_lib.axis_angle_to_quat(axis, angle))\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n\n  # Normalize the axis of rotation.\n  norm = jnp.linalg.norm(axis_angle)\n  axis_angle = jnp.where(\n      norm < eps,\n      jnp.zeros_like(axis_angle),\n      axis_angle / norm\n  )\n\n  # Compute the rotation matrix.\n  angle = jnp.arccos(axis_angle[2])\n  cos_angle = jnp.cos(angle)\n  sin_angle = jnp.sin(angle)\n  return jnp.array(\n      [\n          [cos_angle + axis_angle[0] * axis_angle[0] * (1.0 - cos_angle),\n           axis_angle[0] * axis_angle[1] * (1.0 - cos_angle),\n           axis_angle[0] * axis_angle[2] * (1.0 - cos_angle)],\n          [axis_angle[1] * axis_angle[0] * (1.0 - cos_angle),\n           cos_angle + axis_angle[1] * axis_angle[1] * (1.0 - cos_angle),\n           axis_angle[1] * axis_angle[2] * (1.0 - cos_angle)],\n          [axis_angle[2] * axis_angle[0] * (1.0 - cos_angle),\n           axis_angle[2] * axis_angle[1] * (1.0 - cos_angle),\n           cos_angle + axis_angle[2] * axis_angle[2] * (1.0 - cos_angle)]\n      ]\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  axis = axis_angle / _safe_sqrt(axis_angle[0] ** 2 + axis_angle[1] ** 2 + axis_angle[2] ** 2)\n  axis = jnp.where(\n      jnp.abs(axis) < eps,\n      axis,\n      axis / axis_angle\n  )\n  return quat_lib.quat_to_rot_mat(\n      (jnp.cos(axis_angle), axis * jnp.sin(axis_angle))\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.array(axis_angle)\n  axis = axis_angle[:, :3]\n  angle = axis_angle[:, 3]\n  R = quat_lib.quaternion_to_matrix(quat_lib.from_axis_angle(axis, angle))\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3, 1))\n\n  # Compute the magnitude of the axis-angle.\n  axis_angle_norm = jnp.linalg.norm(axis_angle)\n  # Compute the axis of rotation.\n  axis = axis_angle / axis_angle_norm\n  # Compute the rotation matrix.\n  angle_2 = jnp.square(axis_angle_norm)\n  rotation_matrix = jnp.cos(angle_2) + axis @ axis.T\n  rotation_matrix = jnp.where(\n      axis_angle_norm < eps,\n      rotation_matrix,\n      (1 - jnp.cos(angle_2)) * axis @ axis.T + jnp.sin(angle_2) * skew(axis))\n  # Ensure the rotation matrix is orthonormal.\n  rotation_matrix = optax.l2_normalize(rotation_matrix)\n  return rotation_matrix\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  axis = axis_angle[0:3]\n  angle = axis_angle[3]\n\n  # The angle is small\n  small_angle = jnp.abs(angle) < eps\n  if jnp.any(small_angle):\n    R = jnp.where(small_angle, jnp.eye(3), quat_lib.exp(jnp.array([0, 0, 0, angle])))\n  else:\n    axis_normalized = axis / jnp.linalg.norm(axis)\n    R = quat_lib.exp(quat_lib.quat_from_axis_angle(axis_normalized, angle))\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.array(axis_angle)\n  axis_angle_norm = jnp.linalg.norm(axis_angle)\n  if axis_angle_norm < eps:\n    return jnp.eye(3)\n\n  axis_angle = axis_angle / axis_angle_norm\n  cos = jnp.cos(axis_angle_norm)\n  sin = jnp.sin(axis_angle_norm)\n\n  # Axis-angle to SO(3)\n  return jnp.array(\n      [[cos, -axis_angle[2], axis_angle[1]],\n       [axis_angle[2], cos, -axis_angle[0]],\n       [-axis_angle[1], axis_angle[0], cos]]\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  axis_angle_norm = jnp.linalg.norm(axis_angle)\n  if axis_angle_norm > eps:\n    axis_angle = axis_angle / axis_angle_norm\n  else:\n    axis_angle = jnp.zeros(3)\n  return quat_lib.quat_to_rotation_matrix(quat_lib.exp(axis_angle))\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n\n  # For numerical stability, if the angle is too small, return the identity matrix.\n  # This is the case when the axis-angle is close to zero.\n  small_angle = axis_angle.norm() < eps\n  if jnp.any(small_angle):\n    return jnp.eye(3)\n\n  # The axis is a unit vector, so we can use dot products to compute the\n  # rotation.\n  w = axis_angle / axis_angle.norm()\n  return quat_lib.exp(\n      w,\n      axis_angle.dot(axis_angle) / 2.0,\n      eps=eps)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis = axis_angle[0:3]\n  angle = axis_angle[3]\n  # Compute the rotation matrix from the axis-angle representation.\n  # This is equivalent to the following:\n  # R = jnp.cos(angle) * I +\n  #     (1 - jnp.cos(angle)) * axis * axis.T +\n  #     jnp.sin(angle) * skew(axis)\n  # However, this avoids the divide by zero and near-zero errors that can\n  # occur for small angles.\n  #\n  # We use a 3x3 matrix instead of a 4x4 matrix because the last row and\n  # column of the 3x3 matrix are the same, and so the 4x4 matrix is\n  # redundant.\n  #\n  # The 3x3 matrix is defined as follows:\n  #\n  # R = [\n  #   a_00, a_01, a_02,\n  #   a_10, a_11, a_12,\n  #   a_20, a_21, a_22\n  # ]\n  #\n  # where:\n  #\n  # a_00 = (1 - jnp.cos(angle)) * axis[0] * axis[0] + jnp.cos(angle)\n  # a_01 = (1 - jnp.cos(angle)) * axis[0] * axis[1]\n  # a_02 = (1 - jnp.cos(angle)) * axis[0] * axis[2]\n  # a_10 = (1 - jnp.cos(angle)) * axis[1] * axis[0]\n  # a_11 = (1 - jnp.cos(angle)) * axis[1] * axis[1] + jnp.cos(angle)\n  # a_12 = (1 - jnp.cos(angle)) * axis[1] * axis[2]\n  # a_20 = (1 - jnp.cos(angle)) * axis[2] * axis[0]\n  # a_21 = (1 -"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n\n  # Get the angle.\n  angle = jnp.linalg.norm(axis_angle)\n  # Check for small angle.\n  if angle < eps:\n    # If the angle is very small, the rotation is very close to the identity,\n    # so we just return the identity.\n    return jnp.eye(3)\n\n  # Get the axis.\n  axis = axis_angle / angle\n  # Rodrigues' formula\n  return jnp.eye(3) + jnp.sin(angle) * skew(axis) + (1.0 - jnp.cos(angle)) * (\n      skew(axis) @ skew(axis)\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.array(axis_angle)\n  if axis_angle.ndim == 0:\n    axis_angle = axis_angle.reshape((1, 3))\n  axis = axis_angle[:, :3]\n  angle = axis_angle[:, -1]\n\n  # TODO(b/220020266): Remove this epsilon term.\n  # The jacobian of exp_so3 is singular when axis is a multiple of the identity.\n  # This is because the rotation matrix is then the identity matrix.\n  # To avoid this, we add a small epsilon to the diagonal of the skew matrix\n  # to make it non-singular.\n  # The jacobian is then:\n  #   J(exp_so3) = (I + sin(theta) * W + (1 - cos(theta)) * W**2)\n  # The jacobian of exp_so3 is then invertible iff\n  #   det(J(exp_so3)) != 0.\n  # This is the case if\n  #   1 + sin(theta) * det(W) + (1 - cos(theta)) * det(W**2) != 0\n  # This simplifies to\n  #   sin(theta) * det(W) != 0\n  # This is the case if theta is not 0 and the axis is not parallel to the\n  # identity matrix.\n  # This is the case if and only if axis is not parallel to the identity\n  # matrix.\n  # TODO(b/220020266): This is a hack. We should refactor this function\n  # to avoid this hack.\n  W = skew(axis)\n  W = jnp.where(\n      jnp.all(axis == 0.0),\n      W + jnp.eye(3),\n      W)\n\n  # TODO(b/220020266): Remove this epsilon term.\n  # The jacobian of exp_so3 is singular when axis is a multiple of the identity.\n  # This is because the rotation matrix is then the identity matrix.\n  # To avoid this, we add a small epsilon to the diagonal of the skew"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  d_mag_sq = jnp.sum(d**2, axis=-1, keepdims=True)\n  if diag:\n    d_outer_diag = d**2\n    null_outer_diag = 1 - d_outer_diag / d_mag_sq\n    t_cov_diag = t_var * d_outer_diag\n    xy_cov_diag = r_var * null_outer_diag\n    cov_diag = t_cov_diag + xy_cov_diag\n    return d[Ellipsis, None, :] * t_mean[Ellipsis, None], cov_diag\n  else:\n    d_outer = d[Ellipsis, :, None] * d[Ellipsis, None, :]\n    eye = jnp.eye(d.shape[-1])\n    null_outer = eye - d[Ellipsis, :, None] * (d / d_mag_sq)[Ellipsis, None, :]\n    t_cov = t_var[Ellipsis, None, None] * d_outer[Ellipsis, None, :, :]\n    xy_cov = r_var[Ellipsis, None, None] * null_outer[Ellipsis, None, :, :]\n    cov = t_cov + xy_cov\n    return d[Ellipsis, :, None] * t_mean[Ellipsis, None], cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag=diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Normalize the axis of the cone.\n  d = d / jnp.linalg.norm(d)\n\n  # Calculate the mean and covariance of the Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Lift the Gaussian to 3D coordinates.\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and covariance of the Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return t_mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # TODO: This function can be optimized by using a different approximation for the Gaussian.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # We use the frustum's axis to determine its direction.\n  d = jnp.array(d)\n  d /= jnp.sqrt(jnp.sum(d**2))\n\n  # We calculate the mean and covariance of the frustum.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # We lift the frustum to 3D coordinates.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # We apply the base radius to the covariance matrix.\n  # This is done by multiplying the covariance matrix by the square of the base radius.\n  cov = cov * base_radius**2\n\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag=diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, base_radius, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # This is the Gaussian approximation of the conical frustum.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  # This is the Gaussian distribution of the cone.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # We need to scale the cone by the base radius.\n  if diag:\n    # Diagonal covariance.\n    mean *= base_radius\n    cov *= base_radius**2\n  else:\n    # Full covariance.\n    mean *= base_radius\n    cov *= base_radius**2\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # We start by calculating the mean and covariance of the frustum in the direction of the cone axis.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # We then rotate the mean and covariance matrix to account for the cone direction.\n  # This is done by using the rotation matrix for the frustum.\n  # The rotation matrix is the identity matrix (1) multiplied by the cross product of the frustum axis and the ray direction.\n  # The result is a 3x3 matrix.\n  # The mean is a 3-vector, so it is transposed to make it a 3x1 matrix.\n  # The covariance matrix is a 3x3 matrix, so it is left as is.\n  # The result is the rotated mean and covariance matrix.\n  # We then multiply the rotated covariance matrix by the frustum radius.\n  # This ensures that the covariance matrix is scaled to account for the frustum radius.\n  # The result is the final mean and covariance matrix.\n  frustum_rotation = jax.vmap(math.cross, in_axes=(0, 1))([d, d])\n  mean = jnp.tensordot(frustum_rotation, mean, axes=[(0, 0), (1, 0)])\n  cov = frustum_rotation @ cov @ frustum_rotation.T * base_radius**2\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # The mean of the Gaussian is calculated using the start and end distances of the cylinder.\n  t_mean = (t1 + t0) / 2\n  # The variance of the Gaussian is calculated using the radius of the cylinder.\n  t_var = (t1 - t0) ** 2 / 12\n  r_var = radius ** 2 / 4\n  # The mean and covariance of the Gaussian are lifted to 3D coordinates using the `lift_gaussian` function.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian distribution\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  # Multiply the radius by the base_radius to account for the scaling of the radius as a function of distance\n  r_var *= radius**2\n\n  # Use the `lift_gaussian` function to perform the actual conversion from the cylinder to a Gaussian distribution\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # Return the mean and covariance of the Gaussian distribution\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # This function approximates a cylinder as a Gaussian distribution by calculating its mean and covariance based on the cylinder's axis, start and end distances, radius, and whether the Gaussian should be diagonal or full-covariance.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Assumes the ray is originating from the origin, and radius is the radius at dist=1.\n  # Doesn't assume `d` is normalized.\n  d = d[Ellipsis, None]\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Converts a cylinder to a Gaussian distribution by calculating its mean and covariance.\n  # Assumes the ray is originating from the origin.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  # Converts the radius from a function of distance to a constant.\n  r_var *= radius**2\n  # Uses the `lift_gaussian` function to perform the actual conversion.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # This function approximates a 3D cylindrical frustum as a Gaussian distribution (mean+cov).\n  # Assumes the ray is originating from the origin, and base_radius is the\n  # radius at dist=1. Doesn't assume `d` is normalized.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # This function is used to calculate the mean and covariance of the Gaussian distribution that approximates a cylinder.\n  # It utilizes the `lift_gaussian` function to perform the conversion.\n  return lift_gaussian(d, t0, t1, radius, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculates the mean and variance of the Gaussian.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Multiplies the variance by the radius of the cylinder to account for its radius.\n  r_var *= radius**2\n\n  # Calls the `lift_gaussian` function to perform the actual conversion from a cylinder to a Gaussian.\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # This function calculates the mean and covariance of a Gaussian distribution that approximates a cylinder.\n  t_mean, t_var = gaussianize_frustum(t0, t1)\n  r_var = radius ** 2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  origins = camtoworlds @ xnp.array([pix_x_int, pix_y_int, -1])\n  directions = camtoworlds @ xnp.array([pix_x_int, pix_y_int, 0])\n  if distortion_params is not None:\n    xd, yd = xnp.meshgrid(pix_x_int, pix_y_int)\n    x, y = _radial_and_tangential_undistort(\n        xd=xd,\n        yd=yd,\n        k1=distortion_params.get('k1', 0),\n        k2=distortion_params.get('k2', 0),\n        k3=distortion_params.get('k3', 0),\n        k4=distortion_params.get('k4', 0),\n        p1=distortion_params.get('p1', 0),\n        p2=distortion_params.get('p2', 0),\n        eps=1e-9,\n        max_iterations=10,\n        xnp=xnp,\n    )\n    # x, y = xnp.meshgrid(pix_x_int, pix_y_int)\n    # xd, yd = xnp.meshgrid(x, y)\n    # xd, yd = xnp.meshgrid(pix_x_int, pix_y_int)\n    # x, y = _radial_and_tangential_undistort(\n    #     xd=xd,\n    #     yd=yd,\n    #     k1=distortion_params.get('k1', 0),\n    #     k2=distortion_params.get('k2', 0),\n    #     k3=distortion_params.get('k3', 0),\n    #     k4=distortion_params.get('k4', 0),\n    #     p1=distortion_params.get('p1', 0),\n    #     p2=distortion_params.get('p2', 0),\n    #     eps=1e-9,\n    #     max_iterations=10"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check that the inputs are of the right type.\n  xnp.testing.assert_is_numeric(pix_x_int, 'pix_x_int')\n  xnp.testing.assert_is_numeric(pix_y_int, 'pix_y_int')\n  xnp.testing.assert_is_numeric(pixtocams, 'pixtocams')\n  xnp.testing.assert_is_numeric(camtoworlds, 'camtoworlds')\n\n  # Check that the inputs are broadcastable.\n  xnp.testing.assert_broadcastable(pix_x_int, pix_y_int, 'pix_x_int', 'pix_y_int')\n  xnp.testing.assert_broadcastable(\n      pix_x_int, pixtocams, 'pix_x_int', 'pixtocams'\n  )\n  xnp.testing.assert_broadcastable(\n      pix_x_int, camtoworlds, 'pix_x_int', 'camtoworlds'\n  )\n\n  # Check that the inputs are of the right shape.\n  xnp.testing.assert_shape(\n      pix_x_int, 'pix_x_int', [None]\n  )\n  xnp.testing.assert_shape(\n      pix_y_int, 'pix_y_int', [None]\n  )\n  xnp.testing.assert_shape(pixtocams, 'pixtocams', [None, 3, 3])\n  xnp.testing.assert_shape(camtoworlds, 'camtoworlds', [None, 3, 4])\n\n  # Check that the intrinsics are invertible.\n  xnp.testing.assert_invertible(pixtocams, 'pixtocams')\n\n  # Check that the intrinsics are invertible.\n  xnp.testing.assert_invertible(pixtocams, 'pixtocams')\n\n  # Check that the intrinsics are invertible.\n  xnp.testing.assert_invertible(pixtocams, 'pixtocams')\n\n  # Check that the intrinsics are invertible.\n  xnp.testing.assert_invertible(pixtocams, 'pixtocams')"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pix_x_int = xnp.atleast_3d(pix_x_int)\n  pix_y_int = xnp.atleast_3d(pix_y_int)\n\n  pix_x = pix_x_int.astype(xnp.float32)\n  pix_y = pix_y_int.astype(xnp.float32)\n  pix_x = (pix_x - 0.5) * 2.0\n  pix_y = (pix_y - 0.5) * 2.0\n\n  # Convert pixel coordinates to camera coordinates.\n  if pixtocam_ndc is not None:\n    pix_x = xnp.einsum('...,i,ij->...', pix_x, pixtocam_ndc)\n    pix_y = xnp.einsum('...,i,ij->...', pix_y, pixtocam_ndc)\n  else:\n    pix_x = xnp.einsum('...,i,ij->...', pix_x, pixtocams)\n    pix_y = xnp.einsum('...,i,ij->...', pix_y, pixtocams)\n\n  # Correct lens distortion.\n  if distortion_params is not None:\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        xd=pix_x,\n        yd=pix_y,\n        k1=distortion_params.get('k1', 0.0),\n        k2=distortion_params.get('k2', 0.0),\n        k3=distortion_params.get('k3', 0.0),\n        k4=distortion_params.get('k4', 0.0),\n        p1=distortion_params.get('p1', 0.0),\n        p2=distortion_params.get('p2', 0.0),\n        eps=1e-8,\n        max_iterations=10,\n        xnp=xnp,\n    )\n\n  # Convert camera coordinates to world coordinates.\n  origins, directions = xnp."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pixtocams = xnp.array(pixtocams)\n  pix_x_float = xnp.float32(pix_x_int)\n  pix_y_float = xnp.float32(pix_y_int)\n  cam_x = pixtocams[0] * pix_x_float + pixtocams[1]\n  cam_y = pixtocams[2] * pix_y_float + pixtocams[3]\n  cam_z = pixtocams[4] * pix_y_float + pixtocams[5]\n\n  # Compute ray directions.\n  if camtype == ProjectionType.PANORAMIC:\n    cam_x = cam_x - 0.5\n    cam_y = cam_y - 0.5\n    cam_z = cam_z - 0.5\n  cam_x = cam_x - 0.5\n  cam_y = cam_y - 0.5\n  cam_z = cam_z - 0.5\n  cam_x = cam_x * 2.0\n  cam_y = cam_y * 2.0\n  cam_z = cam_z * 2.0\n\n  if distortion_params is not None:\n    # Correct for lens distortion.\n    xd = cam_x\n    yd = cam_y\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    k4 = distortion_params['k4']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n    xd, yd = _radial_and_tangential_undistort(\n      xd,\n      yd,\n      k1=k1,\n      k2=k2,\n      k3=k3,\n      k4=k4,\n      p1=p1,\n      p2=p2,\n    )\n    cam_x = xd\n    cam_y = yd\n\n  cam_x = cam_x / (1.0 + cam"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  pix_x = xnp.float32(pix_x_int)\n  pix_y = xnp.float32(pix_y_int)\n\n  if distortion_params is not None:\n    # undistort pixel coordinates\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        xd=pix_x,\n        yd=pix_y,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        eps=1e-9,\n        max_iterations=10,\n        xnp=xnp,\n    )\n  if pixtocam_ndc is None:\n    pixtocam_ndc = intrinsic_matrix(1.0, 1.0, 1.0, 1.0, xnp=xnp)\n\n  # transform pixel coordinates to camera coordinates\n  cam_coords = xnp.dot(pixtocams, xnp.array([pix_x, pix_y, 1.0], dtype=xnp.float32))\n\n  # transform camera coordinates to world coordinates\n  world_coords = xnp.dot(camtoworlds, cam_coords)\n\n  # compute ray directions\n  if camtype == ProjectionType.PANORAMIC:\n    # compute ray directions in the panoramic camera model\n    viewdirs = xnp.array([0.0, 0.0, 1.0], dtype=xnp.float32)\n  else:\n    # compute ray directions in the perspective camera model\n    viewdirs = xnp.array([0.0, 0.0, -1.0], dtype=xnp.float32)\n\n  # compute ray origins\n  origins = xnp.copy(world_coords)\n\n  # compute normalized view directions\n  viewdirs = xnp.copy(viewdirs)\n  viewdirs /= xnp.linalg.norm(viewdirs, axis=-1, keep"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if we have a numpy backend or a jax backend.\n  if xnp.issubclass(xnp.ndarray, jax.numpy.ndarray):\n    # JAX backend.\n    # Convert all arguments to JAX arrays.\n    pix_x_int = xnp.array(pix_x_int)\n    pix_y_int = xnp.array(pix_y_int)\n    pixtocams = xnp.array(pixtocams)\n    camtoworlds = xnp.array(camtoworlds)\n    if distortion_params is not None:\n      distortion_params = xnp.array(distortion_params)\n    if pixtocam_ndc is not None:\n      pixtocam_ndc = xnp.array(pixtocam_ndc)\n    # JAX arrays are not broadcastable, so we need to add singleton dimensions.\n    pix_x_int = pix_x_int[..., xnp.newaxis]\n    pix_y_int = pix_y_int[..., xnp.newaxis]\n    pixtocams = pixtocams[..., xnp.newaxis]\n    camtoworlds = camtoworlds[..., xnp.newaxis]\n    if distortion_params is not None:\n      distortion_params = distortion_params[..., xnp.newaxis]\n    if pixtocam_ndc is not None:\n      pixtocam_ndc = pixtocam_ndc[..., xnp.newaxis]\n  else:\n    # Numpy backend.\n    pix_x_int = xnp.array(pix_x_int)\n    pix_y_int = xnp.array(pix_y_int)\n    pixtocams = xnp.array(pixtocams)\n    camtoworlds = xnp.array(camtoworlds)\n    if distortion_params is not None:\n      distortion_params = xnp.array(distortion_params)\n    if pixtocam_ndc is not None:\n      pixtocam_ndc = xnp.array(pixtocam_ndc)\n  pix_x_int = xnp.asfortranarray(pix_x_int)\n  "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  pixtocams = xnp.array(pixtocams)\n  camtoworlds = xnp.array(camtoworlds)\n\n  # Undistort the pixel coordinates.\n  if distortion_params is not None:\n    k1, k2, k3, k4, p1, p2 = distortion_params\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        xd=pix_x_int, yd=pix_y_int, k1=k1, k2=k2, k3=k3, k4=k4, p1=p1, p2=p2,\n        eps=1e-9, max_iterations=10, xnp=xnp\n    )\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x = xnp.matmul(pixtocams, xnp.array([pix_x, pix_y, -1.0]).T)\n  cam_x = cam_x.T\n\n  # Transform camera coordinates to world coordinates.\n  world_x = xnp.matmul(camtoworlds, cam_x)\n\n  # Compute ray directions.\n  directions = world_x[:, 0:3]\n\n  # Compute ray origins.\n  origins = world_x[:, 3:]\n\n  # Compute normalized view directions.\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute ray differential radii.\n  radii = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute image plane coordinates.\n  if pixtocam_ndc is not None:\n    imageplane = xnp.matmul(pixtocam_ndc, cam_x)\n  else:\n    imageplane = cam_x\n\n  # Compute ray-specific image plane coordinates.\n  imageplane = imageplane[:, 0:2]\n\n  return origins, directions, viewdirs, radii, imageplane\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Sanity check on the input shape.\n  pix_x_int = xnp.array(pix_x_int)\n  pix_y_int = xnp.array(pix_y_int)\n  pixtocams = xnp.array(pixtocams)\n  camtoworlds = xnp.array(camtoworlds)\n\n  # Check if the input is a single camera.\n  if pix_x_int.ndim == 1 and pix_y_int.ndim == 1:\n    # If the input is a single camera, reshape the arrays to broadcastable.\n    pix_x_int = pix_x_int[Ellipsis, None]\n    pix_y_int = pix_y_int[Ellipsis, None]\n    pixtocams = pixtocams[Ellipsis, None, :]\n    camtoworlds = camtoworlds[Ellipsis, None, :]\n\n  # Check if the input is a single pixel.\n  if pix_x_int.ndim == 2 and pix_y_int.ndim == 2:\n    # If the input is a single pixel, reshape the arrays to broadcastable.\n    pix_x_int = pix_x_int[Ellipsis, None, None]\n    pix_y_int = pix_y_int[Ellipsis, None, None]\n\n  # Check if the input is a single distortion parameter.\n  if distortion_params is not None:\n    distortion_params = xnp.array(distortion_params)\n    if distortion_params.ndim == 1:\n      # If the input is a single distortion parameter, reshape the array.\n      distortion_params = distortion_params[Ellipsis, None]\n\n  # Check if the input is a single projection type.\n  if camtype is not None:\n    camtype = camtype.value\n  else:\n    camtype = ProjectionType.PERSPECTIVE.value\n\n  # Check if the input is a single normalized device coordinates matrix.\n  if pixtocam_ndc is not None:\n    pixtocam_ndc = xnp.array(pixtocam_ndc)\n\n  # Compute the undistorted pixel coordinates.\n  if distortion_params is not None"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  assert camtype is not None\n  pix_x_float = xnp.float32(pix_x_int)\n  pix_y_float = xnp.float32(pix_y_int)\n  pix_x_float = xnp.broadcast_to(pix_x_float, pix_x_float.shape + (3, 1))\n  pix_y_float = xnp.broadcast_to(pix_y_float, pix_x_float.shape + (3, 1))\n  pix_x_float = xnp.broadcast_to(pix_x_float, pix_x_float.shape + (1, 3))\n  pix_y_float = xnp.broadcast_to(pix_y_float, pix_y_float.shape + (1, 3))\n  if distortion_params is not None:\n    if camtype == ProjectionType.PERSPECTIVE:\n      # For perspective projection, undistort the pixel coordinates.\n      pix_x_float, pix_y_float = _radial_and_tangential_undistort(\n          xd=pix_x_float,\n          yd=pix_y_float,\n          k1=distortion_params['k1'],\n          k2=distortion_params['k2'],\n          k3=distortion_params['k3'],\n          k4=distortion_params['k4'],\n          p1=distortion_params['p1'],\n          p2=distortion_params['p2'],\n          eps=1e-6,\n          max_iterations=10,\n      )\n    else:\n      raise NotImplementedError(\n          f'Distortion correction is not implemented for camera type {camtype}.'\n      )\n\n  # Transform pixel coordinates to camera coordinates.\n  cam_x = pix_x_float @ pixtocams\n  cam_y = pix_y_float @ pixtocams\n\n  # Transform camera coordinates to world coordinates.\n  world_x = cam_x @ camtoworlds\n  world_y = cam_y @ camtoworlds\n\n  # Compute ray origins and directions.\n  origins = world_x\n  directions = world_"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check that the inputs have the right shape, and that the intrinsics are invertible.\n  pix_x_int = xnp.atleast_2d(pix_x_int)\n  pix_y_int = xnp.atleast_2d(pix_y_int)\n  pixtocams = xnp.atleast_3d(pixtocams)\n  camtoworlds = xnp.atleast_3d(camtoworlds)\n  assert pix_x_int.shape == pix_y_int.shape, \\\n    'pix_x_int and pix_y_int must have the same shape.'\n  assert pixtocams.shape[0] == camtoworlds.shape[0], \\\n    'pixtocams and camtoworlds must have the same first dimension.'\n  assert pixtocams.shape[1:] == camtoworlds.shape[1:], \\\n    'pixtocams and camtoworlds must have the same second dimension.'\n  assert pixtocams.shape[1] == 3, \\\n    'pixtocams must have 3 columns.'\n\n  # If distortion parameters are provided, compute the undistorted pixel coordinates.\n  if distortion_params is not None:\n    k1, k2, k3, k4, p1, p2 = distortion_params\n    pix_x_undist = xnp.where(pix_x_int >= 0, pix_x_int, -pix_x_int)\n    pix_y_undist = xnp.where(pix_y_int >= 0, pix_y_int, -pix_y_int)\n    pix_x_undist, pix_y_undist = _radial_and_tangential_undistort(\n      xd=pix_x_undist, yd=pix_y_undist, k1=k1, k2=k2, k3=k3, k4=k4, p1=p1, p2=p2, eps=1e-9, max_iterations=10, xnp=xnp\n    )\n    pix_x_int = xnp.where(pix_x_int >= 0, pix_x"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  pix_x_float = xnp.float32(pix_x_int)\n  pix_y_float = xnp.float32(pix_y_int)\n\n  if pixtocam_ndc is not None:\n    # Transform pixel coordinates to NDC space.\n    pix_x_ndc, pix_y_ndc = xnp.meshgrid(\n        pix_x_float / pixtocam_ndc[0, 0], pix_y_float / pixtocam_ndc[1, 1]\n    )\n\n  # Transform pixel coordinates to camera coordinates.\n  cam_x, cam_y = xnp.tensordot(pixtocams, [pix_x_float, pix_y_float], 1)\n  cam_z = xnp.ones_like(cam_x)\n\n  # Transform camera coordinates to world coordinates.\n  world_x, world_y, world_z = xnp.tensordot(camtoworlds, [cam_x, cam_y, cam_z], 1)\n\n  if distortion_params is not None:\n    # Correct lens distortion.\n    x, y = _radial_and_tangential_undistort(\n        xd=pix_x_float,\n        yd=pix_y_float,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n    )\n  else:\n    x, y = pix_x_float, pix_y_float\n\n  if camtype == ProjectionType.FISHEYE:\n    # Transform pixel coordinates to fisheye coordinates.\n    # Adapted from https://github.com/google/nerfies/blob/main/nerfies/camera.py\n    # We use the fisheye model with center at (0.5, 0.5) and radius 0.5.\n    # The fisheye model is given by:\n    #\n    # x"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Define the camera projection type.\n  if camtype == ProjectionType.PERSPECTIVE:\n    cam_proj = _perspective_pinhole\n    cam_proj_ndc = _perspective_pinhole_ndc\n  elif camtype == ProjectionType.FISHEYE:\n    cam_proj = _fisheye_pinhole\n    cam_proj_ndc = _fisheye_pinhole_ndc\n  elif camtype == ProjectionType.PANORAMIC:\n    cam_proj = _panoramic_pinhole\n    cam_proj_ndc = _panoramic_pinhole_ndc\n  else:\n    raise NotImplementedError('Unknown camera projection type.')\n\n  # Compute the ray origins and directions.\n  origins, directions = cam_proj(\n      xnp.array(pix_x_int), xnp.array(pix_y_int), pixtocams, camtoworlds\n  )\n\n  # Compute the ray differential radii.\n  radii = xnp.zeros_like(origins)\n\n  # Compute the image plane coordinates.\n  imageplane = cam_proj_ndc(origins, directions, pixtocam_ndc)\n\n  # Correct for lens distortion, if provided.\n  if distortion_params is not None:\n    origins, directions = _radial_and_tangential_undistort(\n        origins,\n        directions,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        eps=1e-9,\n        max_iterations=10,\n        xnp=xnp,\n    )\n\n  # Normalize the ray directions.\n  viewdirs = directions / xnp.sqrt(xnp.sum(directions**2, axis=1, keepdims=True))\n\n  return origins, directions, viewdirs, radii, imageplane\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pixtocams_inv = xnp.linalg.inv(pixtocams)\n  pix_x = xnp.reshape(pix_x_int, -1, 1)\n  pix_y = xnp.reshape(pix_y_int, -1, 1)\n  cam_x_int = pixtocams_inv[0:2, 0:2] * (pix_x + 0.5)\n  cam_y_int = pixtocams_inv[0:2, 2:] * (pix_y + 0.5)\n  cam_x = cam_x_int - 0.5\n  cam_y = cam_y_int - 0.5\n  cam_xy = xnp.stack((cam_x, cam_y), axis=1)\n\n  # Compute ray directions in camera coordinates.\n  if distortion_params is not None:\n    # Apply distortion correction to pixel coordinates.\n    cam_xy_distorted = _radial_and_tangential_undistort(\n        xd=cam_x_int,\n        yd=cam_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        eps=1e-9,\n        max_iterations=10,\n        xnp=xnp,\n    )\n\n    # Transform distorted pixel coordinates to camera coordinates.\n    cam_xy_distorted = pixtocams_inv[0:2, 0:2] * cam_xy_distorted\n\n  if camtype == ProjectionType.PANORAMIC:\n    # Compute ray directions in camera coordinates.\n    cam_xy_dir = cam_xy_distorted\n    cam_xy_origin = xnp.zeros_like(cam_xy_distorted)\n\n  elif camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray directions in camera coordinates."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if pixtocam_ndc is None:\n    # Compute intrinsics for Normalized Device Coordinates (NDC) projection.\n    # The intrinsics are used to convert ray origins and directions into NDC space.\n    fx, fy = xnp.ones_like(pixtocams[:, :, 0, 0])\n    cx, cy = xnp.zeros_like(pixtocams[:, :, 0, 0])\n    pixtocam_ndc = xnp.stack([fx, fy, cx, cy], axis=-1)\n\n  # Compute ray origins and directions.\n  origins = xnp.dot(camtoworlds, xnp.stack([pixtocams, xnp.zeros_like(pixtocams)], axis=-1))\n  directions = xnp.dot(camtoworlds, xnp.stack([pixtocams[:, :, :2, :], xnp.ones_like(pixtocams[:, :, :2, :])], axis=-1))\n\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute the ray differential radii, useful for mip-NeRF cones.\n    radii = xnp.sqrt(directions[:, :, 0, 0] ** 2 + directions[:, :, 1, 1] ** 2)\n    # Compute the image plane xy coordinates, representing the projection of pixel coordinates in world space.\n    imageplane = xnp.stack(\n      [\n        xnp.dot(pixtocam_ndc[:, :, 0, 0], directions),\n        xnp.dot(pixtocam_ndc[:, :, 1, 1], directions),\n      ],\n      axis=-1,\n    )\n  else:\n    # Compute the ray differential radii, useful for mip-NeRF cones.\n    radii = xnp.sqrt(directions[:, :, 0, 0] ** 2 + directions[:, :, 1, 1] ** 2)\n    # Compute the image plane xy coordinates, representing the projection of pixel coordinates in world space.\n    imageplane = xnp.stack(\n      [\n        xnp.dot(pixtocam_ndc[:, :, 0, 0], directions),\n        xnp.dot(pixtocam_ndc[:, :,"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  origins = xnp.zeros_like(pix_x_int)\n  directions = xnp.zeros_like(pix_x_int)\n\n  if distortion_params is not None:\n    # Correct lens distortion.\n    # TODO: implement fisheye correction.\n    if camtype == ProjectionType.FISHEYE:\n      raise ValueError('fisheye distortion correction not implemented')\n    else:\n      x, y = _radial_and_tangential_undistort(\n          xd=pix_x_int,\n          yd=pix_y_int,\n          k1=distortion_params['k1'],\n          k2=distortion_params['k2'],\n          p1=distortion_params['p1'],\n          p2=distortion_params['p2'],\n          eps=1e-9,\n          max_iterations=10,\n          xnp=xnp,\n      )\n\n  else:\n    # No distortion correction.\n    x = pix_x_int\n    y = pix_y_int\n\n  if pixtocam_ndc is not None:\n    # Convert to NDC.\n    x_ndc = xnp.dot(xnp.eye(3) + pixtocam_ndc, x)\n    y_ndc = xnp.dot(xnp.eye(3) + pixtocam_ndc, y)\n  else:\n    # No conversion to NDC.\n    x_ndc = x\n    y_ndc = y\n\n  # Compute ray directions.\n  directions_ndc = xnp.array([[-y_ndc, x_ndc], [-x_ndc, y_ndc]])\n\n  if camtype == ProjectionType.PERSPECTIVE:\n    # For perspective cameras, the ray origin is the camera center.\n    origins_ndc = xnp.zeros_like(pix_x_int)\n  elif camtype == ProjectionType.FISHEYE:\n    # For fisheye cameras, the ray origin is the camera center.\n    origins_ndc = xnp.zeros_like(pix_x_int)\n  elif camtype == ProjectionType.PANORAMIC:"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get the number of cameras.\n  num_cams = camtoworlds.shape[0]\n\n  # Compute ray origins and directions.\n  if distortion_params is not None:\n    # If distortion params are provided, undistort the pixel coordinates.\n    if pixtocam_ndc is None:\n      # If no pixtocam_ndc is provided, use the undistorted pixel coordinates.\n      pix_x = pix_x_int\n      pix_y = pix_y_int\n    else:\n      # Otherwise, compute the undistorted pixel coordinates.\n      pix_x, pix_y = _radial_and_tangential_undistort(\n          xd=pix_x_int,\n          yd=pix_y_int,\n          k1=distortion_params['k1'],\n          k2=distortion_params['k2'],\n          k3=distortion_params['k3'],\n          k4=distortion_params['k4'],\n          p1=distortion_params['p1'],\n          p2=distortion_params['p2'],\n      )\n\n  # Transform pixel coordinates to camera coordinates.\n  pix_x = pix_x.reshape(num_cams, -1)\n  pix_y = pix_y.reshape(num_cams, -1)\n  pixtocams = pixtocams.reshape(num_cams, -1, 3, 3)\n  cam_x = xnp.dot(pixtocams, [pix_x, pix_y, xnp.ones_like(pix_x)])\n  cam_x = cam_x.reshape(-1, 3)\n\n  # Transform camera coordinates to world coordinates.\n  cam_x = xnp.dot(camtoworlds, cam_x)\n\n  # Compute ray directions.\n  # If the camera is fisheye, the ray direction is given by the pixel coordinates.\n  if camtype == ProjectionType.FISHEYE:\n    cam_x = cam_x.reshape(num_cams, -1, 3)\n    directions = cam_x\n\n  # If the camera is panoramic, the ray direction is given by the pixel coordinates.\n  elif camtype =="}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check for valid input types and shapes.\n  if pix_x_int.shape != pix_y_int.shape:\n    raise ValueError(\n        'pixel coordinates must have the same shape: '\n        f'{pix_x_int.shape} != {pix_y_int.shape}'\n    )\n\n  pix_x_int, pix_y_int, camtoworlds, pixtocams = (\n      xnp.atleast_3d(pix_x_int),\n      xnp.atleast_3d(pix_y_int),\n      xnp.atleast_3d(camtoworlds),\n      xnp.atleast_3d(pixtocams),\n  )\n  pixtocams = xnp.swapaxes(pixtocams, -1, 1)\n\n  # Convert pixel coordinates to camera coordinates.\n  pix_x = xnp.expand_dims(pix_x_int, -1)\n  pix_y = xnp.expand_dims(pix_y_int, -1)\n  pix_coords = xnp.concatenate([pix_x, pix_y], axis=-1)\n  cam_coords = xnp.matmul(pixtocams, pix_coords)\n  cam_coords = xnp.swapaxes(cam_coords, -1, 1)\n\n  # Compute ray directions.\n  directions = xnp.matmul(camtoworlds, cam_coords)\n  directions = xnp.swapaxes(directions, -1, 1)\n\n  # Compute ray origins.\n  origins = xnp.zeros_like(directions)\n  origins[:, 0, 3] = 1.0\n\n  # Normalize directions.\n  viewdirs = xnp.copy(directions)\n  viewdirs = xnp.where(viewdirs == 0, 0.0, viewdirs)\n  viewdirs = viewdirs / xnp.linalg.norm(viewdirs, axis=-1, keepdims=True)\n\n  # Compute ray differential radii.\n  radii = xnp.zeros_like(directions)\n  radii[:, 0, 0] = 1.0\n\n  # Compute image plane coordinates."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert to float32 for numpy or float64 for jax.numpy.\n  pix_x_int = xnp.asarray(pix_x_int, dtype=xnp.float32)\n  pix_y_int = xnp.asarray(pix_y_int, dtype=xnp.float32)\n\n  # If distortion_params is not None, use undistorted pixel coordinates.\n  if distortion_params is not None:\n    pix_x_int, pix_y_int = _radial_and_tangential_undistort(\n      pix_x_int,\n      pix_y_int,\n      distortion_params,\n      eps=1e-4,\n      xnp=xnp,\n    )\n\n  # Compute the ray origin and direction.\n  origins = xnp.matmul(pixtocams, xnp.array([[pix_x_int], [pix_y_int], [1]]))\n  directions = xnp.matmul(camtoworlds, xnp.array([[0], [0], [1]]))\n\n  # Compute the normalized view direction.\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = xnp.divide(directions, viewdirs)\n  directions = xnp.where(viewdirs > 0, directions, -directions)\n\n  # Compute the ray differential radius.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute the ray differential radius.\n    radii = xnp.zeros_like(origins)\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute the ray differential radius.\n    radii = xnp.zeros_like(origins)\n  elif camtype == ProjectionType.PANORAMIC:\n    # Compute the ray differential radius.\n    radii = xnp.zeros_like(origins)\n\n  # Compute the image plane xy coordinates.\n  imageplane = xnp.matmul(pixtocam_ndc, xnp.array([[pix_x_int], [pix_y_int], [1]]))\n\n  return origins, directions, viewdirs, radii, imageplane\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  def _compute_origin_direction(\n      pix_x_int,\n      pix_y_int,\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      pixtocam_ndc,\n      camtype,\n      xnp,\n  ):\n    \"\"\"Computes ray origins and directions given pixel coordinates and camera params.\"\"\"\n\n    # Compute the undistorted pixel coordinates.\n    if distortion_params is not None:\n      pix_x, pix_y = _radial_and_tangential_undistort(\n          pix_x=pix_x_int,\n          pix_y=pix_y_int,\n          k1=distortion_params[0],\n          k2=distortion_params[1],\n          p1=distortion_params[2],\n          p2=distortion_params[3],\n          eps=1e-9,\n      )\n    else:\n      pix_x = xnp.copy(pix_x_int)\n      pix_y = xnp.copy(pix_y_int)\n\n    # Transform pixel coordinates to camera coordinates.\n    pix_x = xnp.dot(pix_x, pixtocams)\n    pix_y = xnp.dot(pix_y, pixtocams)\n    pix_z = xnp.ones_like(pix_x)\n\n    # Transform camera coordinates to world coordinates.\n    world_pos = xnp.dot(xnp.dstack((pix_x, pix_y, pix_z)), camtoworlds)\n\n    # Compute the ray directions.\n    if camtype == ProjectionType.FISHEYE:\n      # Compute ray directions for fisheye cameras.\n      # The fisheye camera is centered at the origin, so its camera-space\n      # coordinates are (0, 0, 0) and the ray directions are simply (x, y, -1).\n      ray_dirs = xnp.dstack((pix_x, pix_y, -xnp.ones_like(pix_x)))\n    elif camtype == ProjectionType.PANORAMIC:\n      # Compute ray directions for panoramic cameras.\n      # The panoramic camera is centered at"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute ray directions.\n  ray_dirs = xnp.einsum('i,ij->i', pix_x_int, camtoworlds[Ellipsis, :3, :3])\n  ray_dirs = xnp.einsum('i,ij->i', pix_y_int, camtoworlds[Ellipsis, :3, :3])\n  if camtype == ProjectionType.PERSPECTIVE:\n    ray_dirs = xnp.einsum('i,ij->i', -1.0, ray_dirs)\n  elif camtype == ProjectionType.FISHEYE:\n    # Convert rays to fisheye coordinates.\n    # https://www.cs.cmu.edu/~rjmh/notes/notes-15.html#id1\n    # https://github.com/google/nerfies/blob/main/nerfies/camera.py\n    # https://github.com/google/nerfies/blob/main/nerfies/camera.py#L54\n    # https://www.cs.cornell.edu/s/1995/04/01/3d_camera_model.pdf\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L104\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L83\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L49\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L44\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L28\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L20\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L12\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L10\n    # https://github.com/google/nerf/blob/main/nerf/camera.py#L8\n    # https://github"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.abs(jnp.linalg.norm(dirs, axis=-1))\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1)\n  weights = compute_alpha_weights_helper(density_delta)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the product of density and the adjusted distance between points.\n  density_delta = density * jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute alpha compositing weights.\n  density_delta = density * jnp.linalg.norm(dirs, axis=-1)\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # TODO(jbailey): Add support for non-diagonal covariances.\n  # TODO(jbailey): Add support for non-normalized directions.\n  density_delta = -density * tdist\n  return compute_alpha_weights_helper(density_delta)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  if not jnp.ndim(tdist) == 2:\n      raise ValueError('tdist must be 2-D')\n  if not jnp.ndim(dirs) == 2:\n      raise ValueError('dirs must be 2-D')\n\n  if jnp.ndim(tdist) == 2:\n    tdist = jnp.expand_dims(tdist, axis=1)  # NxDxD\n  if jnp.ndim(dirs) == 2:\n    dirs = jnp.expand_dims(dirs, axis=1)  # NxDxD\n\n  density_delta = jnp.expand_dims(density, axis=-3)  # NxDxD\n  density_delta = jnp.concatenate([density_delta, jnp.zeros_like(density_delta)], axis=-1)\n  density_delta = density_delta * dirs\n\n  weights = compute_alpha_weights_helper(density_delta)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1)\n  weights = compute_alpha_weights_helper(density_delta)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  return compute_alpha_weights_helper(\n    density * tdist,\n    tdist,\n    dirs,\n    **kwargs,\n  )\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  weights = compute_alpha_weights_helper(density_delta)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the adjusted distance between points.\n  # TODO(eustace): This should be done in a vectorized way, but that's tricky\n  # since the first point is at zero distance.\n  delta_tdist = jnp.concatenate(\n      [\n          jnp.zeros_like(tdist[Ellipsis, :1]),\n          jnp.diff(tdist[Ellipsis, :], axis=-1),\n      ],\n      axis=-1,\n  )\n  # Compute the alpha compositing weights.\n  # TODO(eustace): This should be done in a vectorized way.\n  density_delta = density * delta_tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  weights = compute_alpha_weights_helper(density_delta)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.abs(dirs)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the distance between points along the ray\n  # TODO(xcheng): This should be the distance between points along the ray, not the\n  # distance between the points in the input.\n  tdist = tdist[Ellipsis, :]\n\n  # Compute the adjusted distance between points along the ray\n  # TODO(xcheng): This should be the distance between points along the ray, not the\n  # distance between the points in the input.\n  dirs = dirs[Ellipsis, :]\n  dirs_norm = jnp.linalg.norm(dirs, axis=-1)\n  dirs_norm_inv = jnp.where(dirs_norm > 0, dirs_norm**-1, 0)\n  tdist_adjusted = dirs_norm_inv[Ellipsis, :] * tdist[Ellipsis, :]\n\n  # Compute the product of the density and the adjusted distance between points along the ray\n  density_delta = density[Ellipsis, :] * tdist_adjusted\n\n  # Compute the alpha weights\n  weights = compute_alpha_weights_helper(density_delta)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # TODO(b/205607558): remove the following line once the density is updated to use the new implementation\n  density = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(density)\n\n  # Compute the distance between points along the ray.\n  tdist = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(tdist)\n  tdist = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(tdist)\n  tdist = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(tdist)\n\n  # Compute the density-adjusted distance between points along the ray.\n  density_delta = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(density)\n  density_delta = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(density_delta)\n  density_delta = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(density_delta)\n\n  density_delta = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(density_delta)\n\n  # Compute the alpha compositing weights based on the density-adjusted distance between points.\n  # TODO(b/205607558): remove the following line once the density is updated to use the new implementation\n  alpha = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(alpha)\n  alpha = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(alpha)\n  alpha = jax.vmap(jnp.at_least_2d, in_axes=(0, 0))(alpha)\n\n  # Compute the alpha compositing weights based on the density-adjusted distance between points.\n  # TODO(b/205607558): remove the following line once the"}
{"namespace": "render.compute_alpha_weights", "completion": "  return compute_alpha_weights_helper(\n      jnp.log(density) * tdist, dirs, **kwargs)\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  u = jax.random.uniform(rng, cw.shape, minval=0, maxval=1)\n  if single_jitter:\n    u = jax.lax.stop_gradient(jnp.full(u.shape, u.mean()))\n    u = jax.random.uniform(rng, u.shape)\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  # Apply deterministic center behavior.\n  t_new = math.select([(deterministic_center, t_new + eps), (not deterministic_center, t_new)], t_new)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate samples.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      t_new = math.linspline.lin_interp(cw, t, 0.5, utils.device_is_tpu())\n    else:\n      t_new = math.linspline.lin_interp(cw, t, jnp.linspace(0, 1, num_samples),\n                                        utils.device_is_tpu())\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,))\n    if single_jitter:\n      u = u + eps * (1 - jnp.abs(u))\n    t_new = invert_cdf(u, t, w_logits)\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  if rng is None:\n    t_new = linspline.lin_interp(cw, t, num_samples, deterministic_center)\n  else:\n    u = jax.random.uniform(rng, cw.shape[:-1], (num_samples, ), (0, 1))\n    t_new = invert_cdf(u, t, w_logits)\n  # Jitter the samples.\n  if single_jitter:\n    jitter_value = jax.random.uniform(rng, (num_samples,), eps)\n  else:\n    jitter_value = jax.random.uniform(rng, (num_samples, cw.shape[-1]), eps)\n    jitter_value = jitter_value.at[Ellipsis, 0].set_subtensor(0)\n  t_new = t_new + jitter_value\n  return t_new"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  # Compute the PDF and CDF for each weight vector.\n  cw = integrate_weights(w)\n  u = jax.random.uniform(rng, cw.shape, minval=eps, maxval=1 - eps)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Sample from the PDF.\n  if deterministic_center:\n    # Sample the centers of each bin.\n    t_new = t_new[..., :-1] + jnp.diff(t_new, axis=-1) / 2\n  elif single_jitter:\n    # Sample from a uniform distribution with the same width as each bin.\n    t_new = t_new[..., :-1] + jax.random.uniform(rng, t_new.shape, minval=-eps, maxval=eps)\n  else:\n    # Sample from a uniform distribution with the width of each bin.\n    t_new = t_new[..., :-1] + jax.random.uniform(rng, t_new.shape, minval=-eps, maxval=eps, dtype=t_new.dtype)\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  if deterministic_center:\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(\n        jnp.linspace(0, 1, num_samples, dtype=w.dtype), cw, t,\n        utils.device_is_tpu())\n  else:\n    # Compute the PDF and CDF for each weight vector.\n    w_pdf = weight_to_pdf(t, w)\n    # Sample from the PDF.\n    u = jax.random.uniform(rng, w_pdf.shape, minval=eps, maxval=1 - eps)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  if single_jitter:\n    t_new = t_new + jax.random.uniform(rng, t_new.shape, minval=-eps,\n                                       maxval=eps)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Generate samples.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample uniformly from the center of each interval.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n      u = u[..., None]\n    else:\n      # Sample uniformly from the entire interval.\n      u = jnp.random.uniform(rng, (num_samples,) + u.shape, low=eps, high=1 - eps)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Random sampling.\n    u = jnp.random.uniform(rng, (num_samples,) + u.shape, low=eps, high=1 - eps)\n    if single_jitter:\n      # Use the same jitter for all samples.\n      jitter = jnp.random.uniform(rng, shape=t_new.shape, low=-eps, high=eps)\n      t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu()) + jitter\n    else:\n      # Use independent jitters for each sample.\n      jitter = jnp.random.uniform(rng, shape=t_new.shape, low=-eps, high=eps)\n      t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu()) + jitter\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      t_new = t[..., 1:] + eps\n    else:\n      t_new = t[..., :-1] - eps\n    t_new = math.sorted_interp(jnp.linspace(0, 1, num_samples + 1), cw, t_new,\n                                utils.device_is_tpu())\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, shape=w.shape[:-1] + (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n  # Jitter the samples if requested.\n  if single_jitter:\n    t_new = t_new + jnp.random.normal(rng, shape=t_new.shape)\n  else:\n    t_new = jax.random.normal(rng, shape=t_new.shape)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample the center of each interval.\n      t_new = 0.5 * (t[Ellipsis, 1:] + t[Ellipsis, :-1])\n    else:\n      # Sample the entire range of each interval.\n      t_new = jnp.linspace(t[Ellipsis, 0], t[Ellipsis, -1], num_samples)\n    # If we're jittering, we need to interpolate into the PDF.\n    if single_jitter:\n      # Jittering all samples by the same amount.\n      t_new = math.sorted_interp(t_new, cw, t, utils.device_is_tpu())\n    else:\n      # Jittering each sample independently.\n      t_new = jax.vmap(math.sorted_interp, in_axes=(None, 0))(\n          t_new, cw, t, utils.device_is_tpu())\n  else:\n    # Random sampling.\n    u = rng.random(t.shape[:-1] + (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n  # Adjust the range of the samples to be the same as the input.\n  t_new = jnp.concatenate([t[Ellipsis, 0] - eps, t_new, t[Ellipsis, -1] + eps],\n                           axis=-1)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if deterministic_center:\n    # Compute the PDF and CDF for each weight vector.\n    w = jax.nn.softmax(w_logits, axis=-1)\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(cw, t, t, utils.device_is_tpu())\n    t_new = t_new[:, ::-1]\n  elif not single_jitter:\n    # Generate a random number for each sample.\n    u = jax.random.uniform(rng, (num_samples,))\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    t_new = t_new[:, ::-1]\n  else:\n    # Generate a single random number for all samples.\n    u = jax.random.uniform(rng, ())\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    t_new = t_new[:, ::-1]\n  # Clip samples to the range of the step function.\n  t_new = jnp.clip(t_new, a_min=t[Ellipsis, :-1], a_max=t[Ellipsis, -1])\n  # Add jitter to the samples.\n  t_new = t_new + eps * jnp.random.normal(rng, t_new.shape)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Random sampling.\n  if rng is not None:\n    u = jax.random.uniform(rng, cw.shape[:-1], minval=eps, maxval=1 - eps)\n  else:\n    u = jax.numpy_ops.linspace(eps, 1 - eps, num_samples, axis=-1)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  # Deterministic sampling.\n  if deterministic_center:\n    t_new = t_new + jnp.diff(t) * 0.5\n  if single_jitter:\n    t_new = t_new + jnp.diff(t) * jax.random.uniform(rng, t_new.shape)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate samples.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # For each sample, we sample from the uniform distribution over the\n      # interior of the bin.\n      u = jnp.random.uniform(\n        shape=jnp.broadcast_to(jnp.ones(num_samples), cw.shape[:-1] + (1,)),\n        minval=eps,\n        maxval=1 - eps,\n      )\n    else:\n      # For each sample, we sample from the uniform distribution over the entire\n      # bin.\n      u = jnp.random.uniform(\n        shape=jnp.broadcast_to(jnp.ones(num_samples), cw.shape[:-1] + (2,)),\n        minval=eps,\n        maxval=1 - eps,\n      )\n    # Interpolate into the step function.\n    t_new = math.sorted_interp(u, cw, t)\n    return t_new\n  else:\n    # Random sampling.\n    # We sample from a uniform distribution over the range [0, 1].\n    u = jnp.random.uniform(\n      shape=jnp.broadcast_to(num_samples, cw.shape[:-1] + (1,)),\n      minval=eps,\n      maxval=1 - eps,\n    )\n    # Interpolate into the inverse CDF.\n    t_new = invert_cdf(u, t, w_logits)\n\n    if single_jitter:\n      # We jitter all samples by the same amount.\n      u_jittered = jnp.random.uniform(\n        shape=jnp.broadcast_to(jnp.ones(num_samples), cw.shape[:-1] + (2,)),\n        minval=eps,\n        maxval=1 - eps,\n      )\n    else:\n      # We jitter each sample independently.\n      "}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # If the CDF is not monotonic, then it's not a PDF.\n  cw = jnp.concatenate([jnp.zeros_like(cw[:, :-1]), cw], axis=-1)\n  # Compute the CDF for the entire batch.\n  cw_all = jax.lax.dynamic_update_slice(\n      cw, cw[:, -1, jnp.newaxis], jnp.full_like(cw[:, -1], 1.0)\n  )\n  # Sample from the CDF.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      t_new = t[jnp.arange(t.shape[0]), jnp.floor(num_samples / 2)]\n      samples = jnp.full((num_samples,), t_new, t_new.dtype)\n    else:\n      samples = math.lin_interp(jnp.linspace(eps, 1 - eps, num_samples), cw_all, t)\n  else:\n    # Random sampling.\n    u = rng.uniform(shape=(num_samples,), minval=eps, maxval=1 - eps)\n    t_new = math.sorted_interp(u, cw_all, t, utils.device_is_tpu())\n    samples = jax.random.choice(\n      t_new,\n      shape=(num_samples,),\n      replace=not single_jitter,\n      key=rng,\n    )\n  return samples\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # If the number of samples is 1, we can just take the center of the CDF.\n  if num_samples == 1:\n    if deterministic_center:\n      # The CDF is a step function, so we can just take the center of each bin.\n      return math.center_of_mass(cw, t)\n    else:\n      # Sample from the CDF using linspace.\n      return math.sorted_interp(\n          linspline.linspline(jnp.linspace(0, 1, num_samples), cw, t,\n                              utils.device_is_tpu())\n      )\n\n  # If we're not jittering, just sample from the CDF.\n  if not single_jitter:\n    return math.sorted_interp(\n        linspline.linspline(\n            jnp.random.uniform(rng, (num_samples,),\n                               minval=eps, maxval=1 - eps), cw, t,\n            utils.device_is_tpu())\n  # Otherwise, jitter the CDF by the same amount.\n  return math.sorted_interp(\n      linspline.linspline(\n          jnp.random.uniform(rng, (num_samples,),\n                              minval=eps, maxval=eps), cw, t,\n          utils.device_is_tpu())\n  )"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # If there is no randomness, just use a deterministic sampling method.\n  if rng is None:\n    # If we're not deterministic, jitter the samples by a small amount.\n    if single_jitter:\n      u = jnp.linspace(0, 1, num_samples + 1)\n    else:\n      u = jax.random.uniform(\n          jax.random.PRNGKey(0), shape=(num_samples,)\n      )\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    return t_new\n  else:\n    # If there is randomness, sample uniformly from the PDF.\n    u = jax.random.uniform(rng, (num_samples,))\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    # If we're deterministic, jitter the samples by a small amount.\n    if deterministic_center:\n      t_new = t_new + eps * jax.random.uniform(\n          rng, t_new.shape)\n    return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  if deterministic_center:\n    t_new = jnp.linspace(t[..., 0], t[..., -1], num_samples, axis=-1)\n    t_new = jnp.concatenate([t_new, t[Ellipsis, -1:]], axis=-1)\n  else:\n    w = jax.nn.softmax(w_logits, axis=-1)\n    cw = integrate_weights(w)\n    t_new = math.sorted_interp(\n        jnp.random.uniform(rng, shape=w.shape[:-1] + (num_samples,)), cw, t,\n        utils.device_is_tpu())\n\n  if single_jitter:\n    t_new = t_new + eps * jnp.random.uniform(rng, shape=t_new.shape)\n  else:\n    t_new = t_new + eps * jnp.random.uniform(rng, shape=t_new.shape[:-1] + (num_samples,))\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  if deterministic_center:\n    # Sample uniformly from the center of each interval.\n    center = jnp.diff(t) / 2\n    if single_jitter:\n      center = center * rng.uniform(center.shape, minval=0, maxval=eps)\n    else:\n      center = center + eps * rng.uniform(center.shape)\n    return jnp.concatenate([t[0], t[1:] - center], axis=-1)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  u = rng.uniform(cw.shape)\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate samples from the CDF.\n  if rng is not None:\n    # Randomly sample a uniform CDF value in [0, 1) and invert.\n    u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n  else:\n    # Deterministically sample the center of each interval.\n    if deterministic_center:\n      t_new = t[Ellipsis, :-1] + jnp.diff(t[Ellipsis, :-1], axis=-1) / 2.0\n      t_new = jnp.concatenate([t[Ellipsis, 0], t_new], axis=-1)\n    else:\n      # Generate a linspace over the interval [0, 1) and invert.\n      u = jax.scipy.stats.lin_space(eps, 1 - eps, num_samples)\n      t_new = invert_cdf(u, t, w_logits)\n\n  # Jitter the samples.\n  if single_jitter:\n    # Jitter the samples by the same amount.\n    jitter_rng = jax.random.foldl(jax.random.foldl, rng, jnp.ones_like(t_new))\n    t_new = jax.random.uniform(jitter_rng, t_new.shape) * jnp.diff(t, axis=-1) + t_new\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  w_sum = jnp.sum(w, axis=-1)\n  # If the sum of the weights is not 1, we're not dealing with a PDF.\n  utils.assert_equal(\n      w_sum,\n      jnp.ones(w.shape[:-1], w.dtype),\n      'Weights must sum to 1.',\n      'The input weights sum to',\n      jnp.sum(w_sum),\n      'instead of 1.',\n  )\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n  # If we're using a deterministic sampling method, we use linspace to generate\n  # the samples.\n  if rng is None:\n    if deterministic_center:\n      # If we're centering the samples, we compute the midpoint of each interval\n      # and use that as the sample.\n      t_new = jnp.linspace(t[Ellipsis, :-1], t[Ellipsis, 1:], num_samples)\n    else:\n      # If we're not centering the samples, we sample uniformly over the entire\n      # range of the step function.\n      t_new = jnp.linspace(t[Ellipsis, 0], t[Ellipsis, -1], num_samples)\n  else:\n    # If we're using a random sampling method, we sample uniformly over the\n    # cumulative sum of the weights and use the corresponding CDF to sample from\n    # the step function.\n    u = rng.uniform(shape=(num_samples,) + cw.shape[:-1], low=0, high=1)\n    t_new = invert_cdf(u, t, w_logits)\n  # If we're jittering the samples, we add a small value to each sample.\n  if single_jitter:\n    t_new = t_new + eps\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the CDF for the PDF.\n  # If deterministic_center is True, we want to sample in the center of each\n  # interval.\n  if deterministic_center:\n    t_new = jnp.linspace(t[Ellipsis, 0], t[Ellipsis, -2], num_samples)\n  else:\n    t_new = t\n\n  if rng is None:\n    # Deterministic sampling.\n    # In the case of deterministic sampling, we want to sample from the\n    # uniform distribution over each interval.\n    t_new = t_new.at[Ellipsis, -1].set(t[Ellipsis, -1])\n    t_new = jax.lax.stop_gradient(t_new)\n    # If we're using deterministic sampling, we want to ensure that we sample\n    # uniformly over the entire PDF.\n    cw = cw.at[Ellipsis, -1].set(1)\n\n    return t_new\n\n  # Random sampling.\n  # We sample uniformly from the uniform distribution over the CDF.\n  u = jax.random.uniform(rng, cw.shape)\n  t_new = invert_cdf(u, t, w_logits)\n\n  # Jittering.\n  if single_jitter:\n    # If jitter is applied to each sample, we can jitter the CDFs by the same\n    # amount.\n    u = jax.random.uniform(rng, cw.shape)\n    t_new = jax.lax.stop_gradient(t_new)\n  else:\n    # If jitter is applied to each sample, we can jitter the CDFs by the same\n    # amount.\n    u = jax.random.uniform(rng, cw.shape)\n    t_new = jax.lax.stop_gradient(t_new)\n\n  # Jittering.\n  if single_jitter:\n    # If jitter is applied to each sample, we can jitter the CDFs by the"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if single_jitter and deterministic_center:\n    raise ValueError(\n        \"Cannot have single_jitter=True and deterministic_center=True\"\n    )\n\n  w = jax.nn.softmax(w_logits, axis=-1)\n  # Compute the CDF for each weight vector.\n  cw = integrate_weights(w)\n\n  if deterministic_center:\n    # We'd like to sample from a uniform distribution on the interval [t_i, t_i+1].\n    # If we use the linspace trick, we'll get a uniform distribution on the\n    # interval [t_i, t_i + 1 - eps].\n    # We'd like to shift the linspace by eps/2 to get the desired range.\n    # We'll also need to clip the result to [t_i, t_i + 1], so we're\n    # adding eps/2 to the left endpoint and subtracting eps/2 from the right\n    # endpoint.\n    t_new = jnp.where(\n        t[:-1, ..., None] + jnp.linspace(eps / 2, eps / 2, num_samples),\n        t[1:, ..., None] - eps / 2,\n        t[..., None],\n    )\n\n  elif single_jitter:\n    # We're jittering all samples by the same amount.\n    u = jax.random.uniform(rng, [t.shape[Ellipsis], num_samples], minval=eps)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  else:\n    # We're jittering each sample independently.\n    u = jax.random.uniform(rng, [t.shape[Ellipsis], num_samples, 1], minval=eps)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n      rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample from CDF\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = t_samples.at[Ellipsis, 0].set(domain[0])\n  t_samples = t_samples.at[Ellipsis, -1].set(domain[1])\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Sample points from the step function.\n  t_samples = sample(\n    rng, t, w_logits, num_samples, single_jitter, deterministic_center=False\n  )\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = 0.5 * (t_samples[Ellipsis, :-1] + t_samples[Ellipsis, 1:])\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n    [domain[0], t_samples, domain[1]], axis=-1\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Sample from the step function.\n  t_samples = sample(\n      rng, t, w_logits, num_samples, single_jitter=single_jitter\n  )\n\n  # Ensure the first and last intervals are within the domain.\n  t_samples = jnp.concatenate(\n      [domain[0], t_samples, domain[1]], axis=0\n  )\n  return t_samples[1:] - t_samples[:-1]\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    if domain[0] is None:\n      u_min = 1.0 / num_samples\n    else:\n      u_min = (domain[0] - t[0]) / (t[1] - t[0])\n    if domain[1] is None:\n      u_max = 1.0\n    else:\n      u_max = (domain[1] - t[-1]) / (t[-2] - t[-1])\n    u = jnp.linspace(u_min, u_max, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    if domain[0] is None:\n      u_min = 1.0 / num_samples\n    else:\n      u_min = (domain[0] - t[0]) / (t[1] - t[0])\n    if domain[1] is None:\n      u_max = 1.0\n    else:\n      u_max = (domain[1] - t[-1]) / (t[-2] - t[-1])\n    max_jitter = (u_max - u_min) / (num_samples - 1)\n    u = jnp.linspace(u_min, u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples - 1,), maxval=max_jitter\n    )\n\n  # Interpolate into the inverse CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust the first and last intervals to fit within the domain.\n  if domain[0] is not None:\n    t_samples = jnp.maximum(t_samples, domain[0])"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  t_samples = sample(\n      rng, t, w_logits, num_samples, single_jitter=single_jitter\n  )\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_samples = jnp.where(\n      t_samples < domain[0], domain[0], t_samples\n  )\n  t_samples = jnp.where(t_samples > domain[1], domain[1], t_samples)\n  # Compute the midpoint of adjacent samples.\n  t_samples = jnp.concatenate([t_samples[:, :-1], t_samples[:, 1:]], axis=-1)\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  utils.assert_valid_domain(domain)\n\n  # Generate random samples from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = (t_samples[Ellipsis, :-1] + t_samples[Ellipsis, 1:]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_samples = math.select(\n    [(t_samples[Ellipsis, 0] < domain[0], domain[0]),\n    (t_samples[Ellipsis, -1] > domain[1], domain[1]),\n    t_samples\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1.0 / (num_samples - 1)\n    max_jitter = u_max / (num_samples - 1)\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, (num_samples,), maxval=max_jitter\n    )\n\n  # Compute the CDF and inverse CDF.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_samples = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_samples = t_samples.at[Ellipsis, 0].set(domain[0])\n  t_samples = t_samples.at[Ellipsis, -1].set(domain[1])\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Draw uniform samples.\n  if rng is None:\n    t_samples = jnp.linspace(domain[0], domain[1], num_samples + 1)\n    t_samples = jnp.broadcast_to(t_samples, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # 'u' is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = domain[1] - domain[0]\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n    t_samples = jnp.linspace(domain[0], domain[1], num_samples + 1) + u\n\n  # Generate the intervals.\n  t_samples = jnp.concatenate([t_samples, t], axis=-1)\n  return jnp.diff(t_samples, axis=-1)\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert CDF\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust first and last intervals\n  t_samples = jnp.concatenate(\n      [\n        jnp.full(t.shape[:-1] + (1,), domain[0]),\n        t_samples,\n        jnp.full(t.shape[:-1] + (1,), domain[1]),\n      ],\n      axis=-1,\n  )\n  return t_samples[Ellipsis, 1:-1]\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    if num_samples % 2 == 0:\n      u = jnp.linspace(0, 1, num_samples)\n    else:\n      u = jnp.linspace(0, 1 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n      rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n  # Calculate the midpoints between adjacent samples.\n  t_samples = jnp.concatenate([t_samples[..., :-1], t_samples[..., 1:]], axis=-1)\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n    [\n      jnp.where(t_samples[..., 0] < domain[0], domain[0], t_samples[..., 0]),\n      t_samples[..., 1:],\n    ],\n    axis=-1,\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1.0 / num_samples\n    max_jitter = 1.0 - u_max\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Interpolate into the inverse CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n  # Ensure the first and last intervals are within the domain.\n  t_samples = jnp.where(\n    t_samples < domain[0], domain[0], t_samples\n  )\n  t_samples = jnp.where(\n    t_samples > domain[1], domain[1], t_samples\n  )\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    if num_samples == 1:\n      return jnp.array([domain[0]])\n    else:\n      u = jnp.linspace(0, 1 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    max_jitter = (1 - eps) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - eps, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Find the corresponding values in the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n  # Find the midpoints between adjacent samples.\n  t_midpoints = jnp.concatenate(\n      [t_samples[:-1] + (t_samples[1:] - t_samples[:-1]) / 2, t_samples[-1:]]\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.where(\n      t_midpoints < domain[0],\n      jnp.array([domain[0]]),\n      t_midpoints,\n  )\n  t_midpoints = jnp.where(\n      t_midpoints > domain[1],\n      jnp.array([domain[1]]),\n      t_midpoints,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - eps, num_samples)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1 - eps, num_samples) + jax.random.uniform(\n      rng, t.shape[:-1] + (num_samples,), maxval=eps\n    )\n\n  # Invert CDF to get samples.\n  t_samples = invert_cdf(u, t, w_logits)\n  # Calculate the midpoints of the intervals.\n  t_mid = (t_samples[:, :-1] + t_samples[:, 1:]) / 2\n  # Adjust the first and last intervals to fit within the domain.\n  t_mid = math.clip(t_mid, domain[0], domain[1])\n  # Return the intervals.\n  return jnp.concatenate([t_samples[:, :-1], t_mid], axis=-1)\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = jnp.concatenate(\n      [t_samples[Ellipsis, :-1] + jnp.diff(t_samples, axis=-1) / 2.0, t_samples[-1:, -1:]],\n      axis=-1,\n  )\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  # This is necessary because the step function could have been defined on an\n  # unbounded domain, but we want to ensure that the resulting intervals are\n  # within the specified domain.\n  if domain[0] > -jnp.inf:\n    t_midpoints = jnp.where(t_midpoints < domain[0], domain[0], t_midpoints)\n  if domain[1] < jnp.inf:\n    t_midpoints = jnp.where(t_midpoints > domain[1], domain[1], t_midpoints)\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1, num_samples)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1, num_samples) + jax.random.uniform(rng, (1,))\n\n  # Compute the corresponding CDF values.\n  u_cdf = integrate_weights(w_logits)\n  # Interpolate into the inverse CDF.\n  t_samples = math.sorted_interp(u, u_cdf, t, utils.device_is_tpu())\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n    [jnp.array(domain[0], dtype=t_samples.dtype), t_samples, jnp.array(domain[1], dtype=t_samples.dtype)],\n    axis=-1\n  )\n\n  return t_samples[Ellipsis, 0:1] - t_samples[Ellipsis, 1:]\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1 / (num_samples - 1)\n    max_jitter = u_max - eps\n    u = jnp.linspace(0, 1, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples - 1,), maxval=max_jitter\n    )\n\n  # Compute the CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_samples = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  # Compute the interval midpoints.\n  t_samples = jax.ops.pad(t_samples, (0, 1), mode='r', value=t_samples[:, -1])\n  t_samples = jax.ops.pad(t_samples, (0, 1), mode='l', value=t_samples[:, 0])\n\n  # Adjust the first and last intervals to fit within the domain.\n  t_samples = t_samples.at[Ellipsis, 0].set(t[Ellipsis, 0])\n  t_samples = t_samples.at[Ellipsis, -1].set(t[Ellipsis, -1])\n  t_samples = jax.lax.cond(\n    domain[0] < t_samples[..., 0],\n    lambda x: x.at[Ellipsis, 0].set(domain[0]),\n    lambda x: x,\n    eltype=t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    if deterministic_center:\n      pad = 1 / (2 * num_samples)\n      u = jnp.linspace(pad, 1.0 - pad - eps, num_samples)\n    else:\n      u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Get the samples from the step function\n  t_samples = invert_cdf(u, t, w_logits)\n  # Calculate the midpoints between adjacent samples.\n  t_samples_midpoints = 0.5 * (jnp.roll(t_samples, 1, -1) + t_samples)\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n      [domain[0], t_samples_midpoints, domain[1]], axis=-1\n  )\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    max_jitter = (1 - eps) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jax.random.uniform(rng, t.shape[:-1] + (d,), maxval=max_jitter)\n\n  return jax.vmap(lambda u: t[math.sorted_interp(u, w_logits, t, utils.device_is_tpu())], in_axes=[1])([u])\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  t = t.reshape(-1)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    max_jitter = 1 / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  u = u.reshape(-1, num_samples)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = jnp.concatenate([t[:-1], t[1:]], axis=-1)\n  t_midpoints = t_midpoints + jnp.diff(t_midpoints) * (u - 0.5)\n  t_midpoints = t_midpoints.reshape(-1, num_samples)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jax.vmap(\n      linspline.clip_to_domain, in_axes=0\n  )(t_midpoints, domain)\n\n  # Calculate the intervals by taking the midpoints and adding the bin widths.\n  t_intervals = jnp.concatenate([t_midpoints[:, :-1], t_midpoints[:, 1:]], axis=-1)\n  t_intervals = t_intervals.reshape(-1, 2, num_samples)\n  return t_intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    if single_jitter:\n      pad = 1 / (2 * num_samples)\n      u = jnp.linspace(pad, 1.0 - pad, num_samples)\n    else:\n      u = jnp.linspace(0, 1, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1 / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Compute the CDF and sample from it.\n  # TODO(b/126688482): This is the same as in `invert_cdf`, but we can't\n  # just use that function because we need to do the domain adjustment.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the CDF and sample from it.\n  t_samples = jnp.interp(u, cw, t, utils.device_is_tpu())\n\n  # Adjust the first and last intervals to fit within the domain.\n  t_samples = t_samples.at[Ellipsis, 0].set(t[Ellipsis, 0])\n  t_samples = t_samples.at[Ellipsis, -1].set(jnp.maximum(t[-1], t_samples[-2, -1]))\n  t_samples = t_samples.at[Ellipsis"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = w / jnp.sum(w)\n\n  # Compute the integrated weights\n  cw = jnp.cumsum(w, axis=-1)\n\n  # Interpolate into the inverse CDF\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_new"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n  # Compute the CDF for each weight vector.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return t_new"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = jnp.array(w)\n  w = w / jnp.sum(w)\n\n  # Compute the integrated weights.\n  cw = jnp.cumsum(w)\n\n  # Interpolate into the percentiles.\n  p = jnp.array(ps)\n  t_new = math.sorted_interp(p, cw, t)\n\n  return t_new"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = w / jnp.sum(w)\n\n  # Integrate the weights to get the CDF\n  cw = integrate_weights(w)\n\n  # Interpolate into the CDF\n  cdf_samples = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  # Interpolate into the inverse CDF\n  return invert_cdf(cdf_samples, t, w)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # ensure that the weights sum to 1\n  w = w / jnp.sum(w)\n\n  # compute the cumulative sum of the weights\n  cw = jnp.cumsum(w, axis=-1)\n\n  # ensure that the CDF starts with exactly 0 and ends with exactly 1\n  cw = jnp.concatenate([jnp.zeros_like(cw[..., :1]), cw, jnp.ones_like(cw[..., -1:])], axis=-1)\n\n  # interpolate into the inverse CDF\n  t_new = math.sorted_interp(ps, cw, t)\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = w / jnp.sum(w)\n\n  # Compute the CDF of the weights\n  cw = jnp.cumsum(w)\n\n  # Interpolate into the weighted percentiles\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Integrate the weights to get the cumulative distribution.\n  w_cum = jnp.cumsum(w, axis=-1)\n\n  # Interpolate into the cumulative distribution.\n  t_out = jax.lax.interp(ps, w_cum, t, method='linear')\n\n  return t_out\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Integrate the weights to get the CDF.\n  cw = integrate_weights(w)\n\n  # Interpolate into the weighted percentiles.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights.\n  w = jnp.minimum(1, jnp.cumsum(w[Ellipsis, :-1], axis=-1))\n  w = w * jnp.diff(t)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100, w, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_in_range(ps, 0, 100)\n  # Normalize weights to sum to 1.\n  w = jnp.array(w) / jnp.sum(w)\n\n  # Compute the integrated weights.\n  w_integrated = integrate_weights(w)\n  # Interpolate into the percentiles.\n  return math.sorted_interp(ps, w_integrated, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  p_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return p_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_in_range(ps, 0, 100)\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n  w_sorted = jnp.sort(w)\n  cw_sorted = jnp.cumsum(w_sorted, axis=-1)\n  w_sorted = jnp.concatenate([jnp.zeros_like(cw_sorted), w_sorted, jnp.ones_like(cw_sorted)], axis=-1)\n  cw_sorted = jnp.concatenate([jnp.zeros_like(w_sorted), cw_sorted, jnp.ones_like(cw_sorted)], axis=-1)\n  ps_sorted = jnp.concatenate([0, ps, 100], axis=-1)\n  return math.sorted_interp(ps_sorted, cw_sorted, t)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the CDF for each weight vector.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = jax.nn.softmax(w)\n  cw = integrate_weights(w)\n  # Interpolate into the weighted percentiles.\n  return math.sorted_interp(ps, cw, t)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Normalize the weights so that they sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  # Integrate the weights.\n  cw = integrate_weights(w)\n  # Interpolate into the percentiles.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_in_range(ps, 0, 100)\n\n  # Compute the CDF and the integrated weights.\n  cw = integrate_weights(w)\n  cw0 = cw[Ellipsis, 0]\n  cw1 = cw[Ellipsis, -1]\n  cw_diff = jnp.diff(cw)\n\n  # Interpolate the CDF.\n  # TODO(b/201340916): This is a hack to avoid the case where cw_interp = 0.\n  cw_interp = math.safe_interp(ps / 100, cw0, cw1, cw_diff)\n\n  # Interpolate the x-values.\n  return math.sorted_interp(cw_interp, t, t[Ellipsis, 1:], utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  w_pdf = weight_to_pdf(t, w)\n  w_blur = linspline.blur_pdf(tq, t, w_pdf, blur_halfwidth)\n  return pdf_to_weight(tq, w_blur)"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert to a PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blurred = linspline.gaussian_blur(t, p, blur_halfwidth)\n  # Resample the PDF.\n  w_resampled = pdf_to_weight(tq, p_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert to PDF.\n  pdf = weight_to_pdf(t, w)\n  # Blur the PDF.\n  pdf_blurred = linspline.blur(tq, t, pdf, blur_halfwidth)\n  # Resample the PDF.\n  w_resampled = pdf_to_weight(tq, pdf_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Blur the histogram by convolving it with a Gaussian kernel.\n  w_pdf = weight_to_pdf(t, w)\n  w_blurred = linspline.gaussian_blur(tq, t, w_pdf, blur_halfwidth)\n  # Resample the blurred histogram.\n  w_resampled = resample(tq, t, w_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert to PDF.\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w = linspline.blur_pdf(t, w, blur_halfwidth)\n  # Resample the blurred PDF.\n  w_resampled = resample(tq, t, w, use_avg=True)\n\n  # Convert back to weights.\n  w_resampled = pdf_to_weight(tq, w_resampled)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  w_pdf = weight_to_pdf(t, w)\n  w_blurred = linspline.blur(tq, w_pdf, blur_halfwidth)\n  return pdf_to_weight(tq, w_blurred)\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Blur the PDF\n  p = weight_to_pdf(t, w)\n  p_blurred = linspline.gaussian_blur(t, p, blur_halfwidth)\n\n  # Resample the blurred PDF\n  resampled_p = resample(tq, t, p_blurred)\n  return pdf_to_weight(tq, resampled_p)\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # TODO(v-sharan): Add a test for this function.\n  utils.assert_valid_stepfun(t, w)\n  # Convert the weights to a PDF.\n  pdf = weight_to_pdf(t, w)\n  # Blur the PDF.\n  pdf_blurred = linspline.blur_pdf(tq, t, pdf, blur_halfwidth)\n  # Convert the blurred PDF to weights.\n  w_resampled = pdf_to_weight(tq, pdf_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Compute the PDF of the input.\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  t_blurred = math.gaussian_blur(t, blur_halfwidth)\n  pdf_blurred = linspline.interp(t, pdf, t_blurred)\n\n  # Resample the PDF.\n  return pdf_to_weight(tq, pdf_blurred)\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a probability density function.\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  pdf_blurred = linspline.blur_pdf(t, pdf, blur_halfwidth)\n  # Resample the blurred PDF.\n  w_new = pdf_to_weight(tq, pdf_blurred)\n\n  return w_new\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Make sure the time points are sorted and add a zero-weight bin at the start and end.\n  t = jnp.array(t)\n  t = jnp.concatenate([jnp.array([t[0] - blur_halfwidth]), t, jnp.array([t[-1] + blur_halfwidth])])\n  w = jnp.concatenate([jnp.array([0]), w, jnp.array([0])])\n\n  # Convert the histogram to a probability density function (PDF)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  pdf = linspline.gaussian_blur(t, pdf, blur_halfwidth)\n\n  # Resample the PDF to the new time points\n  return resample(tq, t, pdf)"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # TODO(jweir): This is a kluge.\n  t_min = t.min()\n  t_max = t.max()\n  # TODO(jweir): This is a kluge.\n  w_min = w.min()\n  w_max = w.max()\n  w_blur = w * 0.0 + w_min\n  t_blur = t * 0.0 + t_min\n  # TODO(jweir): This is a kluge.\n  w_blur = w_blur.astype(jnp.float32)\n  t_blur = t_blur.astype(jnp.float32)\n\n  # TODO(jweir): This is a kluge.\n  w_blur = w_blur.astype(jnp.float64)\n  t_blur = t_blur.astype(jnp.float64)\n\n  # TODO(jweir): This is a kluge.\n  w_blur = w_blur.astype(jnp.float32)\n  t_blur = t_blur.astype(jnp.float32)\n\n  w_blur = jax.nn.softplus(w_blur)\n  t_blur = jax.nn.softplus(t_blur)\n\n  # TODO(jweir): This is a kluge.\n  w_blur = w_blur.astype(jnp.float64)\n  t_blur = t_blur.astype(jnp.float64)\n\n  # TODO(jweir): This is a kluge.\n  w_blur = w_blur.astype(jnp.float32)\n  t_blur = t_blur.astype(jnp.float32)\n\n  w_blur = w_blur / jnp.sum(w_blur, axis=-1, keepdims=True)\n  w_blur = jax.nn.softmax(w_blur, axis=-1)\n\n  # TODO(jweir): This is a kluge.\n  w_blur = w_blur.astype(jnp.float64)\n  t_blur = t_blur.astype(jnp.float6"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # The blur function is the PDF of a gaussian with halfwidth `blur_halfwidth`\n  # and mean 0.\n  w_blurred = linspline.gaussian_pdf(jnp.zeros_like(t), jnp.abs(t), blur_halfwidth)\n\n  # Convert the input to a PDF.\n  w_pdf = w_blurred * weight_to_pdf(t, w)\n\n  # Integrate the PDF to get the CDF.\n  w_cdf = integrate_weights(w_pdf)\n\n  # Interpolate the CDF.\n  w_resampled_cdf = math.sorted_interp(tq, w_cdf, t)\n\n  # Integrate the resampled CDF to get the resampled PDF.\n  w_resampled_pdf = integrate_weights(w_resampled_cdf)\n\n  # Resample the PDF to get the resampled weights.\n  w_resampled_weights = w_resampled_pdf * pdf_to_weight(t, w_pdf)\n\n  return w_resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  w = w / jnp.sum(w)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  pdf_blurred = linspline.blur(t, pdf, blur_halfwidth)\n\n  # Resample the PDF\n  return resample(tq, t, pdf_blurred)\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Compute the PDF of the histogram.\n  w = w / jnp.sum(w)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  pdf_blurred = linspline.gaussian_blur(t, pdf, blur_halfwidth)\n  # Integrate the blurred PDF to get the new histogram.\n  w_blurred = pdf_to_weight(tq, pdf_blurred)\n\n  return w_blurred\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p_blurred = linspline.blur_pdf(t, p, blur_halfwidth)\n  # Resample the PDF.\n  return resample(tq, t, p_blurred)\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Blur the PDF.\n  w = linspline.gaussian_blur(t, w, blur_halfwidth)\n\n  # Resample the PDF to the new time points.\n  return resample(tq, t, w)\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  blurred_pdf = linspline.gaussian_blur(tq, pdf, blur_halfwidth)\n\n  # Resample the PDF.\n  resampled_pdf = resample(tq, t, blurred_pdf)\n\n  # Convert back to the weights.\n  resampled_w = pdf_to_weight(tq, resampled_pdf)\n\n  return resampled_w\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert to PDF\n  pdf = weight_to_pdf(t, w)\n  # Blur PDF\n  pdf_blurred = linspline.blur_pdf(pdf, blur_halfwidth)\n  # Convert blurred PDF to weights\n  w_blurred = pdf_to_weight(tq, pdf_blurred)\n  return w_blurred\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # TODO: check if `tq` is sorted.\n  # TODO: add support for 1D and 3D.\n  # TODO: make sure this is numerically stable.\n  # TODO: add support for step functions with weight vectors that don't sum to 1.\n  # TODO: add support for step functions with bin values that don't integrate to 1.\n\n  # Convert the histogram to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  # TODO: add support for 1D and 3D.\n  p_blurred = linspline.blur(p, blur_halfwidth)\n\n  # Resample the PDF to the new time points.\n  w_resampled = pdf_to_weight(tq, resample(tq, t, p_blurred))\n\n  return w_resampled\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(vectors, jnp.concatenate([transform, jnp.ones_like(vectors[Ellipsis, :1])], axis=-1))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(vectors, transform)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert to homogeneous representation.\n  vectors = to_homogeneous(vectors)\n\n  # Apply transformation.\n  transformed = matmul(vectors, transform)\n\n  # Convert back to non-homogeneous representation.\n  return from_homogeneous(transformed)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # pylint: disable=unnecessary-lambda\n  return matmul(to_homogeneous(vectors),\n                transform)\n  # pylint: enable=unnecessary-lambda"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # pylint: disable=redefined-variable-type\n  vectors = to_homogeneous(vectors)\n  transformed = matmul(transform, vectors)\n  return from_homogeneous(transformed)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # pylint: disable=cell-var-from-loop\n  def _transform(v):\n    return matmul(v, transform)\n\n  return jax.vmap(_transform, in_axes=(Ellipsis, 0))(vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(transform[Ellipsis, :-1], from_homogeneous(vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.matmul(to_homogeneous(vectors), transform)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(transform, from_homogeneous(vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  transformed_vectors = matmul(transform, to_homogeneous(vectors))\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(transform, to_homogeneous(vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(transform, from_homogeneous(vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  v_homog = to_homogeneous(vectors)\n  return from_homogeneous(matmul(transform, v_homog))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.matmul(\n      to_homogeneous(vectors),\n      jnp.concatenate([transform, jnp.zeros_like(transform[Ellipsis, :1])],\n                     axis=-1))[:, :-1]\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(to_homogeneous(vectors), transform)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # TODO(s9carma): Replace this with a more efficient implementation\n  # if we have a better way of doing this.\n  return from_homogeneous(\n      jnp.matmul(\n          to_homogeneous(vectors),\n          jnp.transpose(to_homogeneous(transform), perm=(0, 2, 1))\n  )\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.matmul(transform, to_homogeneous(vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # TODO(ehsan): Add support for non-3D points.\n  # TODO(ehsan): Add support for non-square transforms.\n\n  # pylint: disable=redefined-builtin\n  vectors = to_homogeneous(vectors)\n  # pylint: enable=redefined-builtin\n\n  # TODO(ehsan): Add support for non-square transforms.\n  assert vectors.ndim == 2\n  assert transform.ndim == 3\n\n  return from_homogeneous(matmul(vectors, transform))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return matmul(to_homogeneous(vectors), jnp.concatenate(\n      [transform, jnp.full_like(transform[Ellipsis, :1], 0.0)], axis=1))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # pylint: disable=redefined-builtin\n  if vectors.ndim == 2:\n    vectors = jnp.moveaxis(vectors, 1, -1)\n  # pylint: enable=redefined-builtin\n\n  if vectors.ndim == 3:\n    transformed_points = jnp.matmul(transform, to_homogeneous(vectors))\n  else:\n    transformed_points = jnp.einsum('ij,ijl->il', transform, to_homogeneous(vectors))\n\n  return from_homogeneous(transformed_points)\n\n"}
{"namespace": "stepfun.resample", "completion": "  if use_avg:\n    return linspline.resample_avg(t, tp, vp)\n  else:\n    return linspline.resample_sum(t, tp, vp)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    return vp * jnp.diff(t)\n  else:\n    return jnp.sum(vp, axis=-1)"}
{"namespace": "stepfun.resample", "completion": "  if use_avg:\n      return linspline.interp(t, tp, vp, method=\"avg\")\n  else:\n      return linspline.interp(t, tp, vp, method=\"sum\")"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    # Compute the PDF and CDF for each weight vector.\n    w = weight_to_pdf(tp, vp)\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    return math.sorted_interp(t, cw, tp, utils.device_is_tpu())\n  else:\n    # Compute the PDF and CDF for each weight vector.\n    w = vp\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    return math.sorted_interp(t, cw, tp, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp, vp)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(vp)\n\n  # Interpolate into the new time points.\n  return math.sorted_interp(jnp.array(t), cw, tp, utils.device_is_tpu())"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n  utils.assert_valid_stepfun(t, tp)\n\n  # Compute the CDF of the original step function.\n  # cw = integrate_weights(w)\n  # Interpolate into the CDF of the new step function.\n  # t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  t_new = linspline.interp(t, tp, vp, use_avg)\n  return t_new"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    return linspline.weighted_avg(t, tp, vp)\n  else:\n    return linspline.weighted_sum(t, tp, vp)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    # Sum the values in each interval, weighted by the interval width.\n    td = jnp.diff(tp)\n    return jnp.sum(vp * td, axis=-1) * jnp.diff(t) / td\n  else:\n    # Sum the values in each interval.\n    return jnp.sum(vp, axis=-1) * jnp.diff(t)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp, vp)\n  if use_avg:\n    # Average the values of the step function for each interval in `t`.\n    return jnp.sum(jnp.concatenate([vp, vp[:, -1:]], axis=1) * jnp.diff(tp), axis=1) / jnp.diff(t)\n  else:\n    # Sum the values of the step function for each interval in `t`.\n    return jnp.sum(vp, axis=1)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    return jnp.sum(vp * jnp.diff(tp), axis=-1) / jnp.diff(t, axis=-1)\n  else:\n    return jnp.sum(vp * jnp.diff(tp, axis=-1), axis=-1)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t)\n  if use_avg:\n    # Weighted average.\n    v_new = jnp.sum(vp, axis=-1) * jnp.diff(t)\n    v_new /= jnp.sum(jnp.diff(t), axis=-1)\n    v_new = jnp.concatenate([v_new[..., 0], v_new, v_new[..., -1]], axis=-1)\n  else:\n    # Sum.\n    v_new = jnp.sum(vp, axis=-1)\n  v_new = jnp.concatenate(\n      [v_new[..., 0], v_new, v_new[..., -1]], axis=-1\n  )\n  return v_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    return jnp.sum(vp * jnp.diff(tp), axis=-1) * jnp.diff(t)\n  else:\n    return jnp.sum(vp * jnp.diff(tp), axis=-1)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Get the original weights and integrate them.\n  w = weight_to_pdf(tp, vp)\n  cw = integrate_weights(w)\n  # Interpolate into the new CDF.\n  w_resampled = jnp.interp(cw, jnp.diff(t), w, axis=-1)\n  if use_avg:\n    w_resampled *= jnp.diff(t)\n  # Integrate the weights.\n  cw_resampled = integrate_weights(w_resampled)\n  return jnp.interp(t, cw_resampled, vp, axis=-1)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the CDF of the original step function.\n  cw = integrate_weights(weight_to_pdf(tp, vp))\n\n  # Interpolate into the CDF.\n  t_new = math.sorted_interp(t, cw, tp, utils.device_is_tpu())\n\n  # Compute the PDF of the resampled step function.\n  if use_avg:\n    w = pdf_to_weight(t_new, vp)\n  else:\n    w = vp\n\n  # Compute the integral of the resampled step function.\n  cw_new = integrate_weights(w)\n\n  # Interpolate the integral of the resampled step function.\n  v_new = math.sorted_interp(cw_new, cw, t_new, utils.device_is_tpu())\n\n  return v_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp)\n  t_new = t[Ellipsis, :-1]\n  t_old = tp[Ellipsis, :-1]\n  v_old = vp[Ellipsis, :]\n\n  # Compute the PDF and CDF for each weight vector.\n  cw = integrate_weights(v_old)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(jnp.arange(100) / 100.0, cw, t_new)\n  t_new = jnp.broadcast_to(t_new, t_new.shape[:-1] + (1,))\n\n  # Interpolate into the values of the step function.\n  v_new = math.sorted_interp(jnp.arange(100) / 100.0, cw, v_old)\n  v_new = jnp.broadcast_to(v_new, v_new.shape[:-1] + (1,))\n\n  # Compute the new values of the step function.\n  if use_avg:\n    # Compute the new values of the step function by averaging.\n    v_new = jnp.sum(v_new, axis=-1) / jnp.sum(jnp.diff(t_new), axis=-1)\n  else:\n    # Compute the new values of the step function by summing.\n    v_new = jnp.sum(v_new * jnp.diff(t_new), axis=-1)\n\n  return v_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n  utils.assert_valid_stepfun(t, tp)\n  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    # Compute the PDF and CDF for each weight vector.\n    w = jnp.abs(jnp.diff(tp))\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(cw, jnp.array(t), jnp.array(tp), utils.device_is_tpu())\n    return jnp.array(t_new)\n  else:\n    # Compute the PDF and CDF for each weight vector.\n    w = jnp.abs(jnp.diff(tp))\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(jnp.array(t), cw, jnp.array(tp), utils.device_is_tpu())\n    return jnp.array(t_new)\n\n"}
{"namespace": "stepfun.resample", "completion": "  # We want to interpolate into the integrated weights according to `ps`.\n  w = jnp.where(t == tp, vp, 0)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = jnp.vectorize(jnp.interp, signature='(n),(m),(m)->(n)')(\n      cw, t, tp\n  )\n\n  if use_avg:\n    return t_new * jnp.diff(t)\n  return t_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(vp)\n\n  # Compute the interval boundaries of the new step function.\n  t0 = jnp.concatenate([jnp.zeros_like(t[Ellipsis, :1]), t], axis=-1)\n  t1 = jnp.concatenate([t, jnp.ones_like(t[Ellipsis, -1:])], axis=-1)\n\n  # Interpolate the cumulative sum of the weights.\n  cw_new = jax.lax.dynamic_interp(cw, t0, t1, t)\n\n  # Compute the new values of the step function.\n  if use_avg:\n    return cw_new * (t1 - t0)\n  else:\n    return cw_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  if tp.shape[:-1] != vp.shape[:-1]:\n    raise ValueError(\n        'The shape of `tp` and `vp` must match, but are {} and {}.'\n        .format(tp.shape, vp.shape))\n  if use_avg:\n    # The average value of the step function for each interval in `t` is\n    # the weighted average of the values in `vp` for that interval.\n    #\n    # The weights are the width of each interval in `t`.\n    td = jnp.diff(t)\n    return jnp.sum(vp * td[Ellipsis, None], axis=-2) / td\n  else:\n    # The sum of the step function for each interval in `t` is\n    # the sum of the values in `vp` for that interval.\n    #\n    # The weights are the width of each interval in `t`.\n    td = jnp.diff(t)\n    return jnp.sum(vp[Ellipsis, None] * td, axis=-2)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp, vp)\n\n  # Compute the CDF of the original step function.\n  cw = integrate_weights(jnp.concatenate([vp, [0]], axis=-1))\n\n  # Compute the CDF of the new step function.\n  t_new = math.sorted_interp(jnp.linspace(0, 1, t.shape[-1]), cw, t, utils.device_is_tpu())\n\n  if use_avg:\n      return t_new\n  else:\n    # Interpolate into the original step function.\n      vp_new = math.sorted_interp(t_new, cw, vp, utils.device_is_tpu())\n      return vp_new\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # TODO: Implement this function\n  raise NotImplementedError\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the mean and variance.\n  deg_scale = jnp.linspace(min_deg, max_deg - 1, max_deg - min_deg + 1)\n  scale_mean = jnp.sin(jnp.pi * deg_scale)\n  scale_var = jnp.sin(jnp.pi * deg_scale)\n\n  # Scale the input mean and variance.\n  mean = mean * scale_mean\n  var = var * scale_var\n\n  # Apply the sinusoidal encoding.\n  return jnp.sin(mean) + jnp.sqrt(var) * jnp.cos(mean)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the mean and variance.\n  scaling_factor = jnp.power(2, jnp.arange(min_deg, max_deg))\n  mean_scale = jnp.exp(mean * scaling_factor)\n  var_scale = jnp.exp(var * scaling_factor)\n  # Compute the encoded values.\n  encoded_mean = jnp.sin(mean_scale)\n  encoded_var = jnp.exp(-0.5 * var_scale)\n  # Concatenate the encoded values.\n  return jnp.concatenate([encoded_mean, encoded_var], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  if mean.ndim != 2:\n    raise ValueError(f'mean.ndim={mean.ndim}, expected 2.')\n  if var.ndim != 2:\n    raise ValueError(f'var.ndim={var.ndim}, expected 2.')\n  if mean.shape[:-1] != var.shape[:-1]:\n    raise ValueError(\n        f'mean.shape[:-1] {mean.shape[:-1]} != var.shape[:-1] {var.shape[:-1]}.')\n  if mean.shape[-1] != 2:\n    raise ValueError(f'mean.shape[-1] {mean.shape[-1]} != 2.')\n  if var.shape[-1] != 2:\n    raise ValueError(f'var.shape[-1] {var.shape[-1]} != 2.')\n\n  # Scale the mean and variance by a function of the degree.\n  scale_fn = lambda deg: jnp.power(2, deg)\n  scaled_mean = mean * scale_fn(min_deg)\n  scaled_var = var * scale_fn(max_deg)\n\n  # Concatenate the scaled mean and variance.\n  x_scaled = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding.\n  encoded_x = jnp.concatenate(\n      [jnp.sin(x_scaled), jnp.cos(x_scaled)], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scale factor for the encoding.\n  scale = jnp.power(2, jnp.arange(min_deg, max_deg))\n  scale = jnp.broadcast_to(scale, mean.shape)\n\n  # Scale the mean and variance.\n  mean_scale = mean * scale\n  var_scale = var * scale\n\n  # Compute the sine of the scaled mean and variance.\n  sine_mean = jnp.sin(mean_scale)\n  sine_var = jnp.sin(var_scale)\n\n  # Concatenate the sine of the scaled mean and variance.\n  return jnp.concatenate((sine_mean, sine_var), axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = mean * (2 ** (max_deg - min_deg))\n  scaled_var = var * (2 ** (2 * (max_deg - min_deg)))\n  # concatenate the scaled mean and variance\n  scaled_var_mean = jnp.concatenate((scaled_mean, scaled_var), axis=1)\n  # perform the encoding\n  encoded_var_mean = jnp.sin(scaled_var_mean)\n  return encoded_var_mean\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factors for the mean and variance.\n  # The scaling factor is the sine of the angle between the mean and the\n  # unit vector in the direction of the encoding.\n  # The scaling factor is in [0, 2] and is multiplied by the input mean\n  # to get the final mean.\n  scale_factor_mean = jnp.sin(jnp.arange(min_deg, max_deg) * jnp.pi / 3)\n  scale_factor_var = jnp.sin(jnp.arange(min_deg, max_deg) * jnp.pi / 6)\n\n  # Compute the scaled mean and variance.\n  scale_factor_mean = jnp.broadcast_to(scale_factor_mean, mean.shape)\n  scale_factor_var = jnp.broadcast_to(scale_factor_var, var.shape)\n  mean_scaled = mean * scale_factor_mean\n  var_scaled = var * scale_factor_var\n\n  # Compute the encoded variables.\n  encoded_mean = jnp.sin(mean_scaled)\n  encoded_var = jnp.exp(-0.5 * var_scaled)\n\n  # Concatenate the encoded mean and variance.\n  encoded_mean_and_var = jnp.concatenate([encoded_mean, encoded_var], axis=-1)\n\n  # Return the encoded variables.\n  return encoded_mean_and_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of 2.\n  # The max_deg is exclusive, so we need to add 1 to the max_deg to ensure\n  # that we're still in range.\n  scale = jnp.power(2, jnp.arange(min_deg, max_deg + 1))\n  mean_scaled = mean * scale\n  var_scaled = var * scale * scale\n  # Encode the coordinates.\n  return jnp.sin(mean_scaled) * jnp.sqrt(var_scaled)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the mean and variance.\n  deg_range = jnp.arange(min_deg, max_deg)\n  # The encoding scale is 1 at min_deg and 0 at max_deg.\n  scale = jnp.exp(deg_range * jnp.log(2))\n  # Scale the mean and variance.\n  mean_scaled = mean / scale\n  var_scaled = var / scale**2\n\n  # Compute the mean of sin(x), x ~ N(mean_scaled, var_scaled).\n  return jnp.concatenate((mean_scaled, expected_sin(mean_scaled, var_scaled)), axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by the scaling factor.\n  scaling_factor = 2.0 ** jnp.arange(min_deg, max_deg, dtype=jnp.int32)\n  scale_mean = jnp.multiply(mean, scaling_factor)\n  scale_var = jnp.multiply(var, scaling_factor)\n\n  # Compute the encoded values.\n  sinusoid_values = jnp.sin(scale_mean)\n  sinusoid_values = jnp.concatenate(sinusoid_values, axis=-1)\n  cosusoid_values = jnp.cos(scale_mean)\n  cosusoid_values = jnp.concatenate(cosusoid_values, axis=-1)\n\n  # Return the encoded values.\n  return jnp.concatenate([sinusoid_values, cosusoid_values], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # TODO: Remove this, it's a hack to make the test pass.\n  if len(mean.shape) == 2:\n    mean = mean[0]\n    var = var[0]\n\n  # TODO: Remove this, it's a hack to make the test pass.\n  if len(mean.shape) == 3:\n    mean = mean[0, 0, 0]\n    var = var[0, 0, 0]\n\n  # Normalize the input to be in [0, 1].\n  mean_norm = mean / (2 * np.pi)\n  var_norm = var / (2 * np.pi)\n  # Scale the mean and variance by powers of 2.\n  mean_scaled = mean_norm * 2 ** (jnp.arange(min_deg, max_deg)[:, None] - 1)\n  var_scaled = var_norm * 2 ** (jnp.arange(min_deg, max_deg)[:, None] - 1)\n  # Apply a sinusoidal encoding.\n  return jnp.concatenate([\n      expected_sin(mean_scaled, var_scaled),\n      jnp.cos(mean_scaled)\n  ], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale mean and variance to be in [0, 2pi].\n  # TODO(dli15): Can we use a different scaling?\n  mean = mean * 2 * np.pi\n  var = var * 4 * np.pi**2\n  # Compute the scale for the sinusoidal encoding.\n  scale = jnp.maximum(0, jnp.arange(min_deg, max_deg))\n  # Scale the mean and variance by the scale.\n  scale_mean = jnp.cos(scale) * mean + jnp.sin(scale) * var\n  scale_var = jnp.sin(scale) * mean + jnp.cos(scale) * var\n  # Encode the scaled mean and variance.\n  return jnp.concatenate([scale_mean, scale_var], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance.\n  mean = (\n      mean - jnp.pi / 2) * jnp.pi / 2\n  var = jnp.pi * jnp.pi * var / 2\n  # Encode the scaled mean and variance.\n  # pylint: disable=not-an-iterable\n  encoded_mean = jnp.sum(\n      jnp.sin(jnp.arange(min_deg, max_deg + 1, dtype=mean.dtype) * mean),\n      axis=-1)\n  encoded_var = jnp.sum(\n      jnp.cos(jnp.arange(min_deg, max_deg + 1, dtype=var.dtype) * var),\n      axis=-1)\n  # pylint: enable=not-an-iterable\n  # Concatenate the mean and variance.\n  return jnp.concatenate((encoded_mean, encoded_var), axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance, and then concatenate them.\n  mean = jnp.concatenate([mean, jnp.sqrt(var)], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  # We use `jnp.cos` instead of `jnp.sin` because the former is faster.\n  return jnp.cos(\n      jnp.pi * mean * (2 ** (jnp.arange(min_deg, max_deg) + 0.5))\n  )\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance.\n  # TODO(brendan): This is a bit of a hack, and should be fixed.\n  mean = (mean + 1) / 2\n  var = (var + 1) / 2\n  # Encode the scaled mean and variance.\n  s = (jnp.arange(min_deg, max_deg, dtype=jnp.float32)\n       + jnp.arange(\n           min_deg, max_deg, dtype=jnp.float32)[:, None] * 2)\n  # TODO(brendan): This is a bit of a hack, and should be fixed.\n  s = s * 2 - 1\n  return jnp.sin(s * mean) * jnp.exp(-0.5 * s**2 * var)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to be in the range of the encoding.\n  # The scaling is chosen such that the mean and variance are encoded as 0 and 1, respectively.\n  scale_mean = 2.0 * jnp.pi / (max_deg - min_deg)\n  scale_var = scale_mean**2\n  scaled_mean = mean * scale_mean\n  scaled_var = var * scale_var\n\n  # Encode the scaled mean and variance using a sinusoidal function.\n  # The sinusoidal function is scaled by powers of 2, with the first degree being 2**0 = 1.\n  encoded_mean = jnp.sin(scaled_mean)\n  encoded_var = expected_sin(scaled_mean, scaled_var)\n\n  # Concatenate the encoded mean and variance to get the final output.\n  return jnp.concatenate([encoded_mean, encoded_var], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The 2**(-0.5) is the stddev of a 0-mean, unit-var Gaussian.\n  scale = 2 ** (mean / 2)\n  # The 2**(-0.5 * var) is the stddev of a 0-mean, var-var Gaussian.\n  shift = 2 ** (-0.5 * var)\n  # We use a 3D coordinate system to encode the mean and variance.\n  # The first two dimensions are the mean and variance,\n  # and the third dimension is the degree of the encoding.\n  # This is the encoding of the mean and variance.\n  enc_mean = jnp.concatenate(\n      [scale[..., jnp.newaxis], shift[..., jnp.newaxis]],\n      axis=-1)\n  # This is the encoding of the mean and variance,\n  # but with the first two dimensions swapped.\n  enc_var = jnp.concatenate(\n      [shift[..., jnp.newaxis], scale[..., jnp.newaxis]],\n      axis=-1)\n  # This is the encoding of the mean and variance.\n  enc_both = jnp.concatenate([enc_mean, enc_var], axis=-1)\n  # This is the encoding of the mean and variance,\n  # but with the first two dimensions swapped.\n  enc_both_swap = jnp.concatenate([enc_var, enc_mean], axis=-1)\n  # This is the encoding of the mean and variance,\n  # but with the first two dimensions swapped and the\n  # third dimension scaled by the degree.\n  enc_both_scaled = jnp.concatenate(\n      [enc_both_swap[..., jnp.newaxis],\n       enc_both[..., jnp.newaxis, jnp.newaxis]],\n      axis=-1)\n  # This is the encoding of the mean and variance,\n  # but with the first two dimensions swapped and the\n  # third dimension scaled by the degree.\n  enc_both_scaled_swap = jnp.concatenate(\n      [enc_both[..., jnp.newaxis, jnp.newaxis],\n       enc_both_swap[..., jnp.newaxis]],\n      axis=-1)"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance.\n  scaled_mean = mean * (2**max_deg)\n  scaled_var = var * (2**max_deg) ** 2\n  # Apply the sinusoidal encoding.\n  encoded = jnp.sin(scaled_mean)\n  # The Jacobian of the sinusoidal function is the encoding.\n  jacobian = jnp.cos(scaled_mean)\n  # The Jacobian is used to scale the variance.\n  jacobian_scaled_var = jacobian * (2**max_deg) ** 2\n  return jnp.concatenate((encoded, jacobian_scaled_var))\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # We use a sinusoidal encoding to encode the coordinates.\n  # We scale the mean and variance of the coordinates to ensure the encoding is\n  # not too large or small.\n  # We use the function from https://github.com/google/jax/issues/2922.\n  scale_fn = lambda x: 2 ** (\n      jnp.arange(min_deg, max_deg, dtype=jnp.float32))\n  scaled_mean = mean * scale_fn(1)\n  scaled_var = var * scale_fn(2)\n  return jnp.sin(scaled_mean), jnp.exp(-0.5 * scaled_var)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of two.\n  #\n  # Note that this is equivalent to the following:\n  #\n  #   mean_scaled = mean * 2**(min_deg:max_deg)\n  #   var_scaled = var * 2**(min_deg:max_deg)\n  #\n  # But this way is faster and more numerically stable.\n  #\n  # See https://jlaird.github.io/blog/2019/05/25/scaling-data-with-numpy/\n  # for an explanation.\n  #\n  # We'll use a log-scaled version of the scale factor to avoid numerical\n  # issues with floating-point overflow.\n  scale_factor = jnp.linspace(\n      jnp.log(2), jnp.log(2) * (max_deg - min_deg), num=max_deg - min_deg\n  )\n  mean_scaled = jnp.cumprod(jnp.exp(mean * scale_factor), axis=-1)\n  var_scaled = jnp.cumprod(jnp.exp(var * scale_factor), axis=-1)\n\n  # Apply the encoding.\n  return jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning the directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    de = sph_harms * jnp.exp(-sigma * kappa"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((ml_array.shape[1], ml_array.shape[0]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[i, k] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return directional_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n      raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n      raise ValueError('Only deg_view of at most 5 is numerically stable.')\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n      for k in range(l - m + 1):\n          mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n      \"\"\"Function returning directional encoding.\n\n      Args:\n          xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n      Returns:\n          An array with the resulting directional encoding.\n      \"\"\"\n      x = xyz[Ellipsis, 0:1]\n      y = xyz[Ellipsis, 1:2]\n      z = xyz[Ellipsis, 2:3]\n\n      # Compute z Vandermonde matrix.\n      vmz = jnp.concatenate([z ** i for i in range(mat.shape[0])], axis=-1)\n\n      # Compute x+iy Vandermonde matrix.\n      vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n      # Get spherical harmonics.\n      sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n      return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return directional_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n      raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n      for k in range(l - m + 1):\n          mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n      \"\"\"Function returning directional encoding.\n\n      Args:\n          xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n      Returns:\n          An array with the resulting directional encoding.\n      \"\"\"\n      x = xyz[Ellipsis, 0:1]\n      y = xyz[Ellipsis, 1:2]\n      z = xyz[Ellipsis, 2:3]\n\n      # Compute z Vandermonde matrix.\n      vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n      # Compute x+iy Vandermonde matrix.\n      vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n      # Get spherical harmonics.\n      sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n      # Return the directional encoding.\n      return sph_harms\n\n  return directional_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n      raise ValueError('Only deg_view of at most 5 is numerically stable.')\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n        xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n        kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n            Mises-Fisher distribution.\n\n    Returns:\n        An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    dir_enc = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(dir_enc), jnp.imag(dir_enc)], axis=-1)\n\n  return"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # This function returns a function that computes the directional encoding from\n  # Equations 6-8 of arxiv.org/abs/2112.03907.\n  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((ml_array.shape[1], ml_array.shape[0]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[i, k] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return directional_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 15:\n    raise ValueError('Only deg_view of at most 15 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the (x+iy) Vandermonde matrix,\n  # results in the (x+iy) component of the encoding.\n  mat_xy = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat_xy[k, i] = assoc_legendre_coeff(l, m, k)\n\n  def directional_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Create a list with all pairs of (l, m) values to use in the encoding.\n  ml_list = []\n  for i in range(deg_view):\n    l = 2**i\n    # Only use nonnegative m values, later splitting real and imaginary parts.\n    for m in range(l + 1):\n      ml_list.append((m, l))\n\n  # Convert list into a numpy array.\n  ml_array = np.array(ml_list).T\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  # Generate the function that computes the directional encoding.\n  def directional_encoding_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy *"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((2 * deg_view, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  # Compute the directional encoding function\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    dir_enc = sph_harms * jnp.exp(-sigma * kappa_inv)\n    return dir_enc\n\n  "}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n      raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((ml_array.shape[1], ml_array.shape[0]))\n  for i, (m, l) in enumerate(ml_array):\n    for k in range(l - m + 1):\n      mat[i, k] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n    \"\"\"Function returning directional encoding.\"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n    return sph_harms\n\n  return directional_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((ml_array.shape[1], ml_array.shape[0]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[i, k] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    return sph_harms\n\n  return directional_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([x + 1j * y, x - 1j * y], axis=-1)\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return directional_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 10:\n    raise ValueError('Only deg_view of at most 10 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_encoding_fn(xyz):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return directional_encoding_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # The number of spherical harmonics degrees to use.\n  # If deg_view is 5, we use up to 32 harmonics.\n  if deg_view > 5:\n    raise ValueError('deg_view must be less than 5.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_encoding_fn(xyz, kappa_inv):\n    \"\"\"Function returning the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Generate the integrated directional encoding function\n  ide_fn = generate_ide_fn(deg_view)\n\n  # Define the directional encoding function\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function to compute the directional encoding.\n\n    Args:\n        xyz: [..., 3] array of 3D points to evaluate the directional encoding at.\n\n    Returns:\n      [..., 2 * deg_view] array of directional encoding values.\n    \"\"\"\n    # Compute the integrated directional encoding\n    ide = ide_fn(xyz)\n\n    # Compute the directional encoding\n    return 0.5 * (ide + jnp.conjugate(ide))\n\n  return dir_enc_fn"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(lines)\n    lines = [line_parser.Line(line) for line in lines]\n    # print(lines)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row())\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    # print(lines[0].is_table_row)\n    #"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line.replace(\"\u2018\", \"\u2019\") for line in lines]\n    lines = [line.replace(\"\u2019\", \"\u2018\") for line in lines]\n\n    lines = [line.replace(\"\u2019\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2019\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n\n    lines = [line.replace(\"\u2019\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2019\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n\n    lines = [line.replace(\"\u2019\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2019\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line.replace(\"\u2018\", \"\u2018\") for line in lines]\n    lines = [line"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line for line in lines]\n    # remove empty lines\n    lines = [line for line in lines if line]\n\n    # remove duplicate lines\n    lines = list(set(lines))\n\n    # remove lines with only numbers\n    lines = [line for line in lines if not patterns.num_only.match(line)]\n\n    # remove lines with only numbers\n    lines = [line for line in lines if not patterns.num_only.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only punctuation\n    lines = [line for line in lines if not patterns.punctuation.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not patterns.whitespace.match(line)]\n\n    "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # TODO: Remove the xml argument\n    lines = list(map(str, lines))\n\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    # TODO: Remove the xml argument\n    "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # if xml:\n    #     lines = line_parser.xml_to_text(lines)\n    lines = [line_parser.Line(line) for line in lines]\n\n    # remove duplicate lines\n    lines = [line for line in lines if not line.is_duplicate()]\n\n    # remove empty lines\n    lines = [line for line in lines if not line.is_empty()]\n\n    # remove lines that are only whitespace\n    lines = [line for line in lines if not line.is_whitespace_only()]\n\n    # remove lines that are only punctuation\n    lines = [line for line in lines if not line.is_punctuation_only()]\n\n    # remove lines that are only numbers\n    lines = [line for line in lines if not line.is_number_only()]\n\n    # remove lines that are only numbers and punctuation\n    lines = [line for line in lines if not line.is_number_and_punctuation_only()]\n\n    # remove lines that are only numbers and text\n    lines = [line for line in lines if not line.is_number_and_text_only()]\n\n    # remove lines that are only numbers and text and punctuation\n    lines = [line for line in lines if not line.is_number_and_text_and_punctuation_only()]\n\n    # remove lines that are only numbers and text and punctuation\n    lines = [line for line in lines if not line.is_number_and_text_and_punctuation_only()]\n\n    # remove lines that are only numbers and text and punctuation\n    lines = [line for line in lines if not line.is_number_and_text_and_punctuation_only()]\n\n    # remove lines that are only numbers and text and punctuation\n    lines = [line for line in lines if not line.is_number_and_text_and_punctuation_only()]\n\n    # remove lines that are only numbers and text and punctuation\n    lines = [line for line in lines if not line.is_number_and_text_and_punctuation_only()]\n\n    # remove lines that are only numbers and text and punctuation\n    lines = [line for line in lines if not line.is_number_and_text_and_punctuation_only()]\n\n    # remove lines that are"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line for line in lines if not line.is_empty]\n\n    # if len(lines) == 0:\n    #     return []\n    #\n    # # clean lines\n    # lines = [line.clean() for line in lines]\n    #\n    # # remove empty lines\n    # lines = [line for line in lines if line.is_not_empty]\n    #\n    # # remove duplicate lines\n    # lines = [line for line in lines if line not in lines]\n    #\n    # # remove lines with only numbers\n    # lines = [line for line in lines if not line.is_all_numbers]\n    #\n    # # remove lines with only symbols\n    # lines = [line for line in lines if line.is_not_all_symbols]\n    #\n    # # remove lines with only whitespace\n    # lines = [line for line in lines if line.is_not_only_whitespace]\n    #\n    # # remove lines with only numbers and whitespace\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    #\n    # # remove lines with only whitespace and numbers\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    #\n    # # remove lines with only whitespace and numbers\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    #\n    # # remove lines with only whitespace and numbers\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    #\n    # # remove lines with only whitespace and numbers\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    #\n    # # remove lines with only whitespace and numbers\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    #\n    # # remove lines with only whitespace and numbers\n    # lines = [line for line in lines if line.is_not_only_numbers_and_whitespace]\n    "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if not lines:\n        return []\n\n    # initialize the result list\n    result = []\n\n    # initialize the current block\n    current_block = None\n\n    # initialize the previous line\n    previous_line = None\n\n    # initialize the previous block\n    previous_block = None\n\n    # initialize the previous block index\n    previous_block_index = 0\n    block_index = 1\n\n    # initialize the list of lists\n    list_of_lists = []\n\n    # initialize the list of lists counter\n    list_of_lists_counter = 0\n\n    # initialize the list of lists index\n    list_of_lists_index = 0\n    list_of_lists_index_counter = 0\n\n    # initialize the list of lists level\n    list_of_lists_level = 1\n\n    # initialize the list of lists index of the previous block\n    list_of_lists_previous_block_index = 0\n\n    # initialize the list of lists previous block\n    list_of_lists_previous_block = None\n\n    # initialize the list of lists previous line\n    list_of_lists_previous_line = None\n\n    # initialize the list of lists previous block index\n    list_of_lists_previous_block_index = 0\n\n    # initialize the list of lists previous block\n    list_of_lists_previous_block = None\n\n    # initialize the list of lists previous line\n    list_of_lists_previous_line = None\n\n    # initialize the list of lists index of the previous block\n    list_of_lists_previous_block_index = 0\n\n    # initialize the list of lists previous block\n    list_of_lists_previous_block = None\n\n    # initialize the list of lists previous line\n    list_of_lists_previous_line = None\n\n    # initialize the list of lists index of the previous block\n    list_of_lists_previous_block_index = 0\n\n    # initialize the list of lists previous block\n    list_of_lists_previous_block = None\n\n    # initialize the list of lists previous line\n    list_of_lists_previous_line = None\n\n    # initialize the list of lists index of the previous block\n    list_of"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(\"clean_lines: \", lines)\n    # check if the lines are of the same length\n    if not xml:\n        if not all([len(line) == len(lines[0]) for line in lines]):\n            return []\n\n    # remove duplicate lines\n    lines = list(dict.fromkeys(lines).keys())\n\n    # remove empty lines\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove blank lines\n    lines = [line for line in lines if line != \"\"]\n\n    # remove lines with only one character\n    lines = [line for line in lines if len(line) > 1]\n\n    # remove lines with only numbers\n    lines = [line for line in lines if not line.isnumeric()]\n\n    # remove lines with only numbers\n    lines = [line for line in lines if not line.isnumeric()]\n\n    # remove lines with only punctuation\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only whitespace\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n    # print(\"clean_lines: \", lines)\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n    # print(\"clean_lines: \", lines)\n\n    # remove lines with only spaces\n    lines = [line for line in lines if not line.isspace()]\n\n    "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # set up the result list\n    result = []\n    # initialize the current block\n    current_block = {\"type\": \"text\", \"text\": [], \"index\": 0, \"list\": None}\n\n    # process each line\n    for i, line in enumerate(lines):\n        # skip empty lines\n        if should_skip(line, xml):\n            continue\n\n        # if the line is a header, create a new block\n        if line.is_header():\n            current_block = {\n                \"type\": \"header\",\n                \"text\": [line.text],\n                \"index\": i,\n                \"list\": None,\n            }\n            result.append(current_block)\n            continue\n\n        # if the line is a list item, add it to the current block\n        if line.is_list_item():\n            # if the line is a new list, create a new block\n            if line.is_new_list():\n                current_block = {\n                    \"type\": \"list\",\n                    \"text\": [line.text],\n                    \"index\": i,\n                    \"list\": [line],\n                }\n                result.append(current_block)\n            # if the line is a continuation, add it to the current list\n            else:\n                current_block[\"list\"].append(line)\n            continue\n\n        # if the line is a table row, create a new block\n        if line.is_table_row():\n            current_block = {\n                \"type\": \"table\",\n                \"text\": [line.text],\n                \"index\": i,\n                \"list\": None,\n            }\n            result.append(current_block)\n            continue\n\n        # if the line is a new paragraph, create a new block\n        if line.is_new_paragraph():\n            current_block = {\"type\": \"text\", \"text\": [line.text], \"index\": i, \"list\": None}\n            result.append(current_block)\n            continue\n\n        # if the line is a continuation, add it to the current paragraph\n        current_block[\"text\"].append(line.text)\n\n    # if the current block is a paragraph, add it to the result"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line.strip() for line in lines]\n\n    # TODO: replace with line_parser.Line\n    # TODO: remove the is_table_row function\n    # TODO: remove the is_table_row function\n    # TODO: remove the is_table_row function\n\n    # Remove empty lines\n    lines = [line for line in lines if not should_skip(line, xml=xml)]\n\n    # Remove duplicate lines\n    lines = [line for line in lines if line not in lines[lines.index(line) + 1 :]]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Connect incomplete lines\n    for i in range(len(lines)):\n        if len(lines[i]) > 0 and len(lines[i]) < 3:\n            if i > 0:\n                lines[i - 1] = lines[i - 1] + \" \" + lines[i]\n                lines[i] = \"\"\n            else:\n                lines[i] = lines[i] + \" \"\n    lines = [line for line in lines if line != \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in lines if not line.strip() == \"\"]\n\n    # Remove lines with only punctuation\n    lines = [line for line in"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [x for x in lines if not should_skip(x, xml=xml)]\n\n    # 1. Remove duplicate lines\n    lines = [x for x, y in Counter(lines).items() if y == 1]\n\n    # 2. Remove lines with only numbers\n    lines = [x for x in lines if not re.match(r\"^\\d+$\", x)]\n\n    # 3. Remove lines with only whitespace\n    lines = [x for x in lines if not re.match(r\"^\\s+$\", x)]\n\n    # 4. Fix spaced characters\n    lines = [re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", x) for x in lines]\n\n    # 5. Remove lines with only spaced characters\n    lines = [x for x in lines if not re.match(r\"^\\s\\s+$\", x)]\n\n    # 6. Connect incomplete lines\n    lines = [\n        line + \" \" + line2\n        for line, line2 in zip(lines, lines[1:])\n        if line[-1] == \".\" and line2.startswith(\" \")\n    ]\n\n    # 7. Remove lines with only spaced characters\n    lines = [x for x in lines if not re.match(r\"^\\s\\s+$\", x)]\n\n    # 8. Remove lines with only spaced characters\n    lines = [x for x in lines if not re.match(r\"^\\s\\s+$\", x)]\n\n    # 9. Split lines with newlines\n    lines = [x for x in lines if not re.match(r\"^(.*\\n.*)$\", x)]\n\n    # 10. Remove lines with only spaced characters\n    lines = [x for x in lines if not re.match(r\"^\\s\\s+$\", x)]\n\n    # 11. Remove lines with only spaced characters\n    lines = [x for x in lines if not re.match(r\"^\\s\\s+$\", x)]\n\n    # 12. Split lines with newlines\n    lines = [x for x in lines if not re.match(r\"^(.*\\n.*)$\", x)]\n\n    # 1"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # tokenize the lines\n    lines = [nlm_tokenize(line) for line in lines]\n\n    # add the line metadata\n    lines = [\n        line_parser.Line(line, xml=xml) for line in lines if not should_skip(line, xml=xml)\n    ]\n\n    # create a list of lines that are tables\n    table_lines = [line for line in lines if line.is_table_row]\n\n    # create a list of lines that are not tables\n    non_table_lines = [line for line in lines if not line.is_table_row]\n    # if there are no non-table lines, return the table lines\n    if not non_table_lines:\n        return table_lines\n\n    # remove duplicate lines\n    non_table_lines = [\n        line for line in non_table_lines if not line.is_duplicate\n    ]\n    # if there are no non-table lines, return the table lines\n    if not non_table_lines:\n        return table_lines\n\n    # create a list of lines that are headers\n    header_lines = [line for line in non_table_lines if line.is_header]\n    # if there are no header lines, return the table lines\n    if not header_lines:\n        return table_lines\n\n    # create a list of lines that are not headers\n    non_header_lines = [line for line in non_table_lines if not line.is_header]\n\n    # if there are no non-header lines, return the table lines\n    if not non_header_lines:\n        return table_lines\n\n    # remove lines that are floating characters\n    non_header_lines = [\n        line for line in non_header_lines if not find_floating_chars(line.text)\n    ]\n\n    # remove lines with no content\n    non_header_lines = [line for line in non_header_lines if line.has_content]\n\n    # create a list of lines that are paragraphs\n    paragraph_lines = [line for line in non_header_lines if line.is_paragraph]\n\n    # if there are no paragraph lines, return the table lines\n    if not paragraph_lines:"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line_parser.Line(line) for line in lines]\n\n    # remove duplicate lines\n    lines = [line for line in lines if not line.is_duplicate]\n\n    # fix spaced characters\n    lines = [line for line in lines if not find_floating_chars(line.text)]\n\n    # connect incomplete lines\n    lines = line_parser.join_incomplete_lines(lines)\n\n    # create blocks\n    blocks = [\n        line_parser.Block(line) for line in lines if not is_table_row(line.text)\n    ]\n\n    # remove empty blocks\n    blocks = [block for block in blocks if not block.is_empty]\n    if xml:\n        # remove empty blocks\n        blocks = [block for block in blocks if not block.is_empty]\n\n        # remove empty lines\n        blocks = [block for block in blocks if not block.is_line_empty]\n\n    # remove blank lines\n    blocks = [block for block in blocks if not block.is_blank]\n\n    # remove lines that are not of interest\n    blocks = [block for block in blocks if not should_skip(block.text, xml)]\n\n    # remove duplicate blocks\n    blocks = [block for block in blocks if not block.is_duplicate]\n\n    # remove lines that are just numbers\n    blocks = [\n        block\n        for block in blocks\n        if not (block.is_number and not block.is_number_and_text)\n    ]\n\n    # connect blocks\n    blocks = line_parser.join_blocks(blocks)\n\n    # remove blocks that are just numbers\n    blocks = [block for block in blocks if not block.is_number_and_text]\n    blocks = [block for block in blocks if not block.is_number]\n\n    # remove duplicate blocks\n    blocks = [block for block in blocks if not block.is_duplicate]\n\n    # remove empty blocks\n    blocks = [block for block in blocks if not block.is_empty]\n\n    # remove empty lines\n    blocks = [block for block in blocks if not block.is_line_empty]\n\n    # remove blank lines\n    blocks = [block for block in blocks if not block."}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line for line in lines if not should_skip(line, xml)]\n    if len(lines) == 0:\n        return []\n\n    # remove duplicate lines\n    lines = [line for line in lines if not line.is_duplicate_line()]\n\n    # fix spaced characters\n    lines = [line.fix_spaced_chars() for line in lines]\n\n    # connect incomplete lines\n    lines = [line.connect_incomplete_lines() for line in lines]\n\n    # categorize lines into paragraphs, headers, and list items\n    blocks = []\n    block_index = 0\n    block_type = \"paragraph\"\n    block_start_index = 0\n    block_list = []\n    block_list_level = 0\n    for i, line in enumerate(lines):\n        if line.is_paragraph():\n            if block_type == \"header\" and line.is_header():\n                # if we are in a header block and we encounter a paragraph, we have to close the header\n                blocks.append(\n                    {\n                        \"index\": block_index,\n                        \"text\": \"\\n\".join(block_list),\n                        \"type\": block_type,\n                        \"start_index\": block_start_index,\n                        \"list\": block_list,\n                        \"header\": block_index,\n                    }\n                )\n                block_list = []\n                block_type = \"paragraph\"\n                block_start_index = i\n\n            if not block_type == \"paragraph\":\n                # if we are not in a paragraph block, we need to create a new block\n                block_index += 1\n                blocks.append(\n                    {\n                        \"index\": block_index,\n                        \"text\": \"\\n\".join(block_list),\n                        \"type\": block_type,\n                        \"start_index\": block_start_index,\n                        \"list\": block_list,\n                        \"header\": block_index,\n                    }\n                )\n                block_list = []\n                block_start_index = i\n            block_list.append(line)\n        elif line.is_header():\n            block_list.append(line)\n            block_type ="}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line_parser.Line(line) for line in lines]\n    # lines = [line_parser.Line(line) for line in lines if not line.is_blank()]\n    # lines = [line for line in lines if not line.is_blank()]\n    lines = [line for line in lines if not line.is_blank()]\n    # lines = [line_parser.Line(line) for line in lines if not line.is_blank()]\n    lines = [line for line in lines if not line.is_blank()]\n    lines = [line for line in lines if not line.is_table_row]\n\n    # remove duplicate lines\n    lines = [line for i, line in enumerate(lines) if line not in lines[i + 1 :]]\n\n    # connect incomplete lines\n    lines = connect_incomplete(lines)\n\n    # remove duplicate lines\n    lines = [line for i, line in enumerate(lines) if line not in lines[i + 1 :]]\n\n    # categorize lines\n    blocks = []\n\n    # add first line\n    blocks.append(line_parser.Line(lines.pop(0)))\n    # for line in lines:\n    for i, line in enumerate(lines):\n        if line.is_header:\n            blocks.append(line)\n            continue\n        if line.is_list:\n            blocks[-1].list_items.append(line)\n            continue\n        if line.is_indented:\n            blocks[-1].indented_text.append(line)\n            continue\n        if line.is_table_row:\n            blocks[-1].table_rows.append(line)\n            continue\n\n        # if line.is_empty:\n        #     continue\n        if line.is_blank:\n            blocks[-1].text.append(line)\n        else:\n            blocks.append(line)\n\n    # remove duplicate lines\n    blocks = [block for i, block in enumerate(blocks) if block not in blocks[i + 1 :]]\n\n    # remove empty blocks\n    blocks = [block for block in blocks if block.text or block.indented_text or block.list_items]\n\n    return"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line_parser.Line(line) for line in lines]\n\n    # remove duplicate lines\n    lines = [line for line in lines if not line.is_duplicate()]\n\n    # remove empty lines\n    lines = [line for line in lines if not line.is_empty()]\n\n    # fix spaced characters\n    lines = [line for line in lines if not find_floating_chars(line)]\n\n    # connect incomplete lines\n    lines = connect_incomplete_lines(lines)\n\n    # categorize lines\n    blocks = categorize_lines(lines)\n\n    return blocks\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if xml:\n        lines = [line.strip() for line in lines]\n    else:\n        lines = [line.lstrip() for line in lines]\n\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if not line.startswith(\"  \")]\n\n    # Remove duplicate lines\n    lines = [line for line in lines if not line.isdigit() or not line.startswith(\"1\")]\n\n    # Remove empty lines\n    lines = [line for line in lines if line]\n\n    # Fix spaced characters\n    lines = [line.replace(\"  \", \" \") for line in lines]\n    lines = [line.replace(\"  \", \" \") for line in lines]\n    lines = [line.replace(\"  \", \" \") for line in lines]\n    lines = [line.replace(\"  \", \" \") for line in lines]\n    lines = [line.replace(\"  \", \" \") for line in lines]\n    lines = [line.replace(\"  \", \" \") for line in lines]\n\n    # Split lines into blocks\n    blocks = []\n\n    # Handle empty lines\n    if len(lines) == 0:\n        blocks.append({\n            \"text\": lines,\n            \"type\": \"text\",\n            \"index\": 0,\n            \"list_index\": 0,\n            \"header_index\": 0,\n        })\n        return blocks\n\n    # Handle headers\n    # If the first line is a header, make it a header block\n    if lines[0].isupper():\n        blocks.append({\n            \"text\": lines[0],\n            \"type\": \"header\",\n            \"index\": 0,\n            \"list_index\": 0,\n            \"header_index\": 0,\n        })\n\n    # If the first line is a header, remove it from the list of lines\n    if lines[0].isupper():\n        lines = lines[1:]\n\n    # If the first line is a list item, make it a list item block\n    if lines[0].islower():\n        blocks.append({\n            \"text\": lines[0],\n            \"type\": \"list_item\",\n            \"index\": 0,"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if not lines:\n        return []\n    result = []\n    lines = [line_parser.Line(line) for line in lines]\n\n    # remove duplicate lines\n    lines = [line for i, line in enumerate(lines) if not line.is_duplicate()]\n\n    # fix spaced characters\n    lines = [line_parser.Line(line) for line in lines]\n    # print(lines)\n    # print(lines)\n    for i in range(len(lines)):\n        if lines[i].is_spaced_char():\n            if i > 0:\n                lines[i - 1].join_line(lines[i])\n            else:\n                lines[i].join_line(lines[i + 1])\n    lines = [line.text for line in lines if line.is_spaced_char()]\n    # print(lines)\n\n    # connect incomplete lines\n    # print(lines)\n    for i in range(len(lines) - 1):\n        if lines[i].is_incomplete() and lines[i + 1].is_incomplete():\n            lines[i].join_line(lines[i + 1])\n    lines = [line.text for line in lines if line.is_incomplete()]\n    # print(lines)\n\n    # categorize lines\n    for i in range(len(lines)):\n        if lines[i].is_paragraph():\n            # if the line is a paragraph, it is added to the result list\n            result.append(\n                {\n                    \"text\": lines[i].text,\n                    \"type\": lines[i].type,\n                    \"index\": i,\n                    \"list\": [],\n                    \"header\": None,\n                    \"indent\": 0,\n                }\n            )\n            # the line is removed from the lines list\n            lines.pop(i)\n            # the loop is reset to start at the new index\n            i = -1\n        elif lines[i].is_header():\n            # if the line is a header, it is added to the result list\n            result.append(\n                {\n                    \"text\": lines[i].text,\n                    \"type\": lines[i].type,\n                    "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    i = 0\n    current_block_type = \"paragraph\"\n    current_block_index = 0\n    current_block_text = \"\"\n    current_block_list = []\n    current_header_index = -1\n    current_indent = 0\n    current_list_indent = 0\n    while i < len(lines):\n        # if the line is a table row, skip it\n        if is_table_row(lines[i]):\n            i += 1\n            continue\n        # if the line is a new paragraph,\n        if (\n            (\n                not current_block_text\n                or not should_skip(current_block_text, xml)\n                or current_block_type == \"header\"\n                or (\n                    current_block_type == \"paragraph\"\n                    and current_block_text.endswith(\".\")\n                    and not current_block_text.endswith(\"!\")\n                    and not current_block_text.endswith(\"?\")\n                )\n            )\n            and not should_skip(lines[i], xml)\n            and not find_floating_chars(lines[i])\n        ):\n            # if the line is a header,\n            if lines[i].startswith(\"1.\"):\n                current_block_type = \"header\"\n                current_block_index = 1\n                current_block_text = lines[i].strip()\n                current_header_index = len(result)\n            # if the line is a paragraph,\n            else:\n                current_block_type = \"paragraph\"\n                current_block_index += 1\n                current_block_text = lines[i].strip()\n                current_header_index = -1\n                current_block_list = []\n            # if the line is a list item,\n        elif lines[i].startswith(\"*\") or lines[i].startswith(\"1.\"):\n            current_block_type = \"list\"\n            current_block_index += 1\n            current_block_text = lines[i].lstrip(\"*\")\n            current_block_list.append(current_block_text)\n            current_header_index = -1\n            current_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines_cleaned = []\n    lines_index = 0\n    current_block = []\n    blocks = []\n    current_block_type = None\n    current_block_index = 0\n    current_list_level = 0\n    current_list_index = 0\n    current_list_block_index = 0\n\n    # TODO: implement xml-specific rules\n    if xml:\n        pass\n        # TODO:\n        # - add a flag to the line to indicate it is xml\n    else:\n        for line in lines:\n            line = line.strip()\n            if should_skip(line):\n                continue\n\n            # if there is a list and we have a new line, we need to check if the new line is a new list item\n            if line.startswith(\"\u2022\") or line.startswith(\"1.\"):\n                if current_list_level == 0:\n                    current_list_level = 1\n                    current_list_index = len(blocks)\n                elif current_list_level > 0:\n                    current_list_level += 1\n                    current_list_index = len(blocks)\n\n                # if the list item is not a number, it is a list item with a header\n                if not line.startswith(\"1.\"):\n                    current_list_level = 2\n                    current_list_index = len(blocks)\n            elif current_list_level > 0:\n                current_list_level -= 1\n                current_list_index = 0\n\n            # if the line is a new header, add the current block to the list of blocks\n            if is_header(line):\n                if current_block_type == \"header\":\n                    current_block_index += 1\n                else:\n                    blocks.append(\n                        {\n                            \"text\": current_block,\n                            \"type\": current_block_type,\n                            \"index\": current_block_index,\n                            \"list\": current_list_block_index,\n                            \"list_level\": current_list_level,\n                            \"list_index\": current_list_index,\n                        }\n                    )\n                    current_block_type = \"header\"\n                    current_"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n    else:\n        # Normalize quotation marks\n        org_texts = quotation_pattern.sub(r' ', org_texts)\n\n        # Remove punctuations at the beginning of the text\n        org_texts = space_rule.sub(r'\\1', org_texts)\n\n        # Tokenize the text\n        org_texts = nltk_tokenzier.tokenize(org_texts)\n\n        # Normalize abbreviations\n        for abb_rule, abb_replaced in rules:\n            org_texts = abb_rule.sub(abb_replaced, org_texts)\n        return org_texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return [org_texts]\n    else:\n        org_texts = org_texts.replace(\"\\n\\n\", \" \")\n        org_texts = org_texts.replace(\"\\n\", \" \")\n        org_texts = quotation_pattern.sub(r' ', org_texts)\n        org_texts = space_rule.sub(r'\\1', org_texts)\n        org_texts = bracket_rule.sub(r' \\1 ', org_texts)\n        org_texts = ''.join(rules[0][1].sub(rule, org_texts) for rule in rules)\n        return nltk_tokenzier.tokenize(org_texts)"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if len(org_texts) == 0 or org_texts is None:\n        return org_texts\n\n    # Normalize quotation marks\n    norm_texts = quotation_pattern.sub(r' ', org_texts)\n\n    # Tokenize the sentences\n    sentences = nltk_tokenzier.tokenize(norm_texts)\n\n    # Normalize the sentences\n    for abb in abb_rules:\n        for abb_rule, abb_replaced in abb:\n            sentences = abb_rule.sub(abb_replaced, sentences)\n\n    # Normalize the sentences\n    for abb in bracket_rule:\n        for abb_rule, abb_replaced in abb:\n            sentences = abb_rule.sub(abb_replaced, sentences)\n\n    # Normalize the sentences\n    for abb in space_rule:\n        for abb_rule, abb_replaced in abb_rule:\n            sentences = abb_rule.sub(abb_replaced, sentences)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if len(org_texts) == 0:\n        return [org_texts]\n\n    # normalize quotation marks\n    normalized_text = quotation_pattern.sub(r' ', org_texts)\n\n    # tokenized sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(normalized_text)\n\n    # apply rules\n    for rule, repl in rules:\n        tokenized_sentences = [\n            rule.sub(repl, sent) for sent in tokenized_sentences\n        ]\n\n    # apply bracket rule\n    tokenized_sentences = [bracket_rule.sub(r' \\1', sent) for sent in tokenized_sentences]\n\n    # apply space rule\n    tokenized_sentences = [\n        space_rule.sub(r'\\1', sent) for sent in tokenized_sentences\n    ]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # replace the special abbreviations\n    for abb, repl in rules:\n        org_texts = abb.sub(repl, org_texts)\n\n    # replace quotation marks\n    org_texts = quotation_pattern.sub(r\"\\1\", org_texts)\n\n    # remove all spaces before punctuations\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # remove spaces before parenthesis\n    org_texts = bracket_rule.sub(r\"\\1\", org_texts)\n\n    # tokenization\n    return nltk_tokenzier.tokenize(org_texts)"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function\n    if org_texts == \"\" or org_texts is None:\n        return org_texts\n    else:\n        text = org_texts\n\n        # remove quotation marks\n        text = quotation_pattern.sub(\" \", text)\n\n        # remove punctuations at the start of the text\n        text = space_rule.sub(r\"\\1\", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations at the end of the text\n        text = space_rule.sub(r\"\\1\", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in the middle of the text\n        text = space_rule.sub(r\" \", text)\n\n        # remove punctuations in"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function\n    if not org_texts:\n        return org_texts\n    text = org_texts\n    # Normalize punctuations\n    text = quotation_pattern.sub(r' ', text)\n\n    # Tokenize sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # Normalize punctuations in the beginning of sentences\n    for i, sentence in enumerate(sentences):\n        sentence = space_rule.sub(r' \\1', sentence)\n        sentences[i] = sentence\n\n    # Normalize brackets\n    for i, sentence in enumerate(sentences):\n        sentence = bracket_rule.sub(r' \\1', sentence)\n        sentences[i] = sentence\n\n    # Normalize abbreviations\n    for abb_rule in rules:\n        sentences = abb_rule[0].sub(abb_rule[1], sentences)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return [org_texts]\n    # remove punctuations\n    org_texts = org_texts.replace(\"\\n\", \" \")\n    org_texts = org_texts.replace(\"  \", \" \")\n\n    # remove quotation marks\n    org_texts = quotation_pattern.sub(r'', org_texts)\n    # remove punctuations\n    org_texts = space_rule.sub(r'\\1', org_texts)\n    # tokenize the text into sentences\n    sent_list = nltk_tokenzier.tokenize(org_texts)\n    # handle sentences with brackets\n    for abb in rules:\n        sent_list = [abb[0].sub(abb[1], sent) for sent in sent_list]\n    return sent_list"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # Remove punctuations in the beginning of the text\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks\n    sentences = [quotation_pattern.sub(r'\u201c', sentence) for sentence in sentences]\n\n    # Normalize apostrophes\n    sentences = [sentence.replace(\"\u2019s\", \"'s\") for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Remove punctuations in the beginning of the text\n    sentences = space_rule.sub(r\"\\1\", sentences)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(sentences)\n\n    # Normalize abbreviations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb["}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function\n    #  1. Normalize the text by replacing the punctuations with space\n    org_texts = quotation_pattern.sub(' ', org_texts)\n    #  2. Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    #  3. Iterate over the sentences\n    for sent in sentences:\n        #  3.1. Replace any special abbreviations\n        for rule, repl in rules:\n            sent = rule.sub(repl, sent)\n        #  3.2. Remove any space between punctuations\n        sent = space_rule.sub(repl, sent)\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function.\n    # Hint: Use rege.findall() to find all matches in the text.\n\n    # If the text is empty or None, return the input as is\n    if org_texts is None or len(org_texts) == 0:\n        return [org_texts]\n\n    # Normalize quotation marks\n    normalized_text = quotation_pattern.sub(r\"\\1\", org_texts)\n\n    # Remove any space before punctuations\n    normalized_text = space_rule.sub(r\"\\1\", normalized_text)\n\n    # Tokenize the text\n    sentences = nltk_tokenzier.tokenize(normalized_text)\n\n    # Normalize abbrevations\n    for abb in rules:\n        sentences = [abb[0].sub(abb[1], sentence) for sentence in sentences]\n\n    # Handle brackets\n    sentences = [bracket_rule.sub(r\"(\\1)\", sentence) for sentence in sentences]\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n    else:\n        text = org_texts.replace(r\"\\n\", \" \")\n        text = quotation_pattern.sub(r' \u201c ', text)\n        for abb in abbs:\n            text = abb.replace(f\"{abb}.\", abb)\n            text = abb.replace(f\" {abb}.\", abb)\n        text = abb.replace(f\"{abb}. \", abb)\n        text = abb.replace(f\"{abb}.\", abb)\n        text = abb.replace(f\"{abb}. \", abb)\n        text = abb.replace(f\" {abb}. \", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\"{abb}\", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\" {abb} \", abb)\n        text = abb.replace(f\"{abb} \", abb)\n        text = abb.replace(f\"{abb} \", abb)\n\n        text = abb.replace(f\"{abb}\", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\"{abb} \", abb)\n        text = abb.replace(f\" {abb} \", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\"{abb} \", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\"{abb} \", abb)\n\n        text = abb.replace(f\"{abb}.\", abb)\n        text = abb.replace(f\" {abb}.\", abb)\n        text = abb.replace(f\"{abb}. \", abb)\n        text = abb.replace(f\" {abb}. \", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\"{abb}\", abb)\n        text = abb.replace(f\" {abb}\", abb)\n        text = abb.replace(f\" {abb} \", abb)\n        text = abb.replace"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function.\n    #  You may use regextract or regextractall to extract substrings that match the patterns.\n    #  You may also use regextractall to replace the substrings that match the regextract pattern with regextractall's second argument.\n    #  You may also use regextractall to extract substrings that match regextractall's regextract pattern.\n    #  You may use regextractall to replace regextractall's regextract pattern with regextractall's regextract replacement.\n    #  You may use regextractall to extract substrings that regextract regextractall's regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regextract regext"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function\n\n    if not org_texts:\n        return org_texts\n\n    # Normalize the quotation marks\n    # org_texts = org_texts.replace('\u201d', '\"').replace('\u201c', '\"').replace(\"\u2019\", \"'\").replace(\"\u2018\", \"'\")\n\n    # Normalize the punctuations at the beginning of the text\n    org_texts = re.sub(r\"([.'](?:\\s|$|\\D))\", r\"\\1\", org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize the sentences\n    for abb in rules:\n        sentences = [re.sub(abb[0], abb[1], sent) for sent in sentences]\n\n    # Normalize the sentences\n    sentences = [re.sub(bracket_rule, r' \\1', sent) for sent in sentences]\n\n    # Normalize the sentences\n    sentences = [re.sub(quotation_pattern, r' \\1', sent) for sent in sentences]\n\n    # Normalize the sentences\n    sentences = [re.sub(space_rule, r'\\1', sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not isinstance(org_texts, str):\n        return org_texts\n\n    org_texts = org_texts.replace(\"\\n\", \". \")\n    org_texts = org_texts.replace(\".\", \". \")\n\n    # handling brackets\n    if bracket_rule.search(org_texts) is not None:\n        org_texts = bracket_rule.sub(r\" \\g<1>\", org_texts)\n\n    # handling quotation marks\n    org_texts = quotation_pattern.sub(r' \" ', org_texts)\n\n    # handling punctuations\n    org_texts = space_rule.sub(r'\\g<1>', org_texts)\n\n    # handling abbbreviations\n    for abb_rule in rules:\n        org_texts = abb_rule[0].sub(abb_rule[1], org_texts)\n\n    # handling punctuations\n    org_texts = space_rule.sub(r'\\g<1>', org_texts)\n    org_texts = nltk_tokenzier.tokenize(org_texts)\n    if not org_texts:\n        return org_texts\n\n    return [org_texts[0]]"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function\n    #  You may use abrbr_rules, bracket_rule, space_rule, quotation_pattern, and nltk_tokenizer\n    if not org_texts:\n        return org_texts\n\n    # abrbr_rules = []\n    # abrbr_rules.append((re.compile(r\"^(?:\\s*\\d+\\s*:\\s*)?\", re.IGNORECASE), \" \")\n    # abrbr_rules.append((re.compile(r\"\\s+\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\", re.IGNORECASE), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules.append((re.compile(r\"\\s{2,}\"), \" \"))\n\n    # abrbr_rules"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Implement the function\n    # TODO: Make sure to return the original input if the input is empty or None\n    if not org_texts:\n        return org_texts\n\n    # TODO: Normalize quotation marks in the text\n    # TODO: Tokenize the text into sentences\n    # TODO: Handle special cases such as paragraphs separated by new lines, punctuation at the beginning of the text, and ensuring that sentences within brackets are not broken.\n    # TODO: Return the tokenized sentences\n\n    org_texts = org_texts.replace(\"\u2019\", \"'\")\n    org_texts = org_texts.replace('\u201c', '\"')\n    org_texts = org_texts.replace('\u201d', '\"')\n    org_texts = org_texts.replace('\u2018', \"'\")\n    org_texts = org_texts.replace('\u2019', '\"')\n    org_texts = org_texts.replace('\u201c', '\"')\n    org_texts = org_texts.replace('\u201d', '\"')\n    org_texts = org_texts.replace('\u2018', '\"')\n    org_texts = org_texts.replace('\u2019', '\"')\n    org_texts = org_texts.replace(\"\u2019\", \"'\")\n    org_texts = org_texts.replace('\u201c', '\"')\n    org_texts = org_texts.replace('\u201d', '\"')\n    org_texts = org_texts.replace('\u2018', \"'\")\n    org_texts = org_texts.replace('\u2019', '\"')\n    org_texts = org_texts.replace('\u201c', '\"')\n    org_texts = org_texts.replace('\u201d', '\"')\n\n    # TODO: Return the tokenized sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # TODO: Handle special cases such as paragraphs separated by new lines, punctuation at the beginning of the text, and ensuring that sentences within brackets are not broken.\n    for abb_rule in rules:\n        sentences = [abb_rule[0].sub(abb_rule[1], sent) for sent in sentences]\n\n    for abb_rule in rules:\n        sentences = [abb_rule[0].sub(abb_rule[1], sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # TODO: Implement the function\n    #  1. Tokenize the text using the nltk_tokenzier\n    #  2. Normalize the sentences by applying the rules\n    #  3. Return the list of normalized sentences\n    #  4. If the text is empty, return the text as it is\n\n    # TODO: Tokenize the text using the nltk_tokenzier\n    texts = nltk_tokenzier.tokenize(org_texts)\n\n    # TODO: Normalize the sentences by applying the rules\n    for abb_rule in rules:\n        texts = [abb_rule[0].sub(abb_rule[1], text) for text in texts]\n    texts = [space_rule.sub(r'\\1', text) for text in texts]\n    texts = [bracket_rule.sub(r'()', text) for text in texts]\n\n    # TODO: Return the list of normalized sentences\n    texts = [quotation_pattern.sub(r'\u201c\u201d', text) for text in texts]\n    texts = [quotation_pattern.sub(r'\u201c\u201d', text) for text in texts]\n    texts = [quotation_pattern.sub(r\"\u2018' \", text) for text in texts]\n    texts = [quotation_pattern.sub(r\"\u2018' \", text) for text in texts]\n    return texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return [org_texts]\n\n    # Normalize the quotation marks\n    org_texts = quotation_pattern.sub(\" \", org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize the punctuations at the beginning of the sentence\n    for i, sentence in enumerate(sentences):\n        sentences[i] = space_rule.sub(r'\\1', sentence)\n\n    # Handle the special cases\n    for abb, abb_replacement in rules:\n        for i, sentence in enumerate(sentences):\n            sentences[i] = abb_replacement.join(abb.findall(sentence))\n\n    # Handle the cases where the sentence is inside brackets\n    for i, sentence in enumerate(sentences):\n        sentences[i] = bracket_rule.sub(r'\\1', sentence)\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # TODO: Tokenize the text into sentences\n    # TODO: Handle the following cases:\n        # 1. Handle paragraphs separated by new lines\n        # 2. Handle punctuation at the beginning of the text\n        # 3. Handle sentences within brackets\n        # 4. Handle quotation marks within the text\n    if org_texts is None or org_texts == \"\":\n        return org_texts\n    sentences = nltk_tokenzier.tokenize(org_texts)\n    sentences = [sentence.lstrip().rstrip() for sentence in sentences]\n\n    for abb in rules:\n        sentences = [abb[1].join(abb[0].findall(sentence)) for sentence in sentences]\n    for abb in rules:\n        sentences = [abb[1].join(abb[0].findall(sentence)) for sentence in sentences]\n    sentences = [sentence.rstrip() for sentence in sentences]\n    sentences = [sentence.replace(\"  \", \" \") for sentence in sentences]\n    sentences = [sentence.lstrip() for sentence in sentences]\n\n    return sentences\n\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                return [self.posns.positions(term_id, doc_id=key)]\n            else:\n                return [self.posns.positions(term_id)]\n\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n        else:\n            try:\n                return self.posns.positions(self.term_dict.get_term_id(token),\n                                           doc_id=key)\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if key is None:\n            return self.posns.positions(term=token)\n        else:\n            return self.posns.positions(term=token, doc_id=key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if isinstance(token, list):\n            return [self.positions(token[0]) for token in token]\n        term_id = self.term_dict.get_term_id(token)\n        if key is None:\n            positions_list = self.posns.positions(term_id)\n        else:\n            positions_list = self.posns.positions(term_id, key)\n\n        return positions_list\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str) and not isinstance(token, list):\n            raise TypeError(\"Expected a string or list of strings for tokens\")\n\n        if isinstance(token, list):\n            positions = self.phrase_positions(token, key=key)\n            return positions\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            positions = self.posns.termpositions(term_id, key=key)\n            return positions\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return self.posns.positions(self.term_dict.get_term(self.term_dict.get_term_id(token)))\n        else:\n            try:\n                return self.posns.positions(self.term_dict.get_term(self.term_dict.get_term_id(token)), key)\n            except TermMissingError:\n                return []\n            except ValueError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if isinstance(token, list):\n            raise ValueError(\"Cannot retrieve positions for phrases. Use `phrase_positions` instead.\")\n\n        try:\n            posns = self.posns.positions(self.term_dict.get_term_id(token), doc_id=key)\n            return posns\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                # Get the positions for a specific document\n                return [self.posns.posns(term_id, key)]\n            else:\n                # Get the positions for all documents\n                return self.posns.posns(term_id)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            term_id = self.term_dict.get_term_id(token)\n            doc_freqs, term_freqs = self.posns.termfreqs(term_id,\n                                                         doc_ids=self.term_mat.rows)\n            return [doc_freqs]\n        else:\n            # Get the document id\n            doc_id = self.term_mat.rows[key]\n            term_id = self.term_dict.get_term_id(token)\n            doc_freqs, term_freqs = self.posns.termfreqs(term_id,\n                                                         doc_ids=[doc_id])\n            return [doc_freqs]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n\n        # We're searching within a single document\n        try:\n            doc_id = self.term_mat.rows[key]\n            doc_id += 1\n            return self.posns.positions(self.term_dict.get_term_id(token), doc_id=doc_id)\n        except IndexError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n\n        if key is not None:\n            if isinstance(key, list):\n                if isinstance(key[0], numbers.Integral):\n                    key = [self.term_mat.rows[key]]\n                else:\n                    key = key[0]\n            elif not isinstance(key, numbers.Integral):\n                raise TypeError(\n                    \"Expected a list of ints or a single int for the key\")\n            elif key < 0:\n                key += len(self)\n\n        if self.term_mat.subset:\n            if key is not None:\n                # We've already done this\n                return self.posns.term_posns(self.term_dict.get_term_id(token))\n            else:\n                posns = []\n                for doc_id in self.term_mat.rows:\n                    posns.append(self.posns.term_posns(self.term_dict.get_term_id(token),\n                                                       doc_id=doc_id))\n                return posns\n\n        if key is not None:\n            # We've already done this\n            return self.posns.term_posns(self.term_dict.get_term_id(token), doc_id=key)\n        else:\n            posns = []\n            for doc_id in self.term_mat.rows:\n                posns.append(self.posns.term_posns(self.term_dict.get_term_id(token),\n                                                   doc_id=doc_id))\n            return posns\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, doc_id=key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        try:\n            if key is not None:\n                return self.posns.positions(self.term_dict.get_term_id(token),\n                                            key=key)\n            else:\n                return [self.posns.positions(self.term_dict.get_term_id(token),\n                                             key=key) for key in self.term_mat.rows]\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            positions = self.posns.positions(self.term_dict.get_term_id(token))\n        else:\n            key = self.doc_ids[key]\n            positions = [self.posns.positions(self.term_dict.get_term_id(token), key=key)]\n\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Get the term id\n        if key is not None:\n            if not isinstance(key, int):\n                raise ValueError(\n                    \"Key must be an integer, got {}\".format(type(key)))\n            # If the term is not in the doc, return empty array\n            try:\n                term_id = self.term_dict.get_term_id(token)\n            except TermMissingError:\n                return []\n\n            # Get the positions for the term in the doc\n            return [self.posns[term_id][key]]\n        else:\n            # Get the term id\n            try:\n                term_id = self.term_dict.get_term_id(token)\n            except TermMissingError:\n                return []\n            # Get the positions for the term in all docs\n            return [self.posns[term_id]]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [self.posns.get_positions(self.term_dict.get_term_id(token), key=key)]\n        else:\n            return [self.posns.get_positions(self.term_dict.get_term_id(token), key=None)]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # This is a bit of a hack.\n        # We're assuming we have a single term\n        if isinstance(token, list):\n            raise ValueError(\"Positions is not implemented for phrases\")\n\n        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n\n        # If we have a single term, then we can use the term freqs\n        # to get the position\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token), key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            if isinstance(key, numbers.Integral):\n                key = self[key]\n            elif isinstance(key, pd.Index):\n                key = key.values\n            else:\n                # TODO: Check if this is a valid index\n                return []\n            if not isinstance(key, SearchArray):\n                key = SearchArray([key], tokenizer=self.tokenizer)\n\n            posns = self.posns.positions(self.term_dict.get_term_id(token), key=key)\n            return posns\n        else:\n            posns = self.posns.positions(self.term_dict.get_term_id(token))\n            return posns\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # parse the spec\n    if spec.isdigit():\n        # if the spec is an absolute number, return it\n        return int(spec)\n    elif spec.startswith('('):\n        # if the spec is a conditional expression, parse it\n        spec = re.sub(r'^(\\()|(\\))$', '', spec)\n        if '>' in spec:\n            # if the spec is a conditional expression with a '>' operator, return the maximum of the number of clauses and the result of the expression\n            return max(num_clauses, int(parse_min_should_match(num_clauses, spec)))\n    # if the spec is a percentage, calculate the number of clauses that must match\n    return int(num_clauses * float(spec) / 100)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if not spec:\n        return num_clauses\n\n    if spec[0] == '<':\n        # Conditional specifications\n        return parse_conditional_mm(num_clauses, spec)\n\n    # Absolute and percentage specifications\n    if spec.isdecimal():\n        return int(spec)\n    else:\n        # If the spec is not a decimal, it is a percentage\n        return int(num_clauses * float(spec) / 100)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # parse the spec\n    if re.match(r\"^(\\d+)$\", spec):\n        return int(spec)\n    elif re.match(r\"^(100|100%)$\", spec):\n        return num_clauses\n    elif re.match(r\"^1$\", spec):\n        return 1\n    elif re.match(r\"^[1-9]\\d*$\", spec):\n        return int(spec)\n    elif re.match(r\"^\\d+\\%\", spec):\n        return int(num_clauses * int(spec.replace(\"%%\", \"\")) / 100)\n    elif re.match(r\"^(<|<=)$\", spec):\n        return 1\n    else:\n        raise ValueError(\n            f\"Unrecognized mm spec: '{spec}'. \"\n            \"Supported specs are: \"\n            \"1, 0, 100, 100%, 1-99, 1-99%, <, <=, 100-200, 100-200%, <100, <=100\"\n        )\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Handle case where no 'mm' spec is given.\n    if spec is None or spec == '':\n        return 0\n\n    # Parse the 'mm' spec.\n    m = re.search(r'(?<=\\d+)\\s*([0-9]+)', spec)\n    if m is not None:\n        return int(m.group(1))\n    else:\n        m = re.search(r'(?<=\\d+)\\s*%s', spec)\n        if m is not None:\n            return int(m.group(1))\n        else:\n            m = re.search(r'\\s*%s\\s*([0-9]+)', spec)\n            if m is not None:\n                return int(m.group(1))\n\n    # If no 'mm' spec is found, we'll assume that the user wants to match all clauses.\n    return num_clauses\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n    elif spec == \"1\":\n        return 1\n    elif spec == \"0\":\n        return 0\n    elif spec == \"none\":\n        return 0\n    elif spec == \"any\":\n        return 1\n    elif spec == \"all_to_query\":\n        return num_clauses\n    elif spec == \"all_to_query_with_zero\":\n        return 1\n    elif spec == \"all_to_query_with_zero_or_one\":\n        return 1\n    elif spec == \"all_to_query_with_one\":\n        return 1\n    elif spec == \"all_to_query_with_one_or_two\":\n        return 1\n    elif spec == \"all_to_query_with_two\":\n        return 1\n    elif spec == \"all_to_query_with_two_or_three\":\n        return 1\n    elif spec == \"all_to_query_with_three\":\n        return 1\n\n    # parse the spec\n    spec = spec.replace(' ', '')\n    if spec.startswith('<'):\n        return int(spec[1:])\n    elif spec.startswith('0'):\n        return 0\n    elif spec.startswith('1'):\n        return 1\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n    else:\n        if \">\" in spec:\n            return int(re.sub(r\"\\D\", \"\", spec))\n        else:\n            if \"%\" in spec:\n                return int(float(spec) * num_clauses / 100)\n            else:\n                return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Handle simple cases\n    if spec == 'all':\n        return num_clauses\n    if spec == 'none':\n        return 0\n\n    # Handle conditional specifications\n    if '<' in spec:\n        spec, value = spec.split('<')\n        if spec == 'all':\n            return num_clauses - int(value)\n        elif spec == 'none':\n            return 0\n        else:\n            raise ValueError(f'invalid mm spec \"{spec}\"')\n\n    # Handle percentage specifications\n    if '%' in spec:\n        return int(float(spec) * num_clauses / 100)\n\n    # Handle absolute specifications\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # TODO: Add support for conditional specifications using '<'\n    # TODO: Add support for specifying the number of clauses that must match, instead of the percentage\n    # TODO: Add support for specifying the number of clauses that must match, instead of the percentage\n\n    if spec == \"all\":\n        return num_clauses\n    if spec == \"any\":\n        return 1\n\n    # TODO: Add support for conditional specifications using '<'\n    # TODO: Add support for specifying the number of clauses that must match, instead of the percentage\n\n    # TODO: Add support for specifying the number of clauses that must match, instead of the percentage\n    # TODO: Add support for specifying the number of clauses that must match, instead of the percentage\n    try:\n        num_matches = int(spec)\n        if num_matches < 1:\n            raise ValueError\n    except (ValueError, TypeError):\n        try:\n            num_matches = int(100 * float(spec))\n            if num_matches < 1:\n                raise ValueError\n        except ValueError:\n            num_matches = num_clauses\n\n    return num_matches\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == 'all':\n        return num_clauses\n\n    if spec == 'none':\n        return 0\n\n    # handle conditional expressions\n    if spec[0] == '<':\n        return 0 if num_clauses < int(spec[1:]) else num_clauses - int(spec[1:])\n\n    # handle percentages\n    if spec[-1] == '%':\n        return int(num_clauses * float(spec[:-1]) / 100)\n\n    # handle absolute numbers\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Handle 'must match all'\n    if spec == 'all' or spec == '100%':\n        return num_clauses\n\n    # Handle 'must match none'\n    if spec == 'none' or spec == '0%':\n        return 0\n\n    # Handle the case where the spec is an absolute number\n    if re.fullmatch(r'^\\d+$', spec):\n        return int(spec)\n\n    # Handle the case where the spec is a percentage\n    if re.fullmatch(r'^\\d+%$', spec):\n        return int(spec[:-1])\n\n    # Handle the conditional case\n    if spec.startswith('<'):\n        return int(spec[1:])\n\n    # Handle the default case\n    return 0\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == '1':\n        return 1\n\n    if spec == 'all':\n        return num_clauses\n\n    if '<' in spec:\n        # conditional specification\n        spec = re.sub('<', '', spec)\n\n    # absolute or percentage\n    try:\n        return int(spec)\n    except:\n        # percentage\n        return int(float(spec) * num_clauses)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n    elif spec == \"1\":\n        return 1\n    elif spec == \"0\":\n        return 0\n    elif spec == \"all-2\":\n        return 2 * num_clauses\n    elif spec == \"all-1\":\n        return num_clauses + 1\n\n    # Parse the spec\n    if spec.startswith(\"<\") and spec.endswith(\"%\"):\n        return int(spec.replace(\"<\", \"\").replace(\"%\", \"\"))\n    elif spec.endswith(\"%\"):\n        return int(spec.replace(\"%\", \"\") * num_clauses / 100)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n    elif spec == \"allButOne\":\n        return num_clauses - 1\n    elif spec == \"allButTwo\":\n        return num_clauses - 2\n    elif spec == \"allButThree\":\n        return num_clauses - 3\n\n    # parse the spec\n    spec = re.sub(r\"^\\s*\", \"\", spec)\n    if spec[0] == \"<\":\n        # if the spec is a conditional expression\n        spec = re.sub(r\"^<\", \"\", spec)\n        if spec == \"0\":\n            return 0\n        elif spec == \"1\":\n            return 1\n        else:\n            return int(spec)\n    elif spec.isdigit():\n        # if the spec is an absolute number\n        return int(spec)\n    elif spec == \"100\":\n        # if the spec is 100%\n        return num_clauses\n    elif spec == \"99\":\n        # if the spec is 99%\n        return num_clauses - 1\n    else:\n        # if the spec is a percentage\n        return int(num_clauses * int(spec) / 100)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n\n    if spec == \"none\":\n        return 0\n\n    if not spec.startswith(\"<\") and not spec.startswith(\"!\"):\n        return int(spec)\n\n    if \"!\" in spec:\n        if \">\" in spec:\n            raise ValueError(\n                \"You cannot use both '>' and '!' in a single 'mm' specification. \"\n                \"Please use either '<' or '!' to specify a conditional specification.\"\n            )\n        elif spec.startswith(\"!\"):\n            return 0\n        else:\n            return num_clauses\n\n    if spec.startswith(\"<\"):\n        if \"<\" in spec:\n            raise ValueError(\n                \"You cannot use both '<' and '>' in a single 'mm' specification. \"\n                \"Please use either '>' or '<' to specify a conditional specification.\"\n            )\n        elif spec.endswith(\"<\"):\n            return num_clauses\n        else:\n            return int(spec)\n\n    raise ValueError(\n        \"The 'mm' specification must be a number, a percentage, or a conditional expression.\"\n    )\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n    elif spec == \"all but one\":\n        return num_clauses - 1\n\n    # check if the spec is a number\n    try:\n        return int(spec)\n    except (ValueError, TypeError):\n        pass\n\n    # check if the spec is a percentage\n    try:\n        # if the spec is a percentage, convert it to an int\n        # and return the calculated number of clauses that must match\n        return int(float(spec) * num_clauses)\n    except (ValueError, TypeError):\n        pass\n\n    # check if the spec is a conditional expression\n    if spec[0] == \"<\":\n        # if the spec is a conditional expression,\n        # return the calculated number of clauses that must match\n        return int(num_clauses * (1 - float(spec[1:])))\n\n    # if the spec is not a number, percentage, or conditional expression,\n    # return -1 to indicate that the spec is invalid\n    return -1\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # The 'mm' spec can be an absolute number, a percentage, or a conditional expression.\n    if spec.isdigit():\n        return int(spec)\n    elif spec[0] == \"%\":\n        # If the 'mm' spec is a percentage, convert it to an absolute number.\n        return int(float(spec) * num_clauses / 100)\n    elif spec[0] == \"<\":\n        # If the 'mm' spec is a conditional expression, check if the number of clauses is less than the given value and return 0 or 1 accordingly.\n        return 1 if num_clauses < int(spec[1:]) else 0\n    else:\n        raise ValueError(f\"The 'mm' spec must be an absolute number, a percentage, or a conditional expression, but received {spec}.\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n    else:\n        if spec.startswith(\"<\"):\n            return int(spec[1:])\n        else:\n            if spec.startswith(\"~\"):\n                return int(spec[1:])\n            else:\n                return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.lower() == \"all\":\n        return num_clauses\n    else:\n        num_clauses = int(num_clauses)\n        if spec.lower() == \"1\":\n            return 1\n        elif spec.lower() == \"all\":\n            return num_clauses\n        elif spec.startswith(\"(\"):\n            if spec.endswith(\")\"):\n                return parse_min_should_match(num_clauses, spec[1:-1])\n            else:\n                return parse_min_should_match(num_clauses, spec[1:])\n        elif spec.endswith(\"%\"):\n            return int(spec[0:-1])\n        elif spec.endswith(\"<\"):\n            return int(spec[0:-1])\n        else:\n            return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If there is no specification, return the total number of clauses.\n    if spec is None:\n        return num_clauses\n\n    # If the specification is an absolute number, return that number.\n    if re.fullmatch(r\"^[0-9]+$\", spec):\n        return int(spec)\n\n    # If the specification is a percentage, calculate the percentage of clauses that must match.\n    if re.fullmatch(r\"^[0-9]+%\", spec):\n        return int(float(spec[0:-1]) / 100 * num_clauses)\n\n    # If the specification is a conditional expression, evaluate it and return the result.\n    if re.fullmatch(r\"^\\<\", spec):\n        return int(float(spec[1:]) / 100 * num_clauses)\n\n    # If the specification is not a valid expression, return the total number of clauses.\n    return num_clauses\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Convert the spec to an integer if it is a number\n    if re.match(r'^\\d+$', spec) is not None:\n        return int(spec)\n    # If the spec is a percentage, convert it to an integer\n    elif re.match(r'^\\d+(?:\\.\\d+)?%?', spec) is not None:\n        return int(round(num_clauses * int(spec) / 100))\n    # If the spec is conditional, then evaluate the expression\n    elif re.match(r'<\\d+$', spec) is not None:\n        return int(eval(f\"num_clauses {spec}\"))\n    else:\n        raise ValueError(\n            \"The 'min should match' specification must be a number, a percentage, or a conditional expression using '<'.\")\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if all tokens are unique\n        if len(set(tokens)) == len(tokens):\n            # Calculate phrase frequency directly\n            return self.phrase_freq_direct(tokens, slop=slop)\n        else:\n            # Calculate phrase frequency with slop\n            return self.phrase_freq_slop(tokens, slop=slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if tokens are unique\n        unique_tokens = set(tokens)\n        if len(unique_tokens) != len(tokens):\n            # If the tokens are not unique, we need to use a different method to calculate the phrase frequency\n            return self.phrase_freq_non_unique(tokens, slop)\n        else:\n            # If the tokens are unique, we can use the positions of the terms to directly calculate the phrase frequency\n            return self.phrase_freq_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # 1. Check if tokens are unique\n        if len(set(tokens)) == len(tokens):\n            # 2. Check if the slop is 1\n            if slop == 1:\n                # 3. Calculate phrase frequencies using the positions of terms\n                return self.phrase_freq_adjacent(tokens)\n            else:\n                # 4. Calculate phrase frequencies using the positions of terms\n                return self.phrase_freq_slop(tokens, slop)\n        else:\n            # 5. Calculate phrase frequencies using the positions of terms\n            return self.phrase_freq_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if the slop is 1 and all tokens are unique\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            # Calculate the phrase frequencies directly using the positions of terms\n            return self.phrase_freqs_slop1(tokens)\n        else:\n            # Calculate the phrase frequencies using the scan-merge method\n            return self.phrase_freqs_scan_merge(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        tokens = self._check_token_arg(tokens)\n        if slop == 1:\n            return self.phrase_freqs_slop1(tokens)\n        else:\n            return self.phrase_freqs(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Handle the case where the tokens are all unique and slop is 1\n        if len(tokens) == len(set(tokens)) and slop == 1:\n            return self.unique_phrase_freq(tokens)\n\n        # Otherwise, calculate the phrase frequency using the scan-merge algorithm\n        else:\n            return self.phrase_freq_scan_merge(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If all tokens are unique and slop is 1, use the positions of terms to calculate the phrase frequency.\n        if len(set(tokens)) == len(tokens) and slop == 1:\n            return self.phrase_freq_unique_tokens(tokens)\n\n        # If slop is 0, use the term frequencies to calculate the phrase frequency.\n        elif slop == 0:\n            return self.termfreqs(tokens)\n\n        # If slop is greater than 0, use the positions of terms to calculate the phrase frequency.\n        else:\n            return self.phrase_freq_nonunique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if the tokens are unique and the slop is 1\n        if len(set(tokens)) == len(tokens) and slop == 1:\n            # Calculate the phrase frequencies directly using the positions of terms\n            return self.direct_phrase_freq(tokens)\n\n        # If the tokens are not unique or the slop is not 1, delegate the calculation to another method\n        return self.scan_phrase_freq(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        tokens = [self.term_dict.get_term_id(token) for token in tokens]\n        if slop == 1:\n            return self.phrase_freq_slop1(tokens)\n        else:\n            return self.phrase_freq_slop(tokens, slop)\n    "}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can calculate the phrase frequency directly\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self.phrase_freq_slop1(tokens)\n\n        # Otherwise, we need to use a more general method\n        return self.phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If all tokens are unique and slop is 1, use the positions\n        if self.slop_and_unique_tokens(tokens, slop):\n            # Calculate phrase frequencies using positions\n            return self.positions_freq(tokens, slop)\n\n        # If tokens are not unique or slop is not 1, calculate phrase frequencies using merge_ins\n        else:\n            return self.merge_ins_freq(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        # If the slop is 1 and all tokens are unique, the phrase frequency can be calculated directly from the positions.\n        if slop == 1 and self.is_unique(tokens):\n            return self.phrase_freqs_unique(tokens)\n\n        # Otherwise, use the scan_merge_ins function to calculate the phrase frequency.\n        else:\n            return self.phrase_freqs(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if not isinstance(tokens, list):\n            tokens = [tokens]\n\n        # If tokens are unique and slop is 1, we can use the positions\n        if len(tokens) > 1 and slop == 1 and self.posns is not None:\n            # Get the positions of the tokens\n            posns = [self.posns.positions(self.term_dict.get_term_id(token))\n                     for token in tokens]\n            # Compute the phrase frequencies\n            phrase_freqs = compute_phrase_freqs(posns, slop)\n\n            # Return the phrase frequencies\n            return phrase_freqs\n\n        # If the slop is 2 or greater, we can use the scan-merge method\n        elif slop > 1:\n            # Get the positions of the tokens\n            posns = [self.posns.positions(self.term_dict.get_term_id(token))\n                     for token in tokens]\n            # Compute the phrase frequencies\n            phrase_freqs = scan_merge_ins(posns, slop)\n\n            # Return the phrase frequencies\n            return phrase_freqs\n\n        # If the slop is 1 and the tokens are not unique, we can use the\n        # positions\n        elif slop == 1:\n            # Get the positions of the tokens\n            posns = [self.posns.positions(self.term_dict.get_term_id(token))\n                     for token in tokens]\n            # Compute the phrase frequencies\n            phrase_freqs = compute_phrase_freqs(posns, slop)\n\n            # Return the phrase frequencies\n            return phrase_freqs\n\n        # If the slop is 0, we can use the term frequencies\n        elif slop == 0:\n            # Get the term frequencies\n            tfs = [self.termfreqs(token) for token in tokens]\n\n            # Return the term frequencies\n            return tfs\n\n        # If the slop is less than 0, we can use the term frequencies\n        elif slop < 0:\n            # Get the term frequencies\n            tfs = [self.termfreqs(token) for token in tokens]\n\n            # Return the term frequencies\n            return tfs\n\n        else:\n            raise ValueError(f\"Invalid slop value: {s"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If tokens are not unique or slop is not 1, use the other method\n        if not all(t in self.term_dict for t in tokens) or slop != 1:\n            return self.phrase_freq_with_slop(tokens, slop)\n\n        # If slop is 1 and all tokens are unique, calculate the phrase frequencies directly\n        # from the positions of terms\n        doc_ids = self.term_mat.rows\n        term_freqs = np.zeros(len(self))\n        for i, token in enumerate(tokens):\n            term_freqs += self.termfreqs(token)\n        posns = self.posns.positions(self.term_dict.get_term_id(token))\n\n        # Compute phrase frequencies\n        phrase_freqs = compute_phrase_freqs(doc_ids, posns, slop)\n        return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If tokens are unique and slop is 1, calculate phrase freq directly\n        if len(set(tokens)) == len(tokens) and slop == 1:\n            return self.phrase_freqs_unique_tokens(tokens)\n        else:\n            return self.phrase_freqs_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1:\n            # Calculate the phrase frequencies for all unique tokens\n            unique_tokens = set(tokens)\n            return self.unique_phrase_freqs(unique_tokens)\n        else:\n            # Calculate the phrase frequencies for all tokens\n            return self.phrase_freqs(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if tokens are unique\n        unique_tokens = set(tokens)\n        if len(unique_tokens) != len(tokens):\n            # Tokens are not unique, so use the other method\n            return self.phrase_freq_non_unique(tokens, slop)\n\n        # Tokens are unique, so use the fast method\n        if slop == 1:\n            return self.phrase_freq_unique(tokens)\n        else:\n            # Tokens are unique and slop is not 1, so use the other method\n            return self.phrase_freq_non_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Get the term IDs for the tokens\n        term_ids = [self.term_dict.get_term_id(token)\n                    for token in tokens]\n\n        # If the slop is 1 and tokens are unique, calculate the phrase frequency directly\n        if slop == 1 and len(set(term_ids)) == len(term_ids):\n            return self.phrase_freq_direct(term_ids)\n\n        # If the slop is greater than 1 or tokens are not unique, use the scan_merge_ins method\n        return self.phrase_freq_scan_merge_ins(tokens, term_ids, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Get term freqs per token\n        term_id = self.term_dict.get_term_id(tokens)\n        if term_id is None:\n            return np.zeros(len(self))\n\n        # For expensive toknes, we compute doc freq first, so we\n        # cache them in the DF cache, to let TF cache know it should be cached\n        all_dfs = np.asarray([self.docfreq(term) for term in tokens])\n\n        # If slop is 1, we have a simple case where we can use the positions\n        # to quickly calculate the phrase frequency\n        if slop == 1 and self.posns.compatible(self.term_dict):\n            # We have to make sure the term freqs are the same\n            # (we may have added new terms)\n            if self.term_mat.shape[1] != len(self.term_dict):\n                self._add_new_terms(None, self.term_dict)\n\n            # Get the positions of the term\n            posns = self.posns.positions(term_id, doc_ids=None)\n            # Get the phrase frequencies\n            phrase_freqs = compute_phrase_freqs(posns, self.term_dict.get_term_id(tokens))\n            return phrase_freqs\n\n        # Else, we have to do a more expensive scan\n        # (We could do the scan with a different slop, but it's not worth it)\n        # (This is an O(n^2) operation)\n        else:\n            # Get the positions of the term\n            posns = self.posns.positions(term_id, doc_ids=None)\n\n            # Get the phrase frequencies\n            phrase_freqs = scan_merge_ins(posns, self.term_dict.get_term_id(tokens),\n                                         slop=slop,\n                                         doc_lens=self.doc_lens,\n                                         avg_doc_length=self.avg_doc_length)\n\n            return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check for unique tokens\n        if not self.term_dict.contains_all(tokens):\n            # We don't have the positions of all the tokens, so we'll need to use the slower method\n            # to calculate the phrase freq\n            return self.phrase_freq_scan(tokens, slop)\n\n        # Get the term ids of the tokens\n        term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n\n        # Get the term freqs for each token\n        tfs = [self.termfreqs(term_id) for term_id in term_ids]\n        # Get the positions of each term\n        posns = [self.posns.positions(term_id) for term_id in term_ids]\n\n        # Get the phrase freqs using the positions\n        # We use a custom function here because the default\n        # compute_phrase_freqs is slow\n        # It's a bit of a hack to use the positions\n        # of the first term as the posns, but it works\n        phrase_freqs = self.phrase_freqs_from_posns(posns[0], tfs, slop)\n        return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, pd.Series):\n            array = array.to_list()\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the tokenizer is a callable\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # TODO: Make this a class method\n        # TODO: Make this a class method\n        if not is_list_like(array):\n            raise TypeError(\n                \"Expected list-like object, got {}\".format(type(array))\n            )\n\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        if isinstance(array, SearchArray):\n            # TODO: Make this a class method\n            # TODO: Make this a class method\n            # TODO: Make this a class method\n            # TODO: Make this a class method\n            # TODO: Make this a class method\n            return array\n\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class method\n        # TODO: Make this a class"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # TODO: This is a big function, refactor it\n        # TODO: Add a progress bar\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Make this function async\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n        # TODO: Add an option to write to a file\n\n        # TODO: Add an option to write to a file"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # TODO: Implement this\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, tokenizer, batch_size=batch_size,\n                                                                                            avoid_copies=avoid_copies, truncate=truncate)\n        return cls(term_mat, posns, term_dict, avg_doc_length, doc_lens)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            raise NotImplementedError(\"Truncation not yet implemented\")\n        if isinstance(array, pd.DataFrame):\n            array = array.to_numpy()\n\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Build the index\n        # Build the index from the given array and tokenizer\n        # It handles large arrays by processing them in batches if necessary.\n        # Input-Output Arguments\n        # array: Iterable, the array of strings to be indexed.\n        # tokenizer: A function used for tokenizing the strings in the array. It defaults to ws_tokenizer if not specified.\n        # truncate: bool, indicates whether to truncate the data to fit within memory constraints. It defaults to False, meaning the data will not be truncated unless specified.\n        # batch_size: int, the size of batches to process the array in. This is useful for processing large arrays without loading everything into memory at once. Defaults to 100000.\n        # avoid_copies: bool, indicates whether to avoid making copies of the data to save memory. Defaults to True, optimizing memory usage during the indexing process.\n        # return: An instance of SearchArray, which contains the indexed data including term matrix, positions, term dictionary, average document length, and document lengths.\n        self = cls(postings=list(array), tokenizer=tokenizer, avoid_copies=avoid_copies)\n        return self\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not isinstance(array, Iterable):\n            raise TypeError(\n                \"Expected an iterable, got {}\".format(type(array)))\n        if not isinstance(tokenizer, callable):\n            raise TypeError(\n                \"Expected callable, got {}\".format(type(tokenizer)))\n        if not isinstance(truncate, bool):\n            raise TypeError(\n                \"Expected boolean, got {}\".format(type(truncate)))\n        if not isinstance(batch_size, numbers. oralevel=1):\n            raise TypeError(\n                \"Expected int, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\n                \"Expected boolean, got {}\".format(type(avoid_copies)))\n\n        # Build the index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = \\\n            build_index_from_tokenizer(array, tokenizer, truncate, batch_size,\n                                       avoid_copies)\n\n        # Create the array\n        array_type = cls(term_mat, posns, term_dict, avg_doc_length, doc_lens)\n        return array_type\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not truncate:\n            return cls.index_no_truncation(array, tokenizer)\n\n        # If input is a pd.Series, convert to list\n        if isinstance(array, pd.Series):\n            array = array.to_list()\n\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Convert to list if we're given a pd.Series\n        if isinstance(array, pd.Series):\n            array = array.to_list()\n\n        if isinstance(array, pd.DataFrame):\n            array = array.to_list()\n\n        if isinstance(array, pd.DataFrame):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Build index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms)\n\n        # Create new SearchArray\n        return cls(term_mat, posns=posns, term_dict=term_dict,\n                   avg_doc_length=avg_doc_length, doc_lens=doc_lens,\n                   avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            postings = array.to_postings()\n        else:\n            postings = build_index_from_terms_list(array, Terms, tokenizer)\n        return cls(postings, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not truncate and not avoid_copies:\n            # If we're not truncating, we can just call the regular build_index_from_terms_list\n            return cls.from_terms_list(array, tokenizer)\n\n        # Truncate\n        truncated_array = cls.truncate_array(array, batch_size=batch_size)\n        return cls.from_terms_list(truncated_array, tokenizer)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            raise NotImplementedError(\"Truncation not implemented\")\n        # TODO:\n        #  - Implement truncation\n        #  - Implement batching\n\n        # Build the index\n        #  - This could be done in a different thread\n        term_dict, term_mat, posns, avg_doc_length, doc_lens = \\\n            build_index_from_terms_list(array, Terms,\n                                        tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # Create a new SearchArray\n        return cls(term_mat, posns=posns, term_dict=term_dict,\n                   avg_doc_length=avg_doc_length, doc_lens=doc_lens)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, pd.DataFrame):\n            raise ValueError(\"Cannot index a DataFrame. Use a Series instead\")\n        if not isinstance(array, pd.Series):\n            raise TypeError(\"Expected a Series, got {}\".format(type(array)))\n\n        # Build the index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(array,\n                                                                                           tokenizer,\n                                                                                           truncate,\n                                                                                           batch_size,\n                                                            avoid_copies)\n\n        # Create the array\n        return cls(term_mat, posns=posns, term_dict=term_dict, avg_doc_length=avg_doc_length,\n                   doc_lens=doc_lens, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            # If the input is already a SearchArray, just return it\n            return array\n        elif not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Create the index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms)\n\n        # Create the new array\n        result = cls(term_mat, avoid_copies=avoid_copies)\n        result.term_dict = term_dict\n        result.posns = posns\n        result.avg_doc_length = avg_doc_length\n        result.doc_lens = doc_lens\n        return result\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            # If we're given an array, just return it\n            return array\n\n        # Build the index\n        postings = build_index_from_terms_list(array, Terms)\n        return cls(postings, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            return array\n        elif isinstance(array, pd.DataFrame):\n            return SearchArray.from_dataframe(array, tokenizer, truncate=truncate)\n        elif isinstance(array, pd.Series):\n            return SearchArray.from_series(array, tokenizer, truncate=truncate)\n        else:\n            return SearchArray(array, tokenizer=tokenizer)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Validate\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if truncate:\n            # TODO: Implement this\n            raise NotImplementedError\n        if not isinstance(batch_size, numbers. integrale):\n            raise TypeError(\"batch_size must be an int, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"avoid_copies must be a boolean, got {}\".format(type(avoid_copies)))\n        if not isinstance(tokenizer, (list, set, tuple)):\n            raise TypeError(\"tokenizer must be a list, set or tuple, got {}\".format(type(tokenizer)))\n\n        # Tokenize\n        tokenized = [tokenizer(x) for x in array]\n\n        # Build the index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(\n            tokenized, Terms, batch_size=batch_size, avoid_copies=avoid_copies\n        )\n\n        # Create the new array\n        return cls(term_mat, term_dict, avg_doc_length, doc_lens)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            raise NotImplementedError\n\n        # TODO: Implement\n        # array = pd.Series(array)\n        # if array.size > 100000:\n        #     array = array.apply(lambda x: self.tokenizer(x),\n        #                          meta={'dtype': self.dtype, 'name': self.name})\n\n        # TODO: Implement\n        # if array.dtype == 'object':\n        #     array = array.astype('U1024', copy=self.avoid_copies)\n\n        return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            # If we're passed a SearchArray, return a new SearchArray\n            # with the same index\n            return cls(array, avoid_copies=avoid_copies)\n\n        if isinstance(array, pd.DataFrame):\n            # If we're passed a DataFrame, return a new SearchArray\n            # with the same index\n            return cls(array[array.columns], avoid_copies=avoid_copies)\n\n        # If we're passed a pandas Series, convert to a DataFrame\n        # with a single column\n        if isinstance(array, pd.Series):\n            array = pd.DataFrame(array, columns=[\"text\"])\n\n        # If we're passed a list or array-like, convert to a Pandas\n        # DataFrame\n        if not isinstance(array, pd.DataFrame):\n            array = pd.DataFrame(array, columns=[\"text\"])\n\n        if not is_list_like(array.text):\n            raise TypeError(\"Expected a DataFrame with a 'text' column, got {}\".format(type(array)))\n        if array.shape[1] > 1:\n            raise ValueError(\"Expected a DataFrame with a single column, got {}\".format(array.shape))\n\n        if truncate:\n            logger.info(f\"Truncating array to {truncate} documents.\")\n            # TODO: handle this better\n            array = array.iloc[0:truncate]\n        array = array.fillna(\"\")\n        array.index = array.index.astype(str)\n\n        # TODO: This is a hack - should be able to use the tokenizer\n        # in the constructor\n        array.text = array.text.apply(lambda x: self.tokenizer(x))\n\n        # Get the term matrix, positions, and term dictionary\n        self.term_mat, self.posns, self.term_dict, self.avg_doc_length, self.doc_lens = \\\n            build_index_from_tokenizer(array, Terms)\n\n        return cls(array.text, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            logger.info(\"Truncating data to fit within memory constraints\")\n\n        # If the data is not iterable, make it so.\n        if not is_iterable(array):\n            array = [array]\n\n        # Make sure all strings are strings.\n        for item in array:\n            if isinstance(item, numbers.Number):\n                raise TypeError(\n                    f\"SearchArray only supports strings, got {type(item)}\"\n                )\n        if isinstance(array, str):\n            array = [array]\n\n        # Create a new instance of SearchArray to hold the indexed data\n        array = cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If the data is too large, process it in batches\n        if len(array) > 0 and array.is_too_large_for_memory():\n            logger.info(\n                \"Data is too large to fit in memory. Processing in batches.\"\n            )\n            for batch in array.batches(batch_size):\n                array.index_batch(batch)\n        else:\n            array.index()\n\n        return array\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            if array.tokenizer != tokenizer:\n                raise ValueError(\n                    \"Cannot change the tokenizer after indexing.\"\n                    \"Use a new instance of SearchArray with the new tokenizer.\"\n                )\n            if array.avoid_copies:\n                return array\n            else:\n                return cls(array.postings, tokenizer=tokenizer)\n\n        if not isinstance(array, pd.DataFrame) and not is_list_like(array):\n            raise TypeError(\n                \"Expected a list-like object, got {}\".format(type(array))\n            )\n\n        if len(array) == 0:\n            return cls(postings=[], tokenizer=tokenizer)\n\n        # Build the index\n        if isinstance(array, pd.DataFrame):\n            # TODO: Make this more efficient\n            # TODO: If the data is already indexed, don't re-index\n            return cls(postings=array[array.columns[0]],\n                       tokenizer=tokenizer)\n        if not truncate:\n            return cls(build_index_from_terms_list(array, Terms))\n\n        # TODO: Make this more efficient\n        # TODO: If the data is already indexed, don't re-index\n        # TODO: Use a list of dicts\n        postings = []\n        doc_len = 0\n        for i, doc in enumerate(array):\n            if isinstance(doc, pd.Series):\n                doc = doc[doc.columns[0]]\n            if isinstance(doc, pd.Series):\n                doc = doc.to_frame().T\n            if isinstance(doc, pd.DataFrame):\n                doc = doc[doc.columns[0]]\n            if isinstance(doc, pd.DataFrame):\n                raise ValueError(\n                    \"DataFrame is not supported. \"\n                    \"Use the .to_frame() method to convert the DataFrame to a Series.\"\n                )\n            postings.append(doc)\n            doc_len += len(doc)\n        return cls(postings=postings, tokenizer=tokenizer)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected iterable, got {}\".format(type(array)))\n\n        if not truncate:\n            # If not truncating, make sure the array fits in memory\n            # (Note: This is a bit of a hack, as we're pessimistically\n            #  assuming the worst case of a single token per document)\n            if len(array) * 100 < sys.getsizeof(array):\n                raise ValueError(\n                    \"Cannot process array of size {} with {} \"\n                    \"bytes of memory available\".format(len(array), sys.getsizeof(array)))\n\n        if len(array) > batch_size:\n            # We're going to need to process in batches\n            logger.info(\"Indexing in batches\")\n\n            # Process in batches\n            batch_index = 0\n            batches = []\n            for batch in pd. kristal.utils.batch_iterable(array, batch_size):\n                batches.append(cls.index(batch, tokenizer, truncate, avoid_copies=True))\n                batch_index += 1\n\n            # Merge the batches\n            merged_index = cls.merge(*batches, avoid_copies=avoid_copies)\n\n            # Return the merged index\n            return merged_index\n\n        # If we're not truncating and the array fits in memory,\n        #  we can just build the index directly\n        return cls.index_from_list(array, tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger\n        )\n\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['strategies'][self.config['strategy']],\n            self.logger,\n        )\n        self.server.start()\n        self.connections = dict()\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n        "}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config.get('serverHost'), self.config.get('serverPort'), self.config.get('strategies')[self.config.get('strategy')], self.config.get('strategies'))\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.logger.info(f\"Proxifier message interceptor started\")\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['strategies'][self.config['strategy']], self.on_message, self.on_error, self.on_close)\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config.get('serverHost', '127.0.0.1'), self.config.get('serverPort', 25500), self.config.get('proxyHost', '127.0.0.1'), self.config.get('proxyPort', 8888), self.config.get('strategy', 'length'), self.config.get('strategies', {}))\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config.get('proxyHost'),\n            port=self.config.get('proxyPort'),\n            logger=self.logger,\n            on_connection_received=self.on_connection_received,\n            on_message_received=self.on_message_received,\n            on_connection_closed=self.on_connection_closed\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['proxyHost'], self.config['proxyPort'], self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['strategies'],\n            self.logger\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.logger.info('Proxifier server started.')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config.get('proxyHost', self.config.get('host')),\n            port=self.config.get('proxyPort', self.config.get('port')),\n            serverHost=self.config.get('serverHost', '127.0.0.1'),\n            serverPort=self.config.get('serverPort', 25500),\n            logger=self.logger,\n            strategy=getattr(ProxifierMessageInterceptor.strategies, self.config.get('strategy', 'length'), self.length_strategy)\n        )\n        self.connections = {DEFAULT_CONNECTION_ID: Connection(self.server, self.logger, self.config.get('strategies', {}).get('length', self.length_strategy))}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger\n        )\n\n        self.connections = {DEFAULT_CONNECTION_ID: Connection(\n            host=self.config['proxyHost'],\n            port=self.config['proxyPort'],\n            logger=self.logger\n        )}\n        self.lock = threading.Lock()\n\n        self.server.start()\n        self.server.register_connection_handler(DEFAULT_CONNECTION_ID, self.handle_connection)\n        self.server.register_message_handler(self.handle_message)\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    arr = (arr >> 1) & s55 | ((arr & s55) << 1)\n\n    # Step 2:\n    arr = (arr >> 2) & s33 | ((arr & s33) << 2)\n\n    # Step 3:\n    arr = (arr >> 4) & s0F | ((arr & s0F) << 4)\n\n    # Step 4:\n    arr = (arr >> 8) & s01 | ((arr & s01) << 8)\n\n    # Step 5:\n    arr = (arr >> 16) & s01 | ((arr & s01) << 16)\n\n    # Step 6:\n    arr = (arr >> 32) & s01 | ((arr & s01) << 32)\n\n    # Step 7:\n    arr = (arr >> 4) & s01 | ((arr & s01) << 4)\n\n    # Step 8:\n    arr = (arr >> 8) & s01 | ((arr & s01) << 8)\n\n    # Step 9:\n    arr = (arr >> 16) & s01 | ((arr & s01) << 16)\n\n    # Step 10:\n    arr = (arr >> 32) & s01 | ((arr & s01) << 32)\n\n    # Step 11:\n    arr = arr >> 63\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.asarray(arr)\n    arr = np.where(arr & s55 == 0, arr, arr & s55 | (arr >> 1))\n    arr = np.where(arr & s33 == 0, arr, arr & s33 | (arr >> 2))\n    arr = np.where(arr & s0F == 0, arr, arr & s0F | (arr >> 4))\n    arr = np.where(arr & s01 == 0, arr, arr + (arr >> 8))\n    arr = np.where(arr & all_but_one_bit == 0, arr, arr + (arr >> 16))\n    arr = np.where(arr & all_but_one_bit == 0, arr, arr + (arr >> 32))\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    arr = (arr & s55) + ((arr >> 1) & s55)\n    # Step 2:\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    # Step 3:\n    arr = (arr & s0F) + ((arr >> 4) & s0F)\n    # Step 4:\n    arr = (arr & s01) + ((arr >> 8) & s01)\n    # Step 5:\n    arr = (arr & s01) + ((arr >> 16) & s01)\n    # Step 6:\n    arr = (arr & s01) + ((arr >> 32) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # count pairs of bits\n    arr = (arr & s55) + ((arr >> 1) & s55)\n    # count 4 bits\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    # count 8 bits\n    arr = (arr & s0F) + ((arr >> 4) & s0F)\n    # count 16 bits\n    arr = (arr & s01) + ((arr >> 8) & s01)\n    # count 32 bits\n    arr = (arr + (arr >> 16)) & all_but_one_bit\n    # count 64 bits\n    arr = arr + (arr >> 32)\n    return arr & all_but_one_bit\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    arr = (arr & s55) + ((arr >> 1) & s55)\n\n    # Step 2:\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & m2\n\n    # Step 3:\n    arr = (arr & s0F) + ((arr >> 8) & s0F)\n    arr = (arr + (arr >> 16)) & m1\n\n    # Step 4:\n    arr = (arr & s01) + ((arr >> 32) & s01)\n    arr = arr + (arr >> 64)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1\n    arr = arr & s55\n    arr = (arr & s33) + ((arr >> 1) & s33)\n    arr = (arr & s0F) + ((arr >> 2) & s0F)\n    arr = (arr & s01) + ((arr >> 4) & s01)\n\n    # Step 2\n    arr = arr + (arr >> 8)\n    arr = arr + (arr >> 16)\n    arr = arr + (arr >> 32)\n    arr = arr & all_but_one_bit\n\n    # Step 3\n    arr = arr + (arr >> 2)\n    arr = arr + (arr >> 4)\n    arr = arr + (arr >> 8)\n    arr = arr + (arr >> 16)\n    arr = (arr * _4) & all_but_one_bit\n\n    # Step 4\n    arr = arr + (arr >> 2)\n    arr = (arr * _1) & all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr &= m1\n    arr = (arr >> 1) & m2\n    arr = arr + (arr & m1)\n    arr = arr + (arr >> 4)\n    arr = (arr & m3) + (arr >> 8)\n    arr = (arr & m4) + (arr >> 16)\n    arr = (arr & all_but_one_bit) + (arr >> 32)\n    return arr\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    #   arr = (arr & s55) + ((arr >> 1) & s55)\n    arr = arr & s55\n    arr = np.add(arr, np.left_shift(arr, 1))\n    arr = np.bitwise_and(arr, s55)\n\n    # Step 2:\n    #   arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = np.add(arr, np.left_shift(arr, 2))\n    arr = np.bitwise_and(arr, s33)\n\n    # Step 3:\n    #   arr = (arr & s0F) + ((arr >> 4) & s0F)\n    arr = np.add(arr, np.left_shift(arr, 4))\n    arr = np.bitwise_and(arr, s0F)\n\n    # Step 4:\n    #   arr = (arr & s01) + ((arr >> 8) & s01)\n    arr = np.add(arr, np.left_shift(arr, 8))\n    arr = np.bitwise_and(arr, s01)\n\n    # Step 5:\n    #   arr = (arr & 1) + ((arr >> 1) & 1)\n    arr = np.add(arr, np.left_shift(arr, 1))\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # 32-bit version\n    arr = arr.astype(np.uint32)\n    arr = (arr >> 1) & m4 | (arr & m4)\n    arr = (arr >> 2) & m2 | (arr & m2)\n    arr = (arr >> 4) & m1 | (arr & m1)\n    arr = (arr >> 8) & s55 | (arr & s55)\n    arr = (arr >> 16) & s55 | (arr & s55)\n    arr = (arr >> 32) & s55 | (arr & s55)\n\n    # 64-bit version\n    arr = arr.astype(np.uint64)\n    arr = (arr >> 1) & m1 | (arr & m1)\n    arr = (arr >> 2) & m2 | (arr & m2)\n    arr = (arr >> 4) & m4 | (arr & m4)\n    arr = (arr >> 8) & s33 | (arr & s33)\n    arr = (arr >> 16) & s33 | (arr & s33)\n    arr = (arr >> 32) & s33 | (arr & s33)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # The bit count of the element is the sum of the bit counts of the individual bytes.\n    # The bit count of each byte is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set.\n    # The bit count of the element is the sum of the bit counts of the individual bits.\n    # The bit count of each bit is 1 if the bit is set, and 0 if it is not set"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # 32-bit version\n    # arr = np.uint32(arr)\n    # arr = (arr & s55) + ((arr >> 1) & s55)\n    # arr = (arr & s33) + ((arr >> 2) & s33)\n    # arr = (arr & s0F) + ((arr >> 4) & s0F)\n    # arr = (arr & s01) + ((arr >> 8) & s01)\n    # arr = (arr & 15) + ((arr >> 16) & 15)\n    # arr = (arr & 3) + ((arr >> 2) & 3)\n    # arr = arr + (arr >> 3)\n    # arr = arr & 7\n\n    # 64-bit version\n    arr = (arr & s55) + ((arr >> 1) & s55)\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr & s0F) + ((arr >> 4) & s0F)\n    arr = (arr & s01) + ((arr >> 8) & s01)\n    arr = (arr & s01) + ((arr >> 16) & s01)\n    arr = (arr & s01) + ((arr >> 32) & s01)\n    arr = (arr & 15) + ((arr >> 16) & 15)\n    arr = (arr & 7) + ((arr >> 8) & 7)\n    arr = (arr & 3) + ((arr >> 4) & 3)\n    arr = arr + (arr >> 2)\n    arr = arr & 15\n    arr = arr + (arr >> 4)\n    arr = arr & 7\n    arr = arr + (arr >> 2)\n    arr = arr & 3\n    arr = arr + (arr >> 1)\n    arr = arr & 1\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    arr = arr & s55\n    arr = arr - ((arr >> 1) & s55)\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr & s0F) + ((arr >> 4) & s0F)\n    arr = (arr & s01) + ((arr >> 8) & s01)\n    arr = (arr & 0x0F) + ((arr >> 16) & 0x0F)\n    arr = (arr & 0x0F) + ((arr >> 32) & 0x0F)\n\n    # Step 2:\n    arr = (arr + (arr >> 32))\n    arr = (arr & 0x33) + ((arr >> 2) & 0x33)\n    arr = (arr & 0x33) + ((arr >> 4) & 0x33)\n    arr = (arr & 0x33) + ((arr >> 8) & 0x33)\n    arr = (arr & 0x33) + ((arr >> 16) & 0x33)\n    arr = (arr & 0x33) + ((arr >> 32) & 0x33)\n    arr = (arr + (arr >> 32))\n\n    # Step 3:\n    arr = (arr & 0x0F) + ((arr >> 4) & 0x0F)\n    arr = (arr + (arr >> 16))\n    arr = (arr & 0x0F) + ((arr >> 8) & 0x0F)\n    arr = (arr + (arr >> 16))\n    arr = (arr & 0x0F) + ((arr >> 4) & 0x0F)\n    arr = (arr + (arr >> 16))\n\n    # Step 4:\n    arr = (arr & _1) + ((arr >> _2) & _1) + ((arr >> _4) & _1)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # 1.\n    arr = arr & s55\n    arr = arr - (arr >> 1 & s55)\n    arr = (arr * 0x0101010101010101) & mask\n    arr = arr - (arr >> 16 & s33)\n    arr = (arr * 0x0101010101010101) & mask\n    arr = arr - (arr >> 8 & s15)\n    arr = (arr * 0x0101010101010101) & mask\n    arr = arr - (arr >> 4 & s7)\n    arr = (arr * 0x0101010101010101) & mask\n    arr = arr - (arr >> 2 & s3)\n    arr = (arr * 0x0101010101010101) & mask\n    arr = arr - (arr >> 1 & s1)\n    return arr\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    arr = np.where(arr & s55 == 0, 0, arr & s1)\n\n    # Step 2:\n    arr = np.right_shift(arr, 1)\n    arr = np.where(arr & s33 == 0, 0, arr & s2)\n\n    # Step 3:\n    arr = np.right_shift(arr, 2)\n    arr = np.where(arr & s0F == 0, 0, arr & s4)\n\n    # Step 4:\n    arr = np.right_shift(arr, 4)\n    arr = np.where(arr & s01 == 0, 0, arr & all_but_one_bit)\n\n    # Step 5:\n    arr = np.right_shift(arr, 7)\n    arr = np.where(arr == 0, 0, arr + 1)\n\n    # Step 6:\n    arr = np.add(arr, np.right_shift(arr, 4))\n    arr = np.add(arr, np.right_shift(arr, 12))\n    arr = np.add(arr, np.right_shift(arr, 20))\n    arr = np.add(arr, np.right_shift(arr, 28))\n    arr = np.add(arr, _1)\n\n    # Step 7:\n    arr = np.where(arr & _4 == 0, 0, arr & _2)\n    arr = np.right_shift(arr, 2)\n    arr = np.where(arr & _4 == 0, 0, arr & _2)\n    arr = np.right_shift(arr, 2)\n    arr = np.where(arr & _4 == 0, 0, arr & _2)\n    arr = np.right_shift(arr, 2)\n    arr = np.where(arr & _4 == 0, 0, arr & _2)\n    arr = np.right_shift(arr, 2)\n\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # https://en.wikipedia.org/wiki/Hamming_weight\n    arr = arr ^ (arr >> _2)\n    arr = (arr & s55) + ((arr >> _2) & s55)\n    arr = arr + (arr >> _4)\n    arr = (arr & s0F) + ((arr >> _4) & s0F)\n    arr = arr + (arr >> _8)\n    arr = (arr & s33) + ((arr >> _8) & s33)\n    arr = (arr + (arr >> _16)) & all_but_one_bit\n    arr = (arr & s33) + ((arr >> _16) & s33)\n    arr = (arr + (arr >> _32)) & all_but_one_bit\n    return arr + (arr >> _32)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.uint64(arr)\n    arr &= s55\n    arr = (arr >> 1) + arr\n    arr &= s33\n    arr = (arr >> 2) + arr\n    arr &= s0F\n    arr = (arr >> 4) + arr\n    arr &= s01\n    arr = (arr >> 8) + arr\n    arr = (arr * 0x001B) >> 16\n    arr = (arr * 0x0003) >> 16\n    arr = (arr * 0x0001) >> 16\n    arr *= 0x0101\n    return arr >> 1\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1:\n    arr = (arr >> 1) & m2\n    arr = arr ^ s33\n\n    # Step 2:\n    arr = (arr >> 2) & m4\n    arr = arr ^ s0F\n\n    # Step 3:\n    arr = (arr >> 4) & m1\n    arr = arr ^ s55\n\n    # Step 4:\n    arr = (arr >> 8) & m2\n    arr = arr ^ s33\n\n    # Step 5:\n    arr = (arr >> 16) & m4\n    arr = arr ^ s0F\n\n    # Step 6:\n    arr = (arr >> 32) & m1\n    arr = arr ^ s55\n\n    # Step 7:\n    arr = arr >> 64\n\n    # Step 8:\n    arr = arr & s01\n    arr = arr * all_but_one_bit\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # TODO: Optimize for 128bit.\n    arr = arr & m1\n    arr = (arr >> 1) & m2\n    arr = (arr + arr) & m3\n    arr = (arr + arr) >> 3\n    arr = arr & m4\n    arr = arr + arr\n    arr = arr >> 6\n    arr = (arr * 0x0000000000000001) & mask\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # https://en.wikipedia.org/wiki/Hamming_weight\n    arr &= s0F\n    arr = (arr >> 4) + arr\n    arr &= s15\n    arr = (arr >> 8) + arr\n    arr &= s31\n    arr = (arr >> 16) + arr\n    arr &= s63\n    arr = (arr >> 32) + arr\n    arr &= m1\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1: Calculate the number of bits set to 1 in each element.\n    # The first step is to calculate the number of bits set to 1 in each element. This is done by performing a bitwise AND operation between the element and the mask 0x5555555555555555, which will set all the bits to 0 except the ones that are set in both the element and the mask. This is done twice more, each time with a different mask, to set all the bits to 0 except the ones that are set in the element. This is done because the number of bits set to 1 in an element is equal to the number of bits set to 1 in the result of the last AND operation.\n    arr = np.uint64(arr) & s55\n    # Step 2: Double the number of bits set to 1 in each element.\n    # The second step is to double the number of bits set to 1 in each element. This is done by performing a bitwise AND operation between the element and the mask 0x3333333333333333, which will set all the bits to 0 except the ones that are set in both the element and the mask. This is done twice more, each time with a different mask, to set all the bits to 0 except the ones that are set in the element. This is done because the number of bits set to 1 in an element is equal to the number of bits set to 1 in the result of the last AND operation.\n    arr = np.uint64(arr) & s33\n    # Step 3: Add the number of bits set to 1 in each element.\n    # The third step is to add the number of bits set to 1 in each element. This is done by performing a bitwise OR operation between the element and the mask 0x0F0F0F0F0F0F0F0F, which will set all the bits to 1 except the ones that are set in both the element and the mask. This is done twice more, each time with a different mask, to set all the bits to 1 except the ones that are set in the element. This is done because the"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf + pf + pf2 + pf3)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query, qf)\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query, qf)\n    if mm is None:\n        mm = \"1\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if qf is None:\n        qf = []\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    query_fields = parse_field_boosts(qf + pf + pf2 + pf3)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query, qf)\n    if mm is None:\n        if term_centric:\n            mm = \"100%\"\n        else:\n            mm = \"100\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if qf is None:\n        qf = []\n\n    if pf is None:\n        pf = []\n\n    if pf2 is None:\n        pf2 = []\n\n    if pf3 is None:\n        pf3 = []\n\n    query_fields = parse_field_boosts(qf + pf + pf2 + pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    if mm is not None:\n        if term_centric:\n            return _edismax_term_centric(frame=frame,\n                                        query_fields=query_fields,\n                                        num_search_terms=num_search_terms,\n                                        search_terms=search_terms,\n                                        mm=mm,\n                                        similarity=similarity)\n        else:\n            return _edismax_field_centric(frame=frame,\n                                         query_fields=query_fields,\n                                         num_search_terms=num_search_terms,\n                                         search_terms=search_terms,\n                                         mm=mm,\n                                         similarity=similarity)\n    else:\n        if term_centric:\n            return _edismax_term_centric(frame=frame,\n                                        query_fields=query_fields,\n                                        num_search_terms=num_search_terms,\n                                        search_terms=search_terms,\n                                        similarity=similarity)\n        else:\n            return _edismax_field_centric(frame=frame,\n                                         query_fields=query_fields,\n                                         num_search_terms=num_search_terms,\n                                         search_terms=search_terms,\n                                         similarity=similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    # Parse the query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query=q, query_fields=qf)\n\n    # Parse the field boosts\n    query_fields = parse_field_boosts([qf] + pf + pf2 + pf3)\n    if not query_fields:\n        return np.zeros(len(frame)), \"\"\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n    if term_centric:\n        return _edismax_term_centric(frame,\n                                    query_fields,\n                                    num_search_terms,\n                                    search_terms,\n                                    mm,\n                                    similarity)\n    else:\n        return _edismax_field_centric(frame,\n                                     query_fields,\n                                     num_search_terms,\n                                     search_terms,\n                                     mm,\n                                     similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if qf is None:\n        qf = []\n\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    if mm is None:\n        mm = \"1\"\n\n    # Parse the query\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query=q, query_fields=qf)\n\n    # Parse the field boosts\n    field_boosts = parse_field_boosts(qf + pf + pf2 + pf3)\n\n    if term_centric:\n        return _edismax_term_centric(frame, field_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, field_boosts, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if mm is None:\n        mm = \"100\"\n\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    if q_op == \"OR\":\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    elif q_op == \"AND\":\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        raise ValueError(f\"Unknown q_op '{q_op}'\")\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"frame must be a DataFrame\")\n    if not isinstance(q, str) or not isinstance(qf, list):\n        raise ValueError(\"q and qf must be strings and lists, respectively\")\n\n    if mm is None:\n        mm = \"100%\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame=frame,\n                                    query_fields=query_fields,\n                                    num_search_terms=num_search_terms,\n                                    search_terms=search_terms,\n                                    mm=mm,\n                                    similarity=similarity)\n    else:\n        return _edismax_field_centric(frame=frame,\n                                     query_fields=query_fields,\n                                     num_search_terms=num_search_terms,\n                                     search_terms=search_terms,\n                                     mm=mm,\n                                     similarity=similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n    query_fields = parse_field_boosts(qf + pf + pf2 + pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query, qf)\n\n    if mm is not None:\n        mm = f\"({mm})\"\n    else:\n        mm = \"\"\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf + [pf, pf2, pf3])\n\n    # TODO: handle pf, pf2, pf3\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    qf_fields = parse_field_boosts(qf)\n    if pf is not None:\n        pf_fields = parse_field_boosts(pf)\n        pf2_fields = parse_field_boosts(pf2)\n        pf3_fields = parse_field_boosts(pf3)\n        qf_fields.update(pf_fields)\n        qf_fields.update(pf2_fields)\n        qf_fields.update(pf3_fields)\n    else:\n        pf_fields = {}\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n    if not term_centric:\n        return _edismax_field_centric(frame, qf_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_term_centric(frame, qf_fields, num_search_terms, search_terms, mm, similarity)\n\n"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf + [q])\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n    if mm is not None:\n        min_should_match = parse_min_should_match(num_search_terms, spec=mm)\n    else:\n        min_should_match = num_search_terms\n\n    if pf is not None:\n        pf_scores = np.sum(get_field(frame, pf).score(search_terms[pf], similarity=similarity), axis=0)\n    else:\n        pf_scores = 0\n\n    if pf2 is not None:\n        pf2_scores = np.sum(get_field(frame, pf2).score(search_terms[pf2], similarity=similarity), axis=0)\n    else:\n        pf2_scores = 0\n\n    if pf3 is not None:\n        pf3_scores = np.sum(get_field(frame, pf3).score(search_terms[pf3], similarity=similarity), axis=0)\n    else:\n        pf3_scores = 0\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    qf_scores = qf_scores + pf_scores + pf2_scores + pf3_scores\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"0\"\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if pf is not None:\n        if pf2 is not None or pf3 is not None:\n            raise ValueError(\"Only one of pf, pf2, pf3 can be set.\")\n        if term_centric:\n            raise ValueError(\"pf is not supported for term-centric queries.\")\n\n    if pf2 is not None:\n        if pf is not None or pf3 is not None:\n            raise ValueError(\"Only one of pf, pf2, pf3 can be set.\")\n        if term_centric:\n            raise ValueError(\"pf2 is not supported for term-centric queries.\")\n\n    if pf3 is not None:\n        if pf is not None or pf2 is not None:\n            raise ValueError(\"Only one of pf, pf2, pf3 can be set.\")\n        if term_centric:\n            raise ValueError(\"pf3 is not supported for term-centric queries.\")\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms,\n                                     search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms,\n                                      search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # TODO: add support for mm2, mm3, pf2, pf3\n    if pf is not None:\n        raise ValueError(\"pf is not supported\")\n    if pf2 is not None:\n        raise ValueError(\"pf2 is not supported\")\n    if pf3 is not None:\n        raise ValueError(\"pf3 is not supported\")\n\n    # Parse the query terms and field boosts\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query=q, query_fields=qf)\n\n    # Parse the field boosts\n    query_fields = parse_field_boosts(qf)\n\n    if mm is None:\n        if term_centric:\n            return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, q_op, similarity)\n        else:\n            return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, q_op, similarity)\n    else:\n        if term_centric:\n            return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n        else:\n            return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse the query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse the field boosts\n    field_boosts = parse_field_boosts([pf, pf2, pf3])\n\n    # Parse the mm\n    if mm is None:\n        mm = \"100\"\n    if mm == \"all\":\n        mm = \"100\"\n    if mm == \"all_but_one\":\n        mm = \"99\"\n    if mm == \"any\":\n        mm = \"0\"\n\n    # Determine whether to use term-centric or field-centric scoring\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, field_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, field_boosts, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, qf_explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse the query terms and their boosts\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse the field boosts\n    field_boosts = parse_field_boosts([pf, pf2, pf3])\n    query_fields = {**field_boosts, **{field: 1 for field in qf}}\n\n    # Determine the query operator\n    if q_op == \"AND\":\n        query_fields = {field: 1 for field in qf}\n\n    # Perform the edismax search\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query, qf)\n\n    if mm is None:\n        if pf is None and pf2 is None and pf3 is None:\n            return frame.search_score(q, q_op=q_op, similarity=similarity)\n        else:\n            return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n"}
{"namespace": "searcharray.solr.edismax", "completion": "    if pf is None and pf2 is None and pf3 is None:\n        raise ValueError(\"At least one of pf, pf2, pf3 must be specified\")\n\n    qf_fields = parse_field_boosts(qf)\n    # if pf, pf2, pf3 are None, they are treated as if they were empty lists\n    pf_fields = parse_field_boosts(pf or [])\n    pf2_fields = parse_field_boosts(pf2 or [])\n    pf3_fields = parse_field_boosts(pf3 or [])\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query=q, query_fields=qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, qf_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, qf_fields, num_search_terms, search_terms, mm, similarity)\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SendMessage:\n            self.server.c2s(process, message)\n        elif message.type == MessageType.RecvMessage:\n            self.server.s2c(process, message)\n        elif message.type == MessageType.CloseMessage:\n            self.close_connection(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND_MESSAGE:\n            self.send_message(process, message)\n        elif message.type == MessageType.RECV_MESSAGE:\n            self.recv_message(process, message)\n        elif message.type == MessageType.CLOSE_MESSAGE:\n            self.close_message(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.CloseMessage:\n            self.close_connection(process)\n            return\n        \n        self.lock.acquire()\n        if message.type == MessageType.SendMessage:\n            self.connections[process.id].send_data(message.data)\n        else:\n            message.data = self.connections[process.id].recv_data()\n        self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SendMessage:\n            self.send_message(process, message)\n        elif message.type == MessageType.RecvMessage:\n            self.recv_message(process, message)\n        elif message.type == MessageType.CloseMessage:\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if process.type == ProcessType.SERVER:\n            self.lock.acquire()\n            try:\n                if message.type == MessageType.SEND:\n                    self.server.c2s(message.data)\n                elif message.type == MessageType.RECV:\n                    self.server.s2c(message.data)\n                elif message.type == MessageType.CLOSE:\n                    self.close_connection(process)\n                else:\n                    raise Exception(f'Unsupported message type {message.type}')\n            finally:\n                self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND_MESSAGE:\n            # SendMessage\n            self.send_message(process, message)\n        elif message.type == MessageType.RECV_MESSAGE:\n            # RecvMessage\n            self.recv_message(process, message)\n        elif message.type == MessageType.CLOSE_MESSAGE:\n            # CloseMessage\n            self.close_connection(process)\n\n        return message\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Send:\n            self.send(process, message)\n        elif message.type == MessageType.Recv:\n            self.recv(process, message)\n        elif message.type == MessageType.Close:\n            self.close(process, message)\n        else:\n            raise ValueError('Invalid message type')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Send:\n            self.intercept_send(process, message)\n\n        elif message.type == MessageType.Receive:\n            self.intercept_recv(process, message)\n\n        elif message.type == MessageType.Close:\n            self.intercept_close(process, message)\n        else:\n            self.logger.error('Unknown message type: %s', message.type)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.CLOSE:\n            with self.lock:\n                if process.connectionId in self.connections:\n                    self.connections[process.connectionId].close()\n                    del self.connections[process.connectionId]\n                    if self.config['autoCloseConnections']:\n                        self.server.close_connection(process.connectionId)\n        elif message.type == MessageType.SEND:\n            with self.lock:\n                if process.connectionId == DEFAULT_CONNECTION_ID:\n                    self.server.send_message(message)\n                elif process.connectionId in self.connections:\n                    self.connections[process.connectionId].c2s(message)\n        elif message.type == MessageType.RECV:\n            with self.lock:\n                if process.connectionId == DEFAULT_CONNECTION_ID:\n                    message.data = self.server.recv_message()\n                elif process.connectionId in self.connections:\n                    message.data = self.connections[process.connectionId].s2c()\n        else:\n            self.logger.error(f\"Unknown message type: {message.type}\")\n            return\n\n        return message\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Send:\n            self.send(process, message)\n        else:\n            self.receive(process, message)\n\n        return\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            if self.config['multipleConnections']:\n                self.lock.acquire()\n                if process.connection_id not in self.connections:\n                    self.connections[process.connection_id] = Connection(\n                        process.connection_id,\n                        process.connection,\n                        self.server,\n                        self.config\n                    )\n                connection = self.connections[process.connection_id]\n                self.lock.release()\n\n            if self.config['autoCloseConnections']:\n                connection.c2s(message.data)\n            else:\n                connection.c2s(message.data, process)\n        elif message.type == MessageType.RECV:\n            if self.config['multipleConnections']:\n                self.lock.acquire()\n                if process.connection_id not in self.connections:\n                    self.connections[process.connection_id] = Connection(\n                        process.connection_id,\n                        process.connection,\n                        self.server,\n                        self.config\n                    )\n                connection = self.connections[process.connection_id]\n                self.lock.release()\n            else:\n                connection = Connection(\n                    DEFAULT_CONNECTION_ID,\n                    process.connection,\n                    self.server,\n                    self.config\n                )\n            connection.s2c(message.data)\n        elif message.type == MessageType.CLOSE:\n            if self.config['multipleConnections']:\n                self.lock.acquire()\n                if process.connection_id in self.connections:\n                    connection = self.connections[process.connection_id]\n                    connection.close()\n                    del self.connections[process.connection_id]\n                self.lock.release()\n                connection.close()\n            else:\n                connection = Connection(\n                    DEFAULT_CONNECTION_ID,\n                    process.connection,\n                    self.server,\n                    self.config\n                )\n                connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND_MESSAGE:\n            if not self.config['multipleConnections']:\n                connection = DEFAULT_CONNECTION_ID\n            else:\n                connection = message.connection_id\n            self.lock.acquire()\n            if connection not in self.connections:\n                self.connections[connection] = Connection(\n                    connection_id=connection,\n                    logger=self.logger\n                )\n                self.connections[connection].start()\n            self.connections[connection].c2s(message.data)\n            self.lock.release()\n        elif message.type == MessageType.RECV_MESSAGE:\n            if not self.config['multipleConnections']:\n                connection = DEFAULT_CONNECTION_ID\n            else:\n                connection = message.connection_id\n            self.lock.acquire()\n            if connection in self.connections:\n                message.data = self.connections[connection].s2c()\n            self.lock.release()\n        elif message.type == MessageType.CLOSE_MESSAGE:\n            if not self.config['multipleConnections']:\n                connection = DEFAULT_CONNECTION_ID\n            else:\n                connection = message.connection_id\n            self.lock.acquire()\n            if connection in self.connections:\n                self.connections[connection].close()\n                if self.config['autoCloseConnections']:\n                    del self.connections[connection]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Send:\n            self.send_message(process, message)\n\n        elif message.type == MessageType.Recv:\n            self.recv_message(process, message)\n\n        elif message.type == MessageType.Close:\n            self.close_message(process, message)\n\n        else:\n            raise Exception('Invalid message type')\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Send:\n            with self.lock:\n                if process.connectionId not in self.connections:\n                    self.connections[process.connectionId] = self.server.create_connection(\n                        process.connectionId)\n\n                connection = self.connections[process.connectionId]\n\n                if self.config['multipleConnections']:\n                    connection.c2s_write(message.data)\n                else:\n                    connection.c2s_write(message.data)\n                    self.server.close_connection(connection)\n                    del self.connections[process.connectionId]\n        elif message.type == MessageType.Recv:\n            with self.lock:\n                if process.connectionId not in self.connections:\n                    self.connections[process.connectionId] = self.server.create_connection(\n                        process.connectionId)\n\n                connection = self.connections[process.connectionId]\n                if self.config['multipleConnections']:\n                    message.data = connection.s2c_read()\n                else:\n                    message.data = connection.s2c_read()\n                    self.server.close_connection(connection)\n                    del self.connections[process.connectionId]\n        elif message.type == MessageType.Close:\n            with self.lock:\n                if process.connectionId in self.connections:\n                    connection = self.connections.get(process.connectionId)\n                    self.server.close_connection(connection)\n                    del self.connections[process.connectionId]\n        else:\n            raise Exception(\n                'ProxifierInterceptor: Unknown message type. Only Send, Recv and Close are supported.')"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Send:\n            self.server.c2s(process, message.data)\n\n        elif message.type == MessageType.Recv:\n            self.server.s2c(process, message.data)\n\n        elif message.type == MessageType.Close:\n            if self.config['autoCloseConnections'] and self.config['multipleConnections'] and process.id in self.connections:\n                self.connections[process.id].close()\n        else:\n            self.logger.warning(f'Unsupported message type {message.type}.')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send_message(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv_message(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close_message(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.is_send():\n            self.c2s(process, message)\n        elif message.is_recv():\n            self.s2c(process, message)\n        elif message.is_close():\n            self.close(process, message)\n        else:\n            self.logger.error('Unknown message type: %s', message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.message_type == MessageTypes.CloseMessage:\n            self.logger.info(\"Proxifier closing connection\")\n            self.close_connection(message.connection_id)\n            return\n        elif message.message_type == MessageTypes.SendMessage:\n            self.logger.info(f\"Proxifier sending {message.message_type} message to connection {message.connection_id}\")\n            self.send_message(message, process.connection_id)\n        elif message.message_type == MessageTypes.RecvMessage:\n            self.logger.info(f\"Proxifier receiving {message.message_type} message from connection {message.connection_id}\")\n            self.recv_message(message, process.connection_id)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == Message.Type.SEND_MESSAGE:\n            if message.connection_id == DEFAULT_CONNECTION_ID:\n                # if the connection is not already proxified, send the message to the server\n                with self.lock:\n                    if message.connection_id not in self.connections:\n                        self.connections[message.connection_id] = Connection(\n                            process_id=process.id,\n                            connection_id=message.connection_id,\n                            c2s=self.server.c2s,\n                            s2c=self.server.s2c,\n                            logger=self.logger\n                        )\n                self.connections[message.connection_id].send(message.data)\n                return\n\n            # if the connection is proxified, send the message to the proxy\n            connection = self.connections[message.connection_id]\n            connection.send(message.data)\n        elif message.type == Message.Type.RECV_MESSAGE:\n            # if the connection is proxified, send the message to the proxy\n            connection = self.connections[message.connection_id]\n            connection.recv()\n        elif message.type == Message.Type.CLOSE_MESSAGE:\n            # if the connection is proxified, close the connection\n            connection = self.connections[message.connection_id]\n            connection.close()\n\n            # if the connection is not proxified and the autoCloseConnections option is enabled, close the connection\n            if not connection.proxified and self.config['autoCloseConnections']:\n                process.close(message.connection_id)\n\n        return"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.Close:\n            self.closeConnection(process)\n        elif message.type == MessageType.Send:\n            self.sendMessage(process, message)\n        elif message.type == MessageType.Recv:\n            self.recvMessage(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.connections.clear()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        \n        self.server.stop()\n        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.connections.values()._close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        if self.server:\n            self.server.stop()\n        self.server = None\n\n        if self.connections:\n            for connection_id, connection in self.connections.items():\n                connection.stop()\n        self.connections = {}\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        for connection in self.connections.values():\n            connection.stop()\n        self.server.join()\n        self.connections.clear()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        for connection_id, connection in self.connections.items():\n            connection.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.connections = {}\n        self.server = None\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        for connection in self.connections.values():\n            connection.close()\n\n        # TODO: should we wait for all connections to be closed?\n\n        # self.server.wait_for_all_connections_to_close()\n\n        # TODO: we should close the server after all connections are closed\n\n        self.server.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n\n        with self.lock:\n            for connection_id in self.connections.keys():\n                self.connections[connection_id].close()\n\n            self.connections.clear()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.connections = {}\n        self.server = None\n        self.lock = None\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        \n        self.server.stop()\n        self._close_connections()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n                self.logger.debug(f'Connection {connection.id} closed')\n            self.connections.clear()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        if self.config['autoCloseConnections']:\n            self.logger.info('Closing all connections...')\n            for connection in self.connections.values():\n                connection.close()\n\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # stop all connections\n        for connection in self.connections.values():\n            connection.close()\n        self.connections.clear()\n\n        # stop the server\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.connections = {}\n        self.server = None\n        self.lock = None\n"}
