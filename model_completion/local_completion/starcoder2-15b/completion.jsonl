{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    import subprocess\n\n    print(cmd)\n    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n    process.wait()\n    return process.returncode\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    import subprocess\n\n    print(cmd)\n    process = subprocess.Popen(cmd, shell=True)\n    process.wait()\n    return process.returncode\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running cmd: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing the following command:\\n{cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = z / scale\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(z_mag_sq)) / 2\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(z_mag_sq)) / (2 - z_mag_sq)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 + jnp.sqrt(z_mag_sq)) / (2 * jnp.sqrt(z_mag_sq) - 1)\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = z / scale\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\"CREATE TABLE IF NOT EXISTS cache (key TEXT PRIMARY KEY, value TEXT)\")\n            key = hashlib.sha256(f\"{func_name}-{str(args)}-{str(kwargs)}\".encode(\"utf-8\")).hexdigest()\n            c.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            row = c.fetchone()\n            if row:\n                conn.close()\n                return json.loads(row[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        \"\"\"\n        This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n        Input-Output Arguments\n        :param func: The function to be memoized. It is used as a key in the SQLite database to store and retrieve the function's output.\n        :return: A decorator function that wraps the original function, adding memoization functionality to it. No direct return value from this function itself.\n        \"\"\"\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            \"\"\"\n            This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n            Input-Output Arguments\n            :param *args: The arguments passed to the function to be memoized.\n            :param **kwargs: The keyword arguments passed to the function to be memoized.\n            :return: The result of the function call, either retrieved from the database or computed and stored in the database.\n            \"\"\"\n\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache (\n                func_name text,\n                args text,\n                kwargs text,\n                result text,\n                PRIMARY KEY (func_name, args, kwargs)\n                )\"\"\"\n            )\n\n            # Convert the arguments to strings\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n\n            # Check if the result is already in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, args_str, kwargs_str),\n            )\n            result = c.fetchone()\n\n            # If the result is in the database, return it\n            if result is not None:\n                result = result[0]\n                return json.loads"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        \"\"\"\n        This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n        Input-Output Arguments\n        :param func: function, The function to be memoized. It is used as a key in the SQLite database to store and retrieve the function's output.\n        :return: A decorator function that wraps the original function, adding memoization functionality to it. No direct return value from this function itself.\n        \"\"\"\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            \"\"\"\n            This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n            Input-Output Arguments\n            :param args: tuple, The positional arguments passed to the function to be memoized. They are used as a key in the SQLite database to store and retrieve the function's output.\n            :param kwargs: dict, The keyword arguments passed to the function to be memoized. They are used as a key in the SQLite database to store and retrieve the function's output.\n            :return: The result of the function call, either retrieved from the database or computed and then stored in the database.\n            \"\"\"\n\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs\n            c.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT NOT NULL,\n                    args TEXT NOT NULL,\n                    kwargs TEXT NOT NULL,\n                    output TEXT NOT NULL\n                )\n                \"\"\"\n            )\n\n            # Create a unique key for the function call\n            key = hashlib.sha256(\n                (func_name + str(args) + str(kwargs)).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Check if the function output is already stored in the database\n            c.execute(\n                \"\"\"\n                SELECT output FROM cache WHERE func_name=? AND args=?"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        \"\"\"\n        This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n        Input-Output Arguments\n        :param func: The function to be memoized. It is used as a key in the SQLite database to store and retrieve the function's output.\n        :return: A decorator function that wraps the original function, adding memoization functionality to it. No direct return value from this function itself.\n        \"\"\"\n\n        def wrapper(*args, **kwargs):\n\n            \"\"\"\n            This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n            Input-Output Arguments\n            :param *args: The positional arguments passed to the function. They are used to generate a unique hash key for the function call.\n            :param **kwargs: The keyword arguments passed to the function. They are used to generate a unique hash key for the function call.\n            :return: The result of the function call, either retrieved from the database or computed and stored in the database.\n            \"\"\"\n\n            # Create a connection to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Generate a unique hash key for the function call\n            key = hashlib.sha256(str(args).encode() + str(kwargs).encode()).hexdigest()\n\n            # Check if the result of the function call is already stored in the database\n            c.execute(\"SELECT result FROM cache WHERE func_name = ? AND key = ?\", (func_name, key))\n            row = c.fetchone()\n\n            # If the result is already stored in the database, retrieve it and return it\n            if row is not None:\n                return json.loads(row[0])\n\n            # Otherwise, compute the result, store it in the database, and then return it\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache VALUES (?, ?,"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        def wrapper(*args, **kwargs):\n\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n\n            # Create the table if it doesn't exist\n            cursor.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, output TEXT)\"\n            )\n\n            # Check if the result is already in the database\n            cursor.execute(\n                \"SELECT * FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, json.dumps(args), json.dumps(kwargs)),\n            )\n            row = cursor.fetchone()\n\n            if row is not None:\n                # If the result is already in the database, return it\n                return json.loads(row[3])\n            else:\n                # If the result is not in the database, compute it, store it, and return it\n                output = func(*args, **kwargs)\n                cursor.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, output) VALUES (?, ?, ?, ?)\",\n                    (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(output)),\n                )\n                conn.commit()\n                return output\n\n        return wrapper\n\n    return decorator\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        \"\"\"\n        This is a decorator function that wraps the original function, adding memoization functionality to it. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n        Input-Output Arguments\n        :param func: The original function to be memoized.\n        :return: The memoized version of the original function.\n        \"\"\"\n\n        def memoized(*args, **kwargs):\n\n            \"\"\"\n            This is the memoized version of the original function. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n            Input-Output Arguments\n            :param args: The positional arguments of the original function.\n            :param kwargs: The keyword arguments of the original function.\n            :return: The result of the original function, either retrieved from the database or computed and then stored in the database.\n            \"\"\"\n\n            # Create a connection to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table for the function's outputs if it doesn't exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS {} (hash TEXT PRIMARY KEY, output TEXT)\".format(\n                    func_name\n                )\n            )\n\n            # Compute the hash of the function's arguments\n            hash_str = hashlib.sha256(\n                json.dumps(args, sort_keys=True).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Check if the hash is already in the database\n            c.execute(\"SELECT output FROM {} WHERE hash=?\".format(func_name), (hash_str,))\n            row = c.fetchone()\n\n            # If the hash is in the database, return the cached output\n            if row is not None:\n                return json.loads(row[0])\n\n            # If the hash is not in the database, compute the function's output, store it in the database, and return it\n            else:\n                output = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO {} VALUES (?, ?)\".format(func_name),\n                    (hash_str, json.dumps(output)),\n                )\n                conn.commit()\n                return output\n\n       "}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        \"\"\"\n        This function acts as a decorator for memoization, caching the output of a function in a SQLite database to avoid redundant computations. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n        Input-Output Arguments\n        :param func: The function to be memoized. It is used as a key in the SQLite database to store and retrieve the function's output.\n        :return: A decorator function that wraps the original function, adding memoization functionality to it. No direct return value from this function itself.\n        \"\"\"\n\n        def wrapper(*args, **kwargs):\n\n            \"\"\"\n            This function is a wrapper for the original function, adding memoization functionality to it. It checks if the result of a function call is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n            Input-Output Arguments\n            :param args: The positional arguments passed to the original function.\n            :param kwargs: The keyword arguments passed to the original function.\n            :return: The result of the original function, either retrieved from the database or computed.\n            \"\"\"\n\n            db = sqlite3.connect(filename)\n            c = db.cursor()\n\n            # Create a table if it doesn't exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, hash TEXT, output TEXT)\"\n            )\n\n            # Hash the arguments\n            arg_hash = hashlib.sha256(json.dumps(args).encode()).hexdigest()\n            kwarg_hash = hashlib.sha256(json.dumps(kwargs).encode()).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(\n                \"SELECT output FROM cache WHERE func_name=? AND args=? AND kwargs=? AND hash=?\",\n                (func_name, arg_hash, kwarg_hash, arg_hash + kwarg_hash),\n            )\n            row = c.fetchone()\n\n            # If so, return the result\n            if row:\n                db.close()\n                return json.loads(row[0])\n\n            # Otherwise, compute the result, store it in the database, and return it\n            result = func(*"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        def wrapper(*args, **kwargs):\n\n            # Create a connection to the SQLite database\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n\n            # Create a table if it does not exist\n            cursor.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\"\"\n            )\n\n            # Create a hash of the function arguments to uniquely identify each function call\n            args_hash = hashlib.md5(str(args).encode()).hexdigest()\n            kwargs_hash = hashlib.md5(str(kwargs).encode()).hexdigest()\n\n            # Check if the result is already stored in the database\n            cursor.execute(\n                \"\"\"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\"\"\",\n                (func_name, args_hash, kwargs_hash),\n            )\n            row = cursor.fetchone()\n\n            # If the result is already stored, return it\n            if row:\n                return json.loads(row[0])\n\n            # Otherwise, compute the result, store it in the database, and return it\n            result = func(*args, **kwargs)\n            cursor.execute(\n                \"\"\"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\"\"\",\n                (func_name, args_hash, kwargs_hash, json.dumps(result)),\n            )\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n            cursor.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\n            )\n            cursor.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, json.dumps(args), json.dumps(kwargs)),\n            )\n            result = cursor.fetchone()\n            if result is None:\n                result = func(*args, **kwargs)\n                cursor.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                    (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(result)),\n                )\n                conn.commit()\n            else:\n                result = json.loads(result[0])\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            db = sqlite3.connect(filename)\n            db.execute(\"CREATE TABLE IF NOT EXISTS cache (key TEXT PRIMARY KEY, value TEXT)\")\n            db.commit()\n            key = func_name + str(args) + str(kwargs)\n            key = hashlib.sha256(key.encode()).hexdigest()\n            cursor = db.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            result = cursor.fetchone()\n            if result:\n                db.close()\n                return json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                db.execute(\"INSERT INTO cache (key, value) VALUES (?, ?)\", (key, json.dumps(result)))\n                db.commit()\n                db.close()\n                return result\n        return wrapper\n    return decorator\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        \"\"\"\n        This is the decorator function that wraps the original function, adding memoization functionality to it. It takes a function as input and returns a new function that wraps the original function. The new function checks if the output of the original function is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n        Input-Output Arguments\n        :param func: The original function to be wrapped.\n        :return: A new function that wraps the original function, adding memoization functionality to it.\n        \"\"\"\n\n        def wrapper(*args, **kwargs):\n            \"\"\"\n            This is the wrapper function that wraps the original function, adding memoization functionality to it. It takes any number of positional arguments and any number of keyword arguments and returns a new function that wraps the original function. The new function checks if the output of the original function is already stored in the database; if so, it retrieves the result from the database, otherwise, it computes the result, stores it, and then returns it.\n\n            Input-Output Arguments\n            :param *args: Any number of positional arguments.\n            :param **kwargs: Any number of keyword arguments.\n            :return: A new function that wraps the original function, adding memoization functionality to it.\n            \"\"\"\n\n            def hash_args(*args, **kwargs):\n                \"\"\"\n                This is a helper function that hashes the arguments of the original function. It takes any number of positional arguments and any number of keyword arguments and returns a hash of the arguments.\n\n                Input-Output Arguments\n                :param *args: Any number of positional arguments.\n                :param **kwargs: Any number of keyword arguments.\n                :return: A hash of the arguments of the original function.\n                \"\"\"\n\n                def hash_value(value):\n                    \"\"\"\n                    This is a helper function that hashes the value of the argument. It takes a value as input and returns a hash of the value.\n\n                    Input-Output Arguments\n                    :param value: The value of the argument.\n                    :return: A hash of the value of the argument.\n                    \"\"\"\n\n                    def hash_dict(d):\n                        \"\"\"\n                        This is a helper function that hashes the dictionary of the argument. It takes a dictionary as input and returns a hash of the dictionary.\n\n                        Input-Output Arguments\n                        :param d: The dictionary of the argument.\n                        :return: A hash of"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Create a connection to the SQLite database\n            conn = sqlite3.connect(filename)\n            # Create a cursor to execute SQL commands\n            c = conn.cursor()\n            # Create a table in the SQLite database to store the function outputs\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS {} (hash TEXT PRIMARY KEY, result TEXT)\"\"\".format(\n                    func_name\n                )\n            )\n            # Create a unique hash for the function call based on the arguments and keyword arguments\n            hash_key = hashlib.sha256(\n                json.dumps(args, sort_keys=True).encode()\n                + json.dumps(kwargs, sort_keys=True).encode()\n            ).hexdigest()\n            # Check if the function output is already stored in the database\n            c.execute(\n                \"\"\"SELECT result FROM {} WHERE hash = ?\"\"\".format(func_name), (hash_key,)\n            )\n            # If the function output is already stored, retrieve it from the database\n            result = c.fetchone()\n            if result:\n                result = json.loads(result[0])\n            # Otherwise, compute the function output, store it in the database, and return it\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"\"\"INSERT INTO {} VALUES (?, ?)\"\"\".format(func_name),\n                    (hash_key, json.dumps(result)),\n                )\n                conn.commit()\n            # Close the connection to the SQLite database\n            conn.close()\n            # Return the function output\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs\n            c.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT,\n                    args TEXT,\n                    kwargs TEXT,\n                    result TEXT\n                )\n                \"\"\"\n            )\n\n            # Serialize the arguments and keyword arguments\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n\n            # Compute the hash of the arguments and keyword arguments\n            hash_args = hashlib.sha256(args_str.encode()).hexdigest()\n            hash_kwargs = hashlib.sha256(kwargs_str.encode()).hexdigest()\n\n            # Query the database to check if the function output is already stored\n            c.execute(\n                \"\"\"\n                SELECT result\n                FROM cache\n                WHERE func_name = ? AND args = ? AND kwargs = ?\n                \"\"\",\n                (func_name, hash_args, hash_kwargs),\n            )\n            result = c.fetchone()\n\n            # If the function output is not stored, compute it and store it in the database\n            if result is None:\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"\"\"\n                    INSERT INTO cache (func_name, args, kwargs, result)\n                    VALUES (?, ?, ?, ?)\n                    \"\"\",\n                    (func_name, hash_args, hash_kwargs, json.dumps(result)),\n                )\n                conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            # Return the function output\n            return json.loads(result)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            db = sqlite3.connect(filename)\n            cursor = db.cursor()\n            cursor.execute(\"SELECT * FROM cache WHERE key = ?\", (func_name,))\n            row = cursor.fetchone()\n            if row is None:\n                value = func(*args, **kwargs)\n                value_hash = hashlib.md5(str(value).encode(\"utf-8\")).hexdigest()\n                cursor.execute(\n                    \"INSERT INTO cache (key, value, value_hash) VALUES (?, ?, ?)\",\n                    (func_name, json.dumps(value), value_hash),\n                )\n                db.commit()\n                db.close()\n                return value\n            else:\n                value = json.loads(row[1])\n                value_hash = hashlib.md5(str(value).encode(\"utf-8\")).hexdigest()\n                if value_hash == row[2]:\n                    db.close()\n                    return value\n                else:\n                    value = func(*args, **kwargs)\n                    value_hash = hashlib.md5(str(value).encode(\"utf-8\")).hexdigest()\n                    cursor.execute(\n                        \"UPDATE cache SET value = ?, value_hash = ? WHERE key = ?\",\n                        (json.dumps(value), value_hash, func_name),\n                    )\n                    db.commit()\n                    db.close()\n                    return value\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\n                f\"\"\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT PRIMARY KEY, kwargs TEXT, result TEXT)\"\"\"\n            )\n            args_hash = hashlib.sha256(str(args).encode()).hexdigest()\n            kwargs_hash = hashlib.sha256(str(kwargs).encode()).hexdigest()\n            c.execute(\n                f\"\"\"SELECT result FROM {func_name} WHERE args=? AND kwargs=?\"\"\",\n                (args_hash, kwargs_hash),\n            )\n            result = c.fetchone()\n            if result is None:\n                result = func(*args, **kwargs)\n                c.execute(\n                    f\"\"\"INSERT INTO {func_name} (args, kwargs, result) VALUES (?, ?, ?)\"\"\",\n                    (args_hash, kwargs_hash, json.dumps(result)),\n                )\n                conn.commit()\n            else:\n                result = json.loads(result[0])\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the database and create a table if it doesn't exist\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\n            )\n            conn.commit()\n\n            # Create a hash of the function arguments to uniquely identify the function call\n            hash_args = hashlib.md5(repr(args).encode(\"utf-8\")).hexdigest()\n            hash_kwargs = hashlib.md5(repr(kwargs).encode(\"utf-8\")).hexdigest()\n\n            # Check if the function output is already cached in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, hash_args, hash_kwargs),\n            )\n            result = c.fetchone()\n\n            # If the function output is cached, return it\n            if result is not None:\n                return json.loads(result[0])\n\n            # Otherwise, compute the function output, cache it, and return it\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO cache VALUES (?, ?, ?, ?)\",\n                    (func_name, hash_args, hash_kwargs, json.dumps(result)),\n                )\n                conn.commit()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        def wrapper(*args, **kwargs):\n\n            # Open the database connection and create a cursor\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table if it doesn't already exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (key TEXT PRIMARY KEY, value TEXT)\"\n            )\n\n            # Create a hash of the function name and arguments\n            key = hashlib.sha1(\n                f\"{func_name}{args}{json.dumps(kwargs)}\".encode()\n            ).hexdigest()\n\n            # Check if the result is already stored in the database\n            c.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            row = c.fetchone()\n\n            # If the result is already stored, return it\n            if row is not None:\n                conn.close()\n                return json.loads(row[0])\n\n            # Otherwise, compute the result, store it in the database, and return it\n            result = func(*args, **kwargs)\n            c.execute(\"INSERT INTO cache VALUES (?, ?)\", (key, json.dumps(result)))\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\n                f\"\"\"CREATE TABLE IF NOT EXISTS {func_name} (id TEXT PRIMARY KEY, args TEXT, kwargs TEXT, output TEXT)\"\"\"\n            )\n            key = hashlib.md5(str(args).encode(\"utf-8\")).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE id=?\", (key,))\n            row = c.fetchone()\n            if row is None:\n                output = func(*args, **kwargs)\n                c.execute(\n                    f\"\"\"INSERT INTO {func_name} (id, args, kwargs, output) VALUES (?, ?, ?, ?)\"\"\",\n                    (key, str(args), json.dumps(kwargs), json.dumps(output)),\n                )\n                conn.commit()\n                return output\n            else:\n                return json.loads(row[0])\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\n            )\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, json.dumps(args), json.dumps(kwargs)),\n            )\n            result = c.fetchone()\n            if result:\n                result = json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO cache VALUES (?, ?, ?, ?)\",\n                    (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(result)),\n                )\n                conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\n                f\"\"\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT, kwargs TEXT, result TEXT)\"\"\"\n            )\n            args_hash = hashlib.sha256(\n                json.dumps(args, sort_keys=True).encode(\"utf-8\")\n            ).hexdigest()\n            kwargs_hash = hashlib.sha256(\n                json.dumps(kwargs, sort_keys=True).encode(\"utf-8\")\n            ).hexdigest()\n            c.execute(\n                f\"\"\"SELECT result FROM {func_name} WHERE args = ? AND kwargs = ?\"\"\",\n                (args_hash, kwargs_hash),\n            )\n            result = c.fetchone()\n            if result is None:\n                result = func(*args, **kwargs)\n                c.execute(\n                    f\"\"\"INSERT INTO {func_name} (args, kwargs, result) VALUES (?, ?, ?)\"\"\",\n                    (args_hash, kwargs_hash, json.dumps(result)),\n                )\n                conn.commit()\n            else:\n                result = json.loads(result[0])\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: x_min must be less than x_max. Received {values['x_min']}, {values['x_max']}\"\n        )\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: y_min must be less than y_max. Received {values['y_min']}, {values['y_max']}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {x_min} and {x_max}.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {y_min} and {y_max}.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: x_min ({values['x_min']}) must be less than x_max ({values['x_max']})\"\n        )\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: y_min ({values['y_min']}) must be less than y_max ({values['y_max']})\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values}\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {x_min} and {x_max}\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {y_min} and {y_max}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n    if x_min >= x_max or y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: bounding box is invalid.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  sq_norm0 = np.sum(mat0**2, axis=0, keepdims=True)\n  sq_norm1 = np.sum(mat1**2, axis=0, keepdims=True)\n  dist = sq_norm0 - 2 * np.dot(mat0.T, mat1) + sq_norm1.T\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm0 = np.sum(mat0**2, axis=0)\n  sq_norm1 = np.sum(mat1**2, axis=0)\n  dist = -2 * np.matmul(mat0.T, mat1)\n  dist += sq_norm0[:, np.newaxis]\n  dist += sq_norm1[np.newaxis, :]\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dist = np.sum(mat0**2, axis=0)[:, None] + np.sum(mat1**2, axis=0) - 2 * mat0.T @ mat1\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  return np.sum(mat0**2, axis=0)[:, None] + np.sum(mat1**2, axis=0)[None, :] - 2 * np.dot(mat0.T, mat1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  mat0_norms = np.sum(mat0**2, axis=0)\n  mat1_norms = np.sum(mat1**2, axis=0)\n  dist_mat = np.matmul(mat0.T, mat1)\n  dist_mat *= -2\n  dist_mat += mat0_norms\n  dist_mat += mat1_norms.T\n  dist_mat = np.maximum(dist_mat, 0)\n  return dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norm_sq = np.sum(np.square(mat0), axis=0, keepdims=True)\n  mat1_norm_sq = np.sum(np.square(mat1), axis=0, keepdims=True)\n  mat0_mat1_dot = np.matmul(mat0.T, mat1)\n  sq_dist = mat0_norm_sq + mat1_norm_sq.T - 2 * mat0_mat1_dot\n  sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  dist = np.sum(mat0**2, axis=0)[:, np.newaxis] + np.sum(mat1**2, axis=0) - 2*np.dot(mat0.T, mat1)\n  dist[dist < 0] = 0\n\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  dist = np.sum(mat0**2, axis=0)[:, None] + np.sum(mat1**2, axis=0) - 2 * mat0.T @ mat1\n\n  # set negative values to zero due to numerical errors\n  dist[dist < 0] = 0\n\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute squared norms of columns of mat0 and mat1\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n\n  # Compute dot product of mat0 and mat1\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute squared distances\n  dist = norm0[:, None] + norm1 - 2 * dot\n\n  # Set negative distances to zero\n  dist[dist < 0] = 0\n\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n  dist = norm0[:, None] + norm1[None, :] - 2 * mat0.T @ mat1\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  # If only one matrix is provided, compute distances among columns of the same matrix\n  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the squared norms of the columns of both matrices\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n\n  # Compute the dot product between the columns of both matrices\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute the squared distances between all pairs of columns\n  sq_dist = np.maximum(norm0[:, None] + norm1 - 2*dot, 0)\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n  dist = np.maximum(0, norm0[:, None] + norm1[None, :] - 2 * mat0.T @ mat1)\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  # If the second matrix is not provided, use the first matrix for both sets of vectors.\n  if mat1 is None:\n    mat1 = mat0\n\n  # Calculate the squared norms of the columns of the first matrix.\n  sq_norm0 = np.sum(mat0**2, axis=0)\n\n  # Calculate the squared norms of the columns of the second matrix.\n  sq_norm1 = np.sum(mat1**2, axis=0)\n\n  # Calculate the dot product between the columns of the two matrices.\n  dot_prod = mat0.T @ mat1\n\n  # Calculate the squared distances between the columns of the two matrices.\n  sq_dist = sq_norm0[:, None] + sq_norm1[None, :] - 2 * dot_prod\n\n  # Set negative distances to zero to avoid numerical errors.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm0 = np.sum(mat0**2, axis=0)\n  sq_norm1 = np.sum(mat1**2, axis=0)\n\n  # Compute the dot product between all pairs of columns in mat0 and mat1.\n  # This is equivalent to computing the matrix of pairwise dot products between\n  # the columns of mat0 and mat1.\n  dot_prod = mat0.T @ mat1\n\n  # Compute the squared distances between all pairs of columns in mat0 and mat1.\n  # This is equivalent to computing the matrix of pairwise squared distances\n  # between the columns of mat0 and mat1.\n  sq_dist = np.abs(sq_norm0[:, np.newaxis] + sq_norm1 - 2 * dot_prod)\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # compute the squared norms of the columns of mat0 and mat1\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n\n  # compute the dot product between columns of mat0 and mat1\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # compute the squared distances between columns of mat0 and mat1\n  sq_dists = np.expand_dims(norm0, axis=1) + np.expand_dims(norm1, axis=0) - 2 * dot_prod\n\n  # set negative distances to zero\n  sq_dists[sq_dists < 0] = 0\n\n  return sq_dists\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  # If the second matrix is not provided, use the first matrix for both sets of vectors.\n  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the squared norms of each vector in mat0 and mat1.\n  norm0 = np.sum(mat0 * mat0, axis=0)\n  norm1 = np.sum(mat1 * mat1, axis=0)\n\n  # Compute the squared distances between all pairs of vectors.\n  dist_sq = np.tile(norm0, (mat1.shape[1], 1)).T + np.tile(norm1, (mat0.shape[1], 1)) - 2 * np.dot(mat0.T, mat1)\n\n  # Set negative distances to zero to avoid numerical errors.\n  dist_sq[dist_sq < 0] = 0\n\n  return dist_sq\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the squared norms of each column in the two matrices.\n  norm0 = np.sum(mat0 * mat0, axis=0)\n  norm1 = np.sum(mat1 * mat1, axis=0)\n\n  # Compute the dot product between each pair of columns in the two matrices.\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance between each pair of columns in the two matrices.\n  dist = norm0[:, None] + norm1[None, :] - 2 * dot\n\n  # Set negative distances to zero to avoid numerical errors.\n  dist[dist < 0] = 0\n\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  mat0_norm = np.sum(mat0**2, axis=0)\n  mat1_norm = np.sum(mat1**2, axis=0)\n  dist = mat0_norm[:, None] + mat1_norm[None, :] - 2 * mat0.T @ mat1\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm0 = np.sum(np.square(mat0), axis=0)\n  norm1 = np.sum(np.square(mat1), axis=0)\n  dist = np.maximum(0, norm0[:, None] + norm1[None, :] - 2 * mat0.T @ mat1)\n\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  mat0_norm_sq = np.sum(np.square(mat0), axis=0, keepdims=True)\n  mat1_norm_sq = np.sum(np.square(mat1), axis=0, keepdims=True)\n  mat0_mat1_dot = np.matmul(np.transpose(mat0), mat1)\n\n  dist_sq = mat0_norm_sq + np.transpose(mat1_norm_sq) - 2 * mat0_mat1_dot\n\n  dist_sq[dist_sq < 0] = 0\n\n  return dist_sq\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"http://\") or path.startswith(\"https://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"gs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"file://\") or path.startswith(\"https://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\n        \"https://\"\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"https://\") or path.startswith(\"http://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"https://\") or path.startswith(\"http://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"https://\") or path.startswith(\n        \"gs://\"\n    ):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\n        \"https://\"\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"https://\") or path.startswith(\"s3://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"file://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"https://\") or path.startswith(\"http://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"lightning://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"file://\") or path.startswith(\"s3://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"lightning://\") or path.startswith(\"http://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"http://\") or path.startswith(\"https://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"https://\") or path.startswith(\"http://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"file://\") or path.startswith(\"s3://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path:\n        return True\n    if path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"file://\") or path.startswith(\"https://\")\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(f\"Expected dim to be 1 or 2, got {dim}\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"Expected assets_names to be not None when items is a dictionary, got {assets_names}\"\n            )\n\n        if dim == 1:\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {name} to be a dictionary with {n_assets} elements, got {len(items)}\"\n                )\n            arr = np.full(n_assets, fill_value=fill_value, dtype=float)\n            for asset, value in items.items():\n                if asset not in assets_names:\n                    raise ValueError(\n                        f\"Expected {name} to contain only the assets {assets_names}, got {asset}\"\n                    )\n                arr[np.where(assets_names == asset)] = value\n        else:\n            arr = np.full((n_assets, n_assets), fill_value=fill_value, dtype=float)\n            for asset, value in items.items():\n                if asset not in assets_names:\n                    raise ValueError(\n                        f\"Expected {name} to contain only the assets {assets_names}, got {asset}\"\n                    )\n                for asset_2, value_2 in value.items():\n                    if asset_2 not in assets_names:\n                        raise ValueError(\n                            f\"Expected {name} to contain only the assets {assets_names}, got {asset_2}\"\n                        )\n                    arr[np.where(assets_names == asset), np.where(assets_names == asset_2)] = value_2\n    else:\n        arr = np.asarray(items)\n\n    if dim == 1:\n        if arr.shape != (n_assets,):\n            raise ValueError(\n                f\"Expected {name} to be a 1D array with shape ({n_assets},), got {arr.shape}\"\n            )\n    else:\n        if arr.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"Expected {name} to be a 2D array with shape ({n_assets}, {n_assets}), got {arr.shape}\"\n            )\n\n    return arr\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        # Convert the dictionary to a numpy array\n        items = np.full((n_assets,), fill_value, dtype=np.float64)\n        for asset, value in items.items():\n            if asset in assets_names:\n                items[np.where(assets_names == asset)] = value\n            else:\n                raise ValueError(\n                    f\"The asset '{asset}' is not present in the 'assets_names' array.\"\n                )\n\n    # Convert the array-like to a numpy array\n    items = np.asarray(items)\n\n    # Verify the array's dimensions and shape\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"The '{name}' array must be one-dimensional, but has {items.ndim} dimensions.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The '{name}' array must have shape ({n_assets},), but has shape {items.shape}.\"\n            )\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"The '{name}' array must be two-dimensional, but has {items.ndim} dimensions.\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The '{name}' array must have shape ({n_assets},), but has shape {items.shape}.\"\n            )\n    else:\n        raise ValueError(\n            f\"The 'dim' argument must be either 1 or 2, but got {dim}.\"\n        )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            items = [items.get(asset, fill_value) for asset in assets_names]\n        else:\n            items = [\n                [items.get((group, asset), fill_value) for asset in assets_names]\n                for group in range(dim)\n            ]\n        items = np.array(items)\n    else:\n        items = np.asarray(items)\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"Expected {name} to be a 1-dimensional array, got {items.ndim} \"\n                f\"dimensions.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have shape ({n_assets},), got \"\n                f\"{items.shape}.\"\n            )\n    else:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"Expected {name} to be a 2-dimensional array, got {items.ndim} \"\n                f\"dimensions.\"\n            )\n        if items.shape[0] != dim:\n            raise ValueError(\n                f\"Expected {name} to have shape ({dim}, {n_assets}), got \"\n                f\"{items.shape}.\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"Expected {name} to have shape ({dim}, {n_assets}), got \"\n                f\"{items.shape}.\"\n            )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n            for asset, value in items.items():\n                array[np.where(assets_names == asset)] = value\n        elif dim == 2:\n            array = np.full((n_assets, n_assets), fill_value)\n            for asset, value in items.items():\n                array[np.where(assets_names == asset), :] = value\n        else:\n            raise ValueError(f\"Expected dim=1 or 2, got {dim}\")\n    else:\n        array = np.asarray(items)\n        if dim == 1:\n            if array.shape != (n_assets,):\n                raise ValueError(\n                    f\"Expected shape ({n_assets},), got {array.shape} for '{name}'\"\n                )\n        elif dim == 2:\n            if array.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"Expected shape ({n_assets}, {n_assets}), got {array.shape} for\"\n                    f\" '{name}'\"\n                )\n        else:\n            raise ValueError(f\"Expected dim=1 or 2, got {dim}\")\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"If 'items' is a dictionary, 'assets_names' must have length \"\n                f\"{n_assets}, got {len(assets_names)}\"\n            )\n        if dim == 1:\n            return np.array([items.get(asset, fill_value) for asset in assets_names])\n        if dim == 2:\n            return np.array(\n                [\n                    [items.get((group, asset), fill_value) for asset in assets_names]\n                    for group in range(n_assets)\n                ]\n            )\n\n    if dim == 1:\n        return np.asarray(items, dtype=float).reshape(n_assets)\n    if dim == 2:\n        return np.asarray(items, dtype=float).reshape(n_assets, n_assets)\n    raise ValueError(f\"Expected 'dim' to be 1 or 2, got {dim}\")\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The length of 'assets_names' ({len(assets_names)}) does not match the expected number of assets ({n_assets}).\"\n            )\n        if dim == 1:\n            arr = np.full(n_assets, fill_value, dtype=np.float64)\n            for i, name in enumerate(assets_names):\n                if name in items:\n                    arr[i] = items[name]\n            return arr\n        elif dim == 2:\n            arr = np.full((n_assets, n_assets), fill_value, dtype=np.float64)\n            for i, name in enumerate(assets_names):\n                if name in items:\n                    arr[i] = items[name]\n            return arr\n        else:\n            raise ValueError(f\"The dimension 'dim' must be 1 or 2, got {dim}.\")\n    elif isinstance(items, np.ndarray):\n        if dim == 1 and items.shape == (n_assets,):\n            return items\n        elif dim == 2 and items.shape == (n_assets, n_assets):\n            return items\n        else:\n            raise ValueError(\n                f\"The shape of the array 'items' ({items.shape}) does not match the expected shape ({(n_assets, n_assets)}).\"\n            )\n    else:\n        raise ValueError(\n            f\"The input 'items' must be a dictionary, numpy array, or any array-like structure, got {type(items)}.\"\n        )\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"You must provide the assets names when providing a dictionary for \"\n                f\"the '{name}' argument.\"\n            )\n        if dim == 1:\n            items = np.array([items.get(a, fill_value) for a in assets_names])\n        else:\n            items = np.array(\n                [\n                    [items.get(a, fill_value) for a in assets_names]\n                    for _ in range(n_assets)\n                ]\n            )\n    else:\n        items = np.asarray(items)\n        if dim == 1:\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The '{name}' argument must be of shape ({n_assets},), got \"\n                    f\"{items.shape}.\"\n                )\n        else:\n            if items.shape[0] != n_assets or items.shape[1] != n_assets:\n                raise ValueError(\n                    f\"The '{name}' argument must be of shape ({n_assets}, {n_assets}),\"\n                    f\" got {items.shape}.\"\n                )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            items = np.array([items.get(asset, fill_value) for asset in assets_names])\n        else:\n            items = np.array(\n                [\n                    [items.get(asset, fill_value) for asset in assets_names]\n                    for _ in range(dim)\n                ]\n            )\n    else:\n        items = np.array(items)\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"The {name} must be a 1D array, got {items.ndim}D array.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The {name} must have shape ({n_assets},), got {items.shape}.\"\n            )\n    else:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"The {name} must be a 2D array, got {items.ndim}D array.\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The {name} must have shape ({dim}, {n_assets}), got {items.shape}.\"\n            )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"The {name} must be a numpy array when assets_names is not provided\"\n            )\n        if dim == 1:\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"The {name} must be a numpy array of shape (n_assets,) when \"\n                    f\"assets_names is provided\"\n                )\n        else:\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"The {name} must be a numpy array of shape (n_groups, n_assets) \"\n                    f\"when assets_names is provided\"\n                )\n        arr = np.full((n_assets,), fill_value=fill_value, dtype=float)\n        for asset_name in assets_names:\n            if asset_name in items:\n                arr[asset_name] = items[asset_name]\n        if dim == 1:\n            return arr\n        else:\n            return np.tile(arr, (n_assets, 1))\n    else:\n        if dim == 1:\n            if items.shape != (n_assets,):\n                raise ValueError(\n                    f\"The {name} must be a numpy array of shape (n_assets,) when \"\n                    f\"assets_names is not provided\"\n                )\n        else:\n            if items.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"The {name} must be a numpy array of shape (n_groups, n_assets) \"\n                    f\"when assets_names is not provided\"\n                )\n        return np.asarray(items, dtype=float)\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # If items is a dictionary, convert it to a numpy array\n    if isinstance(items, dict):\n        # If assets_names is not provided, use the keys of the dictionary as assets_names\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        # Create an empty array to store the values\n        values = np.empty((n_assets,), dtype=np.float64)\n        # Fill the array with values from the dictionary, using fill_value for missing keys\n        for i, asset_name in enumerate(assets_names):\n            values[i] = items.get(asset_name, fill_value)\n        # Convert the array to the desired dimension\n        if dim == 1:\n            items = values\n        elif dim == 2:\n            items = values.reshape((1, -1))\n        else:\n            raise ValueError(\n                f\"Invalid dimension {dim} for {name}. Expected 1 or 2.\"\n            )\n    # If items is already an array, convert it to a numpy array\n    elif isinstance(items, np.ndarray):\n        items = items\n    # If items is not an array, convert it to a numpy array\n    else:\n        items = np.array(items)\n\n    # Verify the dimensions and shape of the array\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"Invalid dimension {items.ndim} for {name}. Expected 1.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Invalid shape {items.shape} for {name}. Expected ({n_assets},).\"\n            )\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"Invalid dimension {items.ndim} for {name}. Expected 2.\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"Invalid shape {items.shape} for {name}. Expected (?, {n_assets}).\"\n            )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check if the items are a dictionary and convert to array\n    if isinstance(items, dict):\n        # Check if the assets_names is provided\n        if assets_names is None:\n            raise ValueError(\n                f\"Expected 'assets_names' to be provided when 'items' is a dictionary, \"\n                f\"got {assets_names}\"\n            )\n        # Check if the assets_names is a numpy array\n        if not isinstance(assets_names, np.ndarray):\n            raise TypeError(\n                f\"Expected 'assets_names' to be a numpy array, got {type(assets_names)}\"\n            )\n        # Check if the assets_names is 1D\n        if assets_names.ndim != 1:\n            raise ValueError(\n                f\"Expected 'assets_names' to be a 1D array, got {assets_names.ndim}D\"\n            )\n        # Check if the assets_names has the correct number of assets\n        if assets_names.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected 'assets_names' to have {n_assets} assets, got \"\n                f\"{assets_names.shape[0]}\"\n            )\n        # Check if the assets_names is unique\n        if len(assets_names) != len(set(assets_names)):\n            raise ValueError(\n                f\"Expected 'assets_names' to have unique assets, got \"\n                f\"{assets_names}\"\n            )\n        # Check if the assets_names is of type string\n        if not isinstance(assets_names[0], str):\n            raise TypeError(\n                f\"Expected 'assets_names' to be of type string, got \"\n                f\"{type(assets_names[0])}\"\n            )\n        # Convert the dictionary to a numpy array\n        items = np.array([items.get(name, fill_value) for name in assets_names])\n\n    # Check if the items are array-like\n    if not isinstance(items, npt.ArrayLike):\n        raise TypeError(\n            f\"Expected '{name}' to be array-like, got {type(items)}\"\n        )\n\n    # Convert the items to a numpy array\n    items = np.asarray(items)\n\n    # Check if the items is 1D or 2D\n    if items.ndim not in [1, 2]:\n        raise ValueError(\n            f\""}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        # Check if the dictionary keys are strings\n        if not all(isinstance(key, str) for key in items.keys()):\n            raise ValueError(\n                f\"The keys of the dictionary '{name}' must be strings, \"\n                f\"got {type(items.keys())}\"\n            )\n\n        # Check if the dictionary keys are asset names\n        if assets_names is not None and not set(items.keys()).issubset(\n            set(assets_names)\n        ):\n            raise ValueError(\n                f\"The keys of the dictionary '{name}' must be asset names, \"\n                f\"got {items.keys()}\"\n            )\n\n        # Fill missing values with the specified fill_value\n        items = {key: fill_value for key in assets_names if key not in items} | items\n\n        # Convert the dictionary to a numpy array\n        items = np.fromiter(items.values(), dtype=float)\n\n    # Convert the items to a numpy array\n    items = np.asarray(items)\n\n    # Check the number of dimensions of the array\n    if items.ndim != dim:\n        raise ValueError(\n            f\"The dimension of the array '{name}' must be {dim}, \"\n            f\"got {items.ndim}\"\n        )\n\n    # Check the shape of the array\n    if dim == 1 and items.shape[0] != n_assets:\n        raise ValueError(\n            f\"The shape of the array '{name}' must be ({n_assets},), \"\n            f\"got {items.shape}\"\n        )\n    elif dim == 2 and items.shape[1] != n_assets:\n        raise ValueError(\n            f\"The shape of the array '{name}' must be ({n_assets},), \"\n            f\"got {items.shape}\"\n        )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"The '{name}' must be a numpy array when assets_names is None\"\n            )\n        if dim == 1:\n            items = np.full(n_assets, fill_value, dtype=np.float64)\n            for asset, value in items.items():\n                if asset in assets_names:\n                    items[assets_names == asset] = value\n        elif dim == 2:\n            items = np.full((n_assets, n_assets), fill_value, dtype=np.float64)\n            for asset, value in items.items():\n                if asset in assets_names:\n                    items[assets_names == asset, :] = value\n        else:\n            raise ValueError(f\"Expected dim=1 or 2, got {dim}\")\n    else:\n        items = np.asarray(items)\n        if dim == 1:\n            if items.shape != (n_assets,):\n                raise ValueError(\n                    f\"The '{name}' must be a 1D array of shape ({n_assets},), got \"\n                    f\"{items.shape}\"\n                )\n        elif dim == 2:\n            if items.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"The '{name}' must be a 2D array of shape ({n_assets}, {n_assets}),\"\n                    f\" got {items.shape}\"\n                )\n        else:\n            raise ValueError(f\"Expected dim=1 or 2, got {dim}\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        # Convert dictionary to array\n        if assets_names is None:\n            raise ValueError(\n                f\"You must provide the 'assets_names' argument when 'items' is a \"\n                f\"dictionary.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value=fill_value, dtype=float)\n            for asset, value in items.items():\n                array[np.where(assets_names == asset)[0]] = value\n        elif dim == 2:\n            array = np.full((n_assets, n_assets), fill_value=fill_value, dtype=float)\n            for asset, value in items.items():\n                array[np.where(assets_names == asset)[0]] = value\n        else:\n            raise ValueError(\n                f\"The 'dim' argument must be 1 or 2, got {dim} instead.\"\n            )\n    else:\n        # Convert array-like to array\n        array = np.asarray(items)\n\n    # Verify array dimensions and shape\n    if dim == 1:\n        if array.ndim != 1 or array.shape[0] != n_assets:\n            raise ValueError(\n                f\"The '{name}' array must have shape (n_assets,) and dimension 1, got \"\n                f\"shape {array.shape} and dimension {array.ndim} instead.\"\n            )\n    elif dim == 2:\n        if array.ndim != 2 or array.shape[0] != n_assets or array.shape[1] != n_assets:\n            raise ValueError(\n                f\"The '{name}' array must have shape (n_assets, n_assets) and \"\n                f\"dimension 2, got shape {array.shape} and dimension {array.ndim} \"\n                f\"instead.\"\n            )\n    else:\n        raise ValueError(\n            f\"The 'dim' argument must be 1 or 2, got {dim} instead.\"\n        )\n\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        if dim == 1:\n            arr = np.full(n_assets, fill_value)\n            for asset, value in items.items():\n                if asset not in assets_names:\n                    raise ValueError(\n                        f\"'{name}' contains an asset '{asset}' not present in \"\n                        f\"'assets_names'.\"\n                    )\n                arr[np.where(assets_names == asset)] = value\n        else:\n            arr = np.full((n_assets, n_assets), fill_value)\n            for asset, value in items.items():\n                if asset not in assets_names:\n                    raise ValueError(\n                        f\"'{name}' contains an asset '{asset}' not present in \"\n                        f\"'assets_names'.\"\n                    )\n                arr[np.where(assets_names == asset)] = value\n    else:\n        arr = np.asarray(items)\n        if dim == 1 and arr.ndim != 1:\n            raise ValueError(\n                f\"'{name}' must be a 1D array-like, got {arr.ndim}D array-like.\"\n            )\n        elif dim == 2 and arr.ndim != 2:\n            raise ValueError(\n                f\"'{name}' must be a 2D array-like, got {arr.ndim}D array-like.\"\n            )\n        if arr.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} assets in '{name}', got {arr.shape[0]}.\"\n            )\n\n    return arr\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        items = pd.Series(items, name=name)\n        items = items.reindex(assets_names, fill_value=fill_value)\n        items = items.values\n\n    items = np.asarray(items)\n\n    if dim == 1:\n        if items.ndim != 1 or items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected a 1-dimensional array of shape ({n_assets},), got \"\n                f\"{items.shape}.\"\n            )\n    elif dim == 2:\n        if items.ndim != 2 or items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected a 2-dimensional array of shape ({n_assets},), got \"\n                f\"{items.shape}.\"\n            )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"The '{name}' must be a numpy array or a dictionary with asset names\"\n            )\n        if dim == 1:\n            items = np.full(n_assets, fill_value, dtype=np.float64)\n            for asset, value in items.items():\n                if asset in assets_names:\n                    items[asset] = value\n        else:\n            items = np.full((n_assets, n_assets), fill_value, dtype=np.float64)\n            for asset, value in items.items():\n                if asset in assets_names:\n                    items[asset] = value\n        items = np.array(items)\n    else:\n        items = np.array(items)\n\n    if dim == 1:\n        if items.shape != (n_assets,):\n            raise ValueError(\n                f\"The '{name}' must be a numpy array of shape (n_assets,) but got \"\n                f\"{items.shape} instead.\"\n            )\n    else:\n        if items.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"The '{name}' must be a numpy array of shape (n_groups, n_assets) \"\n                f\"but got {items.shape} instead.\"\n            )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        array = np.full(shape=(n_assets,), fill_value=fill_value)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n            else:\n                raise ValueError(\n                    f\"Missing '{asset}' in '{name}' for asset {asset}.\"\n                )\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(\n                f\"Expected shape ({n_assets},) for '{name}' but got {array.shape}.\"\n            )\n    elif dim == 2:\n        if array.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"Expected shape ({n_assets}, {n_assets}) for '{name}' but got {array.shape}.\"\n            )\n    else:\n        raise ValueError(f\"Expected dim 1 or 2 for '{name}' but got {dim}.\")\n\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    \"The assets_names must be provided when the items is a dictionary\"\n                )\n            items_array = np.full(n_assets, fill_value=fill_value, dtype=float)\n            for i, asset_name in enumerate(assets_names):\n                if asset_name in items:\n                    items_array[i] = items[asset_name]\n                else:\n                    raise ValueError(\n                        f\"The asset '{asset_name}' is not present in the '{name}' dictionary\"\n                    )\n        else:\n            items_array = np.asarray(items)\n        if items_array.shape != (n_assets,):\n            raise ValueError(\n                f\"The '{name}' must have shape (n_assets,), got {items_array.shape}\"\n            )\n        return items_array\n    elif dim == 2:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    \"The assets_names must be provided when the items is a dictionary\"\n                )\n            items_array = np.full(\n                (n_assets, n_assets), fill_value=fill_value, dtype=float\n            )\n            for i, asset_name in enumerate(assets_names):\n                if asset_name in items:\n                    items_array[i] = items[asset_name]\n                else:\n                    raise ValueError(\n                        f\"The asset '{asset_name}' is not present in the '{name}' dictionary\"\n                    )\n        else:\n            items_array = np.asarray(items)\n        if items_array.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"The '{name}' must have shape (n_assets, n_assets), got {items_array.shape}\"\n            )\n        return items_array\n    else:\n        raise ValueError(f\"The 'dim' must be 1 or 2, got {dim}\")\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"When 'items' is a dictionary, 'assets_names' must be provided.\"\n            )\n        # Fill missing values with 'fill_value'\n        items_array = np.full(n_assets, fill_value)\n        for asset, item in items.items():\n            asset_index = np.where(assets_names == asset)[0]\n            if len(asset_index) == 0:\n                raise ValueError(\n                    f\"Asset '{asset}' not found in 'assets_names'. \"\n                    f\"Available assets are: {assets_names}\"\n                )\n            if len(asset_index) > 1:\n                raise ValueError(\n                    f\"Asset '{asset}' appears multiple times in 'assets_names'. \"\n                    f\"Available assets are: {assets_names}\"\n                )\n            items_array[asset_index] = item\n        items = items_array\n\n    items = np.asarray(items)\n\n    if dim == 1:\n        if items.shape != (n_assets,):\n            raise ValueError(\n                f\"Expected array of shape ({n_assets},), got {items.shape} for \"\n                f\"'{name}'.\"\n            )\n    elif dim == 2:\n        if items.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"Expected array of shape ({n_assets}, {n_assets}), got {items.shape} \"\n                f\"for '{name}'.\"\n            )\n    else:\n        raise ValueError(f\"Invalid dimension {dim} for '{name}'.\")\n\n    return items\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if \"dynamic_prompt\" in data:\n            dynamic_prompt = data[\"dynamic_prompt\"]\n        else:\n            dynamic_prompt = None\n\n        if \"purpose\" in data:\n            purpose = data[\"purpose\"]\n        else:\n            purpose = None\n\n        if \"purpose_embedding\" in data:\n            purpose_embedding = data[\"purpose_embedding\"]\n        else:\n            purpose_embedding = None\n\n        if \"depth\" in data:\n            depth = data[\"depth\"]\n        else:\n            depth = None\n\n        if \"max_depth\" in data:\n            max_depth = data[\"max_depth\"]\n        else:\n            max_depth = None\n\n        if \"usage_count\" in data:\n            usage_count = data[\"usage_count\"]\n        else:\n            usage_count = None\n\n        if \"id\" in data:\n            id = data[\"id\"]\n        else:\n            id = None\n\n        if \"parent_id\" in data:\n            parent_id = data[\"parent_id\"]\n        else:\n            parent_id = None\n\n        if \"working_agent\" in data:\n            working_agent = data[\"working_agent\"]\n        else:\n            working_agent = None\n\n        if \"is_prime\" in data:\n            is_prime = data[\"is_prime\"]\n        else:\n            is_prime = None\n\n        if \"evolve_count\" in data:\n            evolve_count = data[\"evolve_count\"]\n        else:\n            evolve_count = None\n\n        if \"number_of_code_executions\" in data:\n            number_of_code_executions = data[\"number_of_code_executions\"]\n        else:\n            number_of_code_executions = None\n\n        if \"last_input\" in data:\n            last_input = data[\"last_input\"]\n        else:\n            last_input = None\n\n        return MicroAgent(\n            dynamic_prompt,\n            purpose,\n            purpose_embedding,\n            depth,\n            max_depth,\n            usage_count,\n            id,\n            parent_id,\n            working_agent,\n            is_prime,\n            evolve_count,\n            number_of_code_executions,\n            last_input,\n            agent_lifecycle,\n            openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\", \"\"),\n            purpose=data.get(\"purpose\", \"\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", None),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", None),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        agent = MicroAgent(\n            data[\"dynamic_prompt\"],\n            data[\"purpose\"],\n            purpose_embedding,\n            data[\"depth\"],\n            data[\"max_depth\"],\n            data[\"usage_count\"],\n            data[\"id\"],\n            data[\"parent_id\"],\n            data[\"working_agent\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n            agent_lifecycle,\n            openai_wrapper,\n        )\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            data[\"dynamic_prompt\"],\n            data[\"purpose\"],\n            purpose_embedding,\n            data[\"depth\"],\n            data[\"max_depth\"],\n            data[\"usage_count\"],\n            data[\"id\"],\n            data[\"parent_id\"],\n            data[\"working_agent\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n            agent_lifecycle,\n            openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\", None),\n            purpose=data.get(\"purpose\", None),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", None),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", None),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if isinstance(data[\"purpose_embedding\"], list):\n            data[\"purpose_embedding\"] = np.array(data[\"purpose_embedding\"])\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=data[\"purpose_embedding\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            data[\"dynamic_prompt\"],\n            data[\"purpose\"],\n            data[\"purpose_embedding\"],\n            data[\"depth\"],\n            data[\"max_depth\"],\n            data[\"usage_count\"],\n            data[\"id\"],\n            data[\"parent_id\"],\n            data[\"working_agent\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n        )\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Initialize the MicroAgent with the given parameters\n        agent = MicroAgent(\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=data[\"purpose_embedding\"],\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        agent = MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n        return agent\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** 12\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** 12\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** 12\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 25 / 323 * srgb\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323 * 25\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 25 / 323 * srgb\n  linear1 = (200 * srgb + 11) / 211\n  linear2 = (24 * srgb + 16) / 116\n  return xnp.where(srgb <= 0.04045, linear0, xnp.where(srgb <= 0.081, linear1, linear2))\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** 12\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 323\n  linear1 = ((srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  spline_degree = min(spline_degree, len(x) - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(\n      t_input, k=spline_degree, s=smoothness, per=False\n  )\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck, u_keyframes = scipy.interpolate.splprep(\n      t_input, k=spline_degree, s=smoothness, per=False\n  )\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  sh = x.shape\n  x = np.reshape(x, (sh[0], -1))\n  tck, u_keyframes = scipy.interpolate.splprep(\n      t_input, k=spline_degree, s=smoothness, per=True\n  )\n  new_x = np.array(scipy.interpolate.splev(t_output, tck))\n  new_x = np.reshape(new_x.T, (len(t_output), sh[1], sh[2]))\n  return new_x, u_keyframes\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  k = min(spline_degree, len(x) - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=k, s=smoothness)\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  spline_degree = min(spline_degree, len(x) - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness)\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x, u_keyframes\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness)\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  spline_degree = min(spline_degree, len(t_input) - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness)\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  sh = x.shape\n  x = np.reshape(x, (sh[0], -1))\n  k = min(spline_degree, sh[0] - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=k, s=smoothness)\n  new_x = np.array(scipy.interpolate.splev(t_output, tck))\n  new_x = np.reshape(new_x.T, (len(t_output), sh[1], sh[2]))\n  return new_x, u_keyframes\n\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  def interp_1d(x, t_input, t_output, k, s):\n    \"\"\"\n    Interpolates a 1-dimensional signal defined at certain input times and queries it at specified output times using spline interpolation of a given degree and smoothness.\n    Input-Output Arguments\n    :param x: Array-like. The 1-dimensional signal to be interpolated.\n    :param t_input: Array-like. The times at which the signal x is defined.\n    :param t_output: Array-like. The times at which the interpolated signal is queried.\n    :param k: Integer. The degree of the spline used for interpolation. It is adjusted to be at most one less than the number of points in x.\n    :param s: Float. A parameter controlling the smoothness of the spline fit. \n    :return: Array-like. The interpolated values of the signal at t_output times.\n    \"\"\"\n    tck, u_keyframes = scipy.interpolate.splprep(t_input, k=k, s=s)\n    new_x = scipy.interpolate.splev(t_output, tck)\n    return new_x\n\n  k = min(spline_degree, len(x) - 1)\n  new_x = interp_1d(x, t_input, t_output, k, smoothness)\n  return new_x\n\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  k = min(spline_degree, len(x) - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=k, s=smoothness)\n  x_new = scipy.interpolate.splev(t_output, tck)\n  return x_new\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck, t_keyframes = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness)\n  x_new = scipy.interpolate.splev(t_output, tck)\n\n  return x_new\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  def interp(x, t_input, t_output, k, s):\n    \"\"\"Runs 1-dimensional B-spline interpolation on the input signal.\"\"\"\n    tck, u_keyframes = scipy.interpolate.splprep(t_input, k=k, s=s)\n    new_x = scipy.interpolate.splev(t_output, tck)\n    return new_x, u_keyframes\n\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  k = min(spline_degree, len(x) - 1)\n  new_x, _ = interp(x, t_input, t_output, k=k, s=smoothness)\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  sh = x.shape\n  tck, t_keyframes = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness)\n  x_keyframes = scipy.interpolate.splev(t_keyframes, tck)\n  x_output = scipy.interpolate.splev(t_output, tck)\n  x_output = np.reshape(x_output, sh)\n  return x_output, t_keyframes, x_keyframes\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck, u_keyframes = scipy.interpolate.splrep(x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if spline_degree is None:\n    spline_degree = min(len(x) - 1, 3)\n  if smoothness is None:\n    smoothness = 0.03\n\n  tck, u_keyframes = scipy.interpolate.splprep(t_input, k=spline_degree, s=smoothness)\n  new_x = scipy.interpolate.splev(t_output, tck)\n\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if len(x) < 2:\n    raise ValueError(\"The number of points in x must be at least 2.\")\n\n  if len(t_input) != len(x):\n    raise ValueError(\"The number of points in t_input must be equal to the number of points in x.\")\n\n  if len(t_output) < 1:\n    raise ValueError(\"The number of points in t_output must be at least 1.\")\n\n  if len(t_input) < 2:\n    raise ValueError(\"The number of points in t_input must be at least 2.\")\n\n  if len(t_output) < 2:\n    raise ValueError(\"The number of points in t_output must be at least 2.\")\n\n  if len(t_input) != len(t_output):\n    raise ValueError(\"The number of points in t_input must be equal to the number of points in t_output.\")\n\n  if len(t_input) < spline_degree + 1:\n    raise ValueError(\"The number of points in t_input must be at least spline_degree + 1.\")\n\n  if len(t_output) < spline_degree + 1:\n    raise ValueError(\"The number of points in t_output must be at least spline_degree + 1.\")\n\n  if len(t_input) != len(t_output):\n    raise ValueError(\"The number of points in t_input must be equal to the number of points in t_output.\")\n\n  if len(t_input) < len(x):\n    raise ValueError(\"The number of points in t_input must be at least the number of points in x.\")\n\n  if len(t_output) < len(x):\n    raise ValueError(\"The number of points in t_output must be at least the number of points in x.\")\n\n  if len(t_input) != len(t_output):\n    raise ValueError(\"The number of points in t_input must be equal to the number of points in t_output.\")\n\n  if len(t_input) < len(x):\n    raise ValueError(\"The number of points in t_input must be at least the number of points in x.\")\n\n  if len(t_output) < len(x):\n    raise ValueError(\"The number of points in t_output must be at least the number of points in x.\")\n\n  if"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Make sure the spline degree is at most one less than the number of points.\n  spline_degree = min(spline_degree, len(x) - 1)\n  # Run the spline interpolation.\n  tck, u_keyframes = scipy.interpolate.splprep(\n      t_input, k=spline_degree, s=smoothness, per=True\n  )\n  new_x = scipy.interpolate.splev(t_output, tck)\n  return new_x\n\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n  # Calculate the spline coefficients of the signal x.\n  tck, _ = scipy.interpolate.splprep(x, k=spline_degree, s=smoothness)\n  # Interpolate the signal x at specified output times.\n  y = scipy.interpolate.splev(t_output, tck)\n  return y\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Adjust spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit a spline to the input signal.\n  tck, u_keyframes = scipy.interpolate.splprep(\n      t_input, k=spline_degree, s=smoothness, per=False\n  )\n\n  # Interpolate the spline at the output times.\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output, u_keyframes\n\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  def get_spline(x, t, k, s):\n    \"\"\"\n    Runs spline interpolation on the input signal x at the input times t using spline of degree k and smoothness s.\n    Input-Output Arguments\n    :param x: Array-like. The input signal to be interpolated.\n    :param t: Array-like. The input times at which the signal x is defined.\n    :param k: Integer. The degree of the spline used for interpolation. It is adjusted to be at most one less than the number of points in x.\n    :param s: Float. A parameter controlling the smoothness of the spline fit. \n    :return: Tuple (tck, u_keyframes). tck is the spline interpolation of the input signal x at the input times t. u_keyframes is the array of the times at which the spline is defined.\n    \"\"\"\n    k = min(k, len(x) - 1)\n    tck, u_keyframes = scipy.interpolate.splprep(t, k=k, s=s, per=True)\n    return tck, u_keyframes\n\n  def get_points(tck, u):\n    \"\"\"\n    Evaluates the spline interpolation tck at the times u.\n    Input-Output Arguments\n    :param tck: Tuple (tck, u_keyframes). tck is the spline interpolation of the input signal x at the input times t. u_keyframes is the array of the times at which the spline is defined.\n    :param u: Array-like. The times at which the interpolated signal is queried.\n    :return: Array-like. The interpolated values of the signal at u times.\n    \"\"\"\n    return np.array(scipy.interpolate.splev(u, tck))\n\n  tck, u_keyframes = get_spline(x, t_input, k=spline_degree, s=smoothness)\n  new_x = get_points(tck, t_output)\n  return new_x, u_keyframes\n\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    # if lower no"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper():\n        if word[1:].islower():\n            return word\n    if word[0].isupper():\n        if word[1:].isupper():\n            return word\n    if word[0].islower():\n        if word[1:].isupper():\n            return word\n    if word[0].islower():\n        if word[1:].islower():\n            return word\n    return word.capitalize()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word.title()\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1:].islower():\n        return word\n    if word[0].isupper() and word[1:].isupper():\n        return word\n    if word[0].islower() and word[1:].islower():\n        return word\n    if word[0].islower() and word[1:].isupper():\n        return word\n    if word[0].isupper() and word[1:].islower():\n        return word.capitalize()\n    if word[0].isupper() and word[1:].isupper():\n        return word.lower()\n    if word[0].islower() and word[1:].islower():\n        return word.upper()\n    if word[0].islower() and word[1:].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower() or word.isupper():\n        return word\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    return word\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper():\n        return word.capitalize()\n    return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0:2].isupper():\n        return word\n    if word[0:2].islower():\n        return word.lower()\n    return word.capitalize()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower() or word.isupper():\n        return word\n    if word.isupper():\n        return word.lower()\n    if word.islower():\n        return word.upper()\n    if word[0].isupper() and word[1].isupper():\n        return word.lower()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    if word[0].islower() and word[1].islower():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower() or word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.capitalize()\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    return word.capitalize()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if word is entirely lowercase or uppercase, return word as is\n    if word.islower() or word.isupper():\n        return word\n\n    # if word is mixed case, apply different rules to correct its casing\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.capitalize()\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].isupper():\n        return word.upper()\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower() or word.isupper():\n        return word\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower() or word.isupper():\n        return word\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    if word[0].isupper() and word[1].isupper():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0:2].islower():\n        return word.lower()\n    if word[0:2].isupper():\n        return word.upper()\n    if word[0:2].istitle():\n        return word.title()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1:].islower():\n        return word\n    if word[0].isupper() and word[1:].isupper():\n        return word\n    if word[0].islower() and word[1:].islower():\n        return word\n    if word[0].islower() and word[1:].isupper():\n        return word\n    if word[0].isupper() and word[1:].islower():\n        return word\n    if word[0].isupper() and word[1:].isupper():\n        return word\n    if word[0].islower() and word[1:].islower():\n        return word\n    return word\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array, found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a boolean array. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array of boolean data type.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary. Found {v.dtype} instead.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary. Found {v.dtype}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be of type np.bool_, but got {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array (i.e., containing only True or False values).\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array (i.e., containing only True or False values). Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary, but contains {v.dtype}.\"\n        )\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary. Found {v.dtype}.\"\n        )\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array (i.e., containing only True or False values).\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array (i.e., containing only True or False values).\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array, got {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * x_mag - 1) / x_mag\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.maximum(1, jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)))\n  scale = (2 * x_mag - 1) / x_mag\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  scale = (2 * jnp.sqrt(x_mag) - 1) / x_mag\n  return scale * x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.maximum(1, jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)))\n  scale = (2 * x_mag - 1) / x_mag**2\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  # Apply the isotropic scaling operation\n  scale = (2 * jnp.sqrt(norm) - norm) / norm\n  z = x * scale\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input along the last axis\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n\n  # Calculate the scale factor based on the norm\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n\n  # Apply the scale factor to the input\n  z = scale * x\n\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = jnp.sqrt(2 * x_mag - 1) / x_mag\n  return scale * x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  scale = 2 * jnp.sqrt(x_mag) - x_mag\n  return x / scale\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Calculate the scale factor based on the norm\n  scale = (2 * jnp.sqrt(norm) - norm) / norm\n\n  # Apply the scale factor to the input array\n  z = scale * x\n\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array along the last axis\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled version of the input array\n  x_scaled = x / (1 + x_norm)\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  scale = 1 / jnp.maximum(1, x_norm)\n  x_scaled = scale * x\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.maximum(1, jnp.linalg.norm(x, axis=-1, keepdims=True))\n  scale = (2 * x_mag - 1) / x_mag**2\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x * jnp.sqrt(2 - x_norm)\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, keep_default_na=False)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        if col in summary_df.columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        if col in df.columns:\n            df[col] = df[col].apply(lambda x: ast.literal_eval(x))\n\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, index_col=0)\n    for col in dict_columns:\n        if col in summary_df.columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column_name in dict_columns:\n        if column_name not in summary_df.columns:\n            raise ValueError(f\"Column {column_name} not found in summary file.\")\n        summary_df[column_name] = summary_df[column_name].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, index_col=0)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    dict_columns = dict_columns or ['module_params']\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    def convert_dict_string(x: str) -> Dict:\n        \"\"\"\n        Converts a dictionary-like string into a dictionary object.\n        \"\"\"\n        if x.startswith('{') and x.endswith('}'):\n            return ast.literal_eval(x)\n        else:\n            return {}\n\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(convert_dict_string)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        if column in df.columns:\n            df[column] = df[column].apply(ast.literal_eval)\n    return df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, index_col=0)\n\n    for col in dict_columns:\n        if col in summary_df.columns:\n            summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        if column in summary_df.columns:\n            summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n    return summary_df\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    return cov / det\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    return cov / jnp.exp(log_det)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'accurate':\n    # Compute the log determinant of the covariance matrix\n    log_det = jnp.linalg.slogdet(cov)[1]\n    # Compute the isotropic covariance matrix\n    isotropic_cov = jnp.exp(log_det / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  elif mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic covariance matrix\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  else:\n    raise ValueError(f\"Invalid mode: {mode}.\")\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det_cov = jnp.linalg.det(cov)\n    isotropic_cov = cov / jnp.sqrt(det_cov)\n  elif mode == 'accurate':\n    log_det_cov = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = cov / jnp.exp(log_det_cov / 2)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    if jnp.any(det <= 0):\n      raise ValueError(f'Invalid determinant: {det}')\n    sqrt_det = jnp.sqrt(det)\n    return cov / sqrt_det\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if jnp.any(log_det <= 0):\n      raise ValueError(f'Invalid log determinant: {log_det}')\n    sqrt_log_det = jnp.sqrt(log_det)\n    return cov / sqrt_log_det\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    return cov / det\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if not jnp.isfinite(log_det):\n      return cov\n    return cov * jnp.exp(-log_det)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Check if the determinant is valid\n    if jnp.isfinite(det) and det > 0:\n      # Compute the isotropic covariance matrix\n      isotropic_cov = cov * (det ** (1 / cov.shape[-1]))\n      return isotropic_cov\n    else:\n      # Handle invalid determinants\n      return cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix\n    log_det = jnp.linalg.slogdet(cov)[1]\n    # Check if the logarithm of the determinant is valid\n    if jnp.isfinite(log_det) and log_det > 0:\n      # Compute the isotropic covariance matrix\n      isotropic_cov = cov * jnp.exp(log_det / cov.shape[-1])\n      return isotropic_cov\n    else:\n      # Handle invalid logarithms of determinants\n      return cov\n  else:\n    raise ValueError(f\"Invalid mode: {mode}. Please choose either 'fast' or 'accurate'.\")\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    det_sqrt = jnp.sqrt(det)\n    return cov / det_sqrt\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    log_det_sqrt = log_det / 2\n    return cov * jnp.exp(-log_det_sqrt)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Handle invalid determinants\n    det = jnp.where(det < 0, 0, det)\n    # Compute the isotropic covariance matrix\n    iso_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix\n    logdet = jnp.linalg.slogdet(cov)[1]\n    # Handle invalid logarithms of determinants\n    logdet = jnp.where(logdet < 0, 0, logdet)\n    # Compute the isotropic covariance matrix\n    iso_cov = cov / jnp.exp(logdet / 2)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix.\n    det = jnp.linalg.det(cov)\n    # Compute the square root of the determinant.\n    sqrt_det = jnp.sqrt(det)\n    # Check if the determinant is valid.\n    if jnp.isfinite(sqrt_det):\n      # Compute the isotropic covariance matrix.\n      iso_cov = cov / sqrt_det\n    else:\n      # If the determinant is invalid, set the isotropic covariance matrix to the identity.\n      iso_cov = jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix.\n    log_det = jnp.linalg.slogdet(cov)[1]\n    # Compute the square root of the logarithm of the determinant.\n    sqrt_log_det = jnp.sqrt(log_det)\n    # Check if the logarithm of the determinant is valid.\n    if jnp.isfinite(sqrt_log_det):\n      # Compute the isotropic covariance matrix.\n      iso_cov = cov / jnp.exp(sqrt_log_det)\n    else:\n      # If the logarithm of the determinant is invalid, set the isotropic covariance matrix to the identity.\n      iso_cov = jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.eye(cov.shape[-1]) * det ** (1 / cov.shape[-1])\n  elif mode == 'accurate':\n    logdet = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = jnp.eye(cov.shape[-1]) * jnp.exp(logdet / cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode {mode}')\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check if the covariance matrix is valid\n  if not (cov.shape[-1] == cov.shape[-2]):\n    raise ValueError(\n        f'The covariance matrix must be square, but has shape {cov.shape}.'\n    )\n\n  # Compute the isotropic covariance matrix\n  if mode == 'fast':\n    # Compute the isotropic covariance matrix using the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.eye(cov.shape[-1]) * det\n  elif mode == 'accurate':\n    # Compute the isotropic covariance matrix using the logarithm of the determinant for stability\n    log_det = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = jnp.eye(cov.shape[-1]) * jnp.exp(log_det)\n  else:\n    raise ValueError(f'Invalid mode: {mode}.')\n\n  # Handle invalid determinants or logarithms of determinants\n  if jnp.isnan(isotropic_cov).any():\n    isotropic_cov = jnp.eye(cov.shape[-1])\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    sqrt_det = jnp.sqrt(det)\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    sqrt_det = jnp.exp(log_det / 2)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n  if jnp.any(jnp.isnan(sqrt_det)) or jnp.any(jnp.isinf(sqrt_det)):\n    # If the determinant is invalid, return the identity matrix.\n    return jnp.eye(cov.shape[-1])\n  else:\n    return cov / sqrt_det\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Fast mode uses the determinant directly.\n    isotropic_cov = cov / jnp.linalg.det(cov) ** (1 / cov.shape[-1])\n  elif mode == 'accurate':\n    # Accurate mode uses the logarithm of the determinant for stability.\n    log_det = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = cov / jnp.exp(log_det / cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n  # Check for invalid determinants or logarithms of determinants.\n  if jnp.isnan(isotropic_cov).any():\n    # Replace invalid determinants with identity matrices.\n    isotropic_cov = jnp.eye(cov.shape[-1])\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    if jnp.any(det <= 0):\n      raise ValueError(f'Invalid determinant: {det}')\n    scale = jnp.sqrt(det)\n    isotropic_cov = cov / scale\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if jnp.any(log_det <= 0):\n      raise ValueError(f'Invalid log determinant: {log_det}')\n    scale = jnp.exp(0.5 * log_det)\n    isotropic_cov = cov / scale\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    return cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if jnp.isnan(log_det):\n      return jnp.eye(cov.shape[-1])\n    return cov / jnp.exp(log_det / 2)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix.\n    det = jnp.linalg.det(cov)\n    # Compute the square root of the determinant.\n    det_sqrt = jnp.sqrt(det)\n    # Compute the isotropic covariance matrix.\n    isotropic_cov = cov / det_sqrt\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant.\n    log_det = jnp.linalg.slogdet(cov)[1]\n    # Compute the square root of the logarithm of the determinant.\n    log_det_sqrt = jnp.sqrt(log_det)\n    # Compute the isotropic covariance matrix.\n    isotropic_cov = cov / jnp.exp(log_det_sqrt)\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n  # Check for invalid determinants or logarithms of determinants.\n  if jnp.any(jnp.isnan(isotropic_cov)) or jnp.any(jnp.isinf(isotropic_cov)):\n    # If the determinant is invalid, use the identity matrix as the isotropic covariance.\n    isotropic_cov = jnp.eye(cov.shape[-1])\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check if the covariance matrix is a valid shape\n  if len(cov.shape) != 3:\n    raise ValueError(\n        f'Invalid shape for covariance matrix. Expected (..., d, d), got {cov.shape}.'\n    )\n\n  # Check if the covariance matrix is positive definite\n  if not jnp.all(jnp.linalg.eigvalsh(cov) > 0):\n    raise ValueError(\n        'Invalid covariance matrix. Expected positive definite, got non-positive definite.'\n    )\n\n  # Compute the determinant of the covariance matrix\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Invalid mode: {mode}. Expected \"fast\" or \"accurate\".')\n\n  # Check if the determinant is valid\n  if not jnp.all(det > 0):\n    raise ValueError(\n        'Invalid determinant. Expected positive, got non-positive.'\n    )\n\n  # Compute the square root of the determinant\n  sqrt_det = jnp.sqrt(det)\n\n  # Compute the isotropic covariance matrix\n  iso_cov = cov / sqrt_det\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'accurate':\n    cov_det = jnp.linalg.det(cov)\n    if cov_det < 0:\n      return jnp.eye(cov.shape[-1])\n    cov_det_log = jnp.log(cov_det)\n    if cov_det_log < 0:\n      return jnp.eye(cov.shape[-1])\n    cov_log_det = cov_det_log / cov.shape[-1]\n    cov_log_det_mat = jnp.eye(cov.shape[-1]) * cov_log_det\n    cov_iso = jnp.exp(cov_log_det_mat)\n  elif mode == 'fast':\n    cov_det = jnp.linalg.det(cov)\n    if cov_det < 0:\n      return jnp.eye(cov.shape[-1])\n    cov_det_sqrt = jnp.sqrt(cov_det)\n    cov_det_sqrt_mat = jnp.eye(cov.shape[-1]) * cov_det_sqrt\n    cov_iso = cov_det_sqrt_mat\n  else:\n    raise ValueError(f'Invalid mode: {mode}.')\n  return cov_iso\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the isotropic covariance matrix by taking the determinant of the input covariance matrix and dividing it by the number of dimensions.\n    isotropic_cov = cov / jnp.linalg.det(cov).shape[-1]\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the input covariance matrix and divide it by the number of dimensions.\n    log_det_cov = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = cov / jnp.exp(log_det_cov / cov.shape[-1])\n  else:\n    raise ValueError(f\"Invalid mode '{mode}'. Valid modes are 'fast' and 'accurate'.\")\n\n  # Check for invalid determinants or logarithms of determinants.\n  if jnp.isnan(isotropic_cov).any():\n    raise ValueError(\n        \"Invalid determinant or logarithm of determinant encountered. \"\n        \"Please ensure that the input covariance matrix is valid.\"\n    )\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix\n  det = jnp.linalg.det(cov)\n  # Check if the determinant is valid\n  if jnp.any(det <= 0):\n    # If the determinant is not valid, set it to a small value to avoid numerical issues\n    det = jnp.maximum(det, jnp.finfo(det.dtype).tiny)\n\n  # Compute the isotropic covariance matrix\n  if mode == 'fast':\n    # Fast mode: use the determinant directly\n    isotropic_cov = jnp.eye(cov.shape[-1]) * det\n  elif mode == 'accurate':\n    # Accurate mode: use the logarithm of the determinant for stability\n    isotropic_cov = jnp.eye(cov.shape[-1]) * jnp.exp(jnp.log(det).sum())\n  else:\n    raise ValueError(f\"Invalid mode '{mode}'.\")\n\n  return isotropic_cov\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', type=bool, default=False, help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', type=bool, help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True,\n                        help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str,\n                        help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str,\n                        help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str,\n                        help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto',\n                        help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true',\n                        help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int,\n                        help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true',\n                        help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int,\n                        help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int,\n                        help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int,\n                        help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int,\n                        help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'),\n                        help='Path to the configuration file, specifying where to find the configuration settings.')\n    return parser.parse"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True,\n                        help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+',\n                        help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str,\n                        help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str,\n                        help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto',\n                        help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', type=bool, default=False,\n                        help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int,\n                        help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', type=bool,\n                        help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int,\n                        help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int,\n                        help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int,\n                        help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int,\n                        help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'),\n                        help='Path to the configuration file, specifying where to find the configuration settings.')\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs=\"+\", type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv(\"CONFIG_FILE\", \"assets/config.yml\"), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='*', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", choices=[\"auto\", \"manual\"], help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.environ.get(\"CONFIG_FILE\", \"assets/config.yml\"), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    # Create the argument parser\n    parser = argparse.ArgumentParser(description=\"XAgent\")\n\n    # Add the arguments\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", choices=[\"auto\", \"manual\"], help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.environ.get(\"CONFIG_FILE\", \"assets/config.yml\"), help=\"Path to the configuration file, specifying where to find the configuration"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n    parser.add_argument('--print-config', action='store_true"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', default=[], help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, default='', help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, default='', help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', type=bool, default=False, help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, default=10, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', type=bool, default=False, help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, default=10, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, default=10, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, default=10, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, default=10, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', default=[], help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, default=None, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, default=None, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, default=None, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, default=None, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, default=None, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, default=None, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, default=None, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', type=bool, default=False, help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', type=bool, help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Run a task.')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"A command line interface for the XAgent system.\"\n    )\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"*\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        type=bool,\n        default=False,\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        type=bool,\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-tree-width\",\n        type=int,\n        help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\",\n    )\n\n    parser.add_argument(\n        \"--max-retry-times\",\n        type=int,\n        help=\""}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', required=True, type=str, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='*', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        '--task', type=str, required=True, help='The task description, specifying what task should be performed.'\n    )\n\n    parser.add_argument(\n        '--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.'\n    )\n\n    parser.add_argument(\n        '--model', type=str, help='Model identifier for the task, specifying which model to use.'\n    )\n\n    parser.add_argument(\n        '--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.'\n    )\n\n    parser.add_argument(\n        '--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \\'auto\\' or \\'manual\\', specifying how the task should be executed.'\n    )\n\n    parser.add_argument(\n        '--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.'\n    )\n\n    parser.add_argument(\n        '--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.'\n    )\n\n    parser.add_argument(\n        '--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.'\n    )\n\n    parser.add_argument(\n        '--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.'\n    )\n\n    parser.add_argument(\n        '--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.'\n    )\n\n    parser.add_argument(\n        '--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.'\n    )\n\n    parser.add_argument(\n        '--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.'\n    )\n\n    parser.add_argument(\n        '--config-file', type=str"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description='Run the agent in a given environment')\n\n    parser.add_argument('--task', type=str, required=True,\n                        help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str,\n                        help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str,\n                        help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str,\n                        help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto',\n                        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument('--quiet', action='store_true',\n                        help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int,\n                        help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true',\n                        help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int,\n                        help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int,\n                        help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int,\n                        help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int,\n                        help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'),\n                        help='Path to the configuration file, specifying where to find the"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='task description')\n    parser.add_argument('--upload-files', nargs='+', type=str, default=[], help='list of files to upload')\n    parser.add_argument('--model', type=str, default='', help='model identifier')\n    parser.add_argument('--record-dir', type=str, default='', help='directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='operational mode')\n    parser.add_argument('--quiet', action='store_true', help='run in quiet mode with minimal output')\n    parser.add_argument('--max-subtask-chain-length', type=int, default=10, help='maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, default=10, help='maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, default=10, help='maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, default=10, help='maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, default=10, help='maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='path to the configuration file')\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n\n    parser.add_argument('--task', type=str, required=True, help='task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='list of files to upload')\n    parser.add_argument('--model', type=str, help='model identifier for the task')\n    parser.add_argument('--record-dir', type=str, help='directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='operational mode')\n    parser.add_argument('--quiet', action='store_true', help='run in quiet mode with minimal output')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='path to the configuration file')\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='task description')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='list of files to upload')\n    parser.add_argument('--model', type=str, help='model identifier for the task')\n    parser.add_argument('--record-dir', type=str, help='directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='operational mode')\n    parser.add_argument('--quiet', type=bool, default=False, help='run in quiet mode with minimal output')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', type=bool, help='flag to enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='path to the configuration file')\n\n    return parser.parse_args()\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    return charset[n % len(charset)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    return charset[n % len(charset)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n % len(char_set)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    return charset[n % len(charset)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Check if the input is a non-negative integer\n    if not isinstance(n, int) or n < 0:\n        raise ValueError(\"The input must be a non-negative integer.\")\n\n    # Encode the integer into a single character\n    encoded_character = character_set[n % len(character_set)]\n\n    return encoded_character\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n\n    # Encode the integer into a character\n    char = char_set[n % len(char_set)]\n\n    return char\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    return charset[n % len(charset)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    return charset[n % len(charset)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + '_'\n    return charset[n % len(charset)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Check if the input integer is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"The input integer is out of range.\")\n\n    # Return the character from the character set based on the input integer\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    # Encode the integer into a single character\n    encoded_char = charset[n % len(charset)]\n\n    return encoded_char\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Encode the integer into a single character\n    encoded_char = character_set[n % len(character_set)]\n\n    return encoded_char\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n % len(char_set)]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n == 0:\n        return char_set[0]\n    result = \"\"\n    while n > 0:\n        n, r = divmod(n, len(char_set))\n        result = char_set[r] + result\n    return result\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    charset = string.ascii_lowercase + string.digits + '_'\n\n    # Check if the input is a valid integer\n    if not isinstance(n, int) or n < 0:\n        raise ValueError(\"Invalid input: n must be a non-negative integer\")\n\n    # Convert the integer to a string representation\n    s = str(n)\n\n    # Initialize the encoded string\n    encoded_str = ''\n\n    # Loop through each character in the string representation\n    for char in s:\n        # Convert the character to an integer\n        char_int = int(char)\n\n        # Check if the integer is within the range of the character set\n        if char_int < 0 or char_int >= len(charset):\n            raise ValueError(\"Invalid input: n must be within the range of the character set\")\n\n        # Append the corresponding character from the character set to the encoded string\n        encoded_str += charset[char_int]\n\n    # Return the encoded string\n    return encoded_str\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    charset = string.ascii_lowercase + string.digits + \"_\"\n    return charset[n % len(charset)]\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in workers_intervals:\n        interval = workers_intervals[worker_idx][indexes[worker_idx] // len(workers_intervals[worker_idx])]\n        chunks_index[worker_idx] = interval[0]\n        indexes[worker_idx] += 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in workers_intervals.items():\n        if indexes[worker_idx] >= len(interval):\n            chunks_index[worker_idx] = 0\n        else:\n            chunks_index[worker_idx] = indexes[worker_idx] // interval[1]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in workers_intervals.items():\n        if indexes[worker_idx] >= len(interval):\n            indexes[worker_idx] = 0\n            chunks_index[worker_idx] = 0\n        else:\n            chunks_index[worker_idx] = indexes[worker_idx] // interval[1]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in workers_intervals.items():\n        if indexes[worker_idx] >= len(interval):\n            chunks_index[worker_idx] = 0\n        else:\n            chunks_index[worker_idx] = indexes[worker_idx] // interval[1]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in workers_intervals:\n        if indexes[worker_idx] >= len(workers_intervals[worker_idx]):\n            indexes[worker_idx] = 0\n            chunks_index[worker_idx] = 0\n        else:\n            chunks_index[worker_idx] = indexes[worker_idx] // workers_intervals[worker_idx][0]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx in workers_intervals:\n        interval = workers_intervals[worker_idx][indexes[worker_idx]]\n        chunk_indexes[worker_idx] = interval[0]\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in workers_intervals.items():\n        chunks_index[worker_idx] = indexes[worker_idx] // interval[1]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks_index = {}\n    workers_indexes = {}\n\n    for worker_idx in range(len(workers_intervals)):\n        worker_chunks_index = []\n        worker_indexes = []\n        for i, (interval_start, interval_end) in enumerate(workers_intervals[worker_idx]):\n            if i % len(workers_intervals) != worker_idx:\n                continue\n            worker_chunks_index.append(interval_start)\n            worker_indexes.append(interval_end)\n\n        workers_chunks_index[worker_idx] = worker_chunks_index\n        workers_indexes[worker_idx] = worker_indexes\n\n    return workers_chunks_index, workers_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in enumerate(workers_intervals):\n        if worker_idx not in indexes:\n            indexes[worker_idx] = 0\n\n        if len(interval) == 0:\n            chunks_index[worker_idx] = 0\n            continue\n\n        interval_size = interval[1] - interval[0]\n        if interval_size == 0:\n            chunks_index[worker_idx] = 0\n            continue\n\n        chunk_index = indexes[worker_idx] // interval_size\n        chunks_index[worker_idx] = chunk_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks = {}\n    for worker_idx, interval in workers_intervals.items():\n        chunk_index = indexes[worker_idx]\n        workers_chunks[worker_idx] = chunk_index\n\n    return workers_chunks, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks_index = {}\n    workers_indexes = {}\n\n    for worker_idx in range(len(workers_intervals)):\n        worker_chunks_index = []\n        worker_indexes = []\n        for i, (interval_index, interval) in enumerate(zip(workers_intervals[worker_idx], workers_intervals)):\n            if i % len(workers_intervals) != worker_idx:\n                continue\n\n            worker_chunks_index.append(interval_index)\n            worker_indexes.append(interval[0] + indexes[worker_idx])\n\n        workers_chunks_index[worker_idx] = worker_chunks_index\n        workers_indexes[worker_idx] = worker_indexes\n\n    return workers_chunks_index, workers_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # Handle restart\n    chunk_index = {}\n    for worker_idx in workers_intervals.keys():\n        if indexes[worker_idx] == 0:\n            chunk_index[worker_idx] = 0\n        else:\n            chunk_index[worker_idx] = workers_intervals[worker_idx].index(indexes[worker_idx])\n\n    return chunk_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in workers_intervals:\n        chunks_index[worker_idx] = indexes[worker_idx] // workers_intervals[worker_idx][2]\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in workers_intervals.items():\n        if indexes[worker_idx] >= interval[1]:\n            chunks_index[worker_idx] = interval[0]\n        else:\n            chunks_index[worker_idx] = indexes[worker_idx]\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        interval = workers_intervals[worker_idx]\n        current_index = indexes[worker_idx]\n        chunk_index = current_index - interval[0]\n        chunks_index[worker_idx] = chunk_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunk_index = 0\n        interval = workers_intervals[worker_idx]\n        current_index = indexes[worker_idx]\n        for i, (first, last) in enumerate(interval):\n            if i >= current_index:\n                chunk_index = i\n                break\n        chunk_indexes[worker_idx] = chunk_index\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    workers_chunks = {}\n    for worker_idx in range(len(workers_intervals)):\n        workers_chunks[worker_idx] = indexes[worker_idx] // workers_intervals[worker_idx][1]\n\n    return workers_chunks, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunk_index = indexes[worker_idx]\n        interval = workers_intervals[worker_idx]\n        chunks_index[worker_idx] = chunk_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, interval in workers_intervals.items():\n        if len(interval) == 0:\n            chunks_index[worker_idx] = indexes[worker_idx]\n            continue\n\n        # The size of the interval\n        interval_size = interval[1] - interval[0]\n\n        # The number of chunks\n        num_chunks = interval_size // batch_size\n\n        # The number of batches\n        num_batches = indexes[worker_idx] // batch_size\n\n        # The number of chunks to skip\n        num_chunks_to_skip = num_batches % num_chunks\n\n        # The number of batches to skip\n        num_batches_to_skip = num_chunks_to_skip * batch_size\n\n        # The number of samples to skip\n        num_samples_to_skip = num_batches_to_skip * batch_size\n\n        # The number of samples to skip\n        indexes[worker_idx] -= num_samples_to_skip\n\n        # The number of chunks to skip\n        indexes[worker_idx] -= num_batches_to_skip * batch_size\n\n        chunks_index[worker_idx] = indexes[worker_idx] // batch_size\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        if indexes[worker_idx] >= len(workers_intervals[worker_idx]):\n            indexes[worker_idx] = 0\n            chunks_index[worker_idx] = 0\n        else:\n            chunks_index[worker_idx] = indexes[worker_idx] // workers_intervals[worker_idx][-1]\n\n    return chunks_index, indexes"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.astype(onp.int32)\n    coordinates = onp.clip(coordinates, 0, values.shape[:3] - 1)\n    return values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure: {datastructure}. Only \"grid\" and \"hash\" are supported.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.astype(jnp.int32)\n    coordinates = jnp.clip(coordinates, 0, values.shape[1:4] - 1)\n    return values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates * (values.shape[:3] - 1)\n    coordinates = jnp.clip(coordinates, 0, values.shape[:3] - 1)\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    coordinates = coordinates * (values.shape[0] - 1)\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.astype(int)\n    return values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilerp(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # Adjust coordinates to the range [-1, 1]\n  coordinates = coordinates / (datastructure.resolution - 1) * 2 - 1\n\n  # If the datastructure is a 3D voxel grid, perform trilinear interpolation\n  if datastructure == 'grid':\n    return resample.trilerp(values, coordinates)\n\n  # If the datastructure is a hash data structure, perform hash sampling\n  elif datastructure == 'hash':\n    return hash_resample.hash_sample(values, coordinates)\n\n  # Raise an error if an invalid datastructure is passed\n  else:\n    raise ValueError(\n        f'Invalid datastructure: {datastructure}. Supported datastructures are \"grid\" and \"hash\".'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to match the voxel grid's dimensions\n    coordinates = coordinates * jnp.array(values.shape[:3])\n    # Trilinear interpolation\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    # Adjust coordinates to match the hash's dimensions\n    coordinates = coordinates * jnp.array(values.shape[:2])\n    # Hash sampling\n    return hash_resample.hash_sample(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure: {datastructure}. Only \"grid\" and \"hash\" are supported.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  coordinates = jnp.array(coordinates)\n  if datastructure == 'grid':\n    # Adjust coordinates to match the voxel grid dimensions.\n    coordinates = coordinates * jnp.array(values.shape[:3])\n    # Trilinear interpolation.\n    return jax.vmap(\n        resample.trilerp, in_axes=(0, 0), out_axes=0)(values, coordinates)\n  elif datastructure == 'hash':\n    # Adjust coordinates to match the hash dimensions.\n    coordinates = coordinates * jnp.array(values.shape[:3])\n    # Hash sampling.\n    return jax.vmap(\n        hash_resample.hash_sample, in_axes=(0, 0), out_axes=0)(values,\n                                                                coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates * jnp.array(values.shape[:3])\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    coordinates = jnp.clip(coordinates, 0, values.shape[:3] - 1)\n    return jnp.take_along_axis(jnp.take_along_axis(jnp.take_along_axis(\n        values, coordinates[:, 0:1, 0:1, 0:1], axis=0), coordinates[:, 0:1, 0:1, 1:2], axis=1), coordinates[:, 0:1, 1:2, 1:2], axis=2)\n  elif datastructure == 'hash':\n    return hash_resample.hash_resample(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  coordinates = jnp.asarray(coordinates)\n  if datastructure == 'grid':\n    coordinates = coordinates.reshape((-1, 3))\n    coordinates = jnp.clip(coordinates, 0, values.shape[:3] - 1)\n    coordinates = coordinates.reshape((-1, 3))\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    values = values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    coordinates = coordinates.reshape((-1, 3))\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    coordinates = coordinates.reshape((-1, 3))\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    values = values[coordinates[:, 0] * values.shape[1] * values.shape[2] +\n                    coordinates[:, 1] * values.shape[2] + coordinates[:, 2]]\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n  return values\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  coordinates = jnp.asarray(coordinates)\n  if datastructure == 'grid':\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    coordinates = jnp.round(coordinates).astype(jnp.int32)\n    values = jnp.asarray(values)\n    return values[coordinates[..., 0], coordinates[..., 1], coordinates[..., 2]]\n  elif datastructure == 'hash':\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    coordinates = jnp.round(coordinates).astype(jnp.int32)\n    return values[coordinates]\n  else:\n    raise ValueError(\n        f'Invalid datastructure {datastructure}. Expected \"grid\" or \"hash\".'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to be within the bounds of the voxel grid\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    # Sample from the voxel grid using trilinear interpolation\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    # Adjust coordinates to be within the bounds of the hash data structure\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    # Sample from the hash data structure using trilinear interpolation\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(\n        f'Unsupported datastructure: {datastructure}. Supported datastructures are \"grid\" and \"hash\".'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to be within the bounds of the voxel grid\n    coordinates = coordinates.clip(0, values.shape[1] - 1)\n\n    # Perform trilinear interpolation on the voxel grid\n    return jax.vmap(\n        lambda x: jax.vmap(\n            lambda y: jax.vmap(\n                lambda z: jax.vmap(\n                    lambda v: jax.lax.convert_element_type(\n                        jax.lax.lerp(\n                            jax.lax.lerp(\n                                jax.lax.lerp(\n                                    v[0], v[1], z[0]),\n                                v[2], z[1]),\n                            jax.lax.lerp(\n                                v[3], v[4], z[0]),\n                            z[2]),\n                        jnp.float32),\n                    vmap_axes=(None, 0)),\n                vmap_axes=(None, 0)),\n            vmap_axes=(None, 0)),\n        vmap_axes=(None, 0))(coordinates)\n\n  elif datastructure == 'hash':\n    # Adjust coordinates to be within the bounds of the hash data structure\n    coordinates = coordinates.clip(0, values.shape[0] - 1)\n\n    # Perform trilinear interpolation on the hash data structure\n    return jax.vmap(\n        lambda x: jax.vmap(\n            lambda y: jax.vmap(\n                lambda z: jax.lax.convert_element_type(\n                    jax.lax.lerp(\n                        jax.lax.lerp(\n                            jax.lax.lerp(\n                                values[int(x[0]), int(y[0]), int(z[0]), :],\n                                values[int(x[0]), int(y[0]), int(z[1]), :],\n                                z[0]),\n                            values[int(x[0]), int(y[1]), int(z[0]), :],\n                            z[1]),\n                        jax.lax.lerp(\n                            values[int(x[1]), int(y[0]), int(z[0]), :],\n                            values[int(x[1]), int(y[0]), int(z[1]), :],\n                            z[0]),\n                        z[2]),\n                    jax.lax.lerp(\n                        jax.lax.lerp("}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.clip(0, values.shape[1] - 1)\n    return jax.vmap(jax.vmap(jax.vmap(jnp.take, (0,)), (0,)), (0, 0))(\n        values, coordinates)\n  elif datastructure == 'hash':\n    coordinates = coordinates.clip(0, values.shape[0] - 1)\n    return jax.vmap(jnp.take, (0, 0))(values, coordinates.astype(jnp.int32))\n  else:\n    raise ValueError(\n        'Unsupported datastructure: %s. Supported datastructures are \\'grid\\' and \\'hash\\'.'\n        % datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates * onp.array(values.shape[:3])\n    coordinates = coordinates.astype(onp.int32)\n    return values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    return hash_resample.hash_sample(\n        values,\n        coordinates,\n        values.shape[0],\n        values.shape[1],\n    )\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.astype(onp.int32)\n    return values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.astype(onp.int32)\n    coordinates = onp.clip(coordinates, 0, values.shape[:3] - 1)\n    return values[coordinates[:, 0], coordinates[:, 1], coordinates[:, 2]]\n  elif datastructure == 'hash':\n    return hash_resample.hash_sample(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure {datastructure}, expected \"grid\" or \"hash\".'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.reshape(-1, 3)\n    coordinates = coordinates * values.shape[:3] + 0.5\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    coordinates = coordinates.reshape(-1, 3)\n    coordinates = coordinates * values.shape[:3] + 0.5\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates.reshape(-1, 3)\n    coordinates = coordinates.transpose()\n    coordinates = coordinates.astype(onp.int32)\n    values = values.transpose((3, 0, 1, 2))\n    values = values.reshape(values.shape[0], -1)\n    values = values[:, coordinates[0] + coordinates[1] * values.shape[1] //\n                      coordinates[2] + coordinates[2] * values.shape[1]]\n    values = values.transpose()\n    return values\n  elif datastructure == 'hash':\n    coordinates = coordinates.reshape(-1, 3)\n    coordinates = coordinates.transpose()\n    coordinates = coordinates.astype(onp.int32)\n    values = values[coordinates[0] + coordinates[1] * values.shape[0] //\n                    coordinates[2] + coordinates[2] * values.shape[0]]\n    values = values.reshape(-1, values.shape[-1])\n    return values\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # check if coordinates are in bounds\n  if datastructure == 'grid':\n    if not (\n        (coordinates >= 0).all()\n        and (coordinates < values.shape[:3]).all()\n    ):\n      raise ValueError(\n          f'Coordinates must be within bounds of voxel grid dimensions: {values.shape[:3]}'\n      )\n  elif datastructure == 'hash':\n    if not (\n        (coordinates >= 0).all()\n        and (coordinates < values.shape[0]).all()\n    ):\n      raise ValueError(\n          f'Coordinates must be within bounds of hashed dimensions: {values.shape[0]}'\n      )\n  else:\n    raise ValueError(\n        f'Invalid datastructure: {datastructure}. Expected \"grid\" or \"hash\".'\n    )\n\n  # convert coordinates to integers\n  coordinates = coordinates.astype(int)\n\n  # get the indices of the coordinates\n  indices = coordinates.reshape(-1, 3)\n\n  # get the corresponding values from the voxel grid or hashed data structure\n  if datastructure == 'grid':\n    values = values[indices[:, 0], indices[:, 1], indices[:, 2]]\n  elif datastructure == 'hash':\n    values = values[indices[:, 0]]\n\n  # reshape the values to match the shape of the coordinates\n  values = values.reshape(coordinates.shape[:-1] + values.shape[-1:])\n\n  return values\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle\n  w = np.arange(v + 1)\n\n  # Normalize the weights to get the barycentric coordinates\n  w = w[:, None] * w[None, :] / (v + 1)**2\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out combinations that do not sum to the tessellation factor\n  weights = weights[np.sum(weights, axis=1) == v]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for the tessellated triangle.\n  # The barycentric weights are the coordinates of the point in the triangle.\n  # The weights are normalized to sum to 1.\n  # The weights are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number of points along the x-axis.\n  # The second factor is the number of points along the y-axis.\n  # The third factor is the number of points along the z-axis.\n  # The factors are computed as the product of the three factors.\n  # The first factor is the number"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for the tessellated triangle\n  w = np.array([\n      [0, 0, 1],\n      [0, 1, 0],\n      [1, 0, 0],\n      [1, 1, 0],\n      [1, 0, 1],\n      [0, 1, 1],\n      [1, 1, 1],\n      [1, 1, 2],\n      [1, 2, 1],\n      [2, 1, 1],\n      [1, 2, 2],\n      [2, 2, 1],\n      [2, 1, 2],\n      [2, 2, 2],\n      [2, 2, 3],\n      [2, 3, 2],\n      [3, 2, 2],\n      [2, 3, 3],\n      [3, 3, 2],\n      [3, 2, 3],\n      [3, 3, 3],\n      [3, 3, 4],\n      [3, 4, 3],\n      [4, 3, 3],\n      [3, 4, 4],\n      [4, 4, 3],\n      [4, 3, 4],\n      [4, 4, 4],\n  ])\n\n  # Normalize the weights to get the barycentric coordinates\n  w = w / v\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Initialize the barycentric weights array\n  barycentric_weights = np.zeros((v + 1, v + 1, v + 1))\n\n  # Iterate over all possible combinations of indices for the barycentric weights\n  for i, j, k in itertools.product(range(v + 1), range(v + 1), range(v + 1)):\n    # Check if the sum of the indices is less than or equal to v\n    if i + j + k <= v:\n      # Compute the barycentric weights for the current combination of indices\n      barycentric_weights[i, j, k] = np.math.factorial(v) / (\n          np.math.factorial(i) * np.math.factorial(j) * np.math.factorial(k))\n\n  # Normalize the barycentric weights to ensure they sum to 1\n  barycentric_weights /= np.sum(barycentric_weights)\n\n  return barycentric_weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Initialize the barycentric weights array\n  weights = np.zeros((v + 1, v + 1, v + 1))\n\n  # Iterate over all possible combinations of weights\n  for i, j, k in itertools.product(range(v + 1), repeat=3):\n    # Check if the sum of the weights is equal to the tessellation factor\n    if i + j + k == v:\n      # Normalize the weights to get the barycentric coordinates\n      weights[i, j, k] = 1 / (i + j + k)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Create a list of all possible combinations of integers from 0 to v-1\n  combinations = itertools.product(range(v), repeat=3)\n\n  # Create a list to store the barycentric weights for each combination\n  barycentric_weights = []\n\n  # Iterate over each combination of integers\n  for combination in combinations:\n\n    # Check if the sum of the integers is equal to v\n    if sum(combination) == v:\n\n      # Normalize the integers to get the barycentric weights\n      barycentric_weight = combination / v\n\n      # Add the barycentric weight to the list\n      barycentric_weights.append(barycentric_weight)\n\n  return np.array(barycentric_weights)\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that v is a positive integer\n  if v < 1:\n    raise ValueError(\"The tessellation factor must be greater than or equal to 1.\")\n\n  # Generate all possible combinations of integer weights for the vertices of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / np.sum(weights, axis=1, keepdims=True)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for each point in the tessellated triangle.\n  # The weights are computed using a combination of the tessellation factor (v)\n  # and the coordinates of the point within the triangle.\n  # The weights are normalized to sum to 1.\n  # The weights are used to interpolate values across the triangle.\n  weights = np.zeros((v + 1, v + 1, v + 1))\n  for i in range(v + 1):\n    for j in range(v + 1 - i):\n      k = v - i - j\n      weights[i, j, k] = 1.0 / (v + 1) * i * j * k\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  # Remove the weights that sum to more than 1\n  weights = weights[np.sum(weights, axis=1) <= 1]\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Initialize the barycentric weights for each vertex of the triangle.\n  barycentric_weights = np.zeros((3, 3))\n\n  # Compute the barycentric weights for each vertex of the triangle.\n  for i in range(3):\n    barycentric_weights[i, i] = v\n    barycentric_weights[i, (i + 1) % 3] = v - 1\n    barycentric_weights[i, (i + 2) % 3] = v - 1\n\n  # Normalize the barycentric weights to get the final weights.\n  barycentric_weights = barycentric_weights / (2 * v - 1)\n\n  return barycentric_weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that v is a positive integer\n  if not isinstance(v, int) or v < 1:\n    raise ValueError(f\"v must be a positive integer, but v = {v}.\")\n\n  # Generate the barycentric coordinates for the tessellated triangle\n  barycentric_coordinates = np.array(\n      list(itertools.product(range(v + 1), repeat=3)))\n  barycentric_coordinates = barycentric_coordinates[\n      np.sum(barycentric_coordinates, axis=1) == v]\n\n  # Normalize the barycentric coordinates to get the weights\n  weights = barycentric_coordinates / np.sum(barycentric_coordinates, axis=1)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that v is an integer greater than or equal to 1\n  if not isinstance(v, int) or v < 1:\n    raise ValueError(\"v must be an integer greater than or equal to 1\")\n\n  # Initialize the weights array\n  weights = np.zeros((v + 1, v + 1, v + 1))\n\n  # Iterate over all possible combinations of i, j, k\n  for i, j, k in itertools.product(range(v + 1), range(v + 1), range(v + 1)):\n    # Check if the sum of i, j, and k is equal to v\n    if i + j + k == v:\n      # Compute the barycentric weights for the current combination of i, j, and k\n      weights[i, j, k] = 1.0 / (v + 1)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that the tessellation factor is valid\n  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1.\")\n\n  # Generate integer weights for each vertex of the triangle\n  w0 = np.arange(v + 1)\n  w1 = np.arange(v + 1)\n  w2 = np.arange(v + 1)\n\n  # Compute the total number of points in the tessellated triangle\n  n = (v + 1) * (v + 2) // 2\n\n  # Initialize the barycentric weights array\n  w = np.zeros((n, 3))\n\n  # Iterate over the rows and columns of the tessellated triangle\n  for i in range(v + 1):\n    for j in range(v + 1 - i):\n      k = v - i - j\n      # Compute the index of the current point in the tessellated triangle\n      index = i * (v + 1) + j\n      # Assign the integer weights to the corresponding row in the barycentric weights array\n      w[index, 0] = w0[i]\n      w[index, 1] = w1[j]\n      w[index, 2] = w2[k]\n\n  # Normalize the barycentric weights to get the barycentric coordinates\n  w = w / (v + 1)\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('Tessellation factor must be greater than or equal to 1.')\n\n  # Generate integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / np.sum(weights, axis=1)[:, None]\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Define the vertices of the triangle\n  vertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3) / 2]])\n\n  # Initialize the array to store the barycentric weights\n  weights = np.zeros((3, 3 * v**2))\n\n  # Loop over the vertices of the triangle\n  for i in range(3):\n    # Define the starting and ending indices for the current vertex\n    start_idx = i * v**2\n    end_idx = (i + 1) * v**2\n\n    # Compute the barycentric weights for the current vertex\n    weights[i, start_idx:end_idx] = np.arange(v**2)\n\n  # Normalize the weights to get the barycentric coordinates\n  weights /= v**2\n\n  # Return the barycentric weights\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric coordinates for the tessellated triangle\n  # by generating integer weights for each vertex of the triangle and\n  # then normalizing these weights to get the barycentric coordinates.\n  #\n  # The weights are generated by iterating over all possible combinations\n  # of three integers that sum to v, and then normalizing each combination\n  # to get the corresponding barycentric coordinates.\n  #\n  # The resulting array has shape (v + 1, v + 1, v + 1, 3), where the first\n  # three dimensions represent the barycentric coordinates for each point\n  # in the tessellated triangle, and the last dimension represents the\n  # three coordinates of the barycentric coordinates.\n\n  # Generate all possible combinations of three integers that sum to v\n  combinations = itertools.product(range(v + 1), repeat=3)\n\n  # Filter out combinations that do not sum to v\n  combinations = [c for c in combinations if sum(c) == v]\n\n  # Convert the combinations to numpy arrays\n  combinations = np.array(combinations)\n\n  # Normalize the combinations to get the barycentric coordinates\n  barycentric_coords = combinations / v\n\n  # Reshape the barycentric coordinates to match the desired shape\n  barycentric_coords = barycentric_coords.reshape(v + 1, v + 1, v + 1, 3)\n\n  return barycentric_coords\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the tessellation weights for the triangle\n  v_weights = np.array([\n      np.arange(v + 1),\n      np.arange(v + 1),\n      np.arange(v + 1),\n  ])\n  v_weights = np.array([\n      v_weights[0, :],\n      v_weights[1, :],\n      v_weights[2, :],\n  ])\n  v_weights = v_weights.T\n  v_weights = v_weights[np.sum(v_weights, 1) <= v, :]\n  v_weights = v_weights[np.sum(v_weights, 1) > 0, :]\n  v_weights = v_weights / np.sum(v_weights, 1)[:, None]\n  return v_weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the weights for the tessellation of the triangle\n  w = np.array(list(itertools.product(range(v + 1), range(v + 1))))\n  w = w[w[:, 0] + w[:, 1] <= v, :]\n\n  # Normalize the weights to get the barycentric coordinates\n  w = w / v\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Define the number of points to generate for each axis\n  n_points = v + 1\n\n  # Create a meshgrid of points on the unit square\n  x, y = np.meshgrid(np.linspace(0, 1, n_points), np.linspace(0, 1, n_points))\n\n  # Flatten the meshgrid into a list of points\n  points = np.stack([x.flatten(), y.flatten()])\n\n  # Compute the barycentric weights for each point\n  weights = np.stack([1 - points[0] - points[1], points[0], points[1]])\n\n  return weights\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Check that the query points are within the original range.\n  checkify.check(jnp.all(tq >= t[0]), 'Query points must be within the original range.')\n  checkify.check(jnp.all(tq <= t[-1]), 'Query points must be within the original range.')\n\n  # Interpolate the values at the query points.\n  def interpolate(tq, t, v):\n    tq = jnp.expand_dims(tq, axis=1)\n    t = jnp.expand_dims(t, axis=0)\n    v = jnp.expand_dims(v, axis=0)\n    return jnp.where(tq < t[0], 0, jnp.where(tq > t[-1], 0, jnp.interp(tq, t, v)))\n  return interpolate(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the time points are monotonically increasing and the values are all non-negative.\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Time points must be monotonically increasing.')\n  checkify.check(jnp.all(v >= 0), 'Values must be non-negative.')\n\n  # Find the indices of the time points that are just before the query points.\n  indices = jnp.searchsorted(t, tq) - 1\n\n  # Clip the indices to be within the valid range.\n  indices = jnp.clip(indices, 0, t.shape[0] - 2)\n\n  # Find the values at the query points using linear interpolation.\n  values = v[indices] + (v[indices + 1] - v[indices]) * (tq - t[indices]) / (t[indices + 1] - t[indices])\n\n  # Set the values outside the original range to 0.\n  values = jnp.where(tq < t[0], 0, values)\n  values = jnp.where(tq > t[-1], 0, values)\n\n  return values\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Ensure the query points are sorted.\n  tq = jnp.sort(tq)\n\n  # Calculate the slopes of the linear segments between knots.\n  slopes = jnp.diff(v, axis=-1) / jnp.diff(t, axis=-1)\n\n  # Calculate the intercepts of the linear segments.\n  intercepts = v[..., :-1] - slopes * t[..., :-1]\n\n  # Find the indices of the knots that are closest to the query points.\n  knot_indices = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Calculate the values at the query points using linear interpolation.\n  values = slopes[..., knot_indices] * tq + intercepts[..., knot_indices]\n\n  # Set the values outside the range of the spline to 0.\n  values = jnp.where(\n      (tq >= t[..., 0]) & (tq <= t[..., -1]), values, jnp.zeros_like(values))\n\n  return values\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n\n  # Find the indices of the knots that are less than or equal to the query points.\n  indices = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Find the slopes of the linear segments.\n  slopes = (v[..., 1:] - v[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n  # Interpolate the values at the query points.\n  interpolated_values = v[..., indices] + slopes[..., indices] * (tq - t[..., indices])\n\n  # Set the extrapolated values to 0.\n  extrapolated_mask = (tq < t[..., 0]) | (tq > t[..., -1])\n  interpolated_values = jnp.where(extrapolated_mask, 0, interpolated_values)\n\n  return interpolated_values\n\n"}
{"namespace": "linspline.query", "completion": "  # Check the endpoints of the spline are 0\n  check_zero_endpoints(v)\n\n  # Ensure the spline is valid\n  v = utils.make_valid_spline(t, v)\n\n  # Check the query points are within the range of the spline\n  checkify.check(jnp.all(tq >= t[0]), 'Query points must be greater than or equal to the first time point.')\n  checkify.check(jnp.all(tq <= t[-1]), 'Query points must be less than or equal to the last time point.')\n\n  # Interpolate the spline at the query points\n  return math.interpolate_linear(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  assert tq.ndim == 1\n  assert t.ndim == 1\n  assert v.ndim == 2\n  assert t.shape[0] == v.shape[1]\n  assert jnp.all(jnp.diff(t) > 0)\n  assert jnp.all(v[Ellipsis, 0] == 0)\n  assert jnp.all(v[Ellipsis, -1] == 0)\n  tq = tq.reshape(-1, 1)\n  t = t.reshape(1, -1)\n  v = v.reshape(tq.shape[0], -1)\n  # Linear interpolation\n  tq_interp = jnp.clip(tq, t[Ellipsis, 0], t[Ellipsis, -1])\n  v_interp = jnp.interp(tq_interp, t, v)\n  # Extrapolation\n  v_extrap = jnp.zeros_like(v_interp)\n  # Combine\n  v_combined = jnp.where(tq_interp == tq, v_interp, v_extrap)\n  return v_combined\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that tq is a 1D array\n  tq = jnp.asarray(tq)\n  assert len(tq.shape) == 1, 'tq must be a 1D array'\n\n  # Check that t and v have the same length\n  assert len(t) == len(v), 't and v must have the same length'\n\n  # Check that t and v are 1D arrays\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  assert len(t.shape) == 1, 't must be a 1D array'\n  assert len(v.shape) == 1, 'v must be a 1D array'\n\n  # Check that t is sorted in ascending order\n  assert jnp.all(jnp.diff(t) >= 0), 't must be sorted in ascending order'\n\n  # Check that tq is within the range of t\n  assert jnp.all(tq >= t[0]) and jnp.all(tq <= t[-1]), 'tq must be within the range of t'\n\n  # Check that v is a valid linear spline\n  assert jnp.all(jnp.diff(v) >= 0), 'v must be a valid linear spline'\n\n  # Compute the differences between consecutive time points in t\n  dt = jnp.diff(t)\n\n  # Compute the differences between consecutive values in v\n  dv = jnp.diff(v)\n\n  # Compute the slopes of the linear spline segments\n  m = dv / dt\n\n  # Compute the intercepts of the linear spline segments\n  b = v[:-1]\n\n  # Compute the interpolated values at each query point in tq\n  y = b + m * (tq - t[:-1])\n\n  # Set the extrapolated values to 0 outside the original range\n  y = jnp.where(tq < t[0], 0, y)\n  y = jnp.where(tq > t[-1], 0, y)\n\n  return y\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure that the spline is valid.\n  assert t.ndim == 1\n  assert v.ndim == 1\n  assert t.shape == v.shape\n  assert t.dtype == v.dtype\n  assert tq.dtype == v.dtype\n\n  # Check that the spline starts and ends with 0.\n  check_zero_endpoints(v)\n\n  # Find the indices of the knots that are just less than the query points.\n  idx = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Clip the indices to ensure they are within the valid range.\n  idx = jnp.clip(idx, 0, t.shape[0] - 2)\n\n  # Calculate the slopes of the linear segments between the knots.\n  slopes = (v[1:] - v[:-1]) / (t[1:] - t[:-1])\n\n  # Calculate the interpolated values at the query points.\n  interpolated = v[idx] + slopes[idx] * (tq - t[idx])\n\n  # Set the extrapolated values to 0.\n  extrapolated = jnp.where(tq < t[0], 0, tq > t[-1], 0, interpolated)\n\n  return extrapolated\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  tq = jnp.asarray(tq)\n\n  # Ensure that the query points are within the range of the time points.\n  tq = jnp.clip(tq, jnp.min(t), jnp.max(t))\n\n  # Find the indices of the time points that are closest to the query points.\n  idx = jnp.searchsorted(t, tq) - 1\n\n  # Calculate the slopes of the linear spline at each knot.\n  slopes = (v[:, 1:] - v[:, :-1]) / (t[1:] - t[:-1])\n\n  # Calculate the interpolated values at the query points using linear interpolation.\n  interpolated_values = v[jnp.arange(v.shape[0]), idx] + slopes[jnp.arange(\n      slopes.shape[0]), idx] * (tq - t[idx])\n\n  return interpolated_values\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Define the time points and values for the spline\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  # Define the query points\n  tq = jnp.asarray(tq)\n\n  # Ensure the query points are within the spline's range\n  tq = jnp.clip(tq, t[0], t[-1])\n\n  # Define the indices of the knots that are less than or equal to the query points\n  idx = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Define the slopes of the linear segments\n  slopes = (v[..., 1:] - v[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n  # Define the intercepts of the linear segments\n  intercepts = v[..., :-1] - slopes * t[..., :-1]\n\n  # Calculate the interpolated values at the query points\n  y = slopes[..., idx] * tq + intercepts[..., idx]\n\n  return y\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  t_min = jnp.min(t, axis=-1)\n  t_max = jnp.max(t, axis=-1)\n\n  # Find the indices of the knots between which each query point falls\n  idx = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Set extrapolated values to 0\n  idx = jnp.clip(idx, 0, t.shape[-1] - 2)\n\n  # Calculate the fraction of the distance between the knots that each query point falls\n  frac = (tq - t[Ellipsis, idx]) / (t[Ellipsis, idx + 1] - t[Ellipsis, idx])\n\n  # Interpolate the values at each query point using the fraction and the values at the knots\n  return (1 - frac) * v[Ellipsis, idx] + frac * v[Ellipsis, idx + 1]\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that tq is a 1D array\n  tq = jnp.asarray(tq)\n  if tq.ndim != 1:\n    raise ValueError(\n        'The query points must be a 1D array, but got an array with shape {}.'.\n        format(tq.shape))\n\n  # Check that t and v are 2D arrays with the same number of rows\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  if t.ndim != 2 or v.ndim != 2 or t.shape[0] != v.shape[0]:\n    raise ValueError(\n        'The time points and values must be 2D arrays with the same number of rows, but got arrays with shapes {} and {}.'.\n        format(t.shape, v.shape))\n\n  # Check that t is a monotonically increasing array\n  if not jnp.all(jnp.diff(t) > 0):\n    raise ValueError(\n        'The time points must be monotonically increasing, but got an array with values {}.'.\n        format(t))\n\n  # Check that tq is within the range of t\n  if not (jnp.min(tq) >= jnp.min(t) and jnp.max(tq) <= jnp.max(t)):\n    raise ValueError(\n        'The query points must be within the range of the time points, but got query points {} and time points {}.'.\n        format(tq, t))\n\n  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Interpolate the values at the query points\n  tq = jnp.expand_dims(tq, axis=1)\n  t = jnp.expand_dims(t, axis=0)\n  v = jnp.expand_dims(v, axis=0)\n  idx = jnp.searchsorted(t, tq, side='right') - 1\n  t_left = t[Ellipsis, idx]\n  t_right = t[Ellipsis, idx + 1]\n  v_left = v[Ellipsis, idx]\n  v_right = v[Ellipsis, idx + 1]\n  tq_interp = (tq - t_left) / (t_right - t_left)\n  v_interp = (1"}
{"namespace": "linspline.query", "completion": "  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  check_zero_endpoints(v)\n\n  # Ensure tq is a 1D array\n  tq = jnp.asarray(tq).reshape(-1)\n\n  # Find the indices of the knots that are closest to the query points\n  idx = jnp.searchsorted(t, tq)\n\n  # Set extrapolated values to 0\n  idx = jnp.clip(idx, 0, t.shape[0] - 1)\n\n  # Calculate the slopes between each pair of knots\n  slopes = (v[Ellipsis, 1:] - v[Ellipsis, :-1]) / (t[1:] - t[:-1])\n\n  # Find the values at the query points by linear interpolation\n  return v[jnp.arange(v.shape[0]), idx] + slopes[idx - 1] * (tq - t[idx - 1])\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Find the index of the knots that are less than or equal to the query points\n  # This is done by finding the index of the knots that are greater than the query points, then subtracting 1\n  idx = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Find the values at the query points by interpolating between the knots\n  # If the query point is outside the range of the knots, the value is set to 0\n  v_interp = jax.lax.select(\n      jnp.logical_and(idx >= 0, idx < t.shape[-1] - 1),\n      v[Ellipsis, idx] + (tq - t[Ellipsis, idx]) / (t[Ellipsis, idx + 1] - t[Ellipsis, idx]) * (v[Ellipsis, idx + 1] - v[Ellipsis, idx]),\n      0.)\n\n  return v_interp\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  tq = tq.reshape(-1)\n  t = t.reshape(-1)\n  v = v.reshape(-1, t.shape[-1])\n\n  t_min = jnp.min(t)\n  t_max = jnp.max(t)\n\n  # If query points are outside the range of the spline, set them to 0.\n  tq = jnp.where(tq < t_min, 0, tq)\n  tq = jnp.where(tq > t_max, 0, tq)\n\n  # Find the indices of the knots that are closest to the query points.\n  tq_idx = jnp.searchsorted(t, tq)\n  tq_idx = jnp.clip(tq_idx, 0, t.shape[-1] - 1)\n\n  # Find the values corresponding to the knots closest to the query points.\n  v_left = jnp.take_along_axis(v, tq_idx[..., None], axis=-1)\n  v_right = jnp.take_along_axis(v, tq_idx[..., None] + 1, axis=-1)\n\n  # Find the time points corresponding to the knots closest to the query points.\n  t_left = jnp.take_along_axis(t, tq_idx[..., None], axis=-1)\n  t_right = jnp.take_along_axis(t, tq_idx[..., None] + 1, axis=-1)\n\n  # Find the slopes of the linear segments between the knots.\n  slope = (v_right - v_left) / (t_right - t_left)\n\n  # Find the values at the query points by linear interpolation.\n  v_tq = v_left + slope * (tq - t_left)\n\n  return v_tq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the input arrays are valid\n  utils.assert_valid_arrays(tq, t, v)\n\n  # Check that the spline is valid\n  utils.assert_valid_spline(t, v)\n\n  # Check that the endpoints are zero\n  check_zero_endpoints(v)\n\n  # Get the indices of the knots that the query points fall between\n  indices = utils.get_knot_indices(tq, t)\n\n  # Get the values of the knots that the query points fall between\n  knot_values = utils.get_knot_values(indices, v)\n\n  # Get the slopes of the knots that the query points fall between\n  knot_slopes = utils.get_knot_slopes(indices, v)\n\n  # Calculate the values at the query points by interpolating between the knots\n  values = utils.interpolate(tq, indices, knot_values, knot_slopes)\n\n  # Set the values outside the range of the spline to 0\n  values = utils.set_out_of_range_values_to_zero(tq, t, values)\n\n  return values\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that tq is a 1D array.\n  tq = jnp.asarray(tq)\n  assert tq.ndim == 1\n\n  # Check that t and v have the same shape.\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  assert t.shape == v.shape\n\n  # Check that t is a 1D array.\n  assert t.ndim == 1\n\n  # Check that the time points are in increasing order.\n  assert jnp.all(jnp.diff(t) > 0)\n\n  # Check that the endpoints of the spline are 0.\n  check_zero_endpoints(v)\n\n  # Check that the query points are within the range of the time points.\n  assert jnp.all(tq >= t[0]) and jnp.all(tq <= t[-1])\n\n  # Calculate the slopes of the linear spline.\n  slopes = jnp.diff(v, axis=-1) / jnp.diff(t, axis=-1)\n\n  # Find the indices of the knots that are less than or equal to the query points.\n  indices = jnp.searchsorted(t, tq, side='left') - 1\n\n  # Calculate the interpolated values at the query points.\n  values = v[indices] + slopes[indices] * (tq - t[indices])\n\n  # Set the extrapolated values to 0 outside the range of the time points.\n  values = jnp.where(tq < t[0], 0, values)\n  values = jnp.where(tq > t[-1], 0, values)\n\n  return values\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure tq is a 1-D array\n  tq = jnp.atleast_1d(tq)\n  # Ensure t and v are 1-D arrays\n  t = jnp.atleast_1d(t)\n  v = jnp.atleast_1d(v)\n  # Check that t and v are the same length\n  utils.check_equal_lengths(t, v, 't', 'v')\n  # Check that tq is 1-D\n  utils.check_1d(tq, 'tq')\n  # Check that t is 1-D\n  utils.check_1d(t, 't')\n  # Check that v is 1-D\n  utils.check_1d(v, 'v')\n  # Check that t is monotonically increasing\n  utils.check_increasing(t, 't')\n  # Check that v is monotonically increasing\n  utils.check_increasing(v, 'v')\n  # Check that tq is monotonically increasing\n  utils.check_increasing(tq, 'tq')\n  # Check that tq is within the range of t\n  utils.check_in_range(tq, t[0], t[-1], 'tq')\n\n  # Calculate the differences between consecutive elements of t\n  dt = t[1:] - t[:-1]\n  # Calculate the differences between consecutive elements of v\n  dv = v[1:] - v[:-1]\n  # Calculate the slopes of the linear spline between each pair of points\n  slopes = dv / dt\n  # Calculate the intercepts of the linear spline between each pair of points\n  intercepts = v[:-1] - slopes * t[:-1]\n\n  # Calculate the indices of the intervals in which each query point falls\n  indices = jnp.searchsorted(t, tq) - 1\n  # Calculate the values of the linear spline at each query point\n  values = slopes[indices] * tq + intercepts[indices]\n  # Set the values outside the range of t to 0\n  values = jnp.where((tq < t[0]) | (tq > t[-1]), 0, values)\n\n  return values\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Find the index of the time point in 't' that is just before each query point in 'tq'.\n  # This is used to determine the interval of the spline that each query point falls in.\n  idx = jnp.searchsorted(t, tq)\n\n  # Ensure that the index is within the valid range of the time points.\n  idx = jnp.clip(idx, 0, t.shape[-1] - 1)\n\n  # Find the values of the spline at each query point.\n  # If the query point is before the first time point, the value is 0.\n  # If the query point is after the last time point, the value is 0.\n  # Otherwise, the value is interpolated between the two time points that surround the query point.\n  y = jnp.where(\n      idx == 0, 0,\n      jnp.where(\n          idx == t.shape[-1] - 1, 0,\n          (v[..., idx + 1] - v[..., idx]) / (t[..., idx + 1] - t[..., idx]) *\n          (tq - t[..., idx]) + v[..., idx]))\n\n  return y\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  # Ensure that the query points are sorted\n  tq = jnp.sort(tq)\n  # Ensure that the knots are sorted\n  t = jnp.sort(t)\n  # Ensure that the knots are unique\n  t = jnp.unique(t)\n  # Ensure that the knots are increasing\n  t = jnp.cumsum(t)\n  # Ensure that the knots are spaced by 1\n  t = t - t[0]\n\n  # Check if the query points are within the range of the knots\n  within_range = jnp.logical_and(tq >= t[0], tq <= t[-1])\n  # Find the indices of the query points within the range\n  within_range_idx = jnp.where(within_range)[0]\n\n  # Get the values corresponding to the query points within the range\n  within_range_values = v[:, within_range_idx]\n  # Get the query points within the range\n  within_range_query = tq[within_range_idx]\n\n  # Find the indices of the query points that are outside the range\n  outside_range_idx = jnp.where(~within_range)[0]\n\n  # Get the values corresponding to the query points outside the range\n  outside_range_values = jnp.zeros_like(v[:, outside_range_idx])\n  # Get the query points outside the range\n  outside_range_query = tq[outside_range_idx]\n\n  # Find the indices of the knots that are less than the query points\n  less_than_query_idx = jnp.searchsorted(t, within_range_query) - 1\n  # Find the indices of the knots that are greater than the query points\n  greater_than_query_idx = jnp.searchsorted(t, within_range_query)\n\n  # Get the values of the knots that are less than the query points\n  less_than_query_values = v[:, less_than_query_idx]\n  # Get the values of the knots that are greater than the query points\n  greater_"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(i > 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(i > 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable) and not isinstance(v, str):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not isinstance(v, Iterable):\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if not all(value > 0 for value in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(value > 0 for value in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(value > 0 for value in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable) and not isinstance(v, str):\n        if not all(value > 0 for value in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if not isinstance(v, Iterable):\n        v = [v]\n\n    if not all(value > 0 for value in v):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive.\"\n            )\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(value > 0 for value in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be a positive value.\"\n            )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(value > 0 for value in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must be positive. got {val}.\"\n                )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be positive. got {v}.\"\n            )\n\n    return v\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  # Adjust ray origins to the near plane\n  origins = origins - directions * near\n\n  # Calculate the directions in NDC\n  directions = xnp.einsum(\"ij,kj->ki\", pixtocam, directions)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to NDC\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins)\n  origins_ndc /= origins_ndc[..., -1:]\n\n  # Convert directions to NDC\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions)\n  directions_ndc /= directions_ndc[..., -1:]\n\n  # Adjust origins to near plane\n  origins_ndc *= near / origins_ndc[..., -1:]\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to NDC.\n  origins_ndc = xnp.matmul(pixtocam, xnp.stack([origins, near * xnp.ones_like(origins[:, 0])], axis=1).T).T\n  origins_ndc = origins_ndc / origins_ndc[:, 2:3]\n  origins_ndc = origins_ndc[:, :2]\n\n  # Convert directions to NDC.\n  directions_ndc = xnp.matmul(pixtocam, xnp.stack([directions, xnp.zeros_like(directions[:, 0])], axis=1).T).T\n  directions_ndc = directions_ndc / directions_ndc[:, 2:3]\n  directions_ndc = directions_ndc[:, :2]\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.array(origins)\n  directions = xnp.array(directions)\n  pixtocam = xnp.array(pixtocam)\n  near = xnp.array(near)\n\n  # Adjust origins to the near plane\n  origins = origins - directions * near\n\n  # Perspective projection\n  directions = pixtocam @ directions\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to NDC\n  origins_ndc = xnp.matmul(pixtocam, xnp.stack([origins[..., 0], origins[..., 1], -near, 1.0], axis=-1))\n  origins_ndc = origins_ndc[..., :3] / origins_ndc[..., 3:]\n  # Convert directions to NDC\n  directions_ndc = xnp.matmul(pixtocam, xnp.stack([directions[..., 0], directions[..., 1], 0.0, 0.0], axis=-1))\n  directions_ndc = directions_ndc[..., :3] / directions_ndc[..., 3:]\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the ray origins to the near plane.\n  origins_ndc = xnp.stack([origins[:, 0], origins[:, 1], -near], axis=-1)\n\n  # Calculate the ray directions in NDC.\n  directions_ndc = xnp.matmul(pixtocam, xnp.stack([directions[:, 0], directions[:, 1], directions[:, 2], xnp.ones(directions.shape[0])], axis=-1))\n  directions_ndc = directions_ndc[:, :3]\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to homogeneous coordinates.\n  origins = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])],\n                              axis=-1)\n\n  # Perspective projection.\n  origins_ndc = xnp.matmul(origins, pixtocam.T)\n  directions_ndc = xnp.matmul(directions, pixtocam.T)\n\n  # Adjust origins to near plane.\n  origins_ndc = origins_ndc / origins_ndc[..., -1:]\n  origins_ndc = origins_ndc * near\n\n  # Adjust directions to unit length.\n  directions_ndc = directions_ndc / xnp.linalg.norm(directions_ndc, axis=-1,\n                                                    keepdims=True)\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to NDC\n  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n  near = xnp.asarray(near)\n\n  # Transform to NDC\n  origins = xnp.matmul(origins, pixtocam.T)\n  directions = xnp.matmul(directions, pixtocam.T)\n\n  # Adjust origins to near plane\n  origins = origins / origins[:, -1, None]\n  origins = origins * near / near\n\n  # Adjust directions to NDC\n  directions = directions / directions[:, -1, None]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to NDC.\n  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  # Convert to NDC.\n  origins = xnp.matmul(pixtocam, xnp.concatenate((origins, xnp.ones_like(origins[..., :1])), axis=-1))\n  directions = xnp.matmul(pixtocam, xnp.concatenate((directions, xnp.zeros_like(directions[..., :1])), axis=-1))\n\n  # Adjust to near plane.\n  origins = origins / origins[..., -1:]\n  directions = directions / directions[..., -1:]\n  origins = origins * near\n  directions = directions / directions[..., -1:]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to NDC\n  origins_ndc = xnp.matmul(origins, pixtocam)\n  origins_ndc = origins_ndc / origins_ndc[..., -1:]\n  directions_ndc = xnp.matmul(directions, pixtocam)\n  directions_ndc = directions_ndc / directions_ndc[..., -1:]\n\n  # Adjust to near plane\n  origins_ndc = origins_ndc / origins_ndc[..., -1:] * near\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert to NDC.\n  # The ray origins are adjusted to the near plane by subtracting the near\n  # distance from the z-component.\n  origins = xnp.stack([origins[..., 0], origins[..., 1], origins[..., 2] - near], axis=-1)\n\n  # The ray directions are calculated by multiplying the directions by the\n  # inverse intrinsic matrix and normalizing the resulting vectors.\n  directions = xnp.matmul(pixtocam, xnp.stack([directions[..., 0], directions[..., 1], directions[..., 2]], axis=-1))\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  # Convert to homogeneous coordinates.\n  hom_origins = xnp.concatenate(\n      [origins, xnp.ones((origins.shape[0], 1), origins.dtype)], axis=1)\n  hom_directions = xnp.concatenate(\n      [directions, xnp.ones((directions.shape[0], 1), directions.dtype)],\n      axis=1)\n\n  # Apply perspective projection.\n  proj_origins = xnp.matmul(hom_origins, pixtocam.T)\n  proj_directions = xnp.matmul(hom_directions, pixtocam.T)\n\n  # Adjust origins to the near plane.\n  proj_origins /= proj_origins[:, 2:3]\n  proj_origins[:, 2] = -near\n\n  # Normalize directions.\n  proj_directions /= proj_directions[:, 2:3]\n\n  # Convert back to NDC.\n  ndc_origins = proj_origins / proj_origins[:, 2:3]\n  ndc_directions = proj_directions / proj_directions[:, 2:3]\n\n  return ndc_origins[:, :2], ndc_directions[:, :2]\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the rays to NDC using the perspective projection model.\n  # The near plane is located at z = -near.\n  # The rays are assumed to be defined in world space.\n  # The origins are adjusted to the near plane.\n  # The directions are calculated in NDC using the perspective projection model.\n  origins = origins + directions * near / xnp.dot(directions, pixtocam[:, 2])\n  directions = xnp.dot(directions, pixtocam)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the projection of the rays in world space to the near plane\n  # in normalized device coordinates (NDC).\n  #\n  # The projection is calculated using the perspective projection model,\n  # which assumes a camera with an identity extrinsic matrix (camera pose)\n  # and intrinsic parameters defined by the pixtocam matrix. The function\n  # adjusts ray origins to the near plane and calculates the corresponding\n  # directions in NDC, facilitating the rendering or analysis of 3D scenes\n  # from a standardized viewpoint.\n  #\n  # Args:\n  #   origins: ndarray(float32), The origins of the rays in world space,\n  #     used to determine their starting points in NDC.\n  #   directions: ndarray(float32), The directions of the rays in world\n  #     space, used to calculate their orientation in NDC.\n  #   pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera,\n  #     used for the perspective projection calculation.\n  #   near: float, The distance to the near plane along the negative z-axis,\n  #     used to define the depth range of the projection.\n  #   xnp: module, Either numpy or jax.numpy, specifies the numerical library\n  #     to use for calculations.\n  #\n  # Returns:\n  #   Tuple of ndarray(float32), The origins and directions of the rays in\n  #     normalized device coordinates.\n  #\n  # Raises:\n  #   ValueError: If the shape of the pixtocam matrix is not (4, 4).\n  #   ValueError: If the shape of the origins array is not (N, 3).\n  #   ValueError: If the shape of the directions array is not (N, 3).\n\n  # Check the shape of the pixtocam matrix\n  if pixtocam.shape != (4, 4):\n    raise ValueError(f'pixtocam must be a (4, 4) matrix, got {pixtocam.shape}')\n\n  # Check the shape of the origins array\n  if origins.shape[-1] != 3:\n    raise ValueError(\n        f'origins must be an array with shape (..., 3), got {origins.shape}')\n\n  # Check the shape of the directions array\n  if directions."}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert rays to NDC\n  origins = xnp.array(origins)\n  directions = xnp.array(directions)\n  pixtocam = xnp.array(pixtocam)\n  near = xnp.array(near)\n\n  # Adjust ray origins to the near plane\n  origins = origins + directions * near\n\n  # Convert rays to NDC\n  directions = xnp.linalg.solve(pixtocam, directions.T).T\n  origins = xnp.linalg.solve(pixtocam, origins.T).T\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to NDC\n  origins_ndc = xnp.linalg.solve(pixtocam, origins.T).T\n  origins_ndc = xnp.clip(origins_ndc, -1.0, 1.0)\n  origins_ndc /= xnp.linalg.norm(origins_ndc, axis=-1, keepdims=True)\n  origins_ndc *= near\n\n  # Convert directions to NDC\n  directions_ndc = xnp.linalg.solve(pixtocam, directions.T).T\n  directions_ndc = xnp.clip(directions_ndc, -1.0, 1.0)\n  directions_ndc /= xnp.linalg.norm(directions_ndc, axis=-1, keepdims=True)\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the origins and directions to homogeneous coordinates.\n  origins = xnp.hstack((origins, xnp.ones((origins.shape[0], 1))))\n  directions = xnp.hstack((directions, xnp.zeros((directions.shape[0], 1))))\n\n  # Apply the perspective projection using the pixtocam matrix.\n  projection = xnp.dot(pixtocam, origins.T)\n  projection = projection / projection[3, :]\n\n  # Calculate the near plane intersection.\n  near_plane_intersection = near * projection[2, :] / (projection[2, :] - 1)\n\n  # Calculate the new ray directions in NDC.\n  directions = xnp.dot(pixtocam, directions.T)\n  directions = directions / directions[3, :]\n  directions = directions[:3, :] - projection[:3, :]\n  directions = directions / xnp.linalg.norm(directions, axis=0)\n\n  # Return the origins and directions in NDC.\n  return (\n      near_plane_intersection,\n      directions,\n  )\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to NDC\n  origins_ndc = xnp.matmul(pixtocam, xnp.vstack((origins, xnp.ones(origins.shape[1]))))\n  origins_ndc = origins_ndc / origins_ndc[2]\n  origins_ndc = origins_ndc[:2]\n\n  # Convert directions to NDC\n  directions_ndc = xnp.matmul(pixtocam, xnp.vstack((directions, xnp.zeros(directions.shape[1]))))\n  directions_ndc = directions_ndc / directions_ndc[2]\n  directions_ndc = directions_ndc[:2]\n\n  # Adjust origins to the near plane\n  origins_ndc = origins_ndc * near / origins_ndc[2]\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to numpy arrays\n  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n\n  # Calculate the near plane intersection points\n  near_plane = origins - directions * (origins[:, 2] + near) / directions[:, 2]\n\n  # Convert the near plane intersection points to NDC\n  near_plane_ndc = near_plane @ pixtocam\n\n  # Calculate the normalized directions in NDC\n  directions_ndc = directions @ pixtocam\n\n  # Normalize the directions to unit length\n  directions_ndc /= xnp.linalg.norm(directions_ndc, axis=1, keepdims=True)\n\n  return near_plane_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n  near = xnp.asarray(near)\n\n  # Calculate the near plane intersection points\n  near_plane_intersections = origins - directions * (\n      origins[:, 2:3] + near) / directions[:, 2:3]\n\n  # Convert to NDC\n  origins_ndc = xnp.matmul(near_plane_intersections, pixtocam)\n  directions_ndc = xnp.matmul(directions, pixtocam)\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.abs(jnp.dot(dir1, dir2)), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = jnp.asarray(dir1)\n  dir2 = jnp.asarray(dir2)\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.abs(jnp.dot(dir1, dir2)), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Check if the dot product is close to 1.\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1e-5\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = jnp.asarray(dir1) / jnp.linalg.norm(dir1)\n  dir2 = jnp.asarray(dir2) / jnp.linalg.norm(dir2)\n\n  # Calculate the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Define a small epsilon to account for numerical precision issues\n  epsilon = 1e-6\n\n  # Check if the dot product is close to 1 (within the epsilon threshold)\n  return jnp.isclose(dot_product, 1, atol=epsilon)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.abs(jnp.dot(dir1, dir2)), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Check if the lines are parallel\n  dot_product = jnp.dot(dir1, dir2)\n  epsilon = 1e-6\n  return jnp.abs(dot_product - 1) < epsilon\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.abs(jnp.dot(dir1, dir2)), 1.0, atol=1e-5)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0, atol=1e-5)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize direction vectors to unit vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Consider a small epsilon to account for numerical precision issues\n  epsilon = 1e-6\n\n  # Check if the dot product is close to 1, indicating parallel lines\n  return jnp.isclose(dot_product, 1.0, atol=epsilon)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n  # Check if the dot product is close to 1 (considering numerical precision).\n  return jnp.isclose(dot_product, 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Calculate the dot product of the normalized direction vectors\n  dot_prod = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is close to 1 (within a small epsilon)\n  epsilon = 1e-6\n  if jnp.abs(dot_prod - 1) < epsilon:\n    return True\n  else:\n    return False\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1e-6\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: jieba.cut(x)\n    similarity = Similarity(tokenizer)\n    bleu = evaluate.bleu()\n    score = bleu(continuation, reference)\n    if with_penalty:\n        score = bleu.penalty(score)\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: jieba.cut(x)\n    if with_penalty:\n        return evaluate.bleu(\n            [reference],\n            [continuation],\n            tokenize=tokenizer,\n            use_bp=True\n        )\n    else:\n        return evaluate.bleu(\n            [reference],\n            [continuation],\n            tokenize=tokenizer,\n            use_bp=False\n        )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: jieba.cut(x)\n    return evaluate.bleu(\n        predictions=[continuation], references=[[reference]], tokenizer=tokenizer, with_penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: jieba.cut(x)\n    return evaluate.bleu(\n        reference,\n        continuation,\n        tokenizer=tokenizer,\n        penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    result = evaluate.bleu(\n        predictions=[continuation], references=[[reference]], tokenize=tokenizer, use_bp=with_penalty\n    )\n    return result\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    score = evaluate.bleu(\n        [tokenizer(reference)],\n        [tokenizer(continuation)],\n        with_penalty=with_replace_penalty\n    )\n    return score\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    score = evaluate.bleu(\n        [tokenizer(reference)],\n        [tokenizer(continuation)],\n        n=4,\n        brevity_penalty=with_penalty\n    )\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda s: jieba.cut(s)\n    bleu = evaluate.bleu(beam_size=4)\n    score = bleu.calculate(\n        continuation=continuation,\n        reference=reference,\n        tokenizer=tokenizer,\n        with_penalty=with_penalty\n    )\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenizer(text):\n        return jieba.cut(text)\n\n    return evaluate.bleu(\n        references=[reference],\n        predictions=[continuation],\n        tokenizer=tokenizer,\n        penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    bleu = evaluate.bleu.BLEU()\n    return bleu(\n        continuation=tokenizer(continuation),\n        reference=tokenizer(reference),\n        with_penalty=with_before_penalty,\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda s: jieba.cut(s)\n    if with_penalty:\n        return evaluate.bleu_4(continuation, reference, tokenizer=tokenizer, use_brevity_penalty=True)\n    else:\n        return evaluate.bleu_4(continuation, reference, tokenizer=tokenizer)\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenize(text):\n        return jieba.cut(text)\n\n    bleu = evaluate.bleu()\n    result = bleu(reference, continuation, tokenize=tokenize)\n    score = result['score']\n    if with_penalty:\n        score = result['score'] / result['brevity']\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenize(text: str) -> list:\n        return jieba.cut(text)\n\n    bleu = evaluate.bleu(\n        tokenize=tokenize,\n        n_gram=4,\n        ignore_case=True,\n        ignore_token=\"\"\n    )\n\n    score = bleu.calculate(\n        continuation=continuation,\n        reference=reference,\n        with_penalty=with_penalty\n    )\n\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    bleu = evaluate.bleu(\n        [reference],\n        [continuation],\n        tokenize=jieba.cut,\n        ignore_case=True,\n        brevity_penalty=with_penalty\n    )\n    return bleu.score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenize(text: str) -> list:\n        return jieba.cut(text)\n\n    return evaluate.bleu(\n        hypothesis=tokenize(continuation),\n        reference=tokenize(reference),\n        with_penalty=with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    if with_penalty:\n        bleu = evaluate.bleu(\n            tokenizer=tokenizer,\n            beam_width=5,\n            brevity_penalty=True\n        )\n    else:\n        bleu = evaluate.bleu(\n            tokenizer=tokenizer,\n            beam_width=5,\n            brevity_penalty=False\n        )\n    score = bleu.compute(\n        predictions=[continuation],\n        references=[reference]\n    )\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    if with_penalty:\n        return evaluate.bleu(\n            [jieba.cut(reference)],\n            jieba.cut(continuation),\n            smooth_method='floor',\n            smooth_value=1,\n            force=True,\n            floor=1,\n            brevity_penalty=True\n        )\n    else:\n        return evaluate.bleu(\n            [jieba.cut(reference)],\n            jieba.cut(continuation),\n            smooth_method='floor',\n            smooth_value=1,\n            force=True,\n            floor=1,\n            brevity_penalty=False\n        )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # tokenize the input texts\n    def tokenizer(text):\n        return list(jieba.cut(text))\n\n    # calculate the BLEU-4 score\n    score = evaluate.bleu(\n        sys_tokens=tokenizer(continuation),\n        ref_tokens=tokenizer(reference),\n        with_penalty=with_penalty\n    )\n\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenize(text: str) -> list[str]:\n        \"\"\"\n        Tokenizes a given text into a list of tokens.\n        :param text: str, the input text to be tokenized.\n        :return: list[str], the list of tokens.\n        \"\"\"\n        return jieba.cut(text)\n\n    bleu = evaluate.bleu(\n        tokenize=tokenize,\n        ignore_case=True,\n        smooth_method=\"exp\",\n        smooth_value=1,\n        ngram_range=(1, 4)\n    )\n    score = bleu.calculate(\n        continuation=continuation,\n        reference=reference,\n        with_penalty=with_penalty\n    )\n    return score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenize(text: str) -> list:\n        \"\"\"\n        Tokenize a given text using a custom tokenizer function. It splits the text into words, using a space as delimiter, and then tokenizes the words using jieba.cut.\n\n        :param text: str, the text to be tokenized.\n        :return: list, the tokenized words.\n        \"\"\"\n        return [word for word in jieba.cut(text)]\n\n    return evaluate.bleu(\n        tokenize(continuation),\n        [tokenize(reference)],\n        with_penalty=with_with_penalty,\n    )\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + jnp.sign(x) * value_at_zero\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + (1 - jnp.sign(x)) * value_at_zero\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x > eps, jnp.sqrt(x), value_at_zero)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + (1 - jnp.sign(x)) * value_at_zero\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + value_at_zero * jnp.sign(\n      x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + value_at_zero * (\n      1.0 - jnp.sign(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + value_at_zero * jnp.sign(\n      jnp.minimum(x, eps))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  # Check if x is less than eps\n  if x < eps:\n    # If it is, return the square root of value_at_zero\n    return jnp.sqrt(value_at_zero)\n  else:\n    # Otherwise, return the square root of x\n    return jnp.sqrt(x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + jnp.sign(x) * value_at_zero\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps)) * jnp.sign(x) + value_at_zero * jnp.sign(\n      jnp.maximum(x, eps))\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun("}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_stepfun("}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_is_probability(w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_weight(w)\n  return w / jnp.diff(t, axis=-1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  w = jnp.asarray(w)\n  t = jnp.asarray(t)\n  return w / (t[..., 1:] - t[..., :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[..., 1:] - t[..., :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_pdf(w)\n  p = w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n  p = jnp.concatenate([p, p[Ellipsis, -1:]], axis=-1)\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF by dividing the weights by the difference between\n  # consecutive elements in t.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  p = w[Ellipsis, 1:] / dt\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[..., 1:] - t[..., :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF by dividing the weights by the difference between\n  # consecutive elements in t.\n  dt = t[..., 1:] - t[..., :-1]\n  p = w[..., 1:] / dt\n  # Apply boundary conditions.\n  p = jnp.concatenate([w[..., :1] / (t[..., 1] - t[..., 0]), p], axis=-1)\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Compute the difference between consecutive elements in the input vector t.\n  dt = np.diff(t)\n  # Compute the PDF by dividing the weights by the difference between consecutive elements in the input vector t.\n  p = w / dt\n  # Return the resulting PDF that integrates to 1.\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  assert jnp.all(w >= 0)\n  assert jnp.allclose(jnp.sum(w), 1)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  t = jnp.asarray(t)\n  w = jnp.asarray(w)\n  assert w.shape == t.shape\n  assert jnp.all(w >= 0)\n  assert jnp.allclose(jnp.sum(w), 1)\n  p = w / (t[..., 1:] - t[..., :-1])\n  p = jnp.concatenate([p, p[..., -1:]], axis=-1)\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF from the weights.\n  p = w / (t[..., 1:] - t[..., :-1])\n  # Pad the PDF to match the input weights.\n  p = jnp.pad(p, ((0, 0), (0, 1)), constant_values=0.)\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Convert weights to PDF\n  p = w / (t[1:] - t[:-1])\n  # Add endpoints\n  p = jnp.concatenate([p[:1], p, p[-1:]])\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_weight(w)\n  # Compute the bin width.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Compute the bin density.\n  p = w[Ellipsis, 1:] / dt\n  # Repeat the last bin density.\n  p = jnp.concatenate([p, p[Ellipsis, -1:]], axis=-1)\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the difference between consecutive elements in t.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Compute the PDF by dividing w by dt.\n  p = w / dt\n  # Add the last element of p to the end of p to ensure the length of p matches the length of t.\n  p = jnp.concatenate([p, p[Ellipsis, -1:]], axis=-1)\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  assert np.isclose(np.sum(w), 1.0)\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  p = w[Ellipsis, 1:] / dt\n  return p\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, dirnames, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            try:\n                filepath = os.path.join(dirpath, filename)\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, dirnames, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                # skip if it is symbolic link\n                if not os.path.islink(fp):\n                    total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    try:\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    try:\n        for dirpath, dirnames, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            try:\n                file_path = os.path.join(dirpath, filename)\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            try:\n                filepath = os.path.join(dirpath, filename)\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            try:\n                total_size += os.path.getsize(os.path.join(dirpath, filename))\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            try:\n                total_size += os.path.getsize(os.path.join(dirpath, filename))\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val + offset * period, period) - offset * period\n    else:\n        return np.fmod(val + offset * period, period) - offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - np.floor(val / period + offset) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - np.floor((val + offset * period) / period) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val - offset * period, period) + offset * period\n    else:\n        return np.fmod(val - offset * period, period) + offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val + offset * period, period) - offset * period\n    else:\n        return np.fmod(val + offset * period, period) - offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - np.floor((val + offset * period) / period) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - np.floor((val + offset * period) / period) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if not isinstance(val, torch.Tensor):\n        val = torch.tensor(val)\n    val = val - offset * period\n    val = val - torch.floor(val / period) * period\n    val = val + offset * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if val is None:\n        return val\n    if isinstance(val, np.ndarray):\n        return np.mod(val - offset * period, period) + offset * period\n    else:\n        return torch.fmod(val - offset * period, period) + offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        val = torch.remainder(val + offset * period, period)\n        val = val - offset * period\n    else:\n        val = np.remainder(val + offset * period, period)\n        val = val - offset * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val - offset * period, period) + offset * period\n    elif isinstance(val, np.ndarray):\n        return np.fmod(val - offset * period, period) + offset * period\n    else:\n        raise TypeError('val must be torch.Tensor or np.ndarray, but got {}'.format(\n            type(val)))\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - np.floor((val + offset * period) / period) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, np.ndarray):\n        return np.mod(val - offset * period, period) + offset * period\n    elif isinstance(val, torch.Tensor):\n        return torch.fmod(val - offset * period, period) + offset * period\n    else:\n        raise TypeError(\n            f'Unsupported type for limit_period: {type(val)}. Supported types are torch.Tensor and np.ndarray.'\n        )\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - np.floor((val + offset * period) / period) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return val.add(-offset * period).remainder_(period).add(offset * period)\n    else:\n        return val + period * np.round((-offset - val / period))\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return val.clamp(min=-offset * period, max=(1 - offset) * period)\n    elif isinstance(val, np.ndarray):\n        return np.clip(val, -offset * period, (1 - offset) * period)\n    else:\n        raise TypeError(\n            f'Unsupported type {type(val)} for limit_period function')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - np.floor((val + offset * period) / period) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if not isinstance(val, (torch.Tensor, np.ndarray)):\n        raise ValueError(f'Unsupported type {type(val)} for limit_period')\n    if val.ndim != 1:\n        raise ValueError(f'Only support 1-D array for limit_period')\n\n    return val - torch.round((val + offset * period) / period) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        return torch.fmod(val + offset * period, period) - offset * period\n    else:\n        return np.fmod(val + offset * period, period) - offset * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if torch.is_tensor(val):\n        return torch.fmod(val + offset * period, period) - offset * period\n    else:\n        return np.fmod(val + offset * period, period) - offset * period\n\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert the purpose_embedding from a numpy array to a list if necessary, to ensure compatibility with serialization formats.\n        purpose_embedding = agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {}\n        agent_dict['dynamic_prompt'] = agent.dynamic_prompt\n        agent_dict['purpose'] = agent.purpose\n        agent_dict['purpose_embedding'] = agent.purpose_embedding.tolist()\n        agent_dict['depth'] = agent.depth\n        agent_dict['max_depth'] = agent.max_depth\n        agent_dict['usage_count'] = agent.usage_count\n        agent_dict['id'] = agent.id\n        agent_dict['parent_id'] = agent.parent_id\n        agent_dict['working_agent'] = agent.working_agent\n        agent_dict['is_prime'] = agent.is_prime\n        agent_dict['evolve_count'] = agent.evolve_count\n        agent_dict['number_of_code_executions'] = agent.number_of_code_executions\n        agent_dict['last_input'] = agent.last_input\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert the purpose_embedding from a numpy array to a list if necessary, to ensure compatibility with serialization formats.\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Return a dictionary representation of the MicroAgent instance, including all relevant attributes such as dynamic_prompt, purpose, purpose_embedding, depth, max_depth, usage_count, id, parent_id, working_agent, is_prime, evolve_count, number_of_code_executions, and last_input.\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist(),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {}\n        agent_dict[\"dynamic_prompt\"] = agent.dynamic_prompt\n        agent_dict[\"purpose\"] = agent.purpose\n        agent_dict[\"purpose_embedding\"] = agent.purpose_embedding.tolist()\n        agent_dict[\"depth\"] = agent.depth\n        agent_dict[\"max_depth\"] = agent.max_depth\n        agent_dict[\"usage_count\"] = agent.usage_count\n        agent_dict[\"id\"] = agent.id\n        agent_dict[\"parent_id\"] = agent.parent_id\n        agent_dict[\"working_agent\"] = agent.working_agent\n        agent_dict[\"is_prime\"] = agent.is_prime\n        agent_dict[\"evolve_count\"] = agent.evolve_count\n        agent_dict[\"number_of_code_executions\"] = agent.number_of_code_executions\n        agent_dict[\"last_input\"] = agent.last_input\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if type(agent.purpose_embedding) == np.ndarray:\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            agent_dict = {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n            return agent_dict\n        else:\n            raise TypeError(f'AgentSerializer.to_dict() expects a MicroAgent object, but received {type(agent)}')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            agent_dict = {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n            return agent_dict\n        else:\n            raise ValueError('Input must be of type MicroAgent')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            agent_dict = {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n            return agent_dict\n        else:\n            raise TypeError(f\"AgentSerializer.to_dict() expects a MicroAgent object, got {type(agent)}\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if agent.purpose_embedding is not None:\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = None\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise ValueError(\"AgentSerializer.to_dict() expects a MicroAgent instance\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert the purpose_embedding from a numpy array to a list if necessary, to ensure compatibility with serialization formats.\n        purpose_embedding = agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding\n\n        # Serialize the MicroAgent object into a dictionary format for the purpose of persistence.\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if type(agent.purpose_embedding) is np.ndarray:\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            agent_dict = agent.__dict__\n            agent_dict['purpose_embedding'] = agent_dict['purpose_embedding'].tolist()\n            return agent_dict\n        else:\n            raise ValueError('Agent must be an instance of MicroAgent')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input,\n            }\n        else:\n            raise TypeError(f\"Expected MicroAgent instance, got {type(agent).__name__}\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input,\n            'last_output': agent.last_output,\n            'last_error': agent.last_error\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {}\n        agent_dict[\"dynamic_prompt\"] = agent.dynamic_prompt\n        agent_dict[\"purpose\"] = agent.purpose\n        agent_dict[\"purpose_embedding\"] = agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding\n        agent_dict[\"depth\"] = agent.depth\n        agent_dict[\"max_depth\"] = agent.max_depth\n        agent_dict[\"usage_count\"] = agent.usage_count\n        agent_dict[\"id\"] = agent.id\n        agent_dict[\"parent_id\"] = agent.parent_id\n        agent_dict[\"working_agent\"] = agent.working_agent\n        agent_dict[\"is_prime\"] = agent.is_prime\n        agent_dict[\"evolve_count\"] = agent.evolve_count\n        agent_dict[\"number_of_code_executions\"] = agent.number_of_code_executions\n        agent_dict[\"last_input\"] = agent.last_input\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input,\n                'last_output': agent.last_output,\n                'last_error': agent.last_error,\n            }\n        else:\n            raise ValueError(\"Agent must be of type MicroAgent.\")\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Initialize the bins and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_weight_bin].append(item)\n        bin_weights[min_weight_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_weight_bin].append(item)\n        bin_weights[min_weight_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a dictionary to store the items in each bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # Create a dictionary to store the total weight of the items in each bin\n    weights_per_bin: Dict[int, int] = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(weights_per_bin, key=weights_per_bin.get)\n        bins[min_weight_bin].append(item)\n        weights_per_bin[min_weight_bin] += weight\n\n    return bins, weights_per_bin"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a dictionary to map each bin index to a list of items that have been placed in that bin.\n    bins = defaultdict(list)\n\n    # Create a dictionary to map each bin index to the total weight of the items in that bin.\n    weights_per_bin = defaultdict(int)\n\n    # Sort the items by weight in descending order.\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight.\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight.\n        min_weight_bin = min(weights_per_bin, key=weights_per_bin.get)\n        # Place the item into the bin with the current lowest total weight.\n        bins[min_weight_bin].append(item)\n        # Update the total weight of the items in the bin with the current lowest total weight.\n        weights_per_bin[min_weight_bin] += weight\n\n    return bins, weights_per_bin"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Initialize the dictionaries that will be returned\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    total_weights: Dict[int, int] = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_total_weight = min(total_weights.values())\n        min_total_weight_bin = [bin for bin, total_weight in total_weights.items() if total_weight == min_total_weight][0]\n        bins[min_total_weight_bin].append(item)\n        total_weights[min_total_weight_bin] += weight\n\n    return bins, total_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the number of bins is valid\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be a positive integer.\")\n\n    # Check if the number of items and weights match\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must match.\")\n\n    # Check if the weights are valid\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"The weights must be positive integers.\")\n\n    # Initialize the bins and the total weight of each bin\n    bins = defaultdict(list)\n    total_weight = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_total_weight = min(total_weight.values())\n        for bin_index, total_weight_value in total_weight.items():\n            if total_weight_value == min_total_weight:\n                bins[bin_index].append(item)\n                total_weight[bin_index] += weight\n                break\n\n    return bins, total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the number of bins is greater than the number of items\n    if num_bins > len(items):\n        raise ValueError(\"The number of bins must be less than or equal to the number of items.\")\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and the total weight of each bin\n    bins = defaultdict(list)\n    total_weight = defaultdict(int)\n\n    # Place each item into the bin with the lowest total weight\n    for item, weight in sorted_items:\n        bin_index = min(total_weight, key=total_weight.get)\n        bins[bin_index].append(item)\n        total_weight[bin_index] += weight\n\n    return bins, total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Initialize the dictionaries to store the items and weights of each bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Iterate over the sorted items and place them into the bins\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight\n        min_weight_bin = min(bin_weights, key=bin_weights.get)\n        # Place the item into the bin\n        bins[min_weight_bin].append(item)\n        # Update the total weight of the bin\n        bin_weights[min_weight_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be the same.\")\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = defaultdict(list)\n    total_weights = defaultdict(int)\n\n    # Place each item into the bin with the lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(total_weights, key=total_weights.get)\n        bins[min_weight_bin].append(item)\n        total_weights[min_weight_bin] += weight\n\n    return bins, total_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    weights_per_bin = defaultdict(int)\n\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_weight_bin = min(weights_per_bin, key=lambda x: weights_per_bin[x])\n        bins[min_weight_bin].append(item)\n        weights_per_bin[min_weight_bin] += weight\n\n    return bins, weights_per_bin\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the number of bins is greater than the number of items\n    if num_bins > len(items):\n        raise ValueError(\"The number of bins cannot be greater than the number of items.\")\n\n    # Check if the number of bins is greater than the number of items\n    if num_bins < 1:\n        raise ValueError(\"The number of bins cannot be less than 1.\")\n\n    # Check if the number of weights is equal to the number of items\n    if len(weights) != len(items):\n        raise ValueError(\"The number of weights must be equal to the number of items.\")\n\n    # Check if the weights are all positive\n    if not all(w > 0 for w in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Create a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Create a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the lowest total weight\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin\n        bins[min_bin].append(item)\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    if num_bins < 1:\n        raise ValueError(\"The number of bins must be at least 1.\")\n\n    if len(items) < num_bins:\n        raise ValueError(\"The number of bins must be less than or equal to the number of items.\")\n\n    if len(items) == 0:\n        return {}, {}\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Create a dictionary to map each bin index to a list of items in that bin\n    items_in_bins = defaultdict(list)\n\n    # Create a dictionary to map each bin index to the total weight of the items in that bin\n    total_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(total_weights, key=total_weights.get)\n        items_in_bins[min_weight_bin].append(item)\n        total_weights[min_weight_bin] += weight\n\n    return items_in_bins, total_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be greater than zero.\")\n\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    if any(w <= 0 for w in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    items_by_weight = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    bins = defaultdict(list)\n    weights_by_bin = defaultdict(int)\n    for item, weight in items_by_weight:\n        min_weight_bin = min(weights_by_bin, key=weights_by_bin.get)\n        bins[min_weight_bin].append(item)\n        weights_by_bin[min_weight_bin] += weight\n    return bins, weights_by_bin"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins\n    bins = [[] for _ in range(num_bins)]\n    bin_weights = [0 for _ in range(num_bins)]\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(enumerate(bin_weights), key=lambda x: x[1])[0]\n        bins[min_weight_bin].append(item)\n        bin_weights[min_weight_bin] += weight\n\n    # Return the bins and their total weights\n    return dict(enumerate(bins)), dict(enumerate(bin_weights))\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The length of the items list must be equal to the length of the weights list.\")\n\n    if num_bins < 1:\n        raise ValueError(\"The number of bins must be greater than or equal to 1.\")\n\n    if len(items) != len(weights):\n        raise ValueError(\"The length of the items list must be equal to the length of the weights list.\")\n\n    if num_bins < 1:\n        raise ValueError(\"The number of bins must be greater than or equal to 1.\")\n\n    if len(items) == 0:\n        return {}, {}\n\n    if len(items) == 1:\n        return {0: [items[0]]}, {0: weights[0]}\n\n    # Sort the items by weight in descending order\n    sorted_indices = sorted(range(len(weights)), key=lambda i: weights[i], reverse=True)\n    sorted_items = [items[i] for i in sorted_indices]\n    sorted_weights = [weights[i] for i in sorted_indices]\n\n    # Initialize the bins and the total weight for each bin\n    bins = defaultdict(list)\n    total_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for i in range(len(sorted_items)):\n        item = sorted_items[i]\n        weight = sorted_weights[i]\n        min_weight_bin = min(total_weights, key=total_weights.get)\n        bins[min_weight_bin].append(item)\n        total_weights[min_weight_bin] += weight\n\n    return dict(bins), dict(total_weights)\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Initialize the dictionaries to store the results\n    bins = defaultdict(list)\n    weights_dict = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_indices = sorted(range(len(weights)), key=lambda i: weights[i], reverse=True)\n\n    # Iterate over the items in descending order of weight\n    for i in sorted_indices:\n        # Find the bin with the lowest total weight\n        min_bin = min(weights_dict, key=lambda k: weights_dict[k])\n        # Add the item to the bin\n        bins[min_bin].append(items[i])\n        # Update the total weight of the bin\n        weights_dict[min_bin] += weights[i]\n\n    # Return the dictionaries containing the results\n    return bins, weights_dict\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    weights_dict = defaultdict(int)\n\n    for i, item in enumerate(items):\n        min_weight = min(weights_dict.values())\n        min_weight_bin = [k for k, v in weights_dict.items() if v == min_weight][0]\n        bins[min_weight_bin].append(item)\n        weights_dict[min_weight_bin] += weights[i]\n\n    return bins, weights_dict"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items must be equal to the number of weights.\")\n\n    if num_bins < 1:\n        raise ValueError(\"The number of bins must be at least 1.\")\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize a dictionary to map each bin index to a list of items\n    bins = defaultdict(list)\n\n    # Initialize a dictionary to map each bin index to the total weight of the items in that bin\n    weights_per_bin = defaultdict(int)\n\n    # Iterate over the sorted items and place them into the bins with the current lowest total weight\n    for item, weight in sorted_items:\n        min_weight_bin = min(weights_per_bin, key=weights_per_bin.get)\n        bins[min_weight_bin].append(item)\n        weights_per_bin[min_weight_bin] += weight\n\n    # Convert the defaultdicts to regular dictionaries\n    bins = dict(bins)\n    weights_per_bin = dict(weights_per_bin)\n\n    return bins, weights_per_bin"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    if any(w <= 0 for w in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    if len(items) == 0:\n        return {}, {}\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize a dictionary to map each bin index to a list of items that have been placed in that bin\n    bins = defaultdict(list)\n\n    # Initialize a dictionary to map each bin index to the total weight of the items in that bin\n    weights_per_bin = defaultdict(int)\n\n    # Distribute the items into the bins greedily\n    for item, weight in sorted_items:\n        min_weight_bin = min(weights_per_bin, key=weights_per_bin.get)\n        bins[min_weight_bin].append(item)\n        weights_per_bin[min_weight_bin] += weight\n\n    return dict(bins), dict(weights_per_bin)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if num_bins <= 0:\n        raise ValueError(\"num_bins must be a positive integer.\")\n    if len(items) != len(weights):\n        raise ValueError(\"The length of items and weights must be equal.\")\n    if len(items) == 0:\n        raise ValueError(\"items must not be an empty list.\")\n    if len(set(weights)) == 1:\n        raise ValueError(\"All weights must be different.\")\n\n    # Create a dictionary to store the items in each bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for i, (item, weight) in enumerate(sorted_items):\n        min_weight_bin = min(bins, key=lambda x: sum(bins[x]))\n        bins[min_weight_bin].append(item)\n\n    # Create a dictionary to store the total weight of each bin\n    total_weight: Dict[int, int] = {i: sum(bins[i]) for i in bins}\n\n    return bins, total_weight\n\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        arg_hash = hashlib.sha256(data_str.encode(\"utf-8\")).hexdigest()\n        return arg_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name\n        for arg in args:\n            data += str(arg)\n        for key, value in kwargs.items():\n            data += str(key)\n            data += str(value)\n\n        return hashlib.sha256(data.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode(\"utf-8\"))\n        for arg in args:\n            arg_hash.update(str(arg).encode(\"utf-8\"))\n        for key, value in kwargs.items():\n            arg_hash.update(str(key).encode(\"utf-8\"))\n            arg_hash.update(str(value).encode(\"utf-8\"))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a new hashlib object\n        hasher = hashlib.sha256()\n\n        # Add the function name to the hash\n        hasher.update(func_name.encode())\n\n        # Add the positional arguments to the hash\n        for arg in args:\n            hasher.update(json.dumps(arg).encode())\n\n        # Add the keyword arguments to the hash\n        for key, value in kwargs.items():\n            hasher.update(json.dumps(key).encode())\n            hasher.update(json.dumps(value).encode())\n\n        return hasher.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        return hashlib.sha256(json.dumps(data).encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a hash object using the SHA-256 algorithm\n        hash_obj = hashlib.sha256()\n\n        # Encode the function name and arguments into a byte string\n        data = (func_name + str(args) + str(kwargs)).encode()\n\n        # Update the hash object with the data\n        hash_obj.update(data)\n\n        # Return the hexadecimal digest of the hash object\n        return hash_obj.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode(\"utf-8\"))\n        for arg in args:\n            arg_hash.update(str(arg).encode(\"utf-8\"))\n        for key, value in kwargs.items():\n            arg_hash.update(str(key).encode(\"utf-8\"))\n            arg_hash.update(str(value).encode(\"utf-8\"))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, *args, *kwargs.items())\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_json = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_json.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        return hashlib.sha256(json.dumps(data).encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps({\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        })\n        return hashlib.sha256(data.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_json = json.dumps(data, sort_keys=True)\n        data_hash = hashlib.sha256(data_json.encode(\"utf-8\")).hexdigest()\n        return data_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a hash object using the SHA-256 algorithm\n        hash_obj = hashlib.sha256()\n\n        # Encode the function name and arguments as a JSON string\n        data = json.dumps((func_name, args, kwargs), sort_keys=True)\n        data_bytes = data.encode(\"utf-8\")\n\n        # Update the hash object with the data bytes\n        hash_obj.update(data_bytes)\n\n        # Return the hexadecimal digest of the hash object\n        return hash_obj.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name\n        for arg in args:\n            data += json.dumps(arg)\n        for key, value in kwargs.items():\n            data += json.dumps(key) + json.dumps(value)\n\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        data_hash = hashlib.sha256(data_str.encode(\"utf-8\"))\n        return data_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Initialize a hash object\n        hash_obj = hashlib.sha256()\n\n        # Encode the function name and the arguments and keyword arguments into a byte string\n        data = (func_name, args, kwargs).encode()\n\n        # Update the hash object with the data\n        hash_obj.update(data)\n\n        # Return the hexadecimal digest of the hash object\n        return hash_obj.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name,) + args\n        for key in sorted(kwargs.keys()):\n            data += (key, kwargs[key])\n\n        return hashlib.sha256(json.dumps(data).encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_data = (func_name,) + args + tuple(kwargs.items())\n        return hashlib.sha256(json.dumps(hash_data).encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        return hashlib.sha256(json.dumps(data).encode()).hexdigest()\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    polygon_length = 0\n    for i in range(len(polygon) - 1):\n        point_distance = np.linalg.norm(polygon[i] - polygon[i + 1])\n        if point_distance <= max_point_distance:\n            polygon_length += point_distance\n    return polygon_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the polygon is a 2-dimensional numpy array\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2:\n        raise ValueError(\"The polygon must be a 2-dimensional numpy array.\")\n\n    # Check if the polygon has at least 3 points\n    if polygon.shape[0] < 3:\n        raise ValueError(\"The polygon must have at least 3 points.\")\n\n    # Initialize the total length of the polygon\n    total_length = 0\n\n    # Iterate over the consecutive points in the polygon\n    for i in range(1, len(polygon)):\n        # Calculate the distance between the current point and the previous point\n        distance = np.linalg.norm(polygon[i] - polygon[i - 1])\n\n        # Check if the distance is below the specified maximum distance\n        if distance < max_point_distance:\n            # Add the distance to the total length\n            total_length += distance\n\n    # Return the total length of the polygon\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the input array has the correct shape\n    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to compute the length of a polygon with shape {polygon.shape}. Expecting a 2D array of shape (N, 2).\")\n\n    # Calculate the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Calculate the total length of the polygon, excluding distances that exceed the specified maximum\n    total_length = np.sum(distances[distances <= max_point_distance])\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Calculate the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances < max_point_distance]\n\n    # Sum the filtered distances to get the total length\n    total_length = np.sum(filtered_distances)\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the polygon is empty\n    if len(polygon) == 0:\n        return 0.0\n\n    # Initialize the total length\n    total_length = 0.0\n\n    # Iterate over the consecutive points in the polygon\n    for i in range(len(polygon) - 1):\n        # Calculate the distance between the current point and the next point\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n\n        # If the distance is less than the maximum point distance, add it to the total length\n        if distance <= max_point_distance:\n            total_length += distance\n\n    # Return the total length of the polygon\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the input is a 2D numpy array\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    # Check if the input has at least 3 points\n    if polygon.shape[0] < 3:\n        raise ValueError(\"Input must have at least 3 points.\")\n\n    # Check if the input has 2 columns\n    if polygon.shape[1] != 2:\n        raise ValueError(\"Input must have 2 columns.\")\n\n    # Check if the input is a valid polygon\n    if not is_valid_polygon(polygon):\n        raise ValueError(\"Input is not a valid polygon.\")\n\n    # Check if the max_point_distance is a positive integer\n    if not isinstance(max_point_distance, int) or max_point_distance <= 0:\n        raise ValueError(\"max_point_distance must be a positive integer.\")\n\n    # Calculate the length of each edge\n    edge_lengths = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Find the indices of the edges that are longer than the maximum distance\n    long_edge_indices = np.where(edge_lengths > max_point_distance)[0]\n\n    # Split the polygon into segments based on the long edges\n    segments = np.split(polygon, long_edge_indices + 1)\n\n    # Calculate the length of each segment\n    segment_lengths = [\n        np.sum(np.linalg.norm(segment[1:] - segment[:-1], axis=1)) for segment in segments\n    ]\n\n    # Calculate the total length of the polygon\n    total_length = np.sum(segment_lengths)\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the input polygon is a 2D numpy array\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2:\n        raise ValueError(\"The input polygon must be a 2D numpy array.\")\n\n    # Check if the input polygon has at least 3 points\n    if polygon.shape[0] < 3:\n        raise ValueError(\"The input polygon must have at least 3 points.\")\n\n    # Initialize the total length of the polygon\n    total_length = 0.0\n\n    # Iterate over the points in the polygon\n    for i in range(1, polygon.shape[0]):\n        # Calculate the distance between the current and previous points\n        distance = np.linalg.norm(polygon[i] - polygon[i - 1])\n\n        # If the distance is below the maximum distance, add it to the total length\n        if distance <= max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to compute the length of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    if len(polygon) < 2:\n        raise ValueError(f\"Unable to compute the length of a polygon with {len(polygon)} points. Expecting at least 2 points.\")\n\n    # Compute the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Identify points that are too far apart\n    too_far = distances > max_point_distance\n\n    # Set the distances between too-far points to zero\n    distances[too_far] = 0\n\n    # Compute the total length by summing the distances between consecutive points\n    total_length = np.sum(distances)\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Calculate the distance between consecutive points in the polygon\n    point_distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Find the indices of points that are further apart than the maximum distance\n    disjoint_point_indices = np.where(point_distances > max_point_distance)[0]\n\n    # Split the polygon into separate arcs based on the disjoint points\n    arcs = np.split(polygon, disjoint_point_indices + 1)\n\n    # Calculate the length of each arc\n    arc_lengths = [np.sum(np.linalg.norm(arc[1:] - arc[:-1], axis=1)) for arc in arcs]\n\n    # Return the sum of the lengths of all arcs\n    return np.sum(arc_lengths)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distance between consecutive points in the polygon\n    distances = np.sqrt(np.sum(np.diff(polygon, axis=0) ** 2, axis=1))\n\n    # Filter out distances that exceed the maximum point distance\n    distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between consecutive points in the polygon\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Identify the indices of points that are too far apart\n    too_far_indices = np.where(distances > max_point_distance)[0]\n\n    # Add the distances between consecutive points that are within the maximum distance\n    total_length = np.sum(distances[distances <= max_point_distance])\n\n    # Add the distance between the last point and the first point if they are within the maximum distance\n    if distances[0] <= max_point_distance:\n        total_length += distances[0]\n\n    # Add the distance between consecutive points that are too far apart\n    for i in range(len(too_far_indices) - 1):\n        total_length += distances[too_far_indices[i] + 1 : too_far_indices[i + 1]]\n\n    # Add the distance between the last point and the first point if they are too far apart\n    if len(too_far_indices) > 0 and too_far_indices[-1] != len(distances) - 1:\n        total_length += distances[-1]\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length of the polygon\n    total_length = 0.0\n\n    # Iterate over the rows of the polygon\n    for i in range(len(polygon) - 1):\n        # Calculate the distance between the current point and the next point\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n\n        # If the distance is less than the specified maximum distance, add it to the total length\n        if distance <= max_point_distance:\n            total_length += distance\n\n    # Return the total length of the polygon\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the input is a 2D numpy array\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2:\n        raise ValueError(\"The input 'polygon' must be a 2D numpy array.\")\n\n    # Check if the input has at least 2 points\n    if polygon.shape[0] < 2:\n        raise ValueError(\"The input 'polygon' must have at least 2 points.\")\n\n    # Check if the input has 2 columns (x and y coordinates)\n    if polygon.shape[1] != 2:\n        raise ValueError(\"The input 'polygon' must have 2 columns (x and y coordinates).\")\n\n    # Check if the input has a valid max_point_distance\n    if max_point_distance <= 0:\n        raise ValueError(\"The input 'max_point_distance' must be a positive integer.\")\n\n    # Calculate the total length of the polygon\n    total_length = 0\n    for i in range(len(polygon) - 1):\n        point_1 = polygon[i]\n        point_2 = polygon[i + 1]\n        distance = np.linalg.norm(point_2 - point_1)\n        if distance <= max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the polygon has at least 3 points\n    if len(polygon) < 3:\n        raise ValueError(\"The polygon must have at least 3 points.\")\n\n    # Calculate the distance between consecutive points\n    distances = np.sqrt(np.sum(np.diff(polygon, axis=0) ** 2, axis=1))\n\n    # Find the indices of the points that are further apart than the maximum distance\n    large_distances = np.where(distances > max_point_distance)[0]\n\n    # If there are no points that are further apart than the maximum distance, return the sum of all distances\n    if len(large_distances) == 0:\n        return np.sum(distances)\n\n    # If there are points that are further apart than the maximum distance, split the polygon into multiple arcs\n    # and calculate the length of each arc separately\n    total_length = 0\n    for i in range(len(large_distances) + 1):\n        # Get the indices of the points in the current arc\n        if i == 0:\n            start_index = 0\n        else:\n            start_index = large_distances[i - 1] + 1\n        if i == len(large_distances):\n            end_index = len(polygon) - 1\n        else:\n            end_index = large_distances[i]\n\n        # Calculate the length of the current arc\n        arc_length = np.sum(distances[start_index:end_index])\n\n        # Add the length of the current arc to the total length\n        total_length += arc_length\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the polygon is valid\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2 or polygon.shape[1] != 2:\n        raise ValueError(\"Invalid polygon: expected a 2D numpy array with shape (N, 2)\")\n\n    # Calculate the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Identify points that are too far apart\n    too_far = distances > max_point_distance\n\n    # Replace the distances between consecutive points that are too far apart with zero\n    distances[too_far] = 0\n\n    # Calculate the total length of the polygon\n    polygon_length = np.sum(distances)\n\n    return polygon_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length of the polygon\n    total_length = 0.0\n\n    # Iterate over the rows of the polygon array\n    for i in range(len(polygon)):\n        # Get the current point and the next point\n        current_point = polygon[i]\n        next_point = polygon[(i + 1) % len(polygon)]\n\n        # Compute the distance between the current point and the next point\n        distance = np.linalg.norm(current_point - next_point)\n\n        # Check if the distance is below the maximum point distance\n        if distance <= max_point_distance:\n            # Add the distance to the total length\n            total_length += distance\n\n    # Return the total length of the polygon\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Calculate the distance between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Identify indices where the distance exceeds the maximum point distance\n    exceeding_indices = np.where(distances > max_point_distance)[0]\n\n    # Insert a -1 at each exceeding index to mark the separation between arcs\n    distances = np.insert(distances, exceeding_indices, -1)\n\n    # Remove the -1s and sum the remaining distances to get the total length\n    total_length = np.sum(distances[distances >= 0])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check if the input is a 2D array\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    # Check if the input is a 2D array\n    if polygon.shape[1] != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    # Initialize the total length to zero\n    total_length = 0.0\n\n    # Iterate over the rows of the input array\n    for i in range(1, len(polygon)):\n        # Calculate the distance between consecutive points\n        distance = np.linalg.norm(polygon[i] - polygon[i - 1])\n\n        # If the distance is below the maximum distance, add it to the total length\n        if distance <= max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distance between consecutive points\n    distances = np.sqrt(np.sum(np.diff(polygon, axis=0) ** 2, axis=1))\n\n    # Identify disjoint arcs by finding distances exceeding the maximum point distance\n    disjoint_arcs = np.where(distances > max_point_distance)[0]\n\n    # Initialize the total length\n    total_length = 0.0\n\n    # Loop over the disjoint arcs\n    for i in range(len(disjoint_arcs) + 1):\n        # Identify the start and end indices for the current arc\n        start_idx = 0 if i == 0 else disjoint_arcs[i - 1] + 1\n        end_idx = len(distances) if i == len(disjoint_arcs) else disjoint_arcs[i]\n\n        # Sum the distances between consecutive points within the current arc\n        total_length += np.sum(distances[start_idx:end_idx])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if polygon.shape[1] != 2:\n        raise ValueError(\"The input polygon must be a 2-dimensional array.\")\n\n    # Compute the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Identify the indices of points that are farther apart than the maximum distance\n    far_points = np.where(distances > max_point_distance)[0]\n\n    # If there are no far points, return the total length of the polygon\n    if len(far_points) == 0:\n        return np.sum(distances)\n\n    # Otherwise, compute the total length by summing the distances between consecutive points that are within the maximum distance\n    total_length = 0\n    for i in range(len(far_points) + 1):\n        start_index = far_points[i - 1] + 1 if i > 0 else 0\n        end_index = far_points[i] if i < len(far_points) else len(distances)\n        total_length += np.sum(distances[start_index:end_index])\n\n    return total_length"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_tr = max_area * rel_tr\n    polygons = [polygon for polygon in polygons if area(polygon) > max(abs_tr, rel_tr)]\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    areas = [area(p) for p in polygons]\n    max_area = max(areas)\n    rel_tr = max_area * rel_tr\n    polygons = [p for p in polygons if area(p) >= rel_tr and area(p) >= abs_tr]\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    max_area = max([area(p) for p in polygons])\n    rel_tr = max_area * rel_tr\n    return [p for p in polygons if area(p) > max(rel_tr, abs_tr)]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the area of the largest polygon\n    largest_area = max(area(polygon) for polygon in polygons)\n\n    # Filter out polygons whose area is below either an absolute threshold or a relative threshold\n    filtered_polygons = [\n        polygon\n        for polygon in polygons\n        if area(polygon) > abs_tr and area(polygon) > rel_tr * largest_area\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = np.array([area(p) for p in polygons])\n    max_area = areas.max()\n    mask = np.logical_and(areas > abs_tr, areas > rel_tr * max_area)\n    return [p for p, m in zip(polygons, mask) if m]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    max_area = max(area(polygon) for polygon in polygons)\n    rel_tr = max_area * rel_tr\n\n    polygons = [polygon for polygon in polygons if area(polygon) > max(rel_tr, abs_tr)]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    max_area = max([area(polygon) for polygon in polygons])\n    rel_tr = max_area * rel_tr\n\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) >= rel_tr or area(polygon) >= abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    max_area = max([area(polygon) for polygon in polygons])\n\n    return [\n        polygon\n        for polygon in polygons\n        if area(polygon) >= max(abs_tr, rel_tr * max_area)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    if abs_tr > 0:\n        polygons = [polygon for polygon, area in zip(polygons, areas) if area >= abs_tr]\n    else:\n        polygons = [polygon for polygon, area in zip(polygons, areas) if area >= rel_tr * max_area]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    max_area = area(polygons[np.argmax([area(polygon) for polygon in polygons])])\n\n    return [polygon for polygon in polygons if area(polygon) >= max_area * rel_tr + abs_tr]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_tr_area = max_area * rel_tr\n    abs_tr_area = abs_tr\n    filtered_polygons = [\n        polygon for polygon in polygons if area(polygon) >= rel_tr_area or area(polygon) >= abs_tr_area\n    ]\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_tr = max_area * rel_tr\n    polygons = [polygon for polygon, area in zip(polygons, areas) if area > max(rel_tr, abs_tr)]\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_tr = max_area * rel_tr\n    return [polygon for polygon, area in zip(polygons, areas) if area > max(rel_tr, abs_tr)]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(p) for p in polygons]\n    max_area = max(areas)\n\n    rel_tr = max_area * rel_tr\n\n    polygons = [p for p in polygons if area(p) > rel_tr or area(p) > abs_tr]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    return [\n        polygon\n        for polygon, area_ in zip(polygons, areas)\n        if area_ > abs_tr and area_ > max_area * rel_tr\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # get the largest polygon area\n    largest_area = max([area(polygon) for polygon in polygons])\n    # filter out polygons based on their area\n    filtered_polygons = [\n        polygon for polygon in polygons if area(polygon) >= rel_tr * largest_area or area(polygon) >= abs_tr\n    ]\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_tr *= max_area\n    polygons = [polygon for polygon, area in zip(polygons, areas) if area > rel_tr and area > abs_tr]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    max_area = max([area(poly) for poly in polygons])\n    rel_tr = max_area * rel_tr\n    polygons = [poly for poly in polygons if area(poly) > max(rel_tr, abs_tr)]\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Find the largest polygon's area\n    largest_area = max([area(polygon) for polygon in polygons])\n\n    # Filter out polygons whose area is below the absolute threshold\n    filtered_polygons = [polygon for polygon in polygons if area(polygon) >= abs_tr]\n\n    # Filter out polygons whose area is below the relative threshold\n    filtered_polygons = [\n        polygon for polygon in filtered_polygons if area(polygon) >= largest_area * rel_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n    max_area = max([area(p) for p in polygons])\n    return [p for p in polygons if area(p) >= max(abs_tr, max_area * rel_tr)]\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker has processed\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of remaining samples\n    num_remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of remaining batches\n    num_remaining_batches = num_remaining_samples // batch_size\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_batches_per_worker * batch_size\n\n    # Calculate the number of remaining samples\n    num_remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of remaining batches\n    num_remaining_batches = num_remaining_samples // batch_size\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_batches_per_worker * batch_size\n\n    # Calculate the number of remaining samples\n    num_remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of remaining batches\n    num_remaining_batches = num_remaining_samples // batch_size\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_batches_per_worker * batch_size\n\n    # Calculate the number of remaining samples\n    num_remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of remaining batches\n    num_remaining_batches = num_remaining_samples // batch_size\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_batches_per_worker * batch_size\n\n    # Calculate the number of remaining samples\n    num_remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of remaining batches\n    num_remaining_batches = num_remaining_samples // batch_size\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_batches_per_worker * batch_size\n\n    # Calculate the number of remaining samples\n    num_remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of remaining batches\n    num_remaining_batches"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_samples_yielded / num_workers)\n\n    # calculate the number of batches each worker has processed\n    num_batches_per_worker = int(num_samples_per_worker / batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples remaining to be distributed\n    num_samples_remaining = num_samples_yielded - (num_samples_per_worker * num_workers)\n\n    # calculate the number of batches remaining to be distributed\n    num_batches_remaining = int(num_samples_remaining / batch_size)\n\n    # calculate the number of workers remaining to be distributed\n    num_workers_remaining = num_workers - (num_batches_remaining % num_workers)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_per_worker * batch_size)\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = int(num_batches_"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size = num_samples_per_worker * batch_size\n\n    # calculate the number of batches each worker has processed\n    num_batches_per_worker = num_samples_per_worker_with_batch_size // batch_size\n\n    # calculate the number of batches each worker has processed\n    num_batches_per_worker_with_batch_size = num_batches_per_worker * batch_size\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size = num_samples_per_worker * batch_size\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size_and_num_workers = num_samples_per_worker_with_batch_size // num_workers\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size_and_num_workers_with_batch_size = (\n        num_samples_per_worker_with_batch_size_and_num_workers * batch_size\n    )\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size_and_num_workers_with_batch_size_and_num_samples_yielded = (\n        num_samples_per_worker_with_batch_size_and_num_workers_with_batch_size * num_samples_yielded\n    )\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size_and_num_workers_with_batch_size_and_num_samples_yielded_with_batch_size = (\n        num_samples_per_worker_with_batch_size_and_num_workers_with_batch_size_and_num_samples_yielded * batch_size\n    )\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker_with_batch_size_"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = num_samples_yielded // (num_workers * batch_size) * batch_size\n        num_samples_yielded -= indexes[worker_idx]\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed, given the total number of samples yielded, the batch size, and the number of workers.\n    num_samples_each_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_batches_each_worker = num_samples_each_worker // batch_size\n\n    # Calculate the number of remaining samples, given the total number of samples yielded and the number of samples each worker has processed.\n    num_remaining_samples = num_samples_yielded % num_samples_each_worker\n\n    # Calculate the number of remaining batches, given the total number of batches yielded and the number of batches each worker has processed.\n    num_remaining_batches = num_remaining_samples // batch_size\n\n    # Calculate the number of remaining samples for each worker, given the total number of remaining samples and the number of workers.\n    num_remaining_samples_each_worker = num_remaining_samples // num_workers\n\n    # Calculate the number of remaining batches for each worker, given the total number of remaining batches and the number of workers.\n    num_remaining_batches_each_worker = num_remaining_batches // num_workers\n\n    # Calculate the number of remaining samples for each worker, given the total number of remaining samples and the number of workers.\n    num_remaining_samples_each_worker = num_remaining_samples // num_workers\n\n    # Calculate the number of remaining batches for each worker, given the total number of remaining batches and the number of workers.\n    num_remaining_batches_each_worker = num_remaining_batches // num_workers\n\n    # Calculate the number of samples each worker has processed, given the total number of samples yielded, the batch size, and the number of workers.\n    num_samples_each_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_batches_each_worker = num_samples_each_worker // batch_size\n\n    # Calculate the number of samples each worker has processed, given the total number of samples yielded, the batch size, and the"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_yielded = min(num_samples_yielded, num_workers * batch_size)\n    num_samples_yielded_per_worker = num_samples_yielded // num_workers\n    num_samples_yielded_per_worker_remaining = num_samples_yielded % num_workers\n    indexes = {}\n    for i in range(num_workers):\n        indexes[i] = num_samples_yielded_per_worker * i + min(i, num_samples_yielded_per_worker_remaining)\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for i in range(num_workers):\n        indexes[i] = 0\n\n    for i in range(num_samples_yielded):\n        indexes[i % num_workers] += batch_size\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for worker_rank in range(num_workers):\n        indexes[worker_rank] = num_samples_yielded % batch_size\n        num_samples_yielded += batch_size\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for i in range(num_workers):\n        indexes[i] = 0\n\n    # replay sampling from each worker / chunks using the batch size\n    for i in range(num_samples_yielded):\n        worker_index = i % num_workers\n        indexes[worker_index] += batch_size\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_with_remainder = num_samples_per_worker * num_workers\n    num_samples_per_worker_with_remainder_and_batch_size = num_samples_per_worker_with_remainder * batch_size\n    num_samples_per_worker_with_remainder_and_batch_size_and_num_workers = (\n        num_samples_per_worker_with_remainder_and_batch_size // num_workers\n    )\n\n    indexes = {}\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = (\n            num_samples_per_worker_with_remainder_and_batch_size_and_num_workers * worker_idx\n        ) // batch_size\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Handle restart\n    if num_samples_yielded == 0:\n        return {i: 0 for i in range(num_workers)}\n\n    # Calculate the number of samples each worker has processed.\n    num_samples_per_worker = int(num_samples_yielded / num_workers)\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n    num_batches_per_worker = int(num_samples_per_worker / batch_size)\n    num_batches_per_worker_remainder = num_samples_per_worker_remainder // batch_size\n\n    indexes = {}\n    for i in range(num_workers):\n        if i < num_samples_per_worker_remainder:\n            indexes[i] = num_samples_per_worker * i + num_batches_per_worker * i + num_batches_per_worker_remainder\n        else:\n            indexes[i] = num_samples_per_worker * i + num_batches_per_worker * i\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n\n    for worker_rank in range(num_workers):\n        indexes[worker_rank] = num_samples_yielded % batch_size\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_yielded_per_worker = num_samples_yielded // num_workers\n    num_samples_yielded_remaining = num_samples_yielded % num_workers\n\n    indexes = {}\n\n    for worker_idx in range(num_workers):\n        if worker_idx < num_samples_yielded_remaining:\n            indexes[worker_idx] = num_samples_yielded_per_worker + 1\n        else:\n            indexes[worker_idx] = num_samples_yielded_per_worker\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n\n    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = num_samples_yielded\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    indexes = []\n    for i in range(num_workers):\n        indexes.append(num_samples_yielded // num_workers + (i < (num_samples_yielded % num_workers)))\n\n    # Replay the sampling.\n    indexes = np.array(indexes)\n    indexes = indexes // batch_size * batch_size\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n\n    # calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_with_remainder = num_samples_yielded % num_workers\n\n    # distribute any remaining samples\n    for i in range(num_workers):\n        indexes[i] = num_samples_per_worker * batch_size + (\n            num_samples_per_worker_with_remainder if i < num_samples_per_worker_with_remainder else 0\n        )\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for worker_rank in range(num_workers):\n        indexes[worker_rank] = num_samples_yielded // num_workers + (num_samples_yielded % num_workers > worker_rank)\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = []\n\n    for i in range(num_samples_yielded):\n        worker_idx = i % num_workers\n        indexes[worker_idx].append(i)\n\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = np.array(indexes[worker_idx])\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Handle restart\n    if num_samples_yielded == 0:\n        return {worker_idx: 0 for worker_idx in range(num_workers)}\n\n    indexes = []\n    for i in range(num_samples_yielded):\n        indexes.append(i)\n\n    indexes = np.array(indexes)\n\n    # Divide the total samples by the number of workers and the batch size\n    indexes = indexes // num_workers // batch_size\n\n    # Distribute any remaining samples\n    indexes = indexes * num_workers * batch_size\n\n    # Calculate the number of samples each worker has processed\n    indexes = indexes // num_workers\n\n    # Re-shuffle the indexes\n    indexes = np.random.permutation(indexes)\n\n    return {worker_idx: indexes[worker_idx] for worker_idx in range(num_workers)}\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    indexes = {}\n    for worker_idx in range(num_workers):\n        indexes[worker_idx] = num_samples_yielded // num_workers\n        if worker_idx < num_samples_yielded % num_workers:\n            indexes[worker_idx] += batch_size\n\n    return indexes\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n\n    for i, (result, metadata) in enumerate(zip(results, metadatas)):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If no metadatas are provided, create a list of None values the same length as the results list.\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    # Create empty lists to store the filtered results and metadatas.\n    filtered_results = []\n    filtered_metadatas = []\n\n    # Iterate over the results and metadatas lists, filtering based on the threshold.\n    for result, metadata, val in zip(results, metadatas, value):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    # Return the filtered results and metadatas as a tuple.\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # Initialize empty lists to store the filtered results and metadata\n    filtered_results = []\n    filtered_metadatas = []\n\n    # Iterate over the results and values\n    for i, (result, val) in enumerate(zip(results, value)):\n        # Check if the value is less than or equal to the threshold\n        if val <= threshold:\n            # Append the result and metadata to the filtered lists\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i] if metadatas else None)\n\n    # Return the filtered results and metadata\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    filtered_results = []\n    filtered_metadatas = []\n    for result, metadata, val in zip(results, metadatas, value):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    return [\n        result for result, val in zip(results, value) if val <= threshold\n    ], [\n        metadata for metadata, val in zip(metadatas, value) if val <= threshold\n    ]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, metadata, val in zip(results, metadatas, value):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    filtered_results = []\n    filtered_metadatas = []\n    for result, metadata, val in zip(results, metadatas, value):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadata = []\n\n    for index, result in enumerate(results):\n        if value[index] <= threshold:\n            filtered_results.append(result)\n            if metadatas:\n                filtered_metadata.append(metadatas[index])\n\n    return filtered_results, filtered_metadata\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if len(results) != len(value):\n        raise ValueError(\"The length of results and value must be the same.\")\n\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(metadatas):\n        raise ValueError(\"The length of results and metadatas must be the same.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas)\n\n    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # Check if the input lists have the same length\n    if len(results) != len(value):\n        raise ValueError(\"The length of the results and value lists must be the same.\")\n\n    # Initialize the filtered results and metadata lists\n    filtered_results = []\n    filtered_metadatas = []\n\n    # Iterate over the results and values\n    for i, (result, val) in enumerate(zip(results, value)):\n        # Check if the value is less than or equal to the threshold\n        if val <= threshold:\n            # Append the result and metadata to the filtered lists\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n\n    # Return the filtered results and metadata lists\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadata = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadata.append(metadatas[i])\n\n    return filtered_results, filtered_metadata\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not array.shape[1] == 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ can be any number of points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ can be any number of points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must be of shape (_, 2).\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n    area = abs(area) / 2.0\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not array.shape[1] == 2:\n        raise ValueError(\"Input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2).\")\n\n    return 0.5 * abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x, y = array.T\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ is the number of points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\n            \"The input array must have the shape (_, 2), where _ can be any number of points.\"\n        )\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not array.shape[1] == 2:\n        raise ValueError(\"Input array must be of shape (_, 2)\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input has the expected shape\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array does not have the expected shape. Expected shape: (_, 2), got shape: {}\".format(array.shape))\n\n    # Calculate the area using the Shoelace formula\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\n            \"The input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\"\n        )\n\n    x_coords = array[:, 0]\n    y_coords = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x_coords, np.roll(y_coords, 1)) - np.dot(y_coords, np.roll(x_coords, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise TypeError('Input must be a numpy array')\n    if not array.shape[1] == 2:\n        raise ValueError('Input must be a numpy array with shape (_, 2)')\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the correct shape\n    if not array.shape[1] == 2:\n        raise ValueError(\"Input array does not have the expected shape.\")\n\n    # Calculate the area using the Shoelace formula\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the correct shape\n    if array.shape[1] != 2:\n        raise ValueError(\n            \"The input array does not have the correct shape. It should have the shape (_, 2), where _ is the number of points in the polygon.\"\n        )\n\n    # Calculate the area using the Shoelace formula\n    return 0.5 * abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError('The input array must have the shape (_, 2), where _ can be any number of points.')\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not array.shape[1] == 2:\n        raise ValueError(\"Invalid input array. Expected shape: (_, 2)\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not array.shape[1] == 2:\n        raise ValueError(f\"The input array must have shape (_, 2), not {array.shape}.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the array has the correct shape\n    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2) to represent a valid list of polygon points.\")\n\n    # Calculate the area using the Shoelace formula\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not array.shape[1] == 2:\n        raise ValueError(f\"Input array must have shape (_, 2), got {array.shape}\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape\n    if array.shape[1] != 2:\n        raise ValueError(\n            \"The input array must have the shape (_, 2), where _ can be any number of points.\"\n        )\n\n    # Calculate the area using the Shoelace formula\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get the shape of the input tensors\n    shape_a = a.shape\n    shape_v = v.shape\n\n    # Reshape the input tensors to 2D\n    a = a.reshape(-1)\n    v = v.reshape(-1, shape_v[-1])\n\n    # Initialize the output tensors\n    idx_lo = torch.zeros(v.shape[0], dtype=torch.long)\n    idx_hi = torch.zeros(v.shape[0], dtype=torch.long)\n\n    # Find the indices where elements of v should be inserted into a\n    for i in range(v.shape[0]):\n        idx_lo[i] = torch.searchsorted(a, v[i], side='left')\n        idx_hi[i] = torch.searchsorted(a, v[i], side='right')\n\n    # Reshape the output tensors to match the input tensors\n    idx_lo = idx_lo.reshape(shape_v[:-1])\n    idx_hi = idx_hi.reshape(shape_v[:-1])\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Expand the dimensions of a and v to make them broadcastable\n    a_expanded = a.unsqueeze(-1)\n    v_expanded = v.unsqueeze(-2)\n\n    # Find the indices where elements of v are greater than or equal to the elements of a\n    idx_ge = (v_expanded >= a_expanded).sum(dim=-2)\n\n    # Find the indices where elements of v are less than the elements of a\n    idx_lt = (v_expanded < a_expanded).sum(dim=-2)\n\n    # Combine the indices to get the lower and upper bounds\n    idx_lo = torch.minimum(idx_ge, idx_lt)\n    idx_hi = torch.maximum(idx_ge, idx_lt)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Calculate the shape of the input tensors\n    a_shape = a.shape\n    v_shape = v.shape\n\n    # Flatten the input tensors\n    a_flat = a.flatten()\n    v_flat = v.flatten()\n\n    # Create a tensor to store the indices\n    idx = torch.zeros(v_flat.shape, dtype=torch.long)\n\n    # Initialize the lower and upper bounds\n    lo = 0\n    hi = a_flat.shape[0] - 1\n\n    # Perform binary search for each element in v_flat\n    for i in range(v_flat.shape[0]):\n        while lo < hi:\n            mid = (lo + hi) // 2\n            if v_flat[i] > a_flat[mid]:\n                lo = mid + 1\n            else:\n                hi = mid\n        idx[i] = lo\n        lo = 0\n        hi = a_flat.shape[0] - 1\n\n    # Reshape the indices to match the shape of v\n    idx = idx.reshape(v_shape)\n\n    # Calculate the lower and upper bounds\n    idx_lo = torch.clamp(idx - 1, min=0)\n    idx_hi = torch.clamp(idx, max=a_shape[-1] - 1)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Compute the cumulative sum of a\n    cumsum_a = torch.cumsum(a, dim=-1)\n\n    # Compute the cumulative sum of v\n    cumsum_v = torch.cumsum(v, dim=-1)\n\n    # Compute the difference between the cumulative sums of a and v\n    diff = cumsum_a[..., None] - cumsum_v[..., :, None]\n\n    # Find the indices where the difference is non-positive\n    idx_lo = torch.sum(diff <= 0, dim=-1) - 1\n\n    # Find the indices where the difference is positive\n    idx_hi = torch.sum(diff >= 0, dim=-1)\n\n    # Clip the indices to the range of a\n    idx_lo = torch.clamp(idx_lo, 0, a.shape[-1] - 1)\n    idx_hi = torch.clamp(idx_hi, 0, a.shape[-1] - 1)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Check the validity of the input tensors\n    if not isinstance(a, torch.Tensor):\n        raise TypeError(\"a must be a torch.Tensor\")\n    if not isinstance(v, torch.Tensor):\n        raise TypeError(\"v must be a torch.Tensor\")\n    if a.ndim != 1:\n        raise ValueError(\"a must be a 1D tensor\")\n    if v.ndim < 1:\n        raise ValueError(\"v must be at least a 1D tensor\")\n    if a.shape[-1] != v.shape[-1]:\n        raise ValueError(\"a and v must have the same number of elements in the last dimension\")\n\n    # Create a tensor of indices for a\n    idx = torch.arange(a.shape[-1], device=a.device)\n\n    # Create a tensor of indices for v\n    idx_v = torch.arange(v.shape[-1], device=v.device)\n\n    # Find the indices where each element of v should be inserted into a\n    idx_lo = torch.searchsorted(a, v, side=\"left\", out=idx_v)\n    idx_hi = torch.searchsorted(a, v, side=\"right\", out=idx_v)\n\n    # Check if any element of v is out of the range of a\n    idx_lo_out_of_range = torch.logical_or(idx_lo < 0, idx_lo >= a.shape[-1])\n    idx_hi_out_of_range = torch.logical_or(idx_hi < 0, idx_hi >= a.shape[-1])\n\n    # If an element of v is out of the range of a, set both idx_lo and idx_hi to the first or last index of a\n    idx_lo[idx_lo_out_of_range] = 0\n    idx_hi[idx_hi_out_of_range] = a.shape[-1] - 1\n\n    # Create a tensor of indices for a\n    idx = torch.arange(a.shape[-1], device=a.device)\n\n    # Reshape the indices to match the shape of v\n    idx_lo = idx_lo.reshape(v.shape[:-1])\n    idx_hi = idx_hi.reshape(v.shape[:-1])\n\n    # Return the indices\n    return idx_lo, idx"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Expand the dimensions of v to match the dimensions of a\n    v = v.unsqueeze(-1)\n\n    # Find the indices where v is greater than or equal to the elements in a\n    idx_ge = (v >= a).nonzero()\n\n    # Find the indices where v is less than the elements in a\n    idx_lt = (v < a).nonzero()\n\n    # Find the indices where v is equal to the elements in a\n    idx_eq = (v == a).nonzero()\n\n    # Initialize idx_lo and idx_hi with the first and last indices of a\n    idx_lo = torch.zeros_like(idx_ge[..., 0])\n    idx_hi = torch.ones_like(idx_ge[..., 0]) * (a.shape[-1] - 1)\n\n    # Set the indices where v is greater than or equal to the elements in a\n    idx_lo[idx_ge[..., 0], idx_ge[..., 1]] = idx_ge[..., -1]\n\n    # Set the indices where v is less than the elements in a\n    idx_hi[idx_lt[..., 0], idx_lt[..., 1]] = idx_lt[..., -1] - 1\n\n    # Set the indices where v is equal to the elements in a\n    idx_lo[idx_eq[..., 0], idx_eq[..., 1]] = idx_eq[..., -1]\n    idx_hi[idx_eq[..., 0], idx_eq[..., 1]] = idx_eq[..., -1]\n\n    # Return the indices\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get the shape of the input tensors\n    a_shape = a.shape\n    v_shape = v.shape\n\n    # Reshape the tensors to 2D\n    a_2d = a.view(-1, a_shape[-1])\n    v_2d = v.view(-1, v_shape[-1])\n\n    # Initialize the output tensors\n    idx_lo = torch.zeros_like(v_2d)\n    idx_hi = torch.zeros_like(v_2d)\n\n    # Loop over the first dimension of the tensors\n    for i in range(v_2d.shape[0]):\n        # Find the lower and upper bounds for the current element\n        idx_lo[i] = torch.searchsorted(a_2d, v_2d[i], side='left')\n        idx_hi[i] = torch.searchsorted(a_2d, v_2d[i], side='right')\n\n    # Reshape the output tensors to the original shapes\n    idx_lo = idx_lo.view(v_shape[:-1] + (1,))\n    idx_hi = idx_hi.view(v_shape[:-1] + (1,))\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    a_shape = a.shape\n    v_shape = v.shape\n    a = a.flatten()\n    v = v.flatten()\n    n = a.shape[0]\n    m = v.shape[0]\n    idx_lo = torch.zeros(m, dtype=torch.int64, device=a.device)\n    idx_hi = torch.zeros(m, dtype=torch.int64, device=a.device)\n    idx_lo[0] = 0\n    idx_hi[0] = n - 1\n    for i in range(1, m):\n        idx_lo[i] = idx_hi[i - 1]\n        idx_hi[i] = n - 1\n    for i in range(m):\n        while idx_hi[i] - idx_lo[i] > 1:\n            mid = (idx_hi[i] + idx_lo[i]) // 2\n            if v[i] <= a[mid]:\n                idx_hi[i] = mid\n            else:\n                idx_lo[i] = mid\n    idx_lo = idx_lo.reshape(v_shape)\n    idx_hi = idx_hi.reshape(v_shape)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # First, we need to find the indices where the elements of v are greater than or equal to the elements of a.\n    # This is done by performing a binary search on a using the torch.searchsorted() function.\n    idx_lo = torch.searchsorted(a, v, side='left')\n\n    # Next, we need to find the indices where the elements of v are less than or equal to the elements of a.\n    # This is done by performing a binary search on a using the torch.searchsorted() function with the side='right' argument.\n    idx_hi = torch.searchsorted(a, v, side='right')\n\n    # Finally, we need to handle the cases where the elements of v are out of the range of a.\n    # If an element of v is less than the minimum element of a, both idx_lo and idx_hi will point to the first index of a.\n    # If an element of v is greater than the maximum element of a, both idx_lo and idx_hi will point to the last index of a.\n    # We can accomplish this by using the torch.clamp() function to ensure that idx_lo and idx_hi are within the valid range of indices.\n    idx_lo = torch.clamp(idx_lo, 0, a.shape[-1] - 1)\n    idx_hi = torch.clamp(idx_hi, 0, a.shape[-1] - 1)\n\n    # Return the indices where the elements of v should be inserted into a to maintain order.\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Prepare input tensors\n    a = a.clone().detach().requires_grad_(False).to(v.device)\n    v = v.clone().detach().requires_grad_(False).to(v.device)\n    a_shape = a.shape\n    v_shape = v.shape\n    a = a.reshape(-1)\n    v = v.reshape(-1)\n\n    # Initialize output tensors\n    idx_lo = torch.zeros_like(v)\n    idx_hi = torch.zeros_like(v)\n\n    # Find the indices where elements of v should be inserted into a\n    for i in range(v.shape[0]):\n        if v[i] <= a[0]:\n            idx_lo[i] = 0\n            idx_hi[i] = 0\n        elif v[i] >= a[-1]:\n            idx_lo[i] = a.shape[0] - 1\n            idx_hi[i] = a.shape[0] - 1\n        else:\n            # Perform binary search to find the insertion point\n            lo = 0\n            hi = a.shape[0] - 1\n            while lo < hi:\n                mid = (lo + hi) // 2\n                if v[i] <= a[mid]:\n                    hi = mid\n                else:\n                    lo = mid + 1\n            idx_lo[i] = lo\n            idx_hi[i] = lo\n\n    # Reshape the output tensors to match the input shapes\n    idx_lo = idx_lo.reshape(v_shape)\n    idx_hi = idx_hi.reshape(v_shape)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the indices where v should be inserted into a\n    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n\n    # Adjust the indices if v is out of the range of a\n    idx_lo = torch.where(v < a[0], torch.zeros_like(idx_lo), idx_lo)\n    idx_lo = torch.where(v > a[-1], torch.full_like(idx_lo, a.size(-1)), idx_lo)\n    idx_hi = torch.where(v < a[0], torch.zeros_like(idx_hi), idx_hi)\n    idx_hi = torch.where(v > a[-1], torch.full_like(idx_hi, a.size(-1)), idx_hi)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if a.ndim == v.ndim - 1:\n        v = v[None]\n    if v.shape[-1] != a.shape[-1]:\n        v = torch.cat([v, torch.ones_like(v[..., -1:])], dim=-1)  # 65\n    a = torch.cat([a, a.new_ones(a.shape[:-1] + (1,))], dim=-1)  # 65\n    idx_lo = torch.sum(torch.le(v[..., None, :], a[..., :-1, :]), dim=-1)\n    idx_hi = torch.sum(torch.le(v[..., None, :], a[..., 1:, :]), dim=-1)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Compute the cumulative sum of the step function\n    # (assuming that the input is sorted)\n    cs = torch.cumsum(torch.ones_like(a), dim=-1)\n    # Find the indices where the query points should be inserted\n    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    # If the query point is out of range, adjust the indices accordingly\n    idx_lo = torch.where(idx_lo > 0, idx_lo - 1, idx_lo)\n    idx_hi = torch.where(idx_hi < cs.shape[-1], idx_hi, idx_hi - 1)\n    # Compute the corresponding cumulative sums\n    cs_lo = cs.gather(dim=-1, index=idx_lo)\n    cs_hi = cs.gather(dim=-1, index=idx_hi)\n    # Return the indices and the corresponding cumulative sums\n    return idx_lo, idx_hi, cs_lo, cs_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Expand the dimensions of a and v to match\n    a = a.unsqueeze(-1)\n    v = v.unsqueeze(-1)\n    # Initialize the lower and upper bounds with the first and last indices of a\n    lo = torch.zeros_like(v)\n    hi = torch.full_like(v, a.shape[-1] - 1)\n    # Loop until the bounds converge\n    while torch.any(hi - lo > 1):\n        # Compute the midpoints between the lower and upper bounds\n        mid = (lo + hi) // 2\n        # Compare the midpoints to the elements of v\n        cond = a.gather(-1, mid) < v\n        # Update the lower and upper bounds based on the comparison\n        lo = torch.where(cond, mid, lo)\n        hi = torch.where(cond, hi, mid)\n    # Return the lower and upper bounds\n    return lo, hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # expand the dimension of a to match that of v\n    a = a.unsqueeze(-1).expand(a.shape[:-1] + v.shape[-1:])\n    # expand the dimension of v to match that of a\n    v = v.unsqueeze(-2).expand(v.shape[:-1] + a.shape[-1:])\n    # find the indices where v is greater than or equal to a\n    idx_lo = (v >= a).sum(dim=-1) - 1\n    # find the indices where v is greater than a\n    idx_hi = (v > a).sum(dim=-1) - 1\n    # clamp the indices to the range of a\n    idx_lo = idx_lo.clamp(min=0, max=a.shape[-1] - 1)\n    idx_hi = idx_hi.clamp(min=0, max=a.shape[-1] - 1)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Get the shape of the tensors\n    a_shape = a.shape\n    v_shape = v.shape\n\n    # Reshape the tensors to 2D\n    a_2d = a.reshape(-1, a_shape[-1])\n    v_2d = v.reshape(-1, v_shape[-1])\n\n    # Create a tensor of indices for the last dimension of a\n    idx = torch.arange(a_shape[-1], device=a.device)\n\n    # Find the indices where elements of v should be inserted into a\n    idx_lo = torch.searchsorted(a_2d, v_2d, side='left')\n    idx_hi = torch.searchsorted(a_2d, v_2d, side='right')\n\n    # Reshape the indices to match the original shapes of v\n    idx_lo = idx_lo.reshape(v_shape[:-1] + idx.shape)\n    idx_hi = idx_hi.reshape(v_shape[:-1] + idx.shape)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Expand the dimensions of v to match that of a\n    v = v.unsqueeze(-1)\n    # Create a tensor of indices for a\n    idx = torch.arange(a.shape[-1]).to(a)\n    # Expand the dimensions of idx to match that of a\n    idx = idx.unsqueeze(-1)\n    # Find the indices where v is greater than or equal to a\n    idx_ge = torch.searchsorted(a, v, side='right')\n    # Find the indices where v is less than a\n    idx_lt = torch.searchsorted(a, v, side='left')\n    # Find the indices where v is equal to a\n    idx_eq = torch.where(v == a.unsqueeze(-1), idx, torch.tensor(-1).to(a))\n    # Find the indices where v is between two elements of a\n    idx_between = torch.where((idx_eq == -1) & (idx_ge == idx_lt), idx_ge - 1, torch.tensor(-1).to(a))\n    # Combine the indices for the three cases\n    idx_lo = torch.where(idx_eq != -1, idx_eq, torch.where(idx_between != -1, idx_between, idx_lt))\n    idx_hi = torch.where(idx_eq != -1, idx_eq, idx_ge)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Expand the dimensions of v to match those of a\n    v = v.expand_as(a)\n\n    # Find the indices where elements of v are greater than or equal to elements of a\n    idx_lo = (v >= a).nonzero()[:, 1]\n\n    # Find the indices where elements of v are greater than elements of a\n    idx_hi = (v > a).nonzero()[:, 1]\n\n    # If there are no indices where elements of v are greater than or equal to elements of a, set idx_lo to the first index of a\n    if idx_lo.nelement() == 0:\n        idx_lo = torch.tensor(0, device=a.device)\n\n    # If there are no indices where elements of v are greater than elements of a, set idx_hi to the last index of a\n    if idx_hi.nelement() == 0:\n        idx_hi = torch.tensor(a.shape[-1] - 1, device=a.device)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if v.ndim == a.ndim - 1:\n        v = v[..., None]\n    if v.shape[-1] != a.shape[-1]:\n        v = v[..., :a.shape[-1]]\n    a = a[..., None, :]\n    v = v[..., None, :]\n    # Find the indices where each element of v should be inserted into a\n    idx_lo = torch.searchsorted(a, v, side='left').squeeze(-2)\n    idx_hi = torch.searchsorted(a, v, side='right').squeeze(-2)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    a = a.unsqueeze(-1)\n    v = v.unsqueeze(-2)\n    idx_lo = torch.sum(a < v, dim=-1)\n    idx_hi = torch.sum(a <= v, dim=-1)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  def camera_matrix(\n      fx,\n      fy,\n      cx,\n      cy,\n      xnp = np,\n  ):\n    \"\"\"\n    Generates the camera matrix for a pinhole camera model using the OpenCV coordinate system. This matrix is crucial for camera calibration and 3D reconstruction tasks.\n\n    Input-Output Arguments\n    :param fx: Numeric. The focal length of the camera along the x-axis. It influences how wide or narrow the view is captured.\n    :param fy: Numeric. The focal length of the camera along the y-axis. Similar to fx, it affects the vertical field of view.\n    :param cx: Numeric. The x-coordinate of the optical center of the camera. It's used to align the center of the image with the principal point.\n    :param cy: Numeric. The y-coordinate of the optical center of the camera. Works alongside cx for proper image centering.\n    :param xnp: Module, optional. The numerical Python module used for matrix operations, defaulting to numpy. It allows for flexibility in case a different module or a mock object is needed for testing.\n    :return: Array. The 3x3 camera matrix representing the camera's internal parameters.\n    \"\"\"\n    return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n  def intrinsic_matrix(\n      fx,\n      fy,\n      cx,\n      cy,\n      xnp = np,\n  ):\n    \"\"\"\n    Generates the intrinsic matrix for a pinhole camera model using the OpenCV coordinate system. This matrix is crucial for camera calibration and 3D reconstruction tasks.\n\n    Input-Output Arguments\n    :param fx: Numeric. The focal length of the camera along the x-axis. It influences how wide or narrow the view is captured.\n    :param fy: Numeric. The focal length of the camera along the y-axis. Similar to fx, it affects the vertical field of view.\n    :param cx: Numeric. The x-coordinate of the optical center of the camera. It's used to align the center of the image with the principal point.\n    :param cy: Numeric. The y-coordinate of the optical center of the camera. Works alongside cx for proper image centering.\n    :param xnp: Module, optional. The numerical Python module used for"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is the camera's internal parameters.\n  # It's used to project 3D points into the image plane.\n  # It's crucial for camera calibration and 3D reconstruction tasks.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to project 3D points into the image plane.\n  # It's used to"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is used for camera calibration and 3D reconstruction.\n  # The matrix is crucial for camera calibration and 3D reconstruction tasks.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  # The matrix is used to map the 2D image space to the 3D world space.\n  #"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  def get_intrinsic_matrix_from_focal_lengths(fx, fy, xnp):\n    \"\"\"\n    Generates the intrinsic matrix for a pinhole camera model using the focal lengths.\n\n    Input-Output Arguments\n    :param fx: Numeric. The focal length of the camera along the x-axis. It influences how wide or narrow the view is captured.\n    :param fy: Numeric. The focal length of the camera along the y-axis. Similar to fx, it affects the vertical field of view.\n    :param xnp: Module, optional. The numerical Python module used for matrix operations, defaulting to numpy. It allows for flexibility in case a different module or a mock object is needed for testing.\n    :return: Array. The 3x3 intrinsic matrix representing the camera's internal parameters.\n    \"\"\"\n    return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n  if fx is None:\n    fx = fy\n  if fy is None:\n    fy = fx\n  if cx is None:\n    cx = 0\n  if cy is None:\n    cy = 0\n\n  return get_intrinsic_matrix_from_focal_lengths(fx, fy, xnp)\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  if fx <= 0 or fy <= 0:\n    raise ValueError(\n        f'fx={fx} and fy={fy} must be positive. fx is the focal length along the x-axis. fy is the focal length along the y-axis.'\n    )\n\n  # The principal point is the center of the image.\n  # The optical center is the center of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the camera.\n  # The optical axis is the axis of the"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The matrix is crucial for camera calibration and 3D reconstruction tasks.\n  # The matrix is defined as follows:\n  #\n  # | fx  0  cx |\n  # | 0 fy  0 cy |\n  # | 0  0  1  0 |\n  #\n  # Where fx is the focal length along the x-axis, fy along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera,\n  # cy is the y-coordinate of the optical center of the camera,\n  # and 0 is the zero matrix.\n  #\n  # The matrix is defined as follows:\n  #\n  # | fx  0  cx |\n  # | 0 fy  0 cy |\n  # | 0  0  1  0 |\n  #\n  # Where fx is the focal length along the x-axis, fy along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera,\n  # cy is the y-coordinate of the optical center of the camera,\n  # and 0 is the zero matrix.\n  #\n  # The matrix is defined as follows:\n  #\n  # | fx  0  cx |\n  # | 0 fy  0 cy |\n  # | 0  0  1  0 |\n  #\n  # Where fx is the focal length along the x-axis, fy along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera,\n  # cy is the y-coordinate of the optical center of the camera,\n  # and 0 is the zero matrix.\n  #\n  # The matrix is defined as follows:\n  #\n  # | fx  0  cx |\n  # | 0 fy  0 cy |\n  # | 0  0  1  0 |\n  #\n  # Where fx is the focal length along the x-axis, fy along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera,\n  # cy is the y-coordinate of the optical center of the camera,\n  # and 0 is the zero matrix.\n  #\n  # The matrix is defined as follows:\n  #\n  # | fx  0  cx |\n "}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is a 3x3 matrix.\n  intrinsic = np.zeros((3, 3), dtype=float)\n\n  # The first row of the intrinsic matrix is the focal lengths.\n  intrinsic[0, 0] = fx\n  intrinsic[1, 1] = fy\n\n  # The second row of the intrinsic matrix is the optical center.\n  intrinsic[0, 2] = cx\n  intrinsic[1, 2] = cy\n\n  # The third row of the intrinsic matrix is the scale factor.\n  intrinsic[2, 0] = 1\n  intrinsic[2, 1] = 1\n  intrinsic[2, 2] = 1\n\n  return intrinsic\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is the first 3x3 submatrix of the camera matrix.\n  # https://docs.opencv.org/3.4.1/d4/d94/tutorial_py_camera_calibration.html\n  # https://docs.opencv.org/3.4.1/d9/d0c/group__calib3d.html#gscamera_matrix\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n\n  # The intrinsic matrix is the first 3x3 submatrix of the camera matrix.\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n  # https://docs.opencv.org/3.4.1/d4/d94/tutorial_py_camera_calibration.html\n  # https://docs.opencv.org/3.4.1/d9/d0c/group__calib3d.html#gscamera_matrix\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n\n  # The intrinsic matrix is the first 3x3 submatrix of the camera matrix.\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n  # https://docs.opencv.org/3.4.1/d4/d94/tutorial_py_camera_calibration.html\n  # https://docs.opencv.org/3.4.1/d9/d0c/group__calib3d.html#gscamera_matrix\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n\n  # The intrinsic matrix is the first 3x3 submatrix of the camera matrix.\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n  # https://docs.opencv.org/3.4.1/d4/d94/tutorial_py_camera_calibration.html\n  # https://docs.opencv.org/3.4.1/d9/d0c/group__calib3d.html#gscamera_matrix\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n\n  # The intrinsic matrix is the first 3x3 submatrix of the camera matrix.\n  # https://en.wikipedia.org/"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  if xnp is None:\n    import numpy as xnp\n\n  # Compute the intrinsic matrix.\n  # The intrinsic matrix is a 3x3 matrix representing the camera's internal parameters.\n  # It's used to calibrate the camera and reconstruct 3D world points.\n  # The intrinsic matrix is defined as follows:\n  #\n  #   [fx  0  cx]\n  #   [ 0 fy  cy]\n  #   [ 0  0   1]\n  #\n  # Where fx is the focal length along the x-axis, fy is the focal length along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera, and cy is the y-coordinate\n  # of the optical center of the camera.\n  #\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D world points.\n  # It's used to calibrate the camera and reconstruct 3D world points.\n  #\n  # The intrinsic matrix is defined as follows:\n  #\n  #   [fx  0  cx]\n  #   [ 0 fy  cy]\n  #   [ 0  0   1]\n  #\n  # Where fx is the focal length along the x-axis, fy is the focal length along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera, and cy is the y-coordinate\n  # of the optical center of the camera.\n  #\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D world points.\n  # It's used to calibrate the camera and reconstruct 3D world points.\n  #\n  # The intrinsic matrix is defined as follows:\n  #\n  #   [fx  0  cx]\n  #   [ 0 fy  cy]\n  #   [ 0  0   1]\n  #\n  # Where fx is the focal length along the x-axis, fy is the focal length along the y-axis,\n  # cx is the x-coordinate of the optical center of the camera, and cy is the y-coordinate\n  # of the optical center of the camera.\n  #\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D world points.\n  # It's used to calibrate the camera and reconstruct 3"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  def create_intrinsic_matrix_from_focal_lengths(\n      fx, fy, xnp\n  ):\n    \"\"\"Creates the intrinsic matrix from the focal lengths.\"\"\"\n    return np.array(\n        [\n            [fx, 0, cx],\n            [0, fy, cy],\n            [0, 0, 1],\n        ]\n    )\n\n  def create_intrinsic_matrix_from_principal_point(\n      cx, cy, xnp\n  ):\n    \"\"\"Creates the intrinsic matrix from the principal point.\"\"\"\n    return np.array(\n        [\n            [0, 0, cx],\n            [0, 0, cy],\n            [0, 0, 1],\n        ]\n    )\n\n  def create_intrinsic_matrix_from_principal_point_and_focal_lengths(\n      fx, fy, cx, cy, xnp\n  ):\n    \"\"\"Creates the intrinsic matrix from the principal point and the focal lengths.\"\"\"\n    return np.array(\n        [\n            [fx, 0, cx],\n            [0, fy, cy],\n            [0, 0, 1],\n        ]\n    )\n\n  if fx is None:\n    if fy is None:\n      if cx is None:\n        if cy is None:\n          return create_intrinsic_matrix_from_principal_point(\n              cx, cy, xnp=xnp\n          )\n        else:\n          return create_intrinsic_matrix_from_principal_point_and_focal_lengths(\n              cx, cy, xnp=xnp\n          )\n      else:\n        return create_intrinsic_matrix_from_principal_point_and_focal_lengths(\n            fx, fy, cx, cy, xnp=xnp\n        )\n    else:\n      return create_intrinsic_matrix_from_principal_point_and_focal_lengths(\n          fx, fy, cx, cy, xnp=xnp\n      )\n  else:\n    return create_intrinsic_matrix_from_principal_point_and_focal_lengths(\n        fx, fy, cx, cy, xnp=xnp\n    )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Construct the intrinsic matrix.\n  # https://docs.opencv.org/2.4/doc/tutorials/calib3d/camera_calibration/camera_calibration.html\n  # https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html\n  # https://en.wikipedia.org/wiki/Camera_resectioning\n  # https://en.wikipedia.org/wiki/Camera_matrix\n  # https://en.wikipedia.org/wiki/Camera_matrix_(photography)\n  # https://en.wikipedia.org/wiki/Distortion_(optics)\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Radial_distortion\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Tangential_distortion\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Radial_distortion_coefficients\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Tangential_distortion_coefficients\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_coefficients\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model_parameters\n  # https://en.wikipedia.org/wiki/Distortion_(optics)#Distortion_model"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # The camera matrix is a 3x3 matrix.\n  intrinsic_matrix = xnp.zeros((3, 3))\n\n  # The first row of the camera matrix is the focal length along the x-axis.\n  intrinsic_matrix[0, 0] = fx\n\n  # The second row of the camera matrix is the focal length along the y-axis.\n  intrinsic_matrix[1, 1] = fy\n\n  # The third row of the camera matrix is the optical center's x-coordinate.\n  intrinsic_matrix[0, 2] = cx\n\n  # The fourth row of the camera matrix is the optical center's y-coordinate.\n  intrinsic_matrix[1, 2] = cy\n\n  return intrinsic_matrix\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  if xnp is None:\n    xnp = np\n\n  # Intrinsic matrix is the camera's internal parameters.\n  K = xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n  return K\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is a 3x3 matrix.\n  #\n  # [fx, 0, cx]\n  # [0, fy, cy]\n  # [0, 0, 1]\n  #\n  # The first row represents the x-axis.\n  # The second row represents the y-axis.\n  # The third row represents the z-axis.\n  #\n  # fx is the focal length along the x-axis.\n  # fy is the focal length along the y-axis.\n  # cx is the x-coordinate of the optical center of the camera.\n  # cy is the y-coordinate of the optical center of the camera.\n\n  # The principal point is the point where the principal ray intersects the image plane.\n  # The principal ray is the ray that passes through the optical center of the camera.\n  # The principal ray intersects the image plane at the principal point.\n  # The principal point is the center of the image.\n\n  # The principal point is the point where the principal ray intersects the image plane.\n  # The principal ray is the ray that passes through the optical center of the camera.\n  # The principal ray intersects the image plane at the principal point.\n  # The principal point is the center of the image.\n\n  # The principal point is the point where the principal ray intersects the image plane.\n  # The principal ray is the ray that passes through the optical center of the camera.\n  # The principal ray intersects the image plane at the principal point.\n  # The principal point is the center of the image.\n\n  # The principal point is the point where the principal ray intersects the image plane.\n  # The principal ray is the ray that passes through the optical center of the camera.\n  # The principal ray intersects the image plane at the principal point.\n  # The principal point is the center of the image.\n\n  # The principal point is the point where the principal ray intersects the image plane.\n  # The principal ray is the ray that passes through the optical center of the camera.\n  # The principal ray intersects the image plane at the principal point.\n  # The principal point is the center of the image.\n\n  # The principal point is the point where the principal ray intersects the image plane.\n  # The principal ray is the ray that passes through the optical center of the camera.\n  # The principal ray intersects"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  if fx <= 0 or fy <= 0:\n    raise ValueError(f'fx={fx} and fy={fy} must be positive.')\n\n  if cx is None:\n    cx = 0.0\n  if cy is None:\n    cy = 0.0\n\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # It's crucial to use the OpenCV coordinate system for the camera calibration and 3D reconstruction tasks.\n  # The intrinsic matrix is a 3x3 matrix and the OpenCV coordinate system is a 3D coordinate system.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the camera and reconstruct 3D scenes.\n  # The intrinsic matrix is used to calibrate the"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  if xnp is None:\n    import numpy as xnp\n\n  # The intrinsic matrix is the camera's internal parameters.\n  # It's a 3x3 matrix that represents the camera's internal parameters.\n  # It's used to transform from the camera-space to the world-space.\n  # It's crucial for camera calibration and 3D reconstruction tasks.\n  # It's crucial to compute the extrinsic matrix.\n  # It's used to compute the camera matrix.\n  # It's used to compute the projection matrix.\n  # It's used to compute the distortion matrix.\n  # It's used to compute the essential matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental matrix.\n  # It's used to compute the fundamental"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is used to relate 3D points in the world space to 2D points in the image space.\n  # It is crucial for camera calibration and 3D reconstruction tasks.\n  # It's a 3x3 matrix that can be decomposed into 3 3x1 vectors.\n  # The first vector is the focal length along the x-axis.\n  # The second vector is the focal length along the y-axis.\n  # The third vector is the optical center of the camera.\n  # The optical center is the point of intersection of the optical axis and the image plane.\n  # The optical axis is the line of intersection of the optical plane and the image plane.\n  # The optical plane is the plane of intersection of the optical axis and the image plane.\n  # The image plane is the plane of intersection of the image lines and the optical axis.\n  # The image line is the line of intersection of the image point and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The optical axis is the line of intersection of the optical plane and the image plane.\n  # The optical plane is the plane of intersection of the optical axis and the image plane.\n  # The image plane is the plane of intersection of the image lines and the optical axis.\n  # The image line is the line of intersection of the image point and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point is the point of intersection of the image line and the optical axis.\n  # The image point"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  if fx is None or fy is None:\n    raise ValueError('fx and fy must be specified.')\n  if cx is None or cy is None:\n    raise ValueError('cx and cy must be specified.')\n\n  # The intrinsic matrix is a 3x3 matrix.\n  # The first row represents the x-axis parameters.\n  # The second row represents the y-axis parameters.\n  # The third row represents the z-axis parameters.\n  # The first column represents the x-coordinate parameters.\n  # The second column represents the y-coordinate parameters.\n  # The third column represents the z-coordinate parameters.\n  # The first element of the first row represents the focal length of the camera along the x-axis.\n  # The second element of the first row represents the optical center along the x-axis.\n  # The first element of the second row represents the focal length of the camera along the y-axis.\n  # The second element of the second row represents the optical center along the y-axis.\n  # The first element of the third row represents the x-coordinate of the principal point.\n  # The second element of the third row represents the y-coordinate of the principal point.\n  # The third element of the third row represents the z-coordinate of the principal point.\n  # The principal point is the point in the image where the optical axis intersects the image plane.\n  # The optical axis is the line connecting the optical center with the principal point.\n  # The image plane is the plane connecting the optical axis with the principal point.\n  # The image plane is the plane containing the optical axis.\n  # The optical center is the point in the image where the optical axis intersects the image plane.\n  # The optical axis is the line connecting the optical center with the principal point.\n  # The optical center is the point in the image where the optical axis intersects the image plane.\n  # The optical axis is the line connecting the optical center with the principal point.\n  # The optical center is the point in the image where the optical axis intersects the image plane.\n  # The optical axis is the line connecting the optical center with the principal point.\n  # The optical center is the point in the image where the optical axis intersects the image plane.\n  # The optical axis is the line connecting the optical center with the principal point.\n  # The optical center is the point in the image"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # The focal length of a pinhole camera is the distance between the principal point and the image plane. The principal point is the intersection between the image plane and the optical axis. The optical axis is the line passing through the optical center of the camera. The image plane is the plane containing the image captured by the camera.\n  # The optical center is the center of the image captured by the camera. It's the point where the optical axis and the image plane intersect.\n  # The optical axis is the line passing through the optical center of the camera. It's the line perpendicular to the image plane.\n  # The image plane is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image is the captured image by the camera.\n  # The camera is the device used to capture the image.\n  # The optical center of the camera is the center of the image captured by the camera. It's the point where the optical axis and the image plane intersect.\n  # The optical axis of the camera is the line passing through the optical center of the camera. It's the line perpendicular to the image plane.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image is captured.\n  # The image plane of the camera is the plane containing the image captured by the camera. It's the plane where the image"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Intrinsic matrix is a 3x3 matrix.\n  # See https://docs.opencv.org/3.4/d4/d94/tutorial_py_camera_calibration.html.\n  intrinsic_matrix = xnp.zeros((3, 3))\n\n  # The focal length is the distance between the principal point and the image plane.\n  # See https://en.wikipedia.org/wiki/Focal_length_(optics).\n  # The focal length along the x-axis is the first element of the intrinsic matrix.\n  intrinsic_matrix[0, 0] = fx\n\n  # The focal length along the y-axis is the second element of the intrinsic matrix.\n  intrinsic_matrix[1, 1] = fy\n\n  # The optical center is the point where the principal point is aligned to.\n  # See https://en.wikipedia.org/wiki/Principal_point_(camera_optics).\n  # The x-coordinate of the optical center is the third element of the intrinsic matrix.\n  intrinsic_matrix[0, 2] = cx\n\n  # The y-coordinate of the optical center is the fourth element of the intrinsic matrix.\n  intrinsic_matrix[1, 2] = cy\n\n  # The fifth element of the intrinsic matrix is the skew coefficient.\n  # See https://en.wikipedia.org/wiki/Distortion_(optics).\n  intrinsic_matrix[0, 1] = 0\n\n  # The sixth element of the intrinsic matrix is the scaling coefficient.\n  # See https://en.wikipedia.org/wiki/Distortion_(optics).\n  intrinsic_matrix[1, 0] = 0\n\n  # The seventh element of the intrinsic matrix is the prism coefficient.\n  # See https://en.wikipedia.org/wiki/Distortion_(optics).\n  intrinsic_matrix[2, 0] = 0\n\n  # The eighth element of the intrinsic matrix is the tangential coefficient.\n  # See https://en.wikipedia.org/wiki/Distortion_(optics).\n  intrinsic_matrix[2, 1] = 0\n\n  # The ninth element of the intrinsic matrix is the radial coefficient.\n  # See https://en.wikipedia.org/wiki"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x * x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x * (1 - jnp.square(x)).clip(0, 1) ** 0.5\n\n"}
{"namespace": "coord.contract", "completion": "  return jnp.where(jnp.sum(x**2, axis=-1, keepdims=True) < 1, x / jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)), x)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x * x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  x = jnp.asarray(x)\n  return x / jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x * jnp.sqrt(1.0 - jnp.linalg.norm(x, axis=-1)**2)\n\n"}
{"namespace": "coord.contract", "completion": "  # Get the magnitude squared of the points\n  x_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Calculate the scaling factor\n  scale = jnp.sqrt(1.0 - x_mag_sq)\n\n  # Scale the points towards the origin\n  x = x * scale\n\n  return x\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input points\n  mag_sq = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Calculate the scaling factor based on the magnitude squared\n  scale = 1.0 / (1.0 + mag_sq)\n\n  # Scale the input points towards the origin based on the scaling factor\n  return scale * x\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  return x * jnp.sqrt(1 - jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x * jnp.sqrt(1.0 - jnp.linalg.norm(x, axis=-1)**2)\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input points\n  x_mag_sq = jnp.sum(x**2, axis=-1)\n  # Calculate the scaling factor based on the magnitude squared of the points\n  scaling_factor = 1 / (1 + jnp.sqrt(x_mag_sq))\n  # Scale the points towards the origin based on the scaling factor\n  return x * scaling_factor[..., None]\n\n"}
{"namespace": "coord.contract", "completion": "  x_mag = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return (1. - (1. - x_mag) * jnp.exp(-x_mag)) * x / x_mag\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)), 1)\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes / 1000} KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes / 1000**2} MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes / 1000**3} GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes / 1000**4} TB\"\n    elif num_bytes < 1000**6:\n        return f\"{num_bytes / 1000**5} PB\"\n    else:\n        return f\"{num_bytes / 1000**6} EB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes / 1000} KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes / 1000**2} MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes / 1000**3} GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes / 1000**4} TB\"\n    else:\n        return f\"{num_bytes / 1000**5} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes / 1000} KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes / 1000**2} MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes / 1000**3} GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes / 1000**4} TB\"\n    else:\n        return f\"{num_bytes / 1000**5} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes == 0:\n        return \"0B\"\n    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    i = 0\n    while num_bytes >= 1000 and i < len(units) - 1:\n        num_bytes /= 1000\n        i += 1\n    return f\"{num_bytes:.2f}{units[i]}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes:.2f} B\"\n    elif num_bytes < 1000 ** 2:\n        return f\"{num_bytes / 1000:.2f} KB\"\n    elif num_bytes < 1000 ** 3:\n        return f\"{num_bytes / 1000 ** 2:.2f} MB\"\n    elif num_bytes < 1000 ** 4:\n        return f\"{num_bytes / 1000 ** 3:.2f} GB\"\n    elif num_bytes < 1000 ** 5:\n        return f\"{num_bytes / 1000 ** 4:.2f} TB\"\n    elif num_bytes < 1000 ** 6:\n        return f\"{num_bytes / 1000 ** 5:.2f} PB\"\n    else:\n        return f\"{num_bytes / 1000 ** 6:.2f} EB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes}B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes / 1000}KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes / 1000**2}MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes / 1000**3}GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes / 1000**4}TB\"\n    elif num_bytes < 1000**6:\n        return f\"{num_bytes / 1000**5}PB\"\n    else:\n        return f\"{num_bytes / 1000**6}EB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return \"%3.1f %s\" % (num_bytes, unit)\n        num_bytes /= 1000.0\n    return \"%.1f %s\" % (num_bytes, \"PB\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} {unit}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.1f}{unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.1f}YB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes:.2f} B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes / 1000:.2f} KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes / 1000**2:.2f} MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes / 1000**3:.2f} GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes / 1000**4:.2f} TB\"\n    else:\n        return f\"{num_bytes / 1000**5:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return \"%3.1f %s\" % (num_bytes, unit)\n        num_bytes /= 1000.0\n    return \"%.1f %s\" % (num_bytes, \"YB\")"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} {unit}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n    elif num_bytes < 1000**2:\n        return f\"{round(num_bytes / 1000, 1)} KB\"\n    elif num_bytes < 1000**3:\n        return f\"{round(num_bytes / 1000**2, 1)} MB\"\n    elif num_bytes < 1000**4:\n        return f\"{round(num_bytes / 1000**3, 1)} GB\"\n    elif num_bytes < 1000**5:\n        return f\"{round(num_bytes / 1000**4, 1)} TB\"\n    elif num_bytes < 1000**6:\n        return f\"{round(num_bytes / 1000**5, 1)} PB\"\n    else:\n        return f\"{round(num_bytes / 1000**6, 1)} EB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.1f}{unit}B\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.1f}YB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes:.2f} B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes/1000:.2f} KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes/1000**2:.2f} MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes/1000**3:.2f} GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes/1000**4:.2f} TB\"\n    elif num_bytes < 1000**6:\n        return f\"{num_bytes/1000**5:.2f} PB\"\n    else:\n        return f\"{num_bytes/1000**6:.2f} EB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.1f}{unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.1f}YB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} {unit}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.1f}{unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.1f}{unit}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1000:\n        return f\"{num_bytes:.0f}B\"\n    elif num_bytes < 1000**2:\n        return f\"{num_bytes/1000:.2f}KB\"\n    elif num_bytes < 1000**3:\n        return f\"{num_bytes/1000**2:.2f}MB\"\n    elif num_bytes < 1000**4:\n        return f\"{num_bytes/1000**3:.2f}GB\"\n    elif num_bytes < 1000**5:\n        return f\"{num_bytes/1000**4:.2f}TB\"\n    else:\n        return f\"{num_bytes/1000**5:.2f}PB\""}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that the array has the specified number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that the array has the specified number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {v.ndim}\"\n            )\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is a Pydantic validator that checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have specific number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}\"\n            )\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have specific number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has `nb_dimensions` dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have `nb_dimensions` dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}\"\n            )\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have specific number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got shape {v.shape}\"\n            )\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Validate that an array has a specific number of dimensions.\n\n        Args:\n            cls (type): The class of the model being validated.\n            v (np.ndarray): The array being validated.\n            field (fields.ModelField): The field of the model that is being validated.\n\n        Raises:\n            ValueError: If the array does not have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}\"\n            )\n\n        return v\n\n    return validate_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is a Pydantic validator that checks if a given array has a specific number of dimensions.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n\n        The function raises a ValueError if the array does not have the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}.\"\n            )\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has `nb_dimensions` dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have `nb_dimensions` dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got shape {v.shape}\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has `nb_dimensions` dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have `nb_dimensions` dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}\"\n            )\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Validate that the array has a specific number of dimensions.\n\n        Args:\n            cls (type): The class of the model being validated.\n            v (np.ndarray): The array being validated.\n            field (fields.ModelField): The field of the model that is being validated.\n\n        Returns:\n            np.ndarray: The validated array if it meets the specified number of dimensions.\n\n        Raises:\n            ValueError: If the array does not have the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return validate_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is a Pydantic validator that checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n\n        The validator function checks if the array has the expected number of dimensions. If it does not, it raises a ValueError with a message indicating the expected number of dimensions and the actual number of dimensions of the array. If the array has the expected number of dimensions, it returns the array.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the required number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has `nb_dimensions` dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have `nb_dimensions`.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}\"\n            )\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This is the validator function that is returned by the is_array_n_dimensions() function. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)} dimensions.\"\n            )\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Validate the dimensionality of an array.\n\n        Args:\n            cls (type): The class of the model being validated.\n            v (np.ndarray): The array being validated.\n            field (fields.ModelField): The field of the model that is being validated.\n\n        Returns:\n            np.ndarray: The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)} dimensions.\"\n            )\n        return v\n\n    return validate_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is a Pydantic validator that checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has `nb_dimensions` dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have `nb_dimensions` dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has `nb_dimensions` dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have `nb_dimensions`.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator\n      return self.name"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.moveaxis(cartesian_vector, -1, 0)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.moveaxis(cartesian_vector, -1, 0)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  cartesian_vector = jnp.asarray(cartesian_vector)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Extract the x, y, and z coordinates from the input array\n  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  # Calculate the radius (r)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(z / (r + eps))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  cartesian_vector = jnp.asarray(cartesian_vector)\n  assert cartesian_vector.shape[-1] == 3, \"Input must have shape (..., 3).\"\n\n  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.moveaxis(cartesian_vector, -1, 0)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Convert to numpy array\n  cartesian_vector = jnp.asarray(cartesian_vector)\n\n  # Extract the x, y, and z coordinates\n  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  # Calculate the radius\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(z / (r + eps))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Extract the x, y, and z coordinates from the input array\n  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  # Calculate the radius (r)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(z / (r + eps))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Extract the x, y, and z coordinates from the input array.\n  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  # Calculate the radius (r) of the point.\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta) of the point.\n  theta = jnp.arccos(z / (r + eps))\n\n  # Calculate the azimuth (phi) of the point.\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Convert to jnp array if input is onp array\n  if isinstance(cartesian_vector, onp.ndarray):\n    cartesian_vector = jnp.array(cartesian_vector)\n\n  # Calculate the radius\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(cartesian_vector[..., 2] / (r + eps))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Extract the x, y, and z coordinates from the input array.\n  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  # Calculate the radius (r) as the square root of the sum of the squares of the x, y, and z coordinates.\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta) as the arccosine of z divided by the radius.\n  theta = jnp.arccos(z / (r + eps))\n\n  # Calculate the azimuth (phi) as the arctangent of y divided by x.\n  phi = jnp.arctan2(y, x)\n\n  # Return the spherical coordinates as a tuple.\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Extract the x, y, and z coordinates from the input array\n  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  # Calculate the radius (r)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arctan2(jnp.sqrt(x**2 + y**2), z + eps)\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  cartesian_vector = jnp.asarray(cartesian_vector)\n  assert cartesian_vector.shape[-1] == 3, \"The last dimension of the input array must be 3 for x, y, and z coordinates.\"\n\n  x, y, z = jnp.moveaxis(cartesian_vector, -1, 0)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Extract the x, y, and z components of the input vector\n  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  # Calculate the radius (r)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(z / (r + eps))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(y, x)\n\n  # Return the spherical coordinates as a tuple\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  cartesian_vector = jnp.asarray(cartesian_vector)\n  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  cartesian_vector = jnp.asarray(cartesian_vector)\n  assert cartesian_vector.shape[-1] == 3, 'cartesian_vector must have shape (..., 3)'\n  # Calculate the radius\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  # Calculate the inclination angle (theta)\n  theta = jnp.arccos(cartesian_vector[..., 2] / (r + eps))\n  # Calculate the azimuth angle (phi)\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge1'].fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rougeL = evaluate.load('rouge')\n    results = rougeL.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge1'].mid.fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    def tokenizer(text: str):\n        return list(jieba.cut(text))\n\n    rouge = evaluate.load(\"rouge\")\n    results = rouge.compute(\n        predictions=[continuation], references=[[reference]], tokenizer=tokenizer\n    )\n    return results[\"rouge1\"].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], use_agregator=False, tokenizer=f)\n    score = results['rougeL'].mid.fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge1'].fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    tokenizer = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], use_stemmer=False, tokenizer=tokenizer)\n    score = results['rouge1'].fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge1'].fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    tokenizer = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        use_agregator=False,\n        tokenizer=tokenizer\n    )\n    return results['rouge1'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    def tokenizer(text):\n        return list(jieba.cut(text))\n\n    rouge_metric = evaluate.load(\"rouge\")\n    result = rouge_metric.compute(\n        predictions=[continuation], references=[[reference]], use_stemmer=True, tokenizer=tokenizer\n    )\n    return result['rouge1'].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], use_agregator=False, tokenizer=f)\n    score = results['rouge1'].fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], use_agregator=False, tokenizer=f)\n    return results['rouge1'].low.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge1'].mid.fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        use_stemmer=True,\n        tokenizer=f\n    )\n    return results['rouge1'].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rouge1'].fmeasure\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rouge1'].fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    tokenizer = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load(\"rouge\")\n    result = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)\n    return result['rouge1'].fmeasure\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Try to locate the object in the registry.\n        # This is useful for backward compatibility.\n        from fvcore.common.registry import Registry\n\n        registry = Registry.get(name)\n        return registry.get(name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Check if the object is already in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:\n        return Registry.get(name)\n    except KeyError:\n        pass\n\n    # Check if the object is in the registry\n    try:"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Try to locate the object using a fallback method.\n        # This is a hack that works for many common cases.\n        # For example, if the object is a class defined in a file,\n        # the fallback method will locate the file and import the class.\n        # If the object is a function defined in a file,\n        # the fallback method will locate the file and import the function.\n        # If the object is a class defined in a class,\n        # the fallback method will locate the class and import the class.\n        # If the object is a function defined in a class,\n        # the fallback method will locate the class and import the function.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import the function.\n        # If the object is a class defined in a module,\n        # the fallback method will locate the module and import the class.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import the function.\n        # If the object is a class defined in a module,\n        # the fallback method will locate the module and import the class.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import the function.\n        # If the object is a class defined in a module,\n        # the fallback method will locate the module and import the class.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import the function.\n        # If the object is a class defined in a module,\n        # the fallback method will locate the module and import the class.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import the function.\n        # If the object is a class defined in a module,\n        # the fallback method will locate the module and import the class.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import the function.\n        # If the object is a class defined in a module,\n        # the fallback method will locate the module and import the class.\n        # If the object is a function defined in a module,\n        # the fallback method will locate the module and import"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        raise ImportError(f\"Failed to locate '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except Exception:\n        # Try to locate the object using a fallback method\n        try:\n            module_name, class_name = name.rsplit(\".\", 1)\n            module = __import__(module_name, fromlist=[class_name])\n            return getattr(module, class_name)\n        except Exception:\n            raise ImportError(f\"Failed to import {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Try to resolve the name using the fallback method\n        if \".\" not in name:\n            raise ImportError(f\"Failed to locate object '{name}'\")\n        module, qualname = name.rsplit(\".\", 1)\n        try:\n            module = pydoc.locate(module)\n        except ImportError:\n            raise ImportError(f\"Failed to locate object '{name}'\")\n        try:\n            return getattr(module, qualname)\n        except AttributeError:\n            raise ImportError(f\"Failed to locate object '{name}'\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Try to locate the object using the fallback method\n        if \".\" not in name:\n            raise ImportError(f\"Unable to locate object '{name}'\")\n        module_name, object_name = name.rsplit(\".\", 1)\n        module = pydoc.locate(module_name)\n        if module is None:\n            raise ImportError(f\"Unable to locate module '{module_name}'\")\n        try:\n            return getattr(module, object_name)\n        except AttributeError:\n            raise ImportError(f\"Unable to locate object '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First, try locating the object using the standard method.\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # If the standard method fails, try locating the object using the fallback method.\n    try:\n        module_name, class_name = name.rsplit(\".\", 1)\n        module = __import__(module_name, fromlist=[class_name])\n        return getattr(module, class_name)\n    except (ImportError, AttributeError):\n        pass\n\n    # If the object cannot be located by either method, raise an exception.\n    raise ImportError(f\"Cannot locate object '{name}'.\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First try to locate the object using the standard method\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # If the standard method fails, try to locate the object using a fallback method\n    # This method is used to locate objects that are not part of the standard library\n    # but are part of the project's source code\n    try:\n        # Split the name into module and class parts\n        module_name, class_name = name.rsplit(\".\", 1)\n\n        # Import the module\n        module = __import__(module_name, fromlist=[class_name])\n\n        # Get the class from the module\n        return getattr(module, class_name)\n    except ImportError:\n        pass\n\n    # If both methods fail, raise an ImportError\n    raise ImportError(f\"Could not locate object with name '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except AttributeError:\n        pass\n    try:\n        return pydoc.locate(name + \"()\")\n    except AttributeError:\n        pass\n    raise ImportError(f\"Failed to locate {name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n    # Try to locate the object using the fallback method.\n    parts = name.split(\".\")\n    module = \".\".join(parts[:-1])\n    try:\n        return getattr(__import__(module), parts[-1])\n    except AttributeError:\n        raise ImportError(f\"Cannot locate object {name}\") from None"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First try the standard method\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # Second try the fallback method\n    try:\n        module, qualname = name.rsplit(\".\", 1)\n        __import__(module)\n        module = sys.modules[module]\n        return getattr(module, qualname)\n    except (ImportError, AttributeError):\n        pass\n\n    # Raise an exception if the object cannot be located\n    raise ImportError(f\"Cannot locate object {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # This is a fallback method that can be used to locate objects that are not\n        # part of the Python standard library. It works by splitting the name string\n        # into a list of module names, and then importing each module in turn until\n        # the object is found.\n        module_names = name.split(\".\")\n        for i in range(len(module_names)):\n            try:\n                module_name = \".\".join(module_names[:i + 1])\n                module = __import__(module_name)\n                for sub_name in module_names[i + 1:]:\n                    module = getattr(module, sub_name)\n                return module\n            except ImportError:\n                pass\n        raise ImportError(f\"Cannot locate object '{name}'\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n    if \".\" not in name:\n        raise ImportError(f\"No module named {name}\")\n\n    # Try to locate the object using the fallback method.\n    # The fallback method is to import the module and then look for the object in the module's __dict__.\n    module_name, obj_name = name.rsplit(\".\", 1)\n    try:\n        module = __import__(module_name, fromlist=[obj_name])\n    except ImportError:\n        raise ImportError(f\"No module named {module_name}\")\n    try:\n        return getattr(module, obj_name)\n    except AttributeError:\n        raise ImportError(f\"No module named {module_name}.{obj_name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n    if \".\" not in name:\n        raise ImportError(f\"No module named {name}\")\n\n    module, name = name.rsplit(\".\", 1)\n    module = __import__(module, fromlist=[name])\n    try:\n        return getattr(module, name)\n    except AttributeError:\n        raise ImportError(f\"No module named {name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First, try locating the object using the standard method.\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # If the standard method fails, try locating the object using a fallback method.\n    # This method is based on the assumption that the object's fully qualified name\n    # is in the format \"module.submodule.class_name\", where \"module\" and \"submodule\"\n    # are valid Python modules, and \"class_name\" is a valid class name in the \"submodule\" module.\n    # If the object cannot be located using the fallback method, an exception is raised.\n    module_name, class_name = name.rsplit(\".\", 1)\n    try:\n        module = pydoc.locate(module_name)\n        return getattr(module, class_name)\n    except (ImportError, AttributeError):\n        raise ImportError(f\"Cannot locate object '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # Try to locate the object by importing the module and then searching the module for the object.\n    module_name, _, obj_name = name.rpartition(\".\")\n    if not module_name:\n        raise ImportError(f\"Cannot locate '{name}'\")\n    try:\n        module = pydoc.locate(module_name)\n    except ImportError:\n        raise ImportError(f\"Cannot locate module '{module_name}'\")\n    try:\n        return getattr(module, obj_name)\n    except AttributeError:\n        raise ImportError(f\"Cannot locate '{name}'\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # Try to locate the object using a fallback method.\n    parts = name.split(\".\")\n    for k in range(1, len(parts)):\n        prefix = \".\".join(parts[:k])\n        candidate = f\"{prefix}.{parts[-1]}\"\n        try:\n            return pydoc.locate(candidate)\n        except ImportError:\n            pass\n\n    raise ImportError(f\"Failed to locate object {name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # fallback to locate the object in the registry.\n    import importlib\n\n    parts = name.split(\".\")\n    module = importlib.import_module(\".\".join(parts[:-1]))\n    return getattr(module, parts[-1])\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # If the object is not found using the standard method, it attempts to locate the object using a fallback method.\n    # This fallback method is to split the name string into a list of strings, and then use the getattr() function to\n    # access the object in the module. This method is useful when the object is in a module that is not imported\n    # directly, but is imported as part of a larger module.\n\n    # Split the name string into a list of strings, separated by \".\"\n    name_parts = name.split(\".\")\n\n    # Use the getattr() function to access the object in the module.\n    # The getattr() function takes two arguments: the object to access, and the name of the attribute to access.\n    # The getattr() function will return the attribute value if it exists.\n    obj = __import__(name_parts[0])\n    for part in name_parts[1:]:\n        obj = getattr(obj, part)\n\n    return obj\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Load the module from the in-memory buffer\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Create an in-memory buffer to store the module's serialized data\n    buffer = io.BytesIO()\n\n    # Save the module's serialized data to the buffer\n    torch.jit.save(module, buffer)\n\n    # Load the module's serialized data back from the buffer\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Load the module back from the buffer\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids tuple matches the length of the scores tuple\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids tuple must match the length of the scores tuple.\")\n\n    # Check if the length of the ids tuple matches the length of the weights tuple\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids tuple must match the length of the weights tuple.\")\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores based on the weights\n    normalized_scores = []\n    for i, score_list in enumerate(scores):\n        normalized_score_list = [score * weights[i] for score in score_list]\n        normalized_scores.append(normalized_score_list)\n\n    # Combine the normalized scores into a single list\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_score = sum([normalized_scores[j][i] for j in range(len(normalized_scores))])\n        combined_scores.append(combined_score)\n\n    # Sort the combined scores in descending order and select the top_k results\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)\n    top_indices = sorted_indices[:top_k]\n\n    # Select the top_k ids and scores\n    top_ids = []\n    top_scores = []\n    for i in top_indices:\n        top_id = [ids[j][i] for j in range(len(ids))]\n        top_ids.append(top_id)\n        top_score = combined_scores[i]\n        top_scores.append(top_score)\n\n    return top_ids, top_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores of each retrieval result based on the weights\n    normalized_scores = [\n        [score * weight for score in scores]\n        for scores, weight in zip(scores, weights)\n    ]\n\n    # Combine the normalized scores of each retrieval result\n    combined_scores = [\n        sum(scores)\n        for scores in zip(*normalized_scores)\n    ]\n\n    # Sort the combined scores and ids in descending order\n    sorted_scores = sorted(combined_scores, reverse=True)\n    sorted_ids = [\n        id_\n        for score, id_ in sorted(zip(combined_scores, ids), reverse=True)\n    ]\n\n    # Select the top_k results\n    top_ids = sorted_ids[:top_k]\n    top_scores = sorted_scores[:top_k]\n\n    return top_ids, top_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize scores\n    for i in range(len(scores)):\n        scores[i] = [x / sum(scores[i]) for x in scores[i]]\n\n    # Combine scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_scores.append(sum([scores[j][i] * weights[j] for j in range(len(ids))]))\n\n    # Sort combined scores\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda k: combined_scores[k], reverse=True)\n\n    # Select top_k ids and scores\n    top_ids = [ids[0][i] for i in sorted_indices[:top_k]]\n    top_scores = [combined_scores[i] for i in sorted_indices[:top_k]]\n\n    return top_ids, top_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores):\n        raise ValueError(\"ids and scores must have the same length\")\n    if len(ids) != len(weights):\n        raise ValueError(\"ids and weights must have the same length\")\n    if sum(weights) != 1:\n        raise ValueError(\"weights must sum to 1\")\n\n    # Normalize scores\n    for i, score in enumerate(scores):\n        scores[i] = (score - min(score)) / (max(score) - min(score))\n\n    # Combine scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += weights[j] * scores[j][i]\n        combined_scores.append(combined_score)\n\n    # Sort results\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)\n    sorted_ids = [ids[i] for i in sorted_indices]\n    sorted_scores = [combined_scores[i] for i in sorted_indices]\n\n    # Return top_k results\n    return sorted_ids[:top_k], sorted_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the lengths of ids, scores, and weights are equal\n    if len(ids) != len(scores) or len(ids) != len(weights):\n        raise ValueError('The lengths of ids, scores, and weights must be equal')\n\n    # Check that the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError('The sum of the weights must be equal to 1')\n\n    # Normalize the scores\n    normalized_scores = [\n        [score / sum(scores[i]) for score in scores[i]]\n        for i in range(len(scores))]\n\n    # Combine the scores using the convex combination method\n    combined_scores = [\n        sum([normalized_scores[i][j] * weights[i] for i in range(len(weights))])\n        for j in range(len(normalized_scores[0]))]\n\n    # Sort the combined scores and their corresponding ids\n    sorted_indices = [i[0] for i in sorted(enumerate(combined_scores), key=lambda x: x[1], reverse=True)]\n    sorted_ids = [[ids[i][j] for j in sorted_indices] for i in range(len(ids))]\n    sorted_scores = [[combined_scores[j] for j in sorted_indices] for i in range(len(ids))]\n\n    # Select the top_k results\n    top_k_ids = [sorted_ids[i][:top_k] for i in range(len(ids))]\n    top_k_scores = [sorted_scores[i][:top_k] for i in range(len(ids))]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores):\n        raise ValueError(\"The number of ids and scores must be equal.\")\n\n    if len(ids) != len(weights):\n        raise ValueError(\"The number of ids, scores, and weights must be equal.\")\n\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of weights must equal 1.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(pd.Series(score).rank(pct=True).tolist())\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += normalized_scores[j][i] * weights[j]\n        combined_scores.append(combined_score)\n\n    # Sort the combined scores and ids\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)\n    sorted_ids = [ids[i] for i in sorted_indices]\n    sorted_scores = [combined_scores[i] for i in sorted_indices]\n\n    # Select the top k results\n    top_ids = sorted_ids[:top_k]\n    top_scores = sorted_scores[:top_k]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores)\n    assert len(ids) == len(weights)\n    assert sum(weights) == 1\n\n    # Normalize scores\n    norm_scores = [\n        [score / sum(score_list) for score in score_list] for score_list in scores\n    ]\n\n    # Combine scores\n    combined_scores = [\n        sum(weight * score for weight, score in zip(weights, score_list))\n        for score_list in zip(*norm_scores)\n    ]\n\n    # Sort scores\n    sorted_scores = sorted(\n        zip(combined_scores, ids),\n        key=lambda x: x[0],\n        reverse=True)\n\n    # Select top_k results\n    top_scores = sorted_scores[:top_k]\n\n    # Return ids and scores\n    return list(zip(*top_scores))\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize scores\n    norm_scores = []\n    for i, score in enumerate(scores):\n        norm_scores.append(pd.Series(score).rank(pct=True).tolist())\n\n    # Combine scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += weights[j] * norm_scores[j][i]\n        combined_scores.append(combined_score)\n\n    # Sort results\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)\n\n    # Return top_k results\n    return ids[0][sorted_indices[:top_k]], combined_scores[sorted_indices[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError('The length of the ids and scores tuples must match.')\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError('The length of the weights tuple must match the length of the ids and scores tuples.')\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError('The sum of the weights must equal 1.')\n\n    # Create a dataframe to store the ids and scores from each retrieval result\n    df = pd.DataFrame()\n    for i, (id_list, score_list) in enumerate(zip(ids, scores)):\n        df[f'id_{i}'] = id_list\n        df[f'score_{i}'] = score_list\n\n    # Normalize the scores for each retrieval result\n    for i in range(len(ids)):\n        df[f'norm_score_{i}'] = df[f'score_{i}'] / df[f'score_{i}'].max()\n\n    # Combine the scores based on the weights\n    df['fused_score'] = 0\n    for i, weight in enumerate(weights):\n        df['fused_score'] += df[f'norm_score_{i}'] * weight\n\n    # Sort the dataframe by the fused_score column in descending order\n    df = df.sort_values(by='fused_score', ascending=False)\n\n    # Select the top_k ids and scores\n    top_ids = df['id_0'].head(top_k).tolist()\n    top_scores = df['fused_score'].head(top_k).tolist()\n\n    return top_ids, top_scores\n    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError('The length of the ids and scores tuples must match.')\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError('The length of the weights tuple must match the length of the ids and scores tuples.')\n\n    # Check if the sum of the weights is equal to "}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must be equal.\")\n\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids and weights tuples must be equal.\")\n\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores\n    scores = [\n        [score / sum(score_list) for score in score_list]\n        for score_list in scores]\n\n    # Combine the scores\n    combined_scores = [\n        sum(score * weight for score, weight in zip(score_list, weights))\n        for score_list in zip(*scores)]\n\n    # Sort the combined scores and select the top_k\n    combined_scores, combined_ids = zip(\n        *sorted(zip(combined_scores, ids[0]), reverse=True))\n\n    return list(combined_ids)[:top_k], list(combined_scores)[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the lengths of ids, scores, and weights are equal\n    if len(ids) != len(scores) or len(ids) != len(weights):\n        raise ValueError(\"The lengths of ids, scores, and weights must be equal.\")\n\n    # Check if the sum of weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of weights must be equal to 1.\")\n\n    # Normalize the scores of each retrieval result based on the provided weights\n    normalized_scores = []\n    for i in range(len(scores)):\n        normalized_scores.append([score * weights[i] for score in scores[i]])\n\n    # Combine the normalized scores of each retrieval result into a single list\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_scores.append(sum([normalized_scores[j][i] for j in range(len(normalized_scores))]))\n\n    # Sort the combined scores in descending order and get the corresponding indices\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)\n\n    # Select the top_k indices based on the sorted indices\n    top_indices = sorted_indices[:top_k]\n\n    # Get the top_k ids and scores based on the top_indices\n    top_ids = []\n    top_scores = []\n    for i in range(len(ids)):\n        top_ids.append([ids[i][j] for j in top_indices])\n        top_scores.append([scores[i][j] for j in top_indices])\n\n    return top_ids, top_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of ids and scores match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of ids and scores must match.\")\n\n    # Check that the length of ids and scores match\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of ids and weights must match.\")\n\n    # Check that the sum of weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of weights must equal 1.\")\n\n    # Normalize the scores\n    normalized_scores = [\n        [s / sum(score_list) for s in score_list]\n        for score_list in scores\n    ]\n\n    # Combine the scores using the convex combination method\n    combined_scores = [\n        [w * s for w, s in zip(weights, score_list)]\n        for score_list in zip(*normalized_scores)\n    ]\n\n    # Select the top_k results based on the combined scores\n    top_k_indices = [\n        [i for i, _ in sorted(enumerate(score_list), key=lambda x: x[1], reverse=True)[:top_k]]\n        for score_list in combined_scores\n    ]\n\n    # Retrieve the top_k ids and scores\n    top_k_ids = [[ids[i][j] for j in indices] for i, indices in enumerate(top_k_indices)]\n    top_k_scores = [[scores[i][j] for j in indices] for i, indices in enumerate(top_k_indices)]\n\n    return top_k_ids, top_k_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores for each retrieval result based on the weights\n    normalized_scores = [\n        [score * weight for score in scores] for scores, weight in zip(scores, weights)]\n\n    # Combine the normalized scores\n    combined_scores = [\n        sum(scores) for scores in zip(*normalized_scores)]\n\n    # Sort the ids and scores based on the combined scores\n    sorted_ids, sorted_scores = zip(*sorted(zip(ids, combined_scores), key=lambda x: x[1], reverse=True))\n\n    # Return the top_k results\n    return sorted_ids[:top_k], sorted_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the lengths of ids and scores match\n    if len(ids) != len(scores):\n        raise ValueError('The lengths of ids and scores must match.')\n\n    # Check that the lengths of ids, scores, and weights match\n    if len(ids) != len(scores) != len(weights):\n        raise ValueError('The lengths of ids, scores, and weights must match.')\n\n    # Check that the sum of weights is 1\n    if sum(weights) != 1:\n        raise ValueError('The sum of weights must be 1.')\n\n    # Normalize the scores for each retrieval result\n    normalized_scores = []\n    for i, score in enumerate(scores):\n        max_score = max(score)\n        min_score = min(score)\n        normalized_score = [(s - min_score) / (max_score - min_score) for s in score]\n        normalized_scores.append(normalized_score)\n\n    # Combine the scores based on the weights\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += normalized_scores[j][i] * weights[j]\n        combined_scores.append(combined_score)\n\n    # Sort the combined scores and get the top_k results\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in sorted_indices]\n    top_scores = [combined_scores[i] for i in sorted_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores of each retrieval result based on the weights\n    normalized_scores = []\n    for i, score in enumerate(scores):\n        normalized_scores.append([s * weights[i] for s in score])\n\n    # Combine the normalized scores of each retrieval result\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_score = 0\n        for j in range(len(normalized_scores)):\n            combined_score += normalized_scores[j][i]\n        combined_scores.append(combined_score)\n\n    # Select the top_k results based on the combined scores\n    top_k_indices = pd.Series(combined_scores).nlargest(top_k).index.tolist()\n    top_k_ids = []\n    top_k_scores = []\n    for i in top_k_indices:\n        top_k_ids.append(ids[0][i])\n        top_k_scores.append(combined_scores[i])\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of ids and scores match\n    if len(ids) != len(scores):\n        raise ValueError('The length of ids and scores must match')\n\n    # Check if the length of ids and weights match\n    if len(ids) != len(weights):\n        raise ValueError('The length of ids and weights must match')\n\n    # Check if the sum of weights is 1\n    if sum(weights) != 1:\n        raise ValueError('The sum of weights must equal 1')\n\n    # Normalize the scores for each retrieval result\n    norm_scores = []\n    for i in range(len(ids)):\n        norm_scores.append([s / max(scores[i]) for s in scores[i]])\n\n    # Combine the normalized scores using the convex combination method\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += weights[j] * norm_scores[j][i]\n        combined_scores.append(combined_score)\n\n    # Sort the combined scores in descending order and select the top_k results\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)\n    top_indices = sorted_indices[:top_k]\n\n    # Get the fused ids and scores\n    fused_ids = []\n    fused_scores = []\n    for i in top_indices:\n        for j in range(len(ids)):\n            fused_ids.append(ids[j][i])\n            fused_scores.append(combined_scores[i])\n\n    # Return the fused ids and scores\n    return fused_ids, fused_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the weights sum to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must be equal to 1.\")\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check if the length of each list within the ids and scores tuples matches\n    for i in range(len(ids)):\n        if len(ids[i]) != len(scores[i]):\n            raise ValueError(\"The length of each list within the ids and scores tuples must match.\")\n\n    # Normalize the scores of each retrieval result based on the weights\n    normalized_scores = []\n    for i in range(len(ids)):\n        normalized_scores.append([score * weights[i] for score in scores[i]])\n\n    # Combine the normalized scores into a single list\n    combined_scores = [sum(x) for x in zip(*normalized_scores)]\n\n    # Create a pandas DataFrame with the combined scores\n    df = pd.DataFrame({'ids': ids[0], 'scores': combined_scores})\n\n    # Sort the DataFrame by the scores in descending order\n    df = df.sort_values(by='scores', ascending=False)\n\n    # Select the top_k results based on the scores\n    top_ids = df['ids'].tolist()[:top_k]\n    top_scores = df['scores'].tolist()[:top_k]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the lengths of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The lengths of the ids and scores tuples must be the same.\")\n\n    # Check that the lengths of the ids and scores tuples match the length of the weights tuple\n    if len(ids) != len(weights):\n        raise ValueError(\"The lengths of the ids and scores tuples must be the same as the length of the weights tuple.\")\n\n    # Check that the sum of the weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores\n    normalized_scores = [\n        [score / sum(scores[i]) for score in scores[i]]\n        for i in range(len(ids))\n    ]\n\n    # Combine the scores using the convex combination method\n    combined_scores = [\n        sum([normalized_scores[i][j] * weights[i] for i in range(len(ids))])\n        for j in range(len(ids[0]))\n    ]\n\n    # Select the top_k results\n    top_k_ids = [ids[0][i] for i in range(len(ids[0])) if combined_scores[i] in sorted(combined_scores, reverse=True)[:top_k]]\n    top_k_scores = [combined_scores[i] for i in range(len(ids[0])) if combined_scores[i] in sorted(combined_scores, reverse=True)[:top_k]]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores of each retrieval result based on the weights\n    norm_scores = []\n    for i, score in enumerate(scores):\n        norm_scores.append([s * weights[i] for s in score])\n\n    # Combine the scores of each retrieval result\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_scores.append(sum([score[i] for score in norm_scores]))\n\n    # Sort the combined scores and select the top_k results\n    sorted_indices = sorted(range(len(combined_scores)), key=lambda k: combined_scores[k], reverse=True)\n    top_indices = sorted_indices[:top_k]\n\n    # Return the fused ids and scores\n    return ([ids[i][j] for j in top_indices] for i in range(len(ids))), ([combined_scores[i] for i in top_indices])"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores):\n        raise ValueError('The length of ids and scores must be equal.')\n\n    if len(ids) != len(weights):\n        raise ValueError('The length of ids and weights must be equal.')\n\n    if sum(weights) != 1:\n        raise ValueError('The sum of weights must equal 1.')\n\n    # Normalize the scores\n    scores = [\n        [s / max(s) for s in score]\n        for score in scores\n    ]\n\n    # Combine the scores using convex combination\n    combined_scores = [\n        [w * s for w, s in zip(weights, score)]\n        for score in zip(*scores)\n    ]\n\n    # Sort the combined scores and select the top k\n    top_k_indices = pd.Series(combined_scores).sort_values(ascending=False).head(top_k).index\n\n    # Get the corresponding ids and scores\n    top_k_ids = [id[i] for id, i in zip(ids, top_k_indices)]\n    top_k_scores = [combined_scores[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x == 0:\n        return \"0\"\n    if x < 1e-4:\n        return f\"{x:.2e}\"\n    if x < 0.001:\n        return f\"{x:.4f}\"\n    if x < 0.01:\n        return f\"{x:.3f}\"\n    if x < 0.1:\n        return f\"{x:.2f}\"\n    if x < 1:\n        return f\"{x:.1f}\"\n    if x < 10:\n        return f\"{x:.0f}\"\n    if x < 100:\n        return f\"{x:.0f}\"\n    if x < 1000:\n        return f\"{x:.0f}\"\n    if x < 10000:\n        return f\"{x:.0f}\"\n    if x < 100000:\n        return f\"{x:.0f}\"\n    if x < 1000000:\n        return f\"{x:.0f}\"\n    if x < 10000000:\n        return f\"{x:.0f}\"\n    if x < 100000000:\n        return f\"{x:.0f}\"\n    if x < 1000000000:\n        return f\"{x:.0f}\"\n    if x < 10000000000:\n        return f\"{x:.0f}\"\n    if x < 100000000000:\n        return f\"{x:.0f}\"\n    if x < 1000000000000:\n        return f\"{x:.0f}\"\n    if x < 10000000000000:\n        return f\"{x:.0f}\"\n    if x < 100000000000000:\n        return f\"{x:.0f}\"\n    if x < 1000000000000000:\n        return f\"{x:.0f"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n    if x > 1e-10:\n        return f\"{x:.3f}\"\n    if x > 1e-15:\n        return f\"{x:.4f}\"\n    if x > 1e-20:\n        return f\"{x:.5f}\"\n    if x > 1e-25:\n        return f\"{x:.6f}\"\n    if x > 1e-30:\n        return f\"{x:.7f}\"\n    if x > 1e-35:\n        return f\"{x:.8f}\"\n    if x > 1e-40:\n        return f\"{x:.9f}\"\n    if x > 1e-45:\n        return f\"{x:.10f}\"\n    if x > 1e-50:\n        return f\"{x:.11f}\"\n    if x > 1e-55:\n        return f\"{x:.12f}\"\n    if x > 1e-60:\n        return f\"{x:.13f}\"\n    if x > 1e-65:\n        return f\"{x:.14f}\"\n    if x > 1e-70:\n        return f\"{x:.15f}\"\n    if x > 1e-75:\n        return f\"{x:.16f}\"\n    if x > 1e-80:\n        return f\"{x:.17f}\"\n    if x > 1e-85:\n        return f\"{x:.18f}\"\n    if x > 1e-90:\n        return f\"{x:.19f}\"\n    if x > 1e-95:\n        return f\"{x:.20f}\"\n    if x > 1e-100:\n        return f\"{x:.21f}\"\n    if x > 1e-105:\n        return f\"{x:.22f}\"\n    if x > 1e-110:\n        return f\"{x:.23f}\"\n    if x > 1e-115:\n        return f\"{x:.24f}\"\n    if x > 1e-120:\n        return"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if abs(x) < 1e-3:\n        return f\"{x:.6f}\"\n    if abs(x) < 1e-2:\n        return f\"{x:.5f}\"\n    if abs(x) < 1e-1:\n        return f\"{x:.4f}\"\n    if abs(x) < 1:\n        return f\"{x:.3f}\"\n    if abs(x) < 1e1:\n        return f\"{x:.2f}\"\n    if abs(x) < 1e2:\n        return f\"{x:.1f}\"\n    if abs(x) < 1e3:\n        return f\"{x:.0f}\"\n    if abs(x) < 1e4:\n        return f\"{x:.1f}k\"\n    if abs(x) < 1e5:\n        return f\"{x:.0f}k\"\n    if abs(x) < 1e6:\n        return f\"{x:.1f}M\"\n    if abs(x) < 1e7:\n        return f\"{x:.0f}M\"\n    if abs(x) < 1e8:\n        return f\"{x:.1f}B\"\n    if abs(x) < 1e9:\n        return f\"{x:.0f}B\"\n    if abs(x) < 1e10:\n        return f\"{x:.1f}T\"\n    if abs(x) < 1e11:\n        return f\"{x:.0f}T\"\n    if abs(x) < 1e12:\n        return f\"{x:.1f}Q\"\n    if abs(x) < 1e13:\n        return f\"{x:.0f}Q\"\n    return f\"{x:.1f}P\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0\"\n    if x < 1e-10:\n        return \"<1e-10\"\n    if x < 1e-8:\n        return f\"{x:.1e}\"\n    if x < 1e-6:\n        return f\"{x:.2e}\"\n    if x < 1e-4:\n        return f\"{x:.3e}\"\n    if x < 1e-2:\n        return f\"{x:.4e}\"\n    if x < 1:\n        return f\"{x:.5e}\"\n    if x < 10:\n        return f\"{x:.6e}\"\n    if x < 100:\n        return f\"{x:.7e}\"\n    if x < 1000:\n        return f\"{x:.8e}\"\n    if x < 10000:\n        return f\"{x:.9e}\"\n    return f\"{x:.10e}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x < 0.001:\n        return f\"{x:.2e}\"\n    if x < 0.01:\n        return f\"{x:.3f}\"\n    if x < 0.1:\n        return f\"{x:.4f}\"\n    if x < 1:\n        return f\"{x:.5f}\"\n    if x < 10:\n        return f\"{x:.4f}\"\n    if x < 100:\n        return f\"{x:.3f}\"\n    if x < 1000:\n        return f\"{x:.2f}\"\n    if x < 10000:\n        return f\"{x:.1f}\"\n    if x < 100000:\n        return f\"{x:.0f}\"\n    if x < 1000000:\n        return f\"{x:.0f}k\"\n    if x < 10000000:\n        return f\"{x:.0f}M\"\n    if x < 100000000:\n        return f\"{x:.0f}B\"\n    return f\"{x:.0f}T\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x >= 1000000:\n        return f\"{x / 1000000:.2f}M\"\n    if x >= 1000:\n        return f\"{x / 1000:.2f}K\"\n    if x >= 100:\n        return f\"{x:.2f}\"\n    if x >= 10:\n        return f\"{x:.1f}\"\n    if x >= 1:\n        return f\"{x:.2f}\"\n    if x >= 0.1:\n        return f\"{x:.3f}\"\n    if x >= 0.01:\n        return f\"{x:.4f}\"\n    if x >= 0.001:\n        return f\"{x:.5f}\"\n    if x >= 0.0001:\n        return f\"{x:.6f}\"\n    if x >= 0.00001:\n        return f\"{x:.7f}\"\n    if x >= 0.000001:\n        return f\"{x:.8f}\"\n    if x >= 0.0000001:\n        return f\"{x:.9f}\"\n    return f\"{x:.10f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x >= 1e6:\n        return f\"{x / 1e6:.2f}M\"\n    if x >= 1e3:\n        return f\"{x / 1e3:.2f}K\"\n    return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n        suffix = \"%\"\n    else:\n        suffix = \"\"\n\n    if abs(x) >= 1000:\n        return f\"{x:.0f}{suffix}\"\n    if abs(x) >= 100:\n        return f\"{x:.1f}{suffix}\"\n    if abs(x) >= 10:\n        return f\"{x:.2f}{suffix}\"\n    return f\"{x:.3f}{suffix}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        x = round(x, 2)\n        return f\"{x}%\"\n    if x == 0:\n        return \"0\"\n    if abs(x) < 1e-3:\n        return f\"{x:.2e}\"\n    if abs(x) < 1e-2:\n        return f\"{x:.3f}\"\n    if abs(x) < 1e-1:\n        return f\"{x:.4f}\"\n    if abs(x) < 1:\n        return f\"{x:.5f}\"\n    if abs(x) < 10:\n        return f\"{x:.4f}\"\n    if abs(x) < 100:\n        return f\"{x:.3f}\"\n    if abs(x) < 1000:\n        return f\"{x:.2f}\"\n    if abs(x) < 10000:\n        return f\"{x:.1f}\"\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x >= 1000:\n        return f\"{x:.0f}\"\n    if x >= 100:\n        return f\"{x:.1f}\"\n    if x >= 10:\n        return f\"{x:.2f}\"\n    return f\"{x:.3f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x < 1e-3:\n        return f\"{x:.3e}\"\n    if x < 1e-2:\n        return f\"{x:.4f}\"\n    if x < 1e-1:\n        return f\"{x:.3f}\"\n    if x < 1:\n        return f\"{x:.2f}\"\n    if x < 10:\n        return f\"{x:.1f}\"\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        return f\"{x:.1f}%\"\n    if x < 1e-4:\n        return f\"{x:.4e}\"\n    if x < 1e-2:\n        return f\"{x:.3f}\"\n    if x < 1e-1:\n        return f\"{x:.2f}\"\n    if x < 1:\n        return f\"{x:.1f}\"\n    if x < 10:\n        return f\"{x:.0f}\"\n    if x < 100:\n        return f\"{x:.1f}\"\n    if x < 1000:\n        return f\"{x:.0f}\"\n    return f\"{x:.1e}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        x = round(x, 2)\n        return f\"{x}%\"\n    if x > 100:\n        return f\"{round(x, 2)}\"\n    if x > 10:\n        return f\"{round(x, 3)}\"\n    if x > 1:\n        return f\"{round(x, 4)}\"\n    if x > 0.1:\n        return f\"{round(x, 5)}\"\n    if x > 0.01:\n        return f\"{round(x, 6)}\"\n    if x > 0.001:\n        return f\"{round(x, 7)}\"\n    return f\"{round(x, 8)}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    else:\n        if x >= 1000000:\n            return f\"{x/1000000:.2f}M\"\n        elif x >= 1000:\n            return f\"{x/1000:.2f}K\"\n        elif x >= 100:\n            return f\"{x:.0f}\"\n        elif x >= 10:\n            return f\"{x:.1f}\"\n        else:\n            return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x < 0.01:\n        return f\"{x:.4f}\"\n    if x < 0.1:\n        return f\"{x:.3f}\"\n    if x < 1:\n        return f\"{x:.2f}\"\n    if x < 10:\n        return f\"{x:.1f}\"\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n\n    if percent:\n        x *= 100\n        x = round(x, 2)\n        return f\"{x}%\"\n\n    if x < 0.01:\n        x = round(x, 6)\n    elif x < 0.1:\n        x = round(x, 5)\n    elif x < 1:\n        x = round(x, 4)\n    elif x < 10:\n        x = round(x, 3)\n    elif x < 100:\n        x = round(x, 2)\n    else:\n        x = round(x, 1)\n    return str(x)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        s = \"%\"\n    else:\n        s = \"\"\n    if x < 0.001:\n        return f\"{x:.3e}{s}\"\n    elif x < 0.01:\n        return f\"{x:.4f}{s}\"\n    elif x < 0.1:\n        return f\"{x:.3f}{s}\"\n    elif x < 1:\n        return f\"{x:.2f}{s}\"\n    elif x < 10:\n        return f\"{x:.1f}{s}\"\n    elif x < 100:\n        return f\"{x:.0f}{s}\"\n    else:\n        return f\"{x:.1e}{s}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n        return f\"{x:.1f}%\"\n    if x == 0:\n        return \"0\"\n    if abs(x) < 1e-3:\n        return f\"{x:.3e}\"\n    if abs(x) < 1e-2:\n        return f\"{x:.4f}\"\n    if abs(x) < 1e-1:\n        return f\"{x:.5f}\"\n    if abs(x) < 1:\n        return f\"{x:.6f}\"\n    if abs(x) < 10:\n        return f\"{x:.7f}\"\n    if abs(x) < 100:\n        return f\"{x:.8f}\"\n    return f\"{x:.9f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n\n    if percent:\n        x *= 100\n        s = \"%\"\n    else:\n        s = \"\"\n\n    if x < 1e-3:\n        return f\"{x:.3e}{s}\"\n    elif x < 1e-2:\n        return f\"{x:.4f}{s}\"\n    elif x < 1e-1:\n        return f\"{x:.3f}{s}\"\n    elif x < 1:\n        return f\"{x:.2f}{s}\"\n    elif x < 10:\n        return f\"{x:.1f}{s}\"\n    else:\n        return f\"{x:.0f}{s}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(np.nan)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x > 10000:\n        return f\"{x:.0f}\"\n    elif x > 1000:\n        return f\"{x:.1f}\"\n    elif x > 100:\n        return f\"{x:.2f}\"\n    elif x > 10:\n        return f\"{x:.3f}\"\n    else:\n        return f\"{x:.4f}\"\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024 * 1024 * 1024)\n        if free_space_in_gb > threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024 * 1024 * 1024)\n        if free_space_in_gb < threshold_in_gb:\n            logger.info(f\"Disk usage of {input_dir} is lower than the threshold of {threshold_in_gb} GB.\")\n            break\n        else:\n            logger.info(f\"Disk usage of {input_dir} is {free_space_in_gb} GB, which is higher than the threshold of {threshold_in_gb} GB.\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            free_space_in_gb = shutil.disk_usage(input_dir).free / (2 ** 30)\n            if free_space_in_gb < threshold_in_gb:\n                break\n            sleep(sleep_time)\n        except Exception as e:\n            logger.error(f\"Error while checking disk usage: {e}\")\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            free_space_in_gb = int(os.statvfs(input_dir).f_frsize * os.statvfs(input_dir).f_bavail / 1e9)\n            if free_space_in_gb < threshold_in_gb:\n                break\n        except Exception:\n            pass\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free\n        if free_space < threshold_in_gb * 1e9:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space_in_gb = int(os.statvfs(input_dir).f_bavail * os.statvfs(input_dir).f_frsize / 1e9)\n        if free_space_in_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free\n        if free_space < threshold_in_gb * 1024 * 1024 * 1024:\n            logger.warning(\n                f\"Waiting for free space in {input_dir} to be higher than {threshold_in_gb} GB. \"\n                f\"Current free space: {free_space / 1024 / 1024 / 1024:.2f} GB.\"\n            )\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024 ** 3)\n        if free_space_in_gb < threshold_in_gb:\n            logger.info(f\"Free space in {input_dir} is {free_space_in_gb} GB, which is lower than the threshold of {threshold_in_gb} GB.\")\n            break\n        else:\n            logger.info(f\"Free space in {input_dir} is {free_space_in_gb} GB, which is higher than the threshold of {threshold_in_gb} GB. Sleeping for {sleep_time} seconds...\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024 ** 3)\n        if free_space_in_gb > threshold_in_gb:\n            return\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free // (2 ** 30)\n        if free_gb < threshold_in_gb:\n            logger.warning(f\"Free disk space: {free_gb} GB, waiting for free disk space to be higher than {threshold_in_gb} GB\")\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space_in_gb = int(os.statvfs(input_dir).f_bavail * os.statvfs(input_dir).f_frsize / 1024 / 1024 / 1024)\n        if free_space_in_gb < threshold_in_gb:\n            logger.info(f\"Free space: {free_space_in_gb} GB\")\n            break\n        else:\n            logger.info(f\"Free space: {free_space_in_gb} GB\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space_in_gb = int(shutil.disk_usage(input_dir).free / 1e9)\n        if free_space_in_gb < threshold_in_gb:\n            return\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free / (1024 ** 3)\n        if free_space < threshold_in_gb:\n            logger.info(f\"Disk usage of {input_dir} is lower than the threshold of {threshold_in_gb} GB.\")\n            break\n        else:\n            logger.info(f\"Disk usage of {input_dir} is higher than the threshold of {threshold_in_gb} GB. Waiting for {sleep_time} seconds.\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024 * 1024 * 1024)\n        if free_space_in_gb > threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free < threshold_in_gb * 1024 * 1024 * 1024:\n            logger.info(f\"Free disk space is {free} bytes, waiting for {sleep_time} seconds before checking again\")\n            sleep(sleep_time)\n        else:\n            logger.info(f\"Free disk space is {free} bytes, threshold is {threshold_in_gb} GB\")\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            free_space = shutil.disk_usage(input_dir).free / (1024 * 1024 * 1024)\n            if free_space > threshold_in_gb:\n                return\n        except Exception:\n            pass\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            total, used, free = shutil.disk_usage(input_dir)\n            free_in_gb = free // (2 ** 30)\n            if free_in_gb < threshold_in_gb:\n                sleep(sleep_time)\n            else:\n                break\n        except Exception:\n            logger.warning(f\"Could not check disk usage for {input_dir}.\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free < threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free / (2 ** 30) < threshold_in_gb:\n            logger.info(f\"Free disk space: {free / (2 ** 30)} GB\")\n            sleep(sleep_time)\n        else:\n            logger.info(f\"Free disk space: {free / (2 ** 30)} GB\")\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space_in_bytes = shutil.disk_usage(input_dir).free\n        free_space_in_gb = free_space_in_bytes / (1024 * 1024 * 1024)\n        if free_space_in_gb < threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.strip()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print(line_text)\n    # print(\"Fix Spaced Characters\")\n    # print("}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    line_text = line_text.split()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.strip()\n    line_text = line_text.split()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.strip()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.strip()\n\n    # segment the modified text into smaller parts or tokens\n    line_text_list = segmenter(line_text)\n\n    return line_text, line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove all whitespace characters from the input text\n    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n\n    # segment the modified text into smaller parts or tokens\n    line_text_list = line_text.split()\n\n    return line_text, line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    line_text_list = line_text.split()\n\n    return line_text, line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    line_text = line_text.split()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.strip()\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # print(\"Fix Spaced Characters\")\n    # print(\"-\" * 50)\n    # print(line_text)\n\n    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\r\", \"\")\n    line_text = line_text.strip()\n\n    # print(\"Modified Text\")\n    # print(\"-\" * 50)\n    # print(line_text)\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove all whitespace characters\n    line_text = line_text.replace(\" \", \"\")\n\n    # segment the text into smaller parts or tokens\n    line_text_list = sent_tokenize(line_text)\n\n    return line_text, line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    line_text_list = line_text.split()\n    return line_text, line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n\n    line_text_list = line_text.split()\n\n    return line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\"\\n\", \" \")\n    line_text = line_text.replace(\"\\t\", \" \")\n    line_text = line_text.strip()\n    line_text_list = sent_tokenize(line_text)\n\n    return line_text, line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.strip()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # remove all whitespace characters\n    line_text = line_text.replace(\" \", \"\")\n\n    # segment the modified text\n    line_text_list = segment_text(line_text)\n\n    return line_text_list\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.strip()\n\n    return line_text\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n    weights = np.random.rand(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(np.arange(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n    return weights / np.sum(weights)\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the total number of weights.\")\n\n    weights = np.random.rand(n - zeros)\n    weights /= weights.sum()\n\n    if zeros > 0:\n        zeros_idx = np.random.choice(n, zeros, replace=False)\n        weights[zeros_idx] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n - zeros)\n    weights /= weights.sum()\n\n    if zeros > 0:\n        weights = np.concatenate((weights, np.zeros(zeros)))\n        np.random.shuffle(weights)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n    weights = np.random.rand(n)\n    weights[np.random.choice(n, zeros, replace=False)] = 0\n    return weights / np.sum(weights)\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n    weights = np.random.rand(n - zeros)\n    if zeros > 0:\n        zero_weights = np.zeros(zeros)\n        weights = np.concatenate((weights, zero_weights))\n    return weights / np.sum(weights)\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"`zeros` must be less than or equal to `n`\")\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n    else:\n        weights = np.random.dirichlet(np.ones(n - zeros))\n        zeros_indices = np.random.choice(n, size=zeros, replace=False)\n        weights = np.insert(weights, zeros_indices, 0)\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    if zeros == 0:\n        return np.random.rand(n) / np.sum(np.random.rand(n))\n\n    if zeros == n:\n        return np.zeros(n)\n\n    non_zero_weights = np.random.rand(n - zeros) / np.sum(np.random.rand(n - zeros))\n    zero_weights = np.zeros(zeros)\n    weights = np.concatenate([non_zero_weights, zero_weights])\n    np.random.shuffle(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero-weights cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        zero_indices = np.random.choice(np.arange(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n - zeros)\n    if zeros > 0:\n        zeros_idx = np.random.choice(n, zeros, replace=False)\n        weights = np.insert(weights, zeros_idx, 0)\n\n    return weights / weights.sum()\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n - zeros)\n    if zeros > 0:\n        weights = np.append(weights, np.zeros(zeros))\n    weights = weights / weights.sum()\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    if zeros == 0:\n        weights = np.random.rand(n)\n        weights /= weights.sum()\n        return weights\n\n    # Generate random weights\n    weights = np.random.rand(n - zeros)\n\n    # Normalize weights\n    weights /= weights.sum()\n\n    # Add zeros to the weights\n    zeros_array = np.zeros(zeros)\n    weights = np.concatenate((weights, zeros_array))\n\n    # Shuffle the weights\n    np.random.shuffle(weights)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"Number of zeros must not exceed the total number of weights.\")\n    weights = np.random.rand(n - zeros)\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n    return weights / np.sum(weights)\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"zeros must not exceed n.\")\n    weights = np.random.rand(n - zeros)\n    weights = weights / weights.sum()\n    if zeros > 0:\n        weights = np.pad(weights, (0, zeros))\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n - zeros)\n    weights /= weights.sum()\n\n    if zeros > 0:\n        zeros_idx = np.random.choice(n, size=zeros, replace=False)\n        weights[zeros_idx] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"Number of zeros cannot be greater than the number of weights\")\n\n    if zeros == 0:\n        return np.random.rand(n) / np.sum(np.random.rand(n))\n    else:\n        weights = np.random.rand(n - zeros) / np.sum(np.random.rand(n - zeros))\n        zeros_idx = np.random.choice(n, zeros, replace=False)\n        weights = np.insert(weights, zeros_idx, 0)\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"`zeros` must be less than or equal to `n`\")\n    if zeros == 0:\n        return np.random.rand(n) / np.sum(np.random.rand(n))\n    else:\n        weights = np.random.rand(n - zeros) / np.sum(np.random.rand(n - zeros))\n        zeros_idx = np.random.choice(n, zeros, replace=False)\n        weights_with_zeros = np.zeros(n)\n        weights_with_zeros[zeros_idx] = 0\n        weights_with_zeros[~np.isin(np.arange(n), zeros_idx)] = weights\n        return weights_with_zeros\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(np.arange(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights / weights.sum()\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"Number of zeros cannot exceed the number of weights.\")\n\n    weights = np.random.rand(n - zeros)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        weights = np.append(weights, np.zeros(zeros))\n        np.random.shuffle(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros < 0:\n        raise ValueError(\"Number of zeros must be a non-negative integer.\")\n    if zeros > n:\n        raise ValueError(\"Number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n)\n    if zeros > 0:\n        weights[np.random.choice(n, size=zeros, replace=False)] = 0\n    weights /= weights.sum()\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros < 0 or zeros > n:\n        raise ValueError(\n            \"The number of zero weights (zeros) must be between 0 and n.\"\n        )\n\n    weights = np.random.rand(n - zeros)\n    weights = weights / np.sum(weights)\n\n    if zeros > 0:\n        zeros_weights = np.zeros(zeros)\n        weights = np.concatenate((weights, zeros_weights))\n\n    return weights\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type')\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict[\"module_type\"]\n        module_param = module_dict.copy()\n        module_param.pop(\"module_type\")\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict[\"module_type\"]\n        module_param = deepcopy(module_dict)\n        del module_param[\"module_type\"]\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict[\"module_type\"]\n        module_param = deepcopy(module_dict)\n        module_param.pop(\"module_type\")\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict[\"module_type\"]\n        module_param = deepcopy(module_dict)\n        del module_param[\"module_type\"]\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = module_dict.copy()\n        module_param.pop('module_type')\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict[\"module_type\"]\n        module_param = deepcopy(module_dict)\n        del module_param[\"module_type\"]\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type, module_param)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cropping region in an image, ensuring that the region contains the center of a specified instance. The cropping region is determined based on the instance's bounding box and the desired crop size, with adjustments to ensure it fits within the image boundaries.\n    # Generate a CropTransform object that defines a cro"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    box = instance[\"bbox\"]\n    box_mode = instance[\"bbox_mode\"]\n    box = BoxMode.convert(box, box_mode, BoxMode.XYXY_ABS)\n    box = np.minimum(box, list(image_size + image_size)[::-1])\n    box = np.maximum(box, [0, 0])\n    box_wh = box[2:] - box[:2]\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, list(image_size + image_size)[::-1])\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.minimum(crop_size, box_wh)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"bbox\" in instance:\n        # Transform instance bounding box\n        bbox = BoxMode.convert(\n            instance[\"bbox\"],\n            instance[\"bbox_mode\"],\n            BoxMode.XYXY_ABS,\n        )\n        bbox = bbox.clip(min=0)\n        bbox = bbox.scale(crop_size)\n        bbox = bbox.clip(min=0)\n        bbox = bbox.scale(image_size)\n        bbox = bbox.clip(min=0)\n        bbox = bbox.scale(crop_size)\n        bbox = bbox.clip(min=0)\n\n        # Transform instance mask\n        if \"segmentation\" in instance:\n            mask = instance[\"segmentation\"]\n            if isinstance(mask, list):\n                # polygons\n                polygons = [np.asarray(p).reshape(-1, 2) for p in mask]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]\n                polygons = [p.reshape(-1) for p in polygons]"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    box = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    box = np.array(box)\n    box = box - np.array(crop_size) / 2\n    box = np.maximum(box, np.array([0, 0]))\n    box = np.minimum(box, np.array(image_size) - np.array(crop_size))\n    return T.CropTransform(box, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the instance's bounding box\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the top-left corner of the crop\n    top_left = np.array([bbox[0], bbox[1]]) - np.array(crop_size) / 2\n\n    # Clip the top-left corner to the image boundaries\n    top_left = np.maximum(top_left, np.array([0, 0]))\n    top_left = np.minimum(top_left, np.array(image_size) - np.array(crop_size))\n\n    # Calculate the dimensions of the crop\n    crop_dims = np.array(crop_size)\n\n    # Create a CropTransform object with the specified parameters\n    crop_transform = T.CropTransform(top_left, crop_dims)\n\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the bounding box to the format expected by the CropTransform object\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the bounding box\n    center = np.array([bbox[0] + bbox[2], bbox[1] + bbox[3]]) / 2\n\n    # Calculate the top-left corner of the cropping region based on the center and the desired crop size\n    top_left = np.array([center[0] - crop_size[0] / 2, center[1] - crop_size[1] / 2])\n\n    # Ensure the cropping region fits within the image boundaries\n    top_left = np.maximum(top_left, np.array([0, 0]))\n    top_left = np.minimum(top_left, np.array(image_size) - np.array(crop_size))\n\n    # Return a CropTransform object with the specified parameters\n    return T.CropTransform(top_left, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the bounding box to the format used by the CropTransform class\n    box = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the top-left corner of the crop based on the bounding box and the desired crop size\n    top_left = np.array([box[0] - crop_size[0] / 2, box[1] - crop_size[1] / 2])\n\n    # Ensure the crop fits within the image boundaries\n    top_left = np.maximum(top_left, np.zeros(2))\n    top_left = np.minimum(top_left, np.array(image_size) - np.array(crop_size))\n\n    # Return the CropTransform object with the specified parameters\n    return T.CropTransform(top_left, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"bbox\" not in instance:\n        raise ValueError(\n            \"Cannot crop the instance without its bounding box!\"\n            \"Supported keys are: bbox, bbox_mode.\"\n        )\n    if \"bbox_mode\" not in instance:\n        raise ValueError(\n            \"Cannot crop the instance without its bounding box mode!\"\n            \"Supported keys are: bbox, bbox_mode.\"\n        )\n\n    # Ensure the crop fits within the image boundaries\n    crop_size = np.minimum(crop_size, image_size)\n\n    # Transform the instance's bounding box to the desired crop size\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = np.array([bbox[0], bbox[1], bbox[0] + crop_size[0], bbox[1] + crop_size[1]])\n\n    # Clip the transformed bounding box to the image boundaries\n    bbox = np.maximum(bbox, [0, 0, *image_size])\n    bbox = np.minimum(bbox, [*image_size, *image_size])\n\n    # Calculate the top-left corner of the crop based on the transformed bounding box\n    top_left = np.array([bbox[0], bbox[1]])\n\n    # Calculate the dimensions of the crop based on the transformed bounding box\n    dimensions = np.array([bbox[2] - bbox[0], bbox[3] - bbox[1]])\n\n    # Return the CropTransform object with the specified parameters\n    return T.CropTransform(top_left, dimensions)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    box = instance[\"bbox\"]\n\n    # Get the top-left corner of the bounding box\n    top_left = (box[0], box[1])\n\n    # Get the dimensions of the bounding box\n    dimensions = (box[2] - box[0], box[3] - box[1])\n\n    # Get the center of the bounding box\n    center = (top_left[0] + dimensions[0] / 2, top_left[1] + dimensions[1] / 2)\n\n    # Get the top-left corner of the crop\n    top_left_crop = (center[0] - crop_size[0] / 2, center[1] - crop_size[1] / 2)\n\n    # Get the dimensions of the crop\n    dimensions_crop = crop_size\n\n    # Get the top-left corner of the image\n    top_left_image = (0, 0)\n\n    # Get the dimensions of the image\n    dimensions_image = image_size\n\n    # Create a CropTransform object that defines the crop\n    crop_transform = T.CropTransform(\n        top_left_crop, dimensions_crop, top_left_image, dimensions_image\n    )\n\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Calculate the desired crop size\n    crop_size = np.array(crop_size)\n    image_size = np.array(image_size)\n    crop_size = np.minimum(crop_size, image_size)\n\n    # Calculate the top-left corner of the crop\n    top_left = np.array(instance[\"bbox\"])[:2]\n    top_left = top_left - crop_size / 2\n    top_left = np.maximum(top_left, [0, 0])\n    top_left = np.minimum(top_left, image_size - crop_size)\n\n    # Calculate the dimensions of the crop\n    crop_size = np.minimum(crop_size, image_size - top_left)\n\n    # Create the CropTransform object\n    crop_transform = T.CropTransform(top_left, crop_size)\n\n    # Return the CropTransform object\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Adjust crop size to fit within image boundaries\n    crop_size = np.minimum(crop_size, image_size)\n\n    # Adjust crop size to ensure that the region contains the center of the instance\n    instance_xyxy = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    instance_xyxy = np.array(instance_xyxy)\n    instance_xyxy = instance_xyxy.reshape(-1, 2)\n    instance_xy = instance_xyxy.mean(axis=0)\n    instance_xy = np.array(instance_xy)\n    instance_xy = instance_xy.reshape(-1, 2)\n    crop_xy = instance_xy - crop_size / 2\n    crop_xy = crop_xy.reshape(-1, 2)\n\n    # Ensure that the crop is within the image boundaries\n    crop_xy = np.maximum(crop_xy, np.array([0, 0]))\n    crop_xy = crop_xy.reshape(-1, 2)\n    crop_xy = np.minimum(crop_xy, np.array(image_size) - crop_size)\n    crop_xy = crop_xy.reshape(-1, 2)\n\n    # Define the cropping region\n    crop_transform = T.CropTransform(crop_xy, crop_size)\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.array(crop_size)\n    image_size = np.array(image_size)\n    instance = dict(instance)\n    bbox = np.array(instance[\"bbox\"])\n    bbox_mode = BoxMode.convert(instance[\"bbox_mode\"], BoxMode.XYXY_ABS, BoxMode.XYXY_ABS)\n\n    # Calculate the top-left corner of the crop\n    top_left = np.maximum(bbox[:2] - crop_size / 2, 0)\n    top_left = np.minimum(top_left, image_size - crop_size)\n\n    # Calculate the dimensions of the crop\n    crop_dims = np.minimum(crop_size, image_size - top_left)\n\n    # Create the CropTransform object\n    crop_transform = T.CropTransform(top_left, crop_dims)\n\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    bbox = np.minimum(bbox, image_size)\n    bbox = np.maximum(bbox, [0, 0])\n    bbox = np.array(bbox, dtype=np.float32)\n    crop_size = np.array(crop_size, dtype=np.float32)\n    crop_size = np.minimum(crop_size, image_size)\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.array(crop_size, dtype=np.float32)\n    crop_size = crop_size / 2\n    bbox_wh = bbox[2:] - bbox[:2]\n    bbox_wh = np.maximum(bbox_wh, crop_size)\n    crop_size = bbox_wh - crop_size\n    crop_size = np.maximum(crop_size, [1, 1])\n    crop_size = np.array(crop_size, dtype=np.float32)\n    crop_size = crop_size / 2\n    crop_size = crop_size + bbox[:2]\n    crop_size = np.maximum(crop_size, [0, 0])\n    crop_size = np.minimum(crop_size, image_size)\n    crop_size = np.array(crop_size, dtype=np.float32)\n    crop_size = crop_size - bbox[:2]\n    crop_size = np.maximum(crop_size, [0, 0])\n    crop_size = np.minimum(crop_size, image_size)\n    crop_size = np.array(crop_size, dtype=np.float32)\n    crop_size = crop_size / 2\n    crop_size = crop_size + bbox[:2]\n    crop_size = np.maximum(crop_size, [0, 0])\n    crop_size = np.minimum(crop_size, image_size)\n    crop_size = np.array(crop_size, dtype=np.float32)\n    crop_size = crop_size - bbox[:"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"width\" in instance or \"height\" in instance:\n        image_wh = (instance[\"width\"], instance[\"height\"])\n        expected_wh = (crop_size[0], crop_size[1])\n        if not image_wh == expected_wh:\n            raise SizeMismatchError(\n                \"Mismatched image shape{}, got {}, expect {}.\".format(\n                    \" for image \" + instance[\"file_name\"] if \"file_name\" in instance else \"\",\n                    image_wh,\n                    expected_wh,\n                )\n                + \" Please check the width/height in your annotation.\"\n            )\n\n    # To ensure bbox always remap to original image size\n    if \"width\" not in instance:\n        instance[\"width\"] = image_size[0]\n    if \"height\" not in instance:\n        instance[\"height\"] = image_size[1]\n\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(\n        instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS\n    )\n    bbox = np.array(bbox)\n    # crop_size is 1d (per-instance crop size)\n    crop_size = np.array(crop_size)\n\n    # Calculate the top-left corner of the crop\n    top_left = np.array([bbox[0], bbox[1]])\n    top_left -= crop_size // 2\n\n    # Calculate the dimensions of the crop\n    dimensions = np.array([crop_size[0], crop_size[1]])\n\n    # Clip the top-left corner and dimensions to the image boundaries\n    top_left = np.maximum(top_left, np.array([0, 0]))\n    dimensions = np.minimum(top_left + dimensions, np.array(image_size)) - top_left\n\n    # Create a CropTransform object with the top-left corner and dimensions of the crop\n    return T.CropTransform(top_left, dimensions)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"width\" in instance or \"height\" in instance:\n        instance_wh = (instance[\"width\"], instance[\"height\"])\n        expected_wh = (crop_size[0], crop_size[1])\n        if not instance_wh == expected_wh:\n            raise SizeMismatchError(\n                \"Mismatched instance shape{}, got {}, expect {}.\".format(\n                    \" for instance \" + instance[\"file_name\"]\n                    if \"file_name\" in instance\n                    else \"\",\n                    instance_wh,\n                    expected_wh,\n                )\n                + \" Please check the width/height in your annotation.\"\n            )\n\n    # To ensure bbox always remap to original image size\n    if \"width\" not in instance:\n        instance[\"width\"] = image_size[1]\n    if \"height\" not in instance:\n        instance[\"height\"] = image_size[0]\n\n    # Get the bounding box of the instance\n    instance_bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    instance_bbox = Boxes(instance_bbox)\n\n    # Get the center of the bounding box of the instance\n    instance_center = instance_bbox.get_centers()\n\n    # Calculate the top-left corner of the cropping region\n    top_left = instance_center - crop_size / 2\n\n    # Calculate the dimensions of the cropping region\n    dimensions = crop_size\n\n    # Ensure the cropping region fits within the image boundaries\n    top_left = top_left.clip(min=0)\n    dimensions = dimensions.clip(max=image_size)\n\n    # Return a CropTransform object that defines the cropping region in the image\n    return T.CropTransform(top_left, dimensions)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # TODO: check if the instance is in the image\n\n    # Get the instance's bounding box\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the top-left corner of the crop\n    crop_tl = np.maximum(bbox[:2] - crop_size[:2] // 2, 0)\n\n    # Calculate the dimensions of the crop\n    crop_wh = np.minimum(bbox[2:] - bbox[:2] + crop_size[:2], image_size) - crop_tl\n\n    # Return the CropTransform object\n    return T.CropTransform(crop_tl, crop_wh)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"width\" in instance or \"height\" in instance:\n        instance_wh = (instance[\"width\"], instance[\"height\"])\n        expected_wh = (crop_size[0], crop_size[1])\n        if not instance_wh == expected_wh:\n            raise SizeMismatchError(\n                \"Mismatched instance shape{}, got {}, expect {}.\".format(\n                    \" for instance \" + instance[\"file_name\"]\n                    if \"file_name\" in instance\n                    else \"\",\n                    instance_wh,\n                    expected_wh,\n                )\n                + \" Please check the width/height in your annotation.\"\n            )\n\n    # To ensure bbox always remap to original image size\n    if \"width\" not in instance:\n        instance[\"width\"] = image_size[1]\n    if \"height\" not in instance:\n        instance[\"height\"] = image_size[0]\n\n    # Compute the top-left corner of the crop\n    top_left = np.array(instance[\"bbox\"][:2])\n    top_left -= crop_size / 2\n    top_left = np.maximum(top_left, 0)\n    top_left = np.minimum(top_left, image_size - crop_size)\n\n    # Compute the dimensions of the crop\n    dimensions = crop_size\n\n    # Return the CropTransform object\n    return T.CropTransform(top_left, dimensions)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"width\" in instance or \"height\" in instance:\n        instance_wh = (instance[\"width\"], instance[\"height\"])\n        expected_wh = (crop_size[0], crop_size[1])\n        if not instance_wh == expected_wh:\n            raise SizeMismatchError(\n                \"Mismatched instance shape{}, got {}, expect {}.\".format(\n                    \" for instance \" + instance[\"file_name\"]\n                    if \"file_name\" in instance\n                    else \"\",\n                    instance_wh,\n                    expected_wh,\n                )\n                + \" Please check the width/height in your annotation.\"\n            )\n\n    # To ensure bbox always remap to original image size\n    if \"width\" not in instance:\n        instance[\"width\"] = image_size[1]\n    if \"height\" not in instance:\n        instance[\"height\"] = image_size[0]\n\n    # Transform instance bbox\n    boxes = T.TransformList.apply_box(\n        BoxMode.convert(\n            [instance[\"bbox\"]],\n            instance[\"bbox_mode\"],\n            BoxMode.XYXY_ABS,\n        )\n    )\n    boxes = Boxes(boxes)\n    boxes.clip(image_size)\n    keep = boxes.nonempty(threshold=0)\n    boxes = boxes[keep]\n\n    # Determine the cropping region\n    crop_boxes = boxes.tensor\n    crop_boxes = crop_boxes.new_tensor(crop_size).to(crop_boxes.device)\n    crop_boxes = crop_boxes.to(dtype=torch.float32)\n    crop_boxes = crop_boxes - crop_boxes / 2\n    crop_boxes = crop_boxes.to(dtype=torch.int64)\n\n    # Apply the cropping region\n    crop_transform = T.CropTransform(crop_boxes, image_size)\n\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box and its mode from the instance\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Get the top-left corner and dimensions of the crop\n    crop_top_left = (\n        bbox[0] - (crop_size[0] - bbox[2]) / 2,\n        bbox[1] - (crop_size[1] - bbox[3]) / 2,\n    )\n    crop_dims = (crop_size[0], crop_size[1])\n\n    # Ensure the crop fits within the image boundaries\n    crop_top_left = (\n        max(crop_top_left[0], 0),\n        max(crop_top_left[1], 0),\n    )\n    crop_dims = (\n        min(crop_dims[0], image_size[0] - crop_top_left[0]),\n        min(crop_dims[1], image_size[1] - crop_top_left[1]),\n    )\n\n    # Return a CropTransform object with the specified parameters\n    return T.CropTransform(crop_top_left, crop_dims)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    if \"bbox\" in instance:\n        # Transform instance bounding box\n        bbox = instance[\"bbox\"]\n        bbox_mode = instance[\"bbox_mode\"]\n        bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    else:\n        bbox = [0, 0, 0, 0]\n        bbox_mode = BoxMode.XYXY_ABS\n\n    # clip transformed bbox to image size\n    bbox = Boxes(bbox)\n    bbox.clip(image_size)\n\n    # Adjust crop size if needed\n    crop_size = np.minimum(crop_size, image_size)\n\n    # Calculate the top-left corner of the crop\n    top_left = np.maximum(bbox.xyxy()[:2] - (crop_size - 1) / 2, [0, 0])\n    top_left = np.minimum(top_left, image_size - crop_size)\n\n    # Calculate the dimensions of the crop\n    dimensions = crop_size\n\n    return T.CropTransform(top_left, dimensions)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, jnp.finfo(jnp.float32).eps)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  return x / x_norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm_clamped = jnp.maximum(x_norm, grad_eps)\n  return x / x_norm_clamped\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.maximum(jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)), grad_eps)\n  return x / norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Calculate the squared norm of x along the last axis\n  squared_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value during the forward pass\n  squared_norm = jnp.maximum(squared_norm, jnp.finfo(jnp.float32).eps)\n\n  # Clamp the squared norm to a minimum value during the backward pass\n  squared_norm = jnp.maximum(squared_norm, grad_eps)\n\n  # Normalize x along the last axis\n  return x / jnp.sqrt(squared_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along its last axis\n  squared_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  squared_norm = jnp.maximum(squared_norm, grad_eps)\n\n  # Compute the normalized array by dividing x by the square root of the squared norm\n  return x / jnp.sqrt(squared_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, jnp.sqrt(grad_eps))\n  return x / x_norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x * jnp.sqrt(jnp.maximum(jnp.sum(jnp.square(x), axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array along its last axis\n  sq_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent division by zero\n  sq_norm = jnp.maximum(sq_norm, jnp.finfo(x.dtype).eps)\n\n  # Normalize the input array along its last axis\n  return x / jnp.sqrt(sq_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x = jnp.asarray(x)\n  norm = jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True))\n  norm = jnp.where(norm < jnp.finfo(jnp.float32).eps, jnp.ones_like(norm), norm)\n  norm = jnp.where(norm > 1.0 - jnp.finfo(jnp.float32).eps, jnp.ones_like(norm), norm)\n  norm = jnp.where(norm < grad_eps, jnp.ones_like(norm) * grad_eps, norm)\n  return x / norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm along the last axis of x\n  squared_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  squared_norm = jnp.maximum(squared_norm, jnp.finfo(jnp.float32).eps)\n\n  # Compute the normalized array by dividing x by the square root of the squared norm\n  return x / jnp.sqrt(squared_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm along the last axis of x\n  squared_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  squared_norm_clamped = jnp.maximum(squared_norm, grad_eps)\n\n  # Compute the normalization factor by taking the square root of the clamped squared norm\n  norm_factor = jnp.sqrt(squared_norm_clamped)\n\n  # Normalize x along the last axis by dividing it by the norm factor\n  return x / norm_factor\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # The forward pass\n  # Clamp the denominator to a minimum value to prevent division by zero\n  x_norm = jnp.maximum(jnp.linalg.norm(x, axis=-1), grad_eps)\n  # Normalize the input array\n  return x / x_norm[..., None]\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  squared_norm = jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps)\n  # Normalize the array to unit length along its last axis\n  return x / jnp.sqrt(squared_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array along the last axis.\n  squared_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent division by zero.\n  clamped_squared_norm = jnp.maximum(squared_norm, jnp.finfo(jnp.float32).eps)\n\n  # Compute the normalized array by dividing the input array by the clamped squared norm.\n  normalized_x = x / jnp.sqrt(clamped_squared_norm)\n\n  # Return the normalized array.\n  return normalized_x\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm along the last axis\n  squared_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent division by zero\n  squared_norm = jnp.maximum(squared_norm, jnp.finfo(jnp.float32).eps)\n\n  # Compute the normalized array\n  normalized_x = x / jnp.sqrt(squared_norm)\n\n  # Define the custom gradient function to handle the clamping in the backward pass\n  def custom_grad(g):\n    # Compute the squared norm along the last axis\n    squared_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n    # Clamp the squared norm to a minimum value to prevent division by zero\n    squared_norm = jnp.maximum(squared_norm, grad_eps)\n\n    # Compute the gradient of the normalized array\n    grad = g * (x / squared_norm - jnp.sum(g * x, axis=-1, keepdims=True) * x / squared_norm**2)\n\n    return grad\n\n  # Register the custom gradient function with JAX\n  jnp.grad_custom_jvp(custom_grad)(normalized_x)\n\n  return normalized_x\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Clamp the squared norm to a minimum value during the forward pass to prevent\n  # exploding gradients.\n  squared_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n  squared_norm = jnp.maximum(squared_norm, jnp.finfo(jnp.float32).eps)\n  # Clamp the squared norm to a minimum value during the backward pass to\n  # prevent exploding gradients.\n  grad_eps = jnp.maximum(grad_eps, jnp.finfo(jnp.float32).eps)\n  return x / jnp.sqrt(squared_norm + grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True)), grad_eps)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of each vector in the last axis of x\n  squared_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  squared_norm = jnp.maximum(squared_norm, grad_eps)\n\n  # Normalize each vector in the last axis of x to unit length\n  return x / jnp.sqrt(squared_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Get the squared norm of the input array along its last axis\n  squared_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  squared_norm_clamped = jnp.maximum(squared_norm, grad_eps)\n\n  # Normalize the input array by the clamped squared norm\n  normalized_x = x / jnp.sqrt(squared_norm_clamped)\n\n  return normalized_x\n\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        input_text = input_text.strip() if input_text else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0].strip()\n        input_text = agent_info.split(\":\")[1].strip() if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\") : response.find(\"]\")]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name = agent_info.split(':')[0]\n        input_text = agent_info.split(':')[1] if len(agent_info.split(':')) > 1 else ''\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start_index = response.find(\"Use Agent[\") + len(\"Use Agent[\")\n        end_index = response.find(\"]\", start_index)\n        agent_info = response[start_index:end_index]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name.strip(), input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0].strip()\n        input_text = agent_info.split(\":\")[1].strip() if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        input_text = input_text.strip() if input_text else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name.strip(), input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\") : response.find(\"]\")]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name.strip(), input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\") : response.find(\"]\")]\n        agent_name = agent_info[: agent_info.find(\":\")]\n        input_text = agent_info[agent_info.find(\":\") + 1 :] if \":\" in agent_info else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\") : response.find(\"]\")]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find(\"Use Agent[\") + len(\"Use Agent[\") : response.find(\"]\")]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':')\n        return agent_name, input_text\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            if isinstance(masks[0], list):\n                masks = PolygonMasks(masks)\n            else:\n                masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = BitMasks(masks)\n        else:\n            raise ValueError(f\"Unknown mask type '{mask_format}'\")\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    num_instance = len(annos)\n    if num_instance != 0:\n        boxes = [\n            BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS)\n            if len(obj[\"bbox\"]) == 4\n            else BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYWH_ABS)\n            for obj in annos\n        ]\n        boxes = np.asarray(boxes, dtype=np.float32)\n        target = Instances(image_size)\n        target.gt_boxes = Boxes(boxes)\n\n        classes = [obj[\"category_id\"] for obj in annos]\n        classes = torch.tensor(classes, dtype=torch.int64)\n        target.gt_classes = classes\n\n        if \"segmentation\" in annos[0]:\n            if mask_format == \"polygon\":\n                masks = [obj[\"segmentation\"] for obj in annos]\n                masks = SegmentationMask(masks, image_size)\n            elif mask_format == \"bitmask\":\n                masks = [obj[\"segmentation\"] for obj in annos]\n                masks = BitMasks(masks, image_size)\n            else:\n                raise ValueError(f\"Unknown mask type '{mask_format}'\")\n            target.gt_masks = masks\n\n        if \"keypoints\" in annos[0]:\n            keypoints = [obj[\"keypoints\"] for obj in annos]\n            keypoints = Keypoints(keypoints)\n            target.gt_keypoints = keypoints\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            if isinstance(masks[0], list):\n                masks = PolygonMasks(masks)\n            elif isinstance(masks[0], dict):\n                masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n                masks = BitMasks(masks)\n            else:\n                raise ValueError(\n                    \"Cannot convert segmentation of type '{}' to instances!\".format(type(masks[0]))\n                )\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"].astype(\"uint8\") for obj in annos]\n            masks = BitMasks(masks)\n        else:\n            raise ValueError(f\"Unsupported mask type '{mask_format}'\")\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = Keypoints(keypoints)\n        target.gt_keypoints = keypoints\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    num_instances = len(annos)\n    if num_instances == 0:\n        return Instances(image_size)\n\n    fields = [\"gt_classes\"]\n    if \"boxes\" in annos[0]:\n        fields.append(\"gt_boxes\")\n    if \"keypoints\" in annos[0]:\n        fields.append(\"gt_keypoints\")\n    if mask_format == \"polygon\" and \"segmentation\" in annos[0]:\n        fields.append(\"gt_masks\")\n    elif mask_format == \"bitmask\" and \"segmentation\" in annos[0]:\n        fields.append(\"gt_bitmasks\")\n\n    target = Instances(image_size)\n    for field in fields:\n        data = [ann[field] for ann in annos]\n        if field == \"gt_masks\" and len(data) > 0 and isinstance(data[0], list):\n            target.gt_masks = PolygonMasks(data)\n        elif field == \"gt_bitmasks\" and len(data) > 0 and isinstance(data[0], list):\n            target.gt_bitmasks = BitMasks(data)\n        elif field == \"gt_keypoints\" and len(data) > 0 and isinstance(data[0], list):\n            target.gt_keypoints = Keypoints(data)\n        else:\n            target[field] = torch.tensor(data, dtype=torch.int64)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n    if mask_format == \"polygon\":\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if len(segms) and not isinstance(segms[0], list):\n            raise ValueError(\n                \"Invalid segmentation format for instances! Please convert \"\n                \"them to list[list[float]!] or list[PolygonMasks]!\"\n            )\n        target.gt_masks = PolygonMasks(segms)\n    elif mask_format == \"bitmask\":\n        # if target.has(\"gt_masks\"):\n        #     target = target.remove(\"gt_masks\")\n        target.gt_masks = []\n        for obj in annos:\n            if obj[\"segmentation\"] is not None:\n                gt_mask = obj[\"segmentation\"].astype(np.uint8)\n                gt_mask = polygons_to_bitmask(gt_mask, gt_mask.shape[1], gt_mask.shape[0])\n                target.gt_masks.append(gt_mask)\n        if len(target.gt_masks) > 0:\n            target.gt_masks = BitMasks(target.gt_masks)\n    if len(annos) and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    if mask_format == \"polygon\":\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if len(segms) and isinstance(segms[0], list):\n            filter_empty_gt = [len(segm) > 0 for segm in segms]\n            if not np.all(filter_empty_gt):\n                segms = [segm for segm, f in zip(segms, filter_empty_gt) if f]\n                annos = [obj for obj, f in zip(annos, filter_empty_gt) if f]\n            target.gt_masks = PolygonMasks(segms)\n        else:\n            target.gt_masks = None\n    elif mask_format == \"bitmask\":\n        target.gt_masks = BitMasks(np.stack([obj[\"segmentation\"] for obj in annos], axis=0))\n    else:\n        raise ValueError(f\"Unknown mask type: {mask_format}\")\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n    else:\n        target.gt_keypoints = None\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = [\n                polygons_to_bitmask(segm, image_size[0], image_size[1])\n                if isinstance(segm, list)\n                else segm\n                for segm in segms\n            ]\n        elif mask_format == \"bitmask\":\n            masks = segms\n        else:\n            raise ValueError(f\"Invalid mask_format '{mask_format}'\")\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if len(annos) == 0:\n        return None\n    if \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        # convert to BitMasks to save memory.\n        # TODO: maybe we can also just convert to uint8?\n        masks = [BitMasks(np.asarray(mask).astype(\"bool\")) for mask in annos[\"segmentation\"]]\n    elif \"segmentation\" in annos[0]:\n        masks = [PolygonMasks([mask]) for mask in annos[\"segmentation\"]]\n    else:\n        masks = None\n\n    keypoints = None\n    if \"keypoints\" in annos[0]:\n        keypoints = [Keypoints(kps) for kps in annos[\"keypoints\"]]\n\n    boxes_xyxy = [BoxMode.convert(ann[\"bbox\"], ann[\"bbox_mode\"], BoxMode.XYXY_ABS) for ann in annos]\n    boxes = Boxes(boxes_xyxy)\n    boxes.clip(image_size)\n\n    classes = [ann[\"category_id\"] for ann in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n\n    result = Instances(image_size)\n    result.gt_boxes = boxes\n    result.gt_classes = classes\n    result.gt_masks = masks\n    result.gt_keypoints = keypoints\n    return result\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    assert isinstance(annos, (list, tuple))\n    assert isinstance(image_size, (list, tuple))\n    # TODO: support more format\n    assert mask_format in [\"polygon\", \"bitmask\"]\n\n    boxes = [\n        BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        if len(obj[\"bbox\"]) == 4\n        else BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYWH_ABS)\n        for obj in annos\n    ]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            if isinstance(masks[0], list):\n                # polygon\n                masks = SegmentationMasks(masks, image_size)\n            elif isinstance(masks[0], dict):\n                # COCO RLE\n                masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n                masks = SegmentationMasks(masks, image_size)\n            else:\n                raise ValueError(\n                    \"Cannot convert segmentation of type '{}' to SegmentationMasks\".format(\n                        type(masks[0])\n                    )\n                )\n        else:\n            # This is the only case when we don't have polygons\n            masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n            masks = SegmentationMasks(masks, image_size)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n    if \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = [\n                polygons_to_bitmask(segm, image_size[0], image_size[1])\n                if isinstance(segm, list)\n                else segm\n                for segm in segms\n            ]\n            if any(x is None for x in masks):\n                logging.warning(\n                    \"Some instances have invalid segmentation. \"\n                    \"They will be treated as empty masks.\"\n                )\n                masks = [x if x is None else np.asarray(x, dtype=np.uint8) for x in masks]\n            target.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            if any(x is None for x in masks):\n                logging.warning(\n                    \"Some instances have invalid segmentation. \"\n                    \"They will be treated as empty masks.\"\n                )\n                masks = [x if x is None else np.asarray(x, dtype=np.uint8) for x in masks]\n            target.gt_masks = BitMasks(masks)\n        else:\n            raise ValueError(f\"Invalid mask_format: {mask_format}.\")\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        for idx, keypoint in enumerate(keypoints):\n            keypoints[idx] = transform_keypoint_annotations(\n                keypoint, T.TransformList([]), image_size, None\n            )\n        target.gt_keypoints = Keypoints(keypoints)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n    if mask_format == \"polygon\":\n        masks = [obj[\"segmentation\"] for obj in annos]\n        if len(masks) == 0:\n            target.gt_masks = BitMasks(torch.zeros(0, image_size[0], image_size[1], dtype=torch.uint8))\n        else:\n            masks = [\n                polygons_to_bitmask(obj[\"segmentation\"], image_size[0], image_size[1])\n                for obj in annos\n            ]\n            target.gt_masks = BitMasks(torch.stack(masks, dim=0))\n    elif mask_format == \"bitmask\":\n        masks = [obj[\"segmentation\"] for obj in annos]\n        if len(masks) == 0:\n            target.gt_masks = BitMasks(torch.zeros(0, image_size[0], image_size[1], dtype=torch.uint8))\n        else:\n            masks = [\n                torch.from_numpy(obj[\"segmentation\"][\"counts\"]).to(dtype=torch.uint8)\n                for obj in annos\n            ]\n            target.gt_masks = BitMasks(torch.stack(masks, dim=0))\n    else:\n        raise ValueError(f\"Invalid mask_format: {mask_format}\")\n    if len(annos) > 0 and \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [\n            np.asarray(keypoint).reshape(-1, 3) for keypoint in keypoints\n        ]\n        keypoints = np.concatenate(keypoints, axis=0)\n        target.gt_keypoints = Keypoints(keypoints)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    assert isinstance(annos, (list, tuple))\n    assert isinstance(image_size, (list, tuple))\n    assert len(image_size) == 2\n\n    # TODO: handle the case when the image contains instances of only one category.\n    if len(annos) == 0:\n        return None\n\n    boxes_all = [obj[\"bbox\"] for obj in annos]\n    boxes = BoxMode.convert(boxes_all, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos[0].get(\"segmentation\", [])) > 0:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = PolygonMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = BitMasks(masks)\n        else:\n            raise ValueError(f\"Unknown mask format: {mask_format}\")\n        target.gt_masks = masks\n\n    if len(annos[0].get(\"keypoints\", [])) > 0:\n        keypoints = [obj.get(\"keypoints\", []) for obj in annos]\n        keypoints = Keypoints(keypoints)\n        if \"keypoints_x_scale\" in annos[0]:\n            keypoints_x_scale = [obj[\"keypoints_x_scale\"] for obj in annos]\n            keypoints_x_scale = torch.tensor(keypoints_x_scale, dtype=torch.float32)\n            keypoints.x_scale = keypoints_x_scale\n        if \"keypoints_y_scale\" in annos[0]:\n            keypoints_y_scale = [obj[\"keypoints_y_scale\"] for obj in annos]\n            keypoints_y_scale = torch.tensor(keypoints_y_scale, dtype=torch.float32)\n            keypoints.y_scale = keypoints_y_scale\n        target.gt_keypoints ="}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if len(annos) == 0:\n        return None\n    if \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        masks = [x[\"segmentation\"] for x in annos]\n        masks = polygons_to_bitmask(masks, *image_size)\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n    elif \"segmentation\" in annos[0]:\n        segms = [x[\"segmentation\"] for x in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            raise NotImplementedError(\n                \"Unknown segmentation format {}!\".format(mask_format)\n            )\n    else:\n        masks = None\n\n    boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n    target = Instances(image_size, gt_boxes=Boxes(boxes), gt_classes=[x[\"category_id\"] for x in annos])\n    target.gt_masks = masks\n    if \"keypoints\" in annos[0]:\n        keypoints = [x[\"keypoints\"] for x in annos]\n        target.gt_keypoints = Keypoints(keypoints)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    num_instance = len(annos)\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n    for i in range(num_instance):\n        anno = annos[i]\n        boxes.append(anno[\"bbox\"])\n        classes.append(anno[\"category_id\"])\n        if mask_format == \"bitmask\":\n            masks.append(anno[\"segmentation\"])\n        elif mask_format == \"polygon\":\n            masks.append(anno[\"segmentation\"])\n        else:\n            raise ValueError(f\"Unsupported mask type: {mask_format}\")\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n    classes = torch.as_tensor(classes, dtype=torch.int64)\n    if len(boxes) > 0:\n        boxes = Boxes(boxes)\n    else:\n        boxes = Boxes(torch.zeros(0, 4, dtype=torch.float32))\n\n    classes = torch.tensor(classes, dtype=torch.int64)\n    if mask_format == \"bitmask\":\n        masks = BitMasks(masks)\n    elif mask_format == \"polygon\":\n        masks = PolygonMasks(masks)\n    else:\n        raise ValueError(f\"Unsupported mask type: {mask_format}\")\n    if len(keypoints) > 0:\n        keypoints = Keypoints(keypoints)\n    else:\n        keypoints = Keypoints(torch.zeros(0, 51, dtype=torch.float32))\n    instances = Instances(image_size=image_size)\n    instances.gt_boxes = boxes\n    instances.gt_classes = classes\n    instances.gt_masks = masks\n    instances.gt_keypoints = keypoints\n    return instances\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if len(annos) == 0:\n        return None\n    if not isinstance(annos, (list, tuple)):\n        annos = (annos,)\n    assert isinstance(annos[0], dict)\n    if len(annos) == 1:\n        annos = annos[0]\n\n    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"].to_coco(), BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    segms = [obj[\"segmentation\"] for obj in annos]\n    if len(segms) and segms[0] is not None:\n        if mask_format == \"polygon\":\n            segms = [polygons_to_bitmask(segm, *image_size) for segm in segms]\n        elif mask_format == \"bitmask\":\n            segms = [m.mask.to(torch.bool) for m in segms]\n        else:\n            raise ValueError(f\"Unsupported mask type '{mask_format}'\")\n        if len(segms) > 0:\n            target.gt_masks = BitMasks(segms)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kps = [obj[\"keypoints\"] for obj in annos]\n        for idx, ann in enumerate(annos):\n            if len(ann[\"keypoints\"]) == 0:\n                kps[idx] = None\n        if target.has(\"gt_keypoints\"):\n            target.gt_keypoints = Keypoints(kps)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    assert isinstance(annos, (list, tuple))\n    assert isinstance(image_size, (list, tuple))\n    assert len(image_size) == 2\n\n    # If the annotations contain polygons, we need to convert them to RLE.\n    # This is the case for COCO.\n    if mask_format == \"polygon\" and any(\n        isinstance(anno.get(\"segmentation\", None), list)\n        for anno in annos\n    ):\n        mask_format = \"bitmask\"\n\n    # Count the number of instances in the image.\n    num_instances = len(annos)\n\n    # If there are no instances, return an empty Instances object.\n    if num_instances == 0:\n        return Instances(image_size, gt_boxes=Boxes(torch.zeros(0, 4)))\n\n    # If the annotations contain polygons, we need to convert them to RLE.\n    # This is the case for COCO.\n    if mask_format == \"polygon\" and any(\n        isinstance(anno.get(\"segmentation\", None), list)\n        for anno in annos\n    ):\n        mask_format = \"bitmask\"\n\n    # Count the number of instances in the image.\n    num_instances = len(annos)\n\n    # If there are no instances, return an empty Instances object.\n    if num_instances == 0:\n        return Instances(image_size, gt_boxes=Boxes(torch.zeros(0, 4)))\n\n    # If the annotations contain polygons, we need to convert them to RLE.\n    # This is the case for COCO.\n    if \"segmentation\" in annos:\n        segm = annos[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annos[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            annos[\"segmentation\"] = transforms.apply_segmentation(mask)\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" CO"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    if len(annos) == 0:\n        return None\n    if not isinstance(annos, (list, tuple)):\n        annos = (annos,)\n    assert isinstance(annos[0], dict)\n\n    # Sort labels by id\n    if \"category_id\" in annos[0]:\n        ids = [obj[\"category_id\"] for obj in annos]\n    else:\n        ids = [obj[\"category\"] for obj in annos]\n    inds = [i[0] for i in sorted(enumerate(ids), key=lambda x: x[1])]\n    annos = [annos[i] for i in inds]\n\n    if \"category_id\" in annos[0]:\n        classes = [obj[\"category_id\"] for obj in annos]\n    else:\n        classes = [obj[\"category\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n\n    if \"bbox\" in annos[0]:\n        boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n        boxes = torch.as_tensor(boxes).reshape(-1, 4)  # guard against no boxes\n    else:\n        boxes = torch.zeros((0, 4), dtype=torch.float32)\n\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes, mode=BoxMode.XYXY_ABS)\n    target.gt_classes = classes\n    if \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = [\n                BitMasks.decode(segm) if isinstance(segm, dict) else segm\n                for segm in segms\n            ]\n            target.gt_masks = PolygonMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [\n                segm.get_mask() if isinstance(segm, dict) else segm\n                for segm in segms\n            ]\n            target.gt_masks = BitMasks(masks)\n        else:\n            raise ValueError(f\"Unknown mask format: {mask_format}\")\n\n    if \"keypoints\" in annos[0]:\n        key"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    assert isinstance(annos, (list, tuple))\n    assert isinstance(image_size, (list, tuple))\n    if len(annos) == 0:\n        return None\n    if not isinstance(annos[0], dict):\n        raise ValueError(\n            \"Invalid annotation format {}!\".format(type(annos[0]))\n            + \"Annotations must be a list of dicts.\"\n        )\n\n    # Sort instances by decreasing size to better group small instances.\n    # This is based on Mask R-CNN.\n    if \"segmentation\" in annos[0]:\n        areas = [\n            np.prod(BoxMode.convert(ann[\"bbox\"], ann[\"bbox_mode\"], BoxMode.XYXY_ABS).shape[:2])\n            for ann in annos\n        ]\n        inds = [y[0] for y in sorted(enumerate(areas), key=lambda x: -x[1])]\n        annos = [annos[i] for i in inds]\n\n    if len(annos) == 0:\n        return None\n\n    boxes = [BoxMode.convert(ann[\"bbox\"], ann[\"bbox_mode\"], BoxMode.XYXY_ABS) for ann in annos]\n    target = Instances(image_size, **extra_fields)\n    target.gt_boxes = Boxes(boxes)\n    target.gt_classes = torch.tensor([ann[\"category_id\"] for ann in annos], dtype=torch.int64)\n    if \"segmentation\" in annos[0]:\n        segms = [\n            ann[\"segmentation\"]\n            if isinstance(ann[\"segmentation\"], list)\n            else [ann[\"segmentation\"]]\n            for ann in annos\n        ]\n        if mask_format == \"polygon\":\n            target.gt_masks = PolygonMasks(segms, image_size)\n        elif mask_format == \"bitmask\":\n            target.gt_masks = BitMasks(segms, image_size)\n        else:\n            raise ValueError(f\"Unknown mask format: {mask_format}\")\n    if \"keypoints\" in annos[0]:\n        keypoints = [ann[\"keypoints\"] for ann in annos]\n        target.gt_keypoints = Keypoints(keypoints, image_size)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    assert isinstance(annos, (list, tuple))\n    assert isinstance(image_size, (list, tuple))\n    assert len(image_size) == 2\n    if len(annos) == 0:\n        return None\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [\n                PolygonMasks(polygons=[p]) if len(p) > 0 else PolygonMasks(polygons=[])\n                for p in [a[\"segmentation\"] for a in annos]\n            ]\n        else:\n            assert mask_format == \"bitmask\"\n            masks = [\n                BitMasks(polygons_to_bitmask(p, image_size[0], image_size[1]))\n                if len(p) > 0\n                else BitMasks(np.zeros(image_size, dtype=\"bool\"))\n                for p in [a[\"segmentation\"] for a in annos]\n            ]\n    else:\n        masks = None\n    boxes = [BoxMode.convert(a[\"bbox\"], a[\"bbox_mode\"], BoxMode.XYXY_ABS) for a in annos]\n    keypoints = [a.get(\"keypoints\", None) for a in annos]\n    classes = [a[\"category_id\"] for a in annos]\n    classes = [c + 1 for c in classes]\n    boxes = torch.as_tensor(boxes).reshape(-1, 4)  # Guard against empty boxes\n    target = Instances(image_size)\n    target.gt_boxes = boxes\n    target.gt_classes = torch.as_tensor(classes)\n    if masks is not None:\n        if isinstance(masks[0], PolygonMasks):\n            masks = [m.polygons[0] for m in masks]\n        target.gt_masks = torch.as_tensor(masks)\n    if keypoints is not None and not target.has(\"gt_keypoints\"):\n        target.gt_keypoints = torch.as_tensor(keypoints)\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    assert isinstance(annos, (list, tuple))\n    assert isinstance(image_size, (list, tuple))\n\n    # The `gt_boxes` field is a Boxes object, which represents a list of bounding boxes.\n    # It has a `tensor` field that contains the coordinates of the bounding boxes as a 2D tensor.\n    # The `gt_classes` field is an integer tensor of shape (N,) where N is the number of instances.\n    # The `gt_masks` field is a TensorMask object that contains a boolean tensor of shape (N, H, W)\n    # where N is the number of instances and H and W are the height and width of the image, respectively.\n    # The `gt_keypoints` field is a Keypoint object that contains a tensor of shape (N, K, 3)\n    # where N is the number of instances, K is the number of keypoints, and 3 is the dimensionality of the keypoints.\n    # The `gt_boxes_classes_idxs` field is an integer tensor of shape (N,) that contains the class indices for each instance.\n    # The `image_size` field is a tuple of integers (H, W) that represents the height and width of the image.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,) that contains the class indices for each instance.\n    # The `gt_boxes_classes_idxs` field is a tensor of shape (N,)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir()\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        os.makedirs(data_home)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~\") / \"skfolio_data\")\n\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n\n    data_home = os.path.expanduser(data_home)\n\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~\") / \"skfolio_data\")\n\n    data_home = str(data_home)\n\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    if not data_home.exists():\n        os.makedirs(data_home)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~\") / \"skfolio_data\")\n    data_home = Path(data_home)\n    if not data_home.exists():\n        os.makedirs(data_home)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n\n    data_home = os.path.expanduser(data_home)\n\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir()\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        os.makedirs(data_home)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    if not data_home.exists():\n        os.makedirs(data_home)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~\") / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir()\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~\", \"skfolio_data\"))\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if not isinstance(cov, np.ndarray):\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"Input must be a square matrix.\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if not isinstance(cov, np.ndarray) or cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D numpy array.\")\n\n    # Check if the input is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input must be a square matrix.\")\n\n    # Calculate the standard deviations for each variable\n    std_devs = np.sqrt(np.diag(cov))\n\n    # Check if there are any zeros in the standard deviations\n    if np.any(std_devs == 0):\n        raise ValueError(\"The standard deviations cannot be zero.\")\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std_devs, std_devs)\n\n    # Return the correlation matrix and the standard deviations\n    return corr, std_devs\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array.\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and the standard deviation array\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Calculate standard deviation\n    std = np.sqrt(np.diag(cov))\n\n    # Convert covariance matrix to correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if not isinstance(cov, np.ndarray) or cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Check if the standard deviation is non-zero for all variables\n    if np.any(std == 0):\n        raise ValueError(\"Standard deviation is zero for one or more variables.\")\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if not isinstance(cov, np.ndarray):\n        raise ValueError(\"Input must be a 2D numpy array\")\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D numpy array\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Convert the covariance matrix into a correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if not isinstance(cov, np.ndarray):\n        raise TypeError(\"Input must be a numpy array.\")\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array.\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"Input must be a square matrix.\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    # Check if the covariance matrix is positive semi-definite\n    if not is_cholesky_dec(cov):\n        cov = cov_nearest(cov)\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Ensure the correlation matrix is symmetric\n    corr = (corr + corr.T) / 2\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and standard deviations\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Get the diagonal elements of the covariance matrix\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and the standard deviations\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if not isinstance(cov, np.ndarray) or cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and the standard deviation array\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if not isinstance(cov, np.ndarray) or cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D numpy array.\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Check for non-zero standard deviation\n    if np.any(std == 0):\n        raise ValueError(\"Standard deviation of a variable cannot be zero.\")\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and the standard deviation\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2d-array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if not isinstance(cov, np.ndarray) or len(cov.shape) != 2:\n        raise ValueError(\"Input must be a 2D numpy array.\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Return the correlation matrix and the standard deviation array\n    return corr, std\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: add support for other types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO: support more types of modules\n    # TODO"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        if hasattr(module, \"training\"):\n            module.__class__.training = torch.jit.Final[bool]\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.apply(lambda module: delattr(module.__class__, \"training\"))\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: find a more automatic way to enable import of other classes\n    s = \"\"\""}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        module.__class__.training = torch.jit.Final[bool]\n        return module\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.apply(torch.jit.freeze)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    from detectron2.modeling import build_model\n\n    # Use a context manager to ensure that the changes are reverted back to their original state after the context manager exits.\n    with ExitStack() as stack:\n        # Iterate through all submodules in the model.\n        for module in model.modules():\n            # Skip the model itself.\n            if module is model:\n                continue\n            # If the submodule is a Detectron2 model, use the build_model function to get the original class definition.\n            if isinstance(module, build_model.META_ARCH_REGISTRY):\n                original_class = build_model.META_ARCH_REGISTRY.get(module.__class__.__name__)\n            # If the submodule is a Detectron2 backbone, use the build_backbone function to get the original class definition.\n            elif isinstance(module, build_model.BACKBONE_REGISTRY):\n                original_class = build_model.BACKBONE_REGISTRY.get(module.__class__.__name__)\n            # If the submodule is a Detectron2 head, use the build_head function to get the original class definition.\n            elif isinstance(module, build_model.HEAD_REGISTRY):\n                original_class = build_model.HEAD_REGISTRY.get(module.__class__.__name__)\n            # If the submodule is a Detectron2 proposal generator, use the build_proposal_generator function to get the original class definition.\n            elif isinstance(module, build_model.PROPOSAL_GENERATOR_REGISTRY):\n                original_class = build_model.PROPOSAL_GENERATOR_REGISTRY.get(\n                    module.__class__.__name__\n                )\n            # If the submodule is a Detectron2 ROI head, use the build_roi_heads function to get the original class definition.\n            elif isinstance(module, build_model.ROI_HEADS_REGISTRY):\n                original_class = build_model.ROI_HEADS_REGISTRY.get(module.__class__.__name__)\n            # If the submodule is a Detectron2 detector, use the build_detection_model function to get the original class definition.\n            elif isinstance(module, build_model.DETECTOR_REGISTRY):\n                original_class = build_model.DETECTOR_REGISTRY.get(module.__class__.__name__)\n            # If the submodule is a Detectron2 meta-arch, use the build_model function to"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Freeze training mode for all submodules\n    for module in model.modules():\n        if hasattr(module, \"training\"):\n            module.__class__.training = torch.jit.Final[bool]\n            module.training = False\n\n    yield\n\n    # Revert training mode to original state\n    for module in model.modules():\n        if hasattr(module, \"training\"):\n            delattr(module, \"training\")\n            delattr(module.__class__, \"training\")\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        if hasattr(module, \"training\"):\n            module.__class__.training = torch.jit.Final[bool](module.training)\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.apply(_freeze_training_mode)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        \"\"\"\n        This function modifies the class definition of a given module to temporarily set the \"training\" attribute to a constant value. It uses a context manager to ensure that these changes are reverted back to their original state after the context manager exits.\n        Input-Output Arguments\n        :param module: The module whose class definition is to be modified. It is used to retrieve the class definition and modify it.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module within the context.\n        \"\"\"\n        if hasattr(module, \"training\"):\n            # Use a context manager to ensure that the \"training\" attribute is reverted back to its original state after the context manager exits.\n            with torch.jit.annotate(List[str], []):\n                module.__orig_training = module.training\n                module.training = torch.jit.annotate(bool, module.training)\n\n    def _unfreeze_training_mode(module):\n        \"\"\"\n        This function reverts the class definition of a given module back to its original state, restoring the \"training\" attribute to its original value. It uses a context manager to ensure that these changes are reverted back to their original state after the context manager exits.\n        Input-Output Arguments\n        :param module: The module whose class definition is to be reverted back to its original state. It is used to retrieve the class definition and modify it.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module within the context.\n        \"\"\"\n        if hasattr(module, \"__orig_training\"):\n            # Use a context manager to ensure that the \"training\" attribute is reverted back to its original state after the context manager exits.\n            with torch.jit.annotate(List[str], []):\n                module.training = module.__orig_training\n                del module.__orig_training\n\n    # Iterate through all submodules of the model and modify their class definitions to temporarily set the \"training\" attribute to a constant value.\n    for module in model.modules():\n        _freeze_training_mode(module)\n\n    # Use a context manager to ensure that the \"training\" attribute is reverted back to its original state after the context manager exits.\n    with torch.jit.annotate(List[str], []):\n        yield\n\n    # Iterate through"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        if hasattr(module, \"training\"):\n            module.__class__.training = torch.jit.Final[bool]\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.apply(lambda m: delattr(m.__class__, \"training\"))\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        \"\"\"\n        This function temporarily sets the \"training\" attribute of a given module to a constant value, allowing for optimization by meta-compilation. It uses a context manager to ensure that these changes are reverted back to their original state after the context manager exits.\n        Input-Output Arguments\n        :param module: The module whose \"training\" attribute is to be temporarily annotated as a constant. It is used to modify its class definition.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module within the context.\n        \"\"\"\n        if not hasattr(module, \"__annotations__\"):\n            module.__annotations__ = {}\n        module.__annotations__[\"training\"] = torch.jit.Final[bool]\n\n    # Freeze training mode for all submodules\n    for module in model.modules():\n        _freeze_training_mode(module)\n\n    yield\n\n    # Revert back to original state\n    for module in model.modules():\n        if hasattr(module, \"__annotations__\") and \"training\" in module.__annotations__:\n            del module.__annotations__[\"training\"]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class _ConstantTrainingMode(type):\n        def __new__(cls, name, bases, attrs):\n            attrs[\"training\"] = torch.jit.Final[bool]\n            return type.__new__(cls, name, bases, attrs)\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(mock.patch.object(m.__class__, \"__class__\", _ConstantTrainingMode)) for m in model.modules()]\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        # TODO: check if this is actually needed\n        # if not hasattr(module, \"__torch_script_class__\"):\n        #     return\n        module.__class__.__torch_script_class__ = True\n        module.__class__.__annotations__[\"training\"] = torch.jit.Final[bool]\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.apply(_freeze_training_mode)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode_fn(self):\n        return self._training_mode\n\n    for name, module in model.named_modules():\n        module.__class__.training = torch.jit.Final[bool]\n        module._training_mode = module.training\n        module.training = _freeze_training_mode_fn\n\n    try:\n        yield\n    finally:\n        for name, module in model.named_modules():\n            module.training = module._training_mode\n            del module._training_mode\n            del module.__class__.training"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class_name = model.__class__.__name__\n    assert hasattr(model, \"training\"), f\"{class_name} has no attribute 'training'\"\n    assert (\n        isinstance(model.training, bool)\n    ), f\"Attribute 'training' of {class_name} is not a bool\"\n\n    def _new_training(self):\n        return self._training\n\n    def _new_train(self):\n        self._training = True\n\n    def _new_eval(self):\n        self._training = False\n\n    model._training = model.training\n    model.training = property(fget=_new_training)\n    model.train = _new_train\n    model.eval = _new_eval\n\n    yield\n\n    model.training = model._training\n    del model._training\n    del model.train\n    del model.eval\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    from torch.nn.modules.batchnorm import _BatchNorm\n\n    # TODO: make it work for other modules\n    def _freeze_training_mode(cls):\n        cls.__torch_script_training_mode__ = torch.jit.Final[bool]\n        return cls\n\n    for _, module in model.named_modules():\n        if isinstance(module, _BatchNorm):\n            module.__class__ = _freeze_training_mode(module.__class__)\n    yield\n    for _, module in model.named_modules():\n        if isinstance(module, _BatchNorm):\n            module.__class__ = _unfreeze_training_mode(module.__class__)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        \"\"\"\n        This function is used as a hook to freeze the \"training\" attribute of a given module. It is called by the register_forward_pre_hook method of a module, which is used to register the hook before the forward pass of the module.\n        Input-Output Arguments\n        :param module: The module whose \"training\" attribute is to be frozen.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module.\n        \"\"\"\n        class _FrozenModule(module.__class__):\n            def __init__(self, *args, **kwargs):\n                super(_FrozenModule, self).__init__(*args, **kwargs)\n                self.training = module.training\n        module.__class__ = _FrozenModule\n\n    for m in model.modules():\n        m.register_forward_pre_hook(_freeze_training_mode)\n    yield\n    for m in model.modules():\n        m.__class__ = m.__class__.__bases__[0]"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: move this to detectron2.export.patch_training_mode\n    from detectron2.modeling import META_ARCH_REGISTRY\n\n    if not hasattr(model, \"_training_mode_frozen\"):\n        model._training_mode_frozen = False\n    if model._training_mode_frozen:\n        yield\n        return\n\n    def _freeze_training_mode_recursively(m):\n        if not hasattr(m, \"_training_mode_frozen\"):\n            m._training_mode_frozen = False\n        if m._training_mode_frozen:\n            return\n        m._training_mode_frozen = True\n\n        # For meta-compiled models, we need to freeze the training mode of all submodules\n        # to ensure that they are not compiled again.\n        for submodule in m.modules():\n            if isinstance(submodule, (nn.Module, nn.Parameter)):\n                if hasattr(submodule, \"training\") and not hasattr(submodule, \"_training\"):\n                    submodule._training = submodule.training\n                    submodule.training = torch.jit.Final[bool](submodule.training)\n\n        # For meta-compiled models, we need to freeze the training mode of all submodules\n        # to ensure that they are not compiled again.\n        for submodule in m.modules():\n            if isinstance(submodule, (nn.Module, nn.Parameter)):\n                if hasattr(submodule, \"training\") and not hasattr(submodule, \"_training\"):\n                    submodule._training = submodule.training\n                    submodule.training = torch.jit.Final[bool](submodule.training)\n\n    _freeze_training_mode_recursively(model)\n    model._training_mode_frozen = True\n    yield\n    model._training_mode_frozen = False\n\n    def _unfreeze_training_mode_recursively(m):\n        if not hasattr(m, \"_training_mode_frozen\"):\n            m._training_mode_frozen = False\n        if not m._training_mode_frozen:\n            return\n        m._training_mode_frozen = False\n\n        # For meta-compiled models, we need to unfreeze the training mode of all submodules\n        # to ensure that they are not compiled again.\n        for submodule in m.modules():\n            if isinstance(submodule, (nn.Module, nn.Parameter)):\n                if hasattr(submodule, \"_training\"):\n                    submodule.training = submodule._training\n                   "}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        # This function is used to modify the class definition of a given module to annotate its \"training\" attribute as a constant.\n        # It is used as a callback function for iterating through all submodules of a given model.\n        # Input-Output Arguments\n        # :param module: The module whose class definition is to be modified.\n        # :return: No return values. This function operates by side effects, modifying the class definition of the given module.\n        # The following code block modifies the class definition of the given module to annotate its \"training\" attribute as a constant.\n        # It uses the torch.jit.freeze_class_decorator function to annotate the \"training\" attribute as a constant using the torch.jit.Final type annotation.\n        # It also uses the torch.jit.unused decorator to suppress warnings about unused attributes.\n        # The modified class definition is then assigned back to the module's class attribute.\n        module.__class__ = torch.jit.freeze_class_decorator(\n            torch.jit.unused(torch.jit.Final[bool])(module.__class__)\n        )\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.train()"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: add a test for this function\n\n    def _freeze_training_mode(module):\n        # Freeze training mode of the module\n        module.__class__.__prepare_scriptable__ = lambda self: self\n        module.__class__.__annotations__[\"training\"] = torch.jit.Final[bool]\n\n    model.apply(_freeze_training_mode)\n    yield\n    model.apply(lambda module: delattr(module, \"__prepare_scriptable__\"))\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    from detectron2.modeling import META_ARCH_REGISTRY, build_model\n\n    # First, we need to find all submodules in the model.\n    submodules = []\n    for name, module in model.named_modules():\n        if name == \"\":\n            # Skip the root module itself\n            continue\n        submodules.append(module)\n\n    # Next, we need to temporarily annotate the \"training\" attribute of each submodule as a constant.\n    # We will do this by creating a new class definition that inherits from the original class,\n    # and adding the \"training\" attribute as a constant.\n    for module in submodules:\n        # Create a new class definition\n        class_name = module.__class__.__name__\n        class_dict = module.__class__.__dict__.copy()\n        class_dict[\"training\"] = torch.jit.Final[bool]\n\n        # Create a new class\n        new_class = type(class_name, (module.__class__,), class_dict)\n\n        # Replace the original class with the new class\n        module.__class__ = new_class\n\n    # Finally, we need to ensure that the model's \"training\" attribute is also annotated as a constant.\n    # We will do this by creating a new class definition that inherits from the original class,\n    # and adding the \"training\" attribute as a constant.\n    class_name = model.__class__.__name__\n    class_dict = model.__class__.__dict__.copy()\n    class_dict[\"training\"] = torch.jit.Final[bool]\n\n    # Create a new class\n    new_class = type(class_name, (model.__class__,), class_dict)\n\n    # Replace the original class with the new class\n    model.__class__ = new_class\n\n    # At this point, the \"training\" attribute of each submodule in the model,\n    # and the \"training\" attribute of the model itself, are annotated as constants.\n    # The context manager will now exit, and the original class definitions will be restored.\n    yield\n\n    # Revert the changes to the \"training\" attribute of each submodule and the model.\n    # We will do this by iterating through all submodules in the model,\n    # and removing the \"training\" attribute from their class definitions.\n    for module in submodules:\n        # Get the class definition of the module\n        class_dict = module.__class__.__dict__\n\n        #"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if values[field1].shape equals values[field2].shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{\"name\": m} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], dict):\n            if \"name\" not in metrics[0]:\n                metrics = [{\"name\": m[\"name\"]} for m in metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_names = []\n    metrics_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_names.append(metric)\n            metrics_params.append({})\n        elif isinstance(metric, dict):\n            metrics_names.append(metric[\"name\"])\n            metrics_params.append(metric[\"params\"])\n        else:\n            raise ValueError(\"Invalid metric type\")\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_details = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_details.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_details.append(metric)\n        else:\n            raise ValueError(\"Invalid metric type.\")\n\n    return metric_names, metric_details\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_list = []\n    metrics_params = []\n    if isinstance(metrics, list):\n        for metric in metrics:\n            if isinstance(metric, str):\n                metrics_list.append(metric)\n                metrics_params.append({})\n            elif isinstance(metric, dict):\n                if \"name\" in metric:\n                    metrics_list.append(metric[\"name\"])\n                    metrics_params.append(metric)\n                else:\n                    raise ValueError(\"The metric dictionary must contain a 'name' key.\")\n            else:\n                raise ValueError(\"The metric list must contain either strings or dictionaries.\")\n    elif isinstance(metrics, str):\n        metrics_list.append(metrics)\n        metrics_params.append({})\n    else:\n        raise ValueError(\"The metric list must be a list of strings or dictionaries.\")\n\n    return metrics_list, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            return metrics, []\n        elif isinstance(metrics[0], dict):\n            return [m[\"name\"] for m in metrics], metrics\n    elif isinstance(metrics, str):\n        return [metrics], []\n    elif isinstance(metrics, dict):\n        return [metrics[\"name\"]], [metrics]\n    else:\n        raise ValueError(\"Invalid metrics format.\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        metrics_list = deepcopy(metrics)\n        metrics_list = [m if isinstance(m, dict) else {'name': m} for m in metrics_list]\n        metrics_names = [m['name'] for m in metrics_list]\n        return metrics_names, metrics_list\n    else:\n        raise TypeError(f\"metrics must be a list of dictionaries or strings, not {type(metrics)}\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{\"name\": m} for m in metrics]\n\n    metric_names = []\n    metric_params = []\n    for m in metrics:\n        metric_names.append(m[\"name\"])\n        metric_params.append(m)\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    metric_names = []\n    metric_details = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_details.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_details.append(metric)\n        else:\n            raise ValueError(f\"Metric {metric} is not valid\")\n\n    return metric_names, metric_details\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            return metrics, []\n        elif isinstance(metrics[0], dict):\n            return [m[\"name\"] for m in metrics], metrics\n        else:\n            raise ValueError(\"Invalid metrics format\")\n    else:\n        raise ValueError(\"Invalid metrics format\")\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_names = []\n    metrics_parameters = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_names.append(metric)\n            metrics_parameters.append({})\n        elif isinstance(metric, dict):\n            metrics_names.append(metric[\"name\"])\n            metrics_parameters.append(metric)\n        else:\n            raise ValueError(\"Invalid metric type\")\n\n    return metrics_names, metrics_parameters\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_names = []\n    metrics_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_names.append(metric)\n            metrics_params.append({})\n        elif isinstance(metric, dict):\n            metrics_names.append(metric[\"name\"])\n            metrics_params.append(metric[\"params\"])\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_list = []\n    metrics_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_list.append(metric)\n        elif isinstance(metric, dict):\n            metrics_list.append(metric[\"name\"])\n            metrics_params.append(metric)\n\n    return metrics_list, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            return metrics, []\n        elif isinstance(metrics[0], dict):\n            return [d[\"name\"] for d in metrics], metrics\n    else:\n        raise ValueError(\"metrics must be a list of dictionaries or strings.\")\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metrics_list = []\n    metrics_params = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_list.append(metric)\n            metrics_params.append({})\n        elif isinstance(metric, dict):\n            metrics_list.append(metric['name'])\n            metrics_params.append(metric['params'])\n        else:\n            raise ValueError('Metric must be a string or a dictionary.')\n\n    return metrics_list, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metric_names = deepcopy(metrics)\n            metric_params = []\n        elif isinstance(metrics[0], dict):\n            metric_names = []\n            metric_params = deepcopy(metrics)\n        else:\n            raise ValueError(\"The metrics list should contain strings or dictionaries.\")\n    else:\n        raise ValueError(\"The metrics argument should be a list.\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [\n                {\n                    \"name\": metric,\n                    \"params\": {},\n                }\n                for metric in metrics\n            ]\n        elif isinstance(metrics[0], dict):\n            metrics = deepcopy(metrics)\n        else:\n            raise ValueError(\"Invalid metrics format.\")\n    elif isinstance(metrics, dict):\n        metrics = [\n            {\n                \"name\": metric,\n                \"params\": {},\n            }\n            for metric in metrics\n        ]\n    else:\n        raise ValueError(\"Invalid metrics format.\")\n    metrics = [\n        {\n            \"name\": metric[\"name\"],\n            \"params\": metric.get(\"params\", {}),\n        }\n        for metric in metrics\n    ]\n    metric_names = [metric[\"name\"] for metric in metrics]\n    return metric_names, metrics\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{\"name\": m} for m in metrics]\n        elif isinstance(metrics[0], dict):\n            if not all(isinstance(m, dict) for m in metrics):\n                raise ValueError(\"metrics must be a list of dictionaries\")\n            if not all(\"name\" in m for m in metrics):\n                raise ValueError(\"metrics must be a list of dictionaries with 'name' key\")\n    elif isinstance(metrics, dict):\n        metrics = [metrics]\n    else:\n        raise ValueError(\"metrics must be a list or a dictionary\")\n\n    names = [m[\"name\"] for m in metrics]\n    metrics = [m.pop(\"name\") for m in metrics]\n\n    return names, metrics\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        metrics = deepcopy(metrics)\n    else:\n        metrics = [metrics]\n\n    metrics_names = []\n    metrics_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metrics_names.append(metric)\n            metrics_params.append({})\n        elif isinstance(metric, dict):\n            if \"name\" in metric:\n                metrics_names.append(metric[\"name\"])\n                metrics_params.append(metric)\n            else:\n                raise ValueError(\"Metric dictionary must contain a 'name' key.\")\n        else:\n            raise ValueError(\"Metric must be a string or a dictionary.\")\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metrics = [{\"name\": m} for m in metrics]\n        else:\n            assert all(\n                isinstance(m, dict) and \"name\" in m\n                for m in metrics\n            ), \"metrics must be a list of dictionaries with a 'name' key\"\n    else:\n        metrics = [{\"name\": metrics}]\n\n    metrics = deepcopy(metrics)\n\n    return [m[\"name\"] for m in metrics], [m for m in metrics]\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            return metrics, []\n        elif isinstance(metrics[0], dict):\n            return [m['name'] for m in metrics], metrics\n    else:\n        raise ValueError(\"metrics must be a list of either strings or dicts\")\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError(f'No inverse for {fn} found.')\n\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    s = jnp.clip(s, 0, 1)\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        geopoly.geopoly_forward: geopoly.geopoly_backward,\n        geopoly.geopoly_backward: geopoly.geopoly_forward,\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'No inverse for {fn}')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1], based on the given function and its inverse.\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be transformed.\n    :return: Tensor. The transformed normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = fn(t)\n    s = jnp.clip(s, 0, 1)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances, based on the given function and its inverse.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be transformed.\n    :return: Tensor. The transformed metric distances.\n    \"\"\"\n    s = jnp.clip(s, 0, 1)\n    t = fn_inv(s)\n    t = jnp.clip(t, t_near, t_far)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances in the range [0, 1] corresponding to the input metric distances.\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    :param s: Tensor. Represents the normalized distances to be mapped back to metric distances.\n    :return: Tensor. The metric distances corresponding to the input normalized distances in the range [0, 1].\n    \"\"\"\n    if fn_inv is not None:\n      t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    else:\n      if fn is contract:\n        t = inv_contract(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n      elif fn is contract3_isoscale:\n        t = inv_contract(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n      else:\n        raise ValueError('No inverse for fn.')\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    s = jnp.clip(s, 0.0, 1.0)\n    if fn_inv is not None:\n      t = fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n    else:\n      if fn is contract:\n        t = inv_contract(s * (t_far - t_near) + t_near)\n      elif fn is contract3_isoscale:\n        t = s * (t_far - t_near) + t_near\n      else:\n        raise ValueError(\n            f'No inverse for {fn} is known, and no explicit inverse was provided.'\n        )\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    t = (fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near)) - t_near) / (\n        t_far - t_near\n    )\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped back to metric distances.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        geopoly.geopoly: geopoly.geopoly_inv,\n        geopoly.geopoly_inv: geopoly.geopoly,\n    }.get(fn, None)\n    if fn_inv is None:\n      raise ValueError(\n          f'No inverse for {fn} found. Please provide one using the `fn_inv` argument.'\n      )\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    elif fn is geopoly.geopoly:\n      fn_inv = geopoly.geopoly_inv\n    elif fn is math.sigmoid:\n      fn_inv = math.sigmoid_inv\n    else:\n      raise ValueError(f'No inverse for {fn}')\n\n  def t_to_s(t):\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s = fn(t_clipped)\n    return s\n\n  def s_to_t(s):\n    t = fn_inv(s)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn is jnp.tanh:\n      fn_inv = jnp.arctanh\n    elif fn is jnp.sinh:\n      fn_inv = jnp.arcsinh\n    elif fn is jnp.cosh:\n      fn_inv = jnp.arccosh\n    elif fn is jnp.exp:\n      fn_inv = jnp.log\n    elif fn is jnp.log:\n      fn_inv = jnp.exp\n    elif fn is jnp.sqrt:\n      fn_inv = jnp.square\n    elif fn is jnp.square:\n      fn_inv = jnp.sqrt\n    elif fn is jnp.cbrt:\n      fn_inv = jnp.power(jnp.array(3.0), jnp.array(2.0))\n    elif fn is jnp.power(jnp.array(3.0), jnp.array(2.0)):\n      fn_inv = jnp.cbrt\n    else:\n      raise ValueError(f'No known inverse for {fn}')\n\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t - t_near) - fn(t_far - t_near)) / (fn(t_near) - fn(t_far))\n\n  def s_to_t(s):\n    s = jnp.clip(s, 0.0, 1.0)\n    return fn_inv(s * (fn(t_near) - fn(t_far)) + fn(t_far - t_near)) + t_near\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    if fn_inv is None:\n      if fn is contract:\n        fn_inv = inv_contract\n      elif fn is geopoly.geopoly_warp:\n        fn_inv = geopoly.geopoly_warp_inv\n      else:\n        raise ValueError(\n            f'No inverse function provided for {fn} and no default inverse '\n            'function available.'\n        )\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances in the range [0, 1], corresponding to the input metric distances.\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances corresponding to the input normalized distances.\n    \"\"\"\n    if fn_inv is not None:\n      t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    else:\n      if fn == contract3_isoscale:\n        fn_inv = inv_contract\n      elif fn == contract:\n        fn_inv = inv_contract\n      elif fn == geopoly.geopoly_fn:\n        fn_inv = geopoly.geopoly_inv_fn\n      elif fn == geopoly.geopoly_inv_fn:\n        fn_inv = geopoly.geopoly_fn\n      elif fn == math.sigmoid:\n        fn_inv = math.sigmoid_inv\n      elif fn == math.sigmoid_inv:\n        fn_inv = math.sigmoid\n      elif fn == math.log_sigmoid:\n        fn_inv = math.log_sigmoid_inv\n      elif fn == math.log_sigmoid_inv:\n        fn_inv = math.log_sigmoid\n      elif fn == math.log_sigmoid_inv_exp:\n        fn_inv = math.log_sigmoid_exp\n      elif fn == math.log_sigmoid_exp:\n        fn_inv = math.log_sigmoid_inv_exp\n      else:\n        raise ValueError(f'No inverse for {fn}')\n      t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n "}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        geopoly.geopoly_forward: geopoly.geopoly_backward,\n    }.get(fn)\n  if fn_inv is None:\n    raise ValueError(\n        f'No inverse for {fn} was found. Please provide one with the fn_inv '\n        f'argument.'\n    )\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = fn(t)\n    s = jnp.clip(s, 0, 1)\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances to metric distances.\"\"\"\n    s = jnp.clip(s, 0, 1)\n    t = fn_inv(s)\n    t = jnp.clip(t, t_near, t_far)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        jnp.sin: jnp.arcsin,\n        jnp.cos: jnp.arccos,\n        jnp.tan: jnp.arctan,\n        jnp.sinh: jnp.arcsinh,\n        jnp.cosh: jnp.arccosh,\n        jnp.tanh: jnp.arctanh,\n        jnp.sqrt: jnp.square,\n        jnp.square: jnp.sqrt,\n    }.get(fn)\n\n  if fn_inv is None:\n    raise ValueError(\n        f'fn_inv not provided and could not be automatically determined for fn={fn}'\n    )\n\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    s = jnp.clip(s, 0, 1)\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  t_near = jnp.asarray(t_near)\n  t_far = jnp.asarray(t_far)\n  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    elif fn is math.identity:\n      fn_inv = math.identity\n    elif fn is math.sigmoid:\n      fn_inv = math.sigmoid_inv\n    elif fn is math.sigmoid_inv:\n      fn_inv = math.sigmoid\n    else:\n      raise ValueError(f'No inverse for {fn} known.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances in the range [0, 1] corresponding to the input metric distances.\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = fn(t)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped to metric distances.\n    :return: Tensor. The metric distances corresponding to the input normalized distances.\n    \"\"\"\n    t = fn_inv(s)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == geopoly.geopoly_transform:\n      fn_inv = geopoly.geopoly_transform_inv\n    else:\n      raise NotImplementedError(\n          f'No default inverse for {fn} (please provide `fn_inv`).'\n      )\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be normalized.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    t_norm = (t - t_near) / (t_far - t_near)\n    s = fn(t_norm)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be converted back to metric distances.\n    :return: Tensor. The metric distances corresponding to the normalized distances.\n    \"\"\"\n    t_norm = fn_inv(s)\n    t = t_norm * (t_far - t_near) + t_near\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances in the range [0, 1] corresponding to the input metric distances.\n    \"\"\"\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s = (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances corresponding to the input normalized distances.\n    \"\"\"\n    if fn_inv is None:\n      # Automatically determine the inverse of `fn` if not provided.\n      fn_inv = {\n          contract: inv_contract,\n          contract3_isoscale: lambda x: inv_contract(x)[:, 0],\n      }.get(fn)\n      if fn_inv is None:\n        raise ValueError(\n            f'fn_inv is not provided and cannot be automatically determined for fn {fn}'\n        )\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        geopoly.geopoly_warp: geopoly.geopoly_warp_inv,\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError(\n          f'No inverse function found for {fn}. Please provide it explicitly.'\n      )\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be transformed.\n    :return: Tensor. The transformed normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = fn(t)\n    s = jnp.clip(s, 0, 1)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be transformed.\n    :return: Tensor. The transformed metric distances.\n    \"\"\"\n    s = jnp.clip(s, 0, 1)\n    t = fn_inv(s)\n    t = jnp.clip(t, t_near, t_far)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # The inverse of the contract function is the inv_contract function.\n  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    elif fn is inv_contract:\n      fn_inv = contract\n    else:\n      raise ValueError(\n          'fn_inv not provided and fn is not contract or inv_contract'\n      )\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t_near = jnp.maximum(t_near, t)\n    t_far = jnp.minimum(t_far, t)\n    s = (t - t_near) / (t_far - t_near)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped back to metric distances.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    t = s * (t_far - t_near) + t_near\n    return t\n\n  def t_to_s_inv(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t_near = jnp.maximum(t_near, t)\n    t_far = jnp.minimum(t_far, t)\n    s = (t - t_near) / (t_far - t_near)\n    return s\n\n  def s_to_t_inv(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped back to metric distances.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    t = s * (t_far - t_near)"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == jnp.sin:\n      fn_inv = jnp.arcsin\n    elif fn == jnp.sinh:\n      fn_inv = jnp.arcsinh\n    elif fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.sqrt:\n      fn_inv = jnp.square\n    elif fn == jnp.tan:\n      fn_inv = jnp.arctan\n    elif fn == jnp.tanh:\n      fn_inv = jnp.arctanh\n    elif fn == jnp.sinh_plus_x:\n      fn_inv = jnp.arcsinh_plus_x\n    elif fn == jnp.sinh_minus_x:\n      fn_inv = jnp.arcsinh_minus_x\n    elif fn == jnp.sinh_plus_x_inv:\n      fn_inv = jnp.arcsinh_plus_x_inv\n    elif fn == jnp.sinh_minus_x_inv:\n      fn_inv = jnp.arcsinh_minus_x_inv\n    else:\n      raise ValueError(\n          f'No inverse for {fn} provided, and no default inverse could be determined.'\n      )\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. The normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.clip(t, t_near, t_far)\n    s = fn(t)\n    s = (s - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped back to metric distances.\n    :return: Tensor. The metric distances.\n    \"\"\"\n    s = jnp.clip(s, 0.0, 1.0)\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Clip the distances to ensure they fall within a valid range.\n  t_near = jnp.clip(t_near, 0, t_far)\n  t_far = jnp.clip(t_far, t_near, np.inf)\n\n  # Define the inverse of the `fn` function if not provided.\n  if fn_inv is None:\n    # Define a mapping of functions to their inverses.\n    fn_inv_map = {\n        contract: inv_contract,\n        geopoly.geopoly: geopoly.geopoly_inv,\n        geopoly.geopoly_inv: geopoly.geopoly,\n    }\n    # Check if the `fn` function is in the mapping.\n    if fn in fn_inv_map:\n      # If it is, use the corresponding inverse function.\n      fn_inv = fn_inv_map[fn]\n    else:\n      # Otherwise, raise an error.\n      raise ValueError(\n          f'No inverse function found for {fn} in fn_inv_map. Please provide an inverse function for {fn} using the fn_inv argument.'\n      )\n\n  # Define the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances in the range [0, 1] corresponding to the input metric distances.\n    \"\"\"\n    # Clip the distances to ensure they fall within a valid range.\n    t = jnp.clip(t, t_near, t_far)\n    # Map the distances using the `fn` function.\n    s = fn(t)\n    # Normalize the distances to the range [0, 1].\n    s = (s - t_near) / (t_far - t_near)\n    return s\n\n  # Define the backward mapping from normalized to metric distances.\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances back to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances corresponding to the input normalized distances.\n    \"\"\"\n    # Clip the distances to"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    elif fn is jnp.tanh:\n      fn_inv = jnp.arctanh\n    elif fn is jnp.sinh:\n      fn_inv = jnp.arcsinh\n    elif fn is jnp.sin:\n      fn_inv = jnp.arcsin\n    elif fn is jnp.exp:\n      fn_inv = jnp.log\n    elif fn is jnp.log:\n      fn_inv = jnp.exp\n    else:\n      raise ValueError(\n          f'Cannot automatically determine the inverse of {fn}. Please provide '\n          'it explicitly via the `fn_inv` argument.'\n      )\n\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.cos(phi)\n  y = r * jnp.cos(theta) * jnp.sin(phi)\n  z = r * jnp.sin(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Calculate the cartesian coordinates\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  # Return the cartesian coordinates as a numpy array\n  return jnp.array([x, y, z])  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Calculate the cartesian coordinates\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  check_zero_endpoints(w)\n  return math.trapz(w, t)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Check if the input is a tuple of lists of strings\n    if not all(isinstance(id_list, list) and all(isinstance(id, str) for id in id_list) for id_list in ids):\n        raise TypeError(\"The input 'ids' must be a tuple of lists of strings.\")\n\n    # Check if the input is a tuple of lists of floats\n    if not all(isinstance(score_list, list) and all(isinstance(score, float) for score in score_list) for score_list in scores):\n        raise TypeError(\"The input 'scores' must be a tuple of lists of floats.\")\n\n    # Check if the input is a tuple of floats\n    if not all(isinstance(weight, float) for weight in weights):\n        raise TypeError(\"The input 'weights' must be a tuple of floats.\")\n\n    # Check if the input is an integer\n    if not isinstance(top_k, int):\n        raise TypeError(\"The input 'top_k' must be an integer.\")\n\n    # Check if the input is a positive integer\n    if top_k <= 0:\n        raise ValueError(\"The input 'top_k' must be a positive integer.\")\n\n    # Check if the input is a tuple of lists of the same length\n    if not all(len(id_list) == len(score_list) for id_list, score_list in zip(ids, scores)):\n        raise ValueError(\"The input 'ids' and 'scores' must be tuples of lists of the same length.\")\n\n    # Check if the input is a tuple of lists of the same length as the number of weights\n    if len(ids) != len(weights):\n        raise ValueError(\"The input 'ids' and 'weights' must be tuples of lists of the same length.\")\n\n    # Check if the sum of weights is equal to 1\n    if sum("}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    df['score_sum'] = df[[f'score_{i}' for i in range(len(scores))]].sum(axis=1)\n    df['score_norm'] = df['score_sum'] / df['score_sum'].max()\n    df['score_weighted'] = df['score_norm'] * weights[0]\n    for i in range(1, len(weights)):\n        df[f'score_weighted_{i}'] = df[f'score_norm'] * weights[i]\n        df['score_weighted'] += df[f'score_weighted_{i}']\n    df = df.sort_values(by='score_weighted', ascending=False).reset_index(drop=True)\n    return df.loc[:top_k - 1, 'id_0'].tolist(), df.loc[:top_k - 1, 'score_weighted'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = []\n    for i in range(len(ids[0])):\n        weighted_sum = 0\n        for j in range(len(ids)):\n            weighted_sum += scores[j][i] * weights[j]\n        weighted_sums.append(weighted_sum)\n\n    # Normalize the weighted sums\n    max_sum = max(weighted_sums)\n    min_sum = min(weighted_sums)\n    if max_sum == min_sum:\n        normalized_sums = [1] * len(weighted_sums)\n    else:\n        normalized_sums = [(x - min_sum) / (max_sum - min_sum) for x in weighted_sums]\n\n    # Sort the IDs and corresponding normalized sums in descending order\n    sorted_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)\n    sorted_ids = [ids[i] for i in sorted_indices]\n    sorted_sums = [normalized_sums[i] for i in sorted_indices]\n\n    # Return the top K IDs and their corresponding normalized sums\n    top_k_ids = sorted_ids[:top_k]\n    top_k_sums = sorted_sums[:top_k]\n    return top_k_ids, top_k_sums"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a DataFrame with the IDs, scores, and weights\n    df = pd.DataFrame({'id': ids[0], 'score': scores[0], 'weight': weights[0]})\n    for i in range(1, len(ids)):\n        df_i = pd.DataFrame({'id': ids[i], 'score': scores[i], 'weight': weights[i]})\n        df = pd.concat([df, df_i])\n\n    # Calculate the weighted sum of scores for each ID\n    df['weighted_score'] = df['score'] * df['weight']\n    df = df.groupby('id')['weighted_score'].sum().reset_index()\n\n    # Normalize the weighted scores\n    df['normalized_score'] = (df['weighted_score'] - df['weighted_score'].min()) / (\n                df['weighted_score'].max() - df['weighted_score'].min())\n\n    # Sort the IDs by their normalized scores in descending order\n    df = df.sort_values('normalized_score', ascending=False)\n\n    # Return the top K IDs and their corresponding normalized scores\n    return df['id'].tolist()[:top_k], df['normalized_score'].tolist()[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sum = {}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            if ids[i][j] not in weighted_sum:\n                weighted_sum[ids[i][j]] = scores[i][j] * weights[i]\n            else:\n                weighted_sum[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Normalize the weighted sum scores\n    normalized_sum = {}\n    min_score = min(weighted_sum.values())\n    max_score = max(weighted_sum.values())\n    for id, score in weighted_sum.items():\n        normalized_sum[id] = (score - min_score) / (max_score - min_score)\n\n    # Sort the IDs by their normalized weighted sum scores in descending order\n    sorted_ids = sorted(normalized_sum.items(), key=lambda x: x[1], reverse=True)\n\n    # Return the top K IDs and their corresponding normalized weighted sum scores\n    top_ids = [id for id, _ in sorted_ids[:top_k]]\n    top_scores = [normalized_sum[id] for id in top_ids]\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores for each category\n    normalized_scores = [\n        [score / sum(score_list) for score in score_list] for score_list in scores\n    ]\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = []\n    for i in range(len(ids[0])):\n        weighted_sum = 0\n        for j in range(len(ids)):\n            weighted_sum += normalized_scores[j][i] * weights[j]\n        weighted_sums.append(weighted_sum)\n\n    # Sort the IDs and their corresponding weighted sums in descending order\n    sorted_indices = sorted(range(len(weighted_sums)), key=lambda i: weighted_sums[i], reverse=True)\n    sorted_ids = [ids[i][j] for i in range(len(ids)) for j in sorted_indices]\n    sorted_weighted_sums = [weighted_sums[i] for i in sorted_indices]\n\n    # Return the top K IDs and their corresponding weighted sums\n    return sorted_ids[:top_k], sorted_weighted_sums[:top_k]\n\n        return df['id'].tolist(), df['score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID across all categories\n    weighted_sums = {}\n    for i, id_list in enumerate(ids):\n        for j, id_ in enumerate(id_list):\n            if id_ not in weighted_sums:\n                weighted_sums[id_] = 0\n            weighted_sums[id_] += scores[i][j] * weights[i]\n\n    # Normalize the weighted sums\n    min_sum = min(weighted_sums.values())\n    max_sum = max(weighted_sums.values())\n    if max_sum != min_sum:\n        for id_, weighted_sum in weighted_sums.items():\n            weighted_sums[id_] = (weighted_sum - min_sum) / (max_sum - min_sum)\n\n    # Sort the IDs by their weighted sums in descending order and return the top K\n    sorted_ids = sorted(weighted_sums.items(), key=lambda x: x[1], reverse=True)\n    top_ids = [id_ for id_, _ in sorted_ids[:top_k]]\n    top_scores = [weighted_sums[id_] for id_ in top_ids]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores\n    scores_normalized = []\n    for score_list in scores:\n        score_list_normalized = [score / max(score_list) for score in score_list]\n        scores_normalized.append(score_list_normalized)\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sum = []\n    for i in range(len(ids[0])):\n        weighted_sum_i = 0\n        for j in range(len(ids)):\n            weighted_sum_i += scores_normalized[j][i] * weights[j]\n        weighted_sum.append(weighted_sum_i)\n\n    # Sort the IDs and their corresponding scores by the weighted sum in descending order\n    sorted_indices = sorted(range(len(weighted_sum)), key=lambda i: weighted_sum[i], reverse=True)\n    sorted_ids = [ids[j][i] for j in range(len(ids)) for i in sorted_indices]\n    sorted_scores = [weighted_sum[i] for i in sorted_indices]\n\n    # Return the top K IDs and their corresponding scores\n    return sorted_ids[:top_k], sorted_scores[:top_k]\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(ids)):\n        scores_i = scores[i]\n        min_score = min(scores_i)\n        max_score = max(scores_i)\n        normalized_scores_i = [(score - min_score) / (max_score - min_score) for score in scores_i]\n        normalized_scores.append(normalized_scores_i)\n\n    # Calculate weighted sum of scores\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sums_i = [normalized_scores[i][j] * weights[i] for j in range(len(ids[i]))]\n        weighted_sums.append(weighted_sums_i)\n\n    # Aggregate weighted sums\n    aggregated_weighted_sums = [sum(weighted_sums_i) for weighted_sums_i in zip(*weighted_sums)]\n\n    # Sort IDs and weighted sums based on aggregated weighted sums\n    sorted_indices = sorted(range(len(aggregated_weighted_sums)), key=lambda i: aggregated_weighted_sums[i], reverse=True)\n    sorted_ids = [ids[i] for i in sorted_indices]\n    sorted_weighted_sums = [aggregated_weighted_sums[i] for i in sorted_indices]\n\n    # Return top K IDs and their corresponding weighted sums\n    top_k_ids = sorted_ids[:top_k]\n    top_k_weighted_sums = sorted_weighted_sums[:top_k]\n    return top_k_ids, top_k_weighted_sums"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    id_scores = {}\n    for i, id_list in enumerate(ids):\n        for j, id in enumerate(id_list):\n            if id not in id_scores:\n                id_scores[id] = 0\n            id_scores[id] += scores[i][j] * weights[i]\n\n    # Normalize the weighted sum of scores\n    min_score = min(id_scores.values())\n    max_score = max(id_scores.values())\n    for id in id_scores:\n        id_scores[id] = (id_scores[id] - min_score) / (max_score - min_score)\n\n    # Sort the IDs by their weighted sum in descending order and return the top K IDs and their corresponding scores\n    sorted_id_scores = sorted(id_scores.items(), key=lambda x: x[1], reverse=True)\n    top_ids = [id for id, score in sorted_id_scores[:top_k]]\n    top_scores = [score for id, score in sorted_id_scores[:top_k]]\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Check if the input is a tuple of lists\n    assert isinstance(ids, tuple) and all(isinstance(id_list, list) for id_list in ids), \\\n        \"ids must be a tuple of lists.\"\n    assert isinstance(scores, tuple) and all(isinstance(score_list, list) for score_list in scores), \\\n        \"scores must be a tuple of lists.\"\n    assert isinstance(weights, tuple) and all(isinstance(weight, float) for weight in weights), \\\n        \"weights must be a tuple of floats.\"\n\n    # Initialize a dictionary to store the weighted sum of scores for each ID\n    id_to_score = {}\n\n    # Iterate over each category or group\n    for i in range(len(ids)):\n        # Iterate over each ID and its corresponding score in the category or group\n        for j in range(len(ids[i])):\n            # Retrieve the ID and its corresponding score\n            id_ = ids[i][j]\n            score = scores[i][j]\n\n            # If the ID is already in the dictionary, update its weighted sum of scores\n            if id_ in id_to_score:\n                id_to_score[id_] += score * weights[i]\n            # Otherwise, add the ID to the dictionary with its weighted sum of scores\n            else:\n                id_to_score[id_] = score * weights[i]\n\n    # Normalize the weighted sum of scores for each ID\n    total_score = sum(id_to_score.values())\n    for id_ in id_to_score:\n        id_to_score[id_] /= total_score\n\n    # Sort the IDs based on their weighted sum of scores in descending order\n    sorted_ids = sorted(id_to_score.items(), key=lambda x: x[1], reverse=True)\n\n    # Return the"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def normalize_apply(row):\n        score_list = row[[f'score_{i}' for i in range(len(scores))]].values\n        return (score_list - score_list.min()) / (score_list.max() - score_list.min())\n\n    df[[f'normalized_score_{i}' for i in range(len(scores))]] = df.apply(normalize_apply, axis=1)\n\n    def weighted_sum_apply(row):\n        score_list = row[[f'normalized_score_{i}' for i in range(len(scores))]].values\n        return sum(score_list * weights)\n\n    df['weighted_sum'] = df.apply(weighted_sum_apply, axis=1)\n    df = df.sort_values(by='weighted_sum', ascending=False).head(top_k)\n    return df['id_0'].tolist(), df['weighted_sum'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = {}\n    for i, id_list in enumerate(ids):\n        for j, id in enumerate(id_list):\n            if id not in weighted_sums:\n                weighted_sums[id] = 0\n            weighted_sums[id] += scores[i][j] * weights[i]\n\n    # Normalize the weighted sums\n    normalized_sums = {}\n    min_sum = min(weighted_sums.values())\n    max_sum = max(weighted_sums.values())\n    for id, weighted_sum in weighted_sums.items():\n        normalized_sums[id] = (weighted_sum - min_sum) / (max_sum - min_sum)\n\n    # Sort the IDs based on their normalized weighted sums in descending order\n    sorted_ids = sorted(normalized_sums.keys(), key=lambda x: normalized_sums[x], reverse=True)\n\n    # Return the top K IDs and their corresponding normalized weighted sums\n    return sorted_ids[:top_k], [normalized_sums[id] for id in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sum = {}\n    for i, id_list in enumerate(ids):\n        for j, id_ in enumerate(id_list):\n            if id_ not in weighted_sum:\n                weighted_sum[id_] = 0\n            weighted_sum[id_] += scores[i][j] * weights[i]\n\n    # Normalize the weighted sum of scores\n    min_score = min(weighted_sum.values())\n    max_score = max(weighted_sum.values())\n    if min_score != max_score:\n        for id_ in weighted_sum:\n            weighted_sum[id_] = (weighted_sum[id_] - min_score) / (max_score - min_score)\n\n    # Sort the IDs based on their weighted sum in descending order and return the top K IDs and their corresponding scores\n    sorted_weighted_sum = sorted(weighted_sum.items(), key=lambda x: x[1], reverse=True)\n    top_k_ids = [id_ for id_, _ in sorted_weighted_sum[:top_k]]\n    top_k_scores = [score for _, score in sorted_weighted_sum[:top_k]]\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a DataFrame from the input data\n    data = {'id': ids, 'score': scores}\n    df = pd.DataFrame(data)\n\n    # Calculate the weighted sum of scores for each ID\n    df['weighted_sum'] = df['score'] * weights\n\n    # Group by ID and calculate the sum of weighted scores\n    df = df.groupby('id')['weighted_sum'].sum().reset_index()\n\n    # Normalize the weighted sums\n    df['normalized_weighted_sum'] = df['weighted_sum'] / df['weighted_sum'].sum()\n\n    # Sort by normalized weighted sum in descending order and select the top K IDs and their scores\n    df = df.sort_values('normalized_weighted_sum', ascending=False).head(top_k)\n\n    # Return the top K IDs and their corresponding scores\n    return df['id'].tolist(), df['normalized_weighted_sum'].tolist()\n    # Get the top-k passages\n        top_k_passages = [\n            passage\n            for passage in passages\n            if passage.id in top_k_ids\n        ]\n\n        # Return the top-k passages\n        return top_k_passages\n\n    def get_passages(self, ids: List[str]) -> List[Passage]:\n        \"\"\"\n        Get passages by ids.\n\n        :param ids: The list of ids.\n        :return: The list of passages.\n        \"\"\"\n        return [self.get_passage(id) for id in ids]\n\n    def get_passage(self, id: str) -> Passage:\n        \"\"\"\n        Get passage by id.\n\n        :param id: The id of passage.\n        :return: The passage.\n        \"\"\"\n        return self.passages[id]\n\n    def get_passages_by_query(self, query: str) ->"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Calculate the weighted sum of scores for each ID\n    weighted_sums = {}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            weighted_sums[ids[i][j]] = weighted_sums.get(ids[i][j], 0) + scores[i][j] * weights[i]\n\n    # Normalize the weighted sums\n    min_sum = min(weighted_sums.values())\n    max_sum = max(weighted_sums.values())\n    for k, v in weighted_sums.items():\n        weighted_sums[k] = (v - min_sum) / (max_sum - min_sum)\n\n    # Sort the IDs by their weighted sums in descending order\n    sorted_ids = sorted(weighted_sums.items(), key=lambda x: x[1], reverse=True)\n\n    # Return the top K IDs and their corresponding weighted sums\n    return [k for k, _ in sorted_ids[:top_k]], [v for _, v in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    df['score'] = 0\n    for i in range(len(ids)):\n        df['score'] += df[f'id_{i}'] * scores[i] * weights[i]\n\n    df = df.sort_values(by='score', ascending=False).reset_index(drop=True)\n    return df['id_0'].values[:top_k].tolist(), df['score'].values[:top_k].tolist()\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check the length of the input arguments\n    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a DataFrame from the input arguments\n    df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    df = pd.concat([df, pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})], axis=1)\n\n    # Normalize the scores for each category\n    for i in range(len(ids)):\n        df[f'score_{i}'] = df[f'score_{i}'] / df[f'score_{i}'].sum()\n\n    # Calculate the weighted sum of scores for each ID\n    df['weighted_sum'] = df[[f'score_{i}' for i in range(len(ids))]].mul(weights).sum(axis=1)\n\n    # Sort the DataFrame by the weighted sum in descending order\n    df = df.sort_values(by='weighted_sum', ascending=False)\n\n    # Return the top K IDs and their corresponding weighted sums\n    return df['id_0'].iloc[:top_k].tolist(), df['weighted_sum'].iloc[:top_k].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    df = df.drop_duplicates()\n\n    df['score'] = 0\n    for i, weight in enumerate(weights):\n        df['score'] += df[f'id_{i}'].map(dict(zip(ids[i], scores[i]))) * weight\n\n    df = df.sort_values(by='score', ascending=False)\n    return df[f'id_{i}'].iloc[:top_k].tolist(), df['score'].iloc[:top_k].tolist()"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  jac = jax.jacrev(fn)(mean)\n\n  # Transform the covariances\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n\n  # Transform the means\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', fn_cov, jac)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n  # Calculate the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Calculate the Jacobian of the function at the mean\n  jac = jax.jacrev(fn)(mean)\n\n  # Calculate the transformed means\n  fn_mean = fn(mean)\n\n  # Calculate the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacrev(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', fn_cov, jac)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n  # Compute the transformed means\n  fn_mean = fn(mean)\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, jac) @ cov\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances\n  fn_cov = jnp.einsum(\"...ij,...jk,...kl\", jac, cov, jac)\n\n  # Transform the means\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Calculate the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Calculate the transformed means\n  fn_mean = fn(mean)\n\n  # Calculate the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n\n  # Transform the means using the function\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacrev(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum(\"...ij,...jk,...kl->...il\", jac, cov, jac)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  jac = jax.jacfwd(fn)(mean)\n  # Transform the covariances accordingly\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  jac = jax.jacrev(fn)(mean)\n  # Transform the covariances accordingly\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n  fn_mean = fn(mean)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  J = jax.jacfwd(fn)(mean)\n  # Transform the covariances\n  fn_cov = J @ cov @ J.T\n  # Transform the means\n  fn_mean = fn(mean)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Calculate the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jac @ cov @ jac.T\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  # Calculate the Jacobian of the function at the mean\n  jac = jax.jacrev(fn)(mean)\n\n  # Apply the Jacobian to the covariance\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, cov)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacrev(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', fn_cov, jac)\n\n  # Transform the means using the function\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', fn_cov, jac)\n\n  # Transform the means\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Calculate the Jacobian of the function at the mean\n  jac = jax.jacrev(fn)(mean)\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum(\"...ij,...jk->...ik\", jac, jac) @ cov\n  # Transform the means using the function\n  fn_mean = fn(mean)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n  # Compute the transformed covariance\n  fn_cov = jnp.einsum('...ij,...kj->...ik', jacobian, jacobian) @ cov\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n  # Compute the transformed mean\n  fn_mean = fn(mean)\n  # Compute the transformed covariance\n  fn_cov = jnp.einsum('...ij,...kj->...ik', jac, jac) @ cov\n  return fn_mean, fn_cov\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            n = len(i)\n            yield [i[: n // 2], i[n // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, xi in enumerate(x):\n        if xi.size > 1:\n            yield [xi[: xi.size // 2], xi[xi.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            n = len(i)\n            a = i[: n // 2]\n            b = i[n // 2 :]\n            yield [a, b]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield np.split(i, 2)\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.shape[0] > 1:\n            yield np.split(i, 2)\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.shape[0] > 1:\n            yield [i[: i.shape[0] // 2], i[i.shape[0] // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, arr in enumerate(x):\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]\n        else:\n            yield [arr, arr]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            n = len(i)\n            yield [i[: n // 2], i[n // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            n = len(i)\n            yield i[: n // 2], i[n // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield i[: len(i) // 2], i[len(i) // 2 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            mid = len(i) // 2\n            yield i[:mid], i[mid:]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if x[i].size > 1:\n            yield [x[i][: x[i].size // 2], x[i][x[i].size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, elem in enumerate(x):\n        if len(elem) > 1:\n            yield [elem[: len(elem) // 2], elem[len(elem) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            mid = len(i) // 2\n            yield [i[:mid], i[mid:]]\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input array must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  if append_identity:\n    return jnp.concatenate([scaled_x, x], axis=-1)\n  else:\n    return scaled_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  if append_identity:\n    return jnp.concatenate([scaled_x, x], axis=-1)\n  else:\n    return scaled_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  if append_identity:\n    return jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x), x], axis=-1)\n  else:\n    return jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  if append_identity:\n    return jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi, x], axis=-1)\n  else:\n    return jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1)\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  pos_enc = expected_sin(scaled_x, 0)\n  if append_identity:\n    return jnp.concatenate([pos_enc, x], axis=-1)\n  return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  pos_enc = expected_sin(scaled_x, 0.0)\n  if append_identity:\n    pos_enc = jnp.concatenate([x, pos_enc], axis=-1)\n  return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  if append_identity:\n    return jnp.concatenate([scaled_x, x], axis=-1)\n  else:\n    return scaled_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  encoded = jnp.sin(scaled_x)\n  if append_identity:\n    return jnp.concatenate([encoded, x], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  pos_enc = expected_sin(scaled_x, 0)\n\n  if append_identity:\n    return jnp.concatenate([pos_enc, x], axis=-1)\n  else:\n    return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  pos_enc = jnp.concatenate(\n      [jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1\n  )  # [N, ..., 2 * (max_deg - min_deg)]\n  if append_identity:\n    pos_enc = jnp.concatenate([pos_enc, x], axis=-1)  # [N, ..., 2 * (max_deg - min_deg) + D]\n  return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales as powers of 2 from min_deg to max_deg\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  # Reshape the input to add an extra dimension for broadcasting\n  shape = x.shape[:-1] + (-1,)\n  # Apply the positional encoding by scaling the input and applying a sine function\n  encoded = jnp.sin(jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape))\n  # Optionally concatenate the original input with the encoded features\n  if append_identity:\n    encoded = jnp.concatenate([encoded, x], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None] * scales[:, None], shape)\n\n  if append_identity:\n    return jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x), x[..., None]], axis=-1)\n  else:\n    return jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  result = jnp.sin(scaled_x)\n  if append_identity:\n    result = jnp.concatenate([result, x], axis=-1)\n  return result\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  pos_enc = jnp.concatenate(\n      [jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1\n  )  # [N, 2 * (max_deg - min_deg)]\n  if append_identity:\n    return jnp.concatenate([x, pos_enc], axis=-1)\n  else:\n    return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    return jnp.concatenate([x, encoded], axis=-1)\n  else:\n    return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded = jnp.concatenate([encoded, x], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Calculate the scale factors\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the input by the scale factors\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], x.shape[:-1] + (-1,))\n\n  # Apply the sine function to the scaled input\n  sin_x = jnp.sin(scaled_x)\n\n  # Concatenate the original input with the encoded features if append_identity is True\n  if append_identity:\n    return jnp.concatenate([sin_x, x], axis=-1)\n\n  # Otherwise, return the encoded features only\n  return sin_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = jnp.sin(scaled_x)\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scaling factors\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the input array\n  scaled_x = x[Ellipsis, None, :] * scales[:, None]\n\n  # Apply the sine function to the scaled array\n  pos_enc = jnp.sin(scaled_x)\n\n  # Append the original input array if specified\n  if append_identity:\n    pos_enc = jnp.concatenate([pos_enc, x[Ellipsis, None, :]], axis=-1)\n\n  return pos_enc\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  pos_enc = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    pos_enc = jnp.concatenate([pos_enc, x[..., None, :]], axis=-1)\n  return pos_enc\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator:\n        \"\"\"\n        This function generates a Pydantic validator that checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param field1: str. The name of the first field to be validated. It represents one of the lists of numpy arrays.\n        :param field2: str. The name of the second field to be validated. It represents the other list of numpy arrays to compare against the first.\n        :return: Callable. A function that acts as a Pydantic model validator. This validator function takes a class type and a dictionary of values, checks for shape equality between arrays in the specified fields, and returns the validated values if the check passes.\n\n        \"\"\"\n\n        def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n            \"\"\"Check if len(field1) equals len(field2).\"\"\"\n            if len(values[field1]) != len(values[field2]):\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                    f\"resp. {len(values[field1])} and {len(values[field2])}\"\n                )\n            for i in range(len(values[field1])):\n                if values[field1][i].shape != values[field2][i"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each corresponding pair of arrays within these lists has the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\"\n                )\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        else:\n            for i in range(len(values[field1])):\n                if values[field1][i].shape != values[field2][i].shape:\n                    raise ValueError(\n                        f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\"\n                    )\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each pair of arrays within these lists have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch for element {i}.\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the Pydantic model.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values to be validated.\n        :return: Dict[str, List[np.ndarray]]. The validated values after the shape equality check.\n\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                    f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\"\n                )\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function is a Pydantic model root validator that checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        The function takes a class type and a dictionary of values as input arguments. It checks if the lengths of the two specified fields are equal, and if each corresponding pair of arrays within these fields has the same shape. If the check passes, the function returns the validated values. If the check fails, a ValueError is raised with a custom error message.\n\n        Args:\n            cls (type): The class type of the Pydantic model.\n            values (Dict[str, List[np.ndarray]]): A dictionary of values to be validated. The keys are the field names, and the values are the corresponding values of the fields.\n\n        Returns:\n            Dict[str, List[np.ndarray]]: The validated values of the fields if the check passes.\n\n        Raises:\n            ValueError: If the lengths of the two specified fields are not equal, or if the shapes of corresponding pairs of arrays are not equal.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                    f\"resp. {array1.shape} and {array2.shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function is a Pydantic model validator that checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the Pydantic model.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values to be validated. It contains the two lists of numpy arrays to be checked for shape equality.\n        :return: Dict[str, List[np.ndarray]]. The validated dictionary of values if the check passes. If the check fails, a ValueError is raised with a descriptive message.\n        \"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function acts as a Pydantic model validator. It checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the Pydantic model being validated.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary of values to be validated. It contains the two fields specified by field1 and field2, which are lists of numpy arrays.\n        :return: Dict[str, List[np.ndarray]]. The validated values if the check passes, otherwise it raises a ValueError with a custom message.\n\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\"\n                )\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each corresponding pair of arrays within these lists has the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\"\n                )\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if all corresponding pairs of arrays within these lists have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                    f\"At index {i}, {field1} has shape {values[field1][i].shape} and {field2} has shape {values[field2][i].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the viewport to match the camera's width and height\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh\n        self.render(camera)\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=True,\n        output_attentions=True,\n        return_dict=True,\n    )\n\n    return nomic_config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.pad_token_id = bert_config.pad_token_id\n    nomic_config.position_embedding_type = bert_config.position_embedding_type\n    nomic_config.output_attentions = bert_config.output_attentions\n    nomic_config.output_hidden_states = bert_config.output_hidden_states\n    nomic_config.output_past = bert_config.output_past\n    nomic_config.torchscript = bert_config.torchscript\n    nomic_config.use_cache = bert_config.use_cache\n    nomic_config.pruning_axis = bert_config.pruning_axis\n    nomic_config.pruning_heads = bert_config.pruning_heads\n    nomic_config.pruning_num_heads = bert_config.pruning_num_heads\n    nomic_config.pruning_indices = bert_config.pruning_indices\n    nomic_config.pruning_degree = bert_config."}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.pad_token_id = bert_config.pad_token_id\n    nomic_config.gradient_checkpointing = bert_config.gradient_checkpointing\n    nomic_config.position_embedding_type = bert_config.position_embedding_type\n    nomic_config.is_decoder = bert_config.is_decoder\n    nomic_config.add_cross_attention = bert_config.add_cross_attention\n    nomic_config.add_pooling_layer = bert_config.add_pooling_layer\n    nomic_config.output_hidden_states = bert_config.output_hidden_states\n    nomic_config.output_attentions = bert_config.output_attentions\n    nomic_config.output_past = bert_config.output_past\n    nomic_config.torchscript = bert_config.torchscript\n    nomic_config.use_cache = bert_config.use_cache\n    nomic_config.pruned_heads = bert_config."}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig()\n\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.num_labels = bert_config.num_labels\n\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.num_labels = bert_config.num_labels\n\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.pad_token_id = bert_config.pad_token_id\n    nomic_config.position_embedding_type = bert_config.position_embedding_type\n    nomic_config.output_attentions = bert_config.output_attentions\n    nomic_config.output_hidden_states = bert_config.output_hidden_states\n    nomic_config.output_past = bert_config.output_past\n    nomic_config.torchscript = bert_config.torchscript\n    nomic_config.use_cache = bert_config.use_cache\n    nomic_config.pruning_axis_names = bert_config.pruning_axis_names\n    nomic_config.gradient_checkpointing = bert_config.gradient_checkpointing\n    nomic_config.max_length = 1024\n    nomic_config.num_memory_slots = 1024\n    nomic_config.num_memory_heads = 16\n    nomic_config.num_memory"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig()\n\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.pad_token_id = bert_config.pad_token_id\n\n    # additional arguments\n    config.output_attentions = False\n    config.output_hidden_states = False\n    config.output_past = False\n    config.torchscript = False\n    config.use_cache = False\n\n    return config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    return NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        is_decoder=True,\n        add_cross_attention=True,\n        add_decoder_layer_norm=True,\n        add_decoder_final_layer_norm=True,\n        add_decoder_final_layer_norm_before_activation=True,\n        add_decoder_input_layer_norm=True,\n        add_decoder_input_layer_norm_before_activation=True,\n        add_decoder_input_layer_norm_after_activation=True,\n        add_decoder_input_layer_norm_before_attention=True,\n        add_decoder_input_layer_norm_after_attention=True,\n        add_decoder_input_layer_norm_before_intermediate=True,\n        add_decoder_input_layer_norm_after_intermediate=True,\n        add_decoder_input_layer_norm_before_output=True,\n        add_decoder_input_layer_norm_after_output=True,\n        add_decoder_input_layer_norm_before_attention_output=True,\n        add_decoder_input_layer_norm_after_attention_output=True,\n        add_decoder_input_layer"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=True,\n        is_decoder=False,\n        add_pooling_layer=False,\n        output_hidden_states=False,\n        output_attentions=False,\n        output_past=False,\n        output_past_key_values=False,\n        output_past_key_values_memory_efficient=False,\n        output_past_key_values_memory_efficient_attention_probs=False,\n        output_past_key_values_memory_efficient_hidden_states=False,\n        output_past_key_values_memory_efficient_hidden_states_attention_probs=False,\n        output_past_key_values_memory_efficient_only_attention_probs=False,\n        output_past_key_values_memory_efficient_only_hidden_states=False,\n        output_past_key_values_memory_efficient_only_hidden_states_attention_probs=False,\n        output_past_key_values_memory_efficient_only_key_values=False,\n        output_past_key_values_memory_efficient_only_key_values_attention_probs=False,\n        output_past_key_values_memory_efficient_only_key_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig()\n\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.pad_token_id = bert_config.pad_token_id\n    config.position_embedding_type = bert_config.position_embedding_type\n    config.output_attentions = bert_config.output_attentions\n    config.output_hidden_states = bert_config.output_hidden_states\n    config.output_past = bert_config.output_past\n    config.torchscript = bert_config.torchscript\n    config.pruned_heads = bert_config.pruned_heads\n\n    config.num_memory_tokens = 0\n    config.num_memory_layers = 0\n    config.num_memory_heads = 0\n    config.num_memory_layers_per_block = 0\n    config.num_memory_tokens_per_block = 0\n    config.num_memory_blocks = 0\n    config.num_memory_tokens_per_layer = 0\n    config.num_memory_tokens_per_head = 0\n    config.num_memory_tokens_per_layer_per_head = 0\n    config.num_memory_tokens_per_block_per_head = 0\n    config.num_memory_tokens_per_block_per_layer"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_0.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_attentions=bert_config.output_attentions,\n        output_past=True,\n        use_cache=True,\n        add_pooling_layer=False,\n        add_position_ids=True,\n        add_relative_position_ids=True,\n        add_relative_position_embeddings=True,\n        add_relative_position_bias=True,\n        add_relative_position_bias_embeddings=True,\n        add_relative_position_bias_embeddings_layer_norm=True,\n        add_relative_position_bias_embeddings_layer_norm_before=True,\n        add_relative_position_bias_embeddings_layer_norm_after=False,\n        add_relative_position_bias_embeddings_layer_norm_eps=1e-12,\n        add_relative_position_bias_embeddings_layer_norm_gamma=None,\n        add_relative_position_bias_embeddings_layer_norm_beta=None,\n        add_relative_position_bias_embeddings_layer_norm_gamma_data=None,\n       "}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        use_cache=bert_config.use_cache,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_attentions=bert_config.output_attentions,\n        is_decoder=bert_config.is_decoder,\n        add_cross_attention=bert_config.add_cross_attention,\n        add_nomic_layer=True,\n        nomic_layer_type=\"linear\",\n        nomic_layer_size=bert_config.hidden_size,\n        nomic_layer_dropout=0.0,\n        nomic_layer_activation=\"gelu\",\n        nomic_layer_norm_eps=bert_config.layer_norm_eps,\n        nomic_layer_norm_type=\"layernorm\",\n        nomic_layer_norm_position=\"pre\",\n        nomic_layer_norm_layer_id=0,\n        nomic_layer_norm_layer_id_end=None,\n        nomic_layer_norm_layer_id_start=None,\n        nomic_layer_norm_layer_id_end_inclusive=False,\n        nomic_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object with the same attributes as the BertConfig\n    config = NomicBertConfig()\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bet_config.hidden_size\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.pad_token_id = bert_config.pad_token_id\n    config.gradient_checkpointing = bert_config.gradient_checkpointing\n    config.output_hidden_states = bert_config.output_hidden_states\n    config.output_attentions = bert_config.output_attentions\n    config.torchscript = bert_config.torchscript\n    config.pruned_heads = bert_config.pruned_heads\n    config.position_embedding_type = bert_config.position_embedding_type\n    config.transformers_version = bert_config.transformers_version\n\n    # Add new attributes specific to the Nomic model\n    config.num_nomic_layers = 1\n    config.nomic_hidden_size = bert_config.hidden_size\n    config.nomic_hidden_act = bert_config.hidden_act\n    config.nomic_hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.nomic_attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.nomic_max_position_embeddings = bert"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_relative_position=bert_config.max_relative_position,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=True,\n        use_cache=True,\n        # Additional Nomic-specific configurations\n        num_blocks=bert_config.num_hidden_layers,\n        num_heads=bert_config.num_attention_heads,\n        num_layers=bert_config.num_hidden_layers,\n        num_tokens=bert_config.vocab_size,\n        num_tokens_per_type=bert_config.type_vocab_size,\n        num_types=bert_config.type_vocab_size,\n        num_tokens_per_layer=bert_config.vocab_size,\n        num_tokens_per_block=bert_config.vocab_size,\n        num_tokens_per_head=bert_config.vocab_size,\n        num_tokens_per_layer_per_head=bert_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.output_attentions = bert_config.output_attentions\n    nomic_config.output_hidden_states = bert_config.output_hidden_states\n    nomic_config.output_past = bert_config.output_past\n    nomic_config.torchscript = bert_config.torchscript\n    nomic_config.use_cache = bert_config.use_cache\n\n    # New arguments specific to the Nomic model\n    nomic_config.num_layers = 1  # Number of layers in the Nomic model\n    nomic_config.num_heads = 1  # Number of attention heads in each layer\n    nomic_config.num_channels = 1  # Number of channels in each head\n    nomic_config.num_blocks = 1  # Number of blocks in each channel\n    nomic_config.num_tokens = 1  # Number of tokens in each block\n    nomic_config.num_layers_per_block = 1  # Number of layers in each block\n    nomic_config.num"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        num_attention_heads=bert_config.num_attention_heads,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        hidden_size=bert_config.hidden_size,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=False,\n        output_attentions=False,\n        is_decoder=False,\n        add_cross_attention=False,\n        use_cache=False,\n        add_pooling_layer=False,\n        add_segment_embeddings=False,\n        add_position_embeddings=False,\n        add_relative_embeddings=False,\n        add_bias_linear=False,\n        add_bias_linear_layer=False,\n        add_bias_linear_layer_norm=False,\n        add_bias_linear_layer_norm_layer=False,\n        add_bias_linear_layer_norm_layer_norm=False,\n        add_bias_linear_layer_norm_layer_norm_layer=False,\n        add_bias_linear_layer_norm_layer_norm_layer_norm=False,\n        add_bias_linear_layer_norm_layer_norm_layer_norm_layer=False,\n        add_bias_linear_layer"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=False,\n        output_attentions=False,\n        use_cache=True,\n        pruning_axis_names=None,\n        position_embedding_type=\"absolute\",\n        use_token_type=True,\n        use_position_embedding=True,\n        use_input_mask=True,\n        use_input_ids=True,\n        use_input_type_ids=True,\n        use_output_mask=True,\n        use_output_type_ids=True,\n        use_output_ids=True,\n        use_output_attention=True,\n        use_output_hidden_states=True,\n        use_output_sequence_length=True,\n        use_output_position_ids=True,\n        use_output_token_type_ids=True,\n        use_output_attention_mask=True,\n        use_output_decoder_attention_mask=True,\n        use_output_decoder_hidden_states=True,\n        use_output_decoder_past_key_values=True,\n        use_output_decoder_sequence_length=True,\n        use_output_decoder_position"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        num_attention_heads=bert_config.num_attention_heads,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        type_vocab_size=bert_config.type_vocab_size,\n        hidden_size=bert_config.hidden_size,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=False,\n        output_attentions=False,\n        return_dict=True,\n        # Nomic-specific arguments\n        use_token_type_ids=False,\n        use_position_ids=False,\n        use_input_mask=False,\n        use_token_type_embeddings=False,\n        use_position_embeddings=False,\n        use_input_mask_embeddings=False,\n        use_token_type_embeddings_in_attention=False,\n        use_position_embeddings_in_attention=False,\n        use_input_mask_embeddings_in_attention=False,\n        use_token_type_embeddings_in_mlp=False,\n        use_position_embeddings_in_mlp=False,\n        use_input_mask_embeddings_in_mlp=False,\n        use_token_type_embeddings_in_ffn=False,\n        use_position_embeddings_in_ffn=False,\n        use_input_mask_embeddings_in_ffn=False,\n        use_token_type_embeddings_in_attn_proj=False,\n        use_position"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=True,\n        output_past_attentions=True,\n        output_past_hidden_states=True,\n        is_decoder=True,\n        use_cache=True,\n        add_pooling_layer=True,\n        position_embedding_type=\"absolute\",\n        norm_position_embeddings=True,\n        norm_token_embeddings=True,\n        use_token_type_ids=True,\n        use_token_type_embeddings=True,\n        use_position_embeddings=True,\n        use_position_ids=True,\n        use_relative_position_embeddings=True,\n        use_relative_token_embeddings=True,\n        use_relative_position_ids=True,\n        use_relative_token_ids=True,\n        use_relative_position_embeddings=True,\n        use_relative_token_embeddings=True,\n        use_relative_position_ids=True,\n        use_relative_token_ids=True,\n        use_relative_position"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_attentions=bert_config.output_attentions,\n        is_decoder=bert_config.is_decoder,\n        add_cross_attention=bert_config.add_cross_attention,\n        add_nomic_layer=True,\n        nomic_layer_type=\"nomic_layer\",\n        nomic_layer_num_heads=1,\n        nomic_layer_hidden_size=128,\n        nomic_layer_dropout=0.1,\n        nomic_layer_activation=\"gelu\",\n        nomic_layer_normalize_before=True,\n        nomic_layer_add_bias=True,\n        nomic_layer_num_layers=1,\n        nomic_layer_output_attentions=False,\n        nomic_layer_output_hidden_states=False,\n        nomic_layer_output_nomic_hidden_states=False,\n        nomic_layer_output_nomic_attentions=False,\n        nomic_layer_output_nomic_activations=False,\n        nom"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig()\n\n    # Copy all the attributes from the BertConfig object\n    for key, value in bert_config.__dict__.items():\n        if key not in ['__dict__', '__doc__', '__module__', '__weakref__']:\n            setattr(nomic_config, key, value)\n\n    # Add new attributes specific to the Nomic model\n    nomic_config.num_layers = 1\n    nomic_config.num_heads = 1\n    nomic_config.num_hidden_layers = 1\n    nomic_config.num_attention_heads = 1\n    nomic_config.num_hidden_groups = 1\n    nomic_config.num_memory_blocks = 1\n    nomic_config.num_memory_heads = 1\n    nomic_config.hidden_size = 768\n    nomic_config.inner_group_num = 1\n    nomic_config.inner_group_size = 1\n    nomic_config.num_attention_heads_per_partition = 1\n    nomic_config.num_hidden_layers_per_partition = 1\n    nomic_config.num_memory_heads_per_partition = 1\n    nomic_config.num_partitions = 1\n    nomic_config.num_stages = 1\n    nomic_config.num_tokens = 1\n    nomic_config.num_token_types = 1\n    nomic_config.num_token_types_per_partition = 1\n    nomic_config.partition_method = 'type:a'\n    nomic_config.tensor_parallel_degree = 1\n    nomic_config.use_checkpoint = False\n\n    return nomic_config\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.shape[-1] == 2:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.shape[-1] == 3:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.shape[-1] == 4:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces.shape[-1] >= 3:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.faces.shape[-1], gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Use the appropriate program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the program\n        gl.glUseProgram(program)\n\n        # Upload uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_SHORT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_SHORT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_SHORT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            gl.glPointSize(self.point_radius * camera.H)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload the uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.max_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.shape[-1] == 2:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.max_verts)\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.max_faces, gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.shape[-1] == 3:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.max_verts)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.max_faces, gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.shape[-1] == 4:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.max_verts)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, self.max_faces, gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.max_faces, gl.GL_UNSIGNED_INT, 0)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload the uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * 5, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n        else:\n            gl.glUseProgram(self.mesh_program)\n            self.upload_gl_uniforms(camera)\n            gl.glBindVertexArray(self.vao)\n            if self.faces.dtype == torch.uint32:\n                if self.render_type == Mesh.RenderType.TRIS:\n                    gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                elif self.render_type == Mesh.RenderType.QUADS:\n                    gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                elif self.render_type == Mesh.RenderType.STRIPS:\n                    gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                else:\n                    raise RuntimeError(f'Unsupported render type: {self.render_type}')\n            else:\n                if self.render_type == Mesh.RenderType.TRIS:\n                    gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.faces))\n                elif self.render_type == Mesh.RenderType.QUADS:\n                    gl.glDrawArrays(gl.GL_QUADS, 0, len(self.faces))\n                elif self.render_type == Mesh.RenderType.STRIPS:\n                    gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.faces))\n                else:\n                    raise RuntimeError(f'Unsupported render type: {self.render_type}')\n            gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Bind the appropriate program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload the uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, 0)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) == 0:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.render"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the shader program\n        gl.glUseProgram(program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.max_verts)\n        else:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.max_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.max_faces, gl.GL_UNSIGNED_SHORT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Bind the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.max_verts)\n        else:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.max_faces * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.max_verts)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Render points\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glEnable(gl.GL_POINT_SPRITE)  # MARK: ONLY SPRITE IS WORKING FOR NOW\n            gl.glEnable(gl.GL_PROGRAM_POINT_SIZE)\n            gl.glPointSize(self.point_radius)\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.max_verts)\n            gl.glDisable(gl.GL_POINT_SPRITE)  # MARK: ONLY SPRITE IS WORKING FOR NOW\n            gl.glDisable(gl.GL_PROGRAM_POINT_SIZE)\n        else:\n            use_gl_program(self.mesh_program)\n            gl.glBindVertexArray(self.vao)\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, 0)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, 0)\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, 0)\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, 0)\n            gl.glBindVertexArray(0)\n\n        # Render normals\n        if self.render_normal:\n            gl.glEnable(gl.GL_BLEND)\n            gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n            gl.glLineWidth(3.0)\n            gl.glDrawArrays(gl.GL_LINES, 0, self.max_verts)\n            gl.glDisable(gl.GL_BLEND)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if mesh is visible\n        if not self.visible: return\n\n        # Bind shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if self.faces is None:\n                gl.glDrawArrays(self.render_type.value, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                if self.render_type == Mesh.RenderType.TRIS:\n                    gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n                elif self.render_type == Mesh.RenderType.STRIPS:\n                    gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n                else:\n                    gl.glDrawElements(self.render_type.value, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n\n        # Unbind VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            gl.glEnable(gl.GL_POINT_SPRITE)  # MARK: ONLY SPRITE IS WORKING FOR NOW\n            gl.glPointSize(self.point_radius * camera.W)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the shader program\n        use_gl_program(program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glPointSize(self.point_radius)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if len(self.faces):\n                gl.glDrawElements(\n                    gl.GL_TRIANGLES if self.render_type == Mesh.RenderType.TRIS else gl.GL_TRIANGLE_STRIP,\n                    len(self.faces) * self.face_size,\n                    gl.GL_UNSIGNED_INT,\n                    None\n                )\n            else:\n                gl.glDrawArrays(\n                    gl.GL_TRIANGLES if self.render_type == Mesh.RenderType.TRIS else gl.GL_TRIANGLE_STRIP,\n                    0,\n                    len(self.verts)\n                )\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check visibility\n        if not self.visible: return\n\n        # Use the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO and EBO\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if self.faces.dtype == torch.uint32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.faces) * self.face_size)\n\n        # Unbind the VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check visibility\n        if not self.visible: return\n\n        # Use the appropriate program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if self.faces is not None:\n                if len(self.faces.shape) == 1:\n                    gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n                else:\n                    gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n\n        # Unbind VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Bind the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glPointSize(self.point_radius * camera.H)  # MARK: This is the only way I can get it to work\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.max_verts)\n        else:\n            if self.faces is not None:\n                if self.faces.dtype == torch.int32:\n                    gl.glDrawElements(self.render_type.value, self.max_faces * self.face_size, gl.GL_UNSIGNED_INT, 0)\n                else:\n                    gl.glDrawArrays(self.render_type.value, 0, self.max_faces)\n            else:\n                gl.glDrawArrays(self.render_type.value, 0, self.max_verts)\n\n        # Unbind the VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the appropriate shader program for point rendering or general mesh rendering\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the shader program\n        use_gl_program(program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n\n        # Unbind the vertex array object to clean up\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.max_verts)\n        else:\n            if self.faces.dtype == torch.int32:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_SHORT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Upload uniforms to GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO and draw\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glPointSize(self.point_radius)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n\n        # Unbind VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_draw:\n            return\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_draw:\n            return\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        if self.compose:\n            \"\"\"\n            Blit current framebuffer to this texture (self.tex)\n            Read content of this texture into a cuda buffer\n            Perform alpha blending based on the frame's alpha channel\n            Copy the blended image back into the texture (self.tex)\n            \"\"\"\n            old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 x, y, w, h,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n\n            buffer = torch.empty_like(ptr)\n            CHECK_CUDART_ERROR(cudart.cudaMemcpy2DFromArrayAsync(buffer.data_ptr(),  # dst\n                                                                 w * 4 * buffer.element_size(),  # dpitch\n                                                                 cu_tex_arr,  # src\n                                                                 x * 4 * ptr.element_size(),  # wOffset\n                                                                 y,  # hOffset\n                                                                 w * 4 * buffer.element_size(),  # width Width of matrix transfer (columns in bytes)\n                                                                 h,  # height\n                                                                 kind,  # kind\n                                                                 torch.cuda.current_stream().cuda_stream))  # stream\n\n            # cv2.imwrite('image.png', image.flip(0).detach().cpu().numpy()[..., [2,1,0,3]])\n            alpha = ptr[..., -1:] / 255\n            ptr[..., :-1] = buffer[..., :-1] * (1 - alpha ** self.compose_power) + ptr[..., :-1] * alpha  # storing float into int\n            ptr[..., -1:] = buffer[..., -1:] + ptr[..., -1:]\n            ptr = ptr.clip(0, 255)\n\n        if isinstance(ptr, np.ndarray):\n            ptr ="}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_draw:\n            return\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.ctypes.data)  # hold the reference\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if self.use_quad_draw:\n            self.use_gl_program(self.quad_program)\n            if w == 0: w = self.W\n            if h == 0: h = self.H\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyDeviceToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.element_size(),\n                                                           y,\n                                                           ptr.data_ptr(),\n                                                           w * 4 * ptr.element_size(),  # differently sized\n                                                           w * 4 * ptr.element_size(),  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        # assert ptr.shape[-1] == 4, \"The uploaded data must have 4 channels (RGBA)\"\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.ctypes.data)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        if not w: w = self.W\n        if not h: h = self.H\n\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())  # hold the reference\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to upload from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyDeviceToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                           x * 4 * ptr.element_size(),\n                                                           y,\n                                                           ptr.data_ptr(),\n                                                           w * 4 * ptr.element_size(),  # differently sized\n                                                           w * 4 * ptr.element_size(),  # rgba, should do a composition first\n                                                           h,\n                                                           kind,\n                                                           torch.cuda.current_stream().cuda_stream))\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        if ptr.is_cuda:\n            ptr = ptr.cpu()\n\n        if self.use_quad_draw:\n            old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 x, y, w, h,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n\n        ptr = ptr.detach().numpy()\n        ptr = ptr.astype(np.uint8)\n        ptr = ptr.reshape(ptr.shape + (4,))  # add alpha channel\n        ptr = ptr.swapaxes(-1, -2)  # swap alpha and rgb channels\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D,\n                            x, y,\n                            w, h,\n                            gl.GL_RGBA, gl.GL_UNSIGNED_BYTE,\n                            ptr.data)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_draw:\n            return\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n            if ptr.shape[-1] == 3:\n                ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        if ptr.is_cuda:\n            ptr = ptr.cpu()\n        if ptr.is_floating_point():\n            ptr = ptr.int()\n\n        if ptr.is_floating_point():\n            ptr = ptr.clip(0, 255)\n\n        ptr = ptr.detach().numpy()\n\n        if self.use_quad_cuda:\n            from cuda import cudart\n            kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n            cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n            CHECK_CUDART_ERROR(cudart.cudaMemcpy2DToArrayAsync(cu_tex_arr,\n                                                                x * 4 * ptr.element_size(),\n                                                                y,\n                                                                ptr.data_ptr(),\n                                                                w * 4 * ptr.element_size(),  # differently sized\n                                                                w * 4 * ptr.element_size(),  # rgba, should do a composition first\n                                                                h,\n                                                                kind,\n                                                                torch.cuda.current_stream().cuda_stream))\n            CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        else:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        if ptr.is_cuda:\n            ptr = ptr.cpu()\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())  # hold the reference\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())  # hold the reference\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if not w:\n            w = self.W\n        if not h:\n            h = self.H\n\n        if ptr.dtype == torch.float32:\n            ptr = ptr.numpy()\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data)  # hold the reference\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        if ptr.is_cuda:\n            ptr = ptr.cpu()\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_draw:\n            self.init_texture()\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        ptr = ptr.detach().cpu().numpy()\n        ptr = ptr.astype(np.uint8)\n\n        old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0,\n                            x, y, w, h,\n                            gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.ctypes.data)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        # assert self.use_quad_draw, \"Need to enable quad draw to upload from device to device, check creation of this Quad\"\n\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # assert isinstance(ptr, np.ndarray), \"The data source must be a numpy array\"\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.data_ptr())\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input shapes\n    assert R.shape == tvec.shape\n    assert R.shape[:-2] == camera_matrix.shape[:-2]\n    assert R.shape[:-2] == image_size.shape[:-2]\n\n    # Calculate the camera position\n    camera_position = -R.matmul(tvec)\n\n    # Calculate the rotation matrix in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Calculate the intrinsic parameters\n    focal_length_x = camera_matrix[..., 0, 0]\n    focal_length_y = camera_matrix[..., 1, 1]\n    warn_once_about_pulsar_fxfy()\n    focal_length = (focal_length_x + focal_length_y) / 2\n    principal_point_x = camera_matrix[..., 0, 2]\n    principal_point_y = camera_matrix[..., 1, 2]\n    principal_point_offset_x = (principal_point_x - image_size[..., 1] / 2) / image_size[..., 1]\n    principal_point_offset_y = (principal_point_y - image_size[..., 0] / 2) / image_size[..., 0]\n    sensor_width = image_size[..., 1] * focal_length / focal_length_x\n\n    # Normalize the focal length\n    focal_length = focal_length / (2 * znear)\n\n    # Concatenate the camera parameters\n    camera_params = torch.cat(\n        [\n            camera_position,\n            rotation_6d,\n            focal_length.unsqueeze(-1),\n            principal_point_offset_x.unsqueeze(-1),\n            principal_point_offset_y.unsqueeze(-1),\n            sensor_width.unsqueeze(-1),\n        ],\n        dim=-1,\n    )\n\n    return camera_params\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.shape[-2:] != (3, 3):\n        raise ValueError(\n            f\"Rotation matrix must be of shape (..., 3, 3), but got {R.shape}.\"\n        )\n\n    if tvec.shape[-1] != 3:\n        raise ValueError(\n            f\"Translation vector must be of shape (..., 3), but got {tvec.shape}.\"\n        )\n\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            f\"Camera matrix must be of shape (..., 3, 3), but got {camera_matrix.shape}.\"\n        )\n\n    if image_size.shape[-1] != 2:\n        raise ValueError(\n            f\"Image size must be of shape (..., 2), but got {image_size.shape}.\"\n        )\n\n    # Extract focal lengths and principal points from camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Compute principal point offsets\n    offset_x = (image_size[..., 0] - 1) / 2 - cx\n    offset_y = (image_size[..., 1] - 1) / 2 - cy\n\n    # Normalize focal lengths\n    fx = fx / (image_size[..., 0] / 2)\n    fy = fy / (image_size[..., 1] / 2)\n\n    # Compute sensor width\n    sensor_width = 2 * fx / fy\n\n    # Compute camera position and rotation\n    camera_pos = -torch.einsum(\"...ij,...j->...i\", R, tvec)\n    camera_rot = matrix_to_rotation_6d(R)\n\n    # Stack and return camera parameters\n    return torch.stack(\n        [\n            camera_pos[..., 0],\n            camera_pos[..., 1],\n            camera_pos[..., 2],\n            camera_rot[..., 0],\n            camera_rot[..., 1],\n            camera_rot[..., 2],\n            camera_rot[..., 3],\n            camera_rot[..., 4],\n            camera_rot[..., 5],\n            fx,\n            fy,\n            offset_x,\n            offset_y"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched and have the correct shape\n    R = R.unsqueeze(0) if len(R.shape) == 2 else R\n    tvec = tvec.unsqueeze(0) if len(tvec.shape) == 1 else tvec\n    camera_matrix = camera_matrix.unsqueeze(0) if len(camera_matrix.shape) == 2 else camera_matrix\n    image_size = image_size.unsqueeze(0) if len(image_size.shape) == 1 else image_size\n\n    # Validate the shape of the inputs\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0], \"All inputs must have the same batch size\"\n    assert R.shape[1] == 3 and R.shape[2] == 3, \"R must be a batch of 3x3 rotation matrices\"\n    assert tvec.shape[1] == 3, \"tvec must be a batch of 3D translation vectors\"\n    assert camera_matrix.shape[1] == 3 and camera_matrix.shape[2] == 3, \"camera_matrix must be a batch of 3x3 intrinsic matrices\"\n    assert image_size.shape[1] == 2, \"image_size must be a batch of 2D image sizes\"\n\n    # Extract the focal lengths and principal points from the camera matrix\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n\n    # Calculate the sensor width based on the image size and principal points\n    sensor_width = (image_size[:, 0] - 2 * cx) / fx\n\n    # Adjust the principal point offsets to account for the image center\n    cx = image_size[:, 0] / 2\n    cy = image_size[:, 1] / 2\n\n    # Adjust the focal length to account for the near clipping plane distance\n    fx = fx * znear / (znear + tvec[:, 2])\n    fy = fy * znear / (znear + tvec[:, 2])\n\n    # Convert the rotation"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not torch.is_tensor(R):\n        raise ValueError(\n            \"Rotation matrix must be a tensor, but got {}.\".format(type(R))\n        )\n    if not torch.is_tensor(tvec):\n        raise ValueError(\n            \"Translation vector must be a tensor, but got {}.\".format(type(tvec))\n        )\n    if not torch.is_tensor(camera_matrix):\n        raise ValueError(\n            \"Camera matrix must be a tensor, but got {}.\".format(type(camera_matrix))\n        )\n    if not torch.is_tensor(image_size):\n        raise ValueError(\n            \"Image size must be a tensor, but got {}.\".format(type(image_size))\n        )\n\n    if len(R.shape) != 3 or R.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Rotation matrix must be a tensor of shape (..., 3, 3), but got {}.\".format(\n                R.shape\n            )\n        )\n    if len(tvec.shape) != 2 or tvec.shape[-1] != 3:\n        raise ValueError(\n            \"Translation vector must be a tensor of shape (..., 3), but got {}.\".format(\n                tvec.shape\n            )\n        )\n    if len(camera_matrix.shape) != 3 or camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Camera matrix must be a tensor of shape (..., 3, 3), but got {}.\".format(\n                camera_matrix.shape\n            )\n        )\n    if len(image_size.shape) != 2 or image_size.shape[-1] != 2:\n        raise ValueError(\n            \"Image size must be a tensor of shape (..., 2), but got {}.\".format(\n                image_size.shape\n            )\n        )\n\n    # Ensure all inputs are batched\n    batch_shape = R.shape[:-2]\n    if tvec.shape[:-1] != batch_shape:\n        raise ValueError(\n            \"Rotation and translation must be batched with the same batch shape, \"\n            \"but got {} and {}.\".format(R.shape, tvec.shape)\n        )\n    if camera_matrix.shape[:-2] != batch_shape:\n        raise ValueError(\n            \"Rotation and camera matrix"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes and values\n    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n    assert znear > 0\n\n    # Compute camera position and rotation\n    position = -R.matmul(tvec.unsqueeze(-1)).squeeze(-1)\n    rotation = matrix_to_rotation_6d(R)\n\n    # Compute intrinsic parameters\n    focal_length = camera_matrix[..., 0, 0] / image_size[..., 0]\n    sensor_width = camera_matrix[..., 0, 2] * 2 / image_size[..., 0]\n    principal_point_offset = (\n        torch.stack(\n            [\n                camera_matrix[..., 0, 2] / image_size[..., 0],\n                camera_matrix[..., 1, 2] / image_size[..., 1],\n            ],\n            dim=-1,\n        )\n        - 0.5\n    )\n    focal_length_normalized = focal_length / (2 * znear * torch.tan(torch.pi / 8))\n\n    # Compute camera parameters\n    camera_params = torch.cat(\n        [\n            position,\n            rotation,\n            focal_length_normalized.unsqueeze(-1),\n            sensor_width.unsqueeze(-1),\n            principal_point_offset,\n        ],\n        dim=-1,\n    )\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not isinstance(R, torch.Tensor):\n        R = torch.tensor(R)\n    if not isinstance(tvec, torch.Tensor):\n        tvec = torch.tensor(tvec)\n    if not isinstance(camera_matrix, torch.Tensor):\n        camera_matrix = torch.tensor(camera_matrix)\n    if not isinstance(image_size, torch.Tensor):\n        image_size = torch.tensor(image_size)\n\n    if R.ndim != 3:\n        raise ValueError(\"R must be a batch of 3x3 rotation matrices\")\n    if tvec.ndim != 2:\n        raise ValueError(\"tvec must be a batch of 3-vectors\")\n    if camera_matrix.ndim != 3:\n        raise ValueError(\"camera_matrix must be a batch of 3x3 matrices\")\n    if image_size.ndim != 2:\n        raise ValueError(\"image_size must be a batch of 2-vectors\")\n\n    if R.shape[0] != tvec.shape[0] or R.shape[0] != camera_matrix.shape[0] or R.shape[0] != image_size.shape[0]:\n        raise ValueError(\"Batch sizes of R, tvec, camera_matrix, and image_size must match\")\n\n    if R.shape[1] != 3 or R.shape[2] != 3:\n        raise ValueError(\"Each rotation matrix in R must be 3x3\")\n    if tvec.shape[1] != 3:\n        raise ValueError(\"Each translation vector in tvec must be 3-dimensional\")\n    if camera_matrix.shape[1] != 3 or camera_matrix.shape[2] != 3:\n        raise ValueError(\"Each camera intrinsic matrix in camera_matrix must be 3x3\")\n    if image_size.shape[1] != 2:\n        raise ValueError(\"Each image size in image_size must be 2-dimensional\")\n\n    # Compute the camera rotation\n    rotation = matrix_to_rotation_6d(R)\n\n    # Compute the camera position\n    position = -torch.matmul(R.transpose(1, 2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute the intrinsic parameters\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.ndim == 3 and R.shape[-2:] == (3, 3), \"Rotation matrix must be a batch of 3x3 matrices\"\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3, \"Translation vector must be a batch of 3D vectors\"\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must be a batch of 3x3 matrices\"\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2, \"Image size must be a batch of 2D vectors\"\n\n    # Extract focal lengths and principal points from camera matrix\n    f = torch.sqrt(camera_matrix[..., 0, 0] ** 2 + camera_matrix[..., 1, 1] ** 2)\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Adjust principal point offsets based on image size\n    cx = (cx / image_size[..., 0]) * 2 - 1\n    cy = (cy / image_size[..., 1]) * 2 - 1\n\n    # Adjust focal length based on znear\n    f = f / (znear * 2)\n\n    # Compute sensor width based on focal length and image size\n    sensor_width = 2 * f * image_size[..., 0] / image_size[..., 1]\n\n    # Compute camera position and rotation from rotation matrix and translation vector\n    camera_position = -torch.einsum(\"...ij,...j->...i\", R, tvec)\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Combine camera parameters into a single tensor\n    camera_params = torch.cat(\n        [\n            camera_position,\n            camera_rotation,\n            f[..., None],\n            sensor_width[..., None],\n            cx[..., None],\n            cy[..., None],\n        ],\n        dim=-1,\n    )\n\n    return camera_params\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    if R.ndim != 3 or R.shape[-2:] != (3, 3):\n        raise ValueError(f\"R must be a batch of rotation matrices (shape: (*, 3, 3))\")\n    if tvec.ndim != 2 or tvec.shape[-1] != 3:\n        raise ValueError(f\"tvec must be a batch of translation vectors (shape: (*, 3))\")\n    if camera_matrix.ndim != 3 or camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(f\"camera_matrix must be a batch of camera intrinsic matrices (shape: (*, 3, 3))\")\n    if image_size.ndim != 2 or image_size.shape[-1] != 2:\n        raise ValueError(f\"image_size must be a batch of image sizes (shape: (*, 2))\")\n\n    # Get batch dimensions\n    batch_size = R.shape[0]\n\n    # Compute camera position\n    camera_position = -R.bmm(tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute camera intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 0] / fx\n    sensor_height = image_size[..., 1] / fy\n\n    # Adjust principal point offsets and normalize focal length\n    cx_norm = (cx - image_size[..., 0] / 2) / image_size[..., 0]\n    cy_norm = (cy - image_size[..., 1] / 2) / image_size[..., 1]\n    focal_length = 0.5 * (fx + fy) / (znear * (1 / fx - 1 / fy))\n\n    # Concatenate camera parameters\n    camera_params = torch.cat(\n        [\n            camera_position,\n            camera_rotation,\n            focal_length.unsqueeze(-1),\n            cx_norm.unsqueeze(-1),\n            cy_norm."}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if not isinstance(R, torch.Tensor):\n        raise ValueError(\"R must be a torch.Tensor.\")\n    if not isinstance(tvec, torch.Tensor):\n        raise ValueError(\"tvec must be a torch.Tensor.\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise ValueError(\"camera_matrix must be a torch.Tensor.\")\n    if not isinstance(image_size, torch.Tensor):\n        raise ValueError(\"image_size must be a torch.Tensor.\")\n    if not R.ndim == 3:\n        raise ValueError(\"R must be a batch of rotation matrices, i.e., a 3-dimensional tensor.\")\n    if not tvec.ndim == 2:\n        raise ValueError(\"tvec must be a batch of translation vectors, i.e., a 2-dimensional tensor.\")\n    if not camera_matrix.ndim == 3:\n        raise ValueError(\"camera_matrix must be a batch of intrinsic matrices, i.e., a 3-dimensional tensor.\")\n    if not image_size.ndim == 2:\n        raise ValueError(\"image_size must be a batch of image sizes, i.e., a 2-dimensional tensor.\")\n    if not R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]:\n        raise ValueError(\"R, tvec, camera_matrix, and image_size must have the same batch size.\")\n    if not R.shape[1:] == tvec.shape[1:] == (3, 3):\n        raise ValueError(\"R and tvec must be batches of 3x3 rotation matrices and translation vectors, respectively.\")\n    if not camera_matrix.shape[1:] == (3, 3):\n        raise ValueError(\"camera_matrix must be a batch of 3x3 intrinsic matrices.\")\n    if not image_size.shape[1:] == (2,):\n        raise ValueError(\"image_size must be a batch of 2-dimensional image sizes.\")\n\n    # Compute camera parameters\n    # Convert rotation matrix to rotation vector\n    rotation_vector = torch.empty_like(R)\n    torch.matmul(R, R.transpose(-1, -2), out=rotation_vector)\n    rotation_vector = torch.acos((rotation_vector.trace() - 1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure that the inputs are batched\n    assert len(R.shape) == 3 and len(tvec.shape) == 3 and len(camera_matrix.shape) == 3 and len(image_size.shape) == 2\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Validate the shapes and values of the inputs\n    assert R.shape[1:] == (3, 3)\n    assert tvec.shape[1:] == (3,)\n    assert camera_matrix.shape[1:] == (3, 3)\n    assert image_size.shape[1:] == (2,)\n    assert torch.all(torch.isfinite(R)) and torch.all(torch.isfinite(tvec)) and torch.all(torch.isfinite(camera_matrix)) and torch.all(torch.isfinite(image_size))\n\n    # Compute the camera parameters\n    camera_position = -R.matmul(tvec)\n    camera_rotation = matrix_to_rotation_6d(R)\n    focal_length = camera_matrix[..., 0, 0]\n    focal_length_x = focal_length\n    focal_length_y = camera_matrix[..., 1, 1]\n    principal_point_x = camera_matrix[..., 0, 2]\n    principal_point_y = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 1] * 2 * focal_length / image_size[..., 0]\n    focal_length_x = focal_length_x / (image_size[..., 0] / 2)\n    focal_length_y = focal_length_y / (image_size[..., 1] / 2)\n    principal_point_x = principal_point_x / (image_size[..., 0] / 2) - 1\n    principal_point_y = principal_point_y / (image_size[..., 1] / 2) - 1\n    principal_point_x = principal_point_x * focal_length_x\n    principal_point_y = principal_point_y * focal_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    if R.ndim != 3 or R.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Expected rotation matrix to have shape (..., 3, 3), got {}\".format(\n                R.shape\n            )\n        )\n    if tvec.ndim != 2 or tvec.shape[-1] != 3:\n        raise ValueError(\n            \"Expected translation vector to have shape (..., 3), got {}\".format(\n                tvec.shape\n            )\n        )\n    if camera_matrix.ndim != 3 or camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Expected camera intrinsic matrix to have shape (..., 3, 3), got {}\".format(\n                camera_matrix.shape\n            )\n        )\n    if image_size.ndim != 2 or image_size.shape[-1] != 2:\n        raise ValueError(\n            \"Expected image size to have shape (..., 2), got {}\".format(\n                image_size.shape\n            )\n        )\n\n    # Compute camera parameters\n    focal_length = camera_matrix[..., 0, 0]\n    principal_point = camera_matrix[..., :2, 2]\n    sensor_width = camera_matrix[..., 0, 2] * 2\n    principal_point_offset = principal_point - (image_size - 1) / 2\n    focal_length_normalized = focal_length / (image_size[..., 0] / sensor_width)\n    focal_length_normalized = focal_length_normalized / (2 * znear)\n\n    # Compute camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute camera position\n    camera_position = -R.matmul(tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Return camera parameters\n    return torch.stack(\n        [\n            camera_position,\n            camera_rotation,\n            focal_length_normalized,\n            principal_point_offset,\n        ],\n        dim=-1,\n    )\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.shape == tvec.shape, \"R and tvec must have the same shape\"\n    assert R.shape[-2:] == (3, 3), \"R must be a batch of rotation matrices\"\n    assert tvec.shape[-1] == 3, \"tvec must be a batch of translation vectors\"\n    assert camera_matrix.shape == R.shape, \"camera_matrix and R must have the same shape\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must be a batch of intrinsic matrices\"\n    assert image_size.shape == R.shape[:-2], \"image_size and R must have the same batch shape\"\n    assert image_size.shape[-2:] == (2,), \"image_size must be a batch of image sizes\"\n\n    # Get the focal lengths, principal points, and sensor width from the camera intrinsic matrix\n    focal_lengths = camera_matrix[..., 0, 0]\n    principal_points = camera_matrix[..., 2, :2]\n    sensor_width = camera_matrix[..., 0, 2] * 2\n\n    # Calculate the focal lengths and principal point offsets\n    focal_lengths = focal_lengths / (image_size[..., 1] / 2)\n    principal_point_offsets = principal_points / (image_size / 2) - 1\n\n    # Calculate the near clipping plane distance\n    znear = torch.tensor(znear, dtype=R.dtype, device=R.device)\n\n    # Calculate the camera parameters\n    params = torch.cat(\n        [\n            R.view(-1, 9),\n            tvec.view(-1, 3),\n            focal_lengths.view(-1, 1),\n            znear.view(-1, 1),\n            principal_point_offsets.view(-1, 2),\n            sensor_width.view(-1, 1),\n        ],\n        dim=-1,\n    )\n\n    return params\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure that the input tensors are batched and have the correct shape\n    if not R.ndimension() == 3:\n        raise ValueError(\n            \"Rotation matrix should be a batch of 3D tensors, but got a tensor with shape {}\".format(R.shape)\n        )\n    if not tvec.ndimension() == 2:\n        raise ValueError(\n            \"Translation vector should be a batch of 2D tensors, but got a tensor with shape {}\".format(tvec.shape)\n        )\n    if not camera_matrix.ndimension() == 3:\n        raise ValueError(\n            \"Camera intrinsic matrix should be a batch of 3D tensors, but got a tensor with shape {}\".format(\n                camera_matrix.shape\n            )\n        )\n    if not image_size.ndimension() == 2:\n        raise ValueError(\n            \"Image size should be a batch of 2D tensors, but got a tensor with shape {}\".format(image_size.shape)\n        )\n    if not R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]:\n        raise ValueError(\n            \"Batch sizes of rotation matrix, translation vector, camera intrinsic matrix, and image size do not match.\"\n        )\n\n    # Get the focal lengths and principal points from the camera intrinsic matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Adjust the principal point offsets based on the image size\n    cx = cx - image_size[..., 0] / 2\n    cy = cy - image_size[..., 1] / 2\n\n    # Normalize the focal lengths based on the near clipping plane distance\n    fx = fx / znear\n    fy = fy / znear\n\n    # Calculate the camera position based on the rotation and translation\n    camera_position = -torch.bmm(R, tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Calculate the camera rotation in a different representation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Calculate the sensor width based on the focal length and image size\n    sensor_width = image_size[..., 0]"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.ndim != 3:\n        raise ValueError(\n            \"Rotation matrix must be a batch of matrices, i.e. 3D tensor.\"\n        )\n    if R.shape[1:] != (3, 3):\n        raise ValueError(\"Rotation matrix must be 3x3.\")\n    if tvec.ndim != 2:\n        raise ValueError(\"Translation vector must be a batch of vectors, i.e. 2D tensor.\")\n    if tvec.shape[1:] != (3,):\n        raise ValueError(\"Translation vector must be 3D.\")\n    if camera_matrix.ndim != 3:\n        raise ValueError(\n            \"Camera intrinsic matrix must be a batch of matrices, i.e. 3D tensor.\"\n        )\n    if camera_matrix.shape[1:] != (3, 3):\n        raise ValueError(\"Camera intrinsic matrix must be 3x3.\")\n    if image_size.ndim != 2:\n        raise ValueError(\"Image size must be a batch of vectors, i.e. 2D tensor.\")\n    if image_size.shape[1:] != (2,):\n        raise ValueError(\"Image size must be 2D.\")\n\n    # Extract focal lengths and principal points from the camera intrinsic matrix\n    focal_lengths = camera_matrix[..., 0, 0]\n    principal_points = camera_matrix[..., 2, :2]\n\n    # Adjust principal point offsets to account for image size\n    principal_points = (principal_points - image_size / 2) / image_size\n\n    # Normalize focal lengths by image size\n    focal_lengths = focal_lengths / image_size[..., 0]\n\n    # Compute sensor width from focal length\n    sensor_width = 2 * focal_lengths * znear\n\n    # Compute camera position from rotation and translation\n    camera_position = -torch.bmm(R, tvec[..., None])[..., 0]\n\n    # Convert rotation matrix to 6D rotation representation\n    rotation = matrix_to_rotation_6d(R)\n\n    # Return camera parameters\n    return torch.stack(\n        [camera_position, rotation, focal_lengths, principal_points, sensor_width], dim=-1\n    )\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n\n    # Get the focal length and principal point offsets\n    focal_lengths = camera_matrix[..., 0, 0] / image_size[..., 0]\n    focal_lengths = (focal_lengths + camera_matrix[..., 1, 1] / image_size[..., 1]) / 2\n    principal_point_offsets = (\n        camera_matrix[..., 0, 2] / image_size[..., 0],\n        camera_matrix[..., 1, 2] / image_size[..., 1],\n    )\n\n    # Compute the camera position and rotation\n    camera_position = -R.bmm(tvec.unsqueeze(-1)).squeeze(-1)\n    rotation_matrix = R.bmm(torch.tensor(\n        [\n            [0, 0, 1],\n            [0, -1, 0],\n            [1, 0, 0],\n        ],\n        dtype=R.dtype,\n        device=R.device,\n    ).unsqueeze(0))\n\n    # Compute the intrinsic parameters\n    sensor_width = 2 * focal_lengths / (1 + principal_point_offsets[0])\n    focal_length = focal_lengths / (1 + principal_point_offsets[1])\n    focal_length_x = focal_length / znear\n    focal_length_y = focal_length / znear\n\n    # Return the camera parameters\n    return torch.stack(\n        [\n            camera_position[..., 0],\n            camera_position[..., 1],\n            camera_position[..., 2],\n            matrix_to_rotation_6d(rotation_matrix)[..., 0],\n            matrix_to_rotation_6d(rotation_matrix)[..., 1],\n            matrix_to_rotation_6d(rotation_matrix)[..., 2],\n            matrix_to_rotation_6d(rotation_matrix)[..., 3],\n            matrix_to"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must be of shape (3, 3)\"\n    assert tvec.shape[-1] == 3, \"Translation vector must be of shape (3,)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must be of shape (3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must be of shape (2,)\"\n\n    # Convert rotation matrix to rotation vector\n    rot_vec = torch.zeros_like(R[..., 0])\n    for i in range(R.shape[0]):\n        rot_vec[i] = matrix_to_rotation_6d(R[i:i + 1])\n\n    # Compute camera position and rotation\n    cam_pos = tvec\n    cam_rot = rot_vec\n\n    # Compute focal length and principal point\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    cx, cy = camera_matrix[..., 0, 2], camera_matrix[..., 1, 2]\n\n    # Adjust focal length and principal point offsets\n    focal_length = (fx + fy) / 2\n    cx_offset = (cx - image_size[..., 0] / 2) / image_size[..., 0]\n    cy_offset = (cy - image_size[..., 1] / 2) / image_size[..., 1]\n\n    # Adjust focal length for near clipping plane distance\n    focal_length = focal_length / (znear * torch.tan(torch.atan(1 / focal_length)))\n\n    # Compute sensor width\n    sensor_width = image_size[..., 0] / focal_length\n\n    # Concatenate camera parameters\n    cam_params = torch.stack([cam_pos, cam_rot, focal_length, cx_offset, cy_offset, sensor_width], dim=-1)\n\n    return cam_params\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if not (\n            isinstance(R, torch.Tensor)\n            and isinstance(tvec, torch.Tensor)\n            and isinstance(camera_matrix, torch.Tensor)\n            and isinstance(image_size, torch.Tensor)\n    ):\n        raise TypeError(\"Input arguments must be torch.Tensor.\")\n\n    if not (\n            R.ndim == 3\n            and tvec.ndim == 2\n            and camera_matrix.ndim == 3\n            and image_size.ndim == 1\n    ):\n        raise ValueError(\"Input arguments must be batched.\")\n\n    if not (\n            R.shape[-2:] == (3, 3)\n            and tvec.shape[-1] == 3\n            and camera_matrix.shape[-2:] == (3, 3)\n            and image_size.shape == (2,)\n    ):\n        raise ValueError(\"Input arguments must be of correct shapes.\")\n\n    if not (\n            R.dtype == tvec.dtype == camera_matrix.dtype == image_size.dtype\n    ):\n        raise ValueError(\"Input arguments must be of the same dtype.\")\n\n    if not (\n            R.device == tvec.device == camera_matrix.device == image_size.device\n    ):\n        raise ValueError(\"Input arguments must be on the same device.\")\n\n    # Compute the camera position from the rotation matrix and translation vector\n    camera_position = -torch.bmm(R, tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute the rotation in 6D representation\n    rotation = matrix_to_rotation_6d(R)\n\n    # Compute the intrinsic parameters\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    if not torch.allclose(fx, fy, rtol=1e-2):\n        warn_once_about_pulsar_fxfy()\n        fx = (fx + fy) / 2\n\n    cx, cy = camera_matrix[..., 0, 2], camera_matrix[..., 1, 2]\n    sensor_width = fx * 2 / image_size[0]\n\n    # Normalize the focal length\n    fx = fx / (image_size[0] / 2)\n    fy = fy / (image_size[1] / 2)\n\n    # Adjust the principal point offsets\n    cx = (cx - image_size["}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check input shapes\n    assert R.shape[-2:] == (3, 3), f\"Invalid shape for rotation matrix: {R.shape}\"\n    assert tvec.shape[-1] == 3, f\"Invalid shape for translation vector: {tvec.shape}\"\n    assert camera_matrix.shape[-2:] == (3, 3), f\"Invalid shape for camera intrinsic matrix: {camera_matrix.shape}\"\n    assert image_size.shape[-1] == 2, f\"Invalid shape for image size: {image_size.shape}\"\n\n    # Validate input values\n    assert torch.all(torch.isfinite(R)), \"Invalid rotation matrix: contains non-finite values\"\n    assert torch.all(torch.isfinite(tvec)), \"Invalid translation vector: contains non-finite values\"\n    assert torch.all(torch.isfinite(camera_matrix)), \"Invalid camera intrinsic matrix: contains non-finite values\"\n    assert torch.all(torch.isfinite(image_size)), \"Invalid image size: contains non-finite values\"\n\n    # Compute camera parameters\n    camera_position = -torch.einsum(\"...ij,...j->...i\", R, tvec)\n    camera_rotation = matrix_to_rotation_6d(R)\n    focal_lengths = camera_matrix[..., 0, 0]\n    principal_points = camera_matrix[..., 2, :2]\n    sensor_width = camera_matrix[..., 0, 2] * 2\n    focal_lengths = focal_lengths * (image_size[..., 0] / 2) / (sensor_width / 2)\n    principal_points = principal_points - image_size / 2\n    fx, fy = focal_lengths[..., 0], focal_lengths[..., 1]\n    warn_once_about_pulsar_fxfy()\n    focal_length = (fx + fy) / 2\n    principal_point = principal_points[..., 0]\n\n    # Adjust focal length to match the near clipping plane distance\n    focal_length = focal_length / (znear / focal_length)\n\n    # Return camera parameters\n    return torch.stack([\n        camera_position[..., 0],\n        camera_position[..., 1],\n        camera_position[..., 2],\n       "}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check the shape of the input tensors\n    assert R.shape == tvec.shape\n    assert R.shape[0] == camera_matrix.shape[0]\n    assert camera_matrix.shape[0] == image_size.shape[0]\n\n    # Ensure that the input tensors are batched\n    assert len(R.shape) > 2\n    assert len(camera_matrix.shape) > 2\n    assert len(image_size.shape) > 1\n\n    # Ensure that the input tensors have the correct dimensions\n    assert R.shape[-2:] == (3, 3)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-1] == 2\n\n    # Ensure that the input tensors have the correct values\n    assert (R.abs().max() <= 1).all()\n    assert (camera_matrix.abs().max() > 0).all()\n    assert (image_size.abs().max() > 0).all()\n\n    # Compute the camera position and rotation\n    camera_position = -R.matmul(tvec)\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the intrinsic parameters\n    focal_lengths = camera_matrix[..., 0, 0] / image_size[..., 0]\n    principal_point_offsets = camera_matrix[..., 0, 2] / image_size[..., 0]\n    sensor_width = (camera_matrix[..., 0, 2] - camera_matrix[..., 1, 2]) / (image_size[..., 0] - image_size[..., 1])\n\n    # Adjust the focal lengths and principal point offsets\n    focal_lengths = focal_lengths / (1 - znear / camera_matrix[..., 2, 2])\n    principal_point_offsets = principal_point_offsets - 0.5\n\n    # Create a tensor to hold the camera parameters\n    camera_params = torch.stack(\n        [\n            camera_position,\n            camera_rotation,\n            focal_lengths,\n            principal_point_offsets,\n            sensor_width,\n        ],\n        dim=-1,\n    )\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input shapes and values\n    assert R.shape == tvec.shape\n    assert camera_matrix.shape == tvec.shape\n    assert image_size.shape == tvec.shape\n    assert torch.all(R.abs() <= 1)\n    assert torch.all(camera_matrix[:, 0, 0] > 0)\n    assert torch.all(camera_matrix[:, 1, 1] > 0)\n    assert torch.all(camera_matrix[:, 2, 2] > 0)\n    assert torch.all(camera_matrix[:, 2, 3] > 0)\n    assert torch.all(image_size[:, 0] > 0)\n    assert torch.all(image_size[:, 1] > 0)\n\n    # Calculate the camera parameters\n    K = camera_matrix.clone()\n    K[..., 0, 2] = (image_size[..., 0] - 1) / 2\n    K[..., 1, 2] = (image_size[..., 1] - 1) / 2\n    K[..., 0, 0] *= znear / K[..., 2, 3]\n    K[..., 1, 1] *= znear / K[..., 2, 3]\n    K[..., 2, 2] = 0\n    K[..., 2, 3] = znear\n    R_6d = matrix_to_rotation_6d(R)\n    R_6d_norm = R_6d.norm(p=2, dim=-1, keepdim=True)\n    R_6d_norm = torch.where(R_6d_norm < 1e-6, torch.ones_like(R_6d_norm), R_6d_norm)\n    R_6d = R_6d / R_6d_norm\n    tvec_norm = tvec.norm(p=2, dim=-1, keepdim=True)\n    tvec_norm = torch.where(tvec_norm < 1e-6, torch.ones_like(tvec_norm), tvec_norm)\n    tvec = tvec / tvec_norm\n    params = torch.cat([R_6d, tvec], dim=-1)\n\n   "}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        w = w or self.W\n        h = h or self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        if self.use_quad_draw:\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n            gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        else:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data, x, y, w, h)  # MARK: SYNC\n            return\n\n        # Set up a specific viewport and scissor box for rendering\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate a shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind a texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        if self.use_quad_draw:\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glUniform1i(self.uniforms.tex, 0)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        if self.use_quad_draw:\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        # If the use_quad_draw attribute is False, it falls back to a simpler blit method for drawing. Otherwise, it sets up a specific viewport and scissor box for rendering\n        if not self.use_quad_draw:\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            return\n\n        # Set up a specific viewport and scissor box for rendering\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        # Activate a shader program, bind a texture, and draw the quadrilateral using vertex data\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)  # slow upload and draw\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)\n            return\n\n        # Init the viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        # Set the viewport and scissor box\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        # Use the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data, x, y, w, h)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glCopyTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGBA8, self.W, self.H, 0)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)  # MARK: SYNC\n            return\n\n        gl.glPushAttrib(gl.GL_VIEWPORT_BIT)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n\n        gl.glPushAttrib(gl.GL_SCISSOR_BIT)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        self.use_gl_program(self.quad_program)\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glPopAttrib()\n        gl.glPopAttrib()\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)  # MARK: SYNC\n            return\n\n        # Set up the viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        # Set up the viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate the shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)\n\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glScissor(0, 0, camera.W, camera.H)\n        gl.glViewport(0, 0, camera.W, camera.H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # MARK: Maybe sync\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        # Set the viewport to the size of the texture\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        gl.glUseProgram(self.quad_program)  # use a different program\n        gl.glUniform1i(self.uniforms.tex, 0)  # bind the texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)  # activate the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # bind the texture\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # draw the quad\n\n        gl.glViewport(*old_viewport)  # restore the viewport\n        gl.glScissor(*old_scissor)  # restore the scissor box\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            x, y, w, h = x or 0, y or 0, w or self.W, h or self.H\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)\n        else:\n            if self.fbo:\n                old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n                gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n                gl.glBlitFramebuffer(x or 0, y or 0, w or self.W, h or self.H,\n                                     x or 0, y or 0, w or self.W, h or self.H,\n                                     gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n                gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        x = x or 0\n        y = y or 0\n        w = w or self.W\n        h = h or self.H\n\n        if self.use_quad_draw:\n            # Set up a specific viewport and scissor box for rendering\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            # Activate a shader program, bind a texture, and draw the quadrilateral using vertex data\n            gl.glUseProgram(self.quad_program)\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box to their original sizes\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)\n        else:\n            # Blit the current framebuffer to this texture\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 x, y, w, h,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        # This is a heavy operation\n        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            self.upload_to_texture()\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            return\n\n        # Set up the viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate the program\n        gl.glUseProgram(self.quad_program)\n        gl.glUniform1i(self.uniforms.tex, 0)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(old_viewport)\n        gl.glScissor(old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.upload_to_texture(self.verts_data)  # MARK: Maybe sync\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glUniform1i(self.uniforms.tex, 0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(old_viewport)\n        gl.glScissor(old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            # Use a simpler blit method\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                                 x, y, w or self.W, h or self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n            return\n\n        # Use a viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        self.use_gl_program()\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(old_viewport)\n        gl.glScissor(old_scissor)\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to align with PyTorch3D's coordinate system and conventions\n    R = R.mT\n    T = T.mT\n    # Compute the intrinsic matrix for NDC\n    n = torch.tensor([0.0, 0.0, 1.0], device=R.device)\n    f = torch.tensor([0.0, 0.0, 1.0], device=R.device)\n    ixt = get_ndc_perspective_matrix(K, H, W, n[..., 0], f[..., 0]).to(R.dtype)  # to opengl, remove last dim of n and f\n    return H, W, ixt, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T for PyTorch3D's coordinate system and conventions\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    T = -T  # B, 3, 1\n    # Recalculate K for NDC\n    K = get_ndc_perspective_matrix(K, H, W, n=1, f=1000)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T for PyTorch3D coordinate system\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    T = -T  # B, 3, 1\n    # Recalculate K for NDC\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1000).to(K.dtype)  # B, 4, 4\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation and translation matrices to match PyTorch3D's conventions\n    R = R.mT  # Transpose to match PyTorch3D's conventions\n    T = T.mT  # Transpose to match PyTorch3D's conventions\n\n    # Recalculate intrinsic matrix for NDC\n    K[0, 2] = K[0, 2] / W\n    K[1, 2] = K[1, 2] / H\n    K[0, 0] = K[0, 0] / W\n    K[1, 1] = K[1, 1] / H\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjustments for PyTorch3D coordinate system and conventions\n    R = R.mT  # Adjust for right-handed coordinate system\n    T = T.mT  # Adjust for right-handed coordinate system\n    K[..., 0, 0] *= -1  # Adjust for left-handed coordinate system\n    K[..., 1, 1] *= -1  # Adjust for left-handed coordinate system\n    K[..., 0, 2] = (W - 1) / 2  # Adjust for NDC\n    K[..., 1, 2] = (H - 1) / 2  # Adjust for NDC\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation and translation matrices to match PyTorch3D's conventions\n    R = R.mT  # Transpose rotation matrix to match PyTorch3D's convention (right-handed coordinate system)\n    T = T.mT  # Transpose translation matrix to match PyTorch3D's convention (right-handed coordinate system)\n\n    # Recalculate intrinsic matrix for NDC\n    # K[0, 0] = K[0, 0] / W\n    # K[1, 1] = K[1, 1] / H\n    # K[0, 2] = K[0, 2] / W - 0.5\n    # K[1, 2] = K[1, 2] / H - 0.5\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Compute intrinsic matrix for NDC\n    K_ndc = get_ndc_perspective_matrix(K, H, W, n=1, f=1).to(K.dtype)\n    # Adjust R and T to match PyTorch3D's conventions\n    R_3d = R.mT\n    T_3d = -R.mT @ T\n    return H, W, K_ndc, R_3d, T_3d, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust rotation and translation matrices for PyTorch3D's conventions\n    R = R.mT\n    T = -R @ T\n    # Compute the intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W, n=1, f=1000).to(K.dtype)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjustments to align with PyTorch3D's coordinate system and conventions\n    R = R.mT  # Transpose to align with PyTorch3D's right-handed coordinate system\n    T = -R @ T  # Apply transformation to align with PyTorch3D's right-handed coordinate system\n    K[..., 0, 0] *= W / 2  # Scale focal length to match PyTorch3D's NDC convention\n    K[..., 1, 1] *= H / 2  # Scale focal length to match PyTorch3D's NDC convention\n    K[..., 0, 2] = (W - 1) / 2  # Adjust principal point to match PyTorch3D's NDC convention\n    K[..., 1, 2] = (H - 1) / 2  # Adjust principal point to match PyTorch3D's NDC convention\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T for PyTorch3D coordinate system and conventions\n    R = R.mT  # B, 3, 3\n    T = T.mT  # B, 3, 1\n    # Compute intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust the rotation matrix to match PyTorch3D's convention\n    R = R.mT  # B, 3, 3\n\n    # Adjust the translation vector to match PyTorch3D's convention\n    T = -T  # B, 3, 1\n\n    # Compute the intrinsic matrix for normalized device coordinates\n    K = get_ndc_perspective_matrix(K, H, W, 0.01, 1000)  # B, 4, 4\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n\n    # Adjust rotation and translation matrices to align with PyTorch3D's coordinate system and conventions\n    R = R.mT  # Transpose rotation matrix to match PyTorch3D's convention (right-handed coordinate system)\n    T = -R @ T  # Apply rotation to translation vector to align with PyTorch3D's coordinate system\n\n    # Compute the intrinsic matrix for NDC (normalized device coordinates)\n    K = get_ndc_perspective_matrix(K, H, W, 0.1, 100)\n\n    # Compute the camera center in the camera's coordinate system\n    C = -R.mT @ T\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        if self.H > self.max_H or self.W > self.max_W:  # max got updated\n            self.max_H, self.max_W = max(int(self.H * 1.05), self.max_H), max(int(self.W * 1.05), self.max_W)\n            self.init_texture()\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             0, 0, self.max_W, self.max_H,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        gl.glBlitFramebuffer(x, y, w, h,\n                              x, y, w, h,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        # Some housekeepings\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some housekeepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # The function uses the lower left corner as the origin\n        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h, 0, 0, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        if self.H > self.max_H or self.W > self.max_W:\n            self.max_H, self.max_W = max(int(self.H * 1.05), self.max_H), max(int(self.W * 1.05), self.max_W)\n            self.init_texture()\n\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        gl.glBlitFramebuffer(x, y, w, h,\n                              x, y, w, h,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        gl.glBlitFramebuffer(x, y, w, h,\n                              x, y, w, h,\n                              gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum = torch.cumsum(y1, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum = torch.cumsum(y1_cumsum, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum_cumsum = torch.cumsum(y1_cumsum_cumsum, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum_cumsum_cumsum = torch.cumsum(y1_cumsum_cumsum_cumsum, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum_cumsum_cumsum_cumsum = torch.cumsum(y1_cumsum_cumsum_cumsum_cumsum, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum = torch.cumsum(y1_cumsum_cumsum_cumsum_cumsum_cumsum, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum = torch.cumsum(y1_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum, dim=1)\n\n    # Compute the cumulative sums of the values (y1) along the time axis (dim=1)\n    y1_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum = torch.cumsum(y1_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum_cumsum, dim=1)\n\n    # Compute the"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.view(-1)\n    t1 = t1.view(-1)\n    y1 = y1.view(-1)\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n    t0 = t0.expand_as(t1)\n    y1 = y1.expand_as(t1)\n    t1 = t1.expand_as(t0)\n    y1 = y1.expand_as(t0)\n    t0 = t0.view(-1)\n    t1 = t1.view(-1)\n    y1 = y1.view(-1)\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n    t0 = t0.expand_as(t1)\n    y1 = y1.expand_as(t1)\n    t1 = t1.expand_as(t0)\n    y1 = y1.expand_as(t0)\n    t0 = t0.view(-1)\n    t1 = t1.view(-1)\n    y1 = y1.view(-1)\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n    t0 = t0.expand_as(t1)\n    y1 = y1.expand_as(t1)\n    t1 = t1.expand_as(t0)\n    y1 = y1.expand_as(t0)\n    t0 = t0.view(-1)\n    t1 = t1.view(-1)\n    y1 = y1.view(-1)\n    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n    t0 = t0.expand_as(t1)\n    y1 = y1.expand_as(t1)\n    t1 = t1.expand_as(t0)\n    y1 = y1.expand_as(t0)\n    t0 = t0.view(-1)\n   "}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the given values (y1)\n    cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the inner measure by interpolating between the source times (t1) and their corresponding cumulative sums (cumsum)\n    inner = torch.interp(t0, t1, cumsum)\n\n    # Compute the outer measure by subtracting the inner measure from the cumulative sum at the last source time (t1[-1])\n    outer = cumsum[-1] - inner\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source times that are closest to the target times\n    idx = searchsorted(t1, t0)\n\n    # Check if the target times are within the range of the source times\n    if idx.min() == 0 or idx.max() == t1.shape[0]:\n        raise ValueError(\"Target times are outside the range of source times.\")\n\n    # Compute the inner and outer measures\n    inner = y1[idx - 1] + (y1[idx] - y1[idx - 1]) * (t0 - t1[idx - 1]) / (t1[idx] - t1[idx - 1])\n    outer = y1[idx] + (y1[idx + 1] - y1[idx]) * (t0 - t1[idx]) / (t1[idx + 1] - t1[idx])\n\n    return inner, outer\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the values (y1)\n    cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the indices of the source times (t1) that are less than or equal to the target time (t0)\n    indices = searchsorted(t1, t0)\n\n    # Compute the inner measure using the cumulative sum and indices\n    inner = cumsum[indices]\n\n    # Compute the outer measure using the difference between the cumulative sum and the inner measure\n    outer = cumsum[-1] - inner\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sums for the source times (t1) and values (y1)\n    cumsum_t1 = torch.cumsum(t1, dim=0)\n    cumsum_y1 = torch.cumsum(y1, dim=0)\n\n    # Calculate the inner measure\n    inner = torch.zeros_like(t0)\n    inner[1:] = cumsum_y1[:-1] * (t0[1:] - t1[:-1])\n\n    # Calculate the outer measure\n    outer = torch.zeros_like(t0)\n    outer[1:] = (cumsum_t1[:-1] * y1[:-1]) * (t0[1:] - t1[:-1])\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sort the source times (t1) in ascending order and obtain the corresponding indices (idx1).\n    idx1 = torch.argsort(t1)\n    t1 = t1[idx1]\n    y1 = y1[idx1]\n\n    # Compute the cumulative sums of the source values (y1) and obtain the corresponding indices (idx2).\n    idx2 = torch.argsort(y1)\n    y1 = y1[idx2]\n\n    # Sort the target times (t0) in ascending order and obtain the corresponding indices (idx0).\n    idx0 = torch.argsort(t0)\n    t0 = t0[idx0]\n\n    # Compute the cumulative sums of the sorted target times (t0) and obtain the corresponding indices (idx3).\n    idx3 = torch.argsort(t0)\n    t0 = t0[idx3]\n\n    # Compute the inner measure by interpolating the cumulative sums of the source values (y1) at the sorted target times (t0).\n    inner = torch.searchsorted(y1, t0, right=True)\n    inner = y1[inner - 1]\n\n    # Compute the outer measure by interpolating the cumulative sums of the sorted target times (t0) at the source values (y1).\n    outer = torch.searchsorted(t0, y1, right=True)\n    outer = t0[outer - 1]\n\n    # Sort the indices of the target times (t0) in ascending order and obtain the corresponding indices (idx4).\n    idx4 = torch.argsort(idx0)\n    idx0 = idx0[idx4]\n\n    # Sort the indices of the source times (t1) in ascending order and obtain the corresponding indices (idx5).\n    idx5 = torch.argsort(idx1)\n    idx1 = idx1[idx5]\n\n    # Sort the indices of the source values (y1) in ascending order and obtain the corresponding indices (idx6).\n    idx6 = torch.argsort(idx2)\n    idx2 = idx2[idx6]\n\n    # Sort the indices of the sorted target times (t0) in ascending order and obtain the corresponding indices (idx7).\n    idx7 = torch.argsort(idx3)\n    idx3 = idx3[idx7]\n\n    # Reorder the inner"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Get the indices of the source times (t1) that are less than or equal to the target time (t0)\n    idx_lt = searchsorted(t1, t0)\n\n    # Get the indices of the source times (t1) that are greater than or equal to the target time (t0)\n    idx_gt = searchsorted(t1, t0, side='right')\n\n    # Check if there are any indices where the source times (t1) are equal to the target time (t0)\n    idx_eq = torch.eq(t1, t0)\n\n    # Get the inner measure by interpolating the values (y1) at the target time (t0) using the source times (t1) and their corresponding values (y1)\n    inner = torch.where(idx_eq, y1, torch.lerp(y1[idx_lt - 1], y1[idx_lt], (t0 - t1[idx_lt - 1]) / (t1[idx_lt] - t1[idx_lt - 1])))\n\n    # Get the outer measure by interpolating the values (y1) at the target time (t0) using the source times (t1) and their corresponding values (y1)\n    outer = torch.where(idx_eq, y1, torch.lerp(y1[idx_gt - 1], y1[idx_gt], (t0 - t1[idx_gt - 1]) / (t1[idx_gt] - t1[idx_gt - 1])))\n\n    # Return the inner and outer measures\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the values (y1) using the source times (t1).\n    y1_cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the indices for the target times (t0) in the source times (t1).\n    indices = searchsorted(t1, t0)\n\n    # Compute the inner measure by interpolating the values (y1) at the target times (t0).\n    inner = y1[indices]\n\n    # Compute the outer measure by interpolating the cumulative sum of the values (y1) at the target times (t0).\n    outer = y1_cumsum[indices] - inner * (t1[indices] - t0)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sums of the values (y1) at the source times (t1).\n    y1cumsum = torch.cumsum(y1, dim=-1)\n\n    # Calculate the inner measure based on the cumulative sums at the source times (t1).\n    inner = torch.searchsorted(t1, t0, right=True)\n    inner = torch.gather(y1cumsum, dim=-1, index=inner[..., None])\n\n    # Calculate the outer measure based on the cumulative sums at the source times (t1).\n    outer = torch.searchsorted(t1, t0, right=False)\n    outer = torch.gather(y1cumsum, dim=-1, index=outer[..., None])\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = torch.tensor(t0, dtype=torch.float32)\n    t1 = torch.tensor(t1, dtype=torch.float32)\n    y1 = torch.tensor(y1, dtype=torch.float32)\n\n    y0 = torch.zeros(t0.shape, dtype=torch.float32)\n\n    # Compute the cumulative sum of y1 values up to the target time t0.\n    y0 = torch.cumsum(y1, dim=0)\n    y0 = y0[searchsorted(t1, t0)]\n\n    # Compute the cumulative sum of y1 values up to the target time t0.\n    y1 = torch.cumsum(y1, dim=0)\n    y1 = y1[searchsorted(t1, t0) - 1]\n\n    # Compute the inner and outer measures based on the cumulative sums.\n    inner = y0 - y1\n    outer = y0 - y1 + y1[0]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the values (y1) using the source times (t1) as the weights.\n    y1_cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the inner measure by interpolating the cumulative sum (y1_cumsum) at the target time (t0) using the source times (t1) as the interpolation points.\n    inner = torch.nn.functional.interpolate(y1_cumsum.unsqueeze(1), t0.shape[0], mode='linear', align_corners=False).squeeze(1)\n\n    # Compute the outer measure by interpolating the values (y1) at the target time (t0) using the source times (t1) as the interpolation points.\n    outer = torch.nn.functional.interpolate(y1.unsqueeze(1), t0.shape[0], mode='linear', align_corners=False).squeeze(1)\n\n    # Return the inner and outer measures as a tuple.\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sort the indices of the source times (t1) in ascending order.\n    i = torch.argsort(t1)\n\n    # Compute the cumulative sums of the values (y1) associated with the sorted source times (t1).\n    y = torch.cumsum(y1[i], dim=0)\n\n    # Compute the inner measure by interpolating the cumulative sums (y) at the target times (t0).\n    inner = torch.interp(t0, t1[i], y)\n\n    # Compute the outer measure by interpolating the cumulative sums (y) at the target times (t0) + 1.\n    outer = torch.interp(t0 + 1, t1[i], y)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(-1)\n    t1 = t1.unsqueeze(-1)\n    y1 = y1.unsqueeze(-1)\n    t0 = t0.expand_as(t1)\n    y1 = y1.expand_as(t1)\n\n    inner = torch.cumsum(y1, dim=-1)\n    outer = torch.cumsum(y1, dim=-1)\n    inner = inner - y1 * (t0 - t1)\n    outer = outer - y1 * (t0 - t1)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n    t0_t1 = torch.cat([t0, t1], dim=1)\n    t1_t0 = torch.cat([t1, t0], dim=1)\n    y1_0 = torch.cat([y1, torch.zeros_like(y1)], dim=1)\n    y1_0_t0 = torch.cat([y1, torch.zeros_like(y1), t0], dim=1)\n    y1_0_t0_t1 = torch.cat([y1, torch.zeros_like(y1), t0, t1], dim=1)\n\n    inner = torch.cumsum(y1_0, dim=1)\n    outer = torch.cumsum(y1_0_t0, dim=1) - inner * t0\n    outer = torch.cumsum(outer, dim=1) + inner * t0_t1\n    outer = torch.cumsum(outer, dim=1) - inner * t1_t0\n    outer = torch.cumsum(outer, dim=1) / 2\n    return inner, outer\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source times (t1) that are smaller than the target time (t0)\n    idx_t1_smaller_t0 = searchsorted(t1, t0)\n\n    # Construct the inner measure by summing the values (y1) for the source times (t1) that are smaller than the target time (t0)\n    inner_measure = torch.cumsum(y1, dim=0)[idx_t1_smaller_t0 - 1]\n\n    # Construct the outer measure by summing the values (y1) for the source times (t1) that are greater than or equal to the target time (t0)\n    outer_measure = torch.cumsum(y1, dim=0)[-1] - inner_measure\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices where the target time (t0) lies between the source times (t1)\n    idx = searchsorted(t1, t0)\n\n    # Construct the inner measure based on cumulative sums\n    inner = y1.cumsum(dim=0)\n\n    # Construct the outer measure based on cumulative sums\n    outer = y1.cumsum(dim=0)\n\n    # Adjust the outer measure based on the indices where the target time (t0) lies between the source times (t1)\n    outer[idx] += y1[idx]\n\n    # Return the inner and outer measures\n    return inner, outer\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source times (t1) that are less than or equal to the target time (t0)\n    idx = searchsorted(t1, t0)\n\n    # Construct the inner measure by taking the difference between the cumulative sums of the values (y1) at the target time (t0) and the source time (t1) at the indices (idx)\n    inner = torch.cumsum(y1, dim=1)[:, idx]\n\n    # Construct the outer measure by taking the difference between the cumulative sums of the values (y1) at the target time (t0) and the source time (t1) at the indices (idx) + 1\n    outer = torch.cumsum(y1, dim=1)[:, idx + 1]\n\n    # Return the inner and outer measures as a tuple\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1 = t1.unsqueeze(-1)\n    y1 = y1.unsqueeze(-1)\n\n    t0 = t0.unsqueeze(-1)\n\n    # Compute the cumulative sums of the source times and values\n    cum_t1 = torch.cumsum(t1, dim=-1)\n    cum_y1 = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner measure\n    inner = torch.where(t0 > cum_t1, cum_y1, torch.zeros_like(cum_y1))\n\n    # Compute the outer measure\n    outer = torch.where(t0 > cum_t1, cum_y1 - y1, torch.zeros_like(cum_y1))\n\n    return inner, outer\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute cumulative sums for the source times (t1) and their corresponding values (y1)\n    cum_sum = torch.cumsum(y1, dim=0)\n    cum_sum_t1 = torch.cumsum(t1, dim=0)\n\n    # Calculate the indices of the source times (t1) that correspond to the target times (t0)\n    idx = searchsorted(t1, t0)\n\n    # Compute the inner measure based on the cumulative sums and indices\n    inner = cum_sum[idx] - cum_sum_t1[idx] * (t0 - t1[idx]) / (t1[idx + 1] - t1[idx])\n\n    # Compute the outer measure based on the cumulative sums and indices\n    outer = cum_sum[idx + 1] - cum_sum_t1[idx + 1] * (t0 - t1[idx + 1]) / (t1[idx + 1] - t1[idx])\n\n    # Return the inner and outer measures as a tuple of Tensors\n    return inner, outer\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    return 0.5 * (y0_outer - y0_inner) ** 2 / (w + eps)\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = torch.clamp(w_inner, min=0)\n    w_outer = torch.clamp(w_outer, min=0)\n    return torch.sum(w_inner * w_outer / (w_inner + w_outer + eps) * (w - w_inner) ** 2)\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = torch.where(w_inner < 0, 0, w_inner)\n    w_outer = torch.where(w_outer < 0, 0, w_outer)\n\n    w_inner = w_inner.clamp(min=eps)\n    w_outer = w_outer.clamp(min=eps)\n    w_inner = w_inner / w_inner.sum(dim=-1, keepdim=True)\n    w_outer = w_outer / w_outer.sum(dim=-1, keepdim=True)\n\n    w_inner = w_inner * w[..., 1:]\n    w_outer = w_outer * w[..., :-1]\n\n    loss = (w_inner - w_outer).pow(2).sum(dim=-1)\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    # calculate the loss\n    loss = (w - w_inner) ** 2 / (w_outer + eps)\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = w_env_inner.clamp_min(0)\n    w_env_outer = w_env_outer.clamp_min(0)\n    w_env_inner = w_env_inner / (w_env_inner.sum(dim=-1, keepdim=True) + eps)\n    w_env_outer = w_env_outer / (w_env_outer.sum(dim=-1, keepdim=True) + eps)\n\n    w_env_inner = w_env_inner.cumsum(dim=-1)\n    w_env_outer = w_env_outer.cumsum(dim=-1)\n\n    w_env_inner = w_env_inner * (w_env_inner > 0).float()\n    w_env_outer = w_env_outer * (w_env_outer > 0).float()\n\n    w_env_inner = w_env_inner.clamp_min(0)\n    w_env_outer = w_env_outer.clamp_min(0)\n\n    w_env_inner = w_env_inner / (w_env_inner.sum(dim=-1, keepdim=True) + eps)\n    w_env_outer = w_env_outer / (w_env_outer.sum(dim=-1, keepdim=True) + eps)\n\n    w_env_inner = w_env_inner * (w_env_inner > 0).float()\n    w_env_outer = w_env_outer * (w_env_outer > 0).float()\n\n    w_env_inner = w_env_inner.clamp_min(0)\n    w_env_outer = w_env_outer.clamp_min(0)\n\n    w_env_inner = w_env_inner / (w_env_inner.sum(dim=-1, keepdim=True) + eps)\n    w_env_outer = w_env_outer / (w_env_outer.sum(dim=-1, keepdim=True) + eps)\n\n    w_env_inner = w_env_inner * (w"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = w_env_inner.clamp(min=0)\n    w_env_outer = w_env_outer.clamp(min=0)\n    w_env_inner = w_env_inner.sum(-1, keepdim=True)\n    w_env_outer = w_env_outer.sum(-1, keepdim=True)\n\n    w_env_inner = w_env_inner.clamp(min=eps)\n    w_env_outer = w_env_outer.clamp(min=eps)\n\n    w_env_inner_inv = 1 / w_env_inner\n    w_env_outer_inv = 1 / w_env_outer\n\n    w_env_inner_inv = w_env_inner_inv.clamp(max=eps)\n    w_env_outer_inv = w_env_outer_inv.clamp(max=eps)\n\n    w_env_inner_inv = w_env_inner_inv.sum(-1, keepdim=True)\n    w_env_outer_inv = w_env_outer_inv.sum(-1, keepdim=True)\n\n    w_env_inner_inv = w_env_inner_inv.clamp(max=eps)\n    w_env_outer_inv = w_env_outer_inv.clamp(max=eps)\n\n    w_env_inner_inv = w_env_inner_inv.sqrt()\n    w_env_outer_inv = w_env_outer_inv.sqrt()\n\n    w_env_inner_inv = w_env_inner_inv.clamp(max=eps)\n    w_env_outer_inv = w_env_outer_inv.clamp(max=eps)\n\n    w_env_inner_inv = w_env_inner_inv.sum(-1, keepdim=True)\n    w_env_outer_inv = w_env_outer_inv.sum(-1, keepdim=True)\n\n    w_env_inner_inv = w_env_inner_inv.clamp(max=eps)\n    w_env_outer_inv = w_env_outer_inv"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = torch.clamp_min(w_inner, 0)\n    w_outer = torch.clamp_min(w_outer, 0)\n    w_inner = torch.cat([w_inner, torch.zeros_like(w_inner[..., :1])], dim=-1)\n    w_outer = torch.cat([w_outer, torch.zeros_like(w_outer[..., :1])], dim=-1)\n\n    w_inner = w_inner / (w_outer + eps)\n    w_inner = torch.clamp(w_inner, 0, 1)\n\n    w_inner = w_inner * w[..., 1:]\n    w_inner = torch.cat([torch.zeros_like(w_inner[..., :1]), w_inner], dim=-1)\n\n    return w_inner\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = torch.clamp(w_inner, min=0)\n    w_outer = torch.clamp(w_outer, min=0)\n    w_inner_sum = torch.sum(w_inner, dim=-1, keepdim=True)\n    w_outer_sum = torch.sum(w_outer, dim=-1, keepdim=True)\n    w_inner_sum = torch.where(w_inner_sum == 0, torch.ones_like(w_inner_sum), w_inner_sum)\n    w_outer_sum = torch.where(w_outer_sum == 0, torch.ones_like(w_outer_sum), w_outer_sum)\n    w_inner_scaled = w_inner / w_inner_sum\n    w_outer_scaled = w_outer / w_outer_sum\n    w_inner_scaled = torch.where(w_inner_scaled == 0, torch.ones_like(w_inner_scaled), w_inner_scaled)\n    w_outer_scaled = torch.where(w_outer_scaled == 0, torch.ones_like(w_outer_scaled), w_outer_scaled)\n    w_inner_scaled = torch.clamp(w_inner_scaled, min=eps)\n    w_outer_scaled = torch.clamp(w_outer_scaled, min=eps)\n    loss = torch.sum(w_inner_scaled * w_outer_scaled, dim=-1)\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = y0_inner / (y0_outer + eps)\n    w_env_inner = torch.clamp(w_env_inner, 0, 1)\n    w_env_outer = 1 - w_env_inner\n    w_env_outer = torch.clamp(w_env_outer, 0, 1)\n    loss = (w_env_inner - w) ** 2 + (w_env_outer - w) ** 2\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = torch.clamp_min(w_inner, 0)\n    w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = w_inner[..., 1:]\n    # w_outer = w_outer[..., :-1]\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer, 0)\n\n    # w_inner = torch.clamp_min(w_inner, 0)\n    # w_outer = torch.clamp_min(w_outer,"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t0, w0 = t[..., :-1], w[..., 1:]\n    t1, w1 = t_env[..., :-1], w_env[..., 1:]\n    y0_inner, y0_outer = inner_outer(t0, t1, w1)\n\n    loss = torch.where(y0_outer > 0, 0.5 * (w0 - y0_inner) ** 2 / y0_outer, 0)\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss based on the difference between the inner and outer weights\n    loss = w_outer - w_inner\n\n    # scale the loss using a half-quadratic loss function\n    loss = loss.pow(2) / (2 * eps) + loss.abs() / eps\n    loss = loss.sum(-1)\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = w_inner[..., :-1]\n    w_outer = w_outer[..., 1:]\n    w_inner = torch.max(w_inner, torch.zeros_like(w_inner))\n    w_outer = torch.max(w_outer, torch.zeros_like(w_outer))\n    w_inner_sum = torch.sum(w_inner, dim=-1, keepdim=True)\n    w_outer_sum = torch.sum(w_outer, dim=-1, keepdim=True)\n    w_inner_sum = torch.max(w_inner_sum, torch.ones_like(w_inner_sum) * eps)\n    w_outer_sum = torch.max(w_outer_sum, torch.ones_like(w_outer_sum) * eps)\n    w_inner = w_inner / w_inner_sum\n    w_outer = w_outer / w_outer_sum\n    w_inner = w_inner * w[..., 1:]\n    w_outer = w_outer * w[..., :-1]\n    loss = torch.mean(torch.sum((w_inner - w_outer) ** 2, dim=-1))\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n    w_env_inner = torch.where(w_env_inner < 0, 0, w_env_inner)\n    w_env_outer = torch.where(w_env_outer < 0, 0, w_env_outer)\n\n    w_env_inner = w_env_inner.clamp(min=eps)\n    w_env_outer = w_env_outer.clamp(min=eps)\n\n    w_env_inner_cum = torch.cumsum(w_env_inner, dim=-1)\n    w_env_outer_cum = torch.cumsum(w_env_outer, dim=-1)\n\n    w_env_inner_cum = torch.where(w_env_inner_cum < 0, 0, w_env_inner_cum)\n    w_env_outer_cum = torch.where(w_env_outer_cum < 0, 0, w_env_outer_cum)\n\n    w_env_inner_cum = w_env_inner_cum.clamp(min=eps)\n    w_env_outer_cum = w_env_outer_cum.clamp(min=eps)\n\n    w_env_inner_cum = w_env_inner_cum[..., None]\n    w_env_outer_cum = w_env_outer_cum[..., None]\n\n    w_env_inner_cum = torch.cat([torch.zeros_like(w_env_inner_cum[..., :1]), w_env_inner_cum], dim=-1)\n    w_env_outer_cum = torch.cat([torch.zeros_like(w_env_outer_cum[..., :1]), w_env_outer_cum], dim=-1)\n\n    w_env_inner_cum = torch.where(w_env_inner_cum < 0, 0, w_env_inner_cum)\n    w_env_outer_cum = torch.where(w_env_outer_cum < 0, 0, w_env_outer_cum)\n\n    w_env_inner_cum = w_env_inner_cum.clamp(min="}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # w_env.shape[-1] = w.shape[-1]\n    # t_env.shape[-1] = w.shape[-1] + 1\n    # t.shape[-1] = w.shape[-1] + 1\n    # w.shape[-1] = w_env.shape[-1] - 1\n    # w.shape[-1] = t.shape[-1] - 1\n\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    return 0.5 * ((w - w_inner) ** 2) / (w_outer + eps)\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t_env.shape[-1] == w_env.shape[-1] + 1\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    w_inner = torch.clamp_min(w_inner, 0)\n    w_outer = torch.clamp_min(w_outer, 0)\n\n    w_inner_sum = torch.sum(w_inner, dim=-1, keepdim=True)\n    w_outer_sum = torch.sum(w_outer, dim=-1, keepdim=True)\n\n    w_inner_sum = torch.clamp_min(w_inner_sum, eps)\n    w_outer_sum = torch.clamp_min(w_outer_sum, eps)\n\n    w_inner_norm = w_inner / w_inner_sum\n    w_outer_norm = w_outer / w_outer_sum\n\n    w_diff = w - torch.sum(w_inner_norm * w_outer, dim=-1, keepdim=True)\n    w_diff = torch.clamp_min(w_diff, 0)\n\n    return 0.5 * w_diff ** 2 / w_outer_norm\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # w_env is the weight of the environment points\n    # w is the weight of the target points\n\n    # t_env is the position of the environment points\n    # t is the position of the target points\n\n    # t_env.shape = (B, N_env, 1)\n    # t.shape = (B, N_target, 1)\n    # w_env.shape = (B, N_env, 1)\n    # w.shape = (B, N_target, 1)\n\n    w_env = w_env.unsqueeze(-1)\n    w = w.unsqueeze(-1)\n    t_env = t_env.unsqueeze(-1)\n    t = t.unsqueeze(-1)\n\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n    loss = (w - w_inner) ** 2 / (w_outer + eps)\n    loss = loss.sum(dim=-1)  # sum over channels\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env = t_env[..., None]\n    w_env = w_env[..., None]\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    w_env_outer_clamped = torch.clamp(w_env_outer, min=eps)\n    w_env_inner_clamped = torch.clamp(w_env_inner, min=eps)\n\n    w_env_inner_clamped = w_env_inner_clamped / w_env_outer_clamped\n    w_env_inner_clamped = w_env_inner_clamped * w_env_outer_clamped\n\n    w_env_inner_clamped = torch.clamp(w_env_inner_clamped, min=eps)\n\n    loss = torch.sum(w * torch.log(w / w_env_inner_clamped), dim=-1)\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env = torch.cat([w_env, torch.zeros_like(w_env[..., :1])], dim=-1)  # 129\n    w_env = w_env.cumsum(dim=-1)  # 129\n    w_env = torch.cat([torch.zeros_like(w_env[..., :1]), w_env], dim=-1)  # 129\n    w_env = w_env[..., 1:] - w_env[..., :-1]  # 128\n\n    t_env = torch.cat([t_env, torch.zeros_like(t_env[..., :1])], dim=-1)  # 129\n    t_env = t_env.cumsum(dim=-1)  # 129\n    t_env = torch.cat([torch.zeros_like(t_env[..., :1]), t_env], dim=-1)  # 129\n    t_env = t_env[..., 1:] - t_env[..., :-1]  # 128\n\n    t = torch.cat([t, torch.zeros_like(t[..., :1])], dim=-1)  # 129\n    t = t.cumsum(dim=-1)  # 129\n    t = torch.cat([torch.zeros_like(t[..., :1]), t], dim=-1)  # 129\n    t = t[..., 1:] - t[..., :-1]  # 128\n\n    w_env_lo, w_env_hi = inner_outer(t, t_env, w_env)  # 128\n\n    w_env_lo = torch.maximum(w_env_lo, 0)\n    w_env_hi = torch.maximum(w_env_hi, 0)\n\n    w_env = w_env_lo + w_env_hi  # 128\n\n    w_env = w_env + eps\n    w_env_lo = w_env_lo + eps\n    w_env_hi = w_env_hi + eps\n\n    w_env = torch.maximum(w_env, 0)\n    w_env_lo = torch.maximum"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)  # 128, 127\n    w_env_outer = w_env_outer + eps  # 127\n\n    w_env_inner = w_env_inner.unsqueeze(-1)  # 127, 1\n    w_env_outer = w_env_outer.unsqueeze(-1)  # 127, 1\n\n    w_env_outer = torch.cat([w_env_inner, w_env_outer], dim=-1)  # 127, 2\n    w_env_outer = w_env_outer.cumsum(dim=-1)  # 127, 2\n\n    w_env_outer = w_env_outer.clamp(0, 1)  # 127, 2\n\n    w = w.unsqueeze(-1)  # 128, 1\n    w_env_outer = w_env_outer.unsqueeze(-2)  # 1, 127, 2\n\n    w_env_outer = w_env_outer * w  # 128, 127, 2\n    w_env_outer = w_env_outer.sum(dim=-2)  # 128, 2\n\n    w_env_outer = w_env_outer.clamp(0, 1)  # 128, 2\n\n    w_env_outer = w_env_outer.sum(dim=-1)  # 128\n\n    w_env_outer = w_env_outer.clamp(0, 1)  # 128\n\n    loss = torch.abs(w - w_env_outer)  # 128\n\n    loss = loss.mean()  # scalar\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    _, w_outer = inner_outer(t, t, w)\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    return (w - w_outer).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    t_outer, w_outer = inner_outer(t, t, w)\n    w_inner = torch.clip(w_inner, min=0.)\n    w_outer = torch.clip(w_outer, min=0.)\n    w_inner_sum = torch.sum(w_inner, dim=-1, keepdim=True)\n    w_outer_sum = torch.sum(w_outer, dim=-1, keepdim=True)\n    w_inner_norm = w_inner / w_inner_sum\n    w_outer_norm = w_outer / w_outer_sum\n    w_inner_norm = torch.where(torch.isnan(w_inner_norm), torch.zeros_like(w_inner_norm), w_inner_norm)\n    w_outer_norm = torch.where(torch.isnan(w_outer_norm), torch.zeros_like(w_outer_norm), w_outer_norm)\n    w_inner_norm = torch.where(torch.isinf(w_inner_norm), torch.zeros_like(w_inner_norm), w_inner_norm)\n    w_outer_norm = torch.where(torch.isinf(w_outer_norm), torch.zeros_like(w_outer_norm), w_outer_norm)\n    w_inner_norm = torch.where(torch.isinf(w_inner_norm), torch.zeros_like(w_inner_norm), w_inner_norm)\n    w_outer_norm = torch.where(torch.isinf(w_outer_norm), torch.zeros_like(w_outer_norm), w_outer_norm)\n    w_inner_norm = torch.where(torch.isinf(w_inner_norm), torch.zeros_like(w_inner_norm), w_inner_norm)\n    w_outer_norm = torch.where(torch.isinf(w_outer_norm), torch.zeros_like(w_outer_norm), w_outer_norm)\n    w_inner_norm = torch.where(torch.isinf("}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the inter-interval loss\n    _, w_outer = inner_outer(t, t, w)\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    inter_loss = (w - w_outer).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n    # Compute the intra-interval loss\n    _, w_inner = inner_outer(t, t, w)\n    # We assume w_inner <= w <= w_outer. We don't penalize w_outer because it's\n    # more effective to pull w_inner up than it is to push w_outer down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_inner = 0.\n    intra_loss = (w_inner - w).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n    # Combine the inter-interval and intra-interval losses\n    loss = (inter_loss + intra_loss).mean()\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    loss_inter = (w_inner - w).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n    loss_intra = (w_inner - w_inner.mean(dim=-1, keepdim=True)).clip(0.).pow(2)\n    loss_intra = loss_intra.mean(dim=-1)\n    return loss_inter.mean(dim=-1) + loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the inter-interval loss\n    t_inner, w_inner = inner_outer(t, t, w)\n    inter_loss = (w_inner - w).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n    # Compute the intra-interval loss\n    intra_loss = (t_inner[..., 1:] - t_inner[..., :-1]).clip(0.).pow(2) / (t_inner[..., 1:] + t_inner[..., :-1] + torch.finfo(torch.float32).eps)\n\n    # Combine the inter-interval and intra-interval losses\n    loss = (inter_loss + intra_loss).mean()\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    w_inner, w_outer = inner_outer(t, t, w)\n\n    # Inter-interval loss\n    inter_loss = (w - w_outer).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n    # Intra-interval loss\n    intra_loss = (w_inner - w).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n    return (inter_loss + intra_loss).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # inter-interval loss\n    t_lo, w_lo = t[..., :-1], w[..., :-1]\n    t_hi, w_hi = t[..., 1:], w[..., 1:]\n    w_lo_hi = torch.cat([w_lo, w_hi], dim=-1)\n    t_lo_hi = torch.cat([t_lo, t_hi], dim=-1)\n    _, w_outer = inner_outer(t_lo_hi, t, w_lo_hi)\n    w_inner = w_lo_hi - w_outer\n    w_inner_lo = w_inner[..., :-1]\n    w_inner_hi = w_inner[..., 1:]\n    w_lo_hi_inner = torch.cat([w_lo, w_inner_lo, w_hi, w_inner_hi], dim=-1)\n    t_lo_hi_inner = torch.cat([t_lo, t_lo, t_hi, t_hi], dim=-1)\n    _, w_outer = inner_outer(t_lo_hi_inner, t_lo_hi, w_lo_hi_inner)\n    w_inner = w_lo_hi_inner - w_outer\n    w_inner_lo_lo = w_inner[..., :-2]\n    w_inner_lo_hi = w_inner[..., 1:-1]\n    w_inner_hi_lo = w_inner[..., 2:]\n    w_inner_hi_hi = w_inner[..., 3:]\n    w_lo_hi_inner_inner = torch.cat([w_lo, w_inner_lo_lo, w_inner_lo_hi, w_hi, w_inner_hi_lo, w_inner_hi_hi], dim=-1)\n    t_lo_hi_inner_inner = torch.cat([t_lo, t_lo, t_lo, t_hi, t_hi, t_hi], dim=-1)\n    _, w_outer = inner_outer(t_lo_hi_inner_inner, t_lo_hi_inner, w_lo_hi_inner_inner)\n    w_inner = w"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    w_inner = torch.clip(w_inner, min=0.)\n    w_outer = torch.clip(w_outer, min=0.)\n\n    # inter-interval loss\n    loss_inter = (w_inner - w_outer).pow(2) / (w_outer + torch.finfo(torch.float32).eps)\n    loss_inter = loss_inter.mean()\n\n    # intra-interval loss\n    loss_intra = (w_inner - w_outer).pow(2) / (w_inner + torch.finfo(torch.float32).eps)\n    loss_intra = loss_intra.mean()\n\n    # total loss\n    loss = loss_inter + loss_intra\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    t_outer, w_outer = inner_outer(t, t, w)\n\n    # Inter-interval loss\n    loss_inter = (w_outer - w_inner).clip(0.).pow(2) / (w_inner + torch.finfo(torch.float32).eps)\n\n    # Intra-interval loss\n    loss_intra = (w_inner - w_outer).clip(0.).pow(2) / (w_outer + torch.finfo(torch.float32).eps)\n\n    # Combine the inter-interval and intra-interval losses\n    loss = loss_inter + loss_intra\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    t_outer, w_outer = inner_outer(t, t, w)\n\n    w_inner = w_inner.clip(0.)\n    w_outer = w_outer.clip(0.)\n\n    w_inner_norm = w_inner / torch.clamp_min(t_inner[..., 1:] - t_inner[..., :-1], 1e-6)\n    w_outer_norm = w_outer / torch.clamp_min(t_outer[..., 1:] - t_outer[..., :-1], 1e-6)\n\n    w_inner_norm_sum = torch.sum(w_inner_norm, dim=-1)\n    w_outer_norm_sum = torch.sum(w_outer_norm, dim=-1)\n\n    # intra-interval loss\n    intra_loss = torch.sum(w_inner_norm.pow(2), dim=-1) / torch.clamp_min(w_inner_norm_sum, 1e-6)\n    # inter-interval loss\n    inter_loss = torch.sum(w_outer_norm.pow(2), dim=-1) / torch.clamp_min(w_outer_norm_sum, 1e-6)\n\n    return intra_loss + inter_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # inter-interval loss\n    t0, t1 = t[..., :-1], t[..., 1:]\n    w0, w1 = w[..., :-1], w[..., 1:]\n    # intra-interval loss\n    w_inner, w_outer = inner_outer(t0, t1, w1)\n    # The proposal weight should be an upper envelope on the nerf weight.\n    # We assume w_inner <= w <= w_outer. We don't penalize w_inner because it's\n    # more effective to pull w_outer up than it is to push w_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at w_outer = 0.\n    loss_inter = (w - w_outer).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n    loss_intra = (w - w_inner).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n    return loss_inter, loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    return (w_inner.clip(0.).pow(2) + (w - w_inner - w_outer).clip(0.).pow(2)).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # inter-interval loss\n    _, w_outer = inner_outer(t, t, w)\n    # intra-interval loss\n    w_inner, _ = inner_outer(t, t, w)\n    # combine\n    return (w_outer + w_inner).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    _, w_outer = inner_outer(t, t, w)\n    w_inner = torch.where(w_outer > 0, w / w_outer, 0)\n\n    return (w_inner - w).clip(0.).pow(2) / (w + 1e-6)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    w_inner = torch.clip(w_inner, min=0.0)\n    w_inner_loss = (w_inner - w).pow(2) / (w + 1e-6)\n\n    t_outer, w_outer = inner_outer(t, t, w)\n    w_outer_loss = (w_outer - w).pow(2) / (w + 1e-6)\n\n    return (w_inner_loss + w_outer_loss).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    t_inner = t_inner[..., 1:]\n    w_inner = w_inner[..., 1:]\n    w_outer = w[..., :-1]\n    w_inner = w_inner.clip(0.)\n    w_outer = w_outer.clip(0.)\n    w_inner_sum = w_inner.sum(-1, keepdim=True)\n    w_outer_sum = w_outer.sum(-1, keepdim=True)\n    t_inner_avg = (t_inner * w_inner).sum(-1, keepdim=True) / w_inner_sum\n    t_outer_avg = (t[..., :-1] * w_outer).sum(-1, keepdim=True) / w_outer_sum\n    loss_inter = ((t_inner_avg - t_outer_avg) * w_inner_sum).sum(-1)\n    loss_intra = ((t_inner - t_inner_avg) * w_inner).sum(-1).sum(-1)\n    return loss_inter + loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_mid = 0.5 * (t[..., 1:] + t[..., :-1])\n    w_mid = 0.5 * (w[..., 1:] + w[..., :-1])\n    w_mid = torch.clamp_min(w_mid, 1e-6)\n\n    w_inner, w_outer = inner_outer(t_mid, t, w)\n    w_inner = torch.clamp_min(w_inner, 1e-6)\n    w_outer = torch.clamp_min(w_outer, 1e-6)\n\n    # Inter-interval loss\n    loss_inter = ((w_inner - w_outer).pow(2) / (w_outer + 1e-6)).mean()\n\n    # Intra-interval loss\n    loss_intra = ((w - w_mid).pow(2) / (w_mid + 1e-6)).mean()\n\n    return loss_inter + loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_inner, w_outer = inner_outer(t, t, w)\n    t_inner_loss = (t_inner / (w_inner + 1e-6)).pow(2)\n    t_outer_loss = (t_outer / (w_outer + 1e-6)).pow(2)\n    t_inner_loss = torch.where(t_inner_loss > 1e-6, t_inner_loss, 0)\n    t_outer_loss = torch.where(t_outer_loss > 1e-6, t_outer_loss, 0)\n    t_loss = t_inner_loss + t_outer_loss\n    return t_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_inner, w_inner = inner_outer(t, t, w)\n    w_inner = w_inner.clip(0.)\n    w_outer = w - w_inner\n    w_inner_norm = w_inner / (w + torch.finfo(torch.float32).eps)\n    w_outer_norm = w_outer / (w + torch.finfo(torch.float32).eps)\n    w_inner_norm_sq = w_inner_norm.pow(2)\n    w_outer_norm_sq = w_outer_norm.pow(2)\n    loss_inter = (w_inner_norm_sq + w_outer_norm_sq) / 2\n    loss_intra = (w_inner_norm_sq * w_outer_norm_sq) / (w_inner_norm_sq + w_outer_norm_sq)\n    return (loss_inter + loss_intra).mean()\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    \"\"\"\n    The loss function is designed to calculate the distortion loss for a given tensor of targets and weights. It calculates both the inter-interval and intra-interval losses based on the provided tensors and combines them to produce the total distortion loss.\n\n    The function first checks if the last dimension of the target tensor 't' is one more than that of the weights tensor 'w'. If this condition is not met, the function raises a ValueError.\n\n    Next, the function calculates the inner and outer measures of the target tensor 't' with respect to the weights tensor 'w'. The inner measures are calculated by taking the cumulative sum of the weights tensor 'w' along the last dimension and then taking the difference between the adjacent elements. The outer measures are calculated by taking the cumulative sum of the weights tensor 'w' along the last dimension and then taking the difference between the adjacent elements.\n\n    The function then calculates the inter-interval loss by taking the difference between the inner and outer measures of the target tensor 't' with respect to the weights tensor 'w'. The intra-interval loss is calculated by taking the difference between the adjacent elements of the target tensor 't'.\n\n    The function then calculates the total distortion loss by taking the maximum of the inter-interval loss and the intra-interval loss. The function returns the total distortion loss as a tensor.\n    \"\"\"\n\n    # inter-interval loss\n    inner, outer = inner_outer(t, t, w)\n    inter_interval_loss = outer - inner\n    # intra-interval loss\n    intra_interval_loss = torch.diff(t, dim=-1)\n    # total distortion loss\n    total_distortion_loss = torch.max(inter_interval_loss, intra_interval_loss)\n    return total_distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    p = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    p = p.view(-1, 1, 1)\n    p = p.expand(p.shape + t.shape[1:])\n    return interpolate(p, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    # Match the channels of t and w\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF and inverse CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Sample uniformly on [0, 1).\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    if perturb:\n        # Perturb the samples to avoid sample clustering at bin boundaries.\n        u += torch.rand(t.shape[:-1] + (num_samples,), device=t.device) / num_samples\n    if single_jitter:\n        # Apply the same jitter to every sample along each dimension.\n        u += torch.rand(t.shape[:-1] + (1,), device=t.device)\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dimension\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)  # 65\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Interpolate into the inverse CDF.\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device, dtype=t.dtype)\n    t_new = interpolate(u, cw, t)\n\n    if perturb:\n        # Compute the PDF and CDF for each weight vector.\n        cw = integrate_weights(w)\n        # Interpolate into the inverse CDF.\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device, dtype=t.dtype)\n        t_new = interpolate(u, cw, t)\n        # Compute the PDF and CDF for each weight vector.\n        cw = integrate_weights(w)\n        # Interpolate into the inverse CDF.\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device, dtype=t.dtype)\n        t_new = interpolate(u, cw, t)\n        # Compute the PDF and CDF for each weight vector.\n        cw = integrate_weights(w)\n        # Interpolate into the inverse CDF.\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device, dtype=t.dtype)\n        t_new = interpolate(u, cw, t)\n        # Compute the PDF and CDF for each weight vector.\n        cw = integrate_weights(w)\n        # Interpolate into the inverse CDF.\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device, dtype=t.dtype)\n        t_new = interpolate(u, cw, t)\n        # Compute the PDF and CDF for each weight vector.\n        cw = integrate_weights(w)\n        # Interpolate"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dimension\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)  # 65\n\n    # Compute the CDF and inverse CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Compute the inverse CDF for each weight vector.\n    t_new = interpolate(torch.rand(t.shape[:-1] + (num_samples,), device=t.device), cw, t)\n\n    if perturb:\n        # Perturb the samples to avoid sample clustering at bin boundaries.\n        t_new = t_new + (torch.rand(t.shape[:-1] + (num_samples,), device=t.device) - 0.5) / (num_samples + 1)\n\n    if single_jitter:\n        # Apply the same jitter to every sample along each dimension.\n        t_new = t_new + (torch.rand(t.shape[:-1] + (1,), device=t.device) - 0.5) / (num_samples + 1)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match up the channels of t and w.\n    t, w = matchup_channels(t, w)\n    # Compute the CDF and invert it.\n    cw = integrate_weights(w)\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    t_new = interpolate(u, cw, t)\n    # Perturb the samples.\n    if perturb:\n        t_new = t_new + (torch.rand_like(t_new) - 0.5) / num_samples\n    # Apply jitter.\n    if single_jitter:\n        t_new = t_new + torch.rand(t_new.shape[:-1] + (1,), device=t_new.device) / num_samples\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Generate uniform samples in [0, 1).\n    if single_jitter:\n        # Generate a single jitter for all samples.\n        u = torch.rand(t.shape[:-1], device=t.device) + torch.rand(t.shape[:-1], device=t.device)\n    else:\n        # Generate independent jitters for each sample.\n        u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device) + torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n\n    # Apply perturbation to the uniform samples.\n    u = u * cw[..., -1]\n\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF and its inverse.\n    cw = integrate_weights(w)\n    # Draw uniform samples in [0, 1) and invert the CDF.\n    u = torch.rand(num_samples, device=t.device)\n    t_new = interpolate(u, cw, t)\n    # Perturb the samples.\n    if perturb:\n        t_new += torch.rand_like(t_new) * (t_new[1] - t_new[0])\n    # Apply jitter.\n    if single_jitter:\n        jitter = torch.rand(1, device=t.device) * (t_new[1] - t_new[0])\n        t_new += jitter\n    else:\n        jitter = torch.rand_like(t_new) * (t_new[1] - t_new[0])\n        t_new += jitter\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Reshape tensors to match the desired output shape\n    t = t.reshape([-1, t.shape[-1]])\n    w = w.reshape([-1, w.shape[-1]])\n\n    # Compute the cumulative sum of weights\n    cw = integrate_weights(w)\n\n    # Generate uniformly distributed samples in [0, 1)\n    u = torch.rand(t.shape[0], num_samples, device=t.device)\n\n    # Apply perturbation\n    if perturb:\n        u = u + torch.rand(t.shape[0], 1, device=t.device) / num_samples\n\n    # Apply jittering\n    if single_jitter:\n        jitter = torch.rand(t.shape[0], 1, device=t.device)\n    else:\n        jitter = torch.rand(t.shape[0], num_samples, device=t.device)\n    u = u + jitter / num_samples\n\n    # Interpolate into the inverse CDF\n    t_new = interpolate(u, cw, t)\n\n    # Reshape the output to match the input shape\n    t_new = t_new.reshape(t.shape[0], num_samples, t.shape[-1])\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Generate uniform samples.\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    # Perturb the samples.\n    if perturb:\n        u = u * (1 - 1e-5) + 1e-5 / 2  # 0.00005\n    # Invert the CDF to get the samples.\n    t_new = interpolate(u, cw, t)\n    # Apply jitter to the samples.\n    if single_jitter:\n        jitter = torch.rand(t.shape[:-1] + (1,), device=t.device)\n        t_new = t_new * (1 - jitter) + jitter * t[..., -1:]\n    else:\n        jitter = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n        t_new = t_new * (1 - jitter) + jitter * t[..., -1:]\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Sample uniformly in [0, 1) for each sample.\n    u = torch.rand(num_samples, device=t.device)\n    # Invert the CDF at the sampled points.\n    t_new = interpolate(u, cw, t)\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Compute the bin widths.\n        dt = t[..., 1:] - t[..., :-1]\n        # Compute the jitter.\n        jitter = torch.rand_like(t_new)\n        # Apply the jitter to the samples.\n        if single_jitter:\n            jitter = jitter.mean(dim=-1, keepdim=True)\n        t_new += jitter * dt\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n    if perturb:\n        # Compute the CDF for each weight vector.\n        cw = integrate_weights(w)\n        # Sample uniformly from [0, 1).\n        u = torch.rand(num_samples, device=t.device)\n        # Interpolate into the inverse CDF.\n        t_new = interpolate(u, cw, t)\n    else:\n        # Sample uniformly from [0, 1).\n        u = torch.rand(num_samples, device=t.device)\n        # Interpolate into the inverse CDF.\n        t_new = interpolate(u, w, t)\n    if single_jitter:\n        # Apply the same jitter to every sample along each dimension.\n        t_new += torch.rand(1, device=t.device) * (t_new[..., -1] - t_new[..., 0])\n    else:\n        # Apply independent jitter to each sample.\n        t_new += torch.rand_like(t_new) * (t_new[..., -1] - t_new[..., 0])\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF and inverse CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Sample uniformly in [0, 1) and invert the CDF.\n    u = torch.rand(num_samples, device=t.device)\n    t_new = interpolate(u, cw, t)\n\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Compute the bin indices for each sample.\n        t_new_mat = t_new.reshape([-1, t_new.shape[-1]])\n        t_mat = t.reshape([-1, t.shape[-1]])\n        idx_lo, idx_hi = searchsorted(t_mat, t_new_mat)\n        idx_lo = idx_lo.reshape(t_new.shape[:-1])\n        idx_hi = idx_hi.reshape(t_new.shape[:-1])\n\n        # Compute the perturbation amount for each sample.\n        perturb_amount = torch.rand_like(t_new)\n        perturb_amount = perturb_amount * (idx_hi - idx_lo) + idx_lo\n\n        # Perturb the samples.\n        t_new = t_new + perturb_amount\n\n    # Jitter the samples to avoid sample clustering at bin centers.\n    if single_jitter:\n        # Compute the bin indices for each sample.\n        t_new_mat = t_new.reshape([-1, t_new.shape[-1]])\n        t_mat = t.reshape([-1, t.shape[-1]])\n        idx_lo, idx_hi = searchsorted(t_mat, t_new_mat)\n        idx_lo = idx_lo.reshape(t_new.shape[:-1])\n        idx_hi = idx_hi.reshape(t_new.shape[:-1])\n\n        # Compute the jitter amount for each sample.\n        jitter_amount = torch.rand_like(t_new)\n        jitter_amount = jitter_amount * (idx_hi - idx_lo) + idx_lo\n\n        # Jitter the samples.\n        t_new = t_new + jitter_amount\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF and inverse CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Sample uniformly along the CDF.\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    t_new = interpolate(u, cw, t)\n    if perturb:\n        # Perturb the sampling process to avoid sample clustering at bin boundaries.\n        # Compute the average bin width.\n        delta = t[..., 1:] - t[..., :-1]\n        delta_avg = delta.mean(dim=-1, keepdim=True)\n        # Compute the perturbation amount.\n        delta_perturb = torch.rand(t.shape[:-1] + (num_samples,), device=t.device) * delta_avg\n        # Apply the perturbation to the samples.\n        t_new = t_new + delta_perturb\n    if single_jitter:\n        # Apply the same jitter to every sample along each dimension.\n        # Compute the jitter amount.\n        jitter = torch.rand(t.shape[:-1] + (1,), device=t.device)\n        # Apply the jitter to the samples.\n        t_new = t_new + jitter\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Validate input tensors\n    if t.ndim != w.ndim + 1:\n        raise ValueError(\"t and w must have the same number of dimensions plus one.\")\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(\"t and w must have the same number of bins.\")\n    if not torch.all(torch.diff(t, dim=-1) >= 0):\n        raise ValueError(\"t must be sorted.\")\n\n    # Match the number of channels\n    t, w = matchup_channels(t, w)\n\n    # Compute the CDF and PDF\n    cw = integrate_weights(w)\n    pdf = w / (cw[..., -1:] - cw[..., :-1])\n\n    # Sample from the CDF\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    t_new = invert_cdf(u, t, cw)\n\n    # Perturb the samples\n    if perturb:\n        t_new = t_new + torch.rand_like(t_new) * (cw[..., 1:] - cw[..., :-1])\n\n    # Jitter the samples\n    if single_jitter:\n        jitter = torch.rand(t.shape[:-1] + (1,), device=t.device)\n        t_new = t_new + (jitter - 0.5) * (cw[..., 1:] - cw[..., :-1])\n    else:\n        jitter = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n        t_new = t_new + (jitter - 0.5) * (cw[..., 1:] - cw[..., :-1])\n\n    # Return the samples\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(f\"t and w must have the same last dimension, but got {t.shape[-1]} and {w.shape[-1]}\")\n\n    # Compute the CDF.\n    cw = integrate_weights(w)\n\n    # Sample uniformly from [0, 1) for each sample.\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n\n    # Invert the CDF to get the samples.\n    t_new = interpolate(u, cw, t)\n\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        t_new = perturb_samples(t_new, t, w)\n\n    # Jitter the samples to avoid sample clustering at bin boundaries.\n    if single_jitter:\n        t_new = jitter_samples(t_new, t, w)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Uniformly sample the CDF.\n    u = torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Compute the midpoints of each bin.\n        t_mid = 0.5 * (t[..., :-1] + t[..., 1:])\n        # Compute the distances between the midpoints and the samples.\n        t_dist = t_new[..., None] - t_mid[..., :, None]\n        # Compute the indices of the closest midpoint to each sample.\n        t_dist_abs = torch.abs(t_dist)\n        t_dist_min, t_dist_min_idx = torch.min(t_dist_abs, dim=-2)\n        # Compute the jittering factor.\n        jitter_factor = 0.5 * torch.rand(t.shape[:-1] + (num_samples,), device=t.device)\n        # Jitter the samples based on the jittering factor and the closest midpoint.\n        t_new = t_new + (1 - 2 * jitter_factor) * t_dist_min * torch.sign(t_dist_min_idx)\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure the weights are normalized.\n    w = w / torch.sum(w, dim=-1, keepdim=True)\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n    # Generate uniform samples in [0, 1).\n    u = torch.rand(num_samples, device=t.device)\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n\n    if perturb:\n        # Compute the PDF and CDF for each weight vector.\n        pdf = w / (t[..., 1:] - t[..., :-1] + 1e-8)\n        cdf = integrate_weights(pdf)\n        # Generate uniform samples in [0, 1).\n        u = torch.rand(num_samples, device=t.device)\n        # Interpolate into the inverse CDF.\n        pdf_new = interpolate(u, cdf, pdf)\n        # Compute the perturbation.\n        perturbation = (t[..., 1:] - t[..., :-1]) * (torch.sqrt(pdf_new) - torch.sqrt(pdf))\n        # Add the perturbation to the samples.\n        t_new = t_new + perturbation\n\n    # Jitter the samples.\n    if single_jitter:\n        # Generate a single jitter value for each dimension.\n        jitter = torch.rand(1, device=t.device)\n        # Apply the jitter to all samples along each dimension.\n        t_new = t_new + jitter\n    else:\n        # Generate independent jitter values for each sample.\n        jitter = torch.rand(num_samples, device=t.device)\n        # Apply the jitter to each sample along each dimension.\n        t_new = t_new + jitter[..., None]\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that the input tensors have the correct shape and data type\n    assert t.ndim == w.ndim + 1, 't and w must have the same number of dimensions, with w having one additional dimension for the weights.'\n    assert t.dtype == torch.float32 or t.dtype == torch.float64, 't and w must have float32 or float64 dtype.'\n\n    # Match the number of channels in t and w if necessary\n    t, w = matchup_channels(t, w)\n\n    # Compute the cumulative weights and normalize them to sum to 1\n    cw = integrate_weights(w)\n\n    # Generate uniformly-distributed random numbers in the range [0, 1)\n    u = torch.rand(num_samples, device=t.device)\n\n    # Perturb the random numbers to avoid sample clustering at bin boundaries\n    if perturb:\n        u += torch.rand_like(u) / num_samples\n\n    # Interpolate the random numbers into the inverse CDF\n    t_new = interpolate(u, cw, t)\n\n    # Apply jittering to the samples\n    if single_jitter:\n        jitter = torch.rand(1, device=t.device)\n    else:\n        jitter = torch.rand(num_samples, device=t.device)\n    t_new = t_new + (jitter - 0.5) / num_samples\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF and PDF for each weight vector.\n    cw = integrate_weights(w)\n    # Invert the CDF to get the samples.\n    u = torch.rand([num_samples, *t.shape[:-1]], device=t.device)\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            jitter = torch.rand(t.shape[:-1], device=t.device)\n        else:\n            # Apply independent jitter to each sample.\n            jitter = torch.rand([num_samples, *t.shape[:-1]], device=t.device)\n        u = (u + jitter) % 1\n    t_new = interpolate(u, cw, t)\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Sample uniformly in [0, 1) along the last dimension.\n    u = torch.rand(num_samples, device=t.device)\n    if single_jitter:\n        u += torch.rand(1, device=t.device)\n    u = u % 1.0\n    # Interpolate into the inverse CDF.\n    t_new = interpolate(u, cw, t)\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Compute the PDF for each weight vector.\n        p = w / cw[..., -1:]\n        # Compute the CDF of the PDF.\n        cp = integrate_weights(p)\n        # Compute the inverse CDF of the PDF.\n        t_new = interpolate(u, cp, t)\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the CDF of the PDF\n    cw = integrate_weights(w)\n\n    # Compute the uniform samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples\n    t_new = interpolate(u, cw, t)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        # Compute the uniform perturbation values\n        u_perturb = torch.rand(num_samples, device=t.device)\n\n        # Compute the perturbation values\n        t_perturb = interpolate(u_perturb, cw, t)\n\n        # Apply the perturbation to the samples\n        t_new = t_new + t_perturb * (1 - cw[..., -1:])\n\n    # Apply jitter to the samples\n    if single_jitter:\n        # Compute the jitter values\n        jitter = torch.rand(t_new.shape[:-1], device=t.device)\n\n        # Apply the jitter to the samples\n        t_new = t_new + jitter[..., None] * (t[..., 1:] - t[..., :-1])\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = dilation * t\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n    w_dilated = w / dilation\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = torch.clamp(dilation * t, min=domain[0], max=domain[1])\n    w_dilated = w / dilation\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = t * dilation\n    t_dilated = torch.clip(t_dilated, *domain)\n    w_dilated = w / dilation\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    t_dilated = t.clone()\n    w_dilated = w.clone()\n\n    # Dilate the time steps\n    t_dilated[..., 1:] = t[..., 1:] * dilation\n    t_dilated[..., :-1] = t[..., :-1] * dilation\n\n    # Clip the dilated time steps within the domain\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_dilated = w_dilated * (t_dilated[..., 1:] - t_dilated[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = dilation * t\n    t_dilated = torch.clamp(t_dilated, *domain)\n    w_dilated = w / dilation\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = torch.cat([torch.as_tensor(domain[0]).to(t, non_blocking=True),\n                           torch.max_pool1d(t, dilation, dilation, return_indices=True)[1].reshape(-1),\n                           torch.as_tensor(domain[1]).to(t, non_blocking=True)], dim=-1)\n    w_dilated = torch.cat([torch.zeros_like(t_dilated[..., :1]),\n                           torch.max_pool1d(w, dilation, dilation),\n                           torch.zeros_like(t_dilated[..., -1:])], dim=-1)\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # t, w = matchup_channels(t, w)\n\n    # Compute the dilated time steps.\n    t_dilated = t[..., 0] * dilation\n\n    # Clip the dilated time steps to the specified domain.\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Compute the adjusted weights.\n    w_dilated = w * (t_dilated - t[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the dilated time steps and weights.\n    t_dilated = t[..., :-1] + dilation * (t[..., 1:] - t[..., :-1])\n    w_dilated = w * (t[..., 1:] - t[..., :-1]) / dilation\n    # Clip the dilated time steps to the specified domain.\n    t_dilated = torch.where(t_dilated < domain[0], torch.full_like(t_dilated, domain[0]), t_dilated)\n    t_dilated = torch.where(t_dilated > domain[1], torch.full_like(t_dilated, domain[1]), t_dilated)\n    # Adjust the weights to match the clipped dilated time steps.\n    w_dilated = w_dilated * (t_dilated[..., 1:] - t_dilated[..., :-1]) / (t[..., 1:] - t[..., :-1])\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Calculate the dilated time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps to the specified domain\n    clipped_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Calculate the adjusted weights\n    adjusted_w = w * (clipped_t - t) / (dilated_t - t)\n\n    return clipped_t, adjusted_w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilated time steps\n    t_dilated = t * dilation\n    # Clip the dilated time steps within the specified domain\n    t_dilated = t_dilated.clip(*domain)\n    # Compute the adjusted weights based on the dilated time steps\n    w_dilated = w / dilation\n    # Return the dilated and clipped time steps and the adjusted weights\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    dilation = torch.as_tensor(dilation, dtype=t.dtype, device=t.device)\n    domain = torch.as_tensor(domain, dtype=t.dtype, device=t.device)\n\n    # Dilate time steps\n    t_dilated = dilation * t\n\n    # Clip dilated time steps to the specified domain\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n\n    # Adjust weights based on the dilated time steps\n    w_dilated = w / dilation\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Dilate the time steps\n    t_dilated = t * dilation\n\n    # Clip the dilated time steps to the specified domain\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    w_adjusted = w * dilation\n\n    return t_dilated, w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_min, t_max = domain\n    t_dilated = torch.cat([t[..., 0:1], (t[..., :-1] + t[..., 1:]) / 2], dim=-1)\n    t_dilated = (t_dilated * dilation).clip(t_min, t_max)\n    w_dilated = (w * (t[..., 1:] - t[..., :-1])).repeat_interleave(2, dim=-1)\n    w_dilated = w_dilated / (t_dilated[..., 1:] - t_dilated[..., :-1])\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Dilate the time steps.\n    t_dilated = t.unsqueeze(-2) * dilation\n    t_dilated = torch.clamp(t_dilated, *domain)\n\n    # Adjust the weights to match the dilated time steps.\n    w_dilated = torch.max_pool1d(w.unsqueeze(-2), kernel_size=2, stride=2, padding=0).squeeze(-2)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # dilate time steps\n    t_dilated = t[..., 0] * dilation\n    # clip dilated time steps\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n    # adjust weights based on dilated time steps\n    w_dilated = w * dilation\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    d = torch.arange(0, t.shape[-1], device=t.device, dtype=t.dtype)\n    t_dilated = (t[..., None] + dilation * d[None, :]).clip(*domain)\n    w_dilated = (w * dilation).reshape(-1, w.shape[-1])\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = t[..., 0] * dilation  # dilate the time steps\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])  # clip the dilated time steps to the domain\n    w_dilated = w * (t_dilated[None] - t[..., :-1])  # adjust the weights to match the dilated time steps\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Check if the domain is valid\n    if domain[0] >= domain[1]:\n        raise ValueError(f\"Invalid domain: {domain}. The minimum value must be less than the maximum value.\")\n\n    # Check if the dilation parameter is valid\n    if dilation <= 0:\n        raise ValueError(f\"Invalid dilation parameter: {dilation}. The dilation parameter must be greater than zero.\")\n\n    # Check if the input tensors have the same shape\n    if t.shape != w.shape:\n        raise ValueError(f\"Incompatible shapes: {t.shape} and {w.shape}. The input tensors must have the same shape.\")\n\n    # Check if the input tensors are non-negative\n    if (t < 0).any() or (w < 0).any():\n        raise ValueError(f\"Negative values found: {t} and {w}. The input tensors must be non-negative.\")\n\n    # Check if the input tensors are sorted\n    if not torch.all(torch.diff(t) >= 0):\n        raise ValueError(f\"Unsorted input: {t}. The input tensors must be sorted.\")\n\n    # Dilate the time steps\n    dilated_t = dilation * t\n\n    # Clip the dilated time steps to the specified domain\n    clipped_t = torch.clamp(dilated_t, domain[0], domain[1])\n\n    # Calculate the weights for the dilated time steps\n    clipped_w = w * (clipped_t - dilated_t) / (t[..., 1:] - t[..., :-1])\n\n    # Return the dilated and clipped time steps and the adjusted weights\n    return clipped_t, clipped_w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = dilation * t\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n    t_dilated = torch.unique(t_dilated, sorted=True)\n    w_dilated = interpolate(t_dilated, t, w)\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Reshape tensors to match the desired output shape\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # Calculate the dilated time steps\n    dilated_t = t[..., :-1] + dilation * (t[..., 1:] - t[..., :-1])\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clip(dilated_t, domain[0], domain[1])\n\n    # Calculate the adjusted weights\n    adjusted_w = w * (dilated_t - t[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n    # Reshape tensors back to the original shape\n    dilated_t = dilated_t.reshape(t.shape)\n    adjusted_w = adjusted_w.reshape(w.shape)\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that tq and t have the same number of dimensions\n    if tq.ndim != t.ndim:\n        raise ValueError(\"tq and t must have the same number of dimensions.\")\n\n    # Ensure that tq and t have the same shape\n    if tq.shape != t.shape:\n        raise ValueError(\"tq and t must have the same shape.\")\n\n    # Ensure that tq and t have the same device\n    if tq.device != t.device:\n        raise ValueError(\"tq and t must have the same device.\")\n\n    # Ensure that tq and t have the same dtype\n    if tq.dtype != t.dtype:\n        raise ValueError(\"tq and t must have the same dtype.\")\n\n    # Ensure that tq and t have the same layout\n    if tq.layout != t.layout:\n        raise ValueError(\"tq and t must have the same layout.\")\n\n    # Ensure that tq and t have the same requires_grad\n    if tq.requires_grad != t.requires_grad:\n        raise ValueError(\"tq and t must have the same requires_grad.\")\n\n    # Ensure that tq and t have the same pin_memory\n    if tq.pin_memory != t.pin_memory:\n        raise ValueError(\"tq and t must have the same pin_memory.\")\n\n    # Ensure that tq and t have the same memory_format\n    if tq.memory_format != t.memory_format:\n        raise ValueError(\"tq and t must have the same memory_format.\")\n\n    # Ensure that tq and t have the same is_shared\n    if tq.is_shared != t.is_shared:\n        raise ValueError(\"tq and t must have the same is_shared.\")\n\n    # Ensure that tq and t have the same is_contiguous\n    if tq.is_contiguous != t.is_contiguous:\n        raise ValueError(\"tq and t must have the same is_contiguous.\")\n\n    # Ensure that tq and t have the same is_leaf\n    if tq.is_leaf != t.is_leaf:\n        raise ValueError(\"tq and t must have the same is_leaf.\")\n\n    # Ensure that tq and t have the same is_quantized\n    if tq.is_quantized != t.is_quantized:\n        raise ValueError(\"tq and t must have the same is_quantized.\")\n\n    # Ensure that"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check if the query times are sorted\n    if not torch.all(torch.diff(tq) >= 0):\n        raise ValueError(\"The query times must be sorted in ascending order.\")\n\n    # Check if the step times are sorted\n    if not torch.all(torch.diff(t) >= 0):\n        raise ValueError(\"The step times must be sorted in ascending order.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != t.shape:\n        raise ValueError(\"The step times and query times must have the same shape.\")\n\n    # Check if the step values and query values have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step values and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times have the same shape\n    if tq.shape != y.shape:\n        raise ValueError(\"The step times and query values must have the same shape.\")\n\n    # Check if the step times and query times"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If the query times are outside the range of the step function, return the outside value.\n    if torch.any(tq < t[0]) or torch.any(tq > t[-1]):\n        return outside_value\n\n    # Find the indices of the step function values that correspond to the query times.\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # If the query times exactly match a step change time, return the outside value.\n    if torch.any(tq == t[idx]):\n        return outside_value\n\n    # Interpolate the values of the step function at the query times.\n    y_interp = (y[idx + 1] - y[idx]) / (t[idx + 1] - t[idx]) * (tq - t[idx]) + y[idx]\n\n    return y_interp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted\n    tq = torch.sort(tq)[0]\n    # Find the indices of the query times that are less than or equal to the step function times\n    indices = torch.searchsorted(t, tq)\n    # If a query time matches a step change time, return the outside value\n    matches = torch.eq(tq, t[indices])\n    result = torch.where(matches, outside_value, y[indices])\n    return result\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If tq is a scalar, convert it to a 1D tensor\n    if tq.ndim == 0:\n        tq = tq[None]\n\n    # If t and y are 1D tensors, convert them to 2D tensors with a single row\n    if t.ndim == 1:\n        t = t[None, :]\n    if y.ndim == 1:\n        y = y[None, :]\n\n    # If tq and t are 1D tensors, convert them to 2D tensors with a single row\n    if tq.ndim == 1:\n        tq = tq[None, :]\n    if t.ndim == 1:\n        t = t[None, :]\n\n    # Check if tq and t have the same shape\n    if tq.shape != t.shape:\n        raise ValueError(\"tq and t must have the same shape.\")\n\n    # Check if tq and t have the same number of dimensions\n    if tq.ndim != t.ndim:\n        raise ValueError(\"tq and t must have the same number of dimensions.\")\n\n    # Check if tq and t have the same number of rows\n    if tq.shape[0] != t.shape[0]:\n        raise ValueError(\"tq and t must have the same number of rows.\")\n\n    # Check if tq and t have the same number of columns\n    if tq.shape[1] != t.shape[1]:\n        raise ValueError(\"tq and t must have the same number of columns.\")\n\n    # Check if y has the same shape as t\n    if y.shape != t.shape:\n        raise ValueError(\"y must have the same shape as t.\")\n\n    # Check if y has the same number of dimensions as t\n    if y.ndim != t.ndim:\n        raise ValueError(\"y must have the same number of dimensions as t.\")\n\n    # Check if y has the same number of rows as t\n    if y.shape[0] != t.shape[0]:\n        raise ValueError(\"y must have the same number of rows as t.\")\n\n    # Check if y has the same number of columns as t\n    if y.shape[1] != t.shape[1]:\n        raise ValueError(\"y must have the same number of columns as t.\")\n\n    # Find the indices of the query times that are less than or equal to the step change times\n    less"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted in ascending order.\n    tq = torch.sort(tq, dim=-1)[0]\n\n    # Find the indices of the query times that are less than or equal to the step change times.\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # If a query time matches a step change time, return the outside value.\n    mask = (tq == t[..., idx])\n    y_out = torch.where(mask, outside_value, y[..., idx])\n\n    # For query times that are not equal to a step change time, interpolate the values.\n    mask = ~mask\n    y_out = torch.where(mask, torch.lerp(y[..., idx], y[..., idx + 1], (tq - t[..., idx]) / (t[..., idx + 1] - t[..., idx])), y_out)\n\n    return y_out\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq = tq.reshape(-1)\n    t = t.reshape(-1)\n    y = y.reshape(-1)\n\n    # Find the index of the time in t that is just before each query time in tq\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # If the query time exactly matches a step change time, return the outside value\n    mask = tq == t[idx]\n    y_out = torch.where(mask, outside_value, y[idx])\n\n    # If the query time is between two step change times, interpolate the value\n    mask = ~mask\n    t_before = t[idx[mask]]\n    t_after = t[idx[mask] + 1]\n    y_before = y[idx[mask]]\n    y_after = y[idx[mask] + 1]\n    tq_interp = tq[mask]\n    y_interp = y_before + (tq_interp - t_before) * (y_after - y_before) / (t_after - t_before)\n    y_out = torch.where(mask, y_interp, y_out)\n\n    return y_out.reshape(tq.shape)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the index of the step function value that is immediately before each query time.\n    idx = torch.searchsorted(t, tq) - 1\n\n    # If the query time exactly matches a step change time, return the outside value.\n    idx = torch.where(tq == t[..., idx], -1, idx)\n\n    # Interpolate the step function value at the query time.\n    y_interp = (y[..., idx + 1] - y[..., idx]) * (tq - t[..., idx]) / (t[..., idx + 1] - t[..., idx]) + y[..., idx]\n\n    # Return the interpolated or outside values.\n    return torch.where(idx < 0, outside_value, y_interp)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted\n    tq, _ = torch.sort(tq)\n\n    # Find the indices of the query times that are less than or equal to the step change times\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # Find the indices of the query times that are equal to the step change times\n    idx_equal = torch.where(tq == t)[0]\n\n    # Set the values of the query times that are equal to the step change times to the outside value\n    y[idx_equal] = outside_value\n\n    # Interpolate the values of the query times that are not equal to the step change times\n    y_interp = y[idx] + (tq - t[idx]) * (y[idx + 1] - y[idx]) / (t[idx + 1] - t[idx])\n\n    # Set the values of the query times that are equal to the step change times to the outside value\n    y_interp[idx_equal] = outside_value\n\n    return y_interp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted\n    tq = torch.sort(tq)[0]\n\n    # Find the indices of the query times that are greater than or equal to the step change times\n    indices = torch.searchsorted(t, tq)\n\n    # Determine which query times exactly match a step change time\n    matches = tq == t[indices - 1]\n\n    # For query times that exactly match a step change time, return the outside value\n    values = torch.where(matches, torch.full_like(tq, outside_value), y[indices - 1])\n\n    # For query times that do not exactly match a step change time, interpolate the value using the step function\n    values = torch.where(~matches, (tq - t[indices - 1]) * (y[indices] - y[indices - 1]) / (t[indices] - t[indices - 1]) + y[indices - 1], values)\n\n    return values\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check input dimensions\n    if tq.ndim != 1:\n        raise ValueError(\"tq must be a 1-dimensional tensor.\")\n    if t.ndim != 1:\n        raise ValueError(\"t must be a 1-dimensional tensor.\")\n    if y.ndim != 1:\n        raise ValueError(\"y must be a 1-dimensional tensor.\")\n    if t.shape != y.shape:\n        raise ValueError(\"t and y must have the same shape.\")\n\n    # Find the index of the step change immediately preceding each query time\n    indices = torch.searchsorted(t, tq, side='right') - 1\n\n    # Check if any query times exactly match a step change time\n    exact_matches = torch.where(tq == t[indices])[0]\n\n    # Set the values of the step function at the exact matches to the outside value\n    y[exact_matches] = outside_value\n\n    # Interpolate the values of the step function at the remaining query times\n    interpolated_values = y[indices] + (tq - t[indices]) * (y[indices + 1] - y[indices]) / (t[indices + 1] - t[indices] + 1e-8)\n\n    return interpolated_values\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check that tq is a 1D tensor\n    if tq.ndim != 1:\n        raise ValueError(\"The query times 'tq' must be a 1D tensor.\")\n\n    # Check that t and y have the same number of elements\n    if t.shape != y.shape:\n        raise ValueError(\"The tensors 't' and 'y' must have the same number of elements.\")\n\n    # Check that tq is within the range of t\n    if not (torch.all(tq >= t[0]) and torch.all(tq <= t[-1])):\n        raise ValueError(\"All query times must be within the range of the step function times.\")\n\n    # Find the index of the step function time that is closest to each query time\n    indices = torch.searchsorted(t, tq)\n\n    # Check if any query times match a step function time exactly\n    matches = (tq == t[indices])\n\n    # If a query time matches a step function time exactly, return the outside value\n    if torch.any(matches):\n        y[indices[matches]] = outside_value\n\n    # If a query time does not match a step function time exactly, interpolate the value\n    if not torch.all(matches):\n        # Find the indices of the step function times that are closest to each query time\n        indices = torch.searchsorted(t, tq)\n\n        # Check if any query times match a step function time exactly\n        matches = (tq == t[indices])\n\n        # If a query time matches a step function time exactly, return the outside value\n        if torch.any(matches):\n            y[indices[matches]] = outside_value\n\n        # If a query time does not match a step function time exactly, interpolate the value\n        if not torch.all(matches):\n            # Find the indices of the step function times that are closest to each query time\n            indices = torch.searchsorted(t, tq)\n\n            # Find the indices of the step function times that are closest to each query time\n            indices = torch.searchsorted(t, tq)\n\n            # Find the indices of the step function times that are closest to each query time\n            indices = torch.searchsorted(t, tq)\n\n            # Find the indices of the step function times that are closest to each query time\n            indices = torch.searchsorted(t, tq)\n\n            # Find the indices of the step"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the index of the last time in 't' that is less than or equal to each query time in 'tq'.\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # If a query time matches a step change, return the outside value.\n    matches = tq == t[idx]\n    result = torch.where(matches, outside_value, torch.zeros_like(tq))\n\n    # For the remaining query times, interpolate the value based on the step function.\n    remaining = ~matches\n    t_diff = t[idx + 1][remaining] - t[idx][remaining]\n    y_diff = y[idx + 1][remaining] - y[idx][remaining]\n    result[remaining] = y[idx][remaining] + (tq[remaining] - t[idx][remaining]) * y_diff / t_diff\n\n    return result\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check the shapes of the input tensors\n    assert tq.ndim == 1, \"tq must be a 1-dimensional tensor\"\n    assert t.ndim == 1, \"t must be a 1-dimensional tensor\"\n    assert y.ndim == 1, \"y must be a 1-dimensional tensor\"\n    assert tq.shape[0] == t.shape[0] - 1, \"tq and t must have the same length minus 1\"\n    assert y.shape[0] == t.shape[0], \"y and t must have the same length\"\n\n    # Find the indices of the query times that match a step change\n    match_indices = torch.where(torch.isclose(tq, t))[0]\n\n    # Find the indices of the query times that do not match a step change\n    nonmatch_indices = torch.where(~torch.isclose(tq, t))[0]\n\n    # Initialize the output tensor\n    output = torch.zeros_like(tq)\n\n    # Set the values of the output tensor at the indices that match a step change\n    output[match_indices] = outside_value\n\n    # Set the values of the output tensor at the indices that do not match a step change\n    output[nonmatch_indices] = y[nonmatch_indices] + (tq[nonmatch_indices] - t[nonmatch_indices]) * (y[nonmatch_indices + 1] - y[nonmatch_indices]) / (t[nonmatch_indices + 1] - t[nonmatch_indices])\n\n    return output\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Reshape the input tensors to ensure they have the same number of dimensions\n    tq = tq.reshape([-1] + [1] * (y.ndim - 1))\n    t = t.reshape([-1] + [1] * (y.ndim - 1))\n    y = y.reshape([-1] + [1] * (y.ndim - 1))\n\n    # Find the indices of the nearest time values to the query times\n    indices = torch.searchsorted(t, tq, right=True)\n\n    # Create a mask to identify the query times that exactly match a step change time\n    mask = torch.logical_and(indices > 0, indices < t.shape[-1])\n\n    # Compute the interpolated values for the query times that do not exactly match a step change time\n    values = torch.where(mask, (tq - t[..., :-1])[..., indices - 1] * y[..., indices - 1] + (t[..., 1:] - tq)[..., indices - 1] * y[..., indices], outside_value)\n\n    # Reshape the output tensor to match the shape of the input tensors\n    values = values.reshape(tq.shape)\n\n    return values\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Convert the tensors to the correct device and data type\n    tq = tq.to(t.device, t.dtype)\n    t = t.to(t.device, t.dtype)\n    y = y.to(t.device, t.dtype)\n\n    # Check if the query times are outside the range of the step function\n    outside_range = (tq < t[0]) | (tq > t[-1])\n\n    # If the query times are outside the range, return the outside value\n    if outside_range.any():\n        return outside_value * torch.ones_like(tq)\n\n    # Find the indices of the query times that are inside the range of the step function\n    inside_range = ~outside_range\n    indices = torch.searchsorted(t, tq[inside_range], side='right') - 1\n\n    # Interpolate the values of the step function at the query times\n    y_interp = y[indices] + (tq[inside_range] - t[indices]) / (t[indices + 1] - t[indices]) * (y[indices + 1] - y[indices])\n\n    # Combine the interpolated and outside values into a single tensor\n    y_query = torch.zeros_like(tq)\n    y_query[inside_range] = y_interp\n    y_query[outside_range] = outside_value\n\n    return y_query\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted\n    tq = torch.sort(tq)[0]\n\n    # Find the index of the first time in 't' that is greater than or equal to each query time\n    indices = torch.searchsorted(t, tq)\n\n    # If a query time matches a step change time, return the outside value\n    matches = t[indices - 1] == tq\n    values = torch.where(matches, outside_value, y[indices - 1])\n\n    return values\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted.\n    tq = torch.sort(tq)[0]\n\n    # Find the indices of the query times in the step function's time array.\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # If the query time matches a step change time, return the outside value.\n    matches = (idx >= 0) & (idx < t.shape[-1]) & (tq == t[..., idx])\n    values = outside_value * matches\n\n    # If the query time does not match a step change time, interpolate the value.\n    not_matches = ~matches\n    values += torch.where(not_matches,\n                          (tq[..., None] - t[..., idx + 1]) * (y[..., idx] - y[..., idx + 1]) / (t[..., idx] - t[..., idx + 1]),\n                          0)\n\n    return values\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Convert the tensors to numpy arrays for indexing\n    tq = tq.cpu().numpy()\n    t = t.cpu().numpy()\n    y = y.cpu().numpy()\n\n    # Initialize an empty array to store the interpolated values\n    yq = np.zeros_like(tq)\n\n    # Find the index of the last step change time that is less than or equal to each query time\n    idx = np.searchsorted(t, tq, side='right') - 1\n\n    # For each query time, check if it exactly matches a step change time\n    match = (tq == t[idx])\n\n    # If it does, set the corresponding interpolated value to the outside value\n    yq[match] = outside_value\n\n    # For the remaining query times, interpolate the value based on the step function\n    yq[~match] = y[idx[~match]] + (yq[~match] - t[idx[~match]]) * (y[idx[~match] + 1] - y[idx[~match]]) / (t[idx[~match] + 1] - t[idx[~match]])\n\n    return torch.from_numpy(yq)"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that tq and t are broadcastable to the same shape\n    tq, t = torch.broadcast_tensors(tq, t)\n\n    # Find the index of the time in 't' that is just before each query time in 'tq'\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # Handle the case where the query time matches a step change time\n    matches = (idx >= 0) & (idx < t.shape[-1]) & (tq == t[..., idx])\n    outside_values = torch.where(matches, outside_value, 0)\n\n    # Interpolate the values at the query times that don't match a step change time\n    mask = ~matches\n    interpolated_values = torch.interp(tq[mask], t[..., idx[mask]], y[..., idx[mask] + 1])\n\n    # Combine the outside and interpolated values\n    values = torch.where(mask, interpolated_values, outside_values)\n\n    return values"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    w_anneal = w * (1 - torch.exp(-anneal_slope * (1 - train_frac)))\n    w_anneal = w_anneal / (t[..., 1:] - t[..., :-1]).clip(eps)\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the annealing bias.\n    anneal_bias = 1.0 - train_frac\n    # Compute the annealing factor.\n    anneal_factor = torch.exp(-anneal_slope * anneal_bias)\n    # Apply the annealing factor to the weights.\n    w_anneal = w * anneal_factor\n    # Compute the annealed weights.\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return t, w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the annealing function.\n    anneal = 1.0 / (1.0 + torch.exp(-anneal_slope * (train_frac - t[..., 1:])))\n\n    # Adjust the weights.\n    w_anneal = w * anneal\n\n    # Renormalize the weights.\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t = t[..., :-1]\n    w = w / w.sum(dim=-1, keepdim=True).clip(eps)\n\n    # Compute the annealed weights.\n    w_anneal = w * (1 - train_frac) ** anneal_slope\n    w_anneal = w_anneal / w_anneal.sum(dim=-1, keepdim=True).clip(eps)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_anneal = integrate_weights(w_anneal)\n\n    # Compute the annealed CDF.\n    cw_"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the annealing factor.\n    anneal_factor = 1.0 - torch.exp(-anneal_slope * train_frac)\n    # Compute the annealed weights.\n    w_annealed = w * anneal_factor\n    # Compute the annealing bias.\n    anneal_bias = torch.log(anneal_factor + eps)\n    # Adjust the weights to account for the annealing bias.\n    w_adjusted = w_annealed + anneal_bias\n    # Renormalize the weights to ensure stability.\n    w_adjusted /= torch.sum(w_adjusted, dim=-1, keepdim=True).clip(eps)\n    return t, w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_mid = 0.5 * (t[..., 1:] + t[..., :-1])\n    w_mid = 0.5 * (w[..., 1:] + w[..., :-1])\n    w_mid = w_mid.clip(eps)\n    w_mid_anneal = w_mid * (1 - torch.sigmoid(anneal_slope * (train_frac - t_mid)))\n    w_mid_anneal = w_mid_anneal / torch.sum(w_mid_anneal, dim=-1, keepdim=True).clip(eps)\n    w_anneal = torch.cat([w[..., :1], w_mid_anneal, w[..., -1:]], dim=-1)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the annealed weights.\n    # Compute the annealed weights.\n    w_anneal = torch.where(\n        (t[..., 1:] - t[..., :-1]) < eps,\n        w[..., :-1],\n        w[..., :-1] * (1 - train_frac) + w[..., 1:] * train_frac,\n    )\n    # Compute the annealed weights.\n    w_anneal = w_anneal * torch.exp(-anneal_slope * train_frac * (1 - train_frac))\n    # Compute the annealed weights.\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    w_new = w * (1 - train_frac) ** anneal_slope\n    w_new = w_new / torch.sum(w_new, dim=-1, keepdim=True).clip(eps)\n    return w_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Adjust the weights based on the training fraction and anneal slope using Schlick's bias function.\n    # The bias function is a smooth approximation to the step function, which is useful for annealing.\n    # It ensures stability in the computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights.\n    # This function is used to adjust the weights of a tensor based on the progression of training, making the weight adjustment more dynamic as training progresses.\n    # Input-Output Arguments\n    # t: torch.Tensor. The tensor representing time or another sequential dimension, used to align with the weights tensor.\n    # w: torch.Tensor. The weights tensor that will be adjusted based on the training fraction and anneal slope.\n    # train_frac: float. The fraction of training completed, used to calculate the annealing effect on weights.\n    # anneal_slope: float, optional. The slope of the annealing function, determining how sharply weights are adjusted. Defaults to 10.0.\n    # eps: torch.float32, optional. A very small number added to prevent division by zero and log of zero in computations. Defaults to a small epsilon value squared.\n    # Return: torch.Tensor. The adjusted weights tensor after applying the annealing process.\n\n    # Ensure that the weights are non-negative and sum to 1.\n    w = w.clip(min=0)\n    w = w / torch.sum(w, dim=-1, keepdim=True).clip(eps)\n\n    # Compute the annealed weights.\n    w_anneal = w * (1 - torch.exp(-anneal_slope * (1 - train_frac)))\n\n    # Compute the annealed weights.\n    w_anneal = w * (1 - torch.exp(-anneal_slope * (1 - train_frac)))\n\n    # Compute the annealed weights.\n    w_anneal = w * (1 - torch.exp(-anneal_slope * (1 - train_frac)))\n\n    # Compute the annealed weights.\n    w_anneal = w * (1 - torch.exp(-anneal_slope * (1 - train_frac)))\n\n    # Compute"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the annealing factor.\n    anneal_factor = torch.clip(\n        torch.where(t[..., 1:] - t[..., :-1] > eps,\n                    1 - torch.exp(-anneal_slope * (t[..., 1:] - t[..., :-1])),\n                    0),\n        0,\n        1,\n    )\n    # Compute the annealed weights.\n    w_anneal = (1 - train_frac) * w + train_frac * anneal_factor * w\n    # Compute the annealed weights, ensuring stability in the computation.\n    w_anneal = torch.where(t[..., 1:] - t[..., :-1] > eps,\n                           w_anneal,\n                           w_anneal.new_zeros(w_anneal.shape),\n                           )\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # Compute the annealing bias.\n    bias = (1 - train_frac) ** anneal_slope\n\n    # Compute the annealed weights.\n    w_anneal = w * bias\n\n    # If the annealed weight is zero, set the weight to zero and the time to\n    # infinity.\n    w_anneal = torch.where(w_anneal > 0, w_anneal, torch.zeros_like(w_anneal))\n    t_anneal = torch.where(w_anneal > 0, t, torch.inf * torch.ones_like(t))\n\n    # Renormalize the weights.\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n\n    # Reshape the tensors back to their original shape.\n    t_anneal = t_anneal.reshape(*t.shape)\n    w_anneal = w_anneal.reshape(*w.shape)\n\n    return t_anneal, w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # matchup channels\n    t, w = matchup_channels(t, w)\n\n    # compute the annealing function\n    anneal_t = t[..., :-1] + (t[..., 1:] - t[..., :-1]) * train_frac\n    anneal_t = anneal_t.clip(0, 1)\n    anneal = anneal_t * anneal_slope\n    anneal = (1 - anneal) ** 2\n\n    # apply the annealing function to the weights\n    w_anneal = w * anneal\n\n    # compute the softmax of the adjusted weights\n    w_anneal_exp = torch.exp(w_anneal)\n    w_anneal_exp_sum = torch.sum(w_anneal_exp, dim=-1, keepdim=True).clip(eps)\n    w_anneal_exp_sum = w_anneal_exp_sum.expand_as(w_anneal_exp)\n    w_anneal_softmax = w_anneal_exp / w_anneal_exp_sum\n\n    # handle cases where adjacent intervals have zero distance\n    w_anneal_softmax = torch.where(w_anneal_softmax > 0, w_anneal_softmax, 0)\n\n    return w_anneal_softmax\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_mid = (t[..., 1:] + t[..., :-1]) / 2\n    t_mid_train = t_mid - t_mid[..., 0:1]\n    # The bias function\n    bias = torch.where(t_mid_train < 0, 0, torch.where(t_mid_train > 1, 1, 1 - t_mid_train))\n    # The annealing function\n    anneal = 1 / (1 + torch.exp(-anneal_slope * (bias - train_frac)))\n    # The adjusted weights\n    w_anneal = w * anneal\n    # Stability in the computation\n    w_anneal = torch.where(t[..., 1:] - t[..., :-1] < eps, 0, w_anneal)\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the annealing factor.\n    t_mid = 0.5 * (t[..., :-1] + t[..., 1:])\n    t_mid = torch.where(t_mid == 0, torch.tensor(1e-8, device=t.device), t_mid)\n    t_mid = t_mid.clip(eps)\n    t_mid = torch.log(t_mid)\n    t_mid = (t_mid - t_mid[..., -1:]) * anneal_slope\n    t_mid = torch.sigmoid(t_mid)\n    # Compute the annealed weights.\n    w_anneal = w * t_mid[..., None]\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # compute annealed weights\n    t_mid = (t[..., 1:] + t[..., :-1]) / 2\n    t_mid_shifted = t_mid - t_mid[..., 0:1]\n    t_mid_shifted = torch.where(t_mid_shifted < 0, t_mid_shifted + 1, t_mid_shifted)\n    w_anneal = w * torch.exp(-anneal_slope * (1 - train_frac) * t_mid_shifted)\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps)\n    return w_anneal\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the annealing factor based on the training fraction and anneal slope.\n    anneal_factor = torch.where(\n        train_frac < 1.0,\n        torch.pow(train_frac, anneal_slope),\n        torch.ones_like(train_frac),\n    )\n\n    # Compute the adjusted weights by multiplying the weights by the annealing factor.\n    w_anneal = w * anneal_factor[..., None]\n\n    # Compute the cumulative sum of the adjusted weights along the last dimension.\n    cw = torch.cumsum(w_anneal, dim=-1)\n\n    # Compute the difference between the cumulative sum and the annealing factor.\n    diff = cw - anneal_factor[..., None]\n\n    # Compute the absolute value of the difference.\n    abs_diff = torch.abs(diff)\n\n    # Find the indices where the absolute value of the difference is less than or equal to 1e-6.\n    idx = torch.where(abs_diff <= 1e-6)\n\n    # Set the weights at those indices to zero.\n    w_anneal[idx] = 0.0\n\n    # Compute the softmax of the adjusted weights along the last dimension.\n    w_anneal = torch.softmax(w_anneal, dim=-1)\n\n    # Handle cases where adjacent intervals have zero distance.\n    idx = torch.where(t[..., 1:] - t[..., :-1] == 0)\n    w_anneal[idx] = 0.0\n\n    # Handle cases where the sum of weights is zero.\n    idx = torch.where(torch.sum(w_anneal, dim=-1) == 0)\n    w_anneal[idx] = 1.0\n\n    # Handle cases where the sum of weights is close to zero.\n    idx = torch.where(torch.sum(w_anneal, dim=-1) < eps)\n    w_anneal[idx] = 1.0\n\n    # Normalize the weights so that they sum to 1.\n    w_anneal = w_anneal / torch.sum(w_anneal, dim=-1, keepdim=True).clip(eps"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # Compute the annealing bias.\n    anneal_bias = 1 - torch.exp(-anneal_slope * train_frac)\n\n    # Compute the distance between adjacent intervals.\n    t_dist = t[..., 1:] - t[..., :-1]\n\n    # Compute the annealed weights.\n    w_annealed = w * anneal_bias + torch.where(t_dist > eps, w, 0)\n    w_annealed /= torch.sum(w_annealed, dim=-1, keepdim=True).clip(eps)\n    return w_annealed\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # t.shape[-1] = w.shape[-1] + 1\n    # w.shape[-1] = t.shape[-1] - 1\n\n    # compute the bias\n    bias = (1 - train_frac) ** anneal_slope\n\n    # compute the weight adjustment\n    w_adj = w * bias\n\n    # compute the distance between adjacent intervals\n    t_dist = t[..., 1:] - t[..., :-1]\n\n    # handle cases where adjacent intervals have zero distance\n    w_adj[..., t_dist < eps] = 0.0\n\n    # compute the sum of adjusted weights\n    w_sum = torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)\n\n    # compute the normalized adjusted weights\n    w_norm = w_adj / w_sum\n\n    return w_norm"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the annealing factor.\n    anneal_factor = (train_frac / (1 - train_frac)).clip(0, 1)\n    # Compute the annealed weights.\n    w_anneal = w * (1 - anneal_factor) ** (anneal_slope * (t[..., 1:] - t[..., :-1]))\n    # Handle cases where adjacent intervals have zero distance.\n    w_anneal = torch.where(\n        (t[..., 1:] - t[..., :-1]) < eps,\n        w_anneal.new_zeros(w_anneal.shape),\n        w_anneal,\n    )\n    # Prevent NaNs by using a softmax operation.\n    w_anneal = torch.softmax(w_anneal, dim=-1)\n    return w_anneal"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # make sure t and w have same number of dimensions\n    if t.ndim == w.ndim + 1:\n        t = t[..., 0]  # remove last dim\n\n    # make sure t and w have same shape\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # compute the difference between adjacent intervals\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # compute the annealing factor\n    anneal_factor = 1 - torch.exp(-anneal_slope * train_frac)\n\n    # compute the adjusted weights\n    w_adj = w * anneal_factor * (1 - t_diff / (t_diff + eps))\n\n    # handle cases where adjacent intervals have zero distance\n    w_adj = torch.where(t_diff < eps, torch.zeros_like(w_adj), w_adj)\n\n    # compute the softmax of the adjusted weights\n    w_adj_softmax = w_adj / (torch.sum(w_adj, dim=-1, keepdim=True) + eps)\n\n    return w_adj_softmax"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"})\n        else:\n            return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items()})\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if not (ignore_list and k == \"meta\")})\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if batch.device == device:\n            return batch\n        else:\n            return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return type(batch)(to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\")\n        else:\n            return type(batch)(to_cuda(v, device, ignore_list) for k, v in batch.items())\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if batch.device.type == device:\n            return batch\n        else:\n            return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\" or not ignore_list})\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if batch.device == device: return batch\n        else: return batch.to(device)\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, list):\n        return list(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor): return batch.to(device)\n    elif isinstance(batch, tuple): return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, list): return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else: return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    elif isinstance(batch, (tuple, list)):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(v, device, ignore_list) for v in batch)\n\n    elif isinstance(batch, dict):\n        return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\" or not ignore_list})\n\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n\n    elif isinstance(batch, dict):\n        return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if not (ignore_list and k == \"meta\")})\n\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if ignore_list:\n            return batch.to(device)\n        else:\n            return batch.cuda(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    if isinstance(batch, (tuple, list)):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    if isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(v, device, ignore_list) for v in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: v for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if batch.device != device:\n            return batch.to(device)\n        else:\n            return batch\n    elif isinstance(batch, dict):\n        if ignore_list and \"meta\" in batch:\n            return batch\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(v, device, ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor): return batch.to(device)\n    if isinstance(batch, (tuple, list)): return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    if isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, np.ndarray):\n        return torch.from_numpy(batch).to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return type(batch)({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\" or not ignore_list})\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if batch.device.type == device: return batch\n        else: return batch.to(device)\n\n    if isinstance(batch, (tuple, list)):\n        batch = [to_cuda(b, device, ignore_list) for b in batch]\n        return torch.stack(batch)\n\n    if isinstance(batch, dict):\n        if ignore_list:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n        else:\n            batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n        return batch\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor): return batch.to(device)\n\n    if isinstance(batch, (tuple, list)):\n        if ignore_list: return tuple(to_cuda(b, device, ignore_list) for b in batch)\n        else: return tuple(to_cuda(b, device) for b in batch)\n\n    if isinstance(batch, dict):\n        if ignore_list: return dotdict({k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"})\n        else: return dotdict({k: to_cuda(v, device) for k, v in batch.items() if k != \"meta\"})\n\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)(to_cuda(v, device, ignore_list) for v in batch)\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: v for k, v in batch.items() if k != \"meta\"}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if f.shape[0] != v.shape[0]:\n        f = f.repeat(v.shape[0], 1, 1)\n\n    # Gather the triangles from the vertices tensor\n    triangles = multi_gather(v, f, dim)\n\n    # Reshape the triangles tensor to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    triangles = triangles.reshape(v.shape[0], -1, 3, 3)\n\n    return triangles\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Gather the value at the -2th dim of values, augment index shape on the back\n    # Example: values: B, P, 3, index: B, N, -> B, N, 3\n\n    # index will first be augmented to match the values' dimentionality at the back\n    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(-1).expand(*v.shape[:-1], *f.shape[-1:])\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust faces shape to match batch dimension of vertices\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(-1).expand(-1, -1, v.shape[dim])\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    if f.ndim < v.ndim:\n        f = f.unsqueeze(-1).expand(-1, -1, v.shape[dim])\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # gather triangles from vertices and faces\n    # v: B, N, 3\n    # f: B, M, 3\n    # return: B, M, 3, 3\n    # if v.shape[0] != f.shape[0]: f = f.expand(v.shape[0], *f.shape[1:])\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim: f = f.unsqueeze(dim)\n\n    # gather the triangles from the vertices tensor\n    triangles = multi_gather(v, f, dim)\n\n    # compute the normals of the triangles\n    normals = (triangles[:, 1] - triangles[:, 0]).cross(triangles[:, 2] - triangles[:, 0])\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return normals.reshape(f.shape[:-1] + normals.shape[-1:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # index will first be augmented to match the values' dimentionality at the back\n    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    return multi_gather(v, f, dim).reshape(*f.shape, *v.shape[dim + 1:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(-1).expand(*v.shape[:f.ndim], *f.shape[1:])\n\n    # Gather the triangles from the vertices tensor\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the faces tensor to match the batch dimension of the vertices tensor\n    if v.ndim - f.ndim == 1:\n        f = f.unsqueeze(-1)\n    elif v.ndim - f.ndim == 2:\n        f = f.unsqueeze(-1).unsqueeze(-1)\n    elif v.ndim - f.ndim == 3:\n        f = f.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n\n    # gather the triangles from the vertices tensor\n    triangles = multi_gather(v, f, dim)\n\n    # reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    return triangles.reshape(v.shape[0], *f.shape[1:], 3, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # dim = -2\n    # f = f.view(f.shape[0], -1, 3)\n    # f = f.expand(-1, -1, v.shape[dim])\n    # v = v.gather(dim, f)\n    # v = v.view(v.shape[0], -1, 3, 3)\n    # v = v[:, :, 1] - v[:, :, 0]\n    # v = v.cross(v[:, :, 2] - v[:, :, 0], dim=2)\n    # v = v.norm(dim=2)\n    # return v\n\n    # dim = -2\n    # f = f.view(f.shape[0], -1, 3)\n    # f = f.expand(-1, -1, v.shape[dim])\n    # v = v.gather(dim, f)\n    # v = v.view(v.shape[0], -1, 3, 3)\n    # v = v[:, :, 1] - v[:, :, 0]\n    # v = v.cross(v[:, :, 2] - v[:, :, 0], dim=2)\n    # v = v.norm(dim=2)\n    # return v\n\n    # dim = -2\n    # f = f.view(f.shape[0], -1, 3)\n    # f = f.expand(-1, -1, v.shape[dim])\n    # v = v.gather(dim, f)\n    # v = v.view(v.shape[0], -1, 3, 3)\n    # v = v[:, :, 1] - v[:, :, 0]\n    # v = v.cross(v[:, :, 2] - v[:, :, 0], dim=2)\n    # v = v.norm(dim=2)\n    # return v\n\n    # dim = -2\n    # f = f.view(f.shape[0], -1, 3)\n    # f = f.expand(-1, -1, v.shape[dim])\n    # v = v.gather(dim, f)\n    # v = v.view(v.shape[0], -1, 3, 3)\n    # v = v[:,"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if v.ndim - 1 != f.ndim:\n        f = f.unsqueeze(dim=-2)\n    # Gather the triangles from the vertices tensor using the faces tensor\n    tris = multi_gather(v, f, dim=dim)\n    # Reshape the gathered triangles to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    return tris.reshape(tris.shape[:2] + (-1, tris.shape[-1]))\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # gather triangles from faces\n    if f.ndim == v.ndim:\n        # no need to expand\n        pass\n    elif f.ndim == v.ndim - 1:\n        # expand faces to match batch dim\n        f = f.unsqueeze(dim)\n    else:\n        raise RuntimeError(f'f.ndim {f.ndim} should be equal to v.ndim {v.ndim} or v.ndim - 1 {v.ndim - 1}')\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the dimension of faces to match the batch dimension of vertices\n    if f.shape[dim] == 1: f = f.expand(-1, v.shape[dim], -1)\n    # Gather the triangles from the vertices tensor\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim == v.ndim - 1:\n        f = f.unsqueeze(-1)\n\n    # gather the triangles from the vertices tensor using the faces tensor\n    triangles = multi_gather(v, f, dim)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return triangles.reshape(*f.shape, -1, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    if f.ndim == v.ndim - 1:\n        f = f.unsqueeze(-1)\n    # if f.ndim == v.ndim:\n    #     f = f.unsqueeze(-1)\n    return multi_gather(v, f, dim).reshape(*f.shape, -1)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the faces tensor to match the batch dimension of the vertices tensor\n    if v.shape[0] != f.shape[0]: f = f.unsqueeze(0).expand(v.shape[0], *f.shape[1:])\n\n    # gather the triangles from the vertices tensor\n    # the triangles are gathered along the last dimension (dim)\n    # the gathered triangles are reshaped to maintain the structure of the faces tensor with additional dimensions for batch processing\n    return multi_gather(v, f, dim).view(*f.shape, *v.shape[dim + 1:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the dimension of faces to match the batch dimension of vertices\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(-1).expand(-1, -1, v.shape[-1])\n    # Gather the triangles from the vertices tensor\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # gather vertices from faces\n    # v: B, N, 3, f: B, M, 3\n    # v: B, N, 3, f: B, M, 3 -> v: B, M, 3, f: B, M, 3\n    if v.ndim != f.ndim:\n        f = f.unsqueeze(-2).expand(-1, -1, v.shape[-2], -1)\n\n    # gather triangles from vertices\n    # v: B, M, 3, f: B, M, 3 -> v: B, M, 3, f: B, M, 3\n    triangles = multi_gather(v, f, dim)\n\n    # compute normals from triangles\n    # v: B, M, 3, f: B, M, 3 -> v: B, M, 3, f: B, M, 3\n    normals = triangles[:, :, 1:] - triangles[:, :, :1]\n    normals = torch.cross(normals[:, :, 0], normals[:, :, 1], dim=-1)\n    normals = normals / normals.norm(dim=-1, keepdim=True)\n\n    # reshape normals to match faces tensor\n    # v: B, M, 3, f: B, M, 3 -> v: B, M, 3, f: B, M, 3\n    normals = normals.reshape(*f.shape[:-1], -1, *f.shape[-1:])\n\n    return normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # Adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    # if necessary, and reshape the result to maintain the original faces tensor structure with\n    # additional dimensions for batch processing\n    if v.ndim == f.ndim + 1: f = f.unsqueeze(dim)\n    return multi_gather(v, f, dim)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # The following line expands the faces tensor to match the batch dimension of the vertices tensor, if necessary.\n    # This is done by adding an extra dimension at the front of the faces tensor and then repeating it along that dimension to match the batch size of the vertices tensor.\n    if f.shape[0] != v.shape[0]: f = f.unsqueeze(0).repeat(v.shape[0], 1, 1)\n\n    # The following line gathers the triangles from the vertices tensor using the faces tensor as indices, along the specified dimension.\n    # This results in a tensor containing the triangles corresponding to the faces in the faces tensor.\n    # The gather operation is performed along the specified dimension (dim), which is typically the second last dimension (-2).\n    # The resulting tensor has shape (B, F, 3, 3), where B is the batch size, F is the number of faces, and 3 is the number of vertices in each face.\n    # The gather operation selects the vertices corresponding to each face from the vertices tensor, and returns them in a tensor of shape (B, F, 3, 3).\n    # The resulting tensor has shape (B, F, 3, 3), where B is the batch size, F is the number of faces, and 3 is the number of vertices in each face.\n    tris = multi_gather(v, f, dim=dim)\n\n    # The following line reshapes the gathered triangles tensor to maintain the structure of the original faces tensor with additional dimensions for batch processing.\n    # This is done by adding an extra dimension at the front of the gathered triangles tensor, and then reshaping it to match the shape of the original faces tensor.\n    # The resulting tensor has shape (B, F, 3, 3), where B is the batch size, F is the number of faces, and 3 is the number of vertices in each face.\n    # The reshaping operation ensures that the gathered triangles tensor has the same shape as the original faces tensor, while also maintaining the batch dimension.\n    return tris.view(f.shape + tris.shape[2:])\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.unsqueeze(batch, 0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.unsqueeze(batch, 0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    else:  # others, keep as is\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        batch = torch.as_tensor(batch)[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        batch = torch.cat((batch, batch), dim=0)\n    else:  # numpy and others\n        batch = np.concatenate((batch, batch), axis=0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    else:  # others, keep as is\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    else:  # others, keep as is\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.unsqueeze(batch, 0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch)\n        batch = torch.unsqueeze(batch, 0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:  # others, keep as is\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        batch = torch.cat((batch, batch), dim=0)\n    else:\n        batch = torch.cat((torch.as_tensor(batch), torch.as_tensor(batch)), dim=0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.stack([batch])\n    else:  # numpy and others\n        batch = np.stack([batch])\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    else:  # others\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:  # others, keep as is\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.cat([batch], dim=0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.concatenate([batch], axis=0)\n    else:\n        batch = torch.as_tensor(batch)\n        batch = torch.cat([batch], dim=0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.stack([batch])\n    elif isinstance(batch, np.ndarray):\n        batch = np.stack([batch])\n    else:\n        batch = torch.as_tensor([batch])\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = torch.unsqueeze(batch, dim=0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(dim=0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:  # others, keep as is\n        batch = torch.as_tensor(batch)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        batch = torch.as_tensor(batch)\n        batch = torch.unsqueeze(batch, 0)\n    else:\n        batch = torch.as_tensor(batch)\n        batch = torch.unsqueeze(batch, 0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up, batch.drag_ymin, batch.drag_ymax, batch.min_interval, batch.pause_physics = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax, self.min_interval, self.pause_physics\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # GUI related elements\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.angular_speed, batch.angular_acc, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.angular_speed, self.angular_acc, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Camera update hyperparameters\n        batch.min_interval, batch.pause_physics = self.min_interval, self.pause_physics\n\n        # Camera update hyperparameters\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start\n\n        # Camera update hyperparameters\n        batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up = self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up\n\n        # Camera update hyperparameters\n        batch.drag_ymin, batch.drag_ymax = self.drag_ymin, self.drag_ymax\n\n       "}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Batch (network input parameters)\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Batch (network input parameters)\n        batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up, batch.drag_ymin, batch.drag_ymax = self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax\n\n        # Batch (network input parameters)\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.pause_physics, batch.min_interval = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.pause_physics, self.min_interval\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # GUI related elements\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.pause_physics, batch.min_interval = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.pause_physics, self.min_interval\n\n        # Camera parameters\n        batch.mass, batch.moment_of_inertia, batch.angular_speed, batch.angular_acc, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.mass, self.moment_of_inertia, self.angular_speed, self.angular_acc, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Camera parameters\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start\n\n        # Camera parameters\n        batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up = self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up\n\n        # Camera parameters\n        batch.drag_ymin, batch.drag_ymax = self.drag_ymin, self.drag_ymax\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch\n        batch = dotdict()\n\n        # Camera parameters\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = torch.tensor(self.K)\n        batch.R = torch.tensor(self.R)\n        batch.T = torch.tensor(self.T)\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = torch.tensor(self.bounds)\n\n        # GUI related elements\n        batch.origin = torch.tensor(self.origin)\n        batch.world_up = torch.tensor(self.world_up)\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.movement_torque = self.movement_torque\n\n        # Batch meta\n        batch.meta = dotdict()\n        batch.meta.is_dragging = self.is_dragging\n        batch.meta.about_origin = self.about_origin\n        batch.meta.is_panning = self.is_panning\n        batch.meta.lock_fx_fy = self.lock_fx_fy\n        batch.meta.drag_start = torch.tensor(self.drag_start)\n        batch.meta.drag_start_front = torch.tensor(self.drag_start_front)\n        batch.meta.drag_start_down = torch.tensor(self.drag_start_down)\n        batch.meta.drag_start_right = torch.tensor(self.drag_start_right)\n        batch.meta.drag_start_center = torch.tensor(self.drag_start_center)\n        batch.meta.drag_start_origin = torch.tensor(self.drag_start_origin)\n        batch.meta.drag_start"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n        batch.drag_ymin, batch.drag_ymax = self.drag_ymin, self.drag_ymax\n        batch.min_interval, batch.pause_physics = self.min_interval, self.pause_physics\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy\n        batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up = self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Batch (network input parameters)\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Batch (GUI related elements)\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Batch (internal states)\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up, batch.drag_ymin, batch.drag_ymax, batch.min_interval, batch.pause_physics = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax, self.min_interval, self.pause_physics\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters into a batch format using tensors, suitable for processing with PyTorch\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Convert GUI related elements into a batch format using tensors, suitable for processing with PyTorch\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.pause_physics, batch.min_interval = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.pause_physics, self.min_interval\n\n        # Convert mass related elements into a batch format using tensors, suitable for processing with PyTorch\n        batch.mass, batch.moment_of_inertia, batch.angular_speed, batch.angular_acc, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.mass, self.moment_of_inertia, self.angular_speed, self.angular_acc, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Return the batch format using tensors, suitable for processing with PyTorch\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Batch (network input parameters)\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Batch (network input parameters)\n        batch.pause_physics, batch.min_interval = self.pause_physics, self.min_interval\n\n        # Batch (network input parameters)\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up, batch.drag_ymin, batch.drag_ymax = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax\n\n        # Batch (network input parameters)\n        batch.gl_ext, batch.gl_ixt, batch.gl_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n\n        # Camera parameters\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = self.bounds\n\n        # GUI related elements\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.movement_torque = self.movement_torque\n\n        # Batch meta (network input parameters)\n        batch.meta = dotdict()\n        batch.meta.is_dragging = self.is_dragging\n        batch.meta.about_origin = self.about_origin\n        batch.meta.is_panning = self.is_panning\n        batch.meta.lock_fx_fy = self.lock_fx_fy\n        batch.meta.drag_start = self.drag_start\n        batch.meta.drag_start_front = self.drag_start_front\n        batch.meta.drag_start_down = self.drag_start_down\n        batch.meta.drag_start_right = self.drag_start_right\n        batch.meta.drag_start_center = self.drag_start_center\n        batch.meta.drag_start_origin = self.drag_start_origin\n        batch.meta.drag_start_world_up = self.drag_start_world_up\n        batch.meta.drag_ymin = self.drag_ymin\n        batch.meta.drag_ymax = self.drag_ymax\n        batch.meta.min_interval"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up, batch.drag_ymin, batch.drag_ymax = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax\n        batch.min_interval, batch.pause_physics = self.min_interval, self.pause_physics\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # GUI related elements\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Camera parameters and GUI related elements\n        batch.min_interval, batch.pause_physics, batch.lock_fx_fy = self.min_interval, self.pause_physics, self.lock_fx_fy\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n\n        # Direct mapping of camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Nested 'meta' dictionary with camera parameters\n        batch.meta = dotdict()\n        batch.meta.origin, batch.meta.world_up, batch.meta.movement_speed, batch.meta.movement_force, batch.meta.drag_coeff_mult, batch.meta.constant_drag, batch.meta.pause_physics, batch.meta.min_interval = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.pause_physics, self.min_interval\n\n        # Return the batch\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch\n        batch = dotdict()\n\n        # Camera parameters\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = torch.tensor(self.K)\n        batch.R = torch.tensor(self.R)\n        batch.T = torch.tensor(self.T)\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = torch.tensor(self.bounds)\n\n        # GUI related elements\n        batch.origin = torch.tensor(self.origin)\n        batch.world_up = torch.tensor(self.world_up)\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.movement_torque = self.movement_torque\n\n        # Meta\n        meta = dotdict()\n        meta.gl_ixt = torch.tensor(self.gl_ixt)\n        meta.gl_ext = torch.tensor(self.gl_ext)\n        meta.w2c = torch.tensor(self.w2c)\n        meta.c2w = torch.tensor(self.c2w)\n        meta.right = torch.tensor(self.right)\n        meta.down = torch.tensor(self.down)\n        meta.front = torch.tensor(self.front)\n        meta.center = torch.tensor(self.center)\n        meta.s = self.s\n        meta.fx = self.fx\n        meta.fy = self.fy\n        meta.cx = self.cx\n        meta.cy = self.cy\n        meta.is_dragging = self.is_dragging\n        meta.about_origin = self.about_origin\n        meta.is_panning = self.is_panning\n        meta.lock_fx_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters into a batch format\n        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = self.bounds\n\n        # Convert GUI related elements into a batch format\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.pause_physics = self.pause_physics\n        batch.min_interval = self.min_interval\n\n        # Convert camera parameters and GUI related elements into a structured dictionary format\n        meta = dotdict()\n        meta.H, meta.W, meta.K, meta.R, meta.T, meta.n, meta.f, meta.t, meta.v, meta.bounds = batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds\n        meta.origin, meta.world_up, meta.movement_speed, meta.movement_force, meta.drag_coeff_mult, meta.constant_drag, meta.mass, meta.moment_of_inertia, meta.movement_torque, meta.angular_friction, meta.constant_torque, meta.pause_physics, meta.min_interval = batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct a batch of camera parameters and GUI related elements\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n        batch.min_interval, batch.pause_physics = self.min_interval, self.pause_physics\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # GUI related elements\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.angular_friction, batch.constant_torque, batch.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.angular_friction, self.constant_torque, self.movement_torque\n\n        # Camera parameters\n        batch.min_interval, batch.pause_physics = self.min_interval, self.pause_physics\n\n        # Camera parameters\n        batch.is_dragging, batch.about_origin, batch.is_panning, batch.lock_fx_fy, batch.drag_start, batch.drag_start_front, batch.drag_start_down, batch.drag_start_right, batch.drag_start_center, batch.drag_start_origin, batch.drag_start_world_up, batch.drag_ymin, batch.drag_ymax = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Construct a structured dictionary with a direct mapping of parameters\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Add a nested 'meta' dictionary with the same content\n        meta = dotdict()\n        meta.origin, meta.world_up, meta.movement_speed, meta.movement_force, meta.drag_coeff_mult, meta.constant_drag, meta.mass, meta.moment_of_inertia, meta.movement_torque, meta.angular_friction, meta.constant_torque, meta.movement_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.movement_torque\n        meta.is_dragging, meta.about_origin, meta.is_panning, meta.lock_fx_fy, meta.drag_start, meta.drag_start_front, meta.drag_start_down, meta.drag_start_right, meta.drag_start_center, meta.drag_start_origin, meta.drag_start_world_up, meta.drag_ymin, meta.drag_ymax, meta.min_interval, meta.pause_physics = self.is_dragging, self.about_origin, self.is_panning, self.lock_fx_fy, self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up, self.drag_ymin, self.drag_ymax, self.min_interval, self.pause_physics\n        batch.meta = meta\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n\n        # Direct mapping of parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Nested 'meta' dictionary with the same content\n        batch.meta = dotdict()\n        batch.meta.origin, batch.meta.world_up, batch.meta.movement_speed, batch.meta.movement_force, batch.meta.drag_coeff_mult, batch.meta.constant_drag, batch.meta.pause_physics, batch.meta.min_interval = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.pause_physics, self.min_interval\n\n        return batch\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            self.persistence.save_agent(agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_state = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            self.persistence.save_agent(AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            self.persistence.save_agent(agent.id, AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent and agent.is_working_agent:\n            agent_dict = AgentSerializer.to_dict(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent and agent.is_working_agent:\n            self.persistence.save_agent(agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_prime_agent and agent.is_working_agent:\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            self.persistence.save_agent(agent.id, AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            self.persistence.save_agent(agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            self.persistence.save_agent(agent.id, AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_dict = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            agent_dict = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            self.persistence.save_agent(agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_state = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            max_similarity = -np.inf\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0] for agent in self.agents]\n            if not similarities:\n                return None, -np.inf\n            max_similarity = max(similarities)\n            max_similarity_index = similarities.index(max_similarity)\n            return self.agents[max_similarity_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = max(similarities) if similarities else -np.inf\n            return (self.agents[np.argmax(similarities)] if similarities else None, max_similarity)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                   agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            highest_similarity = -np.inf\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    closest_agent = agent\n                    highest_similarity = similarity\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([a.purpose_embedding], [purpose_embedding])[0][0] for a in self.agents]\n            max_similarity = max(similarities)\n            max_similarity_index = similarities.index(max_similarity)\n            return self.agents[max_similarity_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0] for agent in self.agents]\n            if len(similarities) > 0:\n                closest_agent_index = np.argmax(similarities)\n                return self.agents[closest_agent_index], similarities[closest_agent_index]\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            highest_similarity = -np.inf\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    closest_agent = agent\n                    highest_similarity = similarity\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.infimport logging\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = max(similarities)\n            max_similarity_index = np.argmax(similarities)\n            return self.agents[max_similarity_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            highest_similarity = -np.inf\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > highest_similarity:\n                    closest_agent = agent\n                    highest_similarity = similarity\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.infimport os"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0] for agent in self.agents]\n            if not similarities:\n                return None, -np.inf\n\n            max_similarity = max(similarities)\n            max_similarity_index = similarities.index(max_similarity)\n            return self.agents[max_similarity_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            if similarities:\n                return self.agents[np.argmax(similarities)], np.max(similarities)\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = max(similarities)\n            max_similarity_index = np.argmax(similarities)\n            if max_similarity >= 0.999:\n                return self.agents[max_similarity_index], max_similarity\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if purpose_embedding is None:\n                return None, -np.inf\n\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                   agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            closest_agent = None\n            max_similarity = -np.inf\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -np.inf\n\n            similarity_scores = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity_score = max(similarity_scores)\n            max_similarity_index = np.argmax(similarity_scores)\n            return self.agents[max_similarity_index], max_similarity_score\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = max(similarities)\n            if max_similarity < self.calculate_similarity_threshold():\n                return None, -np.inf\n            else:\n                closest_agent = self.agents[np.argmax(similarities)]\n                return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")import logging"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                   agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([agent.purpose_embedding], [purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flags=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unknown_flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=False,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag_1=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                prompt=PRIME_PROMPT,\n                name=PRIME_NAME,\n                weight=PRIME_AGENT_WEIGHT,\n                is_prime=True,\n                is_unspecified_flag=True,\n                openai_wrapper=self.openai_wrapper,\n                agent_persistence=self.agent_persistence\n            )\n        )\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence,\n            max_agents=self.max_agents\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            other_flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            self.openai_wrapper,\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            prime=True,\n            unknown_flag=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence,\n            max_agents=self.max_agents\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flags=[\"prime\"],\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the prime agent\n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flags=[\n                \"prime\",\n                \"prime_agent\",\n            ],\n        )\n\n        # Add the prime agent to the agent list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unknown_flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence,\n            max_agents=self.max_agents\n        )\n        self.agents.append(agent)\n        agent.start()\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            is_prime_agent=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence,\n            max_agents=self.max_agents\n        )\n        self.agents.append(agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            flag=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None\n\n    def load_agent_by_id(self, agent_id, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified id from the database. If an agent with the given id is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_id: int, The id of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent_by_id(agent_id)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None\n\n    def get_agent_by_id(self,"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database. If agents are found, they are deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: A list of instances of the deserialized agents if found, otherwise None.\n        \"\"\"\n        serialized_agents = self.persistence.load_all_agents()\n        if serialized_agents is None:\n            return None\n\n        return [\n            AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            for serialized_agent in serialized_agents\n        ]\n\n    def save_all_agents(self, agents):\n        \"\"\"\n        Saves all agents from the database. If agents are found, they are deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None\n\n    def get_all_agents(self):\n        \"\"\"\n        Get all agents from the database.\n        \"\"\"\n        return self.persistence.get_all_agents()\n\n    def get_all_agents_by_purpose(self, purpose):\n        \"\"\"\n        Get all agents from the database by purpose.\n        \"\"\"\n        return self.persistence.get_all_agents_by_purpose(purpose)\n\n    def get_all_agents_by_purpose_and_agent_lifecycle(self, purpose, agent_lifecycle):\n        \"\"\"\n        Get all agents from the database by purpose and agent lifecycle.\n        \"\"\"\n        return self.persistence.get_all_agents_by_purpose_and_agent_lifecycle(purpose, agent_lifecycle)\n\n    def get_all_agents_by_purpose_and_agent_lifecycle_and_agent_type(self, purpose, agent_lifecycle, agent_type):\n        \"\"\"\n        Get all agents from the database by purpose, agent lifecycle, and agent type.\n        \"\"\"\n        return self.persistence.get_all_agents_by_purpose_and_agent_lifecycle_and_agent_type(purpose, agent_lifecycle, agent_type)\n\n    def get_all_agents_by_agent_lifecycle(self, agent_lifecycle):\n        \"\"\"\n        Get all agents from the database by agent lifecycle.\n        \"\"\"\n        return self.persistence.get_all_agents_by_agent_lifecycle(agent_lifecycle)\n\n    def get_all_agents_by_agent_lifecycle_and_agent_type(self, agent_lifecycle, agent_type):\n        \"\"\"\n        Get all agents from the database by agent lifecycle and agent type.\n        \"\"\"\n        return self.persistence.get_all_agents_by_agent_lifecycle_and_agent_type(agent_lifecycle, agent_type)\n\n    def get_all_agents_by_agent_type(self, agent_type):\n        \"\"\"\n        Get all agents from the database by agent type.\n        \"\"\"\n        return self.persistence.get_all_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_id(self, agent_id):\n        \"\"\"\n        Retrieve an agent from the database by its ID.\n        \"\"\"\n        serialized_agent = self.persistence.get_agent_by_id(agent_id)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_purpose(self, purpose):\n        \"\"\"\n        Retrieve an agent from the database by its purpose.\n        \"\"\"\n        serialized_agent = self.persistence.get_agent_by_purpose(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_name(self, name):\n        \"\"\"\n        Retrieve an agent from the database by its name.\n        \"\"\"\n        serialized_agent = self.persistence.get_agent_by_name(name)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_type(self, agent_type):\n        \"\"\"\n        Retrieve an agent from the database by its type.\n        \"\"\"\n        serialized_agent = self.persistence.get_agent_by_type(agent_type)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_status(self, status):\n        \"\"\"\n        Retrieve an agent from the database by its status.\n        \"\"\"\n        serialized_agent = self.persistence.get_agent_by_status(status)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_status_and_type(self, status, agent_type):\n        \"\"\"\n        Retrieve an agent from the database by its status and type.\n        \"\"\"\n        serialized"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None\n\n    @memoize_to_sqlite\n    def get_agent_ids(self):\n        \"\"\"\n        Returns a list of agent IDs from the database.\n        \"\"\"\n        return self.persistence.get_agent_ids()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n        return None\n\n    @memoize_to_sqlite(db_filename=\"agents.db\")\n    def get_agent_by_id(self, agent_id):\n        \"\"\"\n        Get an agent by its ID.\n        \"\"\"\n        return self.persistence.get_agent_by_id(agent_id)\n\n    def get_all_agents(self):\n        \"\"\"\n        Get all agents.\n        \"\"\"\n        return self.persistence.get_all_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    def load_agent_from_id(self, agent_id, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent_from_id(agent_id)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    @memoize_to_sqlite\n    def get_all_agents(self):\n        \"\"\"\n        Get all agents from the database.\n        \"\"\"\n        return self.persistence.get_all_agents()\n\n    def get_all_agent_purposes(self):\n        \"\"\"\n        Get all agent purposes from the database.\n        \"\"\"\n        return self.persistence.get_all_agent_purposes()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    @memoize_to_sqlite\n    def load_all_agents(self):\n        \"\"\"\n        Loads all agents from the database.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :return: A list of all agents in the database.\n        \"\"\"\n        serialized_agents = self.persistence.load_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agents.append(AgentSerializer.deserialize(serialized_agent))\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database. If agents are found, they are deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: A list of instances of the deserialized agents if found, otherwise None.\n        \"\"\"\n        serialized_agents = self.persistence.load_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return None\n\n    def remove_all_agents(self):\n        \"\"\"\n        Removes all agents from the database.\n        \"\"\"\n        self.persistence.remove_all_agents()\n\n    def get_all_agent_purposes(self):\n        \"\"\"\n        Returns a list of all agent purposes stored in the database.\n        \"\"\"\n        return self.persistence.get_all_agent_purposes()\n\n    def get_all_agent_ids(self):\n        \"\"\"\n        Returns a list of all agent ids stored in the database.\n        \"\"\"\n        return self.persistence.get_all_agent_ids()\n\n    def get_all_agent_ids_by_purpose(self, purpose):\n        \"\"\"\n        Returns a list of all agent ids stored in the database that match a given purpose.\n        \"\"\"\n        return self.persistence.get_all_agent_ids_by_purpose(purpose)\n\n    def get_all_agent_ids_by_purpose_and_status(self, purpose, status):\n        \"\"\"\n        Returns a list of all agent ids stored in the database that match a given purpose and status."}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_count(self):\n        \"\"\"\n        Returns the number of agents in the database.\n        \"\"\"\n        return self.persistence.get_agent_count()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_count(self):\n        \"\"\"\n        Returns the number of agents currently saved in the database.\n        \"\"\"\n        return self.persistence.get_agent_count()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents\n\n    def load_agent_by_id(self, agent_id, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with the given ID from the database and returns it if it is successfully loaded. The agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_id: The ID of the agent to be loaded.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: Agent. The agent that has been successfully loaded from the database.\n        \"\"\"\n        serialized_agent = self.persistence.fetch_agent_by_id(agent_id)\n        if serialized_agent:\n            return AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None\n\n    def load_agent_by_purpose(self, purpose, agent_lifecycle, openai"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load all agents from the database and return a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents\n\n    def load_agents_by_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database with the given purpose and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        agents = []\n        serialized_agents = self.persistence.fetch_agents_by_purpose(purpose)\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents\n\n    def load_agents_by_purpose_and_state(self, purpose, state, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database with the given purpose and state and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        agents = []\n        serialized_agents = self.persistence.fetch_agents_by_purpose_and_state(purpose, state)\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents\n\n    def load_agents_by_state(self, state, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database with the given state and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "from agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom integrations.memoize import memoize_to_sqlite\nfrom integrations.sqlite_agent_persistence import SQLiteAgentPersistence\nfrom integrations.openai_wrapper import OpenAIWrapper\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager\nfrom agents.agent_serializer import AgentSerializer\nfrom agents.agent import Agent\nfrom agents.agent_factory import AgentFactory\nfrom agents.agent_lifecycle import AgentLifecycle\nfrom agents.agent_persistence_manager import AgentPersistenceManager"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n\n        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return []\n\n    def clear_agents(self):\n        \"\"\"\n        Clears all agents from the database.\n        \"\"\"\n        self.persistence.clear_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        agents = []\n        for purpose in self.persistence.fetch_all_purposes():\n            agent = self.load_agent(purpose, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load all agents from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except Exception as e:\n                print(f\"Failed to load agent with id {serialized_agent['id']}: {e}\")\n\n        return agents\n\n    def save_all_agents(self, agents):\n        \"\"\"\n        Save all agents to the database.\n        \"\"\"\n        for agent in agents:\n            self.save_agent(agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents\n\n    def load_all_agents_memoized(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        return memoize_to_sqlite(self.load_all_agents, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load all agents from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n        return []\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        for purpose in self.persistence.get_all_purposes():\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agents.append(AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n        return agents\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except Exception as e:\n                print(f\"Failed to load agent {serialized_agent['id']}: {e}\")\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load all agents from the database and return a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.name}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {agent.purpose}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.name}: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.id}: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.name}: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {agent.name}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.id}: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Failed to save agent {agent.id} with error {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.name}: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent {agent}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {agent.purpose} - {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.name} with ID {agent.id}\")\n            raise e\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=EXAMPLES\n            )\n            prompt_template = PROMPT_ENGINEERING_TEMPLATE.format(\n                prompt=prompt,\n                goal=goal\n            )\n            return self.openai_wrapper.get_chat_completion(prompt_template)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                examples=EXAMPLES,\n                sample_input=sample_input,\n                template=PROMPT_ENGINEERING_TEMPLATE\n            )\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response.choices[0].message.content\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt, response=response)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            prompt = \"\"\n        return prompt"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n        try:\n            prompt_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt, prompt_completion=prompt_completion)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"import logging"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_engineering_system_prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal, sample_input=sample_input, examples=EXAMPLES\n            )\n            prompt_engineering_template = PROMPT_ENGINEERING_TEMPLATE.format(\n                prompt_engineering_system_prompt=prompt_engineering_system_prompt\n            )\n            prompt_engineering_response = self.openai_wrapper.get_chat_completion(prompt_engineering_template)\n            prompt_engineering_response_text = prompt_engineering_response[\"choices\"][0][\"message\"][\"content\"]\n            return prompt_engineering_response_text\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt for agent: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n            prompt_template = PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt, examples=EXAMPLES)\n            response = self.openai_wrapper.get_chat_completion(prompt_template)\n            return response.choices[0].message.content\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_engineer = MicroAgent(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT, \n                \"Prompt Engineering Agent\", \n                0, self, self.openai_wrapper\n            )\n            prompt_engineer.start()\n            prompt_engineer.wait_until_ready()\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, example=sample_input)\n            prompt_engineer.send_message(prompt)\n            prompt_engineer.wait_until_ready()\n            prompt = prompt_engineer.get_last_message()\n            prompt_engineer.stop()\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                examples=EXAMPLES,\n                sample_input=sample_input,\n                template=PROMPT_ENGINEERING_TEMPLATE,\n            )\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion.choices[0].message.content\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_engineering_system_prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=EXAMPLES\n            )\n            prompt_engineering_template = PROMPT_ENGINEERING_TEMPLATE.format(\n                prompt_engineering_system_prompt=prompt_engineering_system_prompt\n            )\n            prompt = self.openai_wrapper.get_chat_completion(prompt_engineering_template)\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                example=EXAMPLES[0],\n                example_input=sample_input,\n                example_output=self.openai_wrapper.get_chat_completion(sample_input),\n                example2=EXAMPLES[1],\n                example2_input=sample_input,\n                example2_output=self.openai_wrapper.get_chat_completion(sample_input),\n                example3=EXAMPLES[2],\n                example3_input=sample_input,\n                example3_output=self.openai_wrapper.get_chat_completion(sample_input),\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_engineering_system_prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n            prompt_engineering_template = PROMPT_ENGINEERING_TEMPLATE.format(prompt_engineering_system_prompt=prompt_engineering_system_prompt)\n            prompt_engineering_response = self.openai_wrapper.get_chat_completion(prompt_engineering_template, EXAMPLES)\n            return prompt_engineering_response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"import logging"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n        try:\n            prompt_completion = self.openai_wrapper.get_chat_completion(prompt)\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt, prompt_completion=prompt_completion)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            prompt = \"\"\n\n        return prompt"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_template = PROMPT_ENGINEERING_TEMPLATE\n            prompt_template = prompt_template.replace(EXAMPLES, sample_input)\n            prompt_template = prompt_template.replace(PROMPT_ENGINEERING_SYSTEM_PROMPT, goal)\n            prompt_template = prompt_template.replace(PRIME_PROMPT, PRIME_NAME)\n            return prompt_template\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_engineer_agent = self.get_or_create_agent(\"Prompt Engineer\", 0, sample_input, force_new=True)\n            prompt_engineer_agent.start()\n            prompt_engineer_agent.wait_until_ready()\n            prompt_engineer_agent.stop()\n            prompt_engineer_agent.reset()\n            prompt_engineer_agent.usage_count = 0\n            prompt_engineer_agent.working_agent = False\n            prompt_engineer_agent.stopped = True\n            prompt_engineer_agent.parent_id = None\n            prompt_engineer_agent.parent = None\n            prompt_engineer_agent.id = None\n            prompt_engineer_agent.depth = 0\n            prompt_engineer_agent.purpose = \"Bootstrap Agent\"\n            prompt_engineer_agent.name = \"Bootstrap Agent\"\n            prompt_engineer_agent.weight = 0\n            prompt_engineer_agent.llm_prompt = None\n            prompt_engineer_agent.llm_response = None\n            prompt_engineer_agent.is_prime_agent = False\n            prompt_engineer_agent.is_prompt_engineer_agent = True\n            prompt_engineer_agent.is_chat_completion_agent = False\n            prompt_engineer_agent.is_agent_similarity_agent = False\n            prompt_engineer_agent.is_agent_persistence_agent = False\n            prompt_engineer_agent.is_agent_lifecycle_agent = False\n            prompt_engineer_agent.is_agent_manager_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_creator_agent = False\n            prompt_engineer_agent.is_agent_"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input)\n            prompt_response = self.openai_wrapper.get_chat_completion(prompt)\n            prompt_response = prompt_response.replace(PROMPT_ENGINEERING_SYSTEM_PROMPT, \"\").strip()\n            return prompt_response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return PROMPT_ENGINEERING_TEMPLATE.format(prompt=prompt, response=response)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                examples=EXAMPLES,\n                sample_input=sample_input,\n                template=PROMPT_ENGINEERING_TEMPLATE\n            )\n\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=EXAMPLES\n            )\n            prompt_embedding = self.openai_wrapper.get_embedding(prompt)\n            prompt_template = PROMPT_ENGINEERING_TEMPLATE.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=EXAMPLES\n            )\n            prompt_template_embedding = self.openai_wrapper.get_embedding(prompt_template)\n            prompt_template_similarity = self.openai_wrapper.get_similarity(prompt_embedding, prompt_template_embedding)\n            if prompt_template_similarity < 0.5:\n                return prompt_template\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"from typing import List"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_engineer_agent = self.get_or_create_agent(\"Prompt Engineering\", 0, sample_input)\n            prompt_engineer_agent.start()\n            prompt_engineer_agent.wait_until_ready()\n            prompt = prompt_engineer_agent.get_response(PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, example=sample_input))\n            prompt_engineer_agent.stop()\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt_template = PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input)\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(prompt_template=prompt_template)\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response.choices[0].message.content\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"]))\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict['data'])\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"]))\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"INSERT OR REPLACE INTO agents VALUES (?, ?, ?)\",\n                (\n                    agent_dict['id'],\n                    agent_dict['purpose'],\n                    json.dumps(agent_dict['data'])\n                )\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict['data'])\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"INSERT OR REPLACE INTO agents VALUES (?, ?, ?)\",\n                (\n                    agent_dict[\"id\"],\n                    agent_dict[\"purpose\"],\n                    json.dumps(agent_dict[\"data\"]),\n                ),\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])),\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES (?, ?, ?)\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict)\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            # Serialize the agent dictionary into a JSON string\n            json_data = json.dumps(agent_dict)\n\n            # Check if the agent already exists in the database\n            cursor = conn.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            row = cursor.fetchone()\n\n            # Update the existing record if the agent already exists\n            if row is not None:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json_data, agent_dict['id'],))\n\n            # Insert a new record if the agent does not exist\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json_data,))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                (\n                    agent_dict[\"id\"],\n                    agent_dict[\"purpose\"],\n                    json.dumps(agent_dict[\"data\"]),\n                ),\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict[\"data\"]))\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT * FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[2])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            data = cursor.fetchone()\n            if data is None:\n                return None\n            else:\n                return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data is None:\n                return None\n            else:\n                return json.loads(agent_data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return Noneimport json"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return Noneimport json"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT * FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[2])import json"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\",\n                (purpose,)\n            )\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return Nonefrom abc import ABC, abstractmethod\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE purpose = ?\", (purpose,)\n            )\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]import json"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,),\n        )\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is not None:\n            result = json.loads(result[0])\n        return result\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,),\n        )\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,),\n        )\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        query = f\"SELECT result FROM cache WHERE hash = '{arg_hash}'\"\n        result = self.connection.execute(query).fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        query = \"SELECT result FROM cache WHERE hash = ?\"\n        cursor = self.connection.cursor()\n        cursor.execute(query, (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,),\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()import os"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()import sqlite3"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()# Python Memoization\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update_from_args(args)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG.get(\"record_dir\"), \"output.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine().run()\n    else:\n        CommandLine().run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global_config = CONFIG.get_global_config()\n\n    if args.task is not None:\n        global_config.task = args.task\n    if args.upload_files is not None:\n        global_config.upload_files = args.upload_files\n    if args.model is not None:\n        global_config.model = args.model\n    if args.record_dir is not None:\n        global_config.record_dir = args.record_dir\n    if args.mode is not None:\n        global_config.mode = args.mode\n    if args.max_subtask_chain_length is not None:\n        global_config.max_subtask_chain_length = args.max_subtask_chain_length\n    if args.enable_ask_human_for_help is not None:\n        global_config.enable_ask_human_for_help = args.enable_ask_human_for_help\n    if args.max_plan_refine_chain_length is not None:\n        global_config.max_plan_refine_chain_length = args.max_plan_refine_chain_length\n    if args.max_plan_tree_depth is not None:\n        global_config.max_plan_tree_depth = args.max_plan_tree_depth\n    if args.max_plan_tree_width is not None:\n        global_config.max_plan_tree_width = args.max_plan_tree_width\n    if args.max_retry_times is not None:\n        global_config.max_retry_times = args.max_retry_times\n\n    if quiet_mode:\n        # Redirect standard output to a file\n        with open(os.path.join(global_config.record_dir, \"stdout.log\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine.execute()\n    else:\n        CommandLine.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    config = deepcopy(CONFIG)\n    config.update(vars(args))\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(config.get(\"record_dir\", \"record.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine(config).execute()\n    else:\n        CommandLine(config).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if args.quiet:\n        quiet_mode = True\n\n    if args.config_file:\n        CONFIG.load_config(args.config_file)\n\n    if args.upload_files:\n        CONFIG.upload_files = args.upload_files\n\n    if args.record_dir:\n        CONFIG.record_dir = args.record_dir\n\n    if args.mode:\n        CONFIG.mode = args.mode\n\n    if args.max_subtask_chain_length:\n        CONFIG.max_subtask_chain_length = args.max_subtask_chain_length\n\n    if args.enable_ask_human_for_help:\n        CONFIG.enable_ask_human_for_help = args.enable_ask_human_for_help\n\n    if args.max_plan_refine_chain_length:\n        CONFIG.max_plan_refine_chain_length = args.max_plan_refine_chain_length\n\n    if args.max_plan_tree_depth:\n        CONFIG.max_plan_tree_depth = args.max_plan_tree_depth\n\n    if args.max_plan_tree_width:\n        CONFIG.max_plan_tree_width = args.max_plan_tree_width\n\n    if args.max_retry_times:\n        CONFIG.max_retry_times = args.max_retry_times\n\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.run(args.task, model=args.model)\n    else:\n        CommandLine.run(args.task, model=args.model)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, \"stdout.log\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine().run()\n    else:\n        CommandLine().run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect standard output to a file instead of printing it to the terminal\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, \"output.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine().run()\n    else:\n        CommandLine().run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect standard output to a file instead of printing it to the terminal.\n    if quiet_mode:\n        with open(os.path.join(CONFIG.get(\"record_dir\", \"record\"), \"output.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine().execute()\n    else:\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect standard output to a file instead of printing it to the terminal\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CommandLineParam(CONFIG.task, CONFIG.upload_files, CONFIG.model, CONFIG.record_dir,\n                                             CONFIG.mode, CONFIG.quiet, CONFIG.max_subtask_chain_length,\n                                             CONFIG.enable_ask_human_for_help, CONFIG.max_plan_refine_chain_length,\n                                             CONFIG.max_plan_tree_depth, CONFIG.max_plan_tree_width,\n                                             CONFIG.max_retry_times, CONFIG.config_file)).run()\n    else:\n        CommandLine(CommandLineParam(CONFIG.task, CONFIG.upload_files, CONFIG.model, CONFIG.record_dir, CONFIG.mode,\n                                      CONFIG.quiet, CONFIG.max_subtask_chain_length, CONFIG.enable_ask_human_for_help,\n                                      CONFIG.max_plan_refine_chain_length, CONFIG.max_plan_tree_depth,\n                                      CONFIG.max_plan_tree_width, CONFIG.max_retry_times, CONFIG.config_file)).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(args)\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, \"output.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine.run()\n    else:\n        CommandLine.run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG.get(\"record_dir\"), \"stdout.log\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine().run(CommandLineParam(args.task))\n    else:\n        CommandLine().run(CommandLineParam(args.task))\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(args.__dict__)\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CommandLineParam(CONFIG.task, CONFIG.model, CONFIG.upload_files, CONFIG.record_dir,\n                                             CONFIG.mode, CONFIG.enable_ask_human_for_help,\n                                             CONFIG.max_subtask_chain_length, CONFIG.max_plan_refine_chain_length,\n                                             CONFIG.max_plan_tree_depth, CONFIG.max_plan_tree_width,\n                                             CONFIG.max_retry_times)).run()\n    else:\n        CommandLine(CommandLineParam(CONFIG.task, CONFIG.model, CONFIG.upload_files, CONFIG.record_dir, CONFIG.mode,\n                                      CONFIG.enable_ask_human_for_help, CONFIG.max_subtask_chain_length,\n                                      CONFIG.max_plan_refine_chain_length, CONFIG.max_plan_tree_depth,\n                                      CONFIG.max_plan_tree_width, CONFIG.max_retry_times)).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration with the provided arguments\n    CONFIG.update(args.__dict__)\n\n    # If quiet mode is enabled, redirect output to a file\n    if quiet_mode:\n        with open(f\"{args.record_dir}/stdout.log\", \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine(args).run()\n    else:\n        CommandLine(args).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        # Redirect stdout to a file instead of printing it to the terminal\n        with open(os.path.join(args.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(args).run()\n    else:\n        CommandLine(args).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if args.quiet:\n        # Redirect standard output to a file\n        with open(os.path.join(args.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.run(args)\n    else:\n        CommandLine.run(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global_config = CONFIG.get_config()\n\n    # Update global configuration parameters with the provided arguments\n    global_config.update(args.__dict__)\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.path.join(global_config['record_dir'], 'stdout.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.process(args)\n    else:\n        CommandLine.process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of printing it to the terminal\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, \"output.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine(CommandLineParam(CONFIG.task)).run()\n    else:\n        CommandLine(CommandLineParam(CONFIG.task)).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        # Create a new file named 'output.txt' in the current directory\n        with open('output.txt', 'w') as f:\n            # Redirect the standard output to the file\n            with redirect_stdout(f):\n                # Execute the command line process\n                CommandLine.run(args.task)\n    else:\n        # Execute the command line process\n        CommandLine.run(args.task)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n    ARGS.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        with open(os.path.join(CONFIG.get(\"record_dir\"), \"command_line_process.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine().run()\n    else:\n        CommandLine().run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global_config = CONFIG\n    global_config.update(args.__dict__)\n\n    if not quiet_mode:\n        print(f\"Running in non-quiet mode.\")\n    else:\n        print(f\"Running in quiet mode.\")\n        with open(\"output.txt\", \"w\") as f:\n            with redirect_stdout(f):\n                print(f\"Output is being redirected to output.txt\")\n\n    print(f\"args: {args}\")\n    print(f\"global_config: {global_config}\")\n\n    # Execute the command line process\n    command_line = CommandLine()\n    command_line.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        with open(os.path.join(args.record_dir, \"output.txt\"), \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine(args).run()\n    else:\n        CommandLine(args).run()\n\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e.message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n            self._last_time = time()\n        elif time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n\n        if self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._last_time = time()\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        assert self.shuffler is not None\n        assert self.cache is not None\n        assert self.worker_env is not None\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n            \"chunk_index\": self.chunk_index,\n            \"global_index\": self.global_index,\n            \"index\": self.index,\n            \"current_indexes\": self.current_indexes,\n            \"worker_chunks\": self.worker_chunks,\n            \"worker_intervals\": self.worker_intervals,\n            \"num_chunks\": self.num_chunks,\n            \"has_triggered_download\": self.has_triggered_download,\n            \"cache\": self.cache.state_dict(),\n            \"shuffler\": self.shuffler.state_dict(),\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"Cannot call `state_dict` from a DataLoader worker process.\")\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        state: Dict[str, Any] = {}\n\n        state[\"num_samples_yielded\"] = num_samples_yielded\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"input_dir\"] = self.input_dir.state_dict()\n        state[\"item_loader\"] = self.item_loader.state_dict() if self.item_loader is not None else None\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"world_size\"] = self.distributed_env.world_size\n        state[\"shuffle\"] = self.shuffle\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process. \"\n                \"Please ensure that you are not using a DataLoader with `num_workers > 0` when calling this method.\"\n            )\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        assert self.worker_env is not None\n        assert self.distributed_env is not None\n        assert self.shuffler is not None\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"You can't call `state_dict` from a DataLoader worker process. \"\n                \"Please call it from the main process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` cannot be called from a DataLoader worker process.\")\n\n        assert self.shuffler is not None\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        self._state_dict = state_dict\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"Cannot call state_dict from a DataLoader worker process.\")\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"StreamingDataset.state_dict() cannot be called from a DataLoader worker process.\"\n            )\n\n        assert self.worker_env is not None\n        assert self.distributed_env is not None\n        assert self.shuffler is not None\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state_dict\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"Cannot call state_dict() from a DataLoader worker process.\")\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state_dict\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"StreamingDataset.state_dict() cannot be called from a DataLoader worker process. \"\n                \"Please, move the call to StreamingDataset.state_dict() to the main process.\"\n            )\n\n        # We need to compute the number of samples yielded by the dataset.\n        # For this, we need to know the number of workers and the batch size.\n        assert self.distributed_env is not None\n        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.num_chunks is not None\n\n        # We need to know the number of samples yielded by the dataset.\n        # For this, we need to know the number of workers and the batch size.\n        assert self.distributed_env is not None\n        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.num_chunks is not None\n\n        # We need to know the number of samples yielded by the dataset.\n        # For this, we need to know the number of workers and the batch size.\n        assert self.distributed_env is not None\n        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.num_chunks is not None\n\n        # We need to know the number of samples yielded by the dataset.\n        # For this, we need to know the number of workers and the batch size.\n        assert self.distributed_env is not None\n        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.num_chunks is not None\n\n        # We need to know the number of samples yielded by the dataset.\n        # For this, we need to know the number of workers and the batch size.\n        assert self.distributed_env is not None\n        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.num_chunks is not None\n\n        # We need to know the number of samples yielded by the dataset.\n        # For this, we need to know the number of workers and the batch size.\n        assert self.distributed_env is not None\n        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.num_chunks is not None"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.state_dict(),\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should not be called from a DataLoader worker process.\")\n\n        if self.distributed_env.world_size > 1:\n            if self.drop_last is False:\n                logger.warn(\n                    \"You're operating within a distributed environment and have disabled the `drop_last` option. \"\n                    \"Please note that this configuration may lead to training interruptions if your system depends \"\n                    \"on distributed collectives.\"\n                )\n            else:\n                self.drop_last = True\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"Cannot call state_dict from a DataLoader worker process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method is not supported in DataLoader worker processes. \"\n                \"Please ensure that you are calling this method from the main process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"StreamingDataset.state_dict() should only be called from the \"\n                \"main process. To retrieve the state dict from a DataLoader worker \"\n                \"process, access the dataset using `worker_info.dataset` instead.\"\n            )\n\n        if self.distributed_env.world_size > 1:\n            if self.drop_last is False:\n                logger.warn(\n                    \"You're operating within a distributed environment and have disabled the `drop_last` option. \"\n                    \"Please note that this configuration may lead to training interruptions if your system depends \"\n                    \"on distributed collectives.\"\n                )\n            else:\n                self.drop_last = True\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"Cannot call state_dict from a DataLoader worker process.\")\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        # TODO: Add the number of samples yielded by the workers\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process.\"\n            )\n\n        if self.distributed_env.world_size > 1:\n            if self.drop_last is False:\n                logger.warn(\n                    \"You're operating within a distributed environment and have disabled the `drop_last` option. \"\n                    \"Please note that this configuration may lead to training interruptions if your system depends \"\n                    \"on distributed collectives.\"\n                )\n            else:\n                self.drop_last = True\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state_dict\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        assert self.worker_env is not None\n        assert self.shuffler is not None\n        assert self.cache is not None\n\n        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process. \"\n                \"Please ensure that you are not using the `state_dict` method within a DataLoader worker process.\"\n            )\n\n        assert self.worker_chunks is not None\n        assert self.worker_intervals is not None\n        assert self.current_indexes is not None\n        assert self.chunk_index is not None\n        assert self.num_chunks is not None\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n            \"worker_chunks\": self.worker_chunks,\n            \"worker_intervals\": self.worker_intervals,\n            \"current_indexes\": self.current_indexes,\n            \"chunk_index\": self.chunk_index,\n            \"num_chunks\": self.num_chunks,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"Cannot call `state_dict()` from a DataLoader worker process. \"\n                \"This probably indicates that you're using a `DataLoader` with \"\n                \"multiple workers which is not supported.\"\n            )\n\n        # TODO: Implement elastic sampling where the number of workers, ranks can change.\n        # TODO: Add the item loader state\n        # TODO: Add the seed and world size of the distributed environment\n        # TODO: Add the shuffle status\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"drop_last\": self.drop_last,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self.input_dir = Dir(path=state_dict[\"input_dir_path\"], url=state_dict[\"input_dir_url\"])\n        self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"]) if state_dict[\"item_loader\"] else None\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        self.distributed_env = _DistributedEnv(\n            world_size=state_dict[\"world_size\"], global_rank=0, local_rank=0, local_world_size=1\n        )\n        self.input_dir = Dir(path=state_dict[\"input_dir_path\"], url=state_dict[\"input_dir_url\"])\n        self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        if self._state_dict is not None:\n            state: Dict[str, Any] = self._state_dict\n            self.current_epoch = state[\"current_epoch\"]\n            self.input_dir.path = state[\"input_dir_path\"]\n            self.input_dir.url = state[\"input_dir_url\"]\n            if state[\"item_loader\"] is not None:\n                self.item_loader = BaseItemLoader.load_state_dict(state[\"item_loader\"])\n            self.drop_last = state[\"drop_last\"]\n            self.seed = state[\"seed\"]\n            self.distributed_env = _DistributedEnv(state[\"world_size\"], 0, 0, 0)\n            self.shuffle = state[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        self.input_dir = Dir(\n            path=self._state_dict[\"input_dir_path\"] or self._state_dict[\"input_dir_url\"],\n            url=self._state_dict[\"input_dir_url\"],\n        )\n\n        if self._state_dict[\"item_loader\"]:\n            self.item_loader.load_state_dict(self._state_dict[\"item_loader\"])\n\n        self.distributed_env = _DistributedEnv(\n            world_size=self._state_dict[\"world_size\"], global_rank=self.distributed_env.global_rank\n        )\n        self.drop_last = self._state_dict[\"drop_last\"]\n        self.seed = self._state_dict[\"seed\"]\n        self.shuffle = self._state_dict[\"shuffle\"]\n        self.current_epoch = self._state_dict[\"current_epoch\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        if self.input_dir.path != self._state_dict[\"input_dir_path\"] or self.input_dir.url != self._state_dict[\"input_dir_url\"]:\n            self.input_dir.path = self._state_dict[\"input_dir_path\"]\n            self.input_dir.url = self._state_dict[\"input_dir_url\"]\n            self.cache = None\n\n        if self.item_loader is None:\n            self.item_loader = BaseItemLoader()\n        if self._state_dict[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(self._state_dict[\"item_loader\"])\n\n        self.drop_last = self._state_dict[\"drop_last\"]\n        self.seed = self._state_dict[\"seed\"]\n        self.distributed_env.world_size = self._state_dict[\"world_size\"]\n        self.shuffle = self._state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n        if self.item_loader is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n        self.shuffle = state_dict[\"shuffle\"]\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        if self.item_loader is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        # If the input_dir has changed, we need to reload the cache\n        if self.input_dir.path != self._state_dict[\"input_dir_path\"]:\n            self.input_dir = Dir(self._state_dict[\"input_dir_path\"])\n            self.cache = None\n\n        # If the item_loader has changed, we need to reload the cache\n        if self.item_loader and self.item_loader.state_dict() != self._state_dict[\"item_loader\"]:\n            self.item_loader = BaseItemLoader.load_state_dict(self._state_dict[\"item_loader\"])\n            self.cache = None\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n        if self.item_loader:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The number of workers in the state dictionary ({state['num_workers']}) does not match the number of workers in the current StreamingDataset instance ({self.worker_env.world_size}).\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary ({state['input_dir_path']}) does not match the input directory path in the current StreamingDataset instance ({self.input_dir.path}).\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary ({state['input_dir_url']}) does not match the input directory URL in the current StreamingDataset instance ({self.input_dir.url}).\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary ({state['seed']}) does not match the seed in the current StreamingDataset instance ({self.seed}).\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last flag in the state dictionary ({state['drop_last']}) does not match the drop_last flag in the current StreamingDataset instance ({self.drop_last}).\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle flag in the state dictionary ({state['shuffle']}) does not match the shuffle flag in the current StreamingDataset instance ({self.shuffle}).\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary ({state['input_dir_path']}) \"\n                f\"does not match the current input directory path ({self.input_dir.path}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary ({state['input_dir_url']}) \"\n                f\"does not match the current input directory URL ({self.input_dir.url}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The number of workers in the state dictionary ({state['num_workers']}) \"\n                f\"does not match the current number of workers ({self.worker_env.world_size}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary ({state['seed']}) \"\n                f\"does not match the current seed ({self.seed}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state dictionary ({state['shuffle']}) \"\n                f\"does not match the current shuffle ({self.shuffle}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last in the state dictionary ({state['drop_last']}) \"\n                f\"does not match the current drop_last ({self.drop_last}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world_size in the state dictionary ({state['world_size']}) \"\n                f\"does not match the current world_size ({self.distributed_env.world_size}) of the StreamingDataset instance.\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary's shuffle value {state['shuffle']} does not match the current shuffle value {self.shuffle} of the StreamingDataset instance.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary's num_workers value {state['num_workers']} does not match the current num_workers value {self.worker_env.world_size} of the StreamingDataset instance.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary's input_dir_path value {state['input_dir_path']} does not match the current input_dir_path value {self.input_dir.path} of the StreamingDataset instance.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary's input_dir_url value {state['input_dir_url']} does not match the current input_dir_url value {self.input_dir.url} of the StreamingDataset instance.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary's seed value {state['seed']} does not match the current seed value {self.seed} of the StreamingDataset instance.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary's drop_last value {state['drop_last']} does not match the current drop_last value {self.drop_last} of the StreamingDataset instance.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n            raise ValueError(\n                f\"The state dictionary's item_loader value {state['item_loader']} does not match the current item_loader value {self.item_loader.state_dict()} of the StreamingDataset instance.\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The number of workers in the state dictionary ({state['num_workers']}) does not match the number of workers in the current StreamingDataset instance ({self.worker_env.world_size}).\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary ({state['input_dir_path']}) does not match the input directory path in the current StreamingDataset instance ({self.input_dir.path}).\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary ({state['input_dir_url']}) does not match the input directory URL in the current StreamingDataset instance ({self.input_dir.url}).\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary ({state['seed']}) does not match the seed in the current StreamingDataset instance ({self.seed}).\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle flag in the state dictionary ({state['shuffle']}) does not match the shuffle flag in the current StreamingDataset instance ({self.shuffle}).\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last flag in the state dictionary ({state['drop_last']}) does not match the drop_last flag in the current StreamingDataset instance ({self.drop_last}).\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            if not self.item_loader.validate_state_dict(state[\"item_loader\"]):\n                raise ValueError(\n                    f\"The item_loader state in the state dictionary ({state['item_loader']}) does not match the item_loader state in the current StreamingDataset instance ({self.item_loader.state_dict()}).\"\n                )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The number of workers in the state dictionary ({state['num_workers']}) does not match the number of workers in the current environment ({self.worker_env.world_size}).\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary ({state['input_dir_path']}) does not match the current input directory path ({self.input_dir.path}).\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary ({state['input_dir_url']}) does not match the current input directory URL ({self.input_dir.url}).\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary ({state['seed']}) does not match the current seed ({self.seed}).\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last flag in the state dictionary ({state['drop_last']}) does not match the current drop_last flag ({self.drop_last}).\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle flag in the state dictionary ({state['shuffle']}) does not match the current shuffle flag ({self.shuffle}).\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The state dictionary `shuffle` parameter `{state['shuffle']}` does not match the current `shuffle` parameter `{self.shuffle}`.\"\n            )\n\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The state dictionary `num_workers` parameter `{state['num_workers']}` does not match the current `num_workers` parameter `{self.worker_env.world_size}`.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The state dictionary `input_dir_path` parameter `{state['input_dir_path']}` does not match the current `input_dir_path` parameter `{self.input_dir.path}`.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The state dictionary `input_dir_url` parameter `{state['input_dir_url']}` does not match the current `input_dir_url` parameter `{self.input_dir.url}`.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The state dictionary `seed` parameter `{state['seed']}` does not match the current `seed` parameter `{self.seed}`.\"\n            )\n\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The state dictionary `drop_last` parameter `{state['drop_last']}` does not match the current `drop_last` parameter `{self.drop_last}`.\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        state_dict = state[\"state_dict\"]\n\n        if state_dict[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary has shuffle set to {state_dict['shuffle']}, \"\n                f\"but the current StreamingDataset instance has shuffle set to {self.shuffle}.\"\n            )\n\n        if state_dict[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has num_workers set to {state_dict['num_workers']}, \"\n                f\"but the current StreamingDataset instance has num_workers set to {self.worker_env.world_size}.\"\n            )\n\n        if state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has input_dir_path set to {state_dict['input_dir_path']}, \"\n                f\"but the current StreamingDataset instance has input_dir_path set to {self.input_dir.path}.\"\n            )\n\n        if state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has input_dir_url set to {state_dict['input_dir_url']}, \"\n                f\"but the current StreamingDataset instance has input_dir_url set to {self.input_dir.url}.\"\n            )\n\n        if state_dict[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary has seed set to {state_dict['seed']}, \"\n                f\"but the current StreamingDataset instance has seed set to {self.seed}.\"\n            )\n\n        if state_dict[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state dictionary has item_loader set to {state_dict['item_loader']}, \"\n                f\"but the current StreamingDataset instance has item_loader set to {self.item_loader.state_dict()}.\"\n            )\n\n        if state_dict[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary has drop_last set to {state_dict['drop_last']}, \""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary has a different shuffle setting ({state['shuffle']}) than the current state ({self.shuffle}).\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has a different number of workers ({state['num_workers']}) than the current state ({self.worker_env.world_size}).\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has a different input directory path ({state['input_dir_path']}) than the current state ({self.input_dir.path}).\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has a different input directory URL ({state['input_dir_url']}) than the current state ({self.input_dir.url}).\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary has a different seed ({state['seed']}) than the current state ({self.seed}).\"\n            )\n\n        if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n            raise ValueError(\n                f\"The state dictionary has a different item loader state ({state['item_loader']}) than the current state ({self.item_loader.state_dict() if self.item_loader else None}).\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary has a different drop_last setting ({state['drop_last']}) than the current state ({self.drop_last}).\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n        assert state\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(f\"The state dictionary has shuffle={state['shuffle']} while the current state is {self.shuffle}\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has num_workers={state['num_workers']} while the current state is {self.worker_env.world_size}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has input_dir_path={state['input_dir_path']} while the current state is {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has input_dir_url={state['input_dir_url']} while the current state is {self.input_dir.url}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(f\"The state dictionary has seed={state['seed']} while the current state is {self.seed}\")\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has world_size={state['world_size']} while the current state is {self.distributed_env.world_size}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary has drop_last={state['drop_last']} while the current state is {self.drop_last}\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The state dictionary `shuffle` value {state['shuffle']} does not match the current \"\n                f\"StreamingDataset instance `shuffle` value {self.shuffle}.\"\n            )\n\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The state dictionary `num_workers` value {state['num_workers']} does not match the current \"\n                f\"StreamingDataset instance `num_workers` value {self.worker_env.world_size}.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The state dictionary `input_dir` value {state['input_dir_path'] or state['input_dir_url']} does not match the current \"\n                f\"StreamingDataset instance `input_dir` value {self.input_dir.path or self.input_dir.url}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The state dictionary `seed` value {state['seed']} does not match the current \"\n                f\"StreamingDataset instance `seed` value {self.seed}.\"\n            )\n\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n        elif self.item_loader is None and state[\"item_loader\"] is not None:\n            raise ValueError(\n                \"The state dictionary `item_loader` is not None while the current StreamingDataset instance `item_loader` is None.\"\n            )\n        elif self.item_loader is not None and state[\"item_loader\"] is None:\n            raise ValueError(\n                \"The state dictionary `item_loader` is None while the current StreamingDataset instance `item_loader` is not None.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The state dictionary `drop_last` value {state['drop_last']} does not match the current \"\n                f\"StreamingDataset instance `drop_last"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        state: Dict[str, Any] = self._state_dict\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The number of workers in the state dict ({state['world_size']}) does not match the number of workers in the current environment ({self.distributed_env.world_size}).\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle mode in the state dict ({state['shuffle']}) does not match the shuffle mode in the current StreamingDataset instance ({self.shuffle}).\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path in the state dict ({state['input_dir_path']}) does not match the input directory path in the current StreamingDataset instance ({self.input_dir.path}).\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory URL in the state dict ({state['input_dir_url']}) does not match the input directory URL in the current StreamingDataset instance ({self.input_dir.url}).\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed in the state dict ({state['seed']}) does not match the seed in the current StreamingDataset instance ({self.seed}).\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last flag in the state dict ({state['drop_last']}) does not match the drop_last flag in the current StreamingDataset instance ({self.drop_last}).\"\n            )\n\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n        elif self.item_loader is None and state[\"item_loader\"] is not None:\n            raise ValueError(\n                \"The item_loader in the state dict is not None, but the current StreamingDataset instance has no item_loader.\"\n            )\n        elif self.item_loader is not None and state[\"item_loader\"] is None:\n           "}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The provided input_dir `{self.input_dir.path}` doesn't match the input_dir provided in the state dict `{state['input_dir_path']}`.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The provided input_dir `{self.input_dir.url}` doesn't match the input_dir provided in the state dict `{state['input_dir_url']}`.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The provided num_workers `{self.worker_env.world_size}` doesn't match the num_workers provided in the state dict `{state['num_workers']}`.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The provided world_size `{self.distributed_env.world_size}` doesn't match the world_size provided in the state dict `{state['world_size']}`.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The provided seed `{self.seed}` doesn't match the seed provided in the state dict `{state['seed']}`.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The provided drop_last `{self.drop_last}` doesn't match the drop_last provided in the state dict `{state['drop_last']}`.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The provided shuffle `{self.shuffle}` doesn't match the shuffle provided in the state dict `{state['shuffle']}`.\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has been created with a world size of {state['world_size']} while the current world size is {self.distributed_env.world_size}\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary has been created with a shuffle value of {state['shuffle']} while the current shuffle value is {self.shuffle}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has been created with an input directory path of {state['input_dir_path']} while the current input directory path is {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has been created with an input directory URL of {state['input_dir_url']} while the current input directory URL is {self.input_dir.url}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary has been created with a seed value of {state['seed']} while the current seed value is {self.seed}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary has been created with a drop_last value of {state['drop_last']} while the current drop_last value is {self.drop_last}\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The state dictionary was created with shuffle={state['shuffle']} but the current state is shuffle={self.shuffle}.\"\n            )\n\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The state dictionary was created with num_workers={state['num_workers']} but the current num_workers is {self.worker_env.world_size}.\"\n            )\n\n        if (self.input_dir.path and self.input_dir.path != state[\"input_dir_path\"]) or (\n            self.input_dir.url and self.input_dir.url != state[\"input_dir_url\"]\n        ):\n            raise ValueError(\n                f\"The state dictionary was created with input_dir={state['input_dir_path'] or state['input_dir_url']} but the current input_dir is {self.input_dir}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The state dictionary was created with seed={state['seed']} but the current seed is {self.seed}.\"\n            )\n\n        if self.item_loader and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                f\"The state dictionary was created with item_loader={state['item_loader']} but the current item_loader is {self.item_loader.state_dict()}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The state dictionary was created with drop_last={state['drop_last']} but the current drop_last is {self.drop_last}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        state: Dict[str, Any] = self._state_dict\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The state dictionary was created with {state['world_size']} workers, \"\n                f\"but the current StreamingDataset instance has {self.distributed_env.world_size} workers.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The state dictionary was created with input_dir path {state['input_dir_path']}, \"\n                f\"but the current StreamingDataset instance has input_dir path {self.input_dir.path}.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The state dictionary was created with input_dir url {state['input_dir_url']}, \"\n                f\"but the current StreamingDataset instance has input_dir url {self.input_dir.url}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The state dictionary was created with seed {state['seed']}, \"\n                f\"but the current StreamingDataset instance has seed {self.seed}.\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The state dictionary was created with drop_last {state['drop_last']}, \"\n                f\"but the current StreamingDataset instance has drop_last {self.drop_last}.\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The state dictionary was created with shuffle {state['shuffle']}, \"\n                f\"but the current StreamingDataset instance has shuffle {self.shuffle}.\"\n            )\n\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state = self._state_dict\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The number of ranks in the state dictionary ({state['world_size']}) does not match the current number of ranks ({self.distributed_env.world_size}).\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle state in the state dictionary ({state['shuffle']}) does not match the current shuffle state ({self.shuffle}).\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory path or URL in the state dictionary ({state['input_dir_path']}, {state['input_dir_url']}) does not match the current input directory path or URL ({self.input_dir.path}, {self.input_dir.url}).\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed in the state dictionary ({state['seed']}) does not match the current seed ({self.seed}).\"\n            )\n\n        if self.item_loader and state[\"item_loader\"]:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n        elif self.item_loader is None and state[\"item_loader\"] is not None:\n            raise ValueError(\"The item_loader state in the state dictionary is not None, but the current item_loader is None.\")\n        elif self.item_loader is not None and state[\"item_loader\"] is None:\n            raise ValueError(\"The item_loader state in the state dictionary is None, but the current item_loader is not None.\")\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last flag in the state dictionary ({state['drop_last']}) does not match the current drop_last flag ({self.drop_last}).\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(f\"The state dictionary has a different `shuffle` value than the current state.\")\n\n        if self.worker_env.world_size != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The state dictionary has a different number of workers than the current state. \"\n                f\"Current number of workers: {self.worker_env.world_size}. \"\n                f\"State dictionary number of workers: {state['num_workers']}.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The state dictionary has a different input directory path than the current state. \"\n                f\"Current input directory path: {self.input_dir.path}. \"\n                f\"State dictionary input directory path: {state['input_dir_path']}.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The state dictionary has a different input directory URL than the current state. \"\n                f\"Current input directory URL: {self.input_dir.url}. \"\n                f\"State dictionary input directory URL: {state['input_dir_url']}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"The state dictionary has a different seed than the current state.\")\n\n        if self.item_loader and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(f\"The state dictionary has a different item loader state than the current state.\")\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(f\"The state dictionary has a different drop_last value than the current state.\")\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n        if state is None:\n            raise ValueError(\"State dictionary is None\")\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has a world size of {state['world_size']}, but the current StreamingDataset has a world size of {self.distributed_env.world_size}.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary has shuffle set to {state['shuffle']}, but the current StreamingDataset has shuffle set to {self.shuffle}.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has input_dir_path set to {state['input_dir_path']}, but the current StreamingDataset has input_dir_path set to {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has input_dir_url set to {state['input_dir_url']}, but the current StreamingDataset has input_dir_url set to {self.input_dir.url}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary has seed set to {state['seed']}, but the current StreamingDataset has seed set to {self.seed}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary has drop_last set to {state['drop_last']}, but the current StreamingDataset has drop_last set to {self.drop_last}.\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                \"The number of ranks in the state dictionary does not match the current number of ranks in the StreamingDataset instance.\"\n            )\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The shuffle parameter in the state dictionary does not match the current shuffle parameter in the StreamingDataset instance.\"\n            )\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                \"The number of workers in the state dictionary does not match the current number of workers in the StreamingDataset instance.\"\n            )\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The input directory path in the state dictionary does not match the current input directory path in the StreamingDataset instance.\"\n            )\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The input directory URL in the state dictionary does not match the current input directory URL in the StreamingDataset instance.\"\n            )\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                \"The seed in the state dictionary does not match the current seed in the StreamingDataset instance.\"\n            )\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                \"The drop_last parameter in the state dictionary does not match the current drop_last parameter in the StreamingDataset instance.\"\n            )\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                \"The item_loader state in the state dictionary does not match the current item_loader state in the StreamingDataset instance.\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state = self._state_dict\n        assert state is not None\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(f\"Shuffle should be {state['shuffle']}. Found {self.shuffle}\")\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The number of workers should be {state['world_size']}. Found {self.distributed_env.world_size}\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory should be {state['input_dir_path'] or state['input_dir_url']}. Found {self.input_dir}\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"The seed should be {state['seed']}. Found {self.seed}\")\n\n        if self.item_loader is not None and state[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state[\"item_loader\"])\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(f\"Drop last should be {state['drop_last']}. Found {self.drop_last}\")\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except OSError:\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_path = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n    os.makedirs(cache_path, exist_ok=True)\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception:\n            return None\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    hash_object = hashlib.sha256(input_dir.encode())\n    cache_dir = hash_object.hexdigest()\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    elif os.getenv(\"DATA_OPTIMIZER_CACHE_DIR_URL\"):\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR_URL\")\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n    try:\n        os.makedirs(cache_dir)\n    except Exception:\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    else:\n        cache_dir = _DEFAULT_CACHE_DIR\n\n    cache_dir = os.path.join(cache_dir, hashlib.sha256(input_dir.encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir)\n        return cache_dir\n    except Exception:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n    try:\n        os.makedirs(cache_dir)\n    except FileExistsError:\n        pass\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Get the cache dir\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\", _DEFAULT_CACHE_DIR)\n\n    # Create the cache dir\n    cache_dir = os.path.join(cache_dir, hashlib.sha256(input_dir.encode()).hexdigest())\n    os.makedirs(cache_dir, exist_ok=True)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(\n        _DEFAULT_CACHE_DIR,\n        hashlib.sha256(input_dir.encode()).hexdigest(),\n    )\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique directory name by hashing the input directory.\n    cache_dir = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, create the cache directory in a default location.\n    if os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\") is None:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n    # If the DATA_OPTIMIZER_CACHE_DIR environment variable is set, create the cache directory in a specified location.\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is not None:\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir)\n\n    # Create the cache directory if it doesn't exist.\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if not cache_dir:\n        cache_dir = _DEFAULT_CACHE_DIR\n\n    cache_dir = os.path.join(cache_dir, hashlib.sha256(input_dir.encode()).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception:\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except OSError:\n        pass\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    # We hash the input_dir to create a unique cache directory.\n    # Note: We could use the `input_dir` as is.\n    # However, it could lead to a lot of cache directories.\n    # We could also use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory.\n    # For example, we could use the `input_dir` as is, but we could add a prefix to the cache directory"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir_path = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if cache_dir_path is None:\n        cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir_path)\n        return cache_dir_path\n    except Exception:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        input_dir = \"\"\n\n    # If the input dir is a URL, we need to hash the URL\n    if input_dir.startswith(\"http\"):\n        input_dir = hashlib.sha256(input_dir.encode()).hexdigest()\n\n    cache_dir = os.path.join(\n        os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\", _DEFAULT_CACHE_DIR),\n        hashlib.sha256(input_dir.encode()).hexdigest(),\n    )\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # If the `DATA_OPTIMIZER_GLOBAL_RANK` env variable is set, it means that we are within a map or optimize call.\n    # In this case, let's not create a cache directory.\n    if os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\"):\n        return None\n\n    # If the `DATA_OPTIMIZER_CACHE_DIR` env variable is set, let's use it.\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if cache_dir is not None:\n        return cache_dir\n\n    # Let's create a cache directory based on the input directory.\n    hash_ = hashlib.sha256(input_dir.encode()).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash_)\n\n    try:\n        os.makedirs(cache_dir)\n    except OSError:\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Check if the cache directory is already set\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_path = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    else:\n        # Create a unique cache directory name\n        cache_path = _DEFAULT_CACHE_DIR + hashlib.sha256(input_dir.encode()).hexdigest()\n\n    try:\n        os.makedirs(cache_path)\n        return cache_path\n    except Exception:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        return None\n\n    hash_object = hashlib.sha256(input_dir.encode())\n    cache_dir = f\"litdata_cache_{hash_object.hexdigest()}\"\n\n    # If the cache dir is in the default path, let's try to create it in the default path\n    if os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\") is None and os.getenv(\"DATA_OPTIMIZER_GLOBAL_SIZE\") is None:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n    try:\n        os.makedirs(cache_dir)\n        return cache_dir\n    except OSError:\n        return None\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not parse.urlparse(remote_filepath).scheme == \"s3\":\n            raise ValueError(\n                f\"Remote file path {remote_filepath} is not an S3 URL. Please provide an S3 URL.\"\n            )\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\"s5cmd\", \"cp\", remote_filepath, local_filepath],\n                        capture_output=True,\n                        check=True,\n                    )\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not parse.urlparse(remote_filepath).scheme == \"s3\":\n            raise ValueError(\"Remote filepath is not an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(f\"{local_filepath}.lock\", timeout=10):\n            if self._s5cmd_available:\n                self._download_file_with_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_file_with_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if parse.urlparse(remote_filepath).scheme != \"s3\":\n            raise ValueError(f\"remote_filepath must be an S3 URL, got {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(f\"{local_filepath}.lock\", timeout=10):\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\"s5cmd\", \"cp\", remote_filepath, local_filepath],\n                    check=True,\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                )\n            else:\n                self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if parse.urlparse(remote_filepath).scheme == \"s3\":\n            if not os.path.exists(local_filepath):\n                with FileLock(f\"{local_filepath}.lock\", timeout=10):\n                    if self._s5cmd_available:\n                        subprocess.run(\n                            [\n                                \"s5cmd\",\n                                \"cp\",\n                                remote_filepath,\n                                local_filepath,\n                            ],\n                            check=True,\n                        )\n                    else:\n                        self._client.download_file(remote_filepath, local_filepath)\n        else:\n            raise ValueError(\"Remote file path must use the 's3' scheme.\")\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Remote filepath {remote_filepath} is not an S3 URL.\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(f\"{local_filepath}.lock\", timeout=60):\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"cp\",\n                            remote_filepath,\n                            local_filepath,\n                        ],\n                        check=True,\n                    )\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not parse.urlparse(remote_filepath).scheme == \"s3\":\n            raise ValueError(\"remote_filepath must be an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock = FileLock(f\"{local_filepath}.lock\", timeout=10)\n\n        with lock:\n            if self._s5cmd_available:\n                self._download_file_with_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_file_with_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if parse.urlparse(remote_filepath).scheme != \"s3\":\n            raise ValueError(f\"Invalid remote file path: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = os.path.join(self._cache_dir, \".lock\")\n        with FileLock(lock_path, timeout=10):\n            if self._s5cmd_available:\n                self._download_with_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_with_boto(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not parse.urlparse(remote_filepath).scheme == \"s3\":\n            raise ValueError(f\"Remote filepath {remote_filepath} is not an S3 URL.\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    self._download_file_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_file_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        if parse.urlparse(remote_filepath).scheme != \"s3\":\n            raise ValueError(f\"Remote file path {remote_filepath} is not an S3 URL.\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Create a file lock to prevent multiple processes from downloading the same file simultaneously\n        file_lock = FileLock(f\"{local_filepath}.lock\", timeout=60)\n        with file_lock:\n            if self._s5cmd_available:\n                # Use s5cmd to download the file\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"cp\",\n                        remote_filepath,\n                        local_filepath,\n                    ],\n                    check=True,\n                )\n            else:\n                # Use boto3 to download the file\n                self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\n                f\"Invalid remote file path: {remote_filepath}. \"\n                f\"The remote file path must be an S3 URL with the 's3' scheme.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Use s5cmd if available\n        if self._s5cmd_available:\n            # Use s5cmd to download the file\n            s5cmd_command = f\"s5cmd cp {remote_filepath} {local_filepath}\"\n            subprocess.run(s5cmd_command, shell=True, check=True)\n        else:\n            # Use boto3 to download the file\n            self._client.download_file(\n                parsed_remote_filepath.netloc,\n                parsed_remote_filepath.path[1:],\n                local_filepath,\n            )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"Remote file path {remote_filepath} does not use the 's3' scheme.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket = parsed_url.netloc\n        key = parsed_url.path[1:]  # Remove leading '/'\n\n        lock_path = os.path.join(self._cache_dir, \".lock\")\n        with FileLock(lock_path, timeout=30):\n            if self._s5cmd_available:\n                self._download_file_with_s5cmd(bucket, key, local_filepath)\n            else:\n                self._download_file_with_boto3(bucket, key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"Remote file path {remote_filepath} does not use the 's3' scheme.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        # Use s5cmd if available\n        if self._s5cmd_available:\n            with FileLock(f\"{local_filepath}.lock\", timeout=10):\n                subprocess.run(\n                    [\"s5cmd\", \"--endpoint-url\", remote_filepath.split(\"/\")[2], \"cp\", remote_filepath, local_filepath],\n                    check=True,\n                )\n            return\n\n        # Use boto3 otherwise\n        with FileLock(f\"{local_filepath}.lock\", timeout=10):\n            self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the remote file path and check if it is an S3 URL\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\n                f\"Invalid S3 URL: {remote_filepath}. S3 URL must use the 's3' scheme.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            print(f\"File already exists: {local_filepath}\")\n            return\n\n        # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath, timeout=60):\n            # Check if the local file already exists after acquiring the lock\n            if os.path.exists(local_filepath):\n                print(f\"File already exists: {local_filepath}\")\n                return\n\n            # Download the file using either s5cmd or boto3\n            if self._s5cmd_available:\n                # Use s5cmd to download the file\n                s5cmd_command = f\"s5cmd cp {remote_filepath} {local_filepath}\"\n                subprocess.run(s5cmd_command, shell=True, check=True)\n            else:\n                # Use boto3 to download the file\n                self._client.download_file(\n                    parsed_remote_filepath.netloc,\n                    parsed_remote_filepath.path,\n                    local_filepath,\n                )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the remote file path to extract the scheme, netloc, and path\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        scheme = parsed_remote_filepath.scheme\n        netloc = parsed_remote_filepath.netloc\n        path = parsed_remote_filepath.path\n\n        # Check if the remote file path is an S3 URL\n        if scheme != \"s3\":\n            raise ValueError(\n                \"Remote file path must be an S3 URL with the 's3' scheme.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Use s5cmd if available\n        if self._s5cmd_available:\n            # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously\n            with FileLock(f\"{local_filepath}.lock\", timeout=10):\n                # Download the file using s5cmd\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"--endpoint-url\",\n                        f\"https://{netloc}\",\n                        \"cp\",\n                        remote_filepath,\n                        local_filepath,\n                    ],\n                    check=True,\n                )\n        else:\n            # Acquire a file lock to prevent multiple processes from downloading the same file simultaneously\n            with FileLock(f\"{local_filepath}.lock\", timeout=10):\n                # Download the file using boto3\n                self._client.download_file(netloc, path, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        if parse.urlparse(remote_filepath).scheme != \"s3\":\n            raise ValueError(\n                f\"Remote file path {remote_filepath} is not an S3 URL. Please provide a valid S3 URL.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Create a file lock to prevent multiple processes from downloading the same file simultaneously\n        lock_path = os.path.join(os.path.dirname(local_filepath), \".lock\")\n        with FileLock(lock_path, timeout=10):\n            # Check if the local file already exists after acquiring the file lock\n            if os.path.exists(local_filepath):\n                return\n\n            # Download the file using either s5cmd or boto3\n            if self._s5cmd_available:\n                # Use s5cmd to download the file\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"cp\",\n                        \"--endpoint-url\",\n                        self._client.endpoint_url,\n                        \"--no-sign-request\",\n                        remote_filepath,\n                        local_filepath,\n                    ],\n                    check=True,\n                )\n            else:\n                # Use boto3 to download the file\n                self._client.download_file(\n                    remote_filepath.replace(\"s3://\", \"\"), local_filepath\n                )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if parse.urlparse(remote_filepath).scheme != \"s3\":\n            raise ValueError(f\"Remote file path must be an S3 URL, got {remote_filepath}\")\n\n        if not os.path.exists(local_filepath):\n            if self._s5cmd_available:\n                with FileLock(f\"{local_filepath}.lock\", timeout=10):\n                    self._download_file_with_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_file_with_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the remote file path into its components\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n\n        # Check if the remote file path uses the \"s3\" scheme\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Invalid remote file path: {remote_filepath}\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Create the parent directory of the local file if it does not exist\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        # Create a file lock to prevent multiple processes from downloading the same file simultaneously\n        lock_filename = os.path.join(\n            self._cache_dir, f\".lock-{os.path.basename(local_filepath)}\"\n        )\n        lock = FileLock(lock_filename, timeout=300)\n        with lock:\n            # If s5cmd is available, use it to download the file\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"cp\",\n                        remote_filepath,\n                        local_filepath,\n                    ],\n                    check=True,\n                )\n            # Otherwise, use boto3 to download the file\n            else:\n                self._client.download_file(\n                    parsed_remote_filepath.netloc,\n                    parsed_remote_filepath.path.lstrip(\"/\"),\n                    local_filepath,\n                )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the S3 URL and check if the local file already exists\n        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Invalid S3 URL: {remote_filepath}\")\n        if os.path.exists(local_filepath):\n            return\n\n        # Attempt to download the file using s5cmd or boto3\n        if self._s5cmd_available:\n            try:\n                # Use s5cmd to download the file\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"--endpoint-url\",\n                        parsed_url.netloc,\n                        \"cp\",\n                        remote_filepath,\n                        local_filepath,\n                    ],\n                    check=True,\n                )\n            except subprocess.CalledProcessError as e:\n                raise ValueError(f\"Failed to download file: {e}\")\n        else:\n            # Use boto3 to download the file\n            self._client.download_file(\n                parsed_url.netloc, parsed_url.path[1:], local_filepath\n            )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not os.path.exists(local_filepath):\n            remote_url = parse.urlparse(remote_filepath)\n            if remote_url.scheme != \"s3\":\n                raise ValueError(\n                    f\"remote_filepath {remote_filepath} must be an S3 URL\"\n                )\n\n            with FileLock(f\"{local_filepath}.lock\", timeout=10):\n                if self._s5cmd_available:\n                    self._download_with_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_with_boto(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"Invalid remote file path: {remote_filepath}\")\n\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket_name = parsed_url.netloc\n        key = parsed_url.path.lstrip(\"/\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(f\"{local_filepath}.lock\", timeout=60):\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\"s5cmd\", \"--no-sign-request\", \"cp\", remote_filepath, local_filepath],\n                    check=True,\n                )\n            else:\n                self._client.download_file(bucket_name, key, local_filepath)\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = [[] for _ in range(num_workers)]\n    intervals_per_worker = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        chunks_per_worker[i % num_workers].append(chunk_index)\n        intervals_per_worker[i % num_workers].append(chunk_interval)\n\n    return chunks_per_worker, intervals_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = []\n    intervals_per_worker = []\n    for i in range(num_workers):\n        chunks_per_worker.append([])\n        intervals_per_worker.append([])\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        chunks_per_worker[worker_index].append(chunk_index)\n        intervals_per_worker[worker_index].append(chunk_interval)\n\n    return chunks_per_worker, intervals_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = chunks_replica[::num_workers]\n    intervals_per_worker = intervals_replica[::num_workers]\n\n    workers_chunks = []\n    workers_intervals = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_per_worker, intervals_per_worker)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        workers_chunks.append(chunk_index)\n        workers_intervals.append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks_per_worker = len(chunks_replica) // num_workers\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i in range(num_workers):\n        for j in range(num_chunks_per_worker):\n            index = i * num_chunks_per_worker + j\n            workers_chunks[i].append(chunks_replica[index])\n            workers_intervals[i].append(intervals_replica[index])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks_per_worker = len(chunks_replica) // num_workers\n    chunks_per_worker = []\n    intervals_per_worker = []\n    for i in range(num_workers):\n        chunks_per_worker.append(chunks_replica[i * num_chunks_per_worker : (i + 1) * num_chunks_per_worker])\n        intervals_per_worker.append(intervals_replica[i * num_chunks_per_worker : (i + 1) * num_chunks_per_worker])\n    return chunks_per_worker, intervals_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = []\n    workers_intervals = []\n\n    for i in range(num_workers):\n        worker_chunks = []\n        worker_intervals = []\n        for j, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            if j % worker_env.world_size == i:\n                worker_chunks.append(chunk_index)\n                worker_intervals.append(chunk_interval)\n        workers_chunks.append(worker_chunks)\n        workers_intervals.append(worker_intervals)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks = len(chunks_replica)\n    chunks_per_worker = num_chunks // num_workers\n    intervals_per_worker = intervals_replica[:chunks_per_worker]\n\n    workers_chunks = []\n    workers_intervals = []\n\n    for i in range(num_workers):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        workers_chunks.append(chunks_replica[i * chunks_per_worker : (i + 1) * chunks_per_worker])\n        workers_intervals.append(intervals_replica[i * chunks_per_worker : (i + 1) * chunks_per_worker])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % num_workers\n        if worker_index == worker_env.rank:\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = []\n    workers_intervals = []\n    for i in range(num_workers):\n        workers_chunks.append([])\n        workers_intervals.append([])\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        workers_chunks[i % worker_env.world_size].append(chunk_index)\n        workers_intervals[i % worker_env.world_size].append(chunk_interval)\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = [[] for _ in range(num_workers)]\n    intervals_per_worker = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        chunks_per_worker[i % num_workers].append(chunk_index)\n        intervals_per_worker[i % num_workers].append(chunk_interval)\n\n    return chunks_per_worker, intervals_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks = len(chunks_replica)\n    num_chunks_per_worker = num_chunks // num_workers\n    num_chunks_per_worker_with_remainder = num_chunks % num_workers\n    num_chunks_per_worker_with_remainder_per_worker = num_chunks_per_worker_with_remainder // num_workers\n\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i in range(num_workers):\n        for j in range(num_chunks_per_worker):\n            if i % num_workers < num_chunks_per_worker_with_remainder:\n                workers_chunks[i].append(chunks_replica[j * num_chunks_per_worker_with_remainder_per_worker + i])\n                workers_intervals[i].append(intervals_replica[j * num_chunks_per_worker_with_remainder_per_worker + i])\n            else:\n                workers_chunks[i].append(chunks_replica[j * num_chunks_per_worker_with_remainder_per_worker + i + 1])\n                workers_intervals[i].append(intervals_replica[j * num_chunks_per_worker_with_remainder_per_worker + i + 1])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks = len(chunks_replica)\n    chunks_per_worker = num_chunks // num_workers\n    remainder = num_chunks % num_workers\n\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % num_workers\n\n        if worker_index == worker_env.rank:\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(interval)\n\n    for i, (chunk_index, interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % num_workers\n\n        if worker_index == worker_env.rank:\n            continue\n\n        if worker_env.rank < remainder:\n            if i % num_workers < chunks_per_worker + 1:\n                workers_chunks[worker_env.rank].append(chunk_index)\n                workers_intervals[worker_env.rank].append(interval)\n        else:\n            if i % num_workers < chunks_per_worker:\n                workers_chunks[worker_env.rank].append(chunk_index)\n                workers_intervals[worker_env.rank].append(interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks_per_worker = len(chunks_replica) // num_workers\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n    for i in range(len(chunks_replica)):\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunks_replica[i])\n        workers_intervals[worker_index].append(intervals_replica[i])\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        workers_chunks[i % num_workers].append(chunk_index)\n        workers_intervals[i % num_workers].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert num_workers == len(chunks_replica) == len(intervals_replica)\n\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_rank = i % num_workers\n        workers_chunks[worker_rank].append(chunk_index)\n        workers_intervals[worker_rank].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = chunks_replica // num_workers\n    intervals_per_worker = intervals_replica // num_workers\n\n    chunks_per_worker = chunks_per_worker.tolist()\n    intervals_per_worker = intervals_per_worker.tolist()\n\n    for i in range(worker_env.world_size):\n        if i % worker_env.world_size == worker_env.rank:\n            chunks_per_worker.append(chunks_replica[i])\n            intervals_per_worker.append(intervals_replica[i])\n\n    return chunks_per_worker, intervals_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of chunks is smaller than the number of workers.\n    if len(chunks_replica) < num_workers:\n        num_chunks = len(chunks_replica)\n        chunks_per_replica = [chunks_replica[i::num_chunks] for i in range(num_chunks)]\n        intervals_per_replica = [intervals_replica[i::num_chunks] for i in range(num_chunks)]\n    else:\n        num_chunks = len(chunks_replica)\n        chunks_per_replica = [[] for _ in range(num_workers)]\n        intervals_per_replica = [[] for _ in range(num_workers)]\n        for i, chunk_index in enumerate(chunks_replica):\n            chunks_per_replica[i % num_workers].append(chunk_index)\n            intervals_per_replica[i % num_workers].append(intervals_replica[i])\n\n    return chunks_per_replica, intervals_per_replica\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert len(chunks_replica) == len(intervals_replica)\n\n    # Distribute the chunks and intervals to the workers\n    chunks_per_workers = []\n    intervals_per_workers = []\n    for i in range(num_workers):\n        chunks_per_workers.append([])\n        intervals_per_workers.append([])\n        for j in range(len(chunks_replica)):\n            if j % num_workers == i:\n                chunks_per_workers[i].append(chunks_replica[j])\n                intervals_per_workers[i].append(intervals_replica[j])\n\n    return chunks_per_workers, intervals_per_workers\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Get the image's dimensions\n        width, height = item.size\n        # Get the image's mode\n        mode = item.mode\n        # Get the raw pixel data\n        data = item.tobytes()\n\n        # Create a bytes object to store the serialized data\n        serialized_data = b\"\"\n\n        # Add the image's dimensions to the serialized data\n        serialized_data += width.to_bytes(4, \"little\")\n        serialized_data += height.to_bytes(4, \"little\")\n\n        # Add the image's mode length to the serialized data\n        mode_length = len(mode).to_bytes(4, \"little\")\n        serialized_data += mode_length\n\n        # Add the image's mode to the serialized data\n        serialized_data += mode.encode(\"utf-8\")\n\n        # Add the image's raw pixel data to the serialized data\n        serialized_data += data\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"PNG\")\n            data = buffer.getvalue()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Serialize the image data\n        with io.BytesIO() as f:\n            item.save(f, format=item.format)\n            data = f.getvalue()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Get the mode and dimensions of the image\n        mode = item.mode\n        width, height = item.size\n\n        # Serialize the mode and dimensions into a bytes object\n        mode_bytes = mode.encode(\"utf-8\")\n        mode_length_bytes = np.array([len(mode_bytes)], dtype=np.uint32).tobytes()\n        width_bytes = np.array([width], dtype=np.uint32).tobytes()\n        height_bytes = np.array([height], dtype=np.uint32).tobytes()\n\n        # Serialize the image data into a bytes object\n        image_bytes = item.tobytes()\n\n        # Concatenate the mode length, mode, width, height, and image data into a single bytes object\n        serialized_data = mode_length_bytes + mode_bytes + width_bytes + height_bytes + image_bytes\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if isinstance(item, (JpegImageFile, PngImageFile)):\n            data = item.tobytes()\n        else:\n            with io.BytesIO() as f:\n                item.save(f, format=item.format)\n                data = f.getvalue()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # get the image mode\n        mode = item.mode\n\n        # get the image dimensions\n        width, height = item.size\n\n        # get the raw pixel data\n        data = item.tobytes()\n\n        # serialize the image mode\n        mode_bytes = mode.encode(\"utf-8\")\n\n        # serialize the image dimensions\n        width_bytes = width.to_bytes(4, \"big\")\n        height_bytes = height.to_bytes(4, \"big\")\n\n        # serialize the image data\n        data_bytes = data\n\n        # serialize the image mode length\n        mode_len_bytes = len(mode_bytes).to_bytes(4, \"big\")\n\n        # combine the serialized data into a single bytes object\n        serialized_data = width_bytes + height_bytes + mode_len_bytes + mode_bytes + data_bytes\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Convert the PIL Image to a bytes object\n        buffer = io.BytesIO()\n        item.save(buffer, format=item.format)\n        data = buffer.getvalue()\n\n        # Serialize the PIL Image\n        data = (\n            item.width.to_bytes(4, \"little\")\n            + item.height.to_bytes(4, \"little\")\n            + len(item.mode).to_bytes(1, \"little\")\n            + item.mode.encode(\"utf-8\")\n            + data\n        )\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Convert the PIL Image object to a bytes object containing the image's dimensions, mode, and raw pixel data.\n        buffer = io.BytesIO()\n        item.save(buffer, format=item.format)\n        data = buffer.getvalue()\n\n        # Return the serialized data along with None, as a tuple.\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Extract the image's dimensions and mode\n        width, height = item.size\n        mode = item.mode\n\n        # Convert the dimensions and mode to bytes\n        width_bytes = width.to_bytes(4, \"big\")\n        height_bytes = height.to_bytes(4, \"big\")\n        mode_bytes = len(mode).to_bytes(4, \"big\")\n        mode_bytes += mode.encode(\"utf-8\")\n\n        # Get the raw pixel data\n        data = item.tobytes()\n\n        # Serialize the data\n        serialized_data = width_bytes + height_bytes + mode_bytes + data\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if isinstance(item, (JpegImageFile, PngImageFile)):\n            data = item.tobytes()\n        else:\n            with io.BytesIO() as f:\n                item.save(f, format=item.format)\n                data = f.getvalue()\n        width, height = item.size\n        mode = item.mode.encode()\n        return b\"\".join([width.to_bytes(4, \"big\"), height.to_bytes(4, \"big\"), len(mode).to_bytes(4, \"big\"), mode, data]), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        img_bytes = io.BytesIO()\n        item.save(img_bytes, format=item.format)\n        img_bytes = img_bytes.getvalue()\n        img_bytes = b\" \".join([b\"%d\" % item.width, b\"%d\" % item.height, img_bytes])\n        return img_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Create a BytesIO object to store the serialized data\n        buffer = io.BytesIO()\n\n        # Save the PIL Image object to the BytesIO object\n        item.save(buffer, format=item.format)\n\n        # Read the serialized data from the BytesIO object\n        serialized_data = buffer.getvalue()\n\n        # Get the image's dimensions\n        width, height = item.size\n\n        # Get the image's mode\n        mode = item.mode\n\n        # Serialize the image's dimensions, mode length, mode, and raw pixel data\n        serialized_data = (\n            width.to_bytes(4, \"little\")\n            + height.to_bytes(4, \"little\")\n            + len(mode).to_bytes(1, \"little\")\n            + mode.encode(\"utf-8\")\n            + serialized_data\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Extract the image's dimensions and mode\n        width, height = item.size\n        mode = item.mode\n\n        # Serialize the image's dimensions, mode length, and mode\n        serialized_data = b\"\"\n        serialized_data += width.to_bytes(4, \"big\")\n        serialized_data += height.to_bytes(4, \"big\")\n        mode_length = len(mode).to_bytes(4, \"big\")\n        serialized_data += mode_length\n        serialized_data += mode.encode(\"utf-8\")\n\n        # Serialize the image's raw pixel data\n        if mode in [\"L\", \"LA\", \"P\", \"RGB\", \"RGBA\"]:\n            serialized_data += item.tobytes()\n        elif mode == \"I\":\n            serialized_data += item.tobytes()\n            serialized_data += item.tobytes()\n        elif mode == \"F\":\n            serialized_data += item.tobytes()\n            serialized_data += item.tobytes()\n            serialized_data += item.tobytes()\n            serialized_data += item.tobytes()\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Open the image file in binary mode\n        with io.BytesIO() as img_bytes:\n            # Save the image to the file object\n            item.save(img_bytes, format=item.format)\n            # Get the image data as a bytes object\n            img_data = img_bytes.getvalue()\n\n        # Get the image's dimensions and mode\n        width, height = item.size\n        mode = item.mode\n\n        # Serialize the image's dimensions, mode, and raw pixel data\n        serialized_data = (\n            width.to_bytes(4, \"little\")\n            + height.to_bytes(4, \"little\")\n            + len(mode).to_bytes(4, \"little\")\n            + mode.encode(\"utf-8\")\n            + img_data\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Convert PIL Image to bytes\n        with io.BytesIO() as f:\n            item.save(f, format=item.format)\n            data = f.getvalue()\n\n        # Serialize PIL Image dimensions, mode, and raw pixel data\n        serialized_data = b\"\".join(\n            [\n                np.array(item.size[0], dtype=np.uint16).tobytes(),\n                np.array(item.size[1], dtype=np.uint16).tobytes(),\n                np.array(len(item.mode), dtype=np.uint16).tobytes(),\n                item.mode.encode(\"utf-8\"),\n                data,\n            ]\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Encode image mode as bytes\n        mode_bytes = len(item.mode).to_bytes(1, \"little\") + item.mode.encode(\"utf-8\")\n\n        # Encode image dimensions as bytes\n        width, height = item.size\n        dimensions_bytes = width.to_bytes(4, \"little\") + height.to_bytes(4, \"little\")\n\n        # Encode image data as bytes\n        data_bytes = item.tobytes()\n\n        # Concatenate all bytes objects into a single bytes object\n        serialized_data = mode_bytes + dimensions_bytes + data_bytes\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Get the image's dimensions\n        width, height = item.size\n\n        # Get the image's mode\n        mode = item.mode\n\n        # Get the image's raw pixel data\n        pixel_data = item.tobytes()\n\n        # Convert the mode to bytes\n        mode_bytes = mode.encode(\"utf-8\")\n\n        # Convert the mode length to bytes\n        mode_len_bytes = len(mode).to_bytes(4, \"little\")\n\n        # Convert the width to bytes\n        width_bytes = width.to_bytes(4, \"little\")\n\n        # Convert the height to bytes\n        height_bytes = height.to_bytes(4, \"little\")\n\n        # Create the serialized data as a bytes object\n        serialized_data = b\"\".join(\n            [width_bytes, height_bytes, mode_len_bytes, mode_bytes, pixel_data]\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if item is None:\n            return None, None\n\n        if not isinstance(item, (JpegImageFile, PngImageFile, WebPImageFile, GifImageFile)):\n            raise ValueError(\"Only JpegImageFile, PngImageFile, WebPImageFile, GifImageFile are supported.\")\n\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=item.format)\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Convert the image to a bytes object\n        buffer = io.BytesIO()\n        item.save(buffer, format=item.format)\n        buffer.seek(0)\n        data = buffer.read()\n\n        # Get the image mode\n        mode = item.mode\n\n        # Return the serialized data\n        return data, mode\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename is not None and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            f = io.BytesIO()\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            if item.filename and os.path.isfile(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                with io.BytesIO() as f:\n                    item.save(f, format=\"JPEG\")\n                    return f.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer only supports Image, not {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            if isinstance(item, JpegImageFile) and item.filename is not None and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n                return data, None\n            else:\n                with io.BytesIO() as f:\n                    item.save(f, format=\"JPEG\")\n                    data = f.getvalue()\n                return data, None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n            else:\n                data = item.tobytes()\n        elif isinstance(item, Image.Image):\n            data = item.tobytes(\"jpeg\")\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.isfile(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise TypeError(f\"JPEG image {item} has no filename\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"JPEG image {item} is not an instance of Image\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename is not None and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer can only serialize JPEG images, got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            if isinstance(item, JpegImageFile) and item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                with io.BytesIO() as f:\n                    item.save(f, format=\"JPEG\")\n                    return f.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer can only serialize Image objects, got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise TypeError(\"Cannot serialize a JpegImageFile without a filename\")\n\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n\n        else:\n            raise TypeError(\"Cannot serialize a non-image type\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.isfile(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n            else:\n                raise TypeError(f\"Cannot read JPEG from {item.filename}\")\n        else:\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            data = buffer.getvalue()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise TypeError(f\"JPEG image {item.filename} does not exist.\")\n\n        if _TORCH_VISION_AVAILABLE:\n            if isinstance(item, torch.Tensor):\n                item = pil_to_tensor(item)\n            return decode_jpeg(item).numpy().tobytes(), None\n\n        if isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n\n        raise TypeError(f\"JPEG image {item} is not supported.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename is not None and os.path.isfile(item.filename):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n            return data, None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                data = f.getvalue()\n            return data, None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise TypeError(f\"JPEG file has no filename or does not exist: {item}\")\n        else:\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, \"JPEG\")\n                return f.getvalue(), None\n        else:\n            raise TypeError(f\"JPEGSerializer can only serialize PIL Image, got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename is not None and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(f\"Cannot read {item} from memory.\")\n\n        if isinstance(item, Image.Image):\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n\n        raise TypeError(f\"Cannot serialize {item} to JPEG.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename is not None and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n                return data, None\n            else:\n                raise TypeError(f\"JPEG file {item.filename} does not exist\")\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                data = f.getvalue()\n            return data, None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = getattr(item, \"filename\", None)\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                item = pil_to_tensor(item)\n        elif isinstance(item, Image.Image):\n            item = pil_to_tensor(item)\n        else:\n            raise TypeError(f\"JPEGSerializer can only serialize PIL.Image.Image and PIL.JpegImagePlugin.JpegImageFile. Got {type(item)}\")\n        return item.numpy().tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, Image.Image):\n            if isinstance(item, JpegImageFile):\n                if item.filename and os.path.exists(item.filename):\n                    with open(item.filename, \"rb\") as f:\n                        return f.read(), None\n                else:\n                    raise TypeError(\n                        f\"Cannot serialize JPEG image {item} because it does not have a defined filename or the file does not exist.\"\n                    )\n            else:\n                with io.BytesIO() as f:\n                    item.save(f, format=\"JPEG\")\n                    return f.getvalue(), None\n        else:\n            raise TypeError(f\"Cannot serialize image {item} because it is not an instance of Image class or its subclasses.\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        item = Image.frombytes(mode, (width, height), raw)\n        return item\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        # Extract the width, height, and mode from the beginning of the data\n        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n\n        # Reconstruct the image from the remaining data\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_size = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + shape_size * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_size = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + shape_size * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_size = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + shape_size * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * num_dims\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype, count=np.prod(shape)).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_len = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx = idx2\n        shape = []\n        for _ in range(shape_len):\n            idx2 = idx + 4\n            shape.append(np.frombuffer(data[idx:idx2], np.uint32)[0])\n            idx = idx2\n        raw = data[idx:]\n        return torch.frombuffer(raw, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + num_dims * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype, count=np.prod(shape)).view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        ndims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * ndims\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype, count=np.prod(shape)).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n\n        shape_size = np.frombuffer(data[:4], np.uint32)[0]\n        data = data[4:]\n\n        shape = np.frombuffer(data[: shape_size * 4], np.uint32)\n        data = data[shape_size * 4 :]\n\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n\n        shape_size = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        data = data[4:]\n\n        shape = np.frombuffer(data[: shape_size * 4], dtype=np.uint32)\n        data = data[shape_size * 4 :]\n\n        return torch.from_buffer(data, dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * num_dims\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        idx4 = idx3 + shape.nbytes\n        raw = data[idx3:idx4]\n        return torch.frombuffer(raw, dtype=dtype, count=np.prod(shape)).view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_size = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + shape_size * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32).tolist()\n        raw = data[idx3:]\n        return torch.frombuffer(raw, dtype=dtype, count=np.prod(shape)).view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_len = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + shape_len * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        idx4 = idx3 + shape.nbytes\n        raw = data[idx3:idx4]\n        return torch.frombuffer(raw, dtype=dtype, count=shape.prod()).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        ndim = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = np.frombuffer(data[idx : idx + 4 * ndim], np.uint32)\n        idx += 4 * ndim\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        tensor = np.frombuffer(data[idx:], dtype=dtype)\n        tensor = tensor.reshape(shape)\n        return torch.from_numpy(tensor)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        data = data[4:]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        data = data[4:]\n        shape = np.frombuffer(data[: shape_len * 4], dtype=np.uint32).tolist()\n        data = data[shape_len * 4 :]\n        return torch.from_buffer(data, dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n\n        shape_len = np.frombuffer(data[:4], np.uint32)[0]\n        data = data[4:]\n        shape = np.frombuffer(data[: shape_len * 4], np.uint32)\n        data = data[shape_len * 4 :]\n        return torch.frombuffer(data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], \"little\")\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        ndim = int.from_bytes(data[idx:idx2], \"little\")\n        idx3 = idx2 + 4 * ndim\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        raw = data[idx3:]\n        return torch.from_buffer(raw, dtype=dtype, shape=shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n\n        idx = 4\n        shape_size = np.frombuffer(data[idx : idx + 4], dtype=np.uint32)[0]\n        idx += 4\n        shape = np.frombuffer(data[idx : idx + 4 * shape_size], dtype=np.uint32)\n        idx += 4 * shape_size\n        tensor_bytes = data[idx:]\n        return torch.from_numpy(np.frombuffer(tensor_bytes, dtype=dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # The first 4 bytes represent the data type index\n        dtype_index = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_index]\n\n        # The next 4 bytes represent the number of dimensions\n        num_dims = np.frombuffer(data[4:8], dtype=np.uint32)[0]\n\n        # The next 4*num_dims bytes represent the shape of the tensor\n        shape = np.frombuffer(data[8 : 8 + 4 * num_dims], dtype=np.uint32)\n\n        # The remaining bytes represent the raw tensor data\n        raw_data = data[8 + 4 * num_dims :]\n\n        # Reconstruct the tensor from the raw data and the shape\n        return torch.frombuffer(raw_data, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # Extract the dtype index from the first 4 bytes of the data\n        dtype_index = int.from_bytes(data[:4], byteorder=\"little\")\n        # Extract the number of dimensions from the next 4 bytes of the data\n        num_dims = int.from_bytes(data[4:8], byteorder=\"little\")\n        # Extract the shape information from the next 4*num_dims bytes of the data\n        shape = []\n        for i in range(num_dims):\n            shape.append(int.from_bytes(data[8 + i * 4 : 12 + i * 4], byteorder=\"little\"))\n        # Extract the tensor data from the remaining bytes\n        tensor_data = data[8 + num_dims * 4 :]\n        # Reconstruct the tensor from the data type index, shape, and raw data\n        dtype = _TORCH_DTYPES_MAPPING[dtype_index]\n        tensor = torch.frombuffer(tensor_data, dtype=dtype).reshape(shape)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # Extract the dtype indice and the shape from the data\n        dtype_indice, shape_len = np.frombuffer(data[:2 * 4], np.uint32)\n\n        # Extract the shape of the tensor\n        shape_data = data[2 * 4 : 2 * 4 + shape_len * 4]\n        shape = np.frombuffer(shape_data, np.uint32)\n\n        # Extract the raw data of the tensor\n        tensor_data = data[2 * 4 + shape_len * 4 :]\n\n        # Reconstruct the tensor from the raw data\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        tensor = torch.frombuffer(tensor_data, dtype=dtype)\n        tensor = tensor.reshape(shape)\n\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.numpy()\n        return pickle.dumps((dtype, shape, raw)), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        dtype_idx = self._dtype_to_indices[dtype]\n        return np.array([dtype_idx, *shape], dtype=np.uint32).tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.int32)\n        data = item.numpy().tobytes()\n        return np.array([dtype_index], dtype=np.int32).tobytes() + shape.tobytes() + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype_index, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.cpu().numpy().tobytes()\n        ints = np.array([dtype_index, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.int32)\n        raw = item.cpu().numpy().tobytes()\n        return np.array([dtype_idx], dtype=np.int32).tobytes() + shape.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.numpy()\n        header = np.array([dtype_index, *shape], dtype=np.uint32)\n        return header.tobytes() + raw.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.contiguous().view(-1).numpy()\n        dtype_idx = self._dtype_to_indices[dtype]\n        dtype_idx = np.array([dtype_idx], dtype=np.uint8)\n        shape = np.array(shape, dtype=np.uint32)\n        return dtype_idx.tobytes() + shape.tobytes() + raw.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        data = item.numpy().tobytes()\n        dtype_idx = self._dtype_to_indices[dtype]\n        dtype_bytes = np.array([dtype_idx], dtype=np.uint8).tobytes()\n        shape_bytes = np.array(shape, dtype=np.uint32).tobytes()\n        return dtype_bytes + shape_bytes + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        data = item.numpy().tobytes()\n        return np.array([dtype_idx], dtype=np.uint8).tobytes() + shape.tobytes() + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.contiguous().view(-1).numpy()\n        dtype_idx = self._dtype_to_indices[dtype]\n        ints = np.array([dtype_idx, *shape], dtype=np.uint32)\n        return ints.tobytes() + raw.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        dtype_index = self._dtype_to_indices[dtype]\n        dtype_bytes = np.array(dtype_index, np.uint8).tobytes()\n        shape_bytes = np.array(shape, np.uint32).tobytes()\n        return dtype_bytes + shape_bytes + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.cpu().numpy().tobytes()\n        ints = np.array([dtype_idx, *shape], dtype=np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        return shape.tobytes() + dtype.to_bytes(1, \"little\") + item.cpu().numpy().tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.cpu().numpy()\n        raw = raw.tobytes()\n        return (\n            np.array([dtype_index] + list(shape), dtype=np.uint32).tobytes() + raw,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        data = item.numpy()\n        data = data.tobytes()\n\n        header = np.array([dtype, *shape], dtype=np.uint32)\n        header = header.tobytes()\n\n        return header + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.cpu().numpy().tobytes()\n        dtype_idx = self._dtype_to_indices[dtype]\n        dtype_idx = np.array([dtype_idx], dtype=np.uint8)\n        shape = np.array(shape, dtype=np.uint32)\n        return dtype_idx.tobytes() + shape.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.cpu().numpy().tobytes()\n        ints = np.array([dtype, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # extract dtype, shape, and raw data\n        dtype = item.dtype\n        shape = item.shape\n        raw = item.contiguous().view(-1).numpy()\n\n        # convert dtype to index\n        dtype_index = self._dtype_to_indices[dtype]\n\n        # convert shape to bytes\n        shape_bytes = pickle.dumps(shape)\n\n        # convert raw data to bytes\n        raw_bytes = raw.tobytes()\n\n        # create header\n        header = np.array([dtype_index, len(shape_bytes), len(raw_bytes)], dtype=np.uint32)\n        header_bytes = header.tobytes()\n\n        return header_bytes + shape_bytes + raw_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.int32)\n        data = item.cpu().numpy()\n        data = data.tobytes()\n        return shape.tobytes() + data, dtype_index\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG image using torchvision\n                return decode_jpeg(data)\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL to decode the data\n                pass\n\n        # If torchvision is not available or decoding fails, use PIL to decode the data\n        item = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # If torchvision is available, convert the PIL image to a PyTorch tensor\n            return pil_to_tensor(item)\n\n        return item\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG using torchvision\n                image = decode_jpeg(torch.from_numpy(np.frombuffer(data, dtype=np.uint8)))\n                # Convert the PIL image to a PyTorch tensor\n                image = pil_to_tensor(image)\n                return image\n            except RuntimeError:\n                # If the decoding fails due to a runtime error (e.g., the data is actually a PNG with a JPEG extension), fall back to using PIL to deserialize the data\n                pass\n\n        # If torchvision is not available or the decoding fails, use PIL to deserialize the data\n        image = Image.open(io.BytesIO(data))\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data, \"RGB\")\n            except RuntimeError:\n                pass\n\n        # if torchvision is not available or the decoding fails, use PIL to deserialize the data\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                img = decode_jpeg(torch.from_numpy(np.frombuffer(data, np.uint8)))\n                if isinstance(img, torch.Tensor):\n                    return img\n                return pil_to_tensor(img)\n            except RuntimeError:\n                pass\n        return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG image using torchvision\n                img = decode_jpeg(data, channels=3)\n                # Convert the PIL image to a PyTorch tensor\n                img = pil_to_tensor(img)\n                return img\n            except RuntimeError:\n                # If the decoding fails, fall back to using PIL\n                pass\n\n        # If torchvision is not available or the decoding fails, use PIL to deserialize the data\n        img = Image.open(io.BytesIO(data))\n        return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data, mode=\"RGB\", device=\"cpu\")\n            except RuntimeError:\n                pass\n\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG image using torchvision\n                decoded_image = decode_jpeg(data)\n                # If the decoding is successful, return the decoded image\n                return decoded_image\n            except RuntimeError:\n                # If the decoding fails, fall back to using PIL to deserialize the data\n                pass\n\n        # If torchvision is not available or the decoding fails, use PIL to deserialize the data\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            # If torchvision is available, convert the PIL image to a PyTorch tensor and return it\n            return pil_to_tensor(image)\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data, \"RGB\", 100)\n            except RuntimeError:\n                pass\n\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # decode the data as a JPEG image using torchvision\n                return decode_jpeg(torch.from_numpy(np.frombuffer(data, dtype=np.uint8)))\n            except RuntimeError:\n                # if the decoding fails, fall back to using PIL to deserialize the data\n                item = Image.open(io.BytesIO(data))\n                # if torchvision is available, convert the PIL image to a PyTorch tensor\n                if _TORCH_VISION_AVAILABLE:\n                    item = pil_to_tensor(item)\n                return item\n\n        # if torchvision is not available, use PIL to deserialize the data\n        item = Image.open(io.BytesIO(data))\n        return item\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the image using torchvision\n                image = decode_jpeg(data)\n                # Convert the PIL image to a PyTorch tensor\n                image = pil_to_tensor(image)\n                return image\n            except RuntimeError:\n                # If the decoding fails, fall back to PIL\n                pass\n\n        # If torchvision is not available or the decoding fails, use PIL to deserialize the data\n        image = Image.open(io.BytesIO(data))\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # attempt to decode the data as a JPEG image using torchvision\n                jpeg_image = decode_jpeg(torch.from_bytes(data))\n                # convert the PIL image to a PyTorch tensor\n                jpeg_image = pil_to_tensor(jpeg_image)\n                return jpeg_image\n            except RuntimeError:\n                # if the decoding fails, fall back to using PIL\n                pass\n\n        # if torchvision is unavailable or the decoding fails, use PIL to deserialize the data\n        return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG using torchvision\n                return decode_jpeg(data, mode=\"RGB\", device=\"cpu\")\n            except RuntimeError:\n                # If decoding fails, fall back to PIL\n                pass\n\n        # If torchvision is not available or decoding fails, use PIL to deserialize the data\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                image = decode_jpeg(data)\n                return pil_to_tensor(image)\n            except RuntimeError as e:\n                pass\n\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data, \"RGB\")\n            except RuntimeError as e:\n                # if torchvision fails to decode the image, fall back to PIL\n                if \"JPEG\" in str(e):\n                    return pil_to_tensor(Image.open(io.BytesIO(data)))\n                else:\n                    raise e\n\n        # if torchvision is not available, fall back to PIL\n        return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # decode the image as a JPEG using torchvision\n                image = decode_jpeg(data)\n\n                # convert the PIL image to a PyTorch tensor\n                image = pil_to_tensor(image)\n\n                return image\n            except RuntimeError:\n                # if the decoding fails due to a runtime error, fall back to using PIL\n                pass\n\n        # if torchvision is not available, or the decoding fails due to a runtime error, use PIL to deserialize the data\n        image = Image.open(io.BytesIO(data))\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the JPEG image using torchvision's decode_jpeg function.\n                return decode_jpeg(torch.from_numpy(np.frombuffer(data, dtype=np.uint8)))\n            except RuntimeError:\n                # If the decoding fails, fall back to using PIL to deserialize the data.\n                pass\n\n        # If torchvision is not available or the decoding fails, use PIL to deserialize the data.\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # try to decode the image with torchvision\n                decoded_image = decode_jpeg(data, mode=\"RGB\")\n                # convert the PIL image to a PyTorch tensor\n                return pil_to_tensor(decoded_image)\n            except RuntimeError:\n                # if the decoding fails, fall back to using PIL\n                pass\n        # use PIL to deserialize the data\n        return PILSerializer.deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG image using torchvision.\n                # If it fails, it will raise a RuntimeError.\n                image = decode_jpeg(data)\n                if isinstance(image, torch.Tensor):\n                    # If the image is already a torch.Tensor, return it directly.\n                    return image\n                # If the image is a PIL Image, convert it to a torch.Tensor.\n                return pil_to_tensor(image)\n            except RuntimeError:\n                # If the decoding failed, fall back to PIL.\n                pass\n\n        # If torchvision is not available or the decoding failed, use PIL to deserialize the data.\n        image = Image.open(io.BytesIO(data))\n        if isinstance(image, JpegImageFile):\n            return image\n        # If the image is a PIL Image, convert it to a torch.Tensor.\n        return pil_to_tensor(image)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # try to decode the image as a JPEG using torchvision\n                decoded_image = decode_jpeg(data, mode=\"RGB\")\n                # convert the PIL image to a PyTorch tensor\n                decoded_image = pil_to_tensor(decoded_image)\n                return decoded_image\n            except RuntimeError as e:\n                # if decoding fails due to a runtime error, fall back to using PIL\n                print(\n                    \"Caught RuntimeError while decoding JPEG image with torchvision. \"\n                    \"Attempting to decode using PIL instead. Error: \",\n                    e,\n                )\n\n        # decode the image using PIL\n        decoded_image = Image.open(io.BytesIO(data))\n        return decoded_image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG image using torchvision\n                decoded_jpeg = decode_jpeg(torch.from_numpy(np.frombuffer(data, dtype=np.uint8)))\n                # If the decoding is successful, return the decoded JPEG image\n                return decoded_jpeg\n            except RuntimeError:\n                # If the decoding fails due to a runtime error (e.g., the data is actually a PNG with a JPEG extension), fall back to using PIL\n                pass\n\n        # If torchvision is unavailable or the decoding fails, use PIL to deserialize the data\n        item = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            # If torchvision is available, convert the PIL image to a PyTorch tensor and return it\n            return pil_to_tensor(item)\n        else:\n            # If torchvision is unavailable, return the PIL image\n            return item\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = [item.numpy().tobytes(order=\"C\")]\n        return b\"\".join(data), f\"no_header_tensor:{self._dtype_to_indices[item.dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[item.dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data format is not defined. HINT: Use the setup method.\")\n        data = [item.numpy().tobytes(order=\"C\")]\n        return b\"\".join(data), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer requires the setup method to be called before serialization.\")\n        data = [item.numpy().tobytes(order=\"C\")]\n        return b\"\".join(data), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [item.numpy().tobytes(order=\"C\")]\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer requires the data format to be set before serialization.\")\n\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = []\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type for the tensor is not defined.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer has no dtype defined. Please use setup() to define it.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not defined. HINT: Set the data type using setup(data_format) method.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = np.array(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype.name]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes())\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state[\"dataset\"] = self.dataset.state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state.update(\n            {\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        )\n\n        if isinstance(self.dataset, StreamingDataset):\n            state.update({\"dataset\": self.dataset.state_dict()})\n        else:\n            state.update({\"dataset\": self.dataset.state_dict()})\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"][\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            state = {\n                \"dataset\": {\n                    \"dataset\": self.dataset.state_dict(),\n                    \"num_samples_yielded\": self._num_samples_yielded_combined,\n                },\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"dataset\"] = {\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            state = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = self.dataset.state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = (\n            self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined\n        )\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = super().state_dict()\n\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required to deserialize video data. Please install it with `pip install torchvision`.\"\n            )\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required to deserialize video data. Please install it with `pip install av`.\"\n            )\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required to deserialize video data. Please install it with 'pip install torchvision'.\"\n            )\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required to deserialize video data. Please install it with 'pip install av'.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torch.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is required to deserialize video data.\")\n\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is required to deserialize video data.\")\n\n        with tempfile.TemporaryFile() as tmp_file:\n            tmp_file.write(data)\n            tmp_file.seek(0)\n            return torchvision.io.read_video(tmp_file)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is not installed. Please install it with `pip install torchvision`.\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is not installed. Please install it with `pip install av`.\")\n\n        with tempfile.TemporaryFile() as f:\n            f.write(data)\n            f.seek(0)\n            return torch.read_video(f)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"torchvision is required to deserialize video data. Please install it with `pip install torchvision`\"\n            )\n\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"av is required to deserialize video data. Please install it with `pip install av`\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torch.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is required for video deserialization.\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is required for video deserialization.\")\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torch.hub.video.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is required to deserialize video data.\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is required to deserialize video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torch.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE and _AV_AVAILABLE:\n            with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n                f.write(data)\n                f.seek(0)\n                return torch.hub.video.read_video(f.name)\n        else:\n            raise Exception(\"torchvision and av are required to deserialize video data.\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required for video deserialization. Please install it with `pip install torchvision`.\"\n            )\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required for video deserialization. Please install it with `pip install av`.\"\n            )\n\n        # Write the data to a temporary file\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file.flush()\n            temp_file.close()\n\n        # Use torchvision's read_video function to deserialize the video file into a video object\n        video = torch.read_video(temp_file.name)\n\n        # Delete the temporary file\n        os.remove(temp_file.name)\n\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is not installed, please install it using pip install torchvision\")\n\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is not installed, please install it using pip install av\")\n\n        with tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".mp4\") as tmp_file:\n            tmp_file.write(data)\n            tmp_file.seek(0)\n            return torch.hub.load(\"pytorch/vision:v0.13.1\", \"read_video\", tmp_file.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required to deserialize video data. Please install it using `pip install torchvision`.\"\n            )\n\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required to deserialize video data. Please install it using `pip install av`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as tmp_file:\n            tmp_file.write(data)\n            tmp_file.flush()\n            return torch.read_video(tmp_file.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"torchvision is required to deserialize video data. \"\n                \"Please install torchvision with `pip install torchvision` or `conda install torchvision`\"\n            )\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"av is required to deserialize video data. \"\n                \"Please install av with `pip install av` or `conda install av`\"\n            )\n        with tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".mp4\") as tmp_file:\n            tmp_file.write(data)\n            tmp_file.seek(0)\n            return torch.hub.load(\"pytorch/vision:v0.15.2\", \"read_video\", tmp_file.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            if _AV_AVAILABLE:\n                with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n                    f.write(data)\n                    f.flush()\n                    return torchvision.io.read_video(f.name)\n            else:\n                raise ImportError(\n                    \"The torchvision library is required to deserialize video data. Please install torchvision using 'pip install torchvision'.\"\n                )\n        else:\n            raise ImportError(\n                \"The torchvision library is required to deserialize video data. Please install torchvision using 'pip install torchvision'.\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE and _AV_AVAILABLE:\n            with tempfile.NamedTemporaryFile(suffix=\".mp4\") as temp_file:\n                temp_file.write(data)\n                temp_file.flush()\n                return torch.hub.load(\"pytorch/vision:v0.10.0\", \"read_video\", temp_file.name)\n        else:\n            raise ImportError(\"torchvision and av libraries are required to deserialize video data.\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is required to deserialize video data\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is required to deserialize video data\")\n\n        with tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torch.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"The torchvision library is required for video deserialization.\")\n\n        if not _AV_AVAILABLE:\n            raise ImportError(\"The av library is required for video deserialization.\")\n\n        with tempfile.NamedTemporaryFile() as tmp:\n            tmp.write(data)\n            tmp.seek(0)\n            return torch.utils.video.read_video(tmp.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is required to deserialize video data.\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is required to deserialize video data.\")\n\n        # Write the data to a temporary file\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            # Deserialize the video using torchvision's read_video function\n            video = torch.hub.load(\"pytorch/vision:v0.10.0\", \"read_video\", f.name)\n            return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"torchvision is required to deserialize video data.\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"av is required to deserialize video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return torch.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE and _AV_AVAILABLE:\n            with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n                f.write(data)\n                f.flush()\n                return torch.hub.load(\"pytorch/vision:v0.13.1\", \"read_video\", f.name)\n        else:\n            raise ImportError(\n                \"The torchvision and av libraries are required to deserialize video data. Please install them using 'pip install torchvision av'.\"\n            )\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"To use VideoSerializer, you need to install the torchvision library. \"\n                \"You can install it with `pip install torchvision`.\"\n            )\n\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"To use VideoSerializer, you need to install the av library. \"\n                \"You can install it with `pip install av`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as tmp_file:\n            tmp_file.write(data)\n            tmp_file.seek(0)\n            return torch.read_video(tmp_file.name)[0]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write the remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of file paths to the written chunks\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write the remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of written chunks\n        return [chunk[\"filename\"] for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk(on_done=True)\n\n        self._is_done = True\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        if self._should_write():\n            self.write_chunk(on_done=True)\n        index_filepath = self.write_chunks_index()\n        self._is_done = True\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        self.write_chunks_index()\n\n        self._is_done = True\n\n        return [os.path.join(self._cache_dir, filename) for filename in os.listdir(self._cache_dir)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            if self._should_write():\n                self.write_chunk()\n            sleep(1)\n        self._is_done = True\n        return [self.write_chunk(on_done=True) for _ in range(self._chunk_index)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk(on_done=True)\n\n        self._is_done = True\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while not self._should_write():\n            sleep(0.1)\n\n        if self._serialized_items:\n            self.write_chunk(on_done=True)\n\n        self._is_done = True\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        filepath = self.write_chunks_index()\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk(on_done=True)\n\n        if len(self._serialized_items) > 0:\n            self.write_chunk(on_done=True)\n\n        index_filepath = self.write_chunks_index()\n        self._is_done = True\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        if self._should_write():\n            self.write_chunk(on_done=True)\n        filepath = self.write_chunks_index()\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk(on_done=True)\n\n        index_filepath = self.write_chunks_index()\n        self._is_done = True\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks to files\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index to a JSON file\n        filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        self._is_done = True\n\n        while self._should_write():\n            self.write_chunk()\n\n        if len(self._serialized_items) > 0:\n            self.write_chunk(on_done=True)\n\n        index_file = self.write_chunks_index()\n\n        return [os.path.join(self._cache_dir, filename) for filename in os.listdir(self._cache_dir)] + [index_file]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks to file\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index to a JSON file\n        index_filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return a list of file paths to the written chunks\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        if self._should_write():\n            self.write_chunk(on_done=True)\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        while self._should_write():\n            self.write_chunk()\n        index_path = self.write_chunks_index()\n        self._is_done = True\n        return [index_path]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk(on_done=True)\n\n        index_path = self.write_chunks_index()\n        self._is_done = True\n\n        return [index_path]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        index_file = self.write_chunks_index()\n        self._is_done = True\n\n        return [index_file]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        else:\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n            )\n        else:\n            self.dataset._load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n        else:\n            self.dataset._load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(obj, dict):\n            raise TypeError(f\"The provided state should be a dictionary. Found {obj}.\")\n\n        if \"dataset\" not in obj:\n            raise ValueError(f\"The provided state should contain a dataset. Found {obj}.\")\n\n        if \"current_epoch\" not in obj:\n            raise ValueError(f\"The provided state should contain a current_epoch. Found {obj}.\")\n\n        if \"latest_worker_idx\" not in obj:\n            raise ValueError(f\"The provided state should contain a latest_worker_idx. Found {obj}.\")\n\n        if \"num_samples_yielded\" not in obj:\n            raise ValueError(f\"The provided state should contain a num_samples_yielded. Found {obj}.\")\n\n        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n        else:\n            self.dataset._load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(obj, dict):\n            raise ValueError(\n                \"The provided state should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if \"dataset\" not in obj:\n            raise ValueError(\n                \"The provided state should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if \"current_epoch\" in obj:\n            self.current_epoch = obj[\"current_epoch\"]\n\n        if \"latest_worker_idx\" in obj:\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if \"num_samples_yielded\" in obj:\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.dataset.load_state_dict(obj[\"dataset\"])\n\n        self.restore = True\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"latest_worker_idx\"],\n            )\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.current_epoch = obj[\"current_epoch\"]\n            self.restore = True\n        else:\n            self.dataset._load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.current_epoch = obj[\"current_epoch\"]\n            self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(obj, dict):\n            raise ValueError(\n                \"The provided object should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if not isinstance(self.dataset, (StreamingDataset, CombinedStreamingDataset)):\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if \"dataset\" not in obj:\n            raise ValueError(\n                \"The provided object should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if \"current_epoch\" not in obj:\n            raise ValueError(\n                \"The provided object should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if \"latest_worker_idx\" not in obj:\n            raise ValueError(\n                \"The provided object should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if \"num_samples_yielded\" not in obj:\n            raise ValueError(\n                \"The provided object should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n        else:\n            self.dataset._load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n                self.restore,\n            )\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size, self.restore)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], obj[\"num_samples_yielded\"], self.num_workers, self.batch_size\n            )\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(obj, dict):\n            raise ValueError(f\"The provided state should be a dictionary. Found {obj}.\")\n\n        if not all(key in obj for key in (\"dataset\", \"current_epoch\", \"latest_worker_idx\", \"num_samples_yielded\")):\n            raise ValueError(\n                \"The provided state should contain a `dataset` key, a `current_epoch` key, a `latest_worker_idx` key, and a `num_samples_yielded` key.\"\n            )\n\n        if not isinstance(obj[\"dataset\"], dict):\n            raise ValueError(f\"The provided state should contain a `dataset` key. Found {obj}.\")\n\n        if not all(key in obj[\"dataset\"] for key in (\"current_epoch\", \"latest_worker_idx\", \"num_samples_yielded\")):\n            raise ValueError(\n                \"The provided state should contain a `current_epoch` key, a `latest_worker_idx` key, and a `num_samples_yielded` key.\"\n            )\n\n        if not isinstance(obj[\"dataset\"][\"current_epoch\"], int):\n            raise ValueError(f\"The provided state should contain a `current_epoch` key. Found {obj}.\")\n\n        if not isinstance(obj[\"dataset\"][\"latest_worker_idx\"], int):\n            raise ValueError(f\"The provided state should contain a `latest_worker_idx` key. Found {obj}.\")\n\n        if not isinstance(obj[\"dataset\"][\"num_samples_yielded\"], list):\n            raise ValueError(f\"The provided state should contain a `num_samples_yielded` key. Found {obj}.\")\n\n        self.current_epoch = obj[\"dataset\"][\"current_epoch\"]\n        self.dataset.set_epoch(self.current_epoch)\n\n        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.set_epoch(self.current_epoch)\n            self._num_samples_yielded_streaming = obj[\"dataset\"][\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"dataset\"][\"latest_worker_idx\"]\n            self.restore = True\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            assert self.batch_size\n            self.dataset.set_epoch(self.current_epoch)\n            self._num"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n        else:\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"current_epoch\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self.restore = True"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n                self.batch_size,\n            )\n        else:\n            self.dataset._load_state_dict(\n                obj[\"dataset\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n                self.batch_size,\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n\n        for worker_idx in self._num_samples_yielded_combined:\n            next(self._worker_idx_iter)\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(obj, dict):\n            raise ValueError(\n                \"The provided object should be a dictionary containing the training state.\"\n                f\" Found {obj}.\"\n            )\n\n        if \"dataset\" not in obj:\n            raise ValueError(\n                \"The provided object should contain a dataset key with the training state of the dataset.\"\n                f\" Found {obj}.\"\n            )\n\n        if \"current_epoch\" not in obj:\n            raise ValueError(\n                \"The provided object should contain a current_epoch key with the current epoch of the dataset.\"\n                f\" Found {obj}.\"\n            )\n\n        if \"latest_worker_idx\" not in obj:\n            raise ValueError(\n                \"The provided object should contain a latest_worker_idx key with the latest worker index of the dataset.\"\n                f\" Found {obj}.\"\n            )\n\n        if \"num_samples_yielded\" not in obj:\n            raise ValueError(\n                \"The provided object should contain a num_samples_yielded key with the number of samples yielded of the dataset.\"\n                f\" Found {obj}.\"\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.current_epoch, self.num_workers, self.batch_size\n            )\n        else:\n            self.dataset._load_state_dict(obj[\"dataset\"], self.current_epoch, self.num_workers, self.batch_size)\n\n        self.restore = True"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(obj, dict):\n            raise TypeError(\n                \"The provided state should be a dictionary containing the training state, including the current epoch, the number of samples yielded, and the latest worker index.\"\n            )\n\n        if not isinstance(self.dataset, (StreamingDataset, CombinedStreamingDataset)):\n            raise RuntimeError(\n                \"We found a dataset that isn't neither a StreamingDataset nor a CombinedStreamingDataset. Only those are supported for now.\"\n            )\n\n        if \"dataset\" not in obj:\n            raise ValueError(\n                \"The provided state should contain the dataset's state. It is used to update the state of the dataset if applicable.\"\n            )\n\n        if \"current_epoch\" not in obj:\n            raise ValueError(\"The provided state should contain the current epoch.\")\n\n        if \"latest_worker_idx\" not in obj:\n            raise ValueError(\"The provided state should contain the latest worker index.\")\n\n        if \"num_samples_yielded\" not in obj:\n            raise ValueError(\"The provided state should contain the number of samples yielded.\")\n\n        if \"num_samples_yielded\" in obj and not isinstance(obj[\"num_samples_yielded\"], dict):\n            raise TypeError(\"The provided state should contain a dictionary containing the number of samples yielded.\")\n\n        if \"num_samples_yielded\" in obj and isinstance(obj[\"num_samples_yielded\"], dict):\n            assert self.batch_size\n            num_samples_yielded = obj[\"num_samples_yielded\"]\n\n            if len(list(num_samples_yielded.values())[0]) != len(list(self._num_samples_yielded_combined.values())[0]):\n                raise ValueError(\n                    \"The provided state should contain a dictionary containing the number of samples yielded.\"\n                )\n\n            for worker_idx in num_samples_yielded:\n                for dataset_idx, samples_yieled in enumerate(num_samples_yielded[worker_idx]):\n                    self._num_samples_yielded_combined[worker_idx][dataset_idx] += samples_yieled\n\n        self.dataset.load_state_dict(obj[\"dataset\"])\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_streaming = obj[\"num_"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"latest_worker_idx\"],\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self.restore = True"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                obj[\"num_samples_yielded\"],\n                self.num_workers,\n                self.batch_size,\n                self._num_samples_yielded_streaming,\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.restore = True\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n\n            state_dict = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [],\n            }\n\n            return state_dict\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            state_dict = self._iterator.state_dict(num_workers, batch_size)\n        else:\n            state_dict = {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: self._num_samples_yielded,\n            }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n\n            return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state_dict = {}\n\n        if self._iterator is None:\n            if num_samples_yielded is None:\n                return state_dict\n\n            state_dict[__NUM_SAMPLES_YIELDED_KEY__] = num_samples_yielded\n            return state_dict\n\n        state_dict = self._iterator.state_dict(num_workers, batch_size)\n\n        if num_samples_yielded is not None:\n            state_dict[__NUM_SAMPLES_YIELDED_KEY__] = num_samples_yielded\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [\n                    dataset.state_dict(num_workers, batch_size, num_samples_yielded[i])\n                    for i, dataset in enumerate(self._datasets)\n                ],\n            }\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is not None:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [],\n                }\n            else:\n                return {}\n\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded}\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state_dict = {}\n\n        if self._iterator is None:\n            if num_samples_yielded is not None:\n                state_dict = {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [],\n                }\n            return state_dict\n\n        state_dict = self._iterator.state_dict(num_workers, batch_size)\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [\n                dataset.state_dict(num_workers, batch_size) for dataset in self._datasets\n            ],\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        # If we have a list of num_samples_yielded, we return the state_dict\n        # of the datasets.\n        # If we don't have a list of num_samples_yielded, we return the state_dict\n        # of the iterator.\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            __SAMPLES_KEY__: [\n                dataset.state_dict(num_workers, batch_size, num_samples_yielded[i])\n                for i, dataset in enumerate(self._datasets)\n            ],\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n        if self._num_samples_yielded is not None:\n            self._num_samples_yielded = [\n                self._num_samples_yielded[i] for i in range(len(self._datasets))\n            ]\n\n        self._iterator = None\n\n        for i, dataset in enumerate(self._datasets):\n            if __SAMPLES_KEY__ in state_dict:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][i])\n            else:\n                dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._datasets = state_dict[__SAMPLES_KEY__]\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n        self._iterator = None\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        # If the state_dict is empty, skip the rest of the function\n        if not state_dict:\n            return\n\n        # Get the number of workers and batch size from the state_dict\n        num_workers = state_dict[__NUM_SAMPLES_YIELDED_KEY__][0]\n        batch_size = state_dict[__NUM_SAMPLES_YIELDED_KEY__][1]\n\n        # Get the number of samples yielded from the state_dict\n        num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__][2]\n\n        # Get the samples from the state_dict\n        samples = state_dict[__SAMPLES_KEY__]\n\n        # Get the worker environment\n        worker_env = _WorkerEnv.detect()\n\n        # Check if the worker environment is valid\n        if worker_env.rank is None:\n            raise RuntimeError(\"The worker environment is not valid.\")\n\n        # Get the rank of the current worker\n        rank = worker_env.rank\n\n        # Check if the rank is valid\n        if rank is None:\n            raise RuntimeError(\"The rank of the current worker is not valid.\")\n\n        # Get the number of samples yielded by the current worker\n        num_samples_yielded_by_current_worker = num_samples_yielded[rank]\n\n        # Check if the number of samples yielded by the current worker is valid\n        if num_samples_yielded_by_current_worker is None:\n            raise RuntimeError(\"The number of samples yielded by the current worker is not valid.\")\n\n        # Get the samples yielded by the current worker\n        samples_yielded_by_current_worker = samples[rank]\n\n        # Check if the samples yielded by the current worker are valid\n        if samples_yielded_by_current_worker is None:\n            raise RuntimeError(\"The samples yielded by the current worker are not valid.\")\n\n        # Get the number of samples yielded by the current worker\n        num_samples_yielded_by_current_worker = len(samples_yielded_by_current_worker)\n\n        # Check if the number of samples yielded by the current worker is valid\n        if num_samples_yielded_by_current_worker == 0:\n            raise RuntimeError(\"The number of samples yielded by the current worker is not valid.\")\n\n        # Get the number of samples y"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._datasets = state_dict[__SAMPLES_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._load_state_dict(self._datasets, state_dict, __SAMPLES_KEY__)\n        else:\n            self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        self._iterator = _CombinedDatasetIterator(self._datasets, self._seed, self._weights)\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n            if self._num_samples_yielded is None:\n                return\n            for dataset, num_samples_yielded in zip(self._datasets, self._num_samples_yielded):\n                dataset.load_state_dict({__NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded})\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            return\n\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        # Update the state of each dataset within the CombinedStreamingDataset\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n        # If the state dictionary contains the key \"__NUM_SAMPLES_YIELDED__\", update the number of samples yielded by the streaming dataloader\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            if self._num_samples_yielded is not None:\n                self._num_samples_yielded = [\n                    int(num_samples) for num_samples in self._num_samples_yielded\n                ]\n            self._datasets = _load_state_dict(self._datasets, state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if __SAMPLES_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__SAMPLES_KEY__]\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        else:\n            self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        self._iterator = _CombinedDatasetIterator(\n            self._datasets,\n            self._seed,\n            self._weights,\n            self._use_streaming_dataloader,\n            self._num_samples_yielded,\n        )\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            del state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        if __SAMPLES_KEY__ in state_dict:\n            del state_dict[__SAMPLES_KEY__]\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict:\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            if __SAMPLES_KEY__ in state_dict:\n                samples = state_dict[__SAMPLES_KEY__]\n                for dataset, sample in zip(self._datasets, samples):\n                    dataset.load_state_dict(sample)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        for dataset in self._datasets:\n            dataset_state_dict = state_dict[dataset.__class__.__name__]\n            dataset.load_state_dict(dataset_state_dict)\n\n        self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"http://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[12:]\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-external://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-external://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-private://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-external://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-private://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-public://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-public-external://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-public-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-public-public-public-private://\"):"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-internal://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\""}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir_path[len(\"lightning://\") :].split(\"/\", 1)\n        return Dir(path=path, url=f\"lightning://{project_id}/{path}\")\n\n    if dir_path.startswith(\"lightning://\"):\n        project_id, path = dir"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud-private-internal://\"):\n        return Dir(url=dir"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"http://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"azure://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"oss://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path[7:])\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"http://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"azure://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"azure://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"oss://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path[7:])\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightningcloud://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightningcloud://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning-cloud://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"~\"):\n        dir_path = dir_path.replace(\"~\", str(Path.home()))\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path.replace(\"lightning://\", \"\")\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"~\"):\n        dir_path = os.path.expanduser(dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[len(\"lightning://\") :]\n        dir_path = f\"lightning://{parse.quote(dir_path)}\"\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        dir_path = dir_path[len(\"lightning://\") :]\n        dir_path = f\"lightning://{parse.quote(dir_path)}\"\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"https://lightning.ai/\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(path=dir_path, url=dir_path)\n    elif dir_path.startswith(\"lightning://\"):\n        return Dir(path=dir_path, url=dir_path)\n    elif dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path[7:], url=None)\n    elif dir_path.startswith(\"gs://\"):\n        return Dir(path=dir_path, url=dir_path)\n    elif dir_path.startswith(\"https://\"):\n        return Dir(path=dir_path, url=dir_path)\n    elif dir_path.startswith(\"http://\"):\n        return Dir(path=dir_path, url=dir_path)\n    else:\n        return Dir(path=dir_path, url=None)\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(f\"You can't set both `append` and `overwrite` to True.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to an S3 bucket is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in an S3 bucket is not supported yet.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        s3_bucket = output_dir.url.split(\"s3://\")[1].split(\"/\")[0]\n        s3_prefix = output_dir.url.split(\"s3://\")[1].split(\"/\", 1)[1]\n\n        response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)\n\n        if response[\"KeyCount\"] > 0:\n            raise ValueError(f\"The `output_dir` must be empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"The `output_dir` must be a valid S3 bucket path, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be a valid S3 bucket path, got: {output_dir}\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"This function requires boto3 to be installed. Please install it with `pip install boto3`.\"\n        )\n\n    if append and overwrite:\n        raise ValueError(\"Cannot append and overwrite at the same time.\")\n\n    if append:\n        raise NotImplementedError(\"Appending is not yet implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting is not yet implemented.\")\n\n    s3_client = boto3.client(\"s3\")\n\n    try:\n        response = s3_client.list_objects_v2(Bucket=output_dir.url.split(\"s3://\")[1].split(\"/\")[0], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n    except botocore.exceptions.ClientError as e:\n        raise ValueError(f\"The `output_dir` is not a valid S3 bucket path, got: {output_dir}\") from e\n\n    if \"Contents\" in response:\n        raise ValueError(f\"The `output_dir` is not empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    # Check if output_dir is a Dir object\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The output_dir must be a `Dir` object, got: {output_dir}\")\n\n    # Check if output_dir starts with \"s3://\"\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The output_dir must be an S3 bucket, got: {output_dir}\")\n\n    # Check if the directory is empty\n    if append and overwrite:\n        raise ValueError(\"Cannot append and overwrite at the same time.\")\n\n    if append:\n        return\n\n    if overwrite:\n        return\n\n    # Check if the directory already contains data\n    if _dir_is_empty(output_dir):\n        return\n\n    raise ValueError(f\"The output_dir is not empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"The provided `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The provided `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to an S3 bucket is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting an S3 bucket is not supported yet.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        paginator = s3_client.get_paginator(\"list_objects_v2\")\n        page_iterator = paginator.paginate(Bucket=parse.urlparse(output_dir.url).netloc, Prefix=parse.urlparse(output_dir.url).path[1:])\n        for page in page_iterator:\n            if \"Contents\" in page:\n                raise ValueError(f\"The provided `output_dir` must be empty, got: {output_dir}\")\n    else:\n        raise RuntimeError(\"`boto3` is not installed, please install it using `pip install boto3`\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"The `output_dir` must be a S3 bucket, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be a S3 bucket, got: {output_dir}\")\n\n    if not append and not overwrite:\n        if _BOTO3_AVAILABLE:\n            bucket_name, prefix = parse.urlparse(output_dir.url).netloc, parse.urlparse(output_dir.url).path.lstrip(\"/\")\n\n            s3_client = boto3.client(\"s3\")\n            paginator = s3_client.get_paginator(\"list_objects_v2\")\n            page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n\n            if next(page_iterator.pages, None) is not None:\n                raise ValueError(f\"The `output_dir` must be empty, got: {output_dir}\")\n\n        else:\n            raise ImportError(\n                \"Please install boto3 to use this feature. You can do so with `pip install boto3`.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"The `output_dir` must be a `Dir` object with a valid URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object with a valid S3 URL, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(\"Only one of `append` or `overwrite` can be True.\")\n\n    if append:\n        raise NotImplementedError(\"Appending to a directory is not yet implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting a directory is not yet implemented.\")\n\n    if _BOTO3_AVAILABLE:\n        s3 = boto3.client(\"s3\")\n        try:\n            s3.list_objects_v2(Bucket=parse.urlparse(output_dir.url).netloc, Prefix=parse.urlparse(output_dir.url).path[1:])\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                raise ValueError(f\"The S3 bucket {parse.urlparse(output_dir.url).netloc} does not exist.\")\n            else:\n                raise e\n\n        response = s3.list_objects_v2(Bucket=parse.urlparse(output_dir.url).netloc, Prefix=parse.urlparse(output_dir.url).path[1:])\n\n        if \"Contents\" in response:\n            raise ValueError(\n                f\"The S3 bucket {parse.urlparse(output_dir.url).netloc} already contains data in the specified directory.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"The `output_dir` must be a URL, got: {output_dir.url}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 URL, got: {output_dir.url}\")\n\n    if not append and not overwrite:\n        raise ValueError(f\"The `output_dir` must be empty, got: {output_dir.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"The `append` flag is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"The `overwrite` flag is not implemented yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` package is required to check if the output directory is empty. \"\n            \"Please install it with `pip install boto3`.\"\n        )\n\n    s3_client = boto3.client(\"s3\")\n    bucket_name, key_prefix = _get_bucket_name_and_key_prefix(output_dir.url)\n\n    if key_prefix is not None:\n        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=key_prefix)\n        if response[\"KeyCount\"] > 0:\n            raise ValueError(f\"The `output_dir` must be empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir.url}\")\n\n    if append and overwrite:\n        raise ValueError(\"Only one of `append` and `overwrite` can be True.\")\n\n    if append:\n        raise NotImplementedError(\"`append` is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"`overwrite` is not yet supported.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"Please install boto3 to use this feature.\")\n\n    bucket_name, key_name = parse.urlparse(output_dir.url).netloc, parse.urlparse(output_dir.url).path.lstrip(\"/\")\n\n    s3 = boto3.client(\"s3\")\n    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=key_name)\n\n    if response[\"KeyCount\"] > 0:\n        raise ValueError(f\"The `output_dir` must be empty, got: {output_dir.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must start with `s3://`, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(f\"`append` and `overwrite` cannot both be True.\")\n\n    if append or overwrite:\n        raise NotImplementedError(f\"`append` and `overwrite` are currently not implemented.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"Please install boto3 to use this function.\")\n\n    parsed_url = parse.urlparse(output_dir.url)\n    bucket_name = parsed_url.netloc\n    prefix = parsed_url.path[1:]\n\n    s3_client = boto3.client(\"s3\")\n    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n\n    if \"Contents\" in response:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"`output_dir` must be a S3 URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a S3 URL, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(f\"Only one of `append` and `overwrite` can be set to True, got: {append} and {overwrite}\")\n\n    if not append and not overwrite:\n        raise ValueError(f\"One of `append` and `overwrite` must be set to True, got: {append} and {overwrite}\")\n\n    if append:\n        return\n\n    if overwrite:\n        return\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be a valid S3 URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a valid S3 URL, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to an S3 directory is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in an S3 directory is not supported yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"This function requires boto3 to be installed.\")\n\n    if _LIGHTNING_SDK_AVAILABLE:\n        from lightning_sdk.utilities.cloud import _get_aws_credentials\n\n        aws_credentials = _get_aws_credentials()\n    else:\n        aws_credentials = {\"aws_access_key_id\": os.getenv(\"AWS_ACCESS_KEY_ID\"), \"aws_secret_access_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\")}\n\n    if aws_credentials[\"aws_access_key_id\"] is None:\n        raise ValueError(\"The AWS access key ID is not available.\")\n\n    if aws_credentials[\"aws_secret_access_key\"] is None:\n        raise ValueError(\"The AWS secret access key is not available.\")\n\n    bucket_name = output_dir.url.split(\"/\")[2]\n    key = \"/\".join(output_dir.url.split(\"/\")[3:])\n\n    s3 = boto3.resource(\n        \"s3\",\n        aws_access_key_id=aws_credentials[\"aws_access_key_id\"],\n        aws_secret_access_key=aws_credentials[\"aws_secret_access_key\"],\n    )\n\n    try:\n        s3.Object(bucket_name, key).load()\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            return\n        else:\n            raise ValueError(f\"The S3 bucket {bucket_name} does not exist.\")\n\n    # Check if the directory is empty\n    try:\n        s3.Object"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"The `output_dir` must be a `Dir` object with an associated URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 URL, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\n            \"The `append` parameter is not implemented for S3 directories. \"\n            \"Please use `overwrite=True` instead.\"\n        )\n\n    if overwrite:\n        raise NotImplementedError(\n            \"The `overwrite` parameter is not implemented for S3 directories. \"\n            \"Please use `append=False` instead.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` package is required to check if an S3 directory is empty. \"\n            \"Please install it with `pip install boto3`.\"\n        )\n\n    s3_url = parse.urlparse(output_dir.url)\n    s3_bucket = s3_url.netloc\n    s3_key = s3_url.path.lstrip(\"/\")\n\n    s3_client = boto3.client(\"s3\")\n    s3_paginator = s3_client.get_paginator(\"list_objects_v2\")\n    s3_iterator = s3_paginator.paginate(Bucket=s3_bucket, Prefix=s3_key)\n\n    for s3_page in s3_iterator:\n        if \"Contents\" in s3_page:\n            raise ValueError(f\"The `output_dir` must be empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"`output_dir` must be a `Dir` with a URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 URL, got: {output_dir.url}\")\n\n    if append:\n        raise ValueError(f\"`append` is not supported yet, got: {append}\")\n\n    if overwrite:\n        raise ValueError(f\"`overwrite` is not supported yet, got: {overwrite}\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"This function requires `boto3` to be installed. Please install it using `pip install boto3`.\"\n        )\n\n    s3_bucket, s3_key = parse.urlparse(output_dir.url).netloc, parse.urlparse(output_dir.url).path[1:]\n\n    s3_client = boto3.client(\"s3\")\n    paginator = s3_client.get_paginator(\"list_objects_v2\")\n    pages = paginator.paginate(Bucket=s3_bucket, Prefix=s3_key)\n\n    for page in pages:\n        if \"Contents\" in page:\n            if len(page[\"Contents\"]) > 0:\n                raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to S3 is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting S3 is not supported yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"`boto3` is required to check if the S3 directory is empty.\")\n\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"`lightning_sdk` is required to check if the S3 directory is empty.\")\n\n    try:\n        s3_client = boto3.client(\"s3\")\n        bucket_name, prefix = parse.urlparse(output_dir.url).netloc, parse.urlparse(output_dir.url).path[1:]\n        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n        if response[\"KeyCount\"] > 0:\n            raise ValueError(f\"The directory `{output_dir.url}` is not empty.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n            raise ValueError(f\"The bucket `{bucket_name}` does not exist.\")\n        else:\n            raise e\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"`output_dir` must be a valid S3 url, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a valid S3 url, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(\"Cannot append and overwrite at the same time.\")\n\n    if append:\n        raise NotImplementedError(\"Appending is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting is not yet supported.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        s3_bucket, s3_key = parse.urlparse(output_dir.url)[1:3]\n        response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=s3_key)\n        if \"Contents\" in response:\n            raise ValueError(f\"The specified directory {output_dir.url} is not empty.\")\n    else:\n        raise RuntimeError(\n            \"This function requires `boto3` to be installed. Please install it with `pip install boto3`.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\n            f\"`output_dir` must be a `Dir` object, got: {output_dir}. \"\n            f\"This is likely due to the fact that you are using a local directory \"\n            f\"which is not supported by this function. Please use an S3 bucket instead.\"\n        )\n\n    if output_dir.url is None:\n        raise ValueError(\n            f\"`output_dir` must be a directory in an S3 bucket, got: {output_dir}. \"\n            f\"This is likely due to the fact that you are using a local directory \"\n            f\"which is not supported by this function. Please use an S3 bucket instead.\"\n        )\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\n            f\"`output_dir` must be a directory in an S3 bucket, got: {output_dir}. \"\n            f\"This is likely due to the fact that you are using a local directory \"\n            f\"which is not supported by this function. Please use an S3 bucket instead.\"\n        )\n\n    if append:\n        raise NotImplementedError(\n            \"This function does not support appending data to the directory. \"\n            \"Please set `append` to False or omit the argument.\"\n        )\n\n    if overwrite:\n        raise NotImplementedError(\n            \"This function does not support overwriting data in the directory. \"\n            \"Please set `overwrite` to False or omit the argument.\"\n        )\n\n    # Check if the directory is empty\n    if _boto3_available():\n        s3_resource = boto3.resource(\"s3\")\n        bucket_name = parse.urlparse(output_dir.url).netloc\n        bucket_path = parse.urlparse(output_dir.url).path.lstrip(\"/\")\n        bucket = s3_resource.Bucket(bucket_name)\n        objects = list(bucket.objects.filter(Prefix=bucket_path))\n\n        if len(objects) > 0:\n            raise ValueError(\n                f\"The specified directory {output_dir.url} is not empty. \"\n                f\"Please either specify a different directory or set `overwrite` to True.\"\n            )\n\n    else:\n        raise ImportError(\n            \"This function requires the boto3 library to be installed. \"\n            \"Please install boto3 and try again.\"\n       "}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(\"Cannot append and overwrite at the same time.\")\n\n    if append:\n        return\n\n    if overwrite:\n        return\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"`boto3` is not installed. Please install it with `pip install boto3`.\")\n\n    s3_client = boto3.client(\"s3\")\n\n    try:\n        s3_client.head_bucket(Bucket=output_dir.url.replace(\"s3://\", \"\"))\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            raise ValueError(f\"The `output_dir` does not exist, got: {output_dir}\")\n        else:\n            raise\n\n    s3_paginator = s3_client.get_paginator(\"list_objects_v2\")\n    s3_result_iterator = s3_paginator.paginate(Bucket=output_dir.url.replace(\"s3://\", \"\"))\n\n    for s3_result in s3_result_iterator:\n        if s3_result[\"KeyCount\"] > 0:\n            raise ValueError(f\"The `output_dir` is not empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(\"`append` and `overwrite` can't be both set to True.\")\n\n    if append:\n        raise NotImplementedError(\"`append` is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"`overwrite` is not implemented yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"This function requires `boto3` to be installed.\")\n\n    s3 = boto3.resource(\"s3\")\n    bucket_name = parse.urlparse(output_dir.url).netloc\n    bucket_path = parse.urlparse(output_dir.url).path.lstrip(\"/\")\n\n    if not s3.Bucket(bucket_name).objects.filter(Prefix=bucket_path).all():\n        return\n\n    raise ValueError(\n        f\"The output directory `{output_dir.url}` is not empty. \"\n        \"Please use a different directory or set `overwrite=True` or `append=True`.\"\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append and overwrite:\n        raise ValueError(f\"You cannot append and overwrite at the same time.\")\n\n    if not append and not overwrite:\n        raise ValueError(f\"You must either append or overwrite.\")\n\n    if append:\n        return\n\n    if overwrite:\n        return\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if the directory contains an index file\n    index_file_exists = False\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file. This is not allowed. \"\n            \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Delete all objects within the specified prefix in the bucket\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                return\n\n        # Delete all objects in the bucket\n        objects = s3.list_objects_v2(\n            Bucket=obj.netloc,\n            Delimiter=\"/\",\n            Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n        )\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # The object does not exist.\n            # We can safely delete all objects within the specified prefix in the bucket.\n            bucket_name = obj.netloc\n            prefix = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"\n            bucket = s3.Bucket(bucket_name)\n            bucket.objects.filter(Prefix=prefix).delete()\n        else:\n            # Something else has gone wrong.\n            raise\n    else:\n        # The object exists.\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index.json file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Check if an index file is present in the specified directory\n    index_file_present = False\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"].endswith(\"index.json\"):\n            index_file_present = True\n            break\n\n    if index_file_present:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Delete all objects in the specified directory\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        index_file = [obj for obj in objects[\"Contents\"] if obj[\"Key\"].endswith(\"index.json\")]\n        if len(index_file) > 0:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n        else:\n            s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]})\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # Check if the index file exists in the specified S3 bucket directory\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\") + \"index.json\")\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index.json file.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # If the index file doesn't exist, delete all objects within the specified prefix in the bucket\n            objects = s3.list_objects_v2(\n                Bucket=obj.netloc,\n                Delimiter=\"/\",\n                Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n            )\n            if objects[\"KeyCount\"] > 0:\n                for obj in objects[\"Contents\"]:\n                    s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == \"index.json\":\n                return\n\n        # If no index.json file is found, delete all objects in the bucket\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\"Key\": obj[\"Key\"]}\n                    for obj in objects[\"Contents\"]\n                ]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        index_file_found = False\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == \"index.json\":\n                index_file_found = True\n                break\n        if not index_file_found:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` does not contain an index file named 'index.json'.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # The index.json file does not exist. Delete all objects within the specified prefix.\n            objects = s3.list_objects_v2(\n                Bucket=obj.netloc,\n                Delimiter=\"/\",\n                Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n            )\n            if objects[\"KeyCount\"] > 0:\n                for obj in objects[\"Contents\"]:\n                    s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n        else:\n            # Some other error occurred.\n            raise\n    else:\n        # The index.json file already exists.\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index.json file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        for key in objects[\"Contents\"]:\n            if key[\"Key\"] == \"index.json\":\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n        # If no index file is found, delete all objects within the specified prefix in the bucket.\n        s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"}]})\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        index_file = s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n        if index_file:\n            raise ValueError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file. HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            # The index file does not exist, so we can proceed.\n            pass\n        else:\n            # Some other error occurred, so we raise it.\n            raise\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # Check if the index file exists\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n        raise ValueError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index.json file. \"\n            \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # The index file does not exist, so we can proceed with deleting all objects within the specified prefix.\n            # Delete all objects within the specified prefix\n            s3.delete_objects(\n                Bucket=obj.netloc,\n                Delete={\n                    \"Objects\": [\n                        {\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key}\n                        for key in s3.list_objects_v2(\n                            Bucket=obj.netloc,\n                            Delimiter=\"/\",\n                            Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n                        )[\"Contents\"]\n                    ]\n                },\n            )\n        else:\n            # An unknown error occurred, so we raise the exception.\n            raise\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if the index file exists\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == obj.path.lstrip(\"/\") + \"/index.json\":\n                return\n\n    # Delete all objects in the prefix\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [\n                {\"Key\": obj[\"Key\"]}\n                for obj in objects[\"Contents\"]\n                if obj[\"Key\"] != obj.path.lstrip(\"/\") + \"/index.json\"\n            ]\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        # check if the index.json file exists\n        index_file_exists = False\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == \"index.json\":\n                index_file_exists = True\n                break\n\n        # if the index.json file exists, raise an error\n        if index_file_exists:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index.json file and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n        # if the index.json file does not exist, delete all objects within the specified prefix in the bucket\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\") + \"index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            # The index file does not exist in the S3 bucket, so we delete all objects in the specified prefix.\n            response = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\"))\n            if \"Contents\" in response:\n                for obj in response[\"Contents\"]:\n                    if obj[\"Key\"] != obj.path.lstrip(\"/\") + \"index.json\":\n                        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n        else:\n            raise\n    else:\n        # The index file already exists in the S3 bucket, so we raise an error.\n        raise ValueError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named index.json.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\":\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index.json file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # If the index.json file is not found, delete all objects within the specified prefix in the bucket.\n    # This is done to ensure that the dataset directory is empty before uploading new files.\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        index_file = False\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == \"index.json\":\n                index_file = True\n                break\n\n        if not index_file:\n            s3.delete_objects(Bucket=obj.netloc, Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]})\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank == 0:\n            # Wait for all index files to be available\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n            # Merge the index files\n            merged_index = []\n            for filename in os.listdir(self._cache_dir):\n                if filename.endswith(_INDEX_FILENAME):\n                    with open(os.path.join(self._cache_dir, filename), \"r\") as f:\n                        index = json.load(f)\n                        merged_index.append(index)\n\n            # Write the merged index file\n            merged_index = {\"chunks\": merged_index, \"config\": self.get_config()}\n            with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as f:\n                json.dump(merged_index, f, sort_keys=True)\n        else:\n            # Wait for the merged index file to be available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        if node_rank == 0:\n            # Wait until all index files are available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge the index files\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            merged_index = {}\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index = json.load(f)\n                    merged_index[\"chunks\"].extend(index[\"chunks\"])\n                    merged_index[\"config\"].update(index[\"config\"])\n\n            # Write the merged index file\n            with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as f:\n                json.dump(merged_index, f, sort_keys=True)\n        else:\n            # Wait until the merged index file is available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all index files to be available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # If the current node is not the master node, wait for the merged index file to be available\n        if node_rank is not None and node_rank != 0:\n            while True:\n                files = os.listdir(self._cache_dir)\n                merged_index_file = f\"{node_rank}.{_INDEX_FILENAME}\"\n                if merged_index_file in files:\n                    break\n                sleep(1)\n\n        # If the current node is the master node, perform the merge\n        if node_rank is None or node_rank == 0:\n            merged_index_data = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index_data = json.load(f)\n                    merged_index_data.append(index_data)\n            merged_index_data = {\n                \"chunks\": [chunk for index_data in merged_index_data for chunk in index_data[\"chunks\"]],\n                \"config\": merged_index_data[0][\"config\"],\n            }\n            with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n                json.dump(merged_index_data, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank == 0:\n            # Wait for all the index files to be available\n            while True:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge the index files\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            chunks = []\n            config = None\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    data = json.load(f)\n                    chunks.extend(data[\"chunks\"])\n                    if config is None:\n                        config = data[\"config\"]\n            with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": config}, out, sort_keys=True)\n        else:\n            # Wait for the merged index file to be available\n            while True:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\", None)\n            if node_rank is None:\n                node_rank = 0\n\n        if node_rank == 0:\n            # Wait for all index files to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge all index files\n            chunks_info = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    data = json.load(f)\n                    chunks_info.extend(data[\"chunks\"])\n\n            # Write the merged index file\n            config = data[\"config\"]\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n        else:\n            # Wait for the merged index file to be available\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                    break\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.world_size == 1:\n            return\n\n        if node_rank is None:\n            node_rank = self._distributed_env.global_rank\n\n        if node_rank != 0:\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, \"index.json\")):\n                    break\n                sleep(1)\n            return\n\n        # Wait until all index parts are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # Read all index parts\n        index_parts = []\n        for file in files:\n            if file.endswith(_INDEX_FILENAME):\n                with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                    index_parts.append(json.load(f))\n\n        # Merge all index parts\n        merged_index = {\"chunks\": [], \"config\": {}}\n        for index_part in index_parts:\n            merged_index[\"chunks\"].extend(index_part[\"chunks\"])\n            merged_index[\"config\"].update(index_part[\"config\"])\n\n        # Write the merged index to a file\n        with open(os.path.join(self._cache_dir, \"index.json\"), \"w\") as out:\n            json.dump(merged_index, out, sort_keys=True)\n\n        # Delete all index parts\n        for file in files:\n            if file.endswith(_INDEX_FILENAME):\n                os.remove(os.path.join(self._cache_dir, file))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all index files to be available\n        while True:\n            if node_rank is None:\n                node_rank = 0\n            if node_rank == 0:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n            else:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(f\"{node_rank}.{_INDEX_FILENAME}\")]\n                if len(index_files) == 1:\n                    break\n            sleep(5)\n\n        # If it's not the master node, wait for the merged index file to be available\n        if node_rank != 0:\n            while True:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(5)\n\n        # Merge the index files\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        index_files.sort()\n        chunks_info: List[Dict[str, Any]] = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file)) as f:\n                index = json.load(f)\n                chunks_info.extend(index[\"chunks\"])\n\n        # Write the merged index file\n        config = self.get_config()\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all index parts are available\n        while True:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # If the node rank is not specified, assume a non-distributed environment\n        if node_rank is None:\n            node_rank = 0\n\n        # If the node is the master node, proceed with the merge\n        if node_rank == 0:\n            # Gather all index files\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n            # Read all index files\n            indices = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    indices.append(json.load(f))\n\n            # Merge all index files\n            merged_index = {\n                \"chunks\": [],\n                \"config\": {\n                    \"compression\": self._compression,\n                    \"chunk_size\": self._chunk_size,\n                    \"chunk_bytes\": self._chunk_bytes,\n                    \"data_format\": self._data_format,\n                    \"data_spec\": self._data_spec,\n                },\n            }\n            for index in indices:\n                merged_index[\"chunks\"].extend(index[\"chunks\"])\n\n            # Write the merged index file\n            merged_index_file = os.path.join(self._cache_dir, f\"merged.{_INDEX_FILENAME}\")\n            with open(merged_index_file, \"w\") as out:\n                json.dump(merged_index, out, sort_keys=True)\n\n            # Wait until the merged index file is available\n            while True:\n                if os.path.exists(merged_index_file):\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n        if node_rank == 0:\n            # Wait until all parts are available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(0.1)\n\n            # Merge all parts into a single index file\n            index_file = {}\n            for index_file_name in index_files:\n                with open(os.path.join(self._cache_dir, index_file_name), \"r\") as f:\n                    index_file.update(json.load(f))\n\n            # Write the merged index file\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump(index_file, f, sort_keys=True)\n        else:\n            # Wait until the merged index file is available\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                    break\n                sleep(0.1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.is_master_node:\n            # Wait for all the index files to be available\n            while True:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(0.1)\n\n            # Merge the index files\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            index_files.sort()\n            chunks: List[Dict[str, Any]] = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    data = json.load(f)\n                    chunks.extend(data[\"chunks\"])\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": data[\"config\"]}, out, sort_keys=True)\n        else:\n            # Wait for the merged index file to be available\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                    break\n                sleep(0.1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\", None)\n            if node_rank is not None:\n                node_rank = int(node_rank)\n            else:\n                worker_env = _WorkerEnv.detect()\n                distributed_env = _DistributedEnv.detect()\n                node_rank = distributed_env.global_rank * worker_env.world_size + worker_env.rank\n\n        if node_rank == 0:\n            # Wait for all the index files to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge all the index files\n            index_files = [os.path.join(self._cache_dir, f) for f in files if f.endswith(_INDEX_FILENAME)]\n            merged_index = []\n            for index_file in index_files:\n                with open(index_file, \"r\") as f:\n                    index = json.load(f)\n                    merged_index.extend(index[\"chunks\"])\n\n            # Write the merged index file\n            merged_index_file = os.path.join(self._cache_dir, \"index.json\")\n            with open(merged_index_file, \"w\") as out:\n                json.dump({\"chunks\": merged_index, \"config\": index[\"config\"]}, out, sort_keys=True)\n\n            # Delete the individual index files\n            for index_file in index_files:\n                os.remove(index_file)\n        else:\n            # Wait for the merged index file to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                merged_index_file = [f for f in files if f == \"index.json\"]\n                if len(merged_index_file) == 1:\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank != 0:\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                    break\n                sleep(1)\n            return\n\n        # Wait for all index files to be available\n        while True:\n            index_files = [\n                f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME) and f.startswith(str(node_rank))\n            ]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # Read all index files\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        indices = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file)) as f:\n                indices.append(json.load(f))\n\n        # Merge all indices\n        merged_index = {\"chunks\": [], \"config\": {}}\n        for index in indices:\n            merged_index[\"chunks\"].extend(index[\"chunks\"])\n            merged_index[\"config\"].update(index[\"config\"])\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump(merged_index, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        if node_rank == 0:\n            # Wait for all index files to be available\n            while True:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge index files\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            chunks = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index_data = json.load(f)\n                    chunks.extend(index_data[\"chunks\"])\n\n            # Write merged index file\n            merged_index_file = os.path.join(self._cache_dir, _INDEX_FILENAME)\n            with open(merged_index_file, \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": self.get_config()}, out, sort_keys=True)\n\n            # Wait for merged index file to be available\n            while not os.path.exists(merged_index_file):\n                sleep(1)\n        else:\n            # Wait for merged index file to be available\n            while not os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        if node_rank == 0:\n            # Wait for all index files to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge the index files\n            index_files = [os.path.join(self._cache_dir, f) for f in files if f.endswith(_INDEX_FILENAME)]\n            merged_index = []\n            for index_file in index_files:\n                with open(index_file, \"r\") as f:\n                    index_data = json.load(f)\n                    merged_index.extend(index_data[\"chunks\"])\n\n            merged_index = sorted(merged_index, key=lambda x: x[\"chunk_bytes\"])\n\n            merged_index_filename = os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")\n            with open(merged_index_filename, \"w\") as out:\n                json.dump({\"chunks\": merged_index, \"config\": self.get_config()}, out, sort_keys=True)\n        else:\n            # Wait for the merged index file to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is None:\n            node_rank = 0\n\n        if node_rank != 0:\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, f\"index.{_INDEX_FILENAME}\")):\n                    break\n                sleep(1)\n            return\n\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n\n        chunks_info = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file)) as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        config = json.load(f)[\"config\"]\n\n        filepath = os.path.join(self._cache_dir, f\"index.{_INDEX_FILENAME}\")\n        with open(filepath, \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the node rank is not provided, assume a non-distributed environment\n        if node_rank is None:\n            node_rank = 0\n\n        # If the node rank is 0, it is the master node and is responsible for the merge operation\n        if node_rank == 0:\n            # Wait for all index parts to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Read and merge all index files\n            index_files = [os.path.join(self._cache_dir, f) for f in index_files]\n            chunks = []\n            for index_file in index_files:\n                with open(index_file) as f:\n                    index_data = json.load(f)\n                    chunks.extend(index_data[\"chunks\"])\n\n            # Write the merged index file\n            merged_index_file = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n            with open(merged_index_file, \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": self.get_config()}, out, sort_keys=True)\n        else:\n            # Wait until the merged index file is available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.filled:\n            return\n\n        if node_rank is None:\n            node_rank = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\", None)\n            if node_rank:\n                node_rank = int(node_rank)\n\n        if node_rank is None:\n            node_rank = 0\n\n        if node_rank == 0:\n            # Wait until all index files are available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge index files\n            merged_chunks = []\n            merged_config = {}\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index = json.load(f)\n                    merged_chunks.extend(index[\"chunks\"])\n                    merged_config.update(index[\"config\"])\n\n            # Write down the merged index file\n            merged_chunks_info = {\n                \"chunks\": merged_chunks,\n                \"config\": merged_config,\n            }\n\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump(merged_chunks_info, out, sort_keys=True)\n\n        else:\n            # Wait until the merged index file is available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        while True:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        if node_rank == 0:\n            # Merge the index files\n            merged_chunks = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    data = json.load(f)\n                    merged_chunks.extend(data[\"chunks\"])\n\n            # Write down the merged index\n            merged_index = {\"chunks\": merged_chunks}\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump(merged_index, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.is_master:\n            # Wait until all the index files are available\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n            # Merge the index files\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            chunks_info = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    data = json.load(f)\n                    chunks_info.extend(data[\"chunks\"])\n\n            # Write the merged index file\n            config = data[\"config\"]\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as out:\n                json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n        else:\n            # Wait until the merged index file is available\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, _INDEX_FILENAME)):\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = self.rank\n\n        if node_rank == 0:\n            # Wait for all index files to be available\n            while True:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge all index files into a single file\n            merged_index = {}\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file)) as f:\n                    index = json.load(f)\n                    merged_index[index_file] = index\n\n            # Write the merged index to a file\n            with open(os.path.join(self._cache_dir, \"index.json\"), \"w\") as f:\n                json.dump(merged_index, f, sort_keys=True)\n        else:\n            # Wait for the merged index file to be available\n            while True:\n                if os.path.exists(os.path.join(self._cache_dir, \"index.json\")):\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` is not available. Please install it using `pip install lightning-sdk` and try again.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` is not available. Please install it using `pip install boto3` and try again.\"\n        )\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=0, memory=1, name=\"default\", type=\"cpu\")\n\n    if command is None:\n        command = (\n            f\"cd {os.getcwd()} && \"\n            f\"export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_NAME={os.getenv('LIGHTNING_CLOUD_PROJECT_NAME')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_NAME={os.getenv('LIGHTNING_CLOUD_SPACE_NAME')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_ID={os.getenv('LIGHTNING_CLOUD_DATASET_ID')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_NAME={os.getenv('LIGHTNING_CLOUD_DATASET_NAME')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_VERSION={os.getenv('LIGHTNING_CLOUD_DATASET_VERSION')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_VERSION_ID={os.getenv('LIGHTNING_CLOUD_DATASET_VERSION_ID')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_VERSION_NAME={os.getenv('LIGHTNING_CLOUD_DATASET_VERSION_NAME')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_VERSION_DESCRIPTION={os.getenv('LIGHTNING_CLOUD_DATASET_VERSION_DESCRIPTION')} && \"\n            f\"export LIGHTNING_CLOUD_DATASET_VERSION_STATE={os.getenv('LIGHTNING_CLOUD"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` package is not installed. Please install it using `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` package is not installed. Please install it using `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=1, memory=4)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'lightning run')}\"\n\n    # Get the ids from env variables\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    # Create a new job\n    job = Studio.create_job(\n        project_id=project_id,\n        cloudspace_id=cloud_space_id,\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    # Get the job URL\n    job_url = Studio.get_job_url(project_id=project_id, cloudspace_id=cloud_space_id, job_id=job.id)\n\n    # Print the job URL\n    print(f\"Job URL: {job_url}\")\n\n    # Wait for the job to start\n    while True:\n        job = Studio.get_job(project_id=project_id, cloudspace_id=cloud_space_id, job_id=job.id)\n        if job.state == \"STARTED\":\n            break\n        sleep(1)\n\n    # Wait for the job to finish\n    while True:\n        job = Studio.get_job(project_id=project_id, cloudspace_id=cloud_space_id, job_id=job.id)\n        if job.state == \"SUCCEEDED\":\n           "}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"Lightning SDK is not available. Please install it using `pip install lightning-sdk` or `pip install lightning-cloud`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"Boto3 is not available. Please install it using `pip install boto3` or `pip install lightning-cloud`.\"\n        )\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=0, memory=1)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && \"\n\n        for key, value in os.environ.items():\n            command += f\"export {key}={value} && \"\n\n        command += f\"python -m lightning_cloud.operator.run\"\n\n    job = Studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n        cluster_id=cluster_id,\n        project_id=project_id,\n        cloud_space_id=cloud_space_id,\n        lightning_cloud_url=_get_lightning_cloud_url(),\n    )\n\n    print(f\"The job {job.name} has been created. Waiting for the job to start...\")\n\n    while True:\n        job = Studio.get_job(job.id, cluster_id, project_id, cloud_space_id, _get_lightning_cloud_url())\n\n        if job.state == \"RUNNING\":\n            print(f\"The job {job.name} has"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"This function requires the lightning_sdk package to be installed. \"\n            \"Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND')}\"\n\n    # Get the ids from env variables\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    job = Studio.create_job(\n        name=name,\n        project_id=project_id,\n        cloud_space_id=cloud_space_id,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/projects/{project_id}/cloudspaces/{cloud_space_id}/jobs/{job.id}\"\n\n    print(f\"Job {job.id} created. Waiting for the job to start.\")\n\n    while True:\n        job = Studio.get_job(project_id=project_id, cloud_space_id=cloud_space_id, job_id=job.id)\n        if job.status == \"running\":\n            print(f\"Job {job.id} started. You can check its status at {job_url}\")\n            break\n        if job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"Job {job.id} failed. You can check its status at {job_url}\")\n        sleep(1)\n\n    while True:\n        job = Studio.get_job(project_id=project_id, cloud_space_id=cloud_space_id, job_id=job.id)\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job {job.id} failed. You can check its status"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` package is required to execute jobs remotely. Please install it with `pip install lightning_sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine(cpu=2, gpu=1, memory=4)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'lightning run --cloud')}\"\n\n    job = Studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n        workspace_url=os.getenv(\"LIGHTNING_CLOUD_WORKSPACE_URL\", \"https://lightning.ai/\"),\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job = Studio.get_job(job.id)\n        if job.status == \"RUNNING\":\n            break\n        elif job.status == \"FAILED\":\n            raise RuntimeError(f\"Job failed with error: {job.error}\")\n        sleep(1)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The lightning_sdk package is required to run this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"The boto3 package is required to run this function.\")\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=0, memory=1)\n\n    if command is None:\n        command = f'cd \"{os.getcwd()}\" && {os.getenv(\"LIGHTNING_CLOUD_COMMAND\", \"lightning run\")}'\n\n    # Get the ids from env variables\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    # Create a new job\n    job = Studio.create_job(\n        name=name,\n        project_id=project_id,\n        cloud_space_id=cloud_space_id,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    # Wait for the job to start\n    while True:\n        job = Studio.get_job(job.id)\n        if job.status == \"running\":\n            break\n        sleep(1)\n\n    # Print the job URL\n    print(f\"Job URL: {job.url}\")\n\n    # Wait for the job to finish\n    while True:\n        job = Studio.get_job(job.id)\n        if job.status == \"finished\":\n            break\n        sleep(1)\n\n    # Raise an exception if the job failed\n    if job.status == \"failed\":\n        raise RuntimeError(\"Job failed.\")\n\n    # Print the job URL\n    print(f\"Job URL: {job.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"This function requires the `lightning_sdk` package to be installed. Please install it with `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"This function requires the `boto3` package to be installed. Please install it with `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            instance_type=\"standard_gpu\",\n            instance_family=\"gpu\",\n            instance_size=\"small\",\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud.run_operator\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n        environment_variables=os.environ,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status != \"completed\":\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job failed with error: {job.error_message}\")\n        sleep(5)\n        job = studio.get_job(job.id)\n\n    print(f\"Job completed successfully.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"This function requires the `lightning_sdk` package to be installed. Please install it with `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"This function requires the `boto3` package to be installed. Please install it with `pip install boto3`.\"\n        )\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    # Get the current working directory\n    cwd = os.getcwd()\n\n    # Get the environment variables\n    env_vars = os.environ.copy()\n\n    # Set the command to be executed\n    if command is None:\n        command = f\"cd {cwd} && {sys.executable} -m lightning.app.cli.run --cloud --cloud_space_id {cloud_space_id}\"\n\n    # Create a machine object if not provided\n    if machine is None:\n        machine = Machine(\n            \"lightning.ai/lightning-cloud-m5-4xlarge\",\n            min_instances=num_nodes,\n            max_instances=num_nodes,\n        )\n\n    # Create the job\n    job = Studio.create_job(\n        name=name,\n        entrypoint=command,\n        machine=machine,\n        project_id=project_id,\n        cluster_id=cluster_id,\n        cloud_space_id=cloud_space_id,\n        env=env_vars,\n    )\n\n    # Wait for the job to start\n    while True:\n        job = Studio.get_job(job.id)\n        if job.status == \"PENDING\":\n            print(\"Job is pending...\")\n        elif job"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The `lightning_sdk` package is required to execute the current operator.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"The `boto3` package is required to execute the current operator.\")\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=0, memory=2)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud.operator\"\n\n    job = Studio.create_job(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n        environment_variables=os.environ,\n        max_restarts=0,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job = Studio.get_job(job.id)\n        if job.status == \"RUNNING\":\n            break\n        sleep(1)\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job {job.name} failed with the following error: {job.error}\")\n\n    print(f\"Job {job.name} finished successfully.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` is not available. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"The `boto3` is not available. Please install it with `pip install boto3`.\")\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=0, memory=2)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} {__file__} {name} {num_nodes} --machine {machine}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        command=command,\n        num_nodes=num_nodes,\n        machine=machine,\n    )\n    job_url = f\"{_get_lightning_cloud_url()}/projects/{job.project_id}/jobs/{job.id}\"\n\n    print(f\"Job URL: {job_url}\")\n\n    while job.status != \"SUCCEEDED\":\n        sleep(5)\n        job = studio.get_job(job.id)\n        if job.status == \"FAILED\":\n            raise RuntimeError(f\"Job failed with error: {job.error_message}\")\n\n    print(\"Job completed successfully!\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The `lightning_sdk` package is required to run this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"The `boto3` package is required to run this function.\")\n\n    studio = Studio()\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=1, memory=1)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'lightning run --cloud')}\"\n\n    job_id = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    job = studio.get_job(job_id)\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job {job_id} failed with the following error: {job.error}\")\n\n    if job.status == \"PENDING\":\n        raise RuntimeError(f\"The job {job_id} is pending and hasn't started yet.\")\n\n    if job.status == \"RUNNING\":\n        print(f\"The job {job_id} has started and is running. You can check its status at {job.url}\")\n\n    while job.status == \"RUNNING\":\n        sleep(10)\n        job = studio.get_job(job_id)\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job {job_id} failed with the following error: {job.error}\")\n\n    if job.status == \"SUCCEEDED\":\n        print(f\"The job {job_id} has finished successfully.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"This function requires the `lightning-sdk` package to be installed.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"This function requires the `boto3` package to be installed.\")\n\n    if machine is None:\n        machine = Machine(cpu=2, gpu=1, memory=4)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'lightning run --cloud')}\"\n\n    job = Studio.create_job(\n        name=name,\n        command=command,\n        machine=machine,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job created. Waiting for job to start. URL: {job.url}\")\n\n    while True:\n        job = Studio.get_job(job.id)\n\n        if job.status == \"RUNNING\":\n            print(f\"Job started. URL: {job.url}\")\n            break\n        elif job.status == \"FAILED\":\n            raise RuntimeError(f\"Job failed. URL: {job.url}\")\n        elif job.status == \"CANCELED\":\n            raise RuntimeError(f\"Job canceled. URL: {job.url}\")\n        elif job.status == \"SUCCEEDED\":\n            raise RuntimeError(f\"Job succeeded. URL: {job.url}\")\n\n        sleep(1)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"Please install the lightning_sdk to use this feature.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'lightning run --cloud')}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job = studio.get_job(job.id)\n        if job.status == \"RUNNING\":\n            break\n        elif job.status == \"FAILED\":\n            raise RuntimeError(\"Job failed.\")\n        sleep(1)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"The lightning_sdk is required to execute the current operator remotely.\")\n\n    if machine is None:\n        machine = Machine(name=\"cpu-small\")\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && \"\n        for k, v in os.environ.items():\n            command += f\"export {k}={v} && \"\n        command += \"python -m lightning_cloud.operator\"\n\n    job = Studio.create_job(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    job_id = job.id\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job_id}\"\n\n    print(f\"Job URL: {job_url}\")\n\n    while True:\n        job = Studio.get_job(job_id)\n\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job failed with status: {job.status}.\")\n\n        if job.status == \"running\":\n            break\n\n        sleep(5)\n\n    print(f\"Job started with status: {job.status}.\")\n\n    while True:\n        job = Studio.get_job(job_id)\n\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job failed with status: {job.status}.\")\n\n        if job.status == \"finished\":\n            break\n\n        sleep(5)\n\n    print(f\"Job finished with status: {job.status}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` package is required to run this function. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=1)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} {sys.argv[0]} {sys.argv[1:]}\"\n\n    client = Studio.client()\n\n    job = client.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job = client.get_job(job.id)\n        if job.status == \"running\":\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"Job failed: {job.error_message}\")\n        sleep(10)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    # Check if lightning_sdk is available\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The lightning_sdk package is not available. Please install it using 'pip install lightning_sdk'.\"\n        )\n\n    # Check if machine is provided\n    if machine is None:\n        machine = Machine(cpu=2, gpu=0, memory=8)\n\n    # Check if command is provided\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND')}\"\n\n    # Get the studio object\n    studio = Studio.get_instance()\n\n    # Create the job\n    job = studio.create_job(\n        name=name,\n        command=command,\n        machine=machine,\n        num_nodes=num_nodes,\n    )\n\n    # Wait for the job to start\n    while True:\n        job = studio.get_job(job.id)\n        if job.status == \"RUNNING\":\n            print(f\"Job {job.id} started. You can view it at {job.url}\")\n            break\n        sleep(1)\n\n    # Wait for the job to complete\n    while True:\n        job = studio.get_job(job.id)\n        if job.status == \"COMPLETED\":\n            print(f\"Job {job.id} completed.\")\n            break\n        sleep(1)\n\n    # Check if the job failed\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"Job {job.id} failed. Please check the logs for more details.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"To use this function, you need to install the lightning_sdk package. \"\n            \"You can install it by running `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"To use this function, you need to install the boto3 package. \"\n            \"You can install it by running `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            name=\"data-prep-machine\",\n            machine_type=\"cpu\",\n            instance_type=\"m5.xlarge\",\n            image=\"lightning-base\",\n            instance_count=num_nodes,\n            max_restarts=0,\n            max_run_time_seconds=None,\n        )\n\n    if command is None:\n        command = (\n            \"cd \"\n            + os.getcwd()\n            + \" && \"\n            + \" && \".join(\n                [\n                    f\"export {key}={value}\"\n                    for key, value in os.environ.items()\n                    if key not in [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\"]\n                ]\n            )\n            + \" && \"\n            + \" \".join(sys.argv)\n        )\n\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"To use this function, you need to install the lightning_sdk package. \"\n            \"You can install it by running `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"To use this function, you need to install the boto3 package. \"\n            \"You can install it by running `pip install boto3`.\"\n        )\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        machine=machine,\n        command=command,\n    )\n\n    job_url = _get_lightning_cloud_url() + \"/jobs/\" + job.id\n\n    print(f\"Job {job.id} created. You can monitor the job at {job_url}\")\n\n    job_status = job.status\n\n    while job_status == \"PENDING\":\n        job = studio.get_job(job.id)\n        job_status = job.status\n        sleep(1)\n\n    if job_"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"Please install the lightning_sdk to use this function.\")\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=1)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'lightning run --cloud')}\"\n\n    if Studio.is_available():\n        job = Studio.execute(\n            name=name,\n            num_nodes=num_nodes,\n            machine=machine,\n            command=command,\n        )\n        print(f\"Job URL: {job.url}\")\n\n        while job.status == \"PENDING\":\n            print(\"Job status: PENDING\")\n            sleep(5)\n\n        if job.status == \"RUNNING\":\n            print(\"Job status: RUNNING\")\n            while True:\n                sleep(5)\n\n        if job.status == \"FAILED\":\n            print(\"Job status: FAILED\")\n            raise RuntimeError(f\"Job failed with message: {job.message}\")\n\n        if job.status == \"SUCCEEDED\":\n            print(\"Job status: SUCCEEDED\")\n\n    else:\n        raise RuntimeError(\"Please log in to the Lightning Cloud to use this function.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` package is required to execute this function. Install it with `pip install lightning-sdk`.\"\n        )\n\n    if not isinstance(name, str):\n        raise ValueError(\"The `name` must be a string.\")\n\n    if not isinstance(num_nodes, int):\n        raise ValueError(\"The `num_nodes` must be an integer.\")\n\n    if machine is not None and not isinstance(machine, Machine):\n        raise ValueError(\"The `machine` must be a `Machine` object.\")\n\n    if command is not None and not isinstance(command, str):\n        raise ValueError(\"The `command` must be a string.\")\n\n    if machine is None:\n        machine = Machine(cpu=1, gpu=0, memory=2)\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'python main.py')}\"\n\n    studio = Studio.from_url(_get_lightning_cloud_url())\n\n    job = studio.create_data_preparation_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    print(f\"Job created. Job URL: {job.url}\")\n\n    while True:\n        job.refresh()\n\n        if job.status == \"RUNNING\":\n            print(f\"Job status: {job.status}. Waiting for job to complete.\")\n            sleep(10)\n            continue\n\n        if job.status == \"FAILED\":\n            raise RuntimeError(f\"Job failed with the following error: {job.error}\")\n\n        print(f\"Job status: {job.status}. Job completed successfully.\")\n        break\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `execute` function requires the `lightning_sdk` package to be installed. \"\n            \"Please install it using `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `execute` function requires the `boto3` package to be installed. \"\n            \"Please install it using `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            cpu=1,\n            gpu=0,\n            memory=1,\n            instance_type=\"t3.large\",\n            accelerator=\"cpu\",\n            image=\"lightningai/lightning:latest\",\n            dockerfile=None,\n            environment=None,\n            requirements=None,\n            registry_credential=None,\n            cloud_compute=None,\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && \"\n        for k, v in os.environ.items():\n            command += f\"export {k}={v} && \"\n        command += f\"python {sys.argv[0]}\"\n\n    job_id = Studio.execute(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    job = Studio.get_job(job_id)\n    job_url = f\"{_get_lightning_cloud_url()}/projects/{job.project_id}/jobs/{job.id}\"\n\n    print(f\"Job {job_id} started. View it at {job_url}.\")\n\n    while True:\n        job = Studio.get_job(job_id)\n        if job.status == \"running\":\n            break\n        elif job.status == \"failed\":\n            raise RuntimeError(f\"Job {job_id} failed. View it at {job_url}.\")\n        sleep(5)\n\n    print(f\"Job {job_id} is running. View it at {job_url}.\")"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            # Load the config containing the index\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._item_loader,\n                compression=self._compression,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config is already loaded, return it\n        if self._config is not None:\n            return self._config\n\n        # Try to load the config\n        try:\n            self._config = ChunksConfig.load(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n        except Exception as e:\n            logger.warning(f\"Failed to load the config: {e}\")\n            self._config = None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n            self._config = config\n            return config\n        except Exception as e:\n            logger.error(f\"Failed to load the chunks config: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig.from_cache_dir(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._compression,\n                self._item_loader,\n            )\n            return self._config\n        except Exception:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n        except FileNotFoundError:\n            return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._item_loader,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception as e:\n            logger.debug(f\"Failed to load the config file. {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n        except Exception as e:\n            logger.warning(f\"Failed to load the chunks config: {e}\")\n            return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Unable to load the chunks configuration: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config is already loaded, return it\n        if self._config is not None:\n            return self._config\n\n        # Try to load the config from the cache dir\n        config = ChunksConfig.load_from_cache_dir(\n            self._cache_dir,\n            self._serializers,\n            self._remote_input_dir,\n            self._compression,\n            self._item_loader,\n        )\n\n        # If the config was loaded, update the instance's config and return it\n        if config is not None:\n            self._config = config\n            return self._config\n\n        # If the config was not loaded, return None\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig.from_cache_dir(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception as e:\n            logger.warning(f\"Couldn't load the config file. Error: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Try to load the config\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n        except Exception:\n            # If the config isn't available, return None\n            return None\n\n        # If the config is available, return it\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the index files are available\n        index_files = [\n            os.path.join(self._cache_dir, f\"{self._item_loader.name}.index\"),\n            os.path.join(self._cache_dir, f\"{self._item_loader.name}.index.gz\"),\n        ]\n        if not any(os.path.exists(f) for f in index_files):\n            return None\n\n        # Try to load the index files\n        for index_file in index_files:\n            if os.path.exists(index_file):\n                self._config = ChunksConfig(\n                    cache_dir=self._cache_dir,\n                    serializers=self._serializers,\n                    remote_input_dir=self._remote_input_dir,\n                    compression=self._compression,\n                    item_loader=self._item_loader,\n                    index_file=index_file,\n                )\n                return self._config\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception as e:\n            logger.warning(f\"Failed to load the index: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config is already loaded, return it\n        if self._config is not None:\n            return self._config\n\n        # If the index files are not available, return None\n        if not self._index_files_available():\n            return None\n\n        # If the index files are available, try to load the config\n        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._item_loader,\n                self._compression,\n            )\n            return self._config\n        except Exception as e:\n            logger.warning(f\"Failed to load the configuration file. {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config is already loaded, return it\n        if self._config is not None:\n            return self._config\n\n        # If the index files are not available, return None\n        if not os.path.exists(os.path.join(self._cache_dir, \"index\")):\n            return None\n\n        # Try to load the config\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n        except Exception as e:\n            raise Exception(\n                \"The reader index is defined but the index files are not valid. \"\n                \"Please check that the index files are valid and that the reader index is defined correctly.\"\n            ) from e\n\n        # If the config was successfully loaded, return it\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig.load(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._item_loader,\n                self._compression,\n            )\n            return self._config\n        except Exception as e:\n            logger.warning(f\"Couldn't load the config file. Reason: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        # If the queue is full, wait for a short period of time before trying again\n        for _ in range(self._max_pre_download):\n            if self._to_download_queue.full():\n                self._pre_download_counter += 1\n                if self._pre_download_counter > 5:\n                    logger.warning(\n                        \"The download queue is full. \"\n                        \"This could be because the dataset is too large to fit on the node. \"\n                        \"Try increasing the max_cache_size parameter.\"\n                    )\n                self._pre_download_counter %= 5\n                return\n            try:\n                self._to_download_queue.put_nowait(chunk_indexes)\n                return\n            except multiprocessing.queues.Full:\n                pass\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader index isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader index isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader index isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration of the BinaryReader is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader index isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set. Please call `load_config` first.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader index isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex, got {type(index)}\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk is not already downloaded, download it\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n\n            if self._prepare_thread is None:\n                self._prepare_thread = PrepareChunksThread(\n                    self._config, self._item_loader, self._distributed_env, self._max_cache_size\n                )\n                self._prepare_thread.start()\n\n            self._prepare_thread.download([chunk_index])\n\n        # Read the item\n        return self._item_loader.read(index, self._config)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        # Get the item\n        item = self._item_loader.get_item(index)\n\n        # Delete the chunk if needed\n        if self._prepare_thread._delete_chunks_when_processed:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` is not an instance of ChunkedIndex.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index is None:\n            chunk_index = self._get_chunk_index_from_index(index.index)\n\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._item_loader.load(chunk_index)\n\n        if self._prepare_thread is not None:\n            self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` is not an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check whether the chunk is already downloaded\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n\n            # Check whether the chunk is available locally\n            if not self._config.is_chunk_available(chunk_index):\n                # If not, download the chunk\n                self._config.download_chunk_from_index(chunk_index)\n\n            # Check whether the chunk is available in memory\n            if not self._item_loader.is_chunk_available(chunk_index):\n                # If not, load the chunk\n                self._item_loader.load_chunk(chunk_index)\n\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index is None:\n            chunk_index = self._get_chunk_index_from_index(index.index)\n\n        if chunk_index != self._last_chunk_index:\n            if self._prepare_thread is None:\n                raise Exception(\"The prepare thread is not defined.\")\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        return self._item_loader.read(index, self._config._get_chunk_filepath(chunk_index))\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex. Got {index}.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk index is different from the last one, we need to download it\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n\n            # Check if the prepare thread is running\n            if self._prepare_thread is None:\n                raise Exception(\"The prepare thread isn't running.\")\n\n            # Download the chunk\n            self._prepare_thread.download([chunk_index])\n\n        # Read the item from the chunk\n        return self._item_loader.read(index, self._config)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` is not a ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._item_loader.load_chunk(chunk_index)\n\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be a ChunkedIndex but got {type(index)}.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # If the chunk is not in the cache, download it\n        chunk_index = index.chunk_index\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._config.download_chunk_from_index(chunk_index)\n\n        # If the prepare thread is not running, start it\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                max_cache_size=self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        # If the prepare thread is not running, start it\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                max_cache_size=self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        # Get the item\n        item = self._item_loader.get_item(index)\n\n        # Delete the chunk if it is fully processed\n        if self._item_loader.is_chunk_fully_processed(index.chunk_index):\n            self._prepare_thread.delete([index.chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex. Got {type(index)} instead.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check if the chunk is already downloaded\n        if self._last_chunk_index is None or self._last_chunk_index != chunk_index:\n            # Download the chunk if needed\n            self._download_chunk(chunk_index)\n            self._last_chunk_index = chunk_index\n\n        # Get the item from the chunk\n        return self._item_loader.get_item(index, self._config)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The reader prepare thread isn't defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk is already downloaded, we can directly read it\n        if chunk_index == self._last_chunk_index:\n            return self._item_loader.read(index)\n\n        # Otherwise, we need to download the chunk\n        self._last_chunk_index = chunk_index\n        self._prepare_thread.download([chunk_index])\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index must be a ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = index.chunk_index\n\n        # If the chunk index is None, we need to get it from the index\n        if chunk_index is None:\n            chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk index is the same as the last one, we can just read it from the cache\n        if self._last_chunk_index == chunk_index:\n            return self._item_loader.read(index)\n\n        # If the chunk index is different, we need to download it first\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config, self._item_loader, self._distributed_env, self._max_cache_size\n            )\n            self._prepare_thread.start()\n\n        # Download the chunk\n        self._prepare_thread.download([chunk_index])\n\n        # Read the item\n        item = self._item_loader.read(index)\n\n        # Delete the chunk\n        self._prepare_thread.delete([chunk_index])\n\n        # Store the chunk index\n        self._last_chunk_index = chunk_index\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be a ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # We need to download the chunk if it is not already present\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        return self._item_loader.read(index, self._config)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index must be an instance of ChunkedIndex. Got {type(index)}\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Download the chunk if it hasn't been downloaded yet\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        # Read the item\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex, got {type(index)}.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._config._get_chunk_index_from_index(index.index)\n\n        # If the chunk index is different from the last one, we need to download the chunk\n        if self._last_chunk_index != chunk_index:\n            if self._prepare_thread is None:\n                self._prepare_thread = PrepareChunksThread(\n                    self._config,\n                    self._item_loader,\n                    self._distributed_env,\n                    max_cache_size=self._max_cache_size,\n                )\n                self._prepare_thread.start()\n\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        # Read the item from the chunk\n        chunk_filepath, _, _ = self._config[ChunkedIndex(index=-1, chunk_index=chunk_index)]\n        item = self._item_loader.read(index, chunk_filepath)\n\n        # Delete the chunk if needed\n        if self._prepare_thread is not None:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # The index should be a ChunkedIndex\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be a ChunkedIndex but got {type(index)}.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # If the chunk index is not defined, we need to compute it\n        if index.chunk_index is None:\n            index = ChunkedIndex(index=index.index, chunk_index=self._get_chunk_index_from_index(index.index))\n\n        # Check if the chunk is already loaded\n        if not self._item_loader.is_chunk_loaded(index.chunk_index):\n            # If not, we need to load the chunk\n            self._load_chunk(index.chunk_index)\n\n        # Get the item from the chunk\n        item = self._item_loader.get_item(index)\n\n        # Return the item\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be a ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = index.chunk_index\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self._config[chunk_index]\n\n        # Download the chunk if not available\n        if not self._item_loader.is_chunk_available(chunk_index):\n            if self._prepare_thread is None:\n                self._prepare_thread = PrepareChunksThread(\n                    self._config,\n                    self._item_loader,\n                    self._distributed_env,\n                    max_cache_size=self._max_cache_size,\n                    max_pre_download=self._config.num_chunks,\n                )\n                self._prepare_thread.start()\n\n            # Download the chunk\n            self._config.download_chunk_from_index(chunk_index)\n\n            # Preload item if possible\n            if self._prepare_thread:\n                self._prepare_thread._pre_load_chunk(chunk_index)\n\n        # Read the item\n        item = self._item_loader.read(index, chunk_filepath)\n\n        # Delete the chunk if possible\n        if self._prepare_thread:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # The chunk index is the same as the last one\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index == self._last_chunk_index:\n            return self._item_loader.read(index)\n\n        # The chunk index has changed, we need to download the new chunk\n        self._prepare_thread.download([chunk_index])\n\n        # Delete the current chunk\n        self._prepare_thread.delete([self._last_chunk_index])\n\n        # Read the new chunk\n        self._last_chunk_index = chunk_index\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index {index} is not an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        chunk_filepath, start, end = self._config[chunk_index]\n\n        # If the chunk is not already loaded, download it\n        if self._last_chunk_index is None or self._last_chunk_index != chunk_index:\n            self._last_chunk_index = chunk_index\n            if self._prepare_thread is not None:\n                self._prepare_thread.download([chunk_index])\n\n        # Read the item\n        item = self._item_loader.read(chunk_index, chunk_filepath, start, end, self._compression)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` is not an instance of ChunkedIndex.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._prepare_chunks(chunk_index)\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # Wait for the chunk to be downloaded\n        self._prepare_thread.join(timeout=1)\n\n        # Read the chunk\n        chunk_filepath, chunk_start, chunk_end = self._config[index]\n        item = self._item_loader.read(chunk_index, chunk_filepath, chunk_start, chunk_end)\n\n        # Delete the chunk if needed\n        if self._prepare_thread._delete_chunks_when_processed:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be a ChunkedIndex, got {type(index)}.\")\n\n        if index.index == -1:\n            # We are reading a chunk\n            if index.chunk_index == -1:\n                # We are reading the whole dataset\n                chunk_index = 0\n            else:\n                chunk_index = index.chunk_index\n        else:\n            chunk_index = self._get_chunk_index_from_index(index.index)\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # Download the chunk if needed\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        # Read the item\n        chunk_filepath, start, end = self.config[chunk_index]\n        return self._item_loader.read(chunk_index, chunk_filepath, start, end)\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_mode():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_cloud_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if not _is_in_distributed_environment():\n        return obj\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_in_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # Check if we're in a distributed environment\n    lightning_app_external_url = os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\")\n    if lightning_app_external_url is None:\n        return obj\n\n    # If so, we broadcast the object\n    imd_map = _ImmutableDistributedMap()\n    return imd_map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    intra_node_chunk_shuffle = []\n    for i in range(distributed_env.num_nodes):\n        intra_node_chunk_shuffle.append(np.random.permutation(chunks_per_ranks[i]))\n    intra_node_chunk_shuffle = np.concatenate(intra_node_chunk_shuffle)\n    return intra_node_chunk_shuffle\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed for the shuffle\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunks per rank\n    shuffled_chunks_per_rank = [np.random.permutation(chunks) for chunks in chunks_per_ranks]\n\n    # Flatten the shuffled chunks per rank\n    shuffled_chunks = [chunk for chunks in shuffled_chunks_per_rank for chunk in chunks]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    chunk_indexes = []\n    for i, chunks in enumerate(chunks_per_ranks):\n        np.random.seed(seed + current_epoch)\n        np.random.shuffle(chunks)\n        chunk_indexes.extend(chunks)\n    return chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # Get the world size\n    world_size = distributed_env.world_size\n\n    # Get the node rank\n    node_rank = distributed_env.node_rank\n\n    # Get the node size\n    node_size = distributed_env.node_size\n\n    # Get the chunk indexes assigned to this node\n    chunks_per_node = chunks_per_ranks[node_rank]\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_node)\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // node_size\n\n    # Get the number of chunks per node\n    num_chunks_per"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes and the world size\n    num_nodes = distributed_env.num_nodes\n    world_size = distributed_env.world_size\n\n    # Compute the number of chunks per node\n    num_chunks_per_node = len(chunks_per_ranks[0])\n\n    # Compute the number of chunks per rank\n    num_chunks_per_rank = num_chunks_per_node // num_nodes\n\n    # Compute the total number of chunks\n    total_num_chunks = num_chunks_per_node * world_size\n\n    # Compute the total number of chunks per rank\n    total_num_chunks_per_rank = num_chunks_per_rank * world_size\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num_nodes\n\n    # Compute the total number of chunks per node\n    total_num_chunks_per_node = num_chunks_per_node * num"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the seed for the shuffle\n    np.random.seed(seed + current_epoch)\n\n    # Create a list of shuffled chunk indexes for each node\n    shuffled_chunks = []\n    for rank in range(distributed_env.world_size):\n        shuffled_chunks.append(np.random.permutation(chunks_per_ranks[rank]))\n\n    # Flatten the list of shuffled chunk indexes\n    shuffled_chunks = [item for sublist in shuffled_chunks for item in sublist]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    intra_node_chunk_indexes = []\n    for rank in range(distributed_env.world_size):\n        np.random.seed(seed + current_epoch + rank)\n        intra_node_chunk_indexes.extend(\n            np.random.permutation(chunks_per_ranks[rank]).tolist()\n        )\n    return intra_node_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed for random number generation\n    np.random.seed(seed + current_epoch)\n\n    # Create a list of shuffled chunk indexes for each node\n    shuffled_chunk_indexes = []\n    for node in range(distributed_env.num_nodes):\n        # Shuffle the chunk indexes for the current node\n        np.random.shuffle(chunks_per_ranks[node])\n        shuffled_chunk_indexes.extend(chunks_per_ranks[node])\n\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed for random number generation\n    np.random.seed(seed + current_epoch)\n\n    # Get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # Initialize the shuffled chunks list\n    shuffled_chunks = []\n\n    # Iterate over the nodes\n    for node in range(num_nodes):\n\n        # Get the chunk indexes for the current node\n        chunks_for_node = chunks_per_ranks[node]\n\n        # Shuffle the chunks for the current node\n        np.random.shuffle(chunks_for_node)\n\n        # Add the shuffled chunks for the current node to the shuffled chunks list\n        shuffled_chunks.extend(chunks_for_node)\n\n    # Return the shuffled chunks list\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Generate a random seed for each node based on the provided seed and the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Get the number of nodes in the distributed environment\n    num_nodes = distributed_env.num_nodes\n\n    # Create a list to store the shuffled chunk indexes\n    shuffled_chunk_indexes = []\n\n    # Iterate over the nodes\n    for node in range(num_nodes):\n\n        # Get the chunk indexes assigned to the current node\n        node_chunk_indexes = chunks_per_ranks[node]\n\n        # Shuffle the chunk indexes using the provided seed\n        np.random.shuffle(node_chunk_indexes)\n\n        # Append the shuffled chunk indexes to the list\n        shuffled_chunk_indexes.extend(node_chunk_indexes)\n\n    # Return the shuffled chunk indexes\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # Initialize the list of shuffled chunks\n    shuffled_chunks = []\n\n    # Iterate over the number of nodes\n    for node_id in range(num_nodes):\n\n        # Get the chunk indexes assigned to this node\n        chunks_on_this_node = chunks_per_ranks[node_id]\n\n        # Shuffle the chunk indexes on this node\n        np.random.seed(seed + current_epoch + node_id)\n        np.random.shuffle(chunks_on_this_node)\n\n        # Add the shuffled chunk indexes to the list\n        shuffled_chunks.extend(chunks_on_this_node)\n\n    # Return the shuffled chunk indexes across all nodes\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes and the world size\n    num_nodes = distributed_env.num_nodes\n    world_size = distributed_env.world_size\n\n    # Initialize the seed\n    np.random.seed(seed + current_epoch)\n\n    # Get the chunk indexes assigned to each rank\n    chunk_indexes = np.arange(len(chunks_per_ranks[0]))\n\n    # Shuffle the chunk indexes for each rank\n    for rank in range(world_size):\n        np.random.shuffle(chunk_indexes)\n\n    # Create a list of chunk indexes for each node\n    node_chunks = [[] for _ in range(num_nodes)]\n    for rank in range(world_size):\n        node_chunks[rank % num_nodes].extend(chunk_indexes)\n\n    # Flatten the list of chunk indexes for each node\n    flattened_chunks = [chunk for node_chunks in node_chunks for chunk in node_chunks]\n\n    return flattened_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Create a list of all chunk indexes across all nodes.\n    all_chunks = [chunk for rank in chunks_per_ranks for chunk in rank]\n\n    # Shuffle the chunk indexes based on the seed and current epoch.\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(all_chunks)\n\n    # Split the shuffled chunk indexes into chunks for each node.\n    chunk_chunks = np.array_split(all_chunks, distributed_env.num_nodes)\n\n    # Create a list of chunk indexes for each node.\n    chunks_per_ranks = [\n        chunk_chunks[node_idx].tolist() for node_idx in range(distributed_env.num_nodes)\n    ]\n\n    # Flatten the chunk indexes for each node into a single list.\n    all_chunks = [chunk for rank in chunks_per_ranks for chunk in rank]\n\n    return all_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the world size and the rank of the current node\n    world_size = distributed_env.world_size\n    rank = distributed_env.rank\n\n    # Create a random number generator with the provided seed\n    np.random.seed(seed + current_epoch)\n\n    # Get the number of chunks assigned to the current node\n    num_chunks = len(chunks_per_ranks[rank])\n\n    # Create a list of chunk indexes for the current node\n    chunk_indexes = list(range(num_chunks))\n\n    # Shuffle the chunk indexes using the random number generator\n    np.random.shuffle(chunk_indexes)\n\n    # Create a list of chunk indexes for all nodes\n    all_chunk_indexes = []\n\n    # Loop through the chunks assigned to each node\n    for node_id in range(world_size):\n        # Get the chunk indexes assigned to the current node\n        node_chunk_indexes = chunks_per_ranks[node_id]\n\n        # Loop through the chunk indexes assigned to the current node\n        for chunk_index in node_chunk_indexes:\n            # Append the chunk index to the list of all chunk indexes\n            all_chunk_indexes.append(chunk_index)\n\n    # Return the flattened list of chunk indexes\n    return all_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks per rank\n    num_chunks_per_rank = len(chunks_per_ranks[0])\n\n    # Create a seed based on the current epoch and the provided seed\n    seed = seed + current_epoch\n\n    # Initialize a list of shuffled chunk indexes\n    shuffled_chunk_indexes = []\n\n    # Iterate over each node\n    for node in range(distributed_env.num_nodes):\n\n        # Get the chunk indexes for the current node\n        chunk_indexes = chunks_per_ranks[node]\n\n        # Shuffle the chunk indexes\n        np.random.seed(seed)\n        np.random.shuffle(chunk_indexes)\n\n        # Add the shuffled chunk indexes to the list\n        shuffled_chunk_indexes.extend(chunk_indexes)\n\n    # Return the shuffled chunk indexes\n    return shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    intra_node_chunk_shuffle = np.random.permutation(\n        np.concatenate(chunks_per_ranks)\n    )\n    return intra_node_chunk_shuffle.tolist()\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # This function ensures that each node receives a randomized set of chunk indexes based on the provided seed and the current epoch, aiming to distribute data more evenly and randomly across nodes for each training epoch.\n\n    # Get the rank of the current node\n    rank = distributed_env.rank\n\n    # Get the number of chunks per node\n    num_chunks_per_node = len(chunks_per_ranks[rank])\n\n    # Get the number of nodes\n    num_nodes = distributed_env.world_size\n\n    # Get the node index of the current node\n    node_idx = rank % num_nodes\n\n    # Create a random number generator\n    rng = np.random.RandomState(seed + current_epoch)\n\n    # Create a list of chunk indexes\n    chunk_indexes = list(range(num_chunks_per_node))\n\n    # Shuffle the chunk indexes\n    rng.shuffle(chunk_indexes)\n\n    # Return the shuffled chunk indexes\n    return chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # Get the world size\n    world_size = distributed_env.world_size\n\n    # Get the local rank\n    local_rank = distributed_env.local_rank\n\n    # Get the global rank\n    global_rank = distributed_env.global_rank\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = len(chunks_per_ranks[0])\n\n    # Get the number of chunks per node\n    num_chunks_per_node = num_chunks_per_rank * num_nodes\n\n    # Get the number of chunks per world\n    num_chunks_per_world = num_chunks_per_node * world_size\n\n    # Get the number of chunks per epoch\n    num_chunks_per_epoch = num_chunks_per_world * current_epoch\n\n    # Get the random seed\n    random_seed = seed + current_epoch\n\n    # Create a list of chunk indexes\n    chunk_indexes = list(range(num_chunks_per_node))\n\n    # Shuffle the chunk indexes based on the random seed\n    np.random.seed(random_seed)\n    np.random.shuffle(chunk_indexes)\n\n    # Create a list of shuffled chunks\n    shuffled_chunks = []\n\n    # Iterate over the chunk indexes\n    for chunk_index in chunk_indexes:\n        # Get the chunk index for the current node\n        chunk_index_for_node = chunk_index + num_chunks_per_node * global_rank\n        # Get the chunk index for the current rank\n        chunk_index_for_rank = chunk_index + num_chunks_per_rank * local_rank\n        # Get the chunk index for the current world\n        chunk_index_for_world = chunk_index + num_chunks_per_world * current_epoch\n        # Get the chunk index for the current epoch\n        chunk_index_for_epoch = chunk_index + num_chunks_per_epoch\n        # Add the chunk index to the list of shuffled chunks\n        shuffled_chunks.append(\n            (chunk_index_for_node, chunk_index_for_rank, chunk_index_for_world, chunk_index_for_epoch)\n        )\n\n    # Sort the shuffled chunks based on the chunk index for the current"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    rank = distributed_env.rank\n    world_size = distributed_env.world_size\n    node_id = distributed_env.node_id\n\n    # Generate a random number generator using the seed and the current epoch.\n    rng = np.random.RandomState(seed + current_epoch)\n\n    # Randomly shuffle the chunks on each node.\n    for i in range(world_size):\n        if i == rank:\n            rng.shuffle(chunks_per_ranks[i])\n\n    # Gather the shuffled chunks on each node.\n    chunks_per_ranks = distributed_env.all_gather(chunks_per_ranks)\n\n    # Flatten the list of shuffled chunks on each node.\n    chunks_per_ranks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Reorder the chunks according to the node ID.\n    chunks_per_ranks = chunks_per_ranks[node_id::world_size]\n\n    return chunks_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes in the distributed environment.\n    num_nodes = distributed_env.num_nodes\n\n    # Get the world size (total number of ranks) in the distributed environment.\n    world_size = distributed_env.world_size\n\n    # Get the rank of the current node in the distributed environment.\n    rank = distributed_env.rank\n\n    # Get the list of chunk indexes assigned to the current node.\n    chunks_per_rank = chunks_per_ranks[rank]\n\n    # Get the number of chunks assigned to the current node.\n    num_chunks = len(chunks_per_rank)\n\n    # Initialize an empty list to store the shuffled chunk indexes.\n    shuffled_chunks = []\n\n    # Loop over the chunks assigned to the current node.\n    for chunk_idx in chunks_per_rank:\n        # Create a random seed based on the current epoch and the chunk index.\n        np.random.seed(seed + current_epoch + chunk_idx)\n\n        # Generate a random integer between 0 and the world size.\n        random_node = np.random.randint(world_size)\n\n        # If the random node is the current node, add the chunk index to the shuffled chunks.\n        if random_node == rank:\n            shuffled_chunks.append(chunk_idx)\n\n        # If the random node is not the current node, send the chunk index to that node.\n        else:\n            distributed_env.send(chunk_idx, random_node)\n\n    # If the current node is not the last node in the list, receive chunk indexes from the next node.\n    if rank != world_size - 1:\n        shuffled_chunks.extend(distributed_env.recv(rank + 1))\n\n    # If the current node is not the first node in the list, receive chunk indexes from the previous node.\n    if rank != 0:\n        shuffled_chunks.extend(distributed_env.recv(rank - 1))\n\n    # If the current node is the last node in the list, receive chunk indexes from the first node.\n    if rank == world_size - 1:\n        shuffled_chunks.extend(distributed_env.recv(0))\n\n    # Return the shuffled chunk indexes.\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs[0])\n    indexed_paths.update(_get_indexed_paths(inputs[1]))\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Found inconsistent file paths in inputs: {indexed_paths}. \"\n            f\"Please ensure that all inputs are consistent and contain valid file paths.\"\n        )\n\n    index, path = list(indexed_paths.items())[0]\n\n    if index != 0:\n        raise ValueError(\n            f\"Found inconsistent file paths in inputs: {indexed_paths}. \"\n            f\"Please ensure that all inputs are consistent and contain valid file paths.\"\n        )\n\n    if not os.path.exists(path):\n        raise ValueError(\n            f\"The input path {path} does not exist. \"\n            f\"Please ensure that the input path is valid and exists.\"\n        )\n\n    return _resolve_dir(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) > 0:\n        indexed_paths = _get_indexed_paths(inputs[0])\n        if len(indexed_paths) > 0:\n            return _resolve_dir(indexed_paths[0])\n\n    if len(inputs) > 1:\n        indexed_paths = _get_indexed_paths(inputs[1])\n        if len(indexed_paths) > 0:\n            return _resolve_dir(indexed_paths[0])\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # If the first element of the inputs is a string and the second element is a list,\n    # then the first element is the input directory and the second element is a list of\n    # file paths.\n    if len(inputs) >= 2 and isinstance(inputs[0], str) and isinstance(inputs[1], list):\n        input_dir = inputs[0]\n        file_paths = inputs[1]\n    # If the first element of the inputs is a string and the second element is a string,\n    # then the first element is the input directory and the second element is a file path.\n    elif len(inputs) >= 2 and isinstance(inputs[0], str) and isinstance(inputs[1], str):\n        input_dir = inputs[0]\n        file_paths = [inputs[1]]\n    # If the first element of the inputs is a list, then the first element is a list of\n    # file paths.\n    elif len(inputs) >= 1 and isinstance(inputs[0], list):\n        input_dir = None\n        file_paths = inputs[0]\n    # If the first element of the inputs is a string, then the first element is a file path.\n    elif len(inputs) >= 1 and isinstance(inputs[0], str):\n        input_dir = None\n        file_paths = [inputs[0]]\n    # If the first element of the inputs is a dict, then the first element is a dict of\n    # file paths.\n    elif len(inputs) >= 1 and isinstance(inputs[0], dict):\n        input_dir = None\n        file_paths = list(inputs[0].values())\n    # If the first element of the inputs is a tuple, then the first element is a tuple of\n    # file paths.\n    elif len(inputs) >= 1 and isinstance(inputs[0], tuple):\n        input_dir = None\n        file_paths = list(inputs[0])\n    else:\n        raise ValueError(\n            f\"Unable to determine input directory from inputs: {inputs}. \"\n            \"Inputs must be a list, tuple, dict, or string.\"\n        )\n\n    # If the input directory is not specified, then resolve the directory from the first\n    # file path.\n    if input_dir is None:\n        input_dir = _resolve_dir(file_paths[0])\n\n    # If"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get indexed paths from first two elements of inputs\n    indexed_paths = {\n        index: element\n        for index, element in enumerate(inputs[:2])\n        if isinstance(element, str) and os.path.exists(element)\n    }\n\n    # Check if indexed paths are consistent\n    if len(indexed_paths) > 0:\n        if not all(\n            os.path.dirname(path) == os.path.dirname(list(indexed_paths.values())[0])\n            for path in indexed_paths.values()\n        ):\n            raise ValueError(\"Inconsistent file paths in inputs.\")\n\n        # Format path to include project root or specified depth\n        path = list(indexed_paths.values())[0]\n        if _IS_IN_STUDIO:\n            return os.path.join(os.environ[\"PROJECT_ROOT\"], path)\n        else:\n            return os.path.join(os.environ[\"PROJECT_ROOT\"], os.path.dirname(path))\n\n    # Return None if no valid file paths are found\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(f\"More than two indexed paths found: {indexed_paths}\")\n\n    if len(indexed_paths) == 2:\n        if list(indexed_paths.keys()) != [0, 1]:\n            raise ValueError(f\"Indexed paths must be in order: {indexed_paths}\")\n\n    return _resolve_dir(list(indexed_paths.values())[0])\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Multiple files found in input sequence: {indexed_paths}. \"\n            f\"Please provide a single file or directory.\"\n        )\n\n    path = list(indexed_paths.values())[0]\n\n    if not os.path.exists(path):\n        raise ValueError(f\"File {path} not found.\")\n\n    return _resolve_dir(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) > 0:\n        first_index = min(indexed_paths.keys())\n        first_path = indexed_paths[first_index]\n\n        if len(indexed_paths) > 1:\n            second_index = max(indexed_paths.keys())\n            second_path = indexed_paths[second_index]\n\n            if not os.path.dirname(first_path) == os.path.dirname(second_path):\n                raise ValueError(\n                    \"Inconsistent file paths found in input sequence. Please ensure that all file paths are in the same directory.\"\n                )\n\n        if _IS_IN_STUDIO:\n            return _resolve_dir(first_path)\n        else:\n            return _resolve_dir(first_path, depth=2)\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Extract indexed paths from the first two elements of the input sequence\n    indexed_paths = {\n        index: element\n        for index, element in enumerate(inputs[:2])\n        if isinstance(element, str) and os.path.exists(element)\n    }\n\n    # Check if the indexed paths are consistent\n    if len(indexed_paths) == 2:\n        if indexed_paths[0] != indexed_paths[1]:\n            raise ValueError(\n                \"Inconsistent file paths found in the first two elements of the input sequence. \"\n                \"Please ensure that the input sequence contains valid file paths to the same directory.\"\n            )\n\n    # Format the path to include the project root or a specified depth in the file system\n    if len(indexed_paths) == 1:\n        path = indexed_paths[0]\n        if _IS_IN_STUDIO:\n            path = Path(path).relative_to(Path.cwd().parent)\n        else:\n            path = Path(path).relative_to(Path.cwd())\n        return str(path)\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            f\"Found {len(indexed_paths)} valid file paths in the input sequence. \"\n            \"Please ensure that only two valid file paths are provided.\"\n        )\n\n    if len(indexed_paths) == 1:\n        raise ValueError(\n            \"Found a single valid file path in the input sequence. \"\n            \"Please ensure that two valid file paths are provided.\"\n        )\n\n    if len(indexed_paths) == 2:\n        path_1, path_2 = indexed_paths.values()\n        if path_1 != path_2:\n            raise ValueError(\n                \"Found two inconsistent file paths in the input sequence. \"\n                \"Please ensure that two valid file paths are provided.\"\n            )\n\n    input_dir = indexed_paths[list(indexed_paths.keys())[0]]\n\n    if _IS_IN_STUDIO:\n        input_dir = Path(input_dir).resolve()\n    else:\n        input_dir = Path(input_dir).absolute()\n\n    return str(input_dir)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Check if the first two elements of the input sequence are valid file paths.\n    # If not, raise an error.\n    if not isinstance(inputs[0], str) or not os.path.exists(inputs[0]):\n        raise ValueError(f\"Invalid input path: {inputs[0]}\")\n    if not isinstance(inputs[1], str) or not os.path.exists(inputs[1]):\n        raise ValueError(f\"Invalid input path: {inputs[1]}\")\n\n    # Check if the first two elements of the input sequence have the same file path.\n    # If not, raise an error.\n    if inputs[0] != inputs[1]:\n        raise ValueError(f\"Inconsistent input paths: {inputs[0]}, {inputs[1]}\")\n\n    # Resolve the input directory by extracting the indexed paths from the input sequence and formatting the path.\n    indexed_paths = _get_indexed_paths(inputs)\n    input_dir = _resolve_dir(indexed_paths, depth=1)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            \"More than two file paths were found in the input sequence. \"\n            \"Please ensure that only two file paths are provided.\"\n        )\n\n    path_a, path_b = indexed_paths.values()\n\n    if not os.path.exists(path_a) or not os.path.exists(path_b):\n        raise ValueError(\n            \"One or both of the file paths provided do not exist. \"\n            \"Please ensure that the file paths are valid and accessible.\"\n        )\n\n    if not os.path.samefile(path_a, path_b):\n        raise ValueError(\n            \"The file paths provided are not the same. \"\n            \"Please ensure that only two file paths are provided.\"\n        )\n\n    path = _resolve_dir(path_a)\n\n    return path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # If the first element is a string, assume it's a file path.\n    if isinstance(inputs[0], str):\n        # If the second element is a string, assume it's a file path.\n        if isinstance(inputs[1], str):\n            # If the first element and the second element are different, raise an error.\n            if inputs[0] != inputs[1]:\n                raise ValueError(\n                    \"Inconsistent file paths found in the input sequence. The first two elements must be the same file path.\"\n                )\n            # If the first element and the second element are the same, return the absolute path to the input directory.\n            return os.path.abspath(inputs[0])\n        # If the second element is not a string, return the absolute path to the input directory.\n        return os.path.abspath(inputs[0])\n\n    # If the first element is not a string, return None.\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not inputs:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n    if not indexed_paths:\n        indexed_paths = _get_indexed_paths(inputs[1])\n\n    if not indexed_paths:\n        return None\n\n    input_dir = indexed_paths[0]\n    if len(indexed_paths) > 1:\n        if indexed_paths[1] != input_dir:\n            raise ValueError(\n                f\"Inconsistent input directories found: {indexed_paths[0]} and {indexed_paths[1]}\"\n            )\n\n    input_dir = _resolve_dir(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get the first two elements of the input sequence\n    first_two_elements = inputs[:2]\n\n    # Extract the indexed paths from the first two elements\n    indexed_paths = _get_indexed_paths(first_two_elements)\n\n    # Check if the indexed paths are consistent\n    if len(indexed_paths) == 0:\n        return None\n    elif len(indexed_paths) == 1:\n        path = list(indexed_paths.values())[0]\n        return _resolve_dir(path)\n    else:\n        # Check if the indexed paths are consistent\n        first_path = list(indexed_paths.values())[0]\n        second_path = list(indexed_paths.values())[1]\n        if first_path.startswith(second_path) or second_path.startswith(first_path):\n            raise ValueError(\n                \"Inconsistent paths found in input sequence. Please ensure that the input sequence contains valid file paths to the same directory.\"\n            )\n        else:\n            return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Multiple files found in inputs: {indexed_paths}. \"\n            f\"Please ensure that only one file is present in the inputs.\"\n        )\n\n    path = indexed_paths[list(indexed_paths.keys())[0]]\n\n    if _IS_IN_STUDIO:\n        path = Path(path).resolve()\n        path = path.relative_to(Path.cwd())\n        path = str(path)\n\n    return path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Check the first two elements of the input sequence for valid file paths\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # If there are no valid file paths, return None\n    if not indexed_paths:\n        return None\n\n    # Get the first and second indexed paths\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1] if len(indexed_paths) > 1 else None\n\n    # If the first path is a directory, return it\n    if os.path.isdir(first_path):\n        return first_path\n\n    # If the first and second paths are both files, raise an error\n    if os.path.isfile(first_path) and os.path.isfile(second_path):\n        raise ValueError(\n            \"The first two elements of the input sequence are both files. \"\n            \"Please ensure that the input sequence contains a valid directory path.\"\n        )\n\n    # If the first path is a file, return its parent directory\n    if os.path.isfile(first_path):\n        return os.path.dirname(first_path)\n\n    # If the first path is neither a file nor a directory, raise an error\n    raise ValueError(\n        \"The first element of the input sequence is neither a file nor a directory. \"\n        \"Please ensure that the input sequence contains a valid file path or directory path.\"\n    )\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"Expected a sequence of inputs, got {type(inputs)}\")\n\n    if not inputs:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n\n    if not indexed_paths:\n        indexed_paths = _get_indexed_paths(inputs[1])\n\n    if not indexed_paths:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Found multiple indexed paths in the first two elements of the input sequence: {indexed_paths}. \"\n            \"Please ensure that only one input is a valid file path, or adjust the input sequence accordingly.\"\n        )\n\n    path = list(indexed_paths.values())[0]\n\n    if _IS_IN_STUDIO:\n        path = _resolve_dir(path)\n\n    if not os.path.exists(path):\n        raise ValueError(f\"Input path does not exist: {path}\")\n\n    return path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"The inputs should contain a single file path, but multiple file paths were found: \"\n            + str(indexed_paths)\n        )\n\n    if len(indexed_paths) == 1:\n        path = list(indexed_paths.values())[0]\n\n        if not os.path.exists(path):\n            raise ValueError(f\"The path {path} does not exist.\")\n\n        return _resolve_dir(path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) > 0:\n        first_path = next(iter(indexed_paths.values()))\n        second_path = next(iter(indexed_paths.values()), None)\n\n        if first_path.startswith(\"gs://\") or first_path.startswith(\"s3://\"):\n            input_dir = first_path\n        elif second_path and not first_path.startswith(second_path):\n            raise ValueError(\n                f\"Inconsistent file paths found in inputs: {first_path} and {second_path}\"\n            )\n        else:\n            input_dir = first_path\n\n        input_dir = _resolve_dir(input_dir)\n        return input_dir\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) > 0:\n        indexed_paths = _get_indexed_paths(inputs[0])\n        if len(indexed_paths) == 0:\n            indexed_paths = _get_indexed_paths(inputs[1])\n\n        if len(indexed_paths) > 0:\n            # If there are indexed paths, we can assume that the first input is a directory\n            # and the second input is a file path.\n            # We need to check that the file path is consistent with the directory.\n            input_dir = indexed_paths[0]\n            if len(indexed_paths) > 1:\n                for i in range(1, len(indexed_paths)):\n                    if indexed_paths[i] != input_dir:\n                        raise ValueError(\n                            f\"The first two elements of the input sequence have inconsistent file paths: {indexed_paths[i]} and {input_dir}\"\n                        )\n\n            # Format the path to include the project root or a specified depth in the file system.\n            if not os.path.isabs(input_dir):\n                input_dir = os.path.join(os.getcwd(), input_dir)\n\n            return input_dir\n\n    return None\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # In studio, DNS optimization is already disabled.\n        yield\n    else:\n        # Disable DNS optimization\n        if enable:\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=lo --interface=eth0\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth0\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth1\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth2\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth3\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth4\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth5\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth6\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth7\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth8\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth9\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth10\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth11\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth12\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth13\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface=eth14\")\n            os.system(\"sudo systemd-resolve --set-dns=1.1.1.1 --interface="}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        return\n\n    if enable:\n        # Enable DNS optimization\n        os.system(\"sudo systemctl start systemd-resolved\")\n        os.system(\"sudo systemctl enable systemd-resolved\")\n        os.system(\"sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf\")\n        os.system(\"sudo systemctl restart systemd-resolved\")\n    else:\n        # Disable DNS optimization\n        os.system(\"sudo systemctl stop systemd-resolved\")\n        os.system(\"sudo systemctl disable systemd-resolved\")\n        os.system(\"sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf\")\n        os.system(\"sudo systemctl restart systemd-resolved\")\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        os.system(\"sudo systemctl stop systemd-resolved\")\n        os.system(\"sudo systemctl disable systemd-resolved\")\n        os.system(\"sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf\")\n        os.system(\"sudo systemctl restart systemd-resolved\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        try:\n            with _enable_dns_optimization():\n                yield\n        finally:\n            _disable_dns_optimization()\n    else:\n        try:\n            with _disable_dns_optimization():\n                yield\n        finally:\n            _disable_dns_optimization()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.system(\"echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse\")\n        os.system(\"echo 1 > /proc/sys/net/ipv4/tcp_fin_timeout\")\n        os.system(\"echo 1 > /proc/sys/net/ipv4/tcp_tw_recycle\")\n    else:\n        os.system(\"echo 0 > /proc/sys/net/ipv4/tcp_tw_reuse\")\n        os.system(\"echo 30 > /proc/sys/net/ipv4/tcp_fin_timeout\")\n        os.system(\"echo 0 > /proc/sys/net/ipv4/tcp_tw_recycle\")\n\n    try:\n        yield\n    finally:\n        os.system(\"echo 0 > /proc/sys/net/ipv4/tcp_tw_reuse\")\n        os.system(\"echo 30 > /proc/sys/net/ipv4/tcp_fin_timeout\")\n        os.system(\"echo 0 > /proc/sys/net/ipv4/tcp_tw_recycle\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        Popen(\n            \"sudo systemctl enable systemd-resolved.service\",\n            shell=True,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n        Popen(\n            \"sudo systemctl restart systemd-resolved.service\",\n            shell=True,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n    else:\n        # Disable DNS optimization\n        Popen(\n            \"sudo systemctl disable systemd-resolved.service\",\n            shell=True,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n        Popen(\n            \"sudo systemctl stop systemd-resolved.service\",\n            shell=True,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        Popen(\n            \"sudo systemctl disable systemd-resolved.service\",\n            shell=True,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n        Popen(\n            \"sudo systemctl stop systemd-resolved.service\",\n            shell=True,\n            stdout=DEVNULL,\n            stderr=DEVNULL,\n        )\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        Popen([\"scutil\", \"--dns\", \"flush\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        # Disable DNS optimization\n        Popen([\"scutil\", \"--dns\", \"resolve\", \"google.com\"], stdout=DEVNULL, stderr=DEVNULL)\n    try:\n        yield\n    finally:\n        # Always disable DNS optimization after the context\n        Popen([\"scutil\", \"--dns\", \"flush\"], stdout=DEVNULL, stderr=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        raise RuntimeError(\"This function is only available in the Lightning Studio.\")\n\n    if enable:\n        Popen([\"sudo\", \"systemctl\", \"start\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n    yield\n    Popen([\"sudo\", \"systemctl\", \"stop\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # Disable DNS optimization if it's enabled\n    if enable:\n        os.environ[\"DNS_OPTIMIZATION\"] = \"1\"\n        os.environ[\"DNS_RESOLVER\"] = \"1\"\n    else:\n        os.environ[\"DNS_OPTIMIZATION\"] = \"0\"\n        os.environ[\"DNS_RESOLVER\"] = \"0\"\n\n    # Attempt to execute the code within the context\n    try:\n        yield\n    finally:\n        # Disable DNS optimization regardless of whether an exception occurred\n        os.environ[\"DNS_OPTIMIZATION\"] = \"0\"\n        os.environ[\"DNS_RESOLVER\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        os.environ[\"DNS_RESOLVER_ENABLE\"] = \"1\"\n        os.environ[\"DNS_RESOLVER_MAX_RETRIES\"] = \"1\"\n        os.environ[\"DNS_RESOLVER_TIMEOUT_MS\"] = \"1000\"\n    else:\n        # Disable DNS optimization\n        os.environ[\"DNS_RESOLVER_ENABLE\"] = \"0\"\n        os.environ[\"DNS_RESOLVER_MAX_RETRIES\"] = \"0\"\n        os.environ[\"DNS_RESOLVER_TIMEOUT_MS\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        os.environ[\"DNS_RESOLVER_ENABLE\"] = \"0\"\n        os.environ[\"DNS_RESOLVER_MAX_RETRIES\"] = \"0\"\n        os.environ[\"DNS_RESOLVER_TIMEOUT_MS\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        try:\n            Popen([\"scutil\", \"--dns\", \"flush\"], stdout=DEVNULL, stderr=DEVNULL)\n        except Exception:\n            pass\n\n    try:\n        yield\n    finally:\n        try:\n            Popen([\"scutil\", \"--dns\", \"flush\"], stdout=DEVNULL, stderr=DEVNULL)\n        except Exception:\n            pass\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            os.system(\"sudo systemctl start systemd-resolved\")\n            os.system(\"sudo systemctl stop systemd-resolved\")\n            os.system(\"sudo systemctl start systemd-resolved\")\n        yield\n    finally:\n        os.system(\"sudo systemctl stop systemd-resolved\")\n        os.system(\"sudo systemctl start systemd-resolved\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # If DNS optimization is already disabled, we do nothing.\n    if not enable:\n        yield\n        return\n\n    # Otherwise, we enable DNS optimization.\n    try:\n        # Enable DNS optimization.\n        Popen([\"sudo\", \"systemctl\", \"start\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"systemctl\", \"enable\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        # Wait for DNS optimization to be enabled.\n        while not os.path.exists(\"/run/systemd/resolve/resolv.conf\"):\n            pass\n        # Replace the DNS resolver configuration file with a custom one.\n        Popen([\"sudo\", \"cp\", \"/etc/resolv.conf\", \"/etc/resolv.conf.backup\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"cp\", \"/etc/resolv.conf.dns\", \"/etc/resolv.conf\"], stdout=DEVNULL, stderr=DEVNULL)\n        # Wait for the custom DNS resolver configuration file to be copied.\n        while not os.path.exists(\"/etc/resolv.conf\"):\n            pass\n        # Wait for DNS optimization to be fully enabled.\n        while not os.path.exists(\"/run/systemd/resolve/resolv.conf\"):\n            pass\n        # Yield to the context.\n        yield\n        # Disable DNS optimization.\n        Popen([\"sudo\", \"systemctl\", \"stop\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sudo\", \"systemctl\", \"disable\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        # Wait for DNS optimization to be disabled.\n        while os.path.exists(\"/run/systemd/resolve/resolv.conf\"):\n            pass\n        # Replace the DNS resolver configuration file with the original one.\n        Popen([\"sudo\", \"cp\", \"/etc/resolv.conf.backup\", \"/etc/resolv.conf\"], stdout=DEVNULL, stderr=DEVNULL)\n        # Wait for the original DNS resolver configuration file to be restored.\n        while not os.path.exists(\"/etc/resolv.conf\"):\n            pass\n    except Exception:\n        # If an exception occurs, disable DNS optimization.\n        Popen([\"sudo\", \"systemctl\", \"stop\", \"systemd-resolved\"], stdout="}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # Check if DNS optimization is already enabled or disabled\n    enabled = os.getenv(\"DNS_OPTIMIZATION\") == \"1\"\n\n    # Enable or disable DNS optimization as specified\n    if enable:\n        os.environ[\"DNS_OPTIMIZATION\"] = \"1\"\n    else:\n        os.environ[\"DNS_OPTIMIZATION\"] = \"0\"\n\n    # Ensure DNS optimization is disabled after the context\n    try:\n        yield\n    finally:\n        if not enabled:\n            os.environ[\"DNS_OPTIMIZATION\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\"This function is only available in Lightning Studio.\")\n\n    if enable:\n        Popen([\"sudo\", \"nmcli\", \"con\", \"mod\", \"Wired\", \"ipv4.dns-priority\", \"0\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        Popen([\"sudo\", \"nmcli\", \"con\", \"mod\", \"Wired\", \"ipv4.dns-priority\", \"1\"], stdout=DEVNULL, stderr=DEVNULL)\n    try:\n        yield\n    finally:\n        Popen([\"sudo\", \"nmcli\", \"con\", \"mod\", \"Wired\", \"ipv4.dns-priority\", \"1\"], stdout=DEVNULL, stderr=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # This is a workaround for the issue with DNS optimization in studio\n        # https://github.com/Lightning-AI/lightning/issues/25923\n        # https://github.com/Lightning-AI/lightning/pull/25924\n        # https://github.com/Lightning-AI/lightning/pull/25925\n        enable = False\n\n    if enable:\n        # This is a workaround for the issue with DNS optimization in studio\n        # https://github.com/Lightning-AI/lightning/issues/25923\n        # https://github.com/Lightning-AI/lightning/pull/25924\n        # https://github.com/Lightning-AI/lightning/pull/25925\n        if _IS_IN_STUDIO:\n            os.environ[\"LIGHTNING_DISABLE_DNS_OPTIMIZATION\"] = \"1\"\n        else:\n            os.environ[\"LIGHTNING_DISABLE_DNS_OPTIMIZATION\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        if enable:\n            os.environ[\"LIGHTNING_DISABLE_DNS_OPTIMIZATION\"] = \"1\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        os.system(\"sudo systemctl restart systemd-resolved\")\n    else:\n        # Disable DNS optimization\n        os.system(\"sudo systemctl stop systemd-resolved\")\n\n    try:\n        yield\n    finally:\n        # Always disable DNS optimization\n        os.system(\"sudo systemctl stop systemd-resolved\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.environ[\"DNS_OPTIMIZATIONS\"] = \"1\"\n    else:\n        os.environ[\"DNS_OPTIMIZATIONS\"] = \"0\"\n    try:\n        yield\n    finally:\n        os.environ[\"DNS_OPTIMIZATIONS\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        yield\n        return\n\n    if not enable:\n        yield\n        return\n\n    # Credit to the https://github.com/rom1504/img2dataset Github repo\n    # The code was taken from there. It has a MIT License.\n\n    # This is a context manager that temporarily enables or disables DNS optimization.\n    # It is designed to be used with the \"with\" statement, for example:\n    # with optimize_dns_context(True):\n    #     # Code that requires DNS optimization\n    #\n    # When the context is exited, DNS optimization will be disabled again.\n    #\n    # This context manager is useful for situations where DNS optimization is required\n    # but not desirable to be enabled by default.\n\n    # To enable DNS optimization, the script sets the \"resolvconf\" package to use the\n    # \"resolvconf-no-systemd\" configuration file. This file is designed to disable\n    # systemd-resolved, which is the default DNS resolver on some Linux distributions.\n    #\n    # To disable DNS optimization, the script sets the \"resolvconf\" package to use the\n    # \"resolvconf-original\" configuration file. This file is designed to restore the\n    # original DNS resolver configuration.\n\n    # Credit to the https://github.com/rom1504/img2dataset Github repo\n    # The code was taken from there. It has a MIT License.\n\n    try:\n        # Credit to the https://github.com/rom1504/img2dataset Github repo\n        # The code was taken from there. It has a MIT License.\n\n        # This function is designed to temporarily enable or disable DNS optimization based on the input parameter.\n        # It attempts to perform operations within a context where DNS optimization is enabled or disabled as specified,\n        # and ensures that DNS optimization is always disabled after these operations, even if an exception occurs.\n\n        # Input-Output Arguments\n        # :param enable: Bool, indicates whether DNS optimization should be enabled (True) or disabled (False) during the execution of the context.\n        # :return: No return values. This function is a context manager that does not return any value but ensures DNS optimization is set according to the 'enable' parameter and then reset to disabled afterwards.\n\n        # Credit to the https://github.com/rom1504/img2dataset Github repo\n        #"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # DNS optimization is not supported in Studio\n        yield\n        return\n\n    if enable:\n        # Enable DNS optimization\n        os.system(\"sudo resolvectl dns $(hostname) 127.0.0.1\")\n        os.system(\"sudo resolvectl dns $(hostname) ::1\")\n        os.system(\"sudo resolvectl default-route $(hostname) none\")\n    else:\n        # Disable DNS optimization\n        os.system(\"sudo resolvectl dns $(hostname) 1.1.1.1\")\n        os.system(\"sudo resolvectl default-route $(hostname) auto\")\n\n    # Ensure DNS optimization is disabled after the context\n    yield\n    os.system(\"sudo resolvectl dns $(hostname) 1.1.1.1\")\n    os.system(\"sudo resolvectl default-route $(hostname) auto\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        return\n\n    if enable:\n        Popen([\"scutil\", \"--dns\", \"flush\"], stdout=DEVNULL, stderr=DEVNULL)\n    try:\n        yield\n    finally:\n        Popen([\"scutil\", \"--dns\", \"flush\"], stdout=DEVNULL, stderr=DEVNULL)"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    if num_items % distributed_env.world_size != 0 and not drop_last:\n        num_items_per_rank += 1\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = i * num_items_per_rank\n        end = min(start + num_items_per_rank, num_items)\n        chunks_per_ranks[i] = indexes[start:end]\n        chunk_intervals_per_ranks[i] = chunk_intervals[start:end]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    num_items_per_rank = int(num_items / distributed_env.world_size)\n    if not drop_last:\n        num_items_per_rank += 1\n\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[List[int]]] = [[] for _ in range(distributed_env.world_size)]\n\n    for i in range(distributed_env.world_size):\n        start_index = i * num_items_per_rank\n        end_index = (i + 1) * num_items_per_rank\n        if end_index > num_items:\n            end_index = num_items\n\n        chunks_per_ranks[i] = indexes[start_index:end_index]\n        chunk_intervals_per_ranks[i] = chunk_intervals[start_index:end_index]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    items_per_rank = int(np.ceil(len(indexes) / distributed_env.world_size))\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for i in range(len(indexes)):\n        rank = i % distributed_env.world_size\n        chunks_per_ranks[rank].append(indexes[i])\n        chunk_intervals_per_ranks[rank].append(chunk_intervals[i])\n\n    # drop the last items if drop_last is True\n    if drop_last and len(indexes) % distributed_env.world_size != 0:\n        for i in range(len(indexes) % distributed_env.world_size, distributed_env.world_size):\n            chunks_per_ranks[i] = []\n            chunk_intervals_per_ranks[i] = []\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of items each rank should process\n    num_items_per_rank = int(np.ceil(len(indexes) / distributed_env.world_size))\n\n    # calculate the number of chunks each rank should process\n    num_chunks_per_rank = int(np.ceil(len(indexes) / distributed_env.world_size))\n\n    # calculate the number of intervals each rank should process\n    num_intervals_per_rank = int(np.ceil(len(chunk_intervals) / distributed_env.world_size))\n\n    # distribute the chunks and their intervals across the ranks\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        start_index = rank * num_items_per_rank\n        end_index = min(start_index + num_items_per_rank, len(indexes))\n        chunks_per_ranks[rank] = indexes[start_index:end_index]\n\n        start_interval = rank * num_intervals_per_rank\n        end_interval = min(start_interval + num_intervals_per_rank, len(chunk_intervals))\n        intervals_per_ranks[rank] = chunk_intervals[start_interval:end_interval]\n\n    # drop the last items if necessary\n    if drop_last:\n        for rank in range(distributed_env.world_size):\n            if len(chunks_per_ranks[rank]) > num_chunks_per_rank:\n                chunks_per_ranks[rank] = chunks_per_ranks[rank][:-1]\n            if len(intervals_per_ranks[rank]) > num_intervals_per_rank:\n                intervals_per_ranks[rank] = intervals_per_ranks[rank][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_chunks = len(indexes)\n    num_items = sum(chunk_intervals[i][1] - chunk_intervals[i][0] for i in range(num_chunks))\n    num_items_per_rank = num_items // distributed_env.world_size\n    if not drop_last:\n        num_items_per_rank += num_items % distributed_env.world_size\n    num_chunks_per_rank = num_chunks // distributed_env.world_size\n    if not drop_last:\n        num_chunks_per_rank += num_chunks % distributed_env.world_size\n\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for i in range(num_chunks_per_rank):\n            chunks_per_ranks[rank].append(indexes[i * distributed_env.world_size + rank])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[i * distributed_env.world_size + rank])\n        if not drop_last and rank < num_chunks % distributed_env.world_size:\n            chunks_per_ranks[rank].append(indexes[num_chunks_per_rank * distributed_env.world_size + rank])\n            chunk_intervals_per_ranks[rank].append(\n                chunk_intervals[num_chunks_per_rank * distributed_env.world_size + rank]\n            )\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process based on the total items and the world size of the distributed environment, taking into account whether to drop the last items or not.\n    num_items = len(indexes)\n    chunk_size = num_items // distributed_env.world_size\n    if not drop_last:\n        chunk_size += num_items % distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank accordingly.\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[Any] = [[] for _ in range(distributed_env.world_size)]\n    for i, (index, chunk_interval) in enumerate(zip(indexes, chunk_intervals)):\n        rank = i % distributed_env.world_size\n        chunks_per_ranks[rank].append(index)\n        chunk_intervals_per_ranks[rank].append(chunk_interval)\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    items_per_rank = (\n        len(indexes) // distributed_env.world_size\n        if drop_last\n        else (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n    )\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: List[List[List[int]]] = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        start_idx = rank * items_per_rank\n        end_idx = min(start_idx + items_per_rank, len(indexes))\n        chunks_per_ranks[rank] = indexes[start_idx:end_idx]\n        intervals_per_ranks[rank] = chunk_intervals[start_idx:end_idx]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items = len(indexes)\n    items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n    if drop_last:\n        items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n    else:\n        items_per_rank = (num_items + distributed_env.world_size) // distributed_env.world_size\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: List[List[List[int]]] = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start_index = i * items_per_rank\n        end_index = min(start_index + items_per_rank, num_items)\n        chunks_per_ranks[i] = indexes[start_index:end_index]\n        intervals_per_ranks[i] = [chunk_intervals[index] for index in chunks_per_ranks[i]]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    num_ranks = distributed_env.world_size\n    num_items_per_rank = num_items // num_ranks\n\n    # distribute the chunks and their intervals across different ranks\n    chunks_per_ranks = [[] for _ in range(num_ranks)]\n    chunk_intervals_per_ranks = [[] for _ in range(num_ranks)]\n    for i in range(num_ranks):\n        start_index = i * num_items_per_rank\n        end_index = (i + 1) * num_items_per_rank if i < num_ranks - 1 else num_items\n        if drop_last and i == num_ranks - 1:\n            end_index -= 1\n        chunks_per_ranks[i] = indexes[start_index:end_index]\n        chunk_intervals_per_ranks[i] = chunk_intervals[start_index:end_index]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    total_items = len(indexes)\n    items_per_rank = int(np.ceil(total_items / distributed_env.world_size))\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start_index = i * items_per_rank\n        end_index = min((i + 1) * items_per_rank, total_items)\n        if drop_last and end_index == total_items:\n            end_index -= 1\n        chunks_per_ranks[i] = indexes[start_index:end_index]\n        chunk_intervals_per_ranks[i] = chunk_intervals[start_index:end_index]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items_per_rank = (len(indexes) - 1) // distributed_env.world_size + 1\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for i, index in enumerate(indexes):\n        rank = i // num_items_per_rank\n        chunks_per_ranks[rank].append(index)\n        chunk_intervals_per_ranks[rank].append(chunk_intervals[index])\n\n    # drop the last items if needed\n    if drop_last and len(chunks_per_ranks[-1]) < num_items_per_rank:\n        chunks_per_ranks[-1] = []\n        chunk_intervals_per_ranks[-1] = []\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # compute the number of items each rank should process\n    num_items_per_rank = int(np.ceil(len(indexes) / distributed_env.world_size))\n\n    # distribute chunks and their corresponding intervals across different ranks\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for i in range(len(indexes)):\n        rank = i % distributed_env.world_size\n        chunks_per_ranks[rank].append(indexes[i])\n        chunk_intervals_per_ranks[rank].append(chunk_intervals[i])\n\n    # drop the last items to make the distribution even across all ranks\n    if drop_last:\n        num_items_last_rank = len(chunks_per_ranks[-1])\n        num_items_to_drop = num_items_last_rank % num_items_per_rank\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-num_items_to_drop]\n        chunk_intervals_per_ranks[-1] = chunk_intervals_per_ranks[-1][:-num_items_to_drop]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # compute the number of items each rank should process\n    if drop_last:\n        num_items_per_rank = int(np.ceil(len(indexes) / distributed_env.world_size))\n    else:\n        num_items_per_rank = int(np.floor(len(indexes) / distributed_env.world_size))\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: List[Any] = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        chunks_per_ranks[i] = indexes[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n        intervals_per_ranks[i] = chunk_intervals[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    # if drop_last is True, then the last items are dropped to make the distribution even across all ranks\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # distribute the chunks and intervals across the ranks\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = i * num_items_per_rank\n        end = (i + 1) * num_items_per_rank\n        chunks_per_ranks[i] = indexes[start:end]\n        intervals_per_ranks[i] = chunk_intervals[start:end]\n\n    return chunks_per_ranks, intervals_per_ranks\n      self.assertEqual(len(self.env.chunk_intervals), len(self.env.chunk_intervals_per_rank))\n        self.assertEqual(len(self.env.chunk_intervals_per_rank), self.env.world_size)\n        self.assertEqual(len(self.env.chunk_intervals_per_rank[0]), len(self.env.chunk_intervals_per_rank[0]))\n        self.assertEqual(len(self.env.chunk_intervals_per_rank[0][0]), 2)\n\n    def test_get_chunk_interval_per_rank(self):\n        self.assertEqual(len(self.env.get_chunk_interval_per_rank(0)), 2)\n\n    def test_get_chunk_interval(self):\n        self.assertEqual(len(self.env.get_chunk_interval(0)), 2)\n\n    def test_get_chunk_intervals_per_rank(self):\n        self.assertEqual(len(self.env.get_chunk_intervals_per_rank()), self.env.world_size)\n\n    def test_get_chunk_intervals(self):\n        self.assertEqual("}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of items each rank should process\n    items_per_rank = int(np.ceil(len(indexes) / distributed_env.world_size))\n\n    # if drop_last is true, remove the last items to make the distribution even across all ranks\n    if drop_last:\n        indexes = indexes[: distributed_env.world_size * items_per_rank]\n        chunk_intervals = chunk_intervals[: distributed_env.world_size * items_per_rank]\n\n    # assign chunks to each rank\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        chunks_per_ranks[i] = indexes[i * items_per_rank : (i + 1) * items_per_rank]\n        chunk_intervals_per_ranks[i] = chunk_intervals[i * items_per_rank : (i + 1) * items_per_rank]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n    return self._get_chunk_intervals(\n            chunk_size=chunk_size,\n            num_chunks=num_chunks,\n            drop_last=drop_last,\n            chunk_intervals=chunk_intervals,\n            shuffle=shuffle,\n            seed=seed,\n            current_epoch=current_epoch,\n        )\n\n    def _get_chunk_intervals(\n        self,\n        chunk_size: int,\n        num_chunks: int,\n        drop_last: bool,\n        chunk_intervals: Any,\n        shuffle: bool,\n        seed: int,\n        current_epoch: int,\n    ) -> Any:\n        \"\"\"\n        This function returns the chunk intervals for a given chunk size and number of chunks. If the chunk intervals are not provided, it calculates the chunk intervals based on the chunk size and number of chunks. If shuffle is True, it shuffles the chunk intervals based on the seed and current epoch.\n\n        Input-Output Arguments\n        :param chunk_size: int. The size of each chunk.\n        :param num_chunks: int. The number of chunks.\n        :param drop_last: bool."}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last and num_items % distributed_env.world_size != 0:\n        num_items_per_rank += 1\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = i * num_items_per_rank\n        end = min(start + num_items_per_rank, num_items)\n        chunks_per_ranks[i] = indexes[start:end]\n        intervals_per_ranks[i] = chunk_intervals[start:end]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[List[int]]] = [[] for _ in range(distributed_env.world_size)]\n\n    # distribute the chunks to each rank\n    for i in range(len(indexes)):\n        rank_index = i % distributed_env.world_size\n        chunks_per_ranks[rank_index].append(indexes[i])\n        chunk_intervals_per_ranks[rank_index].append(chunk_intervals[i])\n\n    # drop the last chunks if drop_last is True\n    if drop_last:\n        chunks_per_ranks = [chunks[:-1] for chunks in chunks_per_ranks]\n        chunk_intervals_per_ranks = [chunk_intervals[:-1] for chunk_intervals in chunk_intervals_per_ranks]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if not drop_last:\n        num_items_per_rank += 1\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] = []\n    intervals_per_ranks: List[List[List[int]]] = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = (rank + 1) * num_items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append([chunk_intervals[index] for index in indexes[start:end]])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process based on the total items and the world size of the distributed environment, taking into account whether to drop the last items or not.\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n    num_items_per_rank = int(num_items_per_rank)\n\n    # Assign chunks and their intervals to each rank accordingly.\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = (rank + 1) * num_items_per_rank\n        if rank == distributed_env.world_size - 1:\n            end = len(indexes)\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    if drop_last:\n        num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    else:\n        num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: Any = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        chunks_per_ranks[rank] = indexes[\n            int(rank * num_items_per_rank) : int((rank + 1) * num_items_per_rank)\n        ]\n        chunk_intervals_per_ranks[rank] = chunk_intervals[\n            int(rank * num_items_per_rank) : int((rank + 1) * num_items_per_rank)\n        ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # Prepare the keyword arguments for the transformation function\n        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # Call the transformation function\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {\"output_dir\": output_dir}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, **kwargs)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device and self._device is not None:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwds: Dict[str, Any] = {}\n        if self._contains_device:\n            kwds[\"device\"] = self._device\n        if self._contains_is_last:\n            kwds[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwds)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # If the device is not set, use the default device\n        if self._device is None:\n            self._device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n        kwargs = {\"device\": self._device, \"is_last\": is_last} if self._contains_is_last else {}\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device, \"is_last\": is_last} if self._contains_is_last else {}\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # Prepare the keyword arguments for the transformation function\n        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # Call the transformation function\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # Prepare the input arguments\n        inputs = [item_metadata, output_dir]\n\n        # Prepare the keyword arguments\n        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # Call the transformation function\n        self._fn(*inputs, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device, \"is_last\": is_last} if self._contains_is_last else {}\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"File {obj.geturl()} not found. Waiting for {sleep_time} seconds...\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"File {obj.path} not found. Waiting for {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path[1:])\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path[1:])\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"File {obj.path} not found, waiting for {sleep_time} seconds\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=_resolve_dir(_get_input_dir(inputs)),\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=_resolve_dir(_get_input_dir(inputs)),\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        output_dir = _resolve_dir(output_dir)\n\n        if output_dir.url and \"cloudspaces\" in output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {output_dir.path if output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_upload"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, (list, tuple)):\n        raise ValueError(f\"The provided inputs {inputs} is not a list or tuple.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} is not a string or Dir.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided fast_dev_run {fast_dev_run} is not a bool or int.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided error_when_not_empty {error_when_not_empty} is not a bool.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided reorder_files {reorder_files} is not a bool.\")\n\n    if not isinstance(batch_size, (type(None), int)):\n        raise ValueError(f\"The provided batch_size {batch_size} is not a int or None.\")\n\n    if not isinstance(weights, (type(None), list)):\n        raise ValueError(f\"The provided weights {weights} is not a list or None.\")\n\n    if not isinstance(num_workers, (type(None), int)):\n        raise ValueError(f\"The provided num_workers {num_workers} is not a int or None.\")\n\n    if not isinstance(num_nodes, (type(None), int)):\n        raise ValueError(f\"The provided num_nodes {num_nodes} is not a int or None.\")\n\n    if not isinstance(machine, (type(None), str)):\n        raise ValueError(f\"The provided machine {machine} is not a str or None.\")\n\n    if not isinstance(num_downloaders, (type(None), int)):\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} is not a int or None.\")\n\n    if not isinstance(num_uploaders, (type(None), int)):\n        raise ValueError(f\"The provided num_uploaders {num_uploaders} is not a int or None.\")\n\n    if not isinstance(reader, (type(None), BaseReader)):\n        raise ValueError(f\"The provided reader {reader} is not a BaseReader or None.\")\n\n    if batch_size is not None and batch_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial, Callable)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(f\"The provided {batch_size} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if not isinstance(weights, (list, tuple, set, None.__class__)):\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if not isinstance(num_workers, (int, None.__class__)):\n        raise ValueError(f\"The provided {num_workers} isn't supported.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if not isinstance(num_nodes, (int, None.__class__)):\n        raise ValueError(f\"The provided {num_nodes} isn't supported.\")\n\n    if not isinstance(machine, (str, None.__class__)):\n        raise ValueError(f\"The provided {machine} isn't supported.\")\n\n    if not isinstance(num_downloaders, (int, None.__class__)):\n        raise ValueError(f\"The provided {num_downloaders} isn't supported.\")\n\n    if not isinstance(num_uploaders, (int, None.__class__)):\n        raise ValueError(f\"The provided {num_uploaders} isn't supported.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided {reorder_files} isn't supported.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided {error_when_not_empty} isn't supported.\")"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    input_dir = _get_input_dir(inputs)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if reader is None:\n        reader = BaseReader()\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, int):\n            num_samples = fast_dev_run\n        else:\n            num_samples = 100\n\n        if len(inputs) < num_samples:\n            num_samples = len(inputs)\n\n        inputs = inputs[:num_samples]\n\n    data_processor = DataProcessor(\n        data_transform_recipe=LambdaDataTransformRecipe(fn, inputs),\n        data_chunk_recipe=LambdaDataChunkRecipe(fn, inputs, chunk_size=batch_size, chunk_bytes=None, compression=None),\n        input_dir=input_dir,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n    )\n\n    data_processor.run()\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if _IS_IN_STUDIO:\n        raise ValueError(\n            \"The `map` function is not supported in Lightning Studio. Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if num_nodes is not None or machine is not None:\n        raise ValueError(\n            \"The `num_nodes` and `machine` arguments are not supported in the `map` function. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if num_downloaders is not None or num_uploaders is not None:\n        raise ValueError(\n            \"The `num_downloaders` and `num_uploaders` arguments are not supported in the `map` function. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if batch_size is not None:\n        raise ValueError(\n            \"The `batch_size` argument is not supported in the `map` function. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if reader is not None:\n        raise ValueError(\n            \"The `reader` argument is not supported in the `map` function. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if not isinstance(fast_dev_run, bool) and fast_dev_run <= 0:\n        raise ValueError(\n            \"The `fast_dev_run` argument must be either a boolean or a positive integer. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(\n            \"The `error_when_not_empty` argument must be a boolean. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(\n            \"The `reorder_files` argument must be a boolean. \"\n            \"Please use the `map` function in the `litdata` package instead.\"\n        )\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError("}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from lightning.app.storage import Path\n\n        output_dir = Path(output_dir)\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if batch_size is None:\n        batch_size = 1\n\n    if batch_size < 1:\n        raise ValueError(f\"The provided batch_size {batch_size} must be greater than 0.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(f\"The provided num_workers {num_workers} must be greater than 0.\")\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_downloaders < 1:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} must be greater than 0.\")\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if num_uploaders < 1:\n        raise ValueError(f\"The provided num_uploaders {num_uploaders} must be greater than 0.\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(f\"The provided num_nodes {num_nodes} must be greater than 0.\")\n\n    if machine is not None and machine not in [\"cpu\", \"gpu\"]:\n        raise ValueError(f\"The provided machine {machine} must be either 'cpu' or 'gpu'.\")\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"The provided inputs didn't contain any filepaths.\")\n\n    if reader is None:\n        reader = BaseReader()\n\n    data_processor = DataProcessor(\n        data_transform_recipe=LambdaDataTransformRecipe(fn, inputs),\n        data_chunk_recipe=LambdaDataChunkRecipe(fn, inputs, batch_size, None, None),\n        reader=reader,\n    )\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 100\n        data_processor."}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if isinstance(fast_dev_run, bool):\n        fast_dev_run = 1 if fast_dev_run else 0\n\n    if fast_dev_run is not None:\n        if fast_dev_run < 1:\n            raise ValueError(f\"fast_dev_run must be a positive integer, got {fast_dev_run}.\")\n        batch_size = fast_dev_run\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if not isinstance(num_nodes, int) and num_nodes is not None:\n        raise ValueError(f\"num_nodes must be an integer, got {num_nodes}.\")\n\n    if not isinstance(batch_size, int):\n        raise ValueError(f\"batch_size must be an integer, got {batch_size}.\")\n\n    if not isinstance(num_workers, int):\n        raise ValueError(f\"num_workers must be an integer, got {num_workers}.\")\n\n    if not isinstance(num_downloaders, int):\n        raise ValueError(f\"num_downloaders must be an integer, got {num_downloaders}.\")\n\n    if not isinstance(num_uploaders, int):\n        raise ValueError(f\"num_uploaders must be an integer, got {num_uploaders}.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"reorder_files must be a bool, got {reorder_files}.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"error_when_not_empty must be a bool, got {error_when_not_empty}.\")\n\n    if reader is not None and not isinstance(reader, BaseReader):\n        raise ValueError(f\"reader must be a BaseReader, got {reader}.\")\n\n    if not isinstance(weights, list) and weights is not None:\n        raise ValueError(f\"weights must be a list, got {weights}.\")\n\n    if weights"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if isinstance(fast_dev_run, bool):\n        if fast_dev_run:\n            fast_dev_run = 1000\n        else:\n            fast_dev_run = None\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run < 1:\n            raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if reader is None:\n        reader = BaseReader()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if machine is None:\n        machine = \"cpu\"\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if reader is None:\n        reader = BaseReader()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if machine is None:\n        machine = \"cpu\"\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if num_workers is None:\n       "}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\n            f\"The provided output_dir {output_dir} is not supported. It should be either a string or a litdata.Dir object.\"\n        )\n\n    if isinstance(inputs, (tuple, list)):\n        if len(inputs) == 0:\n            raise ValueError(f\"The provided inputs {inputs} is not supported. It should be a non-empty sequence.\")\n\n    if not isinstance(inputs, (tuple, list)):\n        raise ValueError(\n            f\"The provided inputs {inputs} is not supported. It should be a sequence of inputs to be processed.\"\n        )\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(\n            f\"The provided fn {fn} is not supported. It should be a callable that takes a filepath and a metadata as inputs.\"\n        )\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\n            f\"The provided output_dir {output_dir} is not supported. It should be either a string or a litdata.Dir object.\"\n        )\n\n    if not isinstance(weights, (list, type(None))):\n        raise ValueError(\n            f\"The provided weights {weights} is not supported. It should be a list of integers or None.\"\n        )\n\n    if not isinstance(num_workers, (int, type(None))):\n        raise ValueError(\n            f\"The provided num_workers {num_workers} is not supported. It should be an integer or None.\"\n        )\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(\n            f\"The provided fast_dev_run {fast_dev_run} is not supported. It should be a boolean or an integer.\"\n        )\n\n    if not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(\n            f\"The provided num_nodes {num_nodes} is not supported. It should be an integer or None.\"\n        )\n\n    if not isinstance(machine, (str, type(None))):\n        raise ValueError(\n            f\"The provided machine {machine} is not supported. It should be a string or None.\"\n        )\n\n    if not isinstance(num_downloaders, (int, type("}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from lightning.app.storage.path import Path\n\n        if isinstance(output_dir, str):\n            output_dir = Path(output_dir)\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't supported.\")\n\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True)\n\n    if error_when_not_empty and output_dir.exists():\n        if len(os.listdir(output_dir.path)) > 0:\n            raise ValueError(f\"The provided output_dir {output_dir} isn't empty.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run > 0:\n        num_workers = fast_dev_run\n        batch_size = fast_dev_run\n\n    if reader is None:\n        reader = BaseReader()\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"The provided inputs didn't contain any filepaths.\")\n\n    with optimize_dns_context(num_downloaders, num_uploaders):\n        _execute(\n            data_transform_recipe=LambdaDataTransformRecipe(fn, inputs),\n            input_dir=input_dir,\n            output_dir=output_dir,\n            weights=weights,\n            num_workers=num_workers,\n            num_nodes=num_nodes,\n            machine=machine,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n            batch_size=batch_size,\n        )\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, (tuple, list)):\n        inputs = [inputs]\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(fast_dev_run, bool):\n        fast_dev_run = int(fast_dev_run)\n\n    if not isinstance(reorder_files, bool):\n        reorder_files = bool(reorder_files)\n\n    if not isinstance(error_when_not_empty, bool):\n        error_when_not_empty = bool(error_when_not_empty)\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(\"Batch size should be greater than 0.\")\n\n    if not isinstance(batch_size, (int, type(None))):\n        raise ValueError(\"Batch size should be an integer or None.\")\n\n    if batch_size is not None and batch_size > 1 and reader is not None:\n        raise ValueError(\"Batch size should be 1 when using a custom reader.\")\n\n    if batch_size is not None and batch_size > 1 and num_workers is not None and num_workers > 1:\n        raise ValueError(\"Batch size should be 1 when using multiple workers.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(\"num_nodes should be greater than 0.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(\"num_downloaders should be greater than 0.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(\"num_uploaders should be greater than 0.\")\n\n    if num_workers <= 0:\n        raise ValueError(\"num_workers should be greater than 0.\")\n\n    if num_workers == 1:\n        if num_nodes is not None:\n            raise ValueError(\"num_nodes should be None when num_workers is 1.\")\n\n        if machine is not None:\n            raise ValueError(\"machine should be None when num_workers is 1.\")\n\n        if num_downloaders is not None:\n            raise ValueError(\"num_downloaders should be None when num_workers is 1.\")\n\n        if num_uploaders"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if not isinstance(inputs, list):\n        inputs = [inputs]\n\n    if batch_size is not None:\n        inputs = [inputs[i : i + batch_size] for i in range(0, len(inputs), batch_size)]\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 10\n        inputs = inputs[:fast_dev_run]\n\n    if num_nodes is not None:\n        if not _IS_IN_STUDIO:\n            raise ValueError(\"`num_nodes` is only supported on https://lightning.ai/\")\n\n    if num_downloaders is not None:\n        if not _IS_IN_STUDIO:\n            raise ValueError(\"`num_downloaders` is only supported on https://lightning.ai/\")\n\n    if num_uploaders is not None:\n        if not _IS_IN_STUDIO:\n            raise ValueError(\"`num_uploaders` is only supported on https://lightning.ai/\")\n\n    if reader is None:\n        reader = BaseReader()\n\n    if not isinstance(weights, list):\n        weights = [1] * len(inputs)\n\n    if len(inputs) != len(weights):\n        raise ValueError(\"The length of inputs and weights should be the same.\")\n\n    if len(inputs) == 0:\n        return\n\n    if not isinstance(inputs[0], list):\n        inputs = [inputs]\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"The provided inputs don't have any input_path.\")\n\n    if num_nodes is not None:\n        if not _IS_IN_STUDIO:\n            raise ValueError(\"`num_nodes` is only supported on https://lightning.ai/\")\n\n    if num_downloaders is not None:\n        if not _IS_IN_STUDIO:\n            raise ValueError(\"`num_downloaders` is only supported on https://lightning.ai/\")\n\n    if num_uploaders is not None:\n        if not"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not isinstance(output_dir, str):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't supported.\")\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run:\n        num_workers = 1\n        if isinstance(fast_dev_run, int):\n            num_workers = fast_dev_run\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if reader is None:\n        reader = BaseReader()\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"No input_dir could be found.\")\n\n    if not _IS_IN_STUDIO:\n        input_dir = _resolve_dir(input_dir, num_downloaders, num_uploaders)\n\n    if not os.path.exists(input_dir):\n        raise ValueError(f\"The provided input_dir {input_dir} doesn't exist.\")\n\n    if not _IS_IN_STUDIO:\n        _assert_dir_has_index_file(input_dir)\n\n    recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    if not _IS_IN_STUDIO:\n        input_dir = optimize_dns_context(input_dir, num_downloaders, num_uploaders)\n\n    processor = DataProcessor(\n        recipe,\n        input_dir,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    processor.process()\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if batch_size is None:\n        batch_size = 1\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run is False:\n        fast_dev_run = 0\n\n    if fast_dev_run > 0:\n        inputs = inputs[:fast_dev_run]\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if reader is None:\n        reader = BaseReader()\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if _IS_IN_STUDIO:\n        # TODO: add support for remote execution\n        raise NotImplementedError(\"Remote execution is not supported yet.\")\n\n    input_dir = _get_input_dir(inputs)\n    if input_dir is None:\n        raise ValueError(\"The provided inputs don't contain any filepaths.\")\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    _assert_dir_has_index_file(input_dir)\n\n    if num_nodes is not None and num_nodes > 1:\n        raise NotImplementedError(\"num_nodes > 1 is not supported yet.\")\n\n    if machine is not None and machine != \"cpu\":\n        raise NotImplementedError(\"machine != 'cpu' is not supported yet.\")\n\n    if num_downloaders is not None and num_downloaders != num_workers:\n        raise NotImplementedError(\"num_downloaders != num_workers is not supported yet.\")\n\n    if num_uploaders is not None and num_uploaders != num_workers:\n        raise NotImplementedError(\"num_uploaders != num_workers is not supported yet.\")\n\n    if reorder_files:\n        inputs = reader.reorder_files(input_dir, inputs)\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if len(inputs) != len(weights):\n        raise ValueError(\"The length of inputs and weights must be the same.\")\n\n    if batch_size > 1:\n        inputs = reader."}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from lightning.app.utilities.network import _get_cluster_environment\n\n        cluster_env = _get_cluster_environment()\n        num_nodes = num_nodes or cluster_env.num_nodes\n        machine = machine or cluster_env.machine_type\n\n    input_dir = _get_input_dir(inputs)\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if isinstance(fast_dev_run, bool):\n        fast_dev_run = 1 if fast_dev_run else 0\n\n    if fast_dev_run is not None and fast_dev_run <= 0:\n        raise ValueError(f\"fast_dev_run must be a positive integer or True, but got {fast_dev_run}.\")\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if batch_size is None:\n        batch_size = 1\n\n    if reader is None:\n        reader = BaseReader()\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run > len(inputs):\n            raise ValueError(f\"fast_dev_run can't be greater than the length of inputs ({len(inputs)}).\")\n\n        inputs = inputs[:fast_dev_run]\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not output_dir.exists():\n        output_dir.mkdir()\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    _assert_dir_has_index_file(output_dir)\n\n    recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    processor = DataProcessor(\n        recipe=recipe,\n        reader=reader,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        input_dir=input"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from litdata.streaming.remote_executor import RemoteExecutor\n\n        remote_executor = RemoteExecutor(num_nodes, machine)\n        remote_executor.map(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers,\n            fast_dev_run,\n            num_downloaders,\n            num_uploaders,\n            reorder_files,\n            error_when_not_empty,\n            reader,\n            batch_size,\n        )\n    else:\n        if isinstance(output_dir, str):\n            output_dir = Dir(output_dir)\n\n        if isinstance(inputs, str):\n            inputs = Dir(inputs)\n\n        if batch_size is not None:\n            raise ValueError(\"batch_size is not supported in local mode.\")\n\n        if num_nodes is not None or machine is not None:\n            raise ValueError(\"num_nodes and machine are only supported in remote mode.\")\n\n        if num_downloaders is not None or num_uploaders is not None:\n            raise ValueError(\"num_downloaders and num_uploaders are only supported in remote mode.\")\n\n        if not isinstance(output_dir, Dir):\n            raise ValueError(f\"output_dir should be a Dir, but got {output_dir}\")\n\n        if not isinstance(inputs, Dir):\n            raise ValueError(f\"inputs should be a Dir, but got {inputs}\")\n\n        if not isinstance(fn, (FunctionType, partial)):\n            raise ValueError(f\"fn should be a FunctionType or partial, but got {fn}\")\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(output_dir)\n\n        input_dir = _get_input_dir(inputs)\n\n        if input_dir is None:\n            raise ValueError(f\"The provided inputs {inputs} didn't contain any filepaths.\")\n\n        if reader is None:\n            reader = BaseReader()\n\n        if num_workers is None:\n            num_workers = _get_default_num_workers()\n\n        if fast_dev_run:\n            if isinstance(fast_dev_run, bool):\n                fast_dev_run = 10\n            else:\n                fast_dev_run = int(fast_dev_run)\n\n        if weights is not None and len(weights) != len(inputs):\n            raise ValueError(f\"The provided weights {weights"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from lightning.app.utilities.network import get_internal_ip\n\n        machine = machine or \"lightning-cloud-cpu-2\"\n        num_nodes = num_nodes or 1\n\n        if num_downloaders is None:\n            num_downloaders = 1\n\n        if num_uploaders is None:\n            num_uploaders = 1\n\n        if num_workers is None:\n            num_workers = 1\n\n        if batch_size is None:\n            batch_size = 1\n\n        if weights is None:\n            weights = [1] * len(inputs)\n\n        if isinstance(output_dir, str):\n            output_dir = Dir(output_dir)\n\n        if not isinstance(output_dir, Dir):\n            raise ValueError(f\"The provided output_dir {output_dir} is not supported.\")\n\n        if not output_dir.is_dir():\n            raise ValueError(f\"The provided output_dir {output_dir} is not a directory.\")\n\n        if output_dir.exists():\n            if error_when_not_empty:\n                raise ValueError(f\"The provided output_dir {output_dir} is not empty.\")\n            _assert_dir_is_empty(output_dir)\n\n        _assert_dir_has_index_file(output_dir)\n\n        if not isinstance(fast_dev_run, bool):\n            fast_dev_run = bool(fast_dev_run)\n\n        if fast_dev_run:\n            inputs = inputs[:fast_dev_run]\n            weights = weights[:fast_dev_run]\n\n        if reader is None:\n            reader = BaseReader()\n\n        if batch_size is not None and batch_size > 1:\n            inputs = reader.read_batch(inputs, batch_size)\n        else:\n            inputs = reader.read(inputs)\n\n        if reorder_files:\n            inputs = reader.reorder_inputs_by_file_size(inputs)\n\n        if not isinstance(fn, partial):\n            fn = partial(fn)\n\n        fn.is_last = False\n\n        recipe = LambdaDataTransformRecipe(fn, inputs)\n\n        with optimize_dns_context():\n            with StreamingDataLoader(\n                recipe=recipe,\n                weights=weights,\n                num_workers=num_workers,\n                num_nodes=num_nodes,\n                machine="}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_nodes is not None and machine is not None:\n        raise ValueError(\"num_nodes and machine are mutually exclusive.\")\n\n    if num_downloaders is not None and num_uploaders is not None:\n        raise ValueError(\"num_downloaders and num_uploaders are mutually exclusive.\")\n\n    if _IS_IN_STUDIO:\n        from lightning.app.utilities.network import _get_lightning_cloud_run_id\n\n        run_id = _get_lightning_cloud_run_id()\n        if run_id is None:\n            raise ValueError(\n                \"You need to be in a Lightning Cloud run to use this feature. \"\n                \"Please check https://lightning.ai/docs/cloud/start.html for more details.\"\n            )\n        from lightning.app.utilities.network import get_lightning_cloud_run_url\n\n        url = get_lightning_cloud_run_url(run_id)\n        print(f\"Running on Lightning Cloud: {url}\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = str(output_dir)\n\n    if not isinstance(output_dir, str):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't supported.\")\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if error_when_not_empty and len(os.listdir(output_dir)) > 0:\n        raise ValueError(f\"The provided output_dir {output_dir} isn't empty.\")\n\n    if reader is None:\n        reader = BaseReader()\n\n    if isinstance(fast_dev_run, int):\n        inputs = inputs[:fast_dev_run]\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_nodes > 1:\n        from lightning.app.utilities.network import _get_lightning_cloud_run_id\n\n        if _get_lightning_cloud_run_id() is None:\n            raise ValueError(\n                \"You need to be in a Light"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if isinstance(fast_dev_run, int) and fast_dev_run > 0:\n        batch_size = fast_dev_run\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if batch_size is not None:\n        if reader is None:\n            reader = BaseReader()\n\n        if reader.is_streaming_reader:\n            raise ValueError(\n                \"Streaming readers do not support batching. Please use a non-streaming reader or set batch_size to None.\"\n            )\n\n        if not reader.is_batch_reader:\n            raise ValueError(\n                \"The provided reader doesn't support batching. Please use a different reader or set batch_size to None.\"\n            )\n\n    if batch_size is None and reader is not None and reader.is_batch_reader:\n        raise ValueError(\n            \"The provided reader supports batching. Please set batch_size to a positive integer to use batching.\"\n        )\n\n    if batch_size is not None and reader is not None and not reader.is_batch_reader:\n        raise ValueError(\n            \"The provided reader doesn't support batching. Please use a different reader or set batch_size to None.\"\n        )\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(\"The provided batch_size must be a positive integer.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(\"The provided num_downloaders must be a positive integer.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(\"The provided num_uploaders must be a positive integer.\")\n\n    if reader is not None and reader.is_streaming_reader:\n        if num_downloaders is not None or num_uploaders is not None:\n            raise ValueError(\n                \"Streaming readers do not support custom num_downloaders or num_uploaders. Please set num_downloaders and num_uploaders to None.\"\n            )\n\n    if reader is not None and not reader.is_streaming_reader:\n        if num_downloaders is None:\n            num_downloaders = num_workers\n        if num_uploaders is None:\n            num_uploaders = num"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if batch_size is None:\n        batch_size = 1\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run:\n        num_workers = 1\n        batch_size = 1\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if reader is None:\n        reader = BaseReader()\n\n    if isinstance(inputs, (list, tuple)):\n        if len(inputs) == 0:\n            raise ValueError(f\"The provided {inputs} is empty.\")\n\n        if batch_size > 1:\n            inputs = reader.read_batch(inputs, batch_size=batch_size)\n        else:\n            inputs = reader.read(inputs)\n    else:\n        inputs = reader.read(inputs)\n\n    if isinstance(fast_dev_run, int):\n        inputs = inputs[:fast_dev_run]\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided {inputs} is empty.\")\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(f\"The provided {inputs} doesn't contain any filepaths.\")\n\n    if _IS_IN_STUDIO:\n        num_nodes = 1\n        machine = \"cpu-1x\"\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if machine is None:\n        machine = \"cpu-1x\"\n\n    if num_nodes > 1:\n        num_workers = 1\n\n    if num_nodes == 1 and num_workers > 1:\n        num_downloaders = 1\n        num_uploaders = 1\n\n    with optimize_dns_context():\n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_downloaders) as executor:\n            _execute(\n                inputs,\n                output_dir,\n                weights=weights,\n                num_workers=num_workers,\n                num_downloaders=num_downloaders,\n                num_upload"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if batch_size is not None:\n        if reader is None:\n            raise ValueError(\"A reader must be provided when using a batch_size.\")\n\n        if num_workers != 1:\n            raise ValueError(\"Batch processing is only supported when num_workers=1.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if isinstance(fast_dev_run, bool):\n        if fast_dev_run:\n            fast_dev_run = 1\n    elif not isinstance(fast_dev_run, int):\n        raise ValueError(\"fast_dev_run must be an integer or a boolean.\")\n\n    if _IS_IN_STUDIO:\n        from lightning.app.utilities.network import _get_cluster_environment_details\n\n        cluster_details = _get_cluster_environment_details()\n        num_nodes = cluster_details[\"num_nodes\"]\n        machine = cluster_details[\"machine\"]\n\n    if machine is not None and num_nodes is None:\n        raise ValueError(\"num_nodes must be provided when machine is specified.\")\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if batch_size is not None:\n        num_downloaders = 1\n        num_uploaders = 1\n\n    if num_downloaders > num_workers:\n        raise ValueError(\"num_downloaders must be less than or equal to num_workers.\")\n\n    if num_uploaders > num_workers:\n        raise ValueError(\"num_uploaders must be less than or equal to num_workers.\")\n\n    if num_downloaders < 1:\n        raise ValueError(\"num_downloaders must be at least 1.\")\n\n    if num_uploaders < 1:\n        raise ValueError(\"num_uploaders must be at least 1.\")\n\n    if batch_size is None:\n        if reader is None:\n            reader = BaseReader()\n        else:\n            raise ValueError(\"A reader must be provided when using a batch_size.\")\n\n    if batch_size is not None:\n        reader = reader.batch(batch_size)\n\n    if error_when_not_empty:\n        _assert_dir_is_empty("}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Download the files in the input directory to the cache directory.\n    # If the file is already downloaded, skip it.\n    # If the file is not downloaded, download it.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are available.\n    # If the file is downloaded, put the task index into the output queue to signal that the files for that index are available.\n    # If the file is not downloaded, download it and put the task index into the output queue to signal that the files for that index are"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        # Check if the files are already downloaded\n        downloaded_files = []\n        for file in files:\n            file_path = os.path.join(cache_dir, file.lstrip(\"/\"))\n            if os.path.exists(file_path):\n                downloaded_files.append(file)\n\n        # Download missing files\n        if len(downloaded_files) < len(files):\n            for file in files:\n                if file not in downloaded_files:\n                    input_dir.download(file, os.path.join(cache_dir, file.lstrip(\"/\")))\n\n        # Signal completion\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # This function is run in a separate process and is responsible for downloading data from a remote directory to a local cache directory to optimize reading. It continuously fetches download tasks from an input queue, checks if the files are already downloaded, downloads missing files, and then signals completion by putting the task index into an output queue.\n\n    # The input_dir argument is a Dir object representing the source directory from which files are to be downloaded. It is used to determine the source path or URL for the files.\n\n    # The cache_dir argument is a string representing the path to the local cache directory where files are to be downloaded. It is used as the destination for the downloaded files.\n\n    # The queue_in argument is a Queue object. It is the input queue from which download tasks are fetched. Each task includes an index and a list of file paths to download.\n\n    # The queue_out argument is also a Queue object. It is the output queue where the index of a completed download task is put to signal that the files for that index are available.\n\n    # The function does not return any values as it is only responsible for performing side effects (downloading files and communicating via queues).\n\n    # The function is typically called in a separate process or thread to avoid blocking the main thread or process while downloading data.\n\n    # The function is designed to be used in conjunction with the _download_data_target function, which is responsible for downloading data from a remote directory to a local cache directory.\n\n    # The function is part of a larger data processing pipeline that involves downloading data from a remote directory, optimizing reading, and then performing analysis or training on the data.\n\n    # The function is part of a larger data processing pipeline that involves downloading data from a remote directory, optimizing reading, and then performing analysis or training on the data.\n\n    # The function is part of a larger data processing pipeline that involves downloading data from a remote directory, optimizing reading, and then performing analysis or training on the data.\n\n    # The function is part of a larger data processing pipeline that involves downloading data from a remote directory, optimizing reading, and then performing analysis or training on the data.\n\n    # The function is part of a larger data processing pipeline that involves downloading data from a remote directory, optimizing reading, and then performing analysis or training on the data.\n\n    # The function is part of a larger data processing pipeline that involves downloading data from a"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            if not os.path.exists(os.path.join(cache_dir, file)):\n                input_dir.download(file, cache_dir)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, files = queue_in.get(timeout=3)\n        except Empty:\n            continue\n\n        for file in files:\n            file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(file_path):\n                input_dir.download_file(file, file_path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            try:\n                input_dir.download(file, cache_dir)\n            except Exception as e:\n                logger.warning(f\"Error downloading {file}: {e}\")\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get(block=False)\n            for file in files:\n                obj = parse.urlparse(file)\n                cache_file = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                if not os.path.exists(cache_file):\n                    os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n                    _wait_for_disk_usage_higher_than_threshold(cache_dir)\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download_file(obj, cache_file)\n            queue_out.put(index)\n        except Empty:\n            sleep(0.1)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n            if task is None:\n                break\n            index, file_paths = task\n            for file_path in file_paths:\n                if not os.path.exists(os.path.join(cache_dir, file_path)):\n                    input_dir.download(file_path, os.path.join(cache_dir, file_path))\n            queue_out.put(index)\n        except Empty:\n            pass\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file_path in file_paths:\n            file_obj = parse.urlparse(file_path)\n            if file_obj.scheme == \"s3\":\n                s3 = S3Client(file_obj.netloc)\n                file_obj = parse.urlparse(file_path)\n                _wait_for_file_to_exist(s3, file_obj)\n                s3.download(file_obj.path.lstrip(\"/\"), os.path.join(cache_dir, file_obj.path.lstrip(\"/\")))\n            else:\n                Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n                shutil.copy(file_path, os.path.join(cache_dir, file_path))\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Initialize the S3Client object to interact with the remote directory.\n    s3 = S3Client()\n\n    # Loop continuously, fetching download tasks from the input queue.\n    while True:\n        # Fetch a download task from the input queue.\n        # The task is a tuple containing the index of the task and a list of file paths to download.\n        index, files = queue_in.get()\n\n        # Check if the files are already downloaded.\n        for file in files:\n            # If the file is not already downloaded, download it.\n            if not os.path.exists(os.path.join(cache_dir, file)):\n                # Get the object (file) from the remote directory.\n                obj = parse.urlparse(os.path.join(input_dir.url, file))\n                # Wait for the file to exist.\n                _wait_for_file_to_exist(s3, obj)\n                # Download the file from the remote directory to the local cache directory.\n                s3.download_file(obj, os.path.join(cache_dir, file))\n\n        # Signal completion by putting the task index into the output queue.\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        index, files = task\n        downloaded_files = []\n\n        for f in files:\n            path = os.path.join(cache_dir, f)\n            if not os.path.exists(path):\n                input_dir.download_file(f, path)\n            downloaded_files.append(path)\n\n        queue_out.put((index, downloaded_files))\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        index, files = task\n        for file in files:\n            dest = os.path.join(cache_dir, file.lstrip(\"/\"))\n            if os.path.exists(dest):\n                continue\n            os.makedirs(os.path.dirname(dest), exist_ok=True)\n            input_dir.download(file, dest)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    cache = Cache(cache_dir)\n    while True:\n        task = queue_in.get()\n        if task is None:\n            break\n        index, files = task\n        for file in files:\n            cache.download(input_dir, file)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n            for file in files:\n                obj = parse.urlparse(file)\n                if obj.scheme == \"s3\":\n                    s3 = S3Client()\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download(file, cache_dir)\n                else:\n                    input_dir.download(file, cache_dir)\n            queue_out.put(index)\n        except Empty:\n            sleep(1)\n            continue\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get()\n            for file in files:\n                obj = parse.urlparse(file)\n                if obj.scheme == \"s3\":\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download_file(file, cache_dir)\n                else:\n                    Path(cache_dir).mkdir(parents=True, exist_ok=True)\n                    shutil.copy(file, cache_dir)\n\n            queue_out.put(index)\n        except Exception as e:\n            logger.error(e)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, file_list = queue_in.get(timeout=10)\n            for f in file_list:\n                obj = parse.urlparse(f)\n                local_file = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                os.makedirs(os.path.dirname(local_file), exist_ok=True)\n                if not os.path.exists(local_file):\n                    _wait_for_disk_usage_higher_than_threshold(cache_dir)\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download_file(f, local_file)\n            queue_out.put(index)\n        except Empty:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    cache_dir = Path(cache_dir)\n\n    while True:\n        try:\n            index, paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        # Check if the files are already downloaded\n        downloaded_paths = [path for path in paths if (cache_dir / path).exists()]\n\n        # Download missing files\n        for path in paths:\n            if path not in downloaded_paths:\n                try:\n                    input_dir.download(path, cache_dir)\n                except Exception as e:\n                    logger.error(f\"Failed to download {path}: {e}\")\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file_path in file_paths:\n            # Get the file object from the input directory\n            obj = input_dir.get(file_path)\n            # Get the file's URL or path\n            url = obj.url\n            # Get the file's size\n            size = obj.size\n            # Get the file's last modified time\n            last_modified = obj.last_modified\n\n            # Get the file's name from the URL or path\n            file_name = os.path.basename(url)\n            # Get the file's extension from the file name\n            file_ext = os.path.splitext(file_name)[1]\n            # Get the file's destination path by concatenating the cache directory and the file name\n            file_dst = os.path.join(cache_dir, file_name)\n\n            # Check if the file already exists in the cache directory\n            if os.path.isfile(file_dst):\n                # If the file exists, check if its size and last modified time match the values from the input directory\n                if os.path.getsize(file_dst) == size and os.path.getmtime(file_dst) == last_modified:\n                    # If the sizes and last modified times match, skip the download and continue to the next file\n                    continue\n                else:\n                    # If the sizes or last modified times do not match, delete the existing file\n                    os.remove(file_dst)\n\n            # Download the file from the URL or path to the destination path\n            if url.startswith(\"s3://\"):\n                # If the URL starts with \"s3://\", use the S3Client to download the file\n                s3 = S3Client()\n                s3.download(url, file_dst)\n            else:\n                # Otherwise, use the standard urllib.request to download the file\n                with open(file_dst, \"wb\") as f:\n                    with urllib.request.urlopen(url) as response:\n                        f.write(response.read())\n\n        # Put the index of the completed task into the output queue\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Create the cache directory if it does not exist\n    os.makedirs(cache_dir, exist_ok=True)\n\n    # Create a S3 client to interact with S3\n    s3 = S3Client()\n\n    # Loop until the input queue is empty\n    while True:\n        try:\n            # Get the next task from the input queue\n            index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            # If the input queue is empty, break the loop\n            break\n\n        # Loop through the file paths in the task\n        for file_path in file_paths:\n            # Get the source path or URL for the file\n            source_path = input_dir.get_path(file_path)\n\n            # Get the destination path for the file in the cache\n            destination_path = os.path.join(cache_dir, file_path)\n\n            # If the destination path does not exist, download the file from the source path\n            if not os.path.exists(destination_path):\n                # If the source path is an S3 URL, use the S3 client to download the file\n                if source_path.scheme == \"s3\":\n                    obj = parse.urlparse(source_path)\n                    # Wait for the file to be available on S3\n                    _wait_for_file_to_exist(s3, obj)\n                    # Download the file from S3 to the cache\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), destination_path)\n                # If the source path is a local file, copy it to the cache\n                elif source_path.scheme == \"file\":\n                    shutil.copy(source_path.path, destination_path)\n                # If the source path is not recognized, raise an error\n                else:\n                    raise ValueError(f\"Unsupported source path scheme: {source_path.scheme}\")\n\n        # Put the task index into the output queue to signal that the files for that index are available\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        task_index, files = queue_in.get()\n        if task_index is None:\n            break\n        for f in files:\n            obj = parse.urlparse(f)\n            if obj.scheme == \"s3\":\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(f, cache_dir)\n            else:\n                _wait_for_disk_usage_higher_than_threshold(cache_dir)\n                shutil.copy(f, cache_dir)\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        # 4. Upload the file\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            remove_queue.put(path)\n            continue\n\n        # 5. Upload the file\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 6. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            if output_dir.path:\n                path = path.replace(cache_dir, output_dir.path)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(path), exist_ok=True)\n                    shutil.copyfile(path, path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 7. Inform the remover the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Upload\n        if output_dir.url is not None:\n            if output_dir.url.startswith(\"s3://\"):\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    s3.client.copy_object(CopySource=path, Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n                else:\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            remove_queue.put(path)\n            continue\n\n        # 5. Upload the file\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 6. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            if output_dir.path:\n                path = path.replace(cache_dir, output_dir.path)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                if not obj.path.endswith(\"/\"):\n                    obj = parse.urlparse(path + \"/\")\n\n                _wait_for_file_to_exist(s3, obj)\n\n            elif os.path.isfile(path):\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(path, path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 7. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            remove_queue.put(path)\n            continue\n\n        # 5. Upload\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n        elif output_dir.path is not None:\n            if not path.startswith(cache_dir):\n                path = path.replace(cache_dir, output_dir.path)\n\n            if not os.path.exists(path):\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.move(path, path.replace(cache_dir, output_dir.path))\n\n        # 6. Remove the file from the cache\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Create the S3 client if the output directory is an S3 bucket\n    if output_dir.url and output_dir.url.startswith(\"s3://\"):\n        s3 = S3Client()\n\n    while True:\n        # 2. Fetch from the queue\n        r = upload_queue.get()\n\n        # 3. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 4. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        # 5. Upload the file\n        if output_dir.url and output_dir.url.startswith(\"s3://\"):\n            # 5.1. Upload to S3\n            obj = parse.urlparse(path)\n            s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n        else:\n            # 5.2. Move to local directory\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if os.path.exists(path):\n                shutil.move(path, output_dir.path)\n\n        # 6. Send the path to the remove queue\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Upload\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Remove\n        if os.path.exists(path) and not path.startswith(cache_dir):\n            os.remove(path)\n\n        # 6. Remove the temporary directory\n        if tmp_dir is not None:\n            shutil.rmtree(tmp_dir)\n\n        # 7. Inform the remover\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    try:\n                        _wait_for_file_to_exist(s3, obj)\n                        continue\n                    except botocore.exceptions.ClientError as e:\n                        if \"the HeadObject operation: Not Found\" in str(e):\n                            pass\n                        else:\n                            raise e\n\n            if output_dir.path:\n                if not path.startswith(cache_dir):\n                    path = path.replace(cache_dir, output_dir.path)\n\n                if os.path.exists(path):\n                    continue\n\n        # 5. Upload the file\n        if output_dir.url:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        elif output_dir.path:\n            if not path.startswith(cache_dir):\n                path = path.replace(cache_dir, output_dir.path)\n\n            if os.path.exists(path):\n                continue\n\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            shutil.move(temp_dir, path)\n\n        # 6. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n            path = os.path.join(tmp_dir, path)\n        else:\n            path = r\n\n        # 4. Upload to S3\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Move to the output directory\n        else:\n            if not os.path.exists(output_dir.path):\n                os.makedirs(output_dir.path)\n\n            shutil.move(path, output_dir.path)\n\n        # 6. Inform the remover the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir = None\n            path = r\n\n        # 4. Upload the file\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Remove the file from the cache directory\n        if tmp_dir is not None:\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir = None\n            path = r\n\n        # 4. Check whether the file exists\n        if os.path.exists(path):\n            # 5. Check whether the file is already uploaded\n            if output_dir.url is not None:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    try:\n                        _wait_for_file_to_exist(s3, obj)\n                    except Exception as e:\n                        logger.warning(f\"Failed to check whether {path} exists in {output_dir.url}. {e}\")\n                        continue\n\n            # 6. Upload the file\n            if output_dir.url is not None:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            # 7. Remove the file from the cache directory\n            remove_queue.put(path)\n\n            # 8. Remove the temporary directory if it exists\n            if tmp_dir is not None:\n                shutil.rmtree(tmp_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Upload the file\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        if not path.startswith(cache_dir) and output_dir.path is not None:\n            path = path.replace(output_dir.path, cache_dir)\n\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n        elif output_dir.path is not None:\n            shutil.move(path, output_dir.path)\n\n        # 4. Send the path to the remove queue\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Iterate through the paths and upload them to the output directory\n        for path in paths:\n            if not path.startswith(cache_dir):\n                path = path.replace(cache_dir, \"\")\n\n            if output_dir.url is not None:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    with open(path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                elif os.path.isfile(path):\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            elif os.path.isfile(path):\n                shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        # 4. Upload the file\n        if output_dir.url is not None:\n            s3 = S3Client()\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Move the file to the output directory\n        elif output_dir.path is not None:\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            shutil.move(path, output_dir.path)\n\n        # 6. Remove the file from the cache directory\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir, path = None, r\n\n        # 4. Upload the file\n        if output_dir.url is not None:\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if temp_dir is not None:\n                path = os.path.join(temp_dir, os.path.basename(path))\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n        elif output_dir.path is not None:\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if temp_dir is not None:\n                path = os.path.join(temp_dir, os.path.basename(path))\n\n            shutil.move(path, output_dir.path)\n\n        # 5. Remove the file from the cache\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Upload the file\n        if isinstance(r, tuple):\n            temp_dir, file_path = r\n            if file_path.startswith(cache_dir):\n                file_path = file_path.replace(cache_dir, \"\")\n            s3.client.upload_file(file_path, output_dir.url.netloc, f\"{output_dir.url.path.lstrip('/')}{file_path}\")\n            remove_queue.put(os.path.join(temp_dir, file_path))\n        else:\n            if r.startswith(cache_dir):\n                r = r.replace(cache_dir, \"\")\n            s3.client.upload_file(r, output_dir.url.netloc, f\"{output_dir.url.path.lstrip('/')}{r}\")\n            remove_queue.put(r)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Create an S3 client if the output directory is S3\n    if output_dir.url is not None and output_dir.url.startswith(\"s3://\"):\n        s3 = S3Client()\n\n    # 2. Process items from the upload queue until a termination signal is received\n    while True:\n        # 3. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 4. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 5. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir, path = None, r\n\n        # 6. Prepend the cache directory to the path if it doesn't start with it\n        if not path.startswith(cache_dir):\n            path = os.path.join(cache_dir, path)\n\n        # 7. Upload the file to the output directory\n        if output_dir.url is not None and output_dir.url.startswith(\"s3://\"):\n            obj = parse.urlparse(path)\n\n            if temp_dir is not None:\n                with open(os.path.join(temp_dir, os.path.basename(path)), \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n        # 8. Remove the temporary directory and file if it exists\n        if temp_dir is not None:\n            shutil.rmtree(temp_dir)\n\n        # 9. Send the file path to the remove queue\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n            if obj.scheme == \"s3\":\n                try:\n                    s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n                    continue\n                except botocore.exceptions.ClientError as e:\n                    if \"the HeadObject operation: Not Found\" in str(e):\n                        pass\n                    else:\n                        raise e\n\n        # 5. Upload the file\n        if output_dir.url is not None:\n            if output_dir.url.startswith(\"s3\"):\n                obj = parse.urlparse(path)\n                if obj.scheme == \"s3\":\n                    if not path.startswith(cache_dir):\n                        path = path.replace(cache_dir, output_dir.url)\n\n                    s3.client.copy_object(\n                        Bucket=obj.netloc,\n                        CopySource={\"Bucket\": obj.netloc, \"Key\": obj.path.lstrip(\"/\")},\n                        Key=obj.path.lstrip(\"/\"),\n                    )\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n        elif output_dir.path is not None:\n            if not path.startswith(cache_dir):\n                path = path.replace(cache_dir, output_dir.path)\n\n            if os.path.isfile(path):\n                shutil.copyfile(path, path)\n            else:\n                shutil.copytree(path, path)\n\n        # 6. Remove the file from the cache\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Check if the output directory is an S3 bucket\n    if output_dir.url and output_dir.url.startswith(\"s3://\"):\n        # 2. Create an S3 client\n        s3 = S3Client()\n        # 3. Get the bucket name and prefix from the output directory URL\n        bucket, prefix = output_dir.url.replace(\"s3://\", \"\").split(\"/\", 1)\n        # 4. Iterate through the upload queue\n        while True:\n            # 5. Fetch an item from the upload queue\n            item = upload_queue.get()\n            # 6. If the item is None, it means the process has been terminated, so exit the loop\n            if item is None:\n                break\n            # 7. If the item is a tuple, it means it's a temporary directory and a file path\n            if isinstance(item, tuple):\n                # 8. Extract the temporary directory and file path from the item\n                temp_dir, path = item\n                # 9. If the file path doesn't start with the cache directory, prepend it\n                if not path.startswith(cache_dir):\n                    path = os.path.join(cache_dir, path)\n                # 10. If the file path doesn't start with the temporary directory, prepend it\n                if not path.startswith(temp_dir):\n                    path = os.path.join(temp_dir, path)\n            # 11. If the item is a string, it means it's a file path\n            elif isinstance(item, str):\n                # 12. If the file path doesn't start with the cache directory, prepend it\n                if not item.startswith(cache_dir):\n                    path = os.path.join(cache_dir, item)\n                else:\n                    path = item\n            # 13. If the file path doesn't start with the output directory path, prepend it\n            if not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path)\n            # 14. Get the file name from the file path\n            file_name = os.path.basename(path)\n            # 15. Upload the file to the S3 bucket with the specified prefix and file name\n            s3.client.upload_file(path, bucket, os.path"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Check whether we are uploading to S3 or to a local directory\n    s3 = None\n    if output_dir.url is not None:\n        s3 = S3Client()\n\n    # 2. Process items from the upload queue\n    while True:\n        # 2.1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2.2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 2.3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            path = r\n\n        # 2.4. Prepend the cache directory to the path if it's not already there\n        if not path.startswith(cache_dir):\n            path = os.path.join(cache_dir, path)\n\n        # 2.5. Upload the file to S3\n        if s3:\n            if not output_dir.path:\n                output_dir.path = \"\"\n\n            if not output_dir.path.endswith(\"/\"):\n                output_dir.path += \"/\"\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, output_dir.url, output_dir.path + obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 2.6. Move the file to the local directory\n        else:\n            if not os.path.exists(output_dir.path):\n                os.makedirs(output_dir.path, exist_ok=True)\n\n            if os.path.isfile(path):\n                shutil.move(path, os.path.join(output_dir.path, os.path.basename(path)))\n\n        # 2.7. Send the file path to the remove queue\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a worker.\n    if len(user_items) < world_size:\n        return [user_items[i : i + 1] for i in range(len(user_items))]\n\n    # If the number of items is less than the number of workers, assign each item to a"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    if node_rank == 0:\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n        print(\"=\" * 80)\n       "}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        for worker_id, items, weight in zip(worker_ids_this_node, worker_items, worker_weights):\n            print(f\"Worker {worker_id} has {len(items)} files with total size {weight / 1000 / 1000:.2f} MB.\")\n    else:\n        for worker_id, items, weight in zip(worker_ids_this_node, worker_items, worker_weights):\n            print(f\"Worker {worker_id} has {len(items)} items with total weight {weight}.\")\n\n    # Shuffle the items for each worker and return.\n    return [np.random.permutation(items).tolist() for items in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for i in user_items]\n\n    # If the number of workers is greater than the number of items, assign each item to a worker.\n    if num_workers > len(user_items):\n        return [[i] for"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        print(\n            f\"Worker {node_rank} distribution: {[(worker_id, f'{size:.2f} MB') for worker_id, size in zip(worker_ids_this_node, worker_weights)]}\"\n        )\n    else:\n        print(f\"Worker {node_rank} distribution: {[(worker_id, weight) for worker_id, weight in zip(worker_ids_this_node, worker_weights)]}\")\n\n    # Shuffle the items for each worker and return the list.\n    return [np.random.permutation(items).tolist() for items in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        worker_sizes = [sum(w) / (1024 * 1024) for w in worker_weights]\n        print(f\"Worker {worker_ids_this_node} has {worker_sizes} MB\")\n    else:\n        print(f\"Worker {worker_ids_this_node} has {worker_weights} items\")\n\n    # Shuffle the items for each worker and return the result.\n    return [np.random.permutation(items).tolist() for items in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(worker_items) != world_size:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    # Shuffle the items for each worker\n    worker_items = [list(np.random.permutation(items)) for items in worker_items]\n\n    # Print the distribution details for workers on the current node\n    if file_size:\n        worker_sizes = [sum(map(os.path.getsize, items)) / 1000 / 1000 for items in worker_items]\n        print(f\"Worker {worker_ids_this_node[0]}: {worker_sizes[0]:.2f} MB\")\n        for i in range(1, len(worker_ids_this_node)):\n            print(f\"Worker {worker_ids_this_node[i]}: {worker_sizes[i]:.2f} MB\")\n    else:\n        worker_weights = [sum(weights) for weights in worker_weights]\n        print(f\"Worker {worker_ids_this_node[0]}: {worker_weights[0]}\")\n        for i in range(1, len(worker_ids_this_node)):\n            print(f\"Worker {worker_ids_this_node[i]}: {worker_weights[i]}\")\n\n    # Return the items for each worker, shuffled\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = num_nodes * num_workers\n\n    # Print the distribution details for workers on the current node\n    print(f\"Worker distribution for node {node_rank}:\")\n    for i in range(node_rank * num_workers, (node_rank + 1) * num_workers):\n        print(f\"Worker {i}: {worker_items[i]} items, {worker_weights[i]} weight\")\n\n    # Shuffle the items for each worker\n    shuffled_items = [random.sample(items, len(items)) for items in worker_items]\n\n    return shuffled_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n    worker_items_this_node = [worker_items[i] for i in worker_ids_this_node]\n\n    print(f\"Worker {os.getpid()}: \", end=\"\")\n    if file_size:\n        total_size = sum(worker_weights)\n        print(f\"Total size: {total_size / 1e6:.2f} MB\")\n        for i, (items, weight) in enumerate(zip(worker_items_this_node, worker_weights)):\n            print(f\"Worker {i}: {len(items)} items, {weight / 1e6:.2f} MB\")\n    else:\n        total_weight = sum(worker_weights)\n        print(f\"Total weight: {total_weight}\")\n        for i, (items, weight) in enumerate(zip(worker_items_this_node, worker_weights)):\n            print(f\"Worker {i}: {len(items)} items, weight {weight}\")\n\n    return worker_items_this_node\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_workers = num_nodes * num_workers\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=total_workers)\n\n    # Print the distribution details for workers on the current node\n    print(f\"Worker distribution on node {node_rank}:\")\n    for i, worker_id in enumerate(worker_ids_this_node):\n        worker_items_this_worker = worker_items[worker_id]\n        if file_size:\n            worker_weights_this_worker = worker_weights[worker_id]\n            print(f\"Worker {worker_id} has {len(worker_items_this_worker)} items with total size {sum(worker_weights_this_worker) / 1000 / 1000} MB\")\n        else:\n            print(f\"Worker {worker_id} has {len(worker_items_this_worker)} items with total weight {sum(worker_weights_this_worker)}\")\n\n    # Shuffle the items for each worker\n    for i, worker_id in enumerate(worker_ids_this_node):\n        np.random.shuffle(worker_items[worker_id])\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        total_size = sum(worker_weights)\n        print(f\"Total size: {total_size / 1000 / 1000:.2f} MB\")\n    else:\n        total_weight = sum(worker_weights)\n        print(f\"Total weight: {total_weight}\")\n\n    for i, worker_id in enumerate(worker_ids_this_node):\n        if file_size:\n            size = worker_weights[worker_id]\n            print(f\"Worker {worker_id}: {size / 1000 / 1000:.2f} MB\")\n        else:\n            weight = worker_weights[worker_id]\n            print(f\"Worker {worker_id}: {weight}\")\n\n    # Shuffle the items for each worker and return the list.\n    return [\n        list(np.random.permutation(items))\n        for items in worker_items[node_rank * num_workers : (node_rank + 1) * num_workers]\n    ]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node\n    if file_size:\n        print(\n            f\"Distribution of files among workers on node {node_rank}:\",\n            {\n                f\"Worker {worker_id}\": f\"{size:.2f} MB\"\n                for worker_id, size in zip(worker_ids_this_node, worker_weights)\n            },\n        )\n    else:\n        print(\n            f\"Distribution of items among workers on node {node_rank}:\",\n            {\n                f\"Worker {worker_id}\": f\"{weight} items\"\n                for worker_id, weight in zip(worker_ids_this_node, worker_weights)\n            },\n        )\n\n    # Shuffle the items assigned to each worker\n    shuffled_worker_items = [\n        list(np.random.permutation(worker_items[worker_id])) for worker_id in worker_ids_this_node\n    ]\n\n    return shuffled_worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If the number of items is less than the number of workers, distribute them evenly.\n    if len(user_items) < world_size:\n        result = []\n        for i in range(world_size):\n            result.append([user_items[i]])\n        return result\n\n    # If the number of items is less than the number of workers, distribute them evenly.\n    if len(user_items) < num_workers:\n        result = []\n        for i in range(num_workers):\n            result.append([user_items[i]])\n        return result\n\n    # If the number of items is less than the number of workers on this node, distribute them evenly.\n    if len(user_items) < len(worker_ids_this_node):\n        result = []\n        for i in range(len(worker_ids_this_node)):\n            result.append([user_items[i]])\n        return result\n\n    # Print the distribution details for workers on this node.\n    if file_size:\n        print(f\"Worker {node_rank}: {len(user_items)} items, {sum(weights) / 1000 / 1000} MB\")\n    else:\n        print(f\"Worker {node_rank}: {len(user_items)} items, {sum(weights)} weight\")\n\n    # Assign items to workers on this node based on their weights.\n    result = []\n    for worker_id in worker_ids_this_node:\n        worker_item_indices = worker_items[worker_id]\n        worker_item_weights = worker_weights[worker_id]\n        worker_items_this_worker = [user_items[i] for i in worker_item_indices]\n        worker_weights_this_worker = [weights[i] for i in worker_item_indices]\n        result.append(worker_items_this_worker)\n\n    # Shuffle the items for each worker.\n    for worker_id, worker_items in enumerate(result):\n        np.random.shuffle(worker_items)\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Check if the number of items is divisible by the number of workers\n    if len(user_items) % num_workers != 0:\n        raise ValueError(\"The number of items must be divisible by the number of workers.\")\n\n    # Calculate the total number of workers across all nodes\n    total_workers = num_nodes * num_workers\n\n    # Check if the number of items is less than the total number of workers\n    if len(user_items) < total_workers:\n        raise ValueError(\"The number of items must be greater than or equal to the total number of workers.\")\n\n    # Check if the weights are provided and have the same length as the items\n    if weights is not None and len(weights) != len(user_items):\n        raise ValueError(\"The weights must be provided and have the same length as the items.\")\n\n    # Calculate the total weight of the items\n    total_weight = sum(weights) if weights is not None else len(user_items)\n\n    # Calculate the average weight of each item\n    avg_weight = total_weight / len(user_items)\n\n    # Calculate the average weight of each worker\n    avg_worker_weight = total_weight / total_workers\n\n    # Calculate the average number of items per worker\n    avg_items_per_worker = len(user_items) / total_workers\n\n    # Calculate the average number of items per worker on the current node\n    avg_items_per_worker_this_node = len(user_items) / num_workers\n\n    # Print the distribution details for workers on the current node\n    print(f\"Average weight of each item: {avg_weight:.2f}\")\n    print(f\"Average weight of each worker: {avg_worker_weight:.2f}\")\n    print(f\"Average number of items per worker: {avg_items_per_worker:.2f}\")\n    print(f\"Average number of items per worker on this node: {avg_items_per_worker_this_node:.2f}\")\n    print(f\"Total number of workers across all nodes: {total_workers}\")\n\n    # Calculate the distribution of items to workers based on weights\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=total_workers)\n\n    # Print the distribution details for workers on the current"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If the number of items is less than the number of workers, distribute them equally\n    if len(user_items) < world_size:\n        worker_items = [[] for _ in range(world_size)]\n        for i, item in enumerate(user_items):\n            worker_items[i % world_size].append(item)\n        return worker_items\n\n    # If the number of items is less than the number of workers, distribute them equally\n    if len(user_items) < num_workers:\n        worker_items = [[] for _ in range(num_workers)]\n        for i, item in enumerate(user_items):\n            worker_items[i % num_workers].append(item)\n        return worker_items\n\n    # Calculate the total weight of items\n    total_weight = sum(worker_weights)\n\n    # Calculate the average weight per worker\n    avg_weight = total_weight / world_size\n\n    # Calculate the average file size per worker\n    avg_size = total_weight / len(user_items)\n\n    # Calculate the average file size per worker\n    if file_size:\n        avg_size = avg_size / 1000000\n\n    # Print the distribution details for workers on the current node\n    print(\n        f\"Worker distribution on node {node_rank}:\",\n        \"\\n\".join(\n            [\n                f\"Worker {i} (node {i // num_workers}): {len(items)} items, {sum(weights)} weight, {sum(weights) / avg_weight:.2f}x average, {sum(weights) / total_weight:.2f}x total\"\n                for i, (items, weights) in enumerate(zip(worker_items, worker_weights))\n                if i in worker_ids_this_node\n            ]\n        ),\n    )\n\n    # Shuffle the items for each worker\n    return [\n        [item for _, item in sorted(zip(weights, items))]\n        for items, weights in zip(worker_items, worker_weights)\n    ]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if num_workers != len(worker_items):\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    # Shuffle the items for each worker\n    for i in range(len(worker_items)):\n        random.shuffle(worker_items[i])\n\n    # Print the distribution details for workers on the current node\n    if node_rank == 0:\n        print(f\"Worker Distribution on Node {node_rank}:\")\n        for i, worker_id in enumerate(worker_ids_this_node):\n            if file_size:\n                print(f\"Worker {worker_id}: {sum(worker_items[i]) / 1000 / 1000:.2f} MB\")\n            else:\n                print(f\"Worker {worker_id}: {sum(worker_weights[i])}\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n\n    # Calculate the weight of each worker\n    worker_weight = total_weight / total_workers\n\n    # Calculate the weight of each item\n    item_weight = [weight / total_weight for weight in weights]\n\n    # Calculate the number of items for each worker\n    worker_items = [0] * total_workers\n    for i, item in enumerate(item_weight):\n        worker_items[i % total_workers] += item\n\n    # Calculate the number of items for each worker on the current node\n    worker_items_this_node = [0] * num_workers\n    for i, item in enumerate(item_weight):\n        worker_items_this_node[i % num_workers] += item\n\n    # Print the distribution details for workers on the current node\n    print(f\"Worker items on node {node_rank}:\", worker_items_this_node)\n    print(f\"Worker weights on node {node_rank}:\", worker_weight)\n\n    # Assign items to workers based on weights\n    worker_items = [[] for _ in range(total_workers)]\n    for i, item in enumerate(user_items):\n        worker_id = i % total_workers\n        worker_items[worker_id].append(item)\n\n    # Shuffle the items for each worker\n    for i in range(total_workers):\n        random.shuffle(worker_items[i])\n\n    # Return the items for each worker\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    world_size = num_nodes * num_workers\n\n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n\n    # Calculate the total size of all items\n    total_size = sum(weights) if file_size else None\n\n    # Print the distribution details for workers on the current node\n    print(f\"Worker distribution on node {node_rank}:\")\n    for i in range(num_workers):\n        worker_id = node_rank * num_workers + i\n        worker_weight = worker_weights[worker_id]\n        worker_size = worker_weights[worker_id] if file_size else None\n        print(f\"Worker {worker_id}: {worker_weight} items, {worker_size} MB\")\n\n    # Distribute items to workers based on provided weights\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Shuffle the items assigned to each worker\n    for i in range(len(worker_items)):\n        random.shuffle(worker_items[i])\n\n    # Return the items for each worker\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n\n    # 3. Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [items_per_worker] * (total_workers - 1))\n    end_indices = np.cumsum([items_per_worker] * total_workers)\n\n    # 4. Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) - sum(end_indices)\n    end_indices[-remainder:] += 1\n\n    # 5. Assign items to workers\n    worker_items = []\n    for i in range(total_workers):\n        worker_items.append(user_items[start_indices[i] : end_indices[i]])\n\n    # 6. Ensure the output list has a length equal to the number of workers\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    total_workers = num_workers * num_nodes\n\n    # Calculate the number of items each worker should process\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    # Assign items to workers sequentially\n    items_per_node = [items_per_worker] * total_workers\n    if remainder > 0:\n        for i in range(remainder):\n            items_per_node[-i - 1] += 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + items_per_node[:-1])\n    end_indices = np.cumsum(items_per_node)\n\n    # Assign items to workers\n    items_per_worker = []\n    for start, end in zip(start_indices, end_indices):\n        items_per_worker.append(user_items[start:end])\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(f\"Improper assignment of items to workers. Expected {num_workers} workers, got {len(items_per_worker)}.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # 2. Calculate how many items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # 3. Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    if remainder:\n        for i in range(remainder):\n            user_items[total_workers - 1 - i].append(user_items[-1 - i])\n\n    # 4. Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (total_workers - 1))\n    end_indices = np.cumsum([num_items_per_worker] * total_workers)\n\n    # 5. Assign the items to each worker\n    worker_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # 6. Ensure the output list has a length equal to the number of workers\n    if len(worker_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    total_workers = num_nodes * num_workers\n\n    # 2. Calculate the number of items each worker should process\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_workers\n\n    # 3. Adjust for any remainder by adding extra items to the last workers in the list\n    remainder = num_items % total_workers\n    num_items_per_worker_with_remainder = num_items_per_worker + 1\n    num_workers_with_remainder = remainder\n\n    # 4. Use cumulative sum to efficiently calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker_with_remainder] * num_workers_with_remainder)\n    end_indices = np.cumsum([num_items_per_worker_with_remainder] * num_workers_with_remainder)\n\n    # 5. Assign the items to the workers\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # 6. Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_num_workers\n\n    # Handle any remainder by distributing extra items to the last workers\n    remainder = len(user_items) % total_num_workers\n\n    # Calculate the start and end indices for each worker's items\n    indices = np.cumsum([0] + [num_items_per_worker] * total_num_workers)\n    indices[-1] += remainder\n\n    # Assign items to workers\n    items_per_worker = [user_items[start:end] for start, end in zip(indices[:-1], indices[1:])]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    total_workers = num_workers * num_nodes\n\n    # Calculate the number of items each worker should process\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n\n    # Handle any remainder by distributing extra items to the last workers in the list\n    remainder = num_items % total_workers\n    if remainder > 0:\n        items_per_worker += 1\n        remainder -= 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [items_per_worker] * (total_workers - 1))\n    end_indices = np.cumsum([items_per_worker] * total_workers)\n\n    # Assign the items to each worker\n    items_per_worker_per_node = []\n    for i in range(num_workers):\n        start_idx = start_indices[i + _get_node_rank() * num_workers]\n        end_idx = end_indices[i + _get_node_rank() * num_workers]\n        items_per_worker_per_node.append(user_items[start_idx:end_idx])\n\n    # Check if the output list has the correct length\n    if len(items_per_worker_per_node) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker_per_node\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # 2. Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n\n    # 3. Calculate the number of workers that will have one extra item\n    remainder = len(user_items) % total_workers\n\n    # 4. Calculate the start and end indices for each worker's items\n    start_indices = [i * num_items_per_worker for i in range(total_workers)]\n    end_indices = [i * num_items_per_worker + num_items_per_worker for i in range(total_workers - 1)]\n    end_indices.append(len(user_items))\n\n    # 5. Add extra items to the workers starting from the end of the list\n    for i in range(remainder):\n        end_indices[-(i + 1)] += 1\n\n    # 6. Create a list of lists, where each sublist contains the items assigned to a worker\n    items_per_worker = []\n    for i in range(total_workers):\n        items_per_worker.append(user_items[start_indices[i] : end_indices[i]])\n\n    # 7. Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers_total = num_nodes * num_workers\n    items_per_worker = len(user_items) // num_workers_total\n\n    # Calculate the number of items for each worker\n    items_per_worker_list = [items_per_worker] * num_workers_total\n\n    # Distribute the remainder to the last workers\n    remainder = len(user_items) % num_workers_total\n    for i in range(remainder):\n        items_per_worker_list[-(i + 1)] += 1\n\n    # Calculate the start and end indices for each worker\n    start_indices = np.cumsum([0] + items_per_worker_list[:-1])\n    end_indices = np.cumsum(items_per_worker_list)\n\n    # Assign items to each worker\n    worker_items = []\n    for i in range(num_workers):\n        start_idx = start_indices[i + node_rank * num_workers]\n        end_idx = end_indices[i + node_rank * num_workers]\n        worker_items.append(user_items[start_idx:end_idx])\n\n    # Ensure the output list has the correct length\n    if len(worker_items) != num_workers:\n        raise RuntimeError(f\"Improper assignment of items to workers. Expected {num_workers} workers, got {len(worker_items)}.\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    total_num_workers = num_nodes * num_workers\n\n    if total_num_workers == 0:\n        return []\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_num_workers\n\n    # Determine the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (total_num_workers - 1))\n    end_indices = np.cumsum([num_items_per_worker] * total_num_workers)\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) - sum(end_indices)\n    if remainder > 0:\n        for i in range(remainder):\n            end_indices[-i - 1] += 1\n\n    # Assign the items to the workers\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_num_workers:\n        raise RuntimeError(\n            f\"Improper assignment of items to workers. Expected {total_num_workers} workers, but got {len(items_per_worker)}.\"\n        )\n\n    # Return the items assigned to the current node's workers\n    return items_per_worker[node_rank * num_workers : (node_rank + 1) * num_workers]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the total number of workers across all nodes\n    total_workers = num_workers * num_nodes\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n\n    # Handle any remainder by distributing extra items to the last workers in the list\n    remainder = len(user_items) % total_workers\n    if remainder > 0:\n        items_per_worker += 1\n        remainder -= 1\n\n    # Determine the start and end indices for each worker's items\n    indices = np.cumsum([0] + [items_per_worker] * (total_workers - 1))\n    start_indices = indices[:-1]\n    end_indices = indices[1:]\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    if remainder > 0:\n        start_indices[-remainder:] += 1\n        end_indices[-remainder:] += 1\n\n    # Assign the items to the workers\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Return the list of lists, where each sublist contains the items assigned to a worker\n    return items_per_worker[node_rank * num_workers : (node_rank + 1) * num_workers]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # Calculate the total number of workers across all nodes\n    total_workers = num_nodes * num_workers\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) % total_workers\n    for i in range(remainder):\n        user_items.insert(len(user_items) - i, user_items.pop())\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (total_workers - 1))\n    end_indices = np.cumsum([num_items_per_worker] * total_workers)\n\n    # Assign the items to the workers based on their rank\n    worker_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    total_workers = num_workers * num_nodes\n    items_per_worker = len(user_items) // total_workers\n\n    # Calculate the number of items to be assigned to each worker\n    worker_items = [items_per_worker] * total_workers\n    remainder = len(user_items) % total_workers\n    if remainder > 0:\n        for i in range(remainder):\n            worker_items[total_workers - i - 1] += 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + worker_items[:-1])\n    end_indices = np.cumsum(worker_items)\n\n    # Assign items to each worker based on their start and end indices\n    worker_items = [user_items[start_indices[i] : end_indices[i]] for i in range(total_workers)]\n\n    # Check that the output list has the correct length\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\n            f\"Improper assignment of items to workers. Expected {num_workers} workers, but got {len(worker_items)}.\"\n        )\n\n    # Return the items assigned to the current node's workers\n    return worker_items[node_rank * num_workers : (node_rank + 1) * num_workers]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    total_num_workers = num_workers * num_nodes\n\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_num_workers\n\n    if num_items_per_worker == 0:\n        raise ValueError(f\"There are {num_items} items, but {total_num_workers} workers. Please reduce the number of workers.\")\n\n    remainder = num_items % total_num_workers\n\n    workers_items = []\n    start = 0\n    for i in range(total_num_workers):\n        end = start + num_items_per_worker\n        if remainder > 0:\n            end += 1\n            remainder -= 1\n        workers_items.append(user_items[start:end])\n        start = end\n\n    if len(workers_items) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return workers_items[node_rank * num_workers : (node_rank + 1) * num_workers]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # Determine how many items each worker should process\n    items_per_worker = int(np.ceil(len(user_items) / total_workers))\n\n    # Calculate the number of items to be assigned to each worker\n    items_to_assign = [items_per_worker] * total_workers\n    items_to_assign[-1] -= sum(items_to_assign) - len(user_items)\n\n    # Create a list to hold the items assigned to each worker\n    items_per_worker_list = []\n\n    # Assign items to workers\n    start_index = 0\n    for num_items in items_to_assign:\n        end_index = start_index + num_items\n        items_per_worker_list.append(user_items[start_index:end_index])\n        start_index = end_index\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker_list) != total_workers:\n        raise RuntimeError(\n            \"Improper assignment of items to workers. Please ensure the output list has a length equal to the number of workers.\"\n        )\n\n    return items_per_worker_list\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # Determine how many items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n\n    # Calculate the total number of items that can be evenly distributed\n    total_items_evenly_distributed = num_items_per_worker * total_workers\n\n    # Calculate the number of items that need to be distributed among the last workers\n    remainder = len(user_items) - total_items_evenly_distributed\n\n    # Determine how many workers should receive an extra item\n    num_workers_with_extra_item = remainder % num_workers\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = [i * num_items_per_worker for i in range(total_workers)]\n    end_indices = [(i + 1) * num_items_per_worker for i in range(total_workers)]\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    for i in range(num_workers_with_extra_item):\n        end_indices[-i - 1] += 1\n\n    # Map the items to the workers\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Return the list of items assigned to each worker\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n\n    # Calculate the remainder of items to be distributed among workers\n    remainder = len(user_items) % total_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    if remainder > 0:\n        items_per_worker += 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = [i * items_per_worker for i in range(total_workers)]\n    end_indices = [i * items_per_worker + items_per_worker for i in range(total_workers)]\n\n    # Handle any remainder by distributing extra items to the last workers in the list\n    if remainder > 0:\n        start_indices[-remainder:] = end_indices[-remainder:]\n        end_indices[-remainder:] = [i + 1 for i in end_indices[-remainder:]]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(start_indices) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    # Assign items to workers\n    return [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n\n    # 3. Calculate the remainder of items\n    remainder = len(user_items) % total_workers\n\n    # 4. Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    if remainder:\n        num_items_per_worker += 1\n        extra_items = user_items[-remainder:]\n        user_items = user_items[:-remainder]\n    else:\n        extra_items = []\n\n    # 5. Determine the start and end indices for each worker's items\n    start_indices = np.arange(0, len(user_items), num_items_per_worker)\n    end_indices = np.arange(num_items_per_worker, len(user_items) + num_items_per_worker, num_items_per_worker)\n\n    # 6. Add the extra items to the workers starting from the end of the list\n    for i in range(remainder):\n        start_indices[total_workers - i - 1] += i\n        end_indices[total_workers - i - 1] += i\n\n    # 7. Ensure the output list has a length equal to the number of workers\n    if len(start_indices) != total_workers:\n        raise RuntimeError(\n            \"Improper assignment of items to workers. Please ensure the number of workers matches the number of items.\"\n        )\n\n    # 8. Assign the items to the workers based on the calculated start and end indices\n    items_per_worker = []\n    for start, end in zip(start_indices, end_indices):\n        items_per_worker.append(user_items[start:end])\n\n    # 9. Add the extra items to the workers starting from the end of the list\n    for i, item in enumerate(extra_items):\n        items_per_worker[total_workers - i - 1].append(item)\n\n    # 10. Return the list of items assigned to each worker\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers = num_nodes * num_workers\n    num_items = len(user_items)\n\n    if num_items == 0:\n        return []\n\n    items_per_worker = num_items // num_workers\n    remainder = num_items % num_workers\n\n    if node_rank == 0:\n        num_items_for_node = items_per_worker * num_nodes + remainder\n    else:\n        num_items_for_node = items_per_worker * num_nodes\n\n    items_per_worker_for_node = num_items_for_node // num_workers\n    remainder_for_node = num_items_for_node % num_workers\n\n    start_indices = np.cumsum(\n        np.concatenate(\n            (\n                np.zeros(node_rank, dtype=int),\n                np.full(num_workers, items_per_worker_for_node, dtype=int),\n                np.full(remainder_for_node, items_per_worker_for_node + 1, dtype=int),\n            )\n        )\n    )\n\n    end_indices = np.cumsum(\n        np.concatenate(\n            (\n                np.zeros(node_rank + 1, dtype=int),\n                np.full(num_workers - 1, items_per_worker_for_node, dtype=int),\n                np.full(remainder_for_node, items_per_worker_for_node + 1, dtype=int),\n            )\n        )\n    )\n\n    if len(start_indices) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return [user_items[start_indices[i] : end_indices[i]] for i in range(num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers = num_nodes * num_workers\n    num_items = len(user_items)\n\n    items_per_worker = num_items // num_workers\n    items_per_worker_remainder = num_items % num_workers\n\n    # Distribute the remainder among the last workers\n    start_indices = np.cumsum([0] + [items_per_worker] * (num_workers - items_per_worker_remainder))\n    end_indices = np.cumsum([items_per_worker] * num_workers)\n    end_indices[-items_per_worker_remainder:] -= 1\n\n    # Assign items to workers\n    worker_items = [user_items[start:end + 1] for start, end in zip(start_indices, end_indices)]\n\n    # Check if the number of workers matches the number of items\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    items_per_worker_adjusted = [items_per_worker] * total_workers\n    for i in range(remainder):\n        items_per_worker_adjusted[total_workers - 1 - i] += 1\n\n    # Calculate the start and end indices for each worker's items\n    indices = np.cumsum([0] + items_per_worker_adjusted)\n\n    # Assign the items to each worker\n    items_per_worker_list = [user_items[indices[i] : indices[i + 1]] for i in range(total_workers)]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker_list) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker_list\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # TODO: Understand why it hangs.\n        if _get_num_nodes() > 1:\n            return\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Ensure the cache dir is the same across all nodes\n        cache_dir = broadcast_object(\"cache_dir\", cache_dir)\n\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Remove the cache directory if it exists\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        # Recreate the cache directory\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(f\"Error: {e}\")\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as exc:\n            logger.error(f\"Error while retrieving file size: {exc}\")\n            item_sizes.append(0)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return element.startswith(input_dir) if input_dir is not None else os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _to_path(element) == element or os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(_to_path(element)) or _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _IS_IN_STUDIO and input_dir is not None and element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, _to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element)\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            return self._get_tcnn_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n        else:\n            return self._get_pytorch_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons <= 1024:\n                return self._get_tcnn_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            else:\n                return self._get_tcnn_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n        else:\n            return self._get_pytorch_network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_layers=n_layers,\n                n_neurons=n_neurons,\n                activation=activation,\n                output_activation=output_activation,\n            )\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, 1),\n                    torch.nn.ReLU(),\n                    torch.nn.Linear(1, n_output_dims),\n                )\n            else:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU(),\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            layers = []\n            for i in range(n_layers):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                elif i == n_layers - 1:\n                    layers.append(nn.Linear(n_neurons, n_output_dims))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise ValueError(f\"Unknown activation function: {activation}\")\n\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise ValueError(f\"Unknown activation function: {output_activation}\")\n\n            return nn.Sequential(*layers)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons < 100:\n                net = tinycudann.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_layers,\n                    n_neurons,\n                    activation,\n                    output_activation,\n                )\n            else:\n                net = tinycudann.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_layers,\n                    n_neurons,\n                    activation,\n                    output_activation,\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU())\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            net = nn.Sequential(*layers)\n\n        return net\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n                )\n\n            if n_neurons == 2:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                    torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n                )\n\n            if n_neurons == 3:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                    torch.nn.Linear(n_neurons, n_neurons),\n                    torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                    torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n                )\n\n            return torch.nn.Sequential(\n                torch.nn.Linear(n_input_dims, n_neurons),\n                torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                torch.nn.Linear(n_neurons, n_neurons),\n                torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                torch.nn.Linear(n_neurons, n_neurons),\n                torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                torch.nn.Linear(n_neurons, n_output_dims),\n                torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n            )\n\n        # PyTorch\n        layers = [\n            torch.nn.Linear"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_output_dims),\n                    torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n                )\n\n            return torch.nn.Sequential(\n                torch.nn.Linear(n_input_dims, n_neurons),\n                torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                *[\n                    torch.nn.Sequential(\n                        torch.nn.Linear(n_neurons, n_neurons),\n                        torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                    )\n                    for _ in range(n_layers - 2)\n                ],\n                torch.nn.Linear(n_neurons, n_output_dims),\n                torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n            )\n        else:\n            return torch.nn.Sequential(\n                torch.nn.Linear(n_input_dims, n_neurons),\n                torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                *[\n                    torch.nn.Sequential(\n                        torch.nn.Linear(n_neurons, n_neurons),\n                        torch.nn.ReLU() if activation == \"ReLU\" else torch.nn.Identity(),\n                    )\n                    for _ in range(n_layers - 2)\n                ],\n                torch.nn.Linear(n_neurons, n_output_dims),\n                torch.nn.Sigmoid() if output_activation == \"Sigmoid\" else torch.nn.Identity(),\n            )\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 32:\n                network = tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            elif n_neurons <= 128:\n                network = tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            elif n_neurons <= 512:\n                network = tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            else:\n                network = tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n        else:\n            # PyTorch\n            network = nn.Sequential()\n            for i in range(n_layers):\n                if i == 0:\n                    network.add_module(\n                        \"layer_{}\".format(i),\n                        nn.Linear(n_input_dims, n_neurons),\n                    )\n                elif i == n_layers - 1:\n                    network.add_module(\n                        \"layer_{}\".format(i),\n                        nn.Linear(n_neurons, n_output_dims),\n                    )\n                else:\n                    network.add_module(\n                        \"layer_{}\".format(i),\n                        nn.Linear(n_neurons, n_neurons),\n                    )\n                if activation == \"ReLU\":\n                    network.add_module"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_neurons <= 256:\n                network = torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU(),\n                    *[\n                        torch.nn.Linear(n_neurons, n_neurons)\n                        for _ in range(n_layers - 1)\n                    ],\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                )\n            else:\n                network = torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU(),\n                    *[\n                        torch.nn.Linear(n_neurons, n_neurons)\n                        for _ in range(n_layers - 1)\n                    ],\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            if activation == \"ReLU\":\n                activation_fn = torch.nn.ReLU()\n            elif activation == \"None\":\n                activation_fn = torch.nn.Identity()\n            else:\n                raise ValueError(f\"Invalid activation function: {activation}\")\n\n            if output_activation == \"ReLU\":\n                output_activation_fn = torch.nn.ReLU()\n            elif output_activation == \"Sigmoid\":\n                output_activation_fn = torch.nn.Sigmoid()\n            elif output_activation == \"None\":\n                output_activation_fn = torch.nn.Identity()\n            else:\n                raise ValueError(\n                    f\"Invalid output activation function: {output_activation}\"\n                )\n\n            layers = [\n                nn.Linear(n_input_dims, n_neurons),\n                activation_fn,\n            ]\n            for _ in range(n_layers - 1):\n                layers.extend(\n                    [\n                        nn.Linear(n_neurons, n_neurons),\n                        activation_fn,\n                    ]\n                )\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(output_activation_fn)\n\n            network = nn.Sequential(*layers)\n\n        return network\n\n   "}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return torch.nn.Linear(n_input_dims, n_output_dims)\n            else:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU(),\n                    *[\n                        torch.nn.Linear(n_neurons, n_neurons)\n                        for _ in range(n_layers - 2)\n                    ],\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            layers = []\n            layers.append(\n                torch.nn.Linear(n_input_dims, n_neurons, bias=False)\n            )\n            if activation == \"ReLU\":\n                layers.append(torch.nn.ReLU())\n            elif activation == \"None\":\n                pass\n            else:\n                raise ValueError(\"Invalid activation function\")\n\n            for _ in range(n_layers - 2):\n                layers.append(\n                    torch.nn.Linear(n_neurons, n_neurons, bias=False)\n                )\n                if activation == \"ReLU\":\n                    layers.append(torch.nn.ReLU())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise ValueError(\"Invalid activation function\")\n\n            layers.append(\n                torch.nn.Linear(n_neurons, n_output_dims, bias=False)\n            )\n\n            if output_activation == \"ReLU\":\n                layers.append(torch.nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(torch.nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise ValueError(\"Invalid output activation function\")\n\n            return torch.nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.Sigmoid(),\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            if activation == \"ReLU\":\n                activation_layer = nn.ReLU()\n            elif activation == \"None\":\n                activation_layer = nn.Identity()\n            else:\n                raise ValueError(f\"Unknown activation function: {activation}\")\n\n            if output_activation == \"ReLU\":\n                output_activation_layer = nn.ReLU()\n            elif output_activation == \"Sigmoid\":\n                output_activation_layer = nn.Sigmoid()\n            elif output_activation == \"None\":\n                output_activation_layer = nn.Identity()\n            else:\n                raise ValueError(f\"Unknown output activation function: {output_activation}\")\n\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims if i == 0 else n_neurons, n_neurons))\n                layers.append(activation_layer)\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(output_activation_layer)\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons <= 1024:\n                return tinycudann.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_layers,\n                    n_neurons,\n                    activation,\n                    output_activation,\n                )\n            else:\n                return tinycudann.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_layers,\n                    n_neurons,\n                    activation,\n                    output_activation,\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = []\n            for i in range(n_layers):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                elif i == n_layers - 1:\n                    layers.append(nn.Linear(n_neurons, n_output_dims))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise Exception(\"Invalid activation function\")\n\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise Exception(\"Invalid output activation function\")\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return torch.nn.Linear(n_input_dims, n_output_dims)\n            else:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    torch.nn.ReLU(),\n                    *[\n                        torch.nn.Linear(n_neurons, n_neurons)\n                        for _ in range(n_layers - 1)\n                    ],\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            if activation == \"ReLU\":\n                activation_fn = torch.nn.ReLU()\n            elif activation == \"None\":\n                activation_fn = torch.nn.Identity()\n            else:\n                raise ValueError(f\"Unknown activation function: {activation}\")\n\n            if output_activation == \"ReLU\":\n                output_activation_fn = torch.nn.ReLU()\n            elif output_activation == \"Sigmoid\":\n                output_activation_fn = torch.nn.Sigmoid()\n            elif output_activation == \"None\":\n                output_activation_fn = torch.nn.Identity()\n            else:\n                raise ValueError(f\"Unknown output activation function: {output_activation}\")\n\n            if n_layers == 1:\n                return torch.nn.Sequential(\n                    torch.nn.Linear(n_input_dims, n_output_dims),\n                    output_activation_fn,\n                )\n            else:\n                layers = [\n                    torch.nn.Linear(n_input_dims, n_neurons),\n                    activation_fn,\n                ]\n                for _ in range(n_layers - 2):\n                    layers.extend([\n                        torch.nn.Linear(n_neurons, n_neurons),\n                        activation_fn,\n                    ])\n                layers.extend([\n                    torch.nn.Linear(n_neurons, n_output_dims),\n                    output_activation_fn,\n                ])\n                return torch.nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                    nn.Sigmoid(),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                    nn.Sigmoid(),\n                )\n        else:\n            # PyTorch\n            model = torch.nn.Sequential()\n            model.add_module(\"linear1\", torch.nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                model.add_module(\"relu1\", torch.nn.ReLU())\n            elif activation == \"Sigmoid\":\n                model.add_module(\"sigmoid1\", torch.nn.Sigmoid())\n            for i in range(2, n_layers):\n                model.add_module(f\"linear{i}\", torch.nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    model.add_module(f\"relu{i}\", torch.nn.ReLU())\n                elif activation == \"Sigmoid\":\n                    model.add_module(f\"sigmoid{i}\", torch.nn.Sigmoid())\n            model.add_module(f\"linear{n_layers}\", torch.nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                model.add_module(f\"relu{n_layers}\", torch.nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                model.add_module(f\"sigmoid{n_layers}\", torch.nn.Sigmoid())\n            return model"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons == 1:\n                model = nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                    nn.Sigmoid(),\n                )\n            else:\n                model = nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    *[\n                        nn.Linear(n_neurons, n_neurons),\n                        nn.ReLU(),\n                    ]\n                    * (n_layers - 2),\n                    nn.Linear(n_neurons, n_output_dims),\n                    nn.Sigmoid(),\n                )\n        else:\n            if activation == \"ReLU\":\n                activation_fn = nn.ReLU()\n            elif activation == \"None\":\n                activation_fn = nn.Identity()\n            else:\n                raise ValueError(f\"Unsupported activation function: {activation}\")\n\n            if output_activation == \"ReLU\":\n                output_activation_fn = nn.ReLU()\n            elif output_activation == \"Sigmoid\":\n                output_activation_fn = nn.Sigmoid()\n            elif output_activation == \"None\":\n                output_activation_fn = nn.Identity()\n            else:\n                raise ValueError(\n                    f\"Unsupported output activation function: {output_activation}\"\n                )\n\n            layers = []\n            for i in range(n_layers - 1):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(activation_fn)\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(output_activation_fn)\n            model = nn.Sequential(*layers)\n\n        return model"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                    nn.Sigmoid(),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                    nn.Sigmoid(),\n                )\n        else:\n            if activation == \"ReLU\":\n                activation_fn = nn.ReLU\n            elif activation == \"None\":\n                activation_fn = nn.Identity\n            else:\n                raise ValueError(f\"Invalid activation function: {activation}\")\n\n            if output_activation == \"ReLU\":\n                output_activation_fn = nn.ReLU\n            elif output_activation == \"Sigmoid\":\n                output_activation_fn = nn.Sigmoid\n            elif output_activation == \"None\":\n                output_activation_fn = nn.Identity\n            else:\n                raise ValueError(f\"Invalid output activation function: {output_activation}\")\n\n            layers = []\n            for i in range(n_layers):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                elif i == n_layers - 1:\n                    layers.append(nn.Linear(n_neurons, n_output_dims))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(activation_fn())\n            layers.append(output_activation_fn())\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                    nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity(),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                    nn.Linear(n_neurons, n_output_dims),\n                    nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity(),\n                )\n        else:\n            seed = self._get_seed()\n            torch.manual_seed(seed)\n            layers = [nn.Linear(n_input_dims, n_neurons)]\n            for _ in range(n_layers - 2):\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(\n                nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity()\n            )\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU(),\n                    nn.Linear(n_neurons, n_output_dims),\n                )\n        else:\n            if activation == \"ReLU\":\n                activation_fn = nn.ReLU()\n            elif activation == \"None\":\n                activation_fn = nn.Identity()\n            else:\n                raise ValueError(\"Invalid activation function\")\n\n            if output_activation == \"ReLU\":\n                output_activation_fn = nn.ReLU()\n            elif output_activation == \"Sigmoid\":\n                output_activation_fn = nn.Sigmoid()\n            elif output_activation == \"None\":\n                output_activation_fn = nn.Identity()\n            else:\n                raise ValueError(\"Invalid output activation function\")\n\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(activation_fn)\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(activation_fn)\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(output_activation_fn)\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            if n_neurons == 1:\n                network_type = \"linear\"\n            else:\n                network_type = \"mlp\"\n\n            network = torch.nn.Sequential(\n                torch.nn.Linear(n_input_dims, n_neurons),\n                torch.nn.ReLU(),\n                torch.nn.Linear(n_neurons, n_output_dims),\n            )\n        else:\n            network = torch.nn.Sequential()\n\n            network.add_module(\n                \"input\",\n                torch.nn.Linear(n_input_dims, n_neurons),\n            )\n            if activation == \"ReLU\":\n                network.add_module(\"input_activation\", torch.nn.ReLU())\n            elif activation == \"None\":\n                pass\n            else:\n                raise ValueError(f\"Invalid activation: {activation}\")\n\n            for i in range(n_layers - 2):\n                network.add_module(\n                    f\"layer_{i + 1}\",\n                    torch.nn.Linear(n_neurons, n_neurons),\n                )\n                if activation == \"ReLU\":\n                    network.add_module(f\"activation_{i + 1}\", torch.nn.ReLU())\n                elif activation == \"None\":\n                    pass\n                else:\n                    raise ValueError(f\"Invalid activation: {activation}\")\n\n            network.add_module(\n                f\"output\",\n                torch.nn.Linear(n_neurons, n_output_dims),\n            )\n            if output_activation == \"ReLU\":\n                network.add_module(\"output_activation\", torch.nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                network.add_module(\"output_activation\", torch.nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise ValueError(f\"Invalid output activation: {output_activation}\")\n\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            # If tinycudann is used, create a network with the specified number of input and output dimensions, and the specified number of layers and neurons.\n            # The activation function is set to the specified activation function for the hidden layers, and the output activation is set to the specified activation function for the output layer.\n            # The network is created using the tinycudann library.\n            if n_neurons == 1:\n                return tinycudann.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n            else:\n                return tinycudann.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n        else:\n            # If PyTorch is used, create a sequential network with the specified number of input and output dimensions, and the specified number of layers and neurons.\n            # The activation function is set to the specified activation function for the hidden layers, and the output activation is set to the specified activation function for the output layer.\n            # The network is created using the torch.nn.Sequential class.\n            # The seed is set to the specified seed value.\n            torch.manual_seed(self._get_seed())\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                *[\n                    nn.Sequential(\n                        nn.Linear(n_neurons, n_neurons),\n                        nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                    )\n                    for _ in range(n_layers - 2)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n                nn.ReLU()\n                if output_activation == \"ReLU\"\n                else nn.Sigmoid()\n                if output_"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            # TinyCUDNN\n            if n_neurons < 1024:\n                network_type = \"tiny\"\n            elif n_neurons < 4096:\n                network_type = \"small\"\n            else:\n                network_type = \"large\"\n\n            network = torch.nn.Sequential(\n                *[\n                    nn.Sequential(\n                        nn.Linear(n_input_dims, n_neurons),\n                        nn.ReLU(),\n                    )\n                    for _ in range(n_layers - 1)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n            )\n        else:\n            # PyTorch\n            network = nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU(),\n                *[\n                    nn.Sequential(\n                        nn.Linear(n_neurons, n_neurons),\n                        nn.ReLU(),\n                    )\n                    for _ in range(n_layers - 2)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n            )\n\n        if activation == \"ReLU\":\n            network.add_module(\"activation\", torch.nn.ReLU())\n        elif activation == \"None\":\n            pass\n        else:\n            raise ValueError(f\"Unknown activation function: {activation}\")\n\n        if output_activation == \"ReLU\":\n            network.add_module(\"output_activation\", torch.nn.ReLU())\n        elif output_activation == \"Sigmoid\":\n            network.add_module(\"output_activation\", torch.nn.Sigmoid())\n        elif output_activation == \"None\":\n            pass\n        else:\n            raise ValueError(f\"Unknown output activation function: {output_activation}\")\n\n        return network"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median by shifting the signal and computing the median of shifted signals\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        rolling_median = np.median(shifted_signals, axis=0)\n\n        # Trim the resulting median array to account for edge effects introduced by the shifting process\n        trimmed_rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return trimmed_rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Shift the signal by the kernel offset in both directions\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signals\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to account for edge effects\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Initialize the output array with the same shape as the input signal\n        output = np.zeros_like(signal)\n\n        # Shift the signal by a range defined by the kernel offset\n        for i in range(-kernel_offset, kernel_offset + 1):\n            shifted_signal = np.roll(signal, i)\n            output += shifted_signal\n\n        # Compute the median of the shifted signals\n        output /= 2 * kernel_offset + 1\n\n        # Trim the output array to account for edge effects introduced by the shifting process\n        output = output[kernel_offset:-kernel_offset]\n\n        return output"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median of the input signal by shifting it by a range defined by the kernel offset.\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Calculate the median of these shifted signals.\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects introduced by the shifting process.\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Shift the signal by the kernel offset in both directions\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signals\n        median = np.median(shifted_signals, axis=0)\n\n        # Trim the median array to remove edge effects\n        trimmed_median = median[kernel_offset:-kernel_offset]\n\n        return trimmed_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Shift the signal by the kernel offset in both directions\n        shifted_signal = np.vstack(\n            [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        )\n\n        # Compute the median of the shifted signals\n        median_signal = np.median(shifted_signal, axis=0)\n\n        # Trim the median signal to remove edge effects\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate shifted versions of the signal array using np.roll\n        shifted_signals = np.array([np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)])\n\n        # Compute the median of the shifted signals along the first axis\n        median = np.median(shifted_signals, axis=0)\n\n        # Trim the median array to remove edge effects\n        return median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate shifted versions of the signal by shifting it by a range defined by the kernel offset\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of these shifted signals\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the resulting median array to account for edge effects introduced by the shifting process\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a shifted version of the signal by shifting it by the kernel offset in both directions\n        shifted_signal_left = np.roll(signal, kernel_offset)\n        shifted_signal_right = np.roll(signal, -kernel_offset)\n\n        # Calculate the median of the shifted signals\n        median_signal = np.median([signal, shifted_signal_left, shifted_signal_right], axis=0)\n\n        # Trim the median signal to remove edge effects introduced by the shifting process\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a shifted version of the signal by shifting it by the kernel offset in both directions\n        shifted_signal = np.concatenate(\n            (signal[kernel_offset:][::-1], signal, signal[:-kernel_offset][::-1])\n        )\n\n        # Compute the rolling median of the shifted signal using the median function from NumPy\n        rolling_median = np.median(\n            np.array(\n                [\n                    shifted_signal[i : i + 2 * kernel_offset + 1]\n                    for i in range(len(signal))\n                ]\n            ),\n            axis=1,\n        )\n\n        # Trim the rolling median to remove edge effects introduced by the shifting process\n        trimmed_rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return trimmed_rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the length of the input signal array\n        length = len(signal)\n\n        # Initialize an empty array to store the rolling median values\n        rolling_median = np.zeros(length)\n\n        # Loop over the range of indices from kernel_offset to length - kernel_offset\n        for i in range(kernel_offset, length - kernel_offset):\n            # Create a shifted version of the signal by shifting it by i elements\n            shifted_signal = np.roll(signal, i)\n\n            # Calculate the median of the shifted signal\n            median = np.median(shifted_signal)\n\n            # Store the median value at the corresponding index in the rolling_median array\n            rolling_median[i] = median\n\n        # Trim the rolling_median array by removing the first and last kernel_offset elements\n        rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate shifted versions of the signal\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signals\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median using the np.median function with a rolling window of size 2*kernel_offset+1\n        rolling_median = np.median(\n            np.column_stack(\n                [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n            ),\n            axis=1,\n        )\n\n        # Trim the rolling median to remove edge effects introduced by the shifting process\n        return rolling_median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Initialize an empty array to store the rolling median values\n        rolling_median = np.empty(signal.shape)\n\n        # Loop over the signal indices and calculate the rolling median\n        for i in range(len(signal)):\n            # Calculate the range of indices to be considered for the rolling median\n            start_index = max(0, i - kernel_offset)\n            end_index = min(len(signal), i + kernel_offset + 1)\n\n            # Extract the relevant portion of the signal for the current index\n            shifted_signal = signal[start_index:end_index]\n\n            # Calculate the median of the shifted signal and store it in the rolling median array\n            rolling_median[i] = np.median(shifted_signal)\n\n        # Trim the rolling median array to remove edge effects introduced by the shifting process\n        trimmed_rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return trimmed_rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Initialize the output array with zeros\n        output = np.zeros(signal.shape)\n\n        # Iterate over the indices of the signal array\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            # Shift the signal by the kernel offset in both directions\n            shifted_left = np.roll(signal, i - kernel_offset)\n            shifted_right = np.roll(signal, -(i - kernel_offset))\n\n            # Compute the median of the shifted signals\n            median = np.median(np.stack([shifted_left, signal, shifted_right]), axis=0)\n\n            # Assign the median to the corresponding position in the output array\n            output[i] = median[i]\n\n        # Trim the output array to remove edge effects introduced by the shifting process\n        return output[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a shifted version of the signal, with the kernel offset applied in both directions\n        shifted_signal = np.concatenate(\n            [np.roll(signal, -i) for i in range(kernel_offset, 0, -1)]\n            + [signal]\n            + [np.roll(signal, i) for i in range(1, kernel_offset + 1)]\n        )\n\n        # Compute the rolling median of the shifted signal, with a window size of 2 * kernel_offset + 1\n        rolling_median = np.median(np.reshape(shifted_signal, (-1, 2 * kernel_offset + 1)), axis=1)\n\n        # Trim the rolling median array to remove edge effects introduced by the shifting process\n        return rolling_median[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Initialize the output array with zeros\n        output = np.zeros(signal.shape)\n\n        # Shift the signal by a range defined by the kernel offset\n        for i in range(-kernel_offset, kernel_offset + 1):\n            # Calculate the shifted signal by shifting the original signal by i\n            shifted_signal = np.roll(signal, i)\n            # Calculate the median of the shifted signal and store it in the output array\n            output += np.median(shifted_signal)\n\n        # Divide the output array by the number of shifted signals (2 * kernel_offset + 1)\n        output /= 2 * kernel_offset + 1\n\n        # Trim the output array to remove edge effects introduced by the shifting process\n        output = output[kernel_offset:-kernel_offset]\n\n        return output"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Shift the signal by a range defined by the kernel offset\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of these shifted signals\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the resulting median array to account for edge effects introduced by the shifting process\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        smoothed = np.zeros_like(signal)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            smoothed[i] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n\n        return smoothed[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate a shifted version of the signal by shifting it by the kernel offset in both directions.\n        shifted_signal_left = np.roll(signal, kernel_offset)\n        shifted_signal_right = np.roll(signal, -kernel_offset)\n\n        # Compute the median of these shifted signals.\n        median_signal = np.median([signal, shifted_signal_left, shifted_signal_right], axis=0)\n\n        # Trim the resulting median array to remove edge effects introduced by the shifting process.\n        return median_signal[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits_probe = template_probe.irisbits\n    irisbits_gallery = template_gallery.irisbits\n    maskbits_probe = template_probe.maskbits\n    maskbits_gallery = template_gallery.maskbits\n\n    half_width = template_probe.half_width\n\n    # Convert rotation shift to columns\n    rotation_shift_cols = rotation_shift * 2\n\n    # Check if weights are provided\n    if weights:\n        # Check if the number of weights tables matches the number of iris codes\n        if len(weights) != len(irisbits_probe):\n            raise MatcherError(\"The number of weights tables does not match the number of iris codes.\")\n\n        # Check if the shape of the weights tables matches the shape of the iris codes\n        for w, x in zip(weights, irisbits_probe):\n            if w.shape != x.shape:\n                raise MatcherError(\"The shape of the weights tables does not match the shape of the iris codes.\")\n\n    # Calculate the total amount of sqrt bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.total_codesize, half_width, weights\n    )\n\n    # Calculate the nonmatch bits for the top and bottom iris codes\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width, weights\n    )\n\n    # Calculate the nonmatch bits for the top and bottom iris codes\n    irisbitcount_top_gallery, maskbitcount_top_gallery, irisbitcount_bot_gallery, maskbitcount_bot_gallery = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width, weights\n    )\n\n    # Calculate the nonmatch bits for the top and bottom iris codes\n    irisbitcount_top_gallery_rot, maskbitcount_top_gallery_rot, irisbitcount_bot_gallery_rot, maskbitcount_bot_gallery_rot = count_nonmatchbits(\n        np.roll(irisbits_gallery, rotation_shift_cols, axis=2),\n        np.roll(maskbits_gallery"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = template_probe.iriscode\n    maskbits = template_gallery.iriscode\n\n    half_width = template_probe.half_width\n\n    if weights is not None and len(weights) != len(irisbits):\n        raise MatcherError(\n            f\"The number of weights tables ({len(weights)}) does not match the number of iriscodes ({len(irisbits)}).\"\n        )\n\n    if len(irisbits) != len(maskbits):\n        raise MatcherError(\n            f\"The number of iriscodes ({len(irisbits)}) does not match the number of maskcodes ({len(maskbits)}).\"\n        )\n\n    if len(irisbits) != len(half_width):\n        raise MatcherError(\n            f\"The number of iriscodes ({len(irisbits)}) does not match the number of half widths ({len(half_width)}).\"\n        )\n\n    if weights is not None:\n        for w, i, m in zip(weights, irisbits, maskbits):\n            if w.shape != i.shape or w.shape != m.shape:\n                raise MatcherError(\n                    f\"The shape of weights table ({w.shape}) does not match the shape of iriscode ({i.shape}) or maskcode ({m.shape}).\"\n                )\n\n    irisbits = np.array([np.roll(i, r, axis=1) for i, r in zip(irisbits, rotation_shift)])\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.total_codesize, half_width, weights\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist is None:\n        nm_dist = sqrt_totalbitcount\n\n    norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n    norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n\n    norm_HD = (norm"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = np.array([probe.irisbit for probe in template_probe.iriscodes])\n    maskbits = np.array([gallery.maskbit for gallery in template_gallery.iriscodes])\n\n    half_width = [probe.half_width for probe in template_probe.iriscodes]\n\n    if weights is None:\n        weights = [np.ones(irisbit.shape) for irisbit in irisbits]\n\n    if rotation_shift > 0:\n        irisbits = np.concatenate([irisbits[:, -rotation_shift:, ...], irisbits[:, :-rotation_shift, ...]], axis=1)\n        maskbits = np.concatenate([maskbits[:, -rotation_shift:, ...], maskbits[:, :-rotation_shift, ...]], axis=1)\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.total_codesize, half_width, weights\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist:\n        norm_HD = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n    else:\n        norm_HD = irisbitcount_top / maskbitcount_top\n        norm_HD_bot = irisbitcount_bot / maskbitcount_bot\n\n    return min(norm_HD, norm_HD_bot), rotation_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Extract iris and mask codes from the probe and gallery templates\n    irisbits_probe = np.array([x.iris_code for x in template_probe.iris_codes])\n    irisbits_gallery = np.array([x.iris_code for x in template_gallery.iris_codes])\n    maskbits_probe = np.array([x.mask_code for x in template_probe.iris_codes])\n    maskbits_gallery = np.array([x.mask_code for x in template_gallery.iris_codes])\n\n    # Calculate the total amount of sqrt bits\n    toal_codesize = irisbits_probe.shape[1]\n    half_width = [x.half_width for x in template_probe.iris_codes]\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate the Hamming distance for each rotation shift\n    min_HD = np.inf\n    min_shift = 0\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        irisbits_gallery_shifted = np.roll(irisbits_gallery, shift, axis=2)\n        maskbits_gallery_shifted = np.roll(maskbits_gallery, shift, axis=2)\n\n        # Calculate nonmatch iriscode bit count and common maskcode bit count\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_probe, maskbits_probe, half_width, weights\n        )\n        irisbitcount_top_gallery, maskbitcount_top_gallery, irisbitcount_bot_gallery, maskbitcount_bot_gallery = count_nonmatchbits(\n            irisbits_gallery_shifted, maskbits_gallery_shifted, half_width, weights\n        )\n\n        # Calculate the Hamming distance\n        HD_top = irisbitcount_top + irisbitcount_top_gallery - 2 * maskbitcount_top\n        HD_bot = irisbitcount_bot + irisbitcount_bot_gallery - 2 *"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    toal_codesize = template_probe.iriscode.shape[1]\n    half_width = [code.shape[2] // 2 for code in template_probe.iriscode]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    min_HD = np.inf\n    min_shift = 0\n\n    for shift in range(rotation_shift + 1):\n        irisbits = [np.roll(code, shift, axis=2) for code in template_probe.iriscode]\n        maskbits = [np.roll(code, shift, axis=2) for code in template_gallery.iriscode]\n\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, maskbits, half_width, weights\n        )\n\n        if nm_dist:\n            norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n            norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n            norm_HD = norm_HD_top + norm_HD_bot\n        else:\n            norm_HD = (irisbitcount_top + irisbitcount_bot) / (maskbitcount_top + maskbitcount_bot)\n\n        if norm_HD < min_HD:\n            min_HD = norm_HD\n            min_shift = shift\n\n    return min_HD, min_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iris_code.shape != template_gallery.iris_code.shape:\n        raise MatcherError(\n            f\"Template probe and gallery do not have the same shape: {template_probe.iris_code.shape} != {template_gallery.iris_code.shape}\"\n        )\n\n    if weights:\n        if len(weights) != len(template_probe.iris_code):\n            raise MatcherError(\n                f\"Number of weights tables does not match number of iris codes: {len(weights)} != {len(template_probe.iris_code)}\"\n            )\n\n    toal_codesize = np.sum([x.shape[1] for x in template_probe.iris_code])\n    half_width = [x.shape[2] for x in template_probe.iris_code]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits = [np.roll(x, rotation_shift, axis=2) for x in template_probe.iris_code]\n    maskbits = [np.roll(x, rotation_shift, axis=2) for x in template_gallery.iris_code]\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist is None:\n        norm_HD = 0\n    else:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n\n    return norm_HD, rotation_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits_probe = np.asarray(template_probe.iris_code)\n    irisbits_gallery = np.asarray(template_gallery.iris_code)\n    maskbits_probe = np.asarray(template_probe.mask_code)\n    maskbits_gallery = np.asarray(template_gallery.mask_code)\n\n    half_width = [int(x / 2) for x in template_probe.code_width]\n\n    if weights is not None:\n        if len(weights) != len(irisbits_probe):\n            raise MatcherError(\n                f\"Length of weights table ({len(weights)}) does not match length of irisbits ({len(irisbits_probe)})\"\n            )\n        if len(weights) != len(irisbits_gallery):\n            raise MatcherError(\n                f\"Length of weights table ({len(weights)}) does not match length of irisbits ({len(irisbits_gallery)})\"\n            )\n\n    if weights is not None and len(weights[0].shape) != 3:\n        raise MatcherError(f\"Weights table must be 3D array, not {len(weights[0].shape)}D\")\n\n    if weights is not None and weights[0].shape != irisbits_probe[0].shape:\n        raise MatcherError(f\"Weights table shape ({weights[0].shape}) does not match irisbits shape ({irisbits_probe[0].shape})\")\n\n    if weights is not None and weights[0].shape != maskbits_probe[0].shape:\n        raise MatcherError(f\"Weights table shape ({weights[0].shape}) does not match maskbits shape ({maskbits_probe[0].shape})\")\n\n    if weights is not None and weights[0].shape != irisbits_gallery[0].shape:\n        raise MatcherError(f\"Weights table shape ({weights[0].shape}) does not match irisbits shape ({irisbits_gallery[0].shape})\")\n\n    if weights is not None and weights[0].shape != maskbits_gallery[0].shape:\n        raise MatcherError(f\"Weights table shape ({weights[0].shape}) does not match maskbits shape ({maskbits_gallery[0].shape})\")\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Calculate the total number of bits in the iris template\n    total_codesize = template_probe.code.shape[1]\n\n    # Calculate the half width of the iris template\n    half_width = [int(total_codesize / 2)] * len(template_probe.code)\n\n    # Calculate the square root of the total number of bits in the iris template\n    sqrt_totalbitcount, _, _ = count_sqrt_totalbits(total_codesize, half_width, weights)\n\n    # Initialize the minimum Hamming distance and the corresponding rotation shift\n    min_HD = np.inf\n    min_rotation_shift = 0\n\n    # Iterate over possible rotation shifts\n    for rotation_shift in range(-rotation_shift, rotation_shift + 1):\n\n        # Shift the iris template by the current rotation shift\n        shifted_template_probe = np.roll(template_probe.code, rotation_shift, axis=1)\n\n        # Calculate the nonmatch bits and common maskbits\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            shifted_template_probe, template_gallery.code, half_width, weights\n        )\n\n        # Calculate the Hamming distance\n        HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount, nm_dist)\n        HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount, nm_dist)\n        HD = max(HD_top, HD_bot)\n\n        # Update the minimum Hamming distance and the corresponding rotation shift if necessary\n        if HD < min_HD:\n            min_HD = HD\n            min_rotation_shift = rotation_shift\n\n    # Return the minimum Hamming distance and the corresponding rotation shift\n    return min_HD, min_rotation_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert the rotation shift to columns for the calculation\n    rotation_shift_col = rotation_shift * template_probe.code_width\n\n    # Get the half width of the iriscodes\n    half_width = [template.code_width // 2 for template in [template_probe, template_gallery]]\n\n    # Get the irisbits and maskbits\n    irisbits = [template.irisbits for template in [template_probe, template_gallery]]\n    maskbits = [template.maskbits for template in [template_probe, template_gallery]]\n\n    # Initialize the minimum Hamming distance and corresponding rotation shift\n    min_hd = np.inf\n    min_rot_shift = -1\n\n    # Iterate over all possible rotation shifts\n    for rot_shift in range(-rotation_shift_col, rotation_shift_col + 1):\n        # Calculate the irisbits and maskbits for the current rotation shift\n        irisbits_rot = [np.roll(x, rot_shift, axis=1) for x in irisbits]\n        maskbits_rot = [np.roll(x, rot_shift, axis=1) for x in maskbits]\n\n        # Calculate the nonmatch iriscode bit count and common maskcode bit count\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_rot, maskbits_rot, half_width, weights\n        )\n\n        # Calculate the total amount of sqrt bits\n        sqrt_totalbitcount, _, _ = count_sqrt_totalbits(\n            template_probe.code_width * template_probe.code_height, half_width, weights\n        )\n\n        # Calculate the Hamming distance for the current rotation shift\n        hd_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount, nm_dist)\n        hd_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount, nm_dist)\n        hd = hd_top + hd_bot\n\n        # Update the minimum Hamming distance and corresponding rotation shift if the current Hamming distance is smaller\n        if hd < min_hd:\n            min_hd = hd\n            min_rot_shift = rot"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits_probe = template_probe.irisbits\n    irisbits_gallery = template_gallery.irisbits\n    maskbits_probe = template_probe.maskbits\n    maskbits_gallery = template_gallery.maskbits\n\n    half_width = [int(x / 2) for x in template_probe.width]\n\n    # Calculate the total amount of sqrt bits for normalization\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.total_codesize, half_width, weights\n    )\n\n    # Initialize the minimum Hamming distance and the corresponding rotation shift\n    min_HD = np.inf\n    min_shift = 0\n\n    # Loop through the allowed rotation shifts\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        # Calculate the irisbits and maskbits for the current rotation shift\n        irisbits = [np.roll(x, shift, axis=2) for x in irisbits_probe]\n        maskbits = [np.roll(x, shift, axis=2) for x in maskbits_probe]\n\n        # Calculate the nonmatch iriscode bit count and common maskcode bit count\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, maskbits, half_width, weights\n        )\n\n        # Calculate the Hamming distance for the current rotation shift\n        HD = irisbitcount_top + irisbitcount_bot\n\n        # If the nonmatch distance is provided, calculate the normalized Hamming distance\n        if nm_dist:\n            norm_HD = normalized_HD(\n                irisbitcount_top,\n                maskbitcount_top,\n                sqrt_totalbitcount_top,\n                nm_dist,\n            )\n            norm_HD += normalized_HD(\n                irisbitcount_bot,\n                maskbitcount_bot,\n                sqrt_totalbitcount_bot,\n                nm_dist,\n            )\n            HD = norm_HD\n\n        # Update the minimum Hamming distance and the corresponding rotation shift if the current HD is smaller\n        if HD < min_HD:\n            min_HD = HD\n            min_shift = shift\n\n    return min_HD"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = template_probe.iris_code\n    maskbits = template_gallery.iris_code\n    half_width = template_probe.half_width\n    toal_codesize = template_probe.total_code_size\n\n    if weights is not None:\n        if len(weights) != len(irisbits):\n            raise MatcherError(\"weights length and irisbits length are not the same\")\n\n    if nm_dist is not None:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            toal_codesize,\n            half_width,\n            weights,\n        )\n\n    if rotation_shift != 0:\n        irisbits = [np.roll(x, rotation_shift, axis=2) for x in irisbits]\n        maskbits = [np.roll(x, rotation_shift, axis=2) for x in maskbits]\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits,\n        maskbits,\n        half_width,\n        weights,\n    )\n\n    if nm_dist is not None:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n    else:\n        norm_HD = None\n\n    return norm_HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    irisbits = template_probe.irisbits\n    maskbits = template_probe.maskbits\n    half_width = template_probe.half_width\n\n    irisbits_gallery = template_gallery.irisbits\n    maskbits_gallery = template_gallery.maskbits\n    half_width_gallery = template_gallery.half_width\n\n    if len(irisbits) != len(irisbits_gallery) or len(maskbits) != len(maskbits_gallery):\n        raise MatcherError(\n            f\"IrisTemplate lengths are different: probe={len(irisbits)}, gallery={len(irisbits_gallery)}\"\n        )\n\n    if len(half_width) != len(half_width_gallery):\n        raise MatcherError(f\"half_width lengths are different: probe={len(half_width)}, gallery={len(half_width_gallery)}\")\n\n    if weights:\n        if len(weights) != len(irisbits):\n            raise MatcherError(\n                f\"weights length is different than irisbits length: weights={len(weights)}, irisbits={len(irisbits)}\"\n            )\n\n    if weights and len(weights) != len(irisbits_gallery):\n        raise MatcherError(\n            f\"weights length is different than irisbits_gallery length: weights={len(weights)}, irisbits_gallery={len(irisbits_gallery)}\"\n        )\n\n    toal_codesize = len(irisbits) * irisbits[0].shape[1] * irisbits[0].shape[2]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    min_dist = np.inf\n    min_rot = 0\n\n    for rot in range(-rotation_shift, rotation_shift + 1):\n\n        irisbits_rot = [np.roll(x, rot, axis=1) for x in irisbits]\n        maskbits_rot = [np.roll(x, rot, axis=1) for x in maskbits]\n\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_rot, maskbits_rot, half"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    toal_codesize = template_probe.codesize\n    half_width = template_probe.half_width\n\n    # Calculate the square root of bit counts for the whole iris, top iris and bottom iris\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Convert rotation shift to columns\n    rotation_shift_columns = rotation_shift * 2\n\n    # Initialize variables for minimum Hamming distance and corresponding rotation shift\n    min_HD = np.inf\n    min_rotation_shift = 0\n\n    # Loop over possible rotation shifts\n    for i in range(rotation_shift_columns + 1):\n        # Calculate the rotation shift in columns\n        rotation_shift_columns = i\n\n        # Extract the irisbits and maskbits for the probe and gallery templates\n        irisbits = template_probe.irisbits\n        maskbits = template_probe.maskbits\n        irisbits_gallery = template_gallery.irisbits\n        maskbits_gallery = template_gallery.maskbits\n\n        # Rotate the irisbits and maskbits of the probe template\n        irisbits = np.roll(irisbits, -rotation_shift_columns, axis=2)\n        maskbits = np.roll(maskbits, -rotation_shift_columns, axis=2)\n\n        # Calculate the nonmatch iriscode bit count and common maskcode bit count from top iris and bottom iris\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, maskbits, half_width, weights\n        )\n\n        # Calculate the normalized Hamming distance for top iris\n        norm_HD_top = normalized_HD(\n            irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist\n        ) if maskbitcount_top > 0 else 0\n\n        # Calculate the normalized Hamming distance for bottom iris\n        norm_HD_bot = normalized_HD(\n            irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist\n        ) if maskbitcount_bot > 0 else "}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift_cols = rotation_shift * template_probe.code_width // 360\n\n    # Get the number of codes in the probe and gallery templates\n    num_codes = len(template_probe.iris_codes)\n\n    # Initialize the minimum Hamming distance and corresponding rotation shift\n    min_HD = np.inf\n    min_rot_shift = 0\n\n    # Loop over the possible rotation shifts\n    for rot_shift in range(-rotation_shift_cols, rotation_shift_cols + 1):\n\n        # Initialize the Hamming distance for the current rotation shift\n        HD = 0\n\n        # Loop over the iris codes in the probe and gallery templates\n        for i in range(num_codes):\n\n            # Get the iris codes and half widths for the current iris code\n            iris_code_probe = template_probe.iris_codes[i]\n            iris_code_gallery = template_gallery.iris_codes[i]\n            half_width = template_probe.half_width[i]\n\n            # Get the weights table for the current iris code\n            if weights:\n                weight = weights[i]\n            else:\n                weight = None\n\n            # Calculate the Hamming distance for the current iris code and rotation shift\n            HD += hamming_distance_single_code(\n                iris_code_probe,\n                iris_code_gallery,\n                rot_shift,\n                half_width,\n                nm_dist,\n                weight,\n            )\n\n        # Check if the current Hamming distance is the minimum\n        if HD < min_HD:\n            min_HD = HD\n            min_rot_shift = rot_shift\n\n    # Return the minimum Hamming distance and corresponding rotation shift\n    return min_HD, min_rot_shift\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert the rotation shift to columns\n    rotation_shift_columns = rotation_shift * template_probe.width\n\n    # Initialize the minimum Hamming distance and corresponding rotation shift\n    min_HD = np.inf\n    min_rot = 0\n\n    # Loop through all possible rotation shifts\n    for rot in range(rotation_shift_columns + 1):\n        # Calculate the Hamming distance for the current rotation shift\n        HD = np.sum(\n            [\n                np.sum(\n                    np.roll(template_probe.iris_code[i], rot, axis=1)\n                    & template_gallery.iris_code[i]\n                    & template_probe.mask_code[i]\n                )\n                for i in range(len(template_probe.iris_code))\n            ]\n        )\n        # Update the minimum Hamming distance and corresponding rotation shift if the current Hamming distance is smaller\n        if HD < min_HD:\n            min_HD = HD\n            min_rot = rot\n\n    # Calculate the normalized Hamming distance if the nonmatch distance is provided\n    if nm_dist:\n        # Calculate the total amount of sqrt bits\n        sqrt_totalbitcount, _, _ = count_sqrt_totalbits(\n            template_probe.total_codesize,\n            template_probe.half_width,\n            weights,\n        )\n        # Calculate the nonmatch iriscode bit count and common maskcode bit count\n        irisbitcount, maskbitcount, _, _ = count_nonmatchbits(\n            template_probe.iris_code,\n            template_probe.mask_code,\n            template_probe.half_width,\n            weights,\n        )\n        # Calculate the normalized Hamming distance\n        norm_HD = normalized_HD(irisbitcount, maskbitcount, sqrt_totalbitcount, nm_dist)\n    else:\n        norm_HD = 0\n\n    return min_HD, min_rot, norm_HD\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the iriscodes are the same size\n    if template_probe.iriscode.shape != template_gallery.iriscode.shape:\n        raise MatcherError(\n            f\"The iriscodes of the probe and gallery templates must be the same size. Probe: {template_probe.iriscode.shape}, Gallery: {template_gallery.iriscode.shape}\"\n        )\n\n    # Calculate the total number of bits in the iriscode\n    total_bitcount = np.prod(template_probe.iriscode.shape)\n\n    # Calculate the square root of the total number of bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_bitcount, template_probe.half_width, weights\n    )\n\n    # Initialize the minimum Hamming distance and corresponding rotation shift\n    min_hd = np.inf\n    min_rotation_shift = 0\n\n    # Loop over all possible rotation shifts\n    for i in range(-rotation_shift, rotation_shift + 1):\n\n        # Calculate the rotated iriscode\n        rotated_iriscode = np.roll(template_probe.iriscode, i, axis=1)\n\n        # Calculate the nonmatch bits and common mask bits\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            rotated_iriscode,\n            template_gallery.iriscode,\n            template_probe.half_width,\n            weights,\n        )\n\n        # Calculate the Hamming distance\n        hd_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        hd_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        hd = hd_top + hd_bot\n\n        # Update the minimum Hamming distance and corresponding rotation shift if necessary\n        if hd < min_hd:\n            min_hd = hd\n            min_rotation_shift = i\n\n    return min_hd, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get the iriscodes from the probe and gallery templates\n    iriscodes_probe = template_probe.iriscodes\n    iriscodes_gallery = template_gallery.iriscodes\n\n    # Get the half width of the iriscodes\n    half_width = template_probe.half_width\n\n    # Get the total amount of bits in the iriscodes\n    total_codesize = template_probe.total_codesize\n\n    # Get the amount of bits in the iriscodes\n    irisbitcount = total_codesize\n\n    # Initialize the minimum Hamming distance and the corresponding rotation shift\n    min_hamming_distance = np.inf\n    min_rotation_shift = 0\n\n    # Iterate over the possible rotation shifts\n    for shift in range(-rotation_shift, rotation_shift + 1):\n\n        # Shift the iriscodes in the probe template\n        iriscodes_probe_shifted = [np.roll(iriscode, shift, axis=1) for iriscode in iriscodes_probe]\n\n        # Calculate the Hamming distance between the shifted probe iriscodes and the gallery iriscodes\n        hamming_distance = np.sum(\n            [\n                np.sum(np.logical_xor(iriscode_probe_shifted, iriscode_gallery))\n                for iriscode_probe_shifted, iriscode_gallery in zip(iriscodes_probe_shifted, iriscodes_gallery)\n            ]\n        )\n\n        # If the Hamming distance is less than the minimum, update the minimum distance and rotation shift\n        if hamming_distance < min_hamming_distance:\n            min_hamming_distance = hamming_distance\n            min_rotation_shift = shift\n\n    # If a nonmatch distance is provided, calculate the normalized Hamming distance\n    if nm_dist:\n        # Calculate the total amount of bits in the iriscodes\n        irisbitcount = total_codesize\n\n        # Calculate the total amount of bits in the iriscodes\n        maskbitcount = total_codesize\n\n        # Calculate the square root of the total amount of bits in the iriscodes\n        sqrt_totalbitcount = np.sqrt(total_codesize * 3 / 4)\n\n        # Calculate the normalized Hamming distance\n        norm_HD = normalized_HD(irisbitcount, mask"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Extract iriscodes from template\n    irisbits_probe = template_probe.irisbits\n    irisbits_gallery = template_gallery.irisbits\n\n    # Extract maskcodes from template\n    maskbits_probe = template_probe.maskbits\n    maskbits_gallery = template_gallery.maskbits\n\n    # Extract half width from template\n    half_width = template_probe.half_width\n\n    # Convert rotation shift to columns\n    rotation_shift_columns = rotation_shift * 2\n\n    # Check if weights are provided\n    if weights:\n        # Check if weights are the same length as irisbits\n        if len(weights) != len(irisbits_probe):\n            raise MatcherError(\"Length of weights is not the same as the length of irisbits.\")\n\n        # Check if weights are the same shape as irisbits\n        if not all(w.shape == i.shape for w, i in zip(weights, irisbits_probe)):\n            raise MatcherError(\"Shape of weights is not the same as the shape of irisbits.\")\n\n    # Initialize minimum distance and rotation shift\n    min_dist = np.inf\n    min_rotation_shift = 0\n\n    # Iterate over rotation shifts\n    for i in range(rotation_shift_columns + 1):\n        # Calculate distance for current rotation shift\n        dist = np.sum(\n            [\n                np.sum(np.bitwise_xor(x[:, i:, ...], y[:, i:, ...]) & z[:, i:, ...])\n                for x, y, z in zip(irisbits_probe, irisbits_gallery, maskbits_probe & maskbits_gallery)\n            ]\n        )\n\n        # Check if distance is less than minimum distance\n        if dist < min_dist:\n            # Update minimum distance and rotation shift\n            min_dist = dist\n            min_rotation_shift = i\n\n    # Check if weights are provided\n    if weights:\n        # Calculate normalized Hamming distance\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.total_codesize, half_width, weights\n        )\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_probe, maskbits"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the iris codes have the same dimensions\n    if template_probe.iris_code.shape != template_gallery.iris_code.shape:\n        raise MatcherError(\"Iris codes have different dimensions.\")\n\n    # Check if the rotation shift is within the allowed range\n    if not 0 <= rotation_shift <= 180:\n        raise MatcherError(\"Rotation shift is out of range.\")\n\n    # Convert the rotation shift to the number of columns\n    rotation_shift_columns = int(template_probe.iris_code.shape[1] * rotation_shift / 180)\n\n    # Calculate the square root of the total bit count for normalization\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.iris_code.shape[1],\n        template_probe.half_width,\n        weights,\n    )\n\n    # Initialize the minimum Hamming distance and corresponding rotation shift\n    min_hd = np.inf\n    min_rot_shift = 0\n\n    # Iterate over the rotation shift in the allowed range\n    for rot_shift in range(rotation_shift_columns + 1):\n        # Rotate the iris codes by the rotation shift\n        probe_code = np.roll(template_probe.iris_code, rot_shift, axis=1)\n        gallery_code = np.roll(template_gallery.iris_code, rot_shift, axis=1)\n\n        # Calculate the Hamming distance between the rotated iris codes\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            probe_code,\n            gallery_code,\n            template_probe.half_width,\n            weights,\n        )\n\n        # Calculate the normalized Hamming distance\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = norm_HD_top + norm_HD_bot\n\n        # Update the minimum Hamming distance and corresponding rotation shift if necessary\n        if norm"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.template_codes.shape != template_gallery.template_codes.shape:\n        raise MatcherError(\"The template codes of the probe and gallery do not have the same shape.\")\n\n    if template_probe.template_codes.shape[0] != len(template_probe.half_width):\n        raise MatcherError(\"The number of half widths does not match the number of template codes.\")\n\n    if template_gallery.template_codes.shape[0] != len(template_gallery.half_width):\n        raise MatcherError(\"The number of half widths does not match the number of template codes.\")\n\n    if rotation_shift < 0:\n        raise MatcherError(\"The rotation shift cannot be negative.\")\n\n    if rotation_shift > min(template_probe.half_width):\n        raise MatcherError(\"The rotation shift cannot be greater than the minimum half width.\")\n\n    if weights and len(weights) != template_probe.template_codes.shape[0]:\n        raise MatcherError(\"The number of weights tables does not match the number of template codes.\")\n\n    if weights and len(weights) != template_gallery.template_codes.shape[0]:\n        raise MatcherError(\"The number of weights tables does not match the number of template codes.\")\n\n    if weights:\n        for w in weights:\n            if w.shape != template_probe.template_codes.shape[1:]:\n                raise MatcherError(\"The shape of the weights table does not match the shape of the template codes.\")\n\n    # Calculate the square root of the total number of bits for normalization\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.template_codes.shape[1], template_probe.half_width, weights\n    )\n\n    # Initialize the minimum Hamming distance and the corresponding rotation shift\n    min_HD = np.inf\n    min_rot = 0\n\n    # Loop over all possible rotation shifts\n    for rot in range(0, rotation_shift + 1):\n\n        # Calculate the irisbits and maskbits for the probe and gallery templates\n        irisbits_probe = np.array(\n            [\n                np.roll(template_probe.template_codes[i, :, :], rot, axis=1)\n                for i in range(template_probe.template_"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            # Randomly select two points from the polygon\n            point1, point2 = self._select_random_points(polygon, min_distance_between_sector_points_in_px)\n\n            # Calculate the midpoint between the two points\n            midpoint = (point1 + point2) / 2\n\n            # Calculate the vector between the two points\n            vector = point2 - point1\n\n            # Calculate the perpendicular vector\n            perpendicular_vector = np.array([-vector[1], vector[0]])\n\n            # Calculate the bisector points\n            first_bisectors_point[i] = midpoint + perpendicular_vector / 2\n            second_bisectors_point[i] = midpoint - perpendicular_vector / 2\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            iterations = 0\n            while True:\n                iterations += 1\n                if iterations > self.params.max_iterations:\n                    raise EyeCentersEstimationError(\n                        f\"Failed to find a pair of points with a minimum distance of {min_distance_between_sector_points_in_px} within {self.params.max_iterations} iterations.\"\n                    )\n\n                first_point_index = np.random.randint(0, len(polygon))\n                second_point_index = np.random.randint(0, len(polygon))\n\n                if second_point_index == first_point_index:\n                    continue\n\n                first_point = polygon[first_point_index]\n                second_point = polygon[second_point_index]\n\n                distance = np.linalg.norm(first_point - second_point)\n\n                if distance >= min_distance_between_sector_points_in_px:\n                    break\n\n            first_bisectors_point[i] = first_point\n            second_bisectors_point[i] = second_point\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            # Randomly select two points from the polygon\n            first_point_index = np.random.randint(0, len(polygon))\n            second_point_index = np.random.randint(0, len(polygon))\n\n            # Check if the distance between the two points is greater than the minimum distance\n            distance = np.linalg.norm(polygon[first_point_index] - polygon[second_point_index])\n            if distance < min_distance_between_sector_points_in_px:\n                continue\n\n            # Calculate the perpendicular bisector\n            midpoint = (polygon[first_point_index] + polygon[second_point_index]) / 2\n            direction = polygon[second_point_index] - polygon[first_point_index]\n            perpendicular_direction = np.array([-direction[1], direction[0]])\n\n            # Add the starting and ending points of the perpendicular bisector to the arrays\n            first_bisectors_point[i] = midpoint + perpendicular_direction / 2\n            second_bisectors_point[i] = midpoint - perpendicular_direction / 2\n\n        # Check if the required number of bisectors were found\n        if np.count_nonzero(first_bisectors_point) < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed. This indicates that it may not be possible to accurately estimate the center of the shape.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(max_iterations):\n            random_points_indices = np.random.choice(len(polygon), size=2 * num_bisectors, replace=False)\n            random_points = polygon[random_points_indices]\n            random_points_1 = random_points[::2]\n            random_points_2 = random_points[1::2]\n            distances = np.linalg.norm(random_points_1 - random_points_2, axis=1)\n            valid_indices = np.where(distances > min_distance_between_sector_points_in_px)[0]\n            if len(valid_indices) >= num_bisectors:\n                first_bisectors_point = random_points_1[valid_indices[:num_bisectors]]\n                second_bisectors_point = random_points_2[valid_indices[:num_bisectors]]\n                break\n\n        if len(first_bisectors_point) < num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {num_bisectors} valid bisectors in {max_iterations} iterations. \"\n                \"Try increasing the number of bisectors or decreasing the minimum distance between points.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.max_iterations):\n            random_points = np.random.randint(0, len(polygon), size=(self.params.num_bisectors, 2))\n            first_bisectors_point = polygon[random_points[:, 0]]\n            second_bisectors_point = polygon[random_points[:, 1]]\n\n            distances = np.linalg.norm(first_bisectors_point - second_bisectors_point, axis=1)\n            if np.all(distances >= min_distance_between_sector_points_in_px):\n                break\n\n        if i == self.params.max_iterations - 1:\n            raise EyeCentersEstimationError(\n                f\"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed. This indicates that it may not be possible to accurately estimate the center of the shape.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Get the number of points in the polygon\n        num_points = polygon.shape[0]\n\n        # Initialize the arrays to store the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize a counter to keep track of the number of bisectors calculated\n        num_bisectors_calculated = 0\n\n        # Initialize a counter to keep track of the number of iterations\n        iteration_count = 0\n\n        # Continue the loop until the desired number of bisectors is calculated or the maximum number of iterations is reached\n        while num_bisectors_calculated < self.params.num_bisectors and iteration_count < self.params.max_iterations:\n            # Choose two random points from the polygon's vertices\n            random_point_1 = polygon[np.random.randint(0, num_points)]\n            random_point_2 = polygon[np.random.randint(0, num_points)]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(random_point_1 - random_point_2)\n\n            # If the distance between the two points is greater than the minimum distance, calculate the perpendicular bisector\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint of the two points\n                midpoint = (random_point_1 + random_point_2) / 2\n\n                # Calculate the slope of the line connecting the two points\n                slope = (random_point_2[1] - random_point_1[1]) / (random_point_2[0] - random_point_1[0])\n\n                # Calculate the slope of the perpendicular bisector\n                perpendicular_slope = -1 / slope\n\n                # Calculate the y-intercept of the perpendicular bisector\n                y_intercept = midpoint[1] - perpendicular_slope * midpoint[0]\n\n                # Calculate the starting and ending points of the perpendicular bisector\n                first_bisectors_point[num_bisectors_calculated] = np.array"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize arrays for the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Iterate over the maximum number of iterations\n        for i in range(self.params.max_iterations):\n            # Randomly select two points from the polygon's vertices\n            point_1 = polygon[np.random.randint(0, polygon.shape[0])]\n            point_2 = polygon[np.random.randint(0, polygon.shape[0])]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(point_1 - point_2)\n\n            # Check if the distance is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint of the two points\n                midpoint = (point_1 + point_2) / 2\n\n                # Calculate the perpendicular bisector by rotating the vector from point_1 to point_2 by 90 degrees\n                perpendicular_vector = np.array([point_2[1] - point_1[1], point_1[0] - point_2[0]])\n                perpendicular_vector /= np.linalg.norm(perpendicular_vector)\n\n                # Calculate the starting and ending points of the perpendicular bisector\n                first_bisectors_point[i] = midpoint + perpendicular_vector * distance / 2\n                second_bisectors_point[i] = midpoint - perpendicular_vector * distance / 2\n\n                # Break the loop if the required number of bisectors have been found\n                if i == self.params.num_bisectors - 1:\n                    break\n\n        # Check if the required number of bisectors have been found\n        if i != self.params.num_bisectors - 1:\n            raise EyeCentersEstimationError(\"Failed to find a sufficient number of bisectors within the maximum number of iterations.\")\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the starting and ending points of the perpendicular bisectors.\n        first_bisectors_point = np.empty((0, 2), dtype=float)\n        second_bisectors_point = np.empty((0, 2), dtype=float)\n\n        # Initialize the number of iterations to zero.\n        iteration = 0\n\n        # Loop until the number of bisectors reaches the desired number or the maximum number of iterations is reached.\n        while len(first_bisectors_point) < self.params.num_bisectors and iteration < self.params.max_iterations:\n            # Select two random points from the polygon.\n            point_1, point_2 = np.random.choice(polygon, 2, replace=False)\n\n            # Calculate the distance between the two points.\n            distance = np.linalg.norm(point_1 - point_2)\n\n            # Check if the distance between the two points is greater than the minimum distance.\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint between the two points.\n                midpoint = (point_1 + point_2) / 2\n\n                # Calculate the perpendicular bisector by rotating the vector from point_1 to point_2 by 90 degrees.\n                perpendicular_bisector = np.array([point_2[1] - point_1[1], point_1[0] - point_2[0]])\n\n                # Calculate the starting and ending points of the perpendicular bisector.\n                first_bisector_point = midpoint + perpendicular_bisector / 2\n                second_bisector_point = midpoint - perpendicular_bisector / 2\n\n                # Append the starting and ending points of the perpendicular bisector to the arrays.\n                first_bisectors_point = np.append(first_bisectors_point, [first_bisector_point], axis=0)\n                second_bisectors_point = np.append(second_bisectors_point, [second_bisector_point], axis=0)\n\n            # Increment the number of iterations.\n            iteration += 1\n\n        # Check if the number of bisectors is less than the desired"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Iterate over the number of bisectors to be calculated\n        for i in range(num_bisectors):\n            # Initialize the number of iterations to zero\n            num_iterations = 0\n\n            # Repeat until a pair of points is found that meets the distance criterion\n            while num_iterations < max_iterations:\n                # Choose two random points from the polygon's vertices\n                random_index_1 = np.random.randint(0, len(polygon))\n                random_index_2 = np.random.randint(0, len(polygon))\n\n                # Calculate the distance between the two points\n                distance = np.linalg.norm(polygon[random_index_1] - polygon[random_index_2])\n\n                # Check if the distance is greater than the minimum distance\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint of the line segment connecting the two points\n                    midpoint = (polygon[random_index_1] + polygon[random_index_2]) / 2.0\n\n                    # Calculate the vector perpendicular to the line segment connecting the two points\n                    perpendicular_vector = np.array([polygon[random_index_2][1] - polygon[random_index_1][1],\n                                                     polygon[random_index_1][0] - polygon[random_index_2][0]])\n\n                    # Calculate the starting and ending points of the perpendicular bisector\n                    first_bisectors_point[i] = midpoint + perpendicular_vector / 2.0\n                    second_bisectors_point[i] = midpoint - perpendicular_vector / 2.0\n\n                    # Break out of the loop since a pair of points has been found that meets the distance criterion\n                    break\n\n                # Increment the number of iterations\n                num_iterations += 1\n\n            # Check if the maximum number of iterations was reached\n            if num_iterations == max_iterations:\n                # Raise an exception if the maximum number of iterations was"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            # Check if the current iteration has reached the maximum number of iterations\n            if i >= self.params.max_iterations:\n                raise EyeCentersEstimationError(\n                    f\"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n            # Randomly select two points from the polygon\n            point1 = polygon[np.random.randint(0, polygon.shape[0])]\n            point2 = polygon[np.random.randint(0, polygon.shape[0])]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(point1 - point2)\n\n            # Check if the distance is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint of the line segment\n                midpoint = (point1 + point2) / 2\n\n                # Calculate the slope of the line segment\n                slope = (point2[1] - point1[1]) / (point2[0] - point1[0])\n\n                # Calculate the slope of the perpendicular bisector\n                perpendicular_slope = -1 / slope\n\n                # Calculate the intercept of the perpendicular bisector\n                perpendicular_intercept = midpoint[1] - perpendicular_slope * midpoint[0]\n\n                # Calculate the coordinates of the first point on the perpendicular bisector\n                first_bisectors_point[i] = (0, perpendicular_intercept)\n\n                # Calculate the coordinates of the second point on the perpendicular bisector\n                second_bisectors_point[i] = (1, perpendicular_intercept + perpendicular_slope)\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        num_vertices = polygon.shape[0]\n        num_points_found = 0\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Loop through the maximum number of iterations\n        for _ in range(max_iterations):\n            # Randomly select two points from the polygon's vertices\n            first_point_idx = np.random.randint(num_vertices)\n            second_point_idx = np.random.randint(num_vertices)\n\n            # Check if the two points are not the same\n            if first_point_idx == second_point_idx:\n                continue\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(polygon[first_point_idx] - polygon[second_point_idx])\n\n            # Check if the distance is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint between the two points\n                midpoint = (polygon[first_point_idx] + polygon[second_point_idx]) / 2\n\n                # Calculate the perpendicular bisector by rotating the line by 90 degrees\n                perpendicular_bisector = np.array(\n                    [\n                        -1 * (polygon[second_point_idx][1] - polygon[first_point_idx][1]),\n                        polygon[second_point_idx][0] - polygon[first_point_idx][0],\n                    ]\n                )\n\n                # Normalize the perpendicular bisector\n                perpendicular_bisector /= np.linalg.norm(perpendicular_bisector)\n\n                # Add the perpendicular bisector to the first and second bisectors arrays\n                first_bisectors_point[num_points_found] = midpoint + perpendicular_bisector\n                second_bisectors_point[num_points_found] = midpoint - perpendicular_bisector\n\n                # Increment the number of points found\n                num_points_found += 1\n\n                # Check if"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_points = polygon.shape[0]\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for j in range(self.params.max_iterations):\n                random_point_1 = polygon[np.random.randint(0, num_points)]\n                random_point_2 = polygon[np.random.randint(0, num_points)]\n\n                if np.linalg.norm(random_point_1 - random_point_2) > min_distance_between_sector_points_in_px:\n                    break\n\n            if j == self.params.max_iterations - 1:\n                raise EyeCentersEstimationError(\n                    \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n            bisector_point = (random_point_1 + random_point_2) / 2.0\n            bisector_direction = random_point_1 - random_point_2\n\n            # Find the perpendicular bisector direction\n            perpendicular_direction = np.array([-bisector_direction[1], bisector_direction[0]])\n\n            # Find the first and second points of the perpendicular bisector\n            first_bisectors_point[i] = bisector_point + perpendicular_direction\n            second_bisectors_point[i] = bisector_point - perpendicular_direction\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            iterations = 0\n            while True:\n                iterations += 1\n                if iterations > self.params.max_iterations:\n                    raise EyeCentersEstimationError(\n                        f\"Could not find a pair of points with a distance greater than {min_distance_between_sector_points_in_px} in {self.params.max_iterations} iterations.\"\n                    )\n\n                point_1, point_2 = np.random.choice(polygon, size=2, replace=False)\n                distance = np.linalg.norm(point_1 - point_2)\n\n                if distance >= min_distance_between_sector_points_in_px:\n                    break\n\n            first_bisectors_point[i] = point_1\n            second_bisectors_point[i] = point_2\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        bisectors_point_1 = np.zeros((self.params.num_bisectors, 2))\n        bisectors_point_2 = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.max_iterations):\n            # randomly choose two points from the polygon\n            point_1 = polygon[np.random.randint(0, len(polygon))]\n            point_2 = polygon[np.random.randint(0, len(polygon))]\n\n            # calculate the distance between the two points\n            distance = np.linalg.norm(point_1 - point_2)\n\n            # check if the distance is greater than the minimum distance\n            if distance >= min_distance_between_sector_points_in_px:\n                # calculate the midpoint between the two points\n                midpoint = (point_1 + point_2) / 2\n\n                # calculate the perpendicular bisector of the line segment connecting the two points\n                perpendicular_bisector = np.array([point_2[1] - point_1[1], point_1[0] - point_2[0]])\n\n                # find the intersection of the perpendicular bisector with the polygon\n                intersection_point = self._find_intersection(polygon, midpoint, perpendicular_bisector)\n\n                # check if an intersection point was found\n                if intersection_point is not None:\n                    # add the intersection point to the list of bisectors\n                    bisectors_point_1[i] = point_1\n                    bisectors_point_2[i] = intersection_point\n                    break\n\n        # check if the maximum number of iterations was reached without finding a sufficient number of bisectors\n        if i == self.params.max_iterations - 1:\n            raise EyeCentersEstimationError(\n                f\"Failed to find a sufficient number of bisectors within the maximum number of iterations. \"\n                f\"Try increasing the number of bisectors or decreasing the minimum distance between points.\"\n            )\n\n        return bisectors_point_1, bisectors_point_2\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        num_points = polygon.shape[0]\n\n        for i in range(self.params.num_bisectors):\n            for j in range(self.params.max_iterations):\n                random_points = np.random.choice(num_points, 2, replace=False)\n                point_1, point_2 = polygon[random_points, :]\n\n                # Calculate the distance between the two points\n                distance = np.linalg.norm(point_1 - point_2)\n\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint of the line segment\n                    midpoint = (point_1 + point_2) / 2\n\n                    # Calculate the perpendicular bisector\n                    direction = point_2 - point_1\n                    perpendicular_direction = np.array([-direction[1], direction[0]])\n\n                    # Calculate the starting and ending points of the perpendicular bisector\n                    first_bisectors_point[i] = midpoint + perpendicular_direction / 2\n                    second_bisectors_point[i] = midpoint - perpendicular_direction / 2\n\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    f\"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed ({self.params.max_iterations}).\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Check if polygon is empty\n        if polygon.size == 0:\n            raise EyeCentersEstimationError(\"Polygon is empty\")\n\n        # Check if polygon is a single point\n        if polygon.size == 2:\n            raise EyeCentersEstimationError(\"Polygon is a single point\")\n\n        # Initialize arrays to store the points of the perpendicular bisectors\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize a counter to keep track of the number of iterations\n        iteration_count = 0\n\n        # Loop until the required number of bisectors is found or the maximum number of iterations is reached\n        while iteration_count < self.params.max_iterations:\n            # Choose two random points from the polygon\n            point_1_index = np.random.randint(0, polygon.shape[0])\n            point_2_index = np.random.randint(0, polygon.shape[0])\n\n            # Check if the two points are the same\n            if point_1_index == point_2_index:\n                continue\n\n            # Get the coordinates of the two points\n            point_1 = polygon[point_1_index]\n            point_2 = polygon[point_2_index]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(point_1 - point_2)\n\n            # Check if the distance between the two points is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint between the two points\n                midpoint = (point_1 + point_2) / 2\n\n                # Calculate the perpendicular bisector of the line segment between the two points\n                direction = point_2 - point_1\n                direction_perpendicular = np.array([direction[1], -direction[0]])\n                direction_perpendicular_unit = direction_perpendicular / np.linalg.norm(direction_perpendicular)\n\n                # Add the midpoint and the perpendicular bisector to the arrays\n                first_bisectors_point[iteration_count] = midpoint\n                second_bisectors_point["}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            # Select two random points from the polygon\n            point_1_idx = np.random.randint(0, len(polygon))\n            point_2_idx = np.random.randint(0, len(polygon))\n\n            # Check if the distance between the points is greater than the minimum distance\n            point_1 = polygon[point_1_idx]\n            point_2 = polygon[point_2_idx]\n            distance = np.linalg.norm(point_1 - point_2)\n\n            # If the distance is not greater than the minimum distance, continue to the next iteration\n            if distance <= min_distance_between_sector_points_in_px:\n                continue\n\n            # Calculate the perpendicular bisector of the two points\n            midpoint = (point_1 + point_2) / 2\n            direction = np.array([point_2[1] - point_1[1], point_1[0] - point_2[0]])\n            direction /= np.linalg.norm(direction)\n\n            # Store the start and end points of the perpendicular bisector\n            first_bisectors_point[i] = midpoint + direction * min_distance_between_sector_points_in_px / 2\n            second_bisectors_point[i] = midpoint - direction * min_distance_between_sector_points_in_px / 2\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            # Select two random points from the polygon\n            random_point_index_1 = np.random.randint(0, len(polygon))\n            random_point_index_2 = np.random.randint(0, len(polygon))\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(polygon[random_point_index_1] - polygon[random_point_index_2])\n\n            # Check if the distance is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint between the two points\n                midpoint = (polygon[random_point_index_1] + polygon[random_point_index_2]) / 2\n\n                # Calculate the perpendicular bisector by rotating the midpoint by 90 degrees\n                perpendicular_bisector = np.array(\n                    [midpoint[1] - (polygon[random_point_index_1][1] - polygon[random_point_index_2][1]), midpoint[0] + (polygon[random_point_index_1][0] - polygon[random_point_index_2][0])]\n                )\n\n                # Store the start and end points of the perpendicular bisector\n                first_bisectors_point[i] = midpoint\n                second_bisectors_point[i] = perpendicular_bisector\n            else:\n                # If the distance is not greater than the minimum distance, start over\n                i -= 1\n\n        # Check if the number of bisectors is sufficient\n        if len(first_bisectors_point) < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Could not find enough bisectors with the minimum distance between points: {min_distance_between_sector_points_in_px}\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.empty((0, 2), dtype=np.float32)\n        second_bisectors_point = np.empty((0, 2), dtype=np.float32)\n\n        for _ in range(self.params.max_iterations):\n            random_pair = np.random.choice(polygon, size=2, replace=False)\n\n            if np.linalg.norm(random_pair[0] - random_pair[1]) > min_distance_between_sector_points_in_px:\n                bisector_point = self._calculate_bisector_point(random_pair)\n                first_bisectors_point = np.append(first_bisectors_point, [bisector_point], axis=0)\n                second_bisectors_point = np.append(second_bisectors_point, [bisector_point], axis=0)\n\n                if first_bisectors_point.shape[0] >= self.params.num_bisectors:\n                    break\n\n        if first_bisectors_point.shape[0] < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {self.params.num_bisectors} bisectors within {self.params.max_iterations} iterations.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            # Initialize the first point as the first vertex of the polygon\n            first_point = polygon[0]\n\n            # Initialize the second point as the second vertex of the polygon\n            second_point = polygon[1]\n\n            # Calculate the midpoint between the first and second points\n            midpoint = (first_point + second_point) / 2\n\n            # Initialize the iteration counter\n            iteration = 0\n\n            # Repeat the following process until a pair of points is found that meets the distance criterion or the maximum number of iterations is reached\n            while iteration < max_iterations:\n                # Randomly select a point from the polygon\n                random_point = polygon[np.random.randint(len(polygon))]\n\n                # Calculate the distance between the random point and the midpoint\n                distance = np.linalg.norm(random_point - midpoint)\n\n                # If the distance is greater than the minimum distance between points, break out of the loop\n                if distance > min_distance_between_sector_points_in_px:\n                    break\n\n                # Increment the iteration counter\n                iteration += 1\n\n            # If the maximum number of iterations is reached without finding a pair of points that meets the distance criterion, raise an exception\n            if iteration == max_iterations:\n                raise EyeCentersEstimationError(\n                    f\"Failed to find a pair of points that meet the distance criterion within the maximum number of iterations ({max_iterations}).\"\n                )\n\n            # Calculate the perpendicular bisector of the random point and the midpoint\n            perpendicular_bisector = np.array([-1, 1])\n\n            # Calculate the intersection point of the perpendicular bisector and the midpoint\n            intersection_point = midpoint + perpendicular_bisector * distance / np.sqrt(2)\n\n            # Store the intersection point as the first point of the bisector\n            first_bisectors_point[i] = intersection_point\n\n            # Store the random point as the second point of the"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution_hook(self, *args, **kwargs)\n\n        result = self._run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution_hook(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n        result = self.run(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n        return result\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except ValueError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n            return self.check_type(output_dict, type_definition)\n        except ValueError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except Exception as e:\n            print(f\"Error occurred while deserializing output: {e}\")\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except ValueError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n            return self.check_type(output_dict, type_definition)\n        except json.JSONDecodeError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            print(f\"Unable to deserialize output: {output}\")\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except Exception as e:\n            print(f\"Error occurred while deserializing the output: {e}\")\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Try to deserialize the output string as JSON\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            # If the output cannot be deserialized, return False\n            return False\n\n        # Check if the deserialized output matches the type definition\n        if self.check_type(deserialized_output, type_definition):\n            return True\n        else:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            # Try to deserialize the output from JSON format\n            deserialized_output = json.loads(output)\n            # Check if the deserialized output matches the type definition\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            # If there is an error in deserializing or checking the type, return False\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # Deserialize the output string from JSON format\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        # Check if the deserialized output matches the type definition\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for key, value in type_hints.items():\n            if key in signature.parameters:\n                input_type_hints[key] = value\n            else:\n                output_type_hints[key] = value\n\n        input_class_definitions = {}\n        for key, value in input_type_hints.items():\n            input_class_definitions[key] = get_class_definition(value)\n\n        output_class_definitions = {}\n        for key, value in output_type_hints.items():\n            output_class_definitions[key] = get_class_definition(value)\n\n        function_type = None\n        output_class_definition = None\n\n        if len(output_type_hints) == 1:\n            output_type_hint = list(output_type_hints.values())[0]\n            if issubclass(output_type_hint, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n                output_class_definition = output_class_definitions[list(output_class_definitions.keys())[0]]\n            elif get_origin(output_type_hint) is Union:\n                for type_hint in output_type_hint.__args__:\n                    if issubclass(type_hint, Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n                        output_class_definition = output_class_definitions[list(output_class_definitions.keys())[0]]\n            else:\n                function_type = FunctionType.SYMBOLIC\n                output_class_definition = output_class_definitions[list(output_class_definitions.keys())[0]]\n        else:\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = output_class_definitions[list(output_class_definitions.keys())[0]]\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definition,"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param in signature.parameters.values():\n            if param.name in type_hints:\n                input_type_hints[param.name] = type_hints[param.name]\n\n        for param in signature.parameters.values():\n            if param.name in type_hints:\n                output_type_hints[param.name] = type_hints[param.name]\n\n        input_class_definitions = {}\n        for key, value in input_type_hints.items():\n            input_class_definitions[key] = get_class_definition(value)\n\n        output_class_definitions = {}\n        for key, value in output_type_hints.items():\n            output_class_definitions[key] = get_class_definition(value)\n\n        function_type = None\n        output_class_definition = None\n\n        if output_class_definitions:\n            output_class_definition = list(output_class_definitions.values())[0]\n            if issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definitions,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Separate input and output type hints\n        input_type_hints = {}\n        output_type_hints = {}\n        for param_name, param in signature.parameters.items():\n            if param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints[param_name]\n            elif param.kind == inspect.Parameter.RETURN:\n                output_type_hints[param_name] = type_hints[param_name]\n\n        # Fetch class definitions for input and output type hints\n        input_class_definitions = {}\n        output_class_definitions = {}\n        for param_name, param_type in input_type_hints.items():\n            input_class_definitions[param_name] = get_class_definition(param_type)\n        for param_name, param_type in output_type_hints.items():\n            output_class_definitions[param_name] = get_class_definition(param_type)\n\n        # Determine function type and output class definition\n        function_type = None\n        output_class_definition = None\n        if len(output_type_hints) == 1:\n            output_type_hint = next(iter(output_type_hints.values()))\n            if issubclass(output_type_hint, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n                output_class_definition = get_class_definition(output_type_hint)\n            elif get_origin(output_type_hint) == Union:\n                output_type_hint_args = output_type_hint.__args__\n                for output_type_hint_arg in output_type_hint_args:\n                    if issubclass(output_type_hint_arg, Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n                        output_class_definition = get_class_definition(output_type_hint_arg)\n                        break\n                if function_type is None:\n                    function_type = FunctionType.SYMBOLIC\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create a"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for name, parameter in sig.parameters.items():\n            if parameter.kind in (inspect.Parameter.POSITIONAL_ONLY, inspect.Parameter.POSITIONAL_OR_KEYWORD):\n                input_type_hints[name] = type_hints[name]\n            elif parameter.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n                pass\n            else:\n                raise ValueError(f\"Unsupported parameter kind {parameter.kind} for parameter {name}\")\n\n        for name, parameter in sig.parameters.items():\n            if parameter.kind in (inspect.Parameter.POSITIONAL_ONLY, inspect.Parameter.POSITIONAL_OR_KEYWORD):\n                output_type_hints[name] = type_hints[name]\n            elif parameter.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n                pass\n            else:\n                raise ValueError(f\"Unsupported parameter kind {parameter.kind} for parameter {name}\")\n\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for name, type_hint in input_type_hints.items():\n            input_class_definitions[name] = get_class_definition(type_hint)\n\n        for name, type_hint in output_type_hints.items():\n            output_class_definitions[name] = get_class_definition(type_hint)\n\n        output_type_hint = list(output_type_hints.values())[0]\n        function_type = FunctionType.SYMBOLIC\n        output_class_definition = None\n        if issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class_definition = get_class_definition(output_type_hint)\n        elif get_origin(output_type_hint) == Union:\n            if issubclass(output_type_hint.__args__[0], Embedding):\n                function_type = FunctionType.EMBEDDABLE\n                output_class_definition = get_class_definition(output_type_hint.__args__[0])\n\n        return Function"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function signature and type hints\n        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get the input and output type hints based on the function signature\n        input_type_hints = {name: type_hints[name] for name in sig.parameters}\n        output_type_hints = {name: type_hints[name] for name in sig.return_annotation}\n\n        # Get the class definitions for the input and output type hints\n        input_class_definitions = {}\n        output_class_definitions = {}\n        for name, type_hint in input_type_hints.items():\n            if isinstance(type_hint, type):\n                input_class_definitions[name] = get_class_definition(type_hint)\n            elif isinstance(type_hint, tuple):\n                input_class_definitions[name] = get_class_definition(type_hint[0])\n            elif isinstance(type_hint, Literal):\n                input_class_definitions[name] = get_class_definition(type_hint.value)\n\n        for name, type_hint in output_type_hints.items():\n            if isinstance(type_hint, type):\n                output_class_definitions[name] = get_class_definition(type_hint)\n            elif isinstance(type_hint, tuple):\n                output_class_definitions[name] = get_class_definition(type_hint[0])\n            elif isinstance(type_hint, Literal):\n                output_class_definitions[name] = get_class_definition(type_hint.value)\n\n        # Check if the output type hint is a class or a subclass of a Union\n        if isinstance(output_type_hints, type):\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = get_class_definition(output_type_hints)\n        elif isinstance(output_type_hints, tuple):\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = get_class_definition(output_type_hints[0])\n        elif isinstance(output_type_hints, Literal):\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = get_class_definition(output_type_hints.value)\n        elif isinstance(output_type_hints,"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        sig = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n\n        # Get the function's name and docstring\n        func_name = func_object.__name__\n        doc = func_object.__doc__\n\n        # Get the input and output type hints\n        input_hints = {}\n        output_hints = {}\n        for name, param in sig.parameters.items():\n            if param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                input_hints[name] = hints[name]\n            elif param.kind == inspect.Parameter.VAR_POSITIONAL:\n                input_hints[name] = Tuple[hints[name]]\n            elif param.kind == inspect.Parameter.VAR_KEYWORD:\n                input_hints[name] = Dict[str, hints[name]]\n        for name, param in sig.parameters.items():\n            if param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                output_hints[name] = hints[name]\n            elif param.kind == inspect.Parameter.VAR_POSITIONAL:\n                output_hints[name] = Tuple[hints[name]]\n            elif param.kind == inspect.Parameter.VAR_KEYWORD:\n                output_hints[name] = Dict[str, hints[name]]\n\n        # Get the class definitions for the input and output type hints\n        input_class_definitions = {}\n        for name, hint in input_hints.items():\n            input_class_definitions[name] = Register.get_class_definition(hint)\n\n        output_class_definitions = {}\n        for name, hint in output_hints.items():\n            output_class_definitions[name] = Register.get_class_definition(hint)\n\n        # Determine the function type based on the output type hint\n        if issubclass(output_hints[list(output_hints.keys())[0]], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create a FunctionDescription instance and return it\n        return FunctionDescription(func_name, doc, input_hints, output_hints, input_class_definitions,\n                                   output_class_definitions, function_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n        input_type_hints = {}\n        output_type_hints = {}\n        for name, param in signature.parameters.items():\n            if param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                input_type_hints[name] = type_hints[name]\n            elif param.kind == inspect.Parameter.VAR_POSITIONAL:\n                input_type_hints[name] = type_hints[name]\n            elif param.kind == inspect.Parameter.VAR_KEYWORD:\n                input_type_hints[name] = type_hints[name]\n        for name, param in signature.parameters.items():\n            if param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                output_type_hints[name] = type_hints[name]\n            elif param.kind == inspect.Parameter.VAR_POSITIONAL:\n                output_type_hints[name] = type_hints[name]\n            elif param.kind == inspect.Parameter.VAR_KEYWORD:\n                output_type_hints[name] = type_hints[name]\n\n        def get_class_definition(type_hint):\n            if get_origin(type_hint) is Union:\n                return Union[\n                    *[get_class_definition(t) for t in type_hint.__args__]\n                ]\n            elif get_origin(type_hint) is Literal:\n                return Literal[\n                    *[get_class_definition(t) for t in type_hint.__args__]\n                ]\n            elif type_hint.__class__.__module__ == \"builtins\":\n                return type_hint\n            else:\n                return type_hint.__class__\n\n        input_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in input_type_hints.items()\n        }\n        output_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in output_type_hints.items()\n        }\n\n        if get_origin(next(iter(output_type_hints.values()))) is Embedding:\n            function_type = FunctionType.EMBEDDABLE\n        elif get_origin"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function signature\n        signature = inspect.signature(func_object)\n\n        # Get the function's input and output type hints\n        input_type_hints = {}\n        output_type_hints = {}\n        for param in signature.parameters.values():\n            if param.annotation is not inspect.Parameter.empty:\n                input_type_hints[param.name] = param.annotation\n            else:\n                input_type_hints[param.name] = None\n        if signature.return_annotation is not inspect.Parameter.empty:\n            output_type_hints = signature.return_annotation\n        else:\n            output_type_hints = None\n\n        # Get the function's docstring\n        docstring = func_object.__doc__\n\n        # Get the class definition for the input and output type hints\n        input_class_definitions = {}\n        output_class_definitions = {}\n        for arg_name, arg_type in input_type_hints.items():\n            input_class_definitions[arg_name] = get_class_definition(arg_type)\n        if isinstance(output_type_hints, dict):\n            for arg_name, arg_type in output_type_hints.items():\n                output_class_definitions[arg_name] = get_class_definition(arg_type)\n        else:\n            output_class_definitions = get_class_definition(output_type_hints)\n\n        # Determine the function type based on the output type hint\n        if isinstance(output_type_hints, dict):\n            output_class_definitions = {}\n            for arg_name, arg_type in output_type_hints.items():\n                output_class_definitions[arg_name] = get_class_definition(arg_type)\n            function_type = FunctionType.EMBEDDABLE\n        elif issubclass(output_type_hints, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create a FunctionDescription object with the function's metadata\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for param in signature.parameters.values():\n            if param.name in type_hints:\n                input_type_hints[param.name] = type_hints[param.name]\n\n        output_type_hints = {key: value for key, value in type_hints.items() if key not in input_type_hints}\n\n        def get_class_definition(type_hint):\n            if get_origin(type_hint) is Literal:\n                return None\n            elif get_origin(type_hint) is Union:\n                return None\n            elif get_origin(type_hint) is Tuple:\n                return None\n            elif get_origin(type_hint) is Callable:\n                return None\n            elif type_hint is None:\n                return None\n            elif type_hint is Ellipsis:\n                return None\n            elif type_hint is type(None):\n                return None\n            elif type_hint is inspect._empty:\n                return None\n            elif type_hint is bool:\n                return None\n            elif type_hint is str:\n                return None\n            elif type_hint is int:\n                return None\n            elif type_hint is float:\n                return None\n            elif type_hint is complex:\n                return None\n            elif type_hint is bytes:\n                return None\n            elif type_hint is bytearray:\n                return None\n            elif type_hint is memoryview:\n                return None\n            elif type_hint is set:\n                return None\n            elif type_hint is frozenset:\n                return None\n            elif type_hint is list:\n                return None\n            elif type_hint is dict:\n                return None\n            elif type_hint is tuple:\n                return None\n            elif type_hint is range:\n                return None\n            elif type_hint is slice:\n                return None\n            elif type_hint is property:\n                return None\n            elif type_hint is type:\n                return None\n            elif type_hint is object:\n                return None\n            elif type_hint is slice:\n                return None\n            elif type_hint is type(None):\n                return None\n            else:\n                return type_hint.__name__\n\n        input_class_definitions = {}\n        for key, value in input_"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get the input and output type hints\n        input_type_hints = {\n            param_name: type_hint\n            for param_name, type_hint in type_hints.items()\n            if param_name in signature.parameters\n        }\n        output_type_hint = next(\n            type_hint\n            for param_name, type_hint in type_hints.items()\n            if param_name not in signature.parameters\n        )\n\n        # Get the class definitions for the input and output type hints\n        input_class_definitions = {\n            param_name: get_class_definition(type_hint)\n            for param_name, type_hint in input_type_hints.items()\n        }\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine the function type based on the output type hint\n        function_type = FunctionType.SYMBOLIC\n        if issubclass(output_type_hint, Embedding) or issubclass(output_type_hint, Union):\n            function_type = FunctionType.EMBEDDABLE\n\n        # Create a FunctionDescription instance with the function's metadata\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            type=function_type,\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = {\n            name: type_hints[name]\n            for name in signature.parameters\n            if name != 'self'\n        }\n\n        output_type_hints = {\n            name: type_hints[name]\n            for name in signature.parameters\n            if name == 'self'\n        }\n\n        def get_class_definition(type_hint):\n            \"\"\"\n            This function is used to fetch the class definition for a given type hint. It handles generic types and ensures that class definitions are fetched for non-built-in types.\n            \"\"\"\n            if isinstance(type_hint, type):\n                return type_hint\n            elif isinstance(type_hint, Callable):\n                return type_hint\n            elif isinstance(type_hint, Literal):\n                return type_hint\n            elif isinstance(type_hint, Tuple):\n                return type_hint\n            elif isinstance(type_hint, Union):\n                return type_hint\n            elif get_origin(type_hint):\n                return get_origin(type_hint)\n            else:\n                return type_hint\n\n        input_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in input_type_hints.items()\n        }\n\n        output_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in output_type_hints.items()\n        }\n\n        if isinstance(output_class_definitions['self'], type) or isinstance(output_class_definitions['self'], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif isinstance(output_class_definitions['self'], Union) and (\n                isinstance(output_class_definitions['self'].__args__[0], type) or isinstance(\n            output_class_definitions['self'].__args__[0], Embedding)):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get the input type hints from the function signature\n        input_type_hints = {k: v for k, v in type_hints.items() if k in sig.parameters}\n\n        # Get the output type hints from the function signature\n        output_type_hints = {k: v for k, v in type_hints.items() if k not in sig.parameters}\n\n        # Get the class definitions for the input type hints\n        input_class_definitions = {}\n        for k, v in input_type_hints.items():\n            if isinstance(v, type):\n                input_class_definitions[k] = get_class_definition(v)\n            elif isinstance(v, Callable):\n                input_class_definitions[k] = get_class_definition(v.__annotations__['return'])\n\n        # Get the class definitions for the output type hints\n        output_class_definitions = {}\n        for k, v in output_type_hints.items():\n            if isinstance(v, type):\n                output_class_definitions[k] = get_class_definition(v)\n            elif isinstance(v, Callable):\n                output_class_definitions[k] = get_class_definition(v.__annotations__['return'])\n\n        # Determine the function type based on the output type hint\n        function_type = FunctionType.SYMBOLIC\n        if isinstance(output_type_hints.get('return', None), type) and issubclass(output_type_hints['return'], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif isinstance(output_type_hints.get('return', None), Callable) and issubclass(output_type_hints['return'].__annotations__['return'], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif isinstance(output_type_hints.get('return', None), Union):\n            if any([issubclass(t, Embedding) for t in output_type_hints['return'].__args__]):\n                function_type = FunctionType.EMBEDDABLE\n\n        # Create a function description object\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        input_type_hints = get_type_hints(func_object)\n        output_type_hint = sig.return_annotation\n\n        def get_class_definition(type_hint):\n            \"\"\"\n            This function is used to get the class definition for a given type hint. It handles generic types and ensures that class definitions are fetched for non-built-in types.\n            :param type_hint: The type hint to get the class definition for.\n            :return: The class definition for the type hint.\n            \"\"\"\n            if get_origin(type_hint) is Union:\n                return Union\n            if get_origin(type_hint) is Literal:\n                return Literal\n            if get_origin(type_hint) is Tuple:\n                return Tuple\n            if get_origin(type_hint) is Callable:\n                return Callable\n            if get_origin(type_hint) is Optional:\n                return Optional\n            if type_hint.__module__ == \"builtins\":\n                return type_hint\n            if type_hint.__module__ == \"typing\":\n                return type_hint\n            if type_hint.__module__ == \"numpy\":\n                return type_hint\n            if type_hint.__module__ == \"torch\":\n                return type_hint\n            if type_hint.__module__ == \"tensorflow\":\n                return type_hint\n            if type_hint.__module__ == \"jax\":\n                return type_hint\n            if type_hint.__module__ == \"pandas\":\n                return type_hint\n            if type_hint.__module__ == \"pydantic\":\n                return type_hint\n            if type_hint.__module__ == \"dataclasses\":\n                return type_hint\n            if type_hint.__module__ == \"__main__\":\n                return type_hint\n            return type_hint\n\n        def get_output_class_definition(output_type_hint):\n            \"\"\"\n            This function is used to get the class definition for the output type hint. It handles generic types and ensures that class definitions are fetched for non-built-in types.\n            :param output_type_hint: The output type hint to get the class definition for.\n            :return: The class definition for the output type hint.\n            \"\"\"\n            if get_origin(output_type_hint) is Union:\n                return Union\n            if get_origin(output_type_hint) is Literal"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_signature = inspect.signature(func_object)\n        func_type_hints = get_type_hints(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param in func_signature.parameters.values():\n            if param.name in func_type_hints:\n                input_type_hints[param.name] = func_type_hints[param.name]\n\n        output_type_hints = func_type_hints[list(func_signature.parameters.values())[-1].name]\n\n        def get_class_definition(type_hint):\n            if get_origin(type_hint) is Union:\n                return Union[tuple(get_class_definition(t) for t in get_origin(type_hint).__args__)]\n            elif get_origin(type_hint) is Literal:\n                return Literal[tuple(get_origin(type_hint).__args__)]\n            elif type_hint.__class__.__name__ == 'TypeVarType':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'ForwardRef':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'ClassVar':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'Annotated':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'NewType':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'UnionType':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'Callable':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'Concatenate':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'ParamSpecArgs':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'ParamSpec':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'Type':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'BoundMethod':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'Method':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'Property':\n                return type_hint\n            elif type_hint.__class__.__name__ == 'GetSetDescriptorType':\n                return type"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param in sig.parameters.values():\n            if param.name in type_hints:\n                input_type_hints[param.name] = type_hints[param.name]\n\n        for param in sig.parameters.values():\n            if param.name in type_hints:\n                output_type_hints[param.name] = type_hints[param.name]\n\n        input_class_definitions = {}\n        for key, value in input_type_hints.items():\n            input_class_definitions[key] = get_class_definition(value)\n\n        output_class_definitions = {}\n        for key, value in output_type_hints.items():\n            output_class_definitions[key] = get_class_definition(value)\n\n        if Embedding in output_type_hints.values():\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definitions,\n            type=function_type\n        )\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n        source = get_source(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for key, value in type_hints.items():\n            if key in sig.parameters:\n                input_type_hints[key] = value\n            else:\n                output_type_hints[key] = value\n\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for key, value in input_type_hints.items():\n            if value.__class__.__name__ == 'TypeVar':\n                input_class_definitions[key] = get_class_definition(value.__bound__)\n            else:\n                input_class_definitions[key] = get_class_definition(value)\n\n        for key, value in output_type_hints.items():\n            if value.__class__.__name__ == 'TypeVar':\n                output_class_definitions[key] = get_class_definition(value.__bound__)\n            else:\n                output_class_definitions[key] = get_class_definition(value)\n\n        function_type = FunctionType.SYMBOLIC\n\n        if output_class_definitions:\n            if issubclass(output_class_definitions[next(iter(output_class_definitions))], Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_class_definitions[next(iter(output_class_definitions))]) == Union:\n                if issubclass(output_class_definitions[next(iter(output_class_definitions))].__args__[0], Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            func_object.__name__,\n            docstring,\n            input_type_hints,\n            output_type_hints,\n            input_class_definitions,\n            output_class_definitions,\n            function_type,\n            source\n        )\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n        source = get_source(func_object)\n        input_type_hints = {}\n        output_type_hints = {}\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for name, parameter in signature.parameters.items():\n            if name == \"self\":\n                continue\n            if parameter.annotation != inspect.Parameter.empty:\n                input_type_hints[name] = parameter.annotation\n            else:\n                input_type_hints[name] = None\n\n        for name, type_hint in type_hints.items():\n            if name == \"return\":\n                output_type_hints[name] = type_hint\n            else:\n                input_type_hints[name] = type_hint\n\n        def get_class_definition(type_hint):\n            if type_hint is None:\n                return None\n            elif type_hint.__class__.__name__ == \"UnionType\":\n                return None\n            elif type_hint.__class__.__name__ == \"ForwardRef\":\n                return None\n            elif type_hint.__class__.__name__ == \"TypeVarType\":\n                return None\n            elif type_hint.__class__.__name__ == \"CallableType\":\n                return None\n            elif type_hint.__class__.__name__ == \"LiteralType\":\n                return None\n            elif type_hint.__class__.__name__ == \"ClassVarType\":\n                return None\n            elif type_hint.__class__.__name__ == \"TypeType\":\n                return None\n            elif type_hint.__class__.__name__ == \"BoundMethodType\":\n                return None\n            elif type_hint.__class__.__name__ == \"GenericAlias\":\n                return None\n            elif type_hint.__class__.__name__ == \"Union\":\n                return None\n            elif type_hint.__class__.__name__ == \"Type\":\n                return None\n            elif type_hint.__class__.__name__ == \"ForwardRef\":\n                return None\n            elif type_hint.__class__.__name__ == \"ForwardRef\":\n                return None\n            else:\n                return json.dumps(type_hint.__class__.__dict__)\n\n        for name, type_hint in input_type_hints.items():\n            input_class_definitions[name] = get_class_definition(type_hint)\n\n        for"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for parameter in signature.parameters.values():\n            if parameter.name in type_hints:\n                input_type_hints[parameter.name] = type_hints[parameter.name]\n\n        if len(type_hints) > len(input_type_hints):\n            for parameter in signature.parameters.values():\n                if parameter.name not in type_hints:\n                    output_type_hints[parameter.name] = type_hints[parameter.name]\n\n        def get_class_definition(type_hint):\n            \"\"\"\n            This function is a helper function for the `load_function_description` function. It is used to fetch the class definition for a given type hint. It handles generic types and ensures that class definitions are fetched for non-built-in types.\n            \"\"\"\n            if hasattr(type_hint, '__origin__'):\n                if type_hint.__origin__ == Union:\n                    return None\n                else:\n                    return type_hint.__origin__\n            else:\n                return type_hint\n\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for key, value in input_type_hints.items():\n            input_class_definitions[key] = get_class_definition(value)\n\n        for key, value in output_type_hints.items():\n            output_class_definitions[key] = get_class_definition(value)\n\n        function_type = FunctionType.SYMBOLIC\n\n        if len(output_type_hints) == 1:\n            if get_origin(list(output_type_hints.values())[0]) == Union:\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                output_class_definition = list(output_class_definitions.values())[0]\n                if issubclass(output_class_definition, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n\n        return FunctionDescription(func_object.__name__, func_object.__doc__, input_type_hints, output_type_hints, input_class_definitions, output_class_definitions, function_type, get_source(func_object))\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature\n        signature = inspect.signature(func_object)\n\n        # Get the type hints for the function's input and output arguments\n        input_type_hints = get_type_hints(func_object)\n        output_type_hints = get_type_hints(func_object)\n\n        # Get the function's name, docstring, and signature\n        function_name = func_object.__name__\n        docstring = func_object.__doc__\n        signature = inspect.signature(func_object)\n\n        # Get the class definitions for the input and output type hints\n        input_class_definitions = {}\n        for arg_name, arg_type in input_type_hints.items():\n            input_class_definitions[arg_name] = get_class_definition(arg_type)\n\n        output_class_definitions = {}\n        for arg_name, arg_type in output_type_hints.items():\n            output_class_definitions[arg_name] = get_class_definition(arg_type)\n\n        # Determine the function type based on the output type hint\n        if issubclass(output_type_hints[list(output_type_hints.keys())[0]], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif issubclass(Union, type(output_type_hints[list(output_type_hints.keys())[0]])):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(function_name=function_name,\n                                   docstring=docstring,\n                                   signature=signature,\n                                   input_type_hints=input_type_hints,\n                                   output_type_hints=output_type_hints,\n                                   input_class_definitions=input_class_definitions,\n                                   output_class_definitions=output_class_definitions,\n                                   type=function_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n        source = get_source(func_object)\n\n        input_type_hints = {param.name: type_hints[param.name] for param in signature.parameters.values()\n                            if param.name not in signature.parameters.keys()}\n        output_type_hints = {param.name: type_hints[param.name] for param in signature.parameters.values()\n                             if param.name in signature.parameters.keys()}\n\n        input_classes = {}\n        output_classes = {}\n\n        for key, value in input_type_hints.items():\n            if get_origin(value) is Union:\n                input_classes[key] = get_class_definition(value.__args__[0])\n            else:\n                input_classes[key] = get_class_definition(value)\n\n        for key, value in output_type_hints.items():\n            if get_origin(value) is Union:\n                output_classes[key] = get_class_definition(value.__args__[0])\n            else:\n                output_classes[key] = get_class_definition(value)\n\n        if issubclass(output_type_hints.get('return', None), Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(func_object.__name__, docstring, input_type_hints, output_type_hints, input_classes, output_classes, function_type, source)\n\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.add(string)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.save(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = 1\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.set_bit_array(self.bit_array)\n        self.persistence.set_indices(self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.set_bit_array(self.bit_array)\n        self.persistence.set_indices(self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.persist(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.save(self.bit_array)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.save(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.persist(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.persist(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        #print(f\"Add: Digest={index}, BitValue={self.bit_array[index]}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            if self.bit_array[index] == 0:\n                self.bit_array[index] = 1\n                self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.write(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.init_bit_array(self.size)\n        self.bit_array = self.persistence.load()\n\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length {len(self.bit_array)} does not match expected length {self.size}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"BloomFilter: The loaded bit array length ({len(self.bit_array)}) does not match the expected length ({self.size}). Reinitializing the bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(loaded_bit_array)}) does not match expected length ({self.size}). Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length {len(loaded_bit_array)} does not match expected length {self.size}. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"The loaded bit array length {len(loaded_bit_array)} does not match the expected length {self.size}. Reinitializing the bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.init_bit_array(self.size)\n        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(\"The loaded bit array does not match the expected length. Reinitializing the bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        expected_length = self.size\n        actual_length = len(self.bit_array)\n        if actual_length != expected_length:\n            logging.warning(f\"Loaded bit array length {actual_length} does not match expected length {expected_length}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(expected_length)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"Loaded bit array has length {len(self.bit_array)} but expected length is {self.size}. Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.init_bit_array(self.size)\n        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"BloomFilter: Loaded bit array size does not match expected size. Reinitializing bit array and indices.\")\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        expected_length = self.size\n        actual_length = len(self.bit_array)\n        if actual_length != expected_length:\n            logging.warning(f\"Bit array length mismatch: Expected {expected_length}, Actual {actual_length}\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(bit_array)}) does not match expected length ({self.size}). Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length {len(loaded_bit_array)} does not match expected length {self.size}. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        expected_length = int(self.size / 8)\n        if len(self.bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length {len(self.bit_array)} does not match expected length {expected_length}. Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length {len(loaded_bit_array)} does not match expected length {expected_length}. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(expected_length)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        expected_length = self.size\n        actual_length = len(self.bit_array)\n        if expected_length != actual_length:\n            logging.warning(f\"Expected bit array length {expected_length} does not match actual bit array length {actual_length}. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.init_bit_array(self.size)\n\n        loaded_bit_array = self.persistence.load()\n\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing and saving.\")\n            self.save()\n            return\n\n        self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Bit array length {len(bit_array)} does not match expected length {self.size}. Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"BloomFilter: Bit array loaded from persistence does not match the expected length. Reinitializing the bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length {len(loaded_bit_array)} does not match expected length {expected_length}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(\"Bit array size mismatch. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Get the hash values\n        hash1, hash2 = self.hash_functions(string)\n\n        # Create an empty bit array to store the indices\n        indices = bitarray(self.size)\n        indices.setall(0)\n\n        # Generate the indices using the hash values and hash count\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            indices[index] = 1\n\n        # Check if all bits at the generated indices are set in the bit array\n        for i in range(self.size):\n            if indices[i] == 1 and self.bit_array[i] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Get the indices for the string\n        hash1, hash2 = self.hash_functions(string)\n        indices = np.zeros(self.hash_count, dtype=np.int32)\n        for i in range(self.hash_count):\n            indices[i] = (hash1 + i * hash2) % self.size\n\n        # Check if all bits at these indices are set\n        for index in indices:\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.load_model_config(json_dict['distilled_model'])\n\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.load_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.load_model_config(json_dict['distilled_model'])\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.load_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.load_config(json_dict['distilled_model'])\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.load_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.load_config(json_dict['distilled_model'])\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.load_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.load_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_from_dict(json_dict['distilled_model'], TEACHER_MODEL)\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.load_from_dict(teacher_model, TEACHER_MODEL) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.create_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.load_model_config(teacher_model_dict) for teacher_model_dict in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_from_dict(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.load_from_dict(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_from_dict(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.load_from_dict(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.teacher_models = [config_factory.load_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.teacher_models = [config_factory.load_model_config(teacher_model_config) for teacher_model_config in json_dict['teacher_models']]\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_from_dict(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.load_from_dict(teacher_model_dict) for teacher_model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.load_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.create_model_config(teacher_model_dict) for teacher_model_dict in json_dict['teacher_models']]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_from_dict(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        self.teacher_models = [config_factory.load_from_dict(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_config(json_dict[\"distilled_model\"], TEACHER_MODEL)\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_config(teacher_model, TEACHER_MODEL) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        if model.model_name == \"gpt-3.5-turbo\":\n            model.model_name = \"gpt-3.5-turbo-0301\"\n        if model.model_name == \"gpt-4\":\n            model.model_name = \"gpt-4-0314\"\n        if model.model_name == \"gpt-3.5-turbo-0301\":\n            model.model_name = \"gpt-3.5-turbo-0301\"\n        if model.model_name == \"gpt-4-0314\":\n            model.model_name = \"gpt-4-0314\"\n        if model.model_name == \"text-davinci-003\":\n            model.model_name = \"text-davinci-003\"\n        if model.model_name == \"text-davinci-002\":\n            model.model_name = \"text-davinci-002\"\n        if model.model_name == \"text-davinci-001\":\n            model.model_name = \"text-davinci-001\"\n        if model.model_name == \"text-curie-001\":\n            model.model_name = \"text-curie-001\"\n        if model.model_name == \"text-babbage-001\":\n            model.model_name = \"text-babbage-001\"\n        if model.model_name == \"text-ada-001\":\n            model.model_name = \"text-ada-001\"\n        if model.model_name == \"davinci\":\n            model.model_name = \"text-davinci-003\"\n        if model.model_name == \"curie\":\n            model.model_name = \"text-curie-001\"\n        if model.model_name == \"babbage\":\n            model.model_name = \"text-babbage-001\"\n        if model.model_name == \"ada\":\n            model.model_name = \"text-ada-001"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # check if the model is valid\n        if model is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the model is valid\n        if model.model_name is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the system message is valid\n        if system_message is None:\n            logging.error(\"No system message specified\")\n            return None\n\n        # check if the prompt is valid\n        if prompt is None:\n            logging.error(\"No prompt specified\")\n            return None\n\n        # check if the model is valid\n        if model.model_name is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the system message is valid\n        if system_message is None:\n            logging.error(\"No system message specified\")\n            return None\n\n        # check if the prompt is valid\n        if prompt is None:\n            logging.error(\"No prompt specified\")\n            return None\n\n        # check if the model is valid\n        if model.model_name is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the system message is valid\n        if system_message is None:\n            logging.error(\"No system message specified\")\n            return None\n\n        # check if the prompt is valid\n        if prompt is None:\n            logging.error(\"No prompt specified\")\n            return None\n\n        # check if the model is valid\n        if model.model_name is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the system message is valid\n        if system_message is None:\n            logging.error(\"No system message specified\")\n            return None\n\n        # check if the prompt is valid\n        if prompt is None:\n            logging.error(\"No prompt specified\")\n            return None\n\n        # check if the model is valid\n        if model.model_name is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the system message is valid\n        if system_message is None:\n            logging.error(\"No system message specified\")\n            return None\n\n        # check if the prompt is valid\n        if prompt is None:\n            logging.error(\"No prompt specified\")\n            return None\n\n        # check if the model is valid\n        if model.model_name is None:\n            logging.error(\"No model specified\")\n            return None\n\n        # check if the"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        try:\n            response = self.client.chat.completions.create(\n                model=model.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                **kwargs\n            )\n            assert response.object == \"chat.completion\"\n            assert response.model == model.model_name\n            assert len(response.choices) == 1\n            assert response.choices[0].object == \"chat.choice\"\n            assert response.choices[0].index == 0\n            assert response.choices[0].message.object == \"chat.message\"\n            assert response.choices[0].message.role == \"assistant\"\n            assert response.choices[0].message.content is not None\n            return response.choices[0].message.content\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        try:\n            if \"temperature\" not in kwargs:\n                kwargs[\"temperature\"] = 0.7\n            if \"top_p\" not in kwargs:\n                kwargs[\"top_p\"] = 1.0\n            if \"frequency_penalty\" not in kwargs:\n                kwargs[\"frequency_penalty\"] = 0.0\n            if \"presence_penalty\" not in kwargs:\n                kwargs[\"presence_penalty\"] = 0.0\n            if \"max_new_tokens\" not in kwargs:\n                kwargs[\"max_new_tokens\"] = 512\n            if \"stop\" not in kwargs:\n                kwargs[\"stop\"] = [\"\\n\"]\n            response = self.client.chat.completions.create(\n                model=model.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                **kwargs\n            )\n            assert response.object == \"chat.completion\"\n            assert response.model == model.model_name\n            assert len(response.choices) == 1\n            assert response.choices[0].object == \"chat.choice\"\n            assert response.choices[0].index == 0\n            assert response.choices[0].message.object == \"chat.message\"\n            assert response.choices[0].message.role == \"assistant\"\n            text = response.choices[0].message.content\n            return text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if the model is valid\n        if model is None:\n            logging.error(\"Invalid model provided.\")\n            return None\n\n        # Check if the system message is valid\n        if system_message is None:\n            logging.error(\"Invalid system message provided.\")\n            return None\n\n        # Check if the prompt is valid\n        if prompt is None:\n            logging.error(\"Invalid prompt provided.\")\n            return None\n\n        # Check if the parameters are valid\n        for param in kwargs:\n            if param not in LLM_GENERATION_PARAMETERS:\n                logging.error(f\"Invalid parameter: {param}\")\n                return None\n\n        # Check if the model is a valid OpenAI model\n        if not model.is_valid_model():\n            logging.error(\"Invalid OpenAI model provided.\")\n            return None\n\n        # Check if the system message is a valid OpenAI system message\n        if not model.is_valid_system_message(system_message):\n            logging.error(\"Invalid OpenAI system message provided.\")\n            return None\n\n        # Check if the prompt is a valid OpenAI prompt\n        if not model.is_valid_prompt(prompt):\n            logging.error(\"Invalid OpenAI prompt provided.\")\n            return None\n\n        # Check if the parameters are valid for the OpenAI model\n        if not model.is_valid_parameters(kwargs):\n            logging.error(\"Invalid OpenAI parameters provided.\")\n            return None\n\n        # Set the model name\n        model_name = model.model_name\n\n        # Set the system message\n        system_message = model.get_system_message(system_message)\n\n        # Set the prompt\n        prompt = model.get_prompt(prompt)\n\n        # Set the parameters\n        parameters = model.get_parameters(kwargs)\n\n        # Set the maximum number of retries\n        max_retries = 5\n\n        # Set the initial backoff time\n        backoff_time = 1\n\n        # Set the initial retry count\n        retry_count = 0\n\n        # Set the initial response\n        response = None\n\n        # Loop until a valid response is received or the maximum number of retries is reached\n        while response is None and retry_count < max_retries:\n            try:\n                # Send the request to the OpenAI API\n                response = self.client.chat.completions.create(\n                    model=model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check if the API key is set\n        self.check_api_key()\n\n        # Check if the model is set\n        if model is None:\n            raise ValueError(\"Model is not set.\")\n\n        # Check if the system message is set\n        if system_message is None:\n            raise ValueError(\"System message is not set.\")\n\n        # Check if the prompt is set\n        if prompt is None:\n            raise ValueError(\"Prompt is not set.\")\n\n        # Check if the parameters are valid\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {key}\")\n\n        # Set the default parameters\n        default_parameters = {\n            \"temperature\": 0.7,\n            \"top_p\": 1.0,\n            \"frequency_penalty\": 0.0,\n            \"presence_penalty\": 0.0,\n            \"max_new_tokens\": 512,\n        }\n\n        # Update the default parameters with the provided parameters\n        default_parameters.update(kwargs)\n\n        # Set the parameters\n        parameters = {\n            \"temperature\": default_parameters[\"temperature\"],\n            \"top_p\": default_parameters[\"top_p\"],\n            \"frequency_penalty\": default_parameters[\"frequency_penalty\"],\n            \"presence_penalty\": default_parameters[\"presence_penalty\"],\n            \"max_tokens\": default_parameters[\"max_new_tokens\"],\n        }\n\n        # Set the API URL\n        api_url = OPENAI_URL\n\n        # Set the request headers\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.api_key}\",\n        }\n\n        # Set the request body\n        data = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            \"temperature\": parameters[\"temperature\"],\n            \"top_p\": parameters[\"top_p\"],\n            \"frequency_penalty\": parameters[\"frequency_penalty\"],\n            \"presence_penalty\": parameters[\"presence_penalty\"],\n            \"max_tokens\": parameters[\"max_tokens\"],\n        }\n\n        # Set the retry parameters\n        retries = 5\n        retry_interval = 1\n        retry_backoff = 2\n\n        # Make the request\n        for i in range("}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        # Validate the model name\n        assert model.model_name is not None, \"Model name is required\"\n\n        # Validate the prompt\n        assert prompt is not None, \"Prompt is required\"\n\n        # Validate the system message\n        assert system_message is not None, \"System message is required\"\n\n        # Validate the parameters\n        for param in kwargs:\n            assert param in LLM_GENERATION_PARAMETERS, f\"{param} is not a valid parameter\"\n\n        # Set up the parameters\n        params = {\n            \"model\": model.model_name,\n            \"temperature\": kwargs.get(\"temperature\", 0.7),\n            \"top_p\": kwargs.get(\"top_p\", 1.0),\n            \"frequency_penalty\": kwargs.get(\"frequency_penalty\", 0.0),\n            \"presence_penalty\": kwargs.get(\"presence_penalty\", 0.0),\n            \"max_tokens\": kwargs.get(\"max_new_tokens\", 256),\n            \"stop\": model.stop_tokens\n        }\n\n        # Set up the messages\n        messages = [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n\n        # Set up the request data\n        data = {\n            \"messages\": messages,\n            \"temperature\": kwargs.get(\"temperature\", 0.7),\n            \"top_p\": kwargs.get(\"top_p\", 1.0),\n            \"frequency_penalty\": kwargs.get(\"frequency_penalty\", 0.0),\n            \"presence_penalty\": kwargs.get(\"presence_penalty\", 0.0),\n            \"max_tokens\": kwargs.get(\"max_new_tokens\", 256),\n            \"stop\": model.stop_tokens\n        }\n\n        # Make the request\n        response = self.client.chat.completions.create(\n            model=model.model_name,\n            messages=messages,\n            **params\n        )\n\n        # Process the response\n        text = response.choices[0].message.content\n\n        # Remove any parsing helper tokens\n        if model.parsing_helper_token is not None:\n            text = text.replace(model.parsing_helper_token, \"\")\n\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        if model.model_name == None:\n            model.model_name = DEFAULT_DISTILLED_MODEL_NAME\n\n        if model.system_message == None:\n            model.system_message = system_message\n\n        if model.prompt == None:\n            model.prompt = prompt\n\n        # Create a list of parameters to pass to the OpenAI API\n        params = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": model.system_message},\n                {\"role\": \"user\", \"content\": model.prompt},\n            ],\n            **kwargs\n        }\n\n        # Validate the parameters\n        for param in params:\n            if param not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {param}\")\n\n        # Make the API request\n        response = self.client.chat.completions.create(\n            model=model.model_name,\n            messages=params[\"messages\"],\n            **kwargs\n        )\n\n        # Check the response status\n        if response.status != 200:\n            raise Exception(f\"API request failed with status {response.status}\")\n\n        # Check the response object\n        if response.object != \"chat.completion\":\n            raise Exception(f\"Invalid response object: {response.object}\")\n\n        # Check the number of choices\n        if len(response.choices) != 1:\n            raise Exception(f\"Invalid number of choices: {len(response.choices)}\")\n\n        # Check the number of messages\n        if len(response.choices[0].messages) != 2:\n            raise Exception(f\"Invalid number of messages: {len(response.choices[0].messages)}\")\n\n        # Check the role of the first message\n        if response.choices[0].messages[0].role != \"system\":\n            raise Exception(f\"Invalid role for first message: {response.choices[0].messages[0].role}\")\n\n        # Check the role of the second message\n        if response.choices[0].messages[1].role != \"user\":\n            raise Exception(f\"Invalid role for second message: {response.choices[0].messages[1].role}\")\n\n        # Check the content of the first message\n        if response.choices[0].messages[0].content != model.system_message:\n            raise Exception("}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = self.client.chat.completions.create(\n                model=model.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                **kwargs\n            )\n            assert response.object == \"chat.completion\"\n            assert response.model == model.model_name\n            assert response.usage[\"total_tokens\"] >= len(prompt)\n            assert response.usage[\"total_tokens\"] >= len(response.choices[0].text)\n            assert response.usage[\"completion_tokens\"] == len(response.choices[0].text)\n            assert response.usage[\"prompt_tokens\"] == len(prompt)\n            assert response.usage[\"total_tokens\"] == response.usage[\"completion_tokens\"] + response.usage[\"prompt_tokens\"]\n            text = response.choices[0].text\n            if model.parse_helper_token is not None:\n                text = text.replace(model.parse_helper_token, \"\")\n            return text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            # create a list of messages to send to the API\n            messages = [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n\n            # create a dictionary of parameters to send to the API\n            params = {\n                \"model\": model.model_name,\n                \"messages\": messages,\n                \"temperature\": kwargs.get(\"temperature\", 0.5),\n                \"top_p\": kwargs.get(\"top_p\", 1.0),\n                \"frequency_penalty\": kwargs.get(\"frequency_penalty\", 0.0),\n                \"presence_penalty\": kwargs.get(\"presence_penalty\", 0.0),\n                \"max_tokens\": kwargs.get(\"max_tokens\", 500),\n                \"stop\": kwargs.get(\"stop\", None),\n            }\n\n            # send the request to the OpenAI API\n            response = self.client.chat.completions.create(**params)\n\n            # process the response to remove any parsing helper tokens\n            text = response.choices[0].message.content\n            if model.parsing_helper_token:\n                text = text.replace(model.parsing_helper_token, \"\")\n\n            # return the generated text\n            return text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = self.client.chat.completions.create(\n                model=model.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt},\n                ],\n                **kwargs\n            )\n            # check if response is valid\n            assert response.object == \"chat.completion\"\n            assert response.model == model.model_name\n            # check if response contains messages\n            assert len(response.choices) == 1\n            assert len(response.choices[0].message) == 1\n            # check if response message is valid\n            assert response.choices[0].message[0].role == \"assistant\"\n            assert response.choices[0].message[0].content is not None\n            # return the response content\n            return response.choices[0].message[0].content\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        # Validate the model\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(\"Invalid model type. Expected an instance of OpenAIConfig.\")\n\n        # Validate the system message\n        if not isinstance(system_message, str):\n            raise ValueError(\"Invalid system message type. Expected a string.\")\n\n        # Validate the prompt\n        if not isinstance(prompt, str):\n            raise ValueError(\"Invalid prompt type. Expected a string.\")\n\n        # Validate the additional parameters\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter '{key}'. Expected one of {LLM_GENERATION_PARAMETERS}.\")\n            if not isinstance(value, (int, float)):\n                raise ValueError(f\"Invalid value type for parameter '{key}'. Expected an integer or float.\")\n\n        # Define the parameters for the generation request\n        params = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            **kwargs\n        }\n\n        # Define the retry parameters\n        max_retries = 5\n        backoff_factor = 1.5\n        retry_status_codes = [500, 502, 503, 504]\n\n        # Define the helper function for handling retries\n        def handle_retry(response, **kwargs):\n            nonlocal backoff_factor\n            if response.status_code in retry_status_codes:\n                backoff_factor *= 2\n                return True\n            return False\n\n        # Define the helper function for processing the response\n        def process_response(response):\n            if response.status_code != 200:\n                raise ValueError(f\"Invalid response status code: {response.status_code}\")\n            response_json = response.json()\n            if \"choices\" not in response_json or len(response_json[\"choices\"]) == 0:\n                raise ValueError(\"Invalid response format: missing 'choices' field\")\n            choice = response_json[\"choices\"][0]\n            if \"message\" not in choice or \"content\" not in choice[\"message\"]:\n                raise ValueError(\"Invalid response format: missing 'message' or 'content' field\")\n            return choice[\"message\"][\"content\"]\n\n        # Define the helper"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # check if the model is a valid OpenAI model\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(f\"Invalid model: {model}\")\n\n        # check if the system message is a valid string\n        if not isinstance(system_message, str):\n            raise ValueError(f\"Invalid system message: {system_message}\")\n\n        # check if the prompt is a valid string\n        if not isinstance(prompt, str):\n            raise ValueError(f\"Invalid prompt: {prompt}\")\n\n        # check if the parameters are valid\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {key}\")\n            if not isinstance(value, (int, float)):\n                raise ValueError(f\"Invalid value for {key}: {value}\")\n\n        # initialise the parameters\n        parameters = {\n            \"model\": model.model_name,\n            \"temperature\": 0.5,\n            \"top_p\": 1,\n            \"frequency_penalty\": 0,\n            \"presence_penalty\": 0,\n            \"max_new_tokens\": 50,\n            \"stop\": model.stop_token,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n        }\n\n        # update the parameters with the provided kwargs\n        parameters.update(kwargs)\n\n        # initialise the response\n        response = None\n\n        # initialise the retry count\n        retry_count = 0\n\n        # initialise the backoff factor\n        backoff_factor = 1\n\n        # initialise the max retries\n        max_retries = 5\n\n        # initialise the backoff limit\n        backoff_limit = 10\n\n        # initialise the backoff\n        backoff = 1\n\n        # loop until the response is not None or the retry count exceeds the max retries\n        while response is None and retry_count < max_retries:\n            try:\n                # make the request to the OpenAI API\n                response = self.client.chat.completions.create(**parameters)\n\n                # check if the response is valid\n                if response.object == \"chat.completion\" and response.choices[0].text:\n                    # return the response text\n                    return response.choices[0].text\n            except Exception as e:\n                # print the error message\n                print("}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate parameters\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(\"model must be of type OpenAIConfig\")\n\n        if not isinstance(system_message, str):\n            raise ValueError(\"system_message must be of type str\")\n\n        if not isinstance(prompt, str):\n            raise ValueError(\"prompt must be of type str\")\n\n        # Validate kwargs\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {key}\")\n\n        # Check if the model name is valid\n        if model.model_name not in OpenAIConfig.MODEL_NAMES:\n            raise ValueError(f\"Invalid model name: {model.model_name}\")\n\n        # Set the model name and any parsing helper tokens\n        model_name = model.model_name\n        if model.parsing_helper_tokens:\n            model_name += f\"-{model.parsing_helper_tokens}\"\n\n        # Set the system message\n        system_messages = [\n            {\n                \"role\": \"system\",\n                \"content\": system_message,\n            }\n        ]\n\n        # Set the prompt\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": prompt,\n            }\n        ]\n\n        # Set the parameters\n        parameters = {\n            \"model\": model_name,\n            \"messages\": system_messages + messages,\n            **kwargs,\n        }\n\n        # Make the API request\n        response = None\n        for retry in range(5):\n            try:\n                response = self.client.chat.completions.create(**parameters)\n                break\n            except Exception as e:\n                logging.error(f\"Error making API request: {e}\")\n                time.sleep(2 ** retry)\n\n        # Check if the response is valid\n        if response is None or not isinstance(response, dict) or \"choices\" not in response or not isinstance(response[\"choices\"], list) or len(response[\"choices\"]) == 0 or not isinstance(response[\"choices\"][0], dict) or \"message\" not in response[\"choices\"][0] or not isinstance(response[\"choices\"][0][\"message\"], dict) or \"content\" not in response[\"choices\"][0][\"message\"] or not isinstance(response[\"choices\"][0][\"message\"][\"content\"], str):\n            raise ValueError(\"Invalid response from API\")\n\n        #"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if model is provided\n        if not model:\n            raise ValueError(\"Model is required\")\n\n        # Check if system message is provided\n        if not system_message:\n            raise ValueError(\"System message is required\")\n\n        # Check if prompt is provided\n        if not prompt:\n            raise ValueError(\"Prompt is required\")\n\n        # Check if parameters are provided\n        if not kwargs:\n            raise ValueError(\"Parameters are required\")\n\n        # Check if parameters are valid\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {key}\")\n\n        # Set the default parameters\n        default_parameters = {\n            \"temperature\": 0.5,\n            \"top_p\": 1,\n            \"frequency_penalty\": 0,\n            \"presence_penalty\": 0,\n            \"max_new_tokens\": 512\n        }\n\n        # Merge the default parameters with the provided parameters\n        parameters = {**default_parameters, **kwargs}\n\n        # Set the retry count and backoff factor\n        retry_count = 5\n        backoff_factor = 1.5\n\n        # Initialize the response\n        response = None\n\n        # Initialize the error\n        error = None\n\n        # Loop until the response is not None or the retry count is exhausted\n        while response is None and retry_count > 0:\n            try:\n                # Send the request to the OpenAI API\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **parameters\n                )\n\n                # Check if the response is valid\n                if response.object == \"chat.completion\":\n                    # Process the response to remove any parsing helper tokens\n                    response_text = response.choices[0].message.content.strip()\n                    # Return the final text\n                    return response_text\n                else:\n                    # Set the error to indicate an invalid response\n                    error = \"Invalid response\"\n            except Exception as e:\n                # Set the error to the exception message\n                error = str(e)\n            # Decrement the retry count\n            retry_count -= 1\n            # Calculate the backoff time\n            backoff_time = backoff_factor * (2 ** (5 - retry_"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate the parameters\n        for param in kwargs:\n            if param not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {param}\")\n\n        # initialise the parameters\n        temperature = kwargs.get(\"temperature\", 0.7)\n        top_p = kwargs.get(\"top_p\", 1)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 512)\n\n        # construct the request data\n        request_data = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"max_tokens\": max_new_tokens,\n        }\n\n        # send the request to the OpenAI API\n        response = requests.post(\n            OPENAI_URL,\n            headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n            json=request_data\n        )\n\n        # check the response status code\n        if response.status_code != 200:\n            raise RuntimeError(f\"OpenAI API error: {response.json()}\")\n\n        # process the response\n        response_json = response.json()\n        response_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n\n        # remove any parsing helper tokens from the response\n        if model.parsing_helper_tokens:\n            for token in model.parsing_helper_tokens:\n                response_text = response_text.replace(token, \"\")\n\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        # verify parameters\n        assert isinstance(model, OpenAIConfig)\n        assert isinstance(system_message, str)\n        assert isinstance(prompt, str)\n        assert isinstance(kwargs, dict)\n\n        # check if the model is distilled and if it is, set the model name to the default distilled model name\n        if model.is_distilled:\n            model.model_name = DEFAULT_DISTILLED_MODEL_NAME\n\n        # create a list of parameters to validate\n        parameters = LLM_GENERATION_PARAMETERS\n\n        # validate the parameters\n        for parameter in parameters:\n            assert parameter in kwargs\n\n        # set the temperature to 0.5 if it is not provided\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = 0.5\n\n        # set the max new tokens to 100 if it is not provided\n        if \"max_new_tokens\" not in kwargs:\n            kwargs[\"max_new_tokens\"] = 100\n\n        # set the frequency penalty to 0 if it is not provided\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = 0\n\n        # set the presence penalty to 0 if it is not provided\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = 0\n\n        # set the stop sequence to the model's stop sequence if it is not provided\n        if \"stop\" not in kwargs:\n            kwargs[\"stop\"] = model.stop_sequence\n\n        # set the top p to 1 if it is not provided\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = 1\n\n        # set the n to 1 if it is not provided\n        if \"n\" not in kwargs:\n            kwargs[\"n\"] = 1\n\n        # set the echo to False if it is not provided\n        if \"echo\" not in kwargs:\n            kwargs[\"echo\"] = False\n\n        # set the logprobs to None if it is not provided\n        if \"logprobs\" not in kwargs:\n            kwargs[\"logprobs\"] = None\n\n        # set the stream to False if it is not provided\n        if \"stream\" not in kwargs:\n            kwargs[\"stream\"] = False\n\n        # set the logit_bias to None if it is not provided\n        if \"logit_bias\" not in kwargs:\n            kwargs"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if the model is valid\n        assert model.model_name in self.client.models.list()[\"data\"]\n\n        # Check if the system message is valid\n        assert len(system_message) > 0\n\n        # Check if the prompt is valid\n        assert len(prompt) > 0\n\n        # Check if the parameters are valid\n        for param in kwargs:\n            assert param in LLM_GENERATION_PARAMETERS\n\n        # Set the default parameters\n        params = {\n            \"temperature\": 0.7,\n            \"top_p\": 1.0,\n            \"frequency_penalty\": 0.0,\n            \"presence_penalty\": 0.0,\n            \"max_new_tokens\": 512,\n        }\n\n        # Update the parameters with the provided values\n        params.update(kwargs)\n\n        # Set the request body\n        data = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            \"temperature\": params[\"temperature\"],\n            \"top_p\": params[\"top_p\"],\n            \"frequency_penalty\": params[\"frequency_penalty\"],\n            \"presence_penalty\": params[\"presence_penalty\"],\n            \"max_tokens\": params[\"max_new_tokens\"],\n        }\n\n        # Make the request\n        response = self.client.chat.completions.create(data)\n\n        # Check if the response is successful\n        if response.status_code == 200:\n            # Process the response\n            response_data = response.json()\n            text = response_data[\"choices\"][0][\"message\"][\"content\"]\n            # Remove the parsing helper tokens from the response\n            if model.parsing_helper_token is not None:\n                text = text.replace(model.parsing_helper_token, \"\")\n            return text\n        else:\n            # Handle the failure\n            print(f\"Error: {response.status_code} {response.reason}\")\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        if not isinstance(model, OpenAIConfig):\n            raise TypeError(\"model must be of type OpenAIConfig\")\n        if not isinstance(system_message, str):\n            raise TypeError(\"system_message must be of type str\")\n        if not isinstance(prompt, str):\n            raise TypeError(\"prompt must be of type str\")\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {key}\")\n            if not isinstance(value, (int, float)):\n                raise TypeError(f\"Parameter {key} must be of type int or float\")\n\n        # Define the retry parameters\n        max_retries = 5\n        initial_delay = 1  # seconds\n        backoff_factor = 2\n\n        # Define the helper tokens\n        start_token = model.start_token\n        end_token = model.end_token\n\n        # Define the request payload\n        payload = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            **kwargs\n        }\n\n        # Define the response processing function\n        def process_response(response):\n            # Remove the helper tokens from the response\n            response = response.replace(start_token, \"\").replace(end_token, \"\")\n            return response\n\n        # Define the request function\n        def request():\n            # Make the request and handle any errors\n            try:\n                response = self.client.chat.completions.create(**payload)\n                return process_response(response.choices[0].message.content)\n            except Exception as e:\n                logging.warning(f\"Error occurred: {e}\")\n                return None\n\n        # Perform the request with retries and exponential backoff\n        for retry in range(max_retries):\n            response = request()\n            if response is not None:\n                return response\n            time.sleep(initial_delay * backoff_factor ** retry)\n\n        # If all retries failed, raise an exception\n        raise Exception(\"Failed to generate response after all retries\")\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate the parameters\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(\"Invalid model type. Expected OpenAIConfig.\")\n        if not isinstance(system_message, str):\n            raise ValueError(\"Invalid system_message type. Expected str.\")\n        if not isinstance(prompt, str):\n            raise ValueError(\"Invalid prompt type. Expected str.\")\n        for key in kwargs.keys():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter '{key}'. Expected one of {LLM_GENERATION_PARAMETERS}.\")\n            if not isinstance(kwargs[key], (int, float)):\n                raise ValueError(f\"Invalid value for '{key}'. Expected int or float.\")\n\n        # define the helper function to generate the response\n        def _generate(retries=5, backoff=1):\n            # initialise the client\n            self.client = OpenAI(api_key=self.api_key)\n\n            # create the request payload\n            payload = {\n                \"model\": model.model_name,\n                \"temperature\": model.temperature,\n                \"top_p\": model.top_p,\n                \"frequency_penalty\": model.frequency_penalty,\n                \"presence_penalty\": model.presence_penalty,\n                \"max_tokens\": model.max_tokens,\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": prompt},\n                ],\n            }\n            # add the additional parameters to the payload\n            payload.update(kwargs)\n\n            # send the request\n            response = self.client.chat.completions.create(**payload)\n\n            # handle the response\n            if response.status_code == 200:\n                # process the response\n                text = response.json()[\"choices\"][0][\"message\"][\"content\"]\n                # remove any parsing helper tokens\n                text = text.replace(model.parsing_helper_token, \"\")\n                return text\n            else:\n                # handle errors\n                if retries > 0:\n                    # retry with exponential backoff\n                    time.sleep(backoff)\n                    return _generate(retries - 1, backoff * 2)\n                else:\n                    # raise an exception\n                    raise Exception(f\"Error generating response: {response.status_code} - {response.text}\")\n\n        # call the helper function to generate the response\n       "}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    # Check if the matrix is square\n    assert_is_square(x)\n\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have diagonal elements close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on its diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on its diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on its diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zeros on the diagonal\")\n\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the model and the align statements\n        model, align_statements = self.get_model_and_align_statements(function_description, llm_parameters)\n\n        # get the prompt\n        prompt = self.get_prompt(function_description, args, kwargs, align_statements)\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the model and the align statements\n        model, align_statements = self.get_model_and_align_statements(function_description, llm_parameters)\n\n        # get the prompt\n        prompt = self.get_prompt(function_description, args, kwargs, align_statements)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.is_distilled_model(model, prompt)\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the model and the align statements\n        model, align_statements = self.get_model_and_align_statements(function_description, llm_parameters)\n\n        # get the prompt\n        prompt = self.get_prompt(function_description, args, kwargs, align_statements)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.is_distilled_model(model, prompt)\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the model and the align statements\n        model, align_statements = self.get_model_and_align_statements(function_description, llm_parameters)\n\n        # get the"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # initialize the function if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the model and prompt for the function\n        model, prompt = self.get_model_and_prompt(args, kwargs, function_description, llm_parameters)\n        # check if the model is suitable for distillation\n        is_distilled_model = model.is_distilled_model\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        already_initialized = self.initialized_functions[func_hash][\"model\"] == model.model_name\n        save_to_finetune = not already_initialized\n\n        # if the model is suitable for distillation and the function is not already initialized, save the example to the function's examples for fine-tuning\n        if is_distilled_model and not already_initialized:\n            self.initialized_functions[func_hash][\"examples\"].append(\n                FunctionExample(args, kwargs, function_description.output_type_hint))\n\n        # return the prompt, model, save_to_finetune, and is_distilled_model\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the model and align statements for the function\n        model, align_statements = self.function_modeler.get_model_and_align_statements(function_description,\n                                                                                       func_hash)\n\n        # Initialize the function if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # Get the current function setup\n        current_function_setup = self.initialized_functions[func_hash]\n\n        # Get the current align statements\n        current_align_statements = current_function_setup[\"examples\"]\n\n        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if current_align_statements and current_function_setup[\"model\"] == model.model_name:\n            save_to_finetune = False\n        else:\n            save_to_finetune = True\n\n        # Check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(model)\n\n        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if current_align_statements and current_function_setup[\"model\"] == model.model_name:\n            save_to_finetune = False\n        else:\n            save_to_finetune = True\n\n        # Check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(model)\n\n        # Construct the prompt\n        prompt = self.function_modeler.construct_prompt(function_description,\n                                                        args,\n                                                        kwargs,\n                                                        align_statements,\n                                                        llm_parameters)\n\n        # Update the function setup with the current align statements and model\n        current_function_setup[\"examples\"] = align_statements\n        current_function_setup[\"model\"] = model.model_name\n\n        # Return the prompt, model, and booleans indicating if the model is suitable for distillation and if the function is already initialized\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model and the prompt\n        model, prompt = self._get_model_and_prompt(args, kwargs, function_description, llm_parameters)\n\n        # check if the function is already initialized and if the model is suitable for distillation\n        is_distilled_model = False\n        save_to_finetune = True\n        if func_hash in self.initialized_functions:\n            # if the function is already initialized, check if the model is suitable for distillation\n            if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                is_distilled_model = True\n                save_to_finetune = False\n\n        # if the function is not already initialized, initialize it and save the examples for fine-tuning\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n            save_to_finetune = True\n\n        # if the model is suitable for distillation, check if the token count is within the limit\n        if is_distilled_model:\n            if self._check_token_count(prompt, model, llm_parameters):\n                save_to_finetune = False\n\n        # if the function is not already initialized, initialize it and save the examples for fine-tuning\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n            save_to_finetune = True\n\n        # if the model is suitable for distillation, check if the token count is within the limit\n        if is_distilled_model:\n            if self._check_token_count(prompt, model, llm_parameters):\n                save_to_finetune = False\n\n        # if the function is not already initialized, initialize it and save the examples for fine-tuning\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n            save_to_finetune = True\n\n        # if the model is suitable for distillation, check if the token count is within the limit\n        if is_distilled_model:"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # check if the function has a distilled model\n        distilled_model = self.function_modeler.get_distilled_model(function_description)\n\n        # check if the function has a teacher model\n        teacher_model = self.function_modeler.get_teacher_model(function_description)\n\n        # check if the function has a teacher model and the distilled model is not suitable for distillation\n        if teacher_model and not distilled_model.suitable_for_distillation:\n            # if so, use the teacher model for fine-tuning\n            model = teacher_model\n            save_to_finetune = True\n            is_distilled_model = False\n        else:\n            # otherwise, use the distilled model for zero-shot prompting\n            model = distilled_model\n            save_to_finetune = False\n            is_distilled_model = True\n\n        # get the prompt\n        prompt = self.get_prompt(args, kwargs, function_description, model)\n\n        # get the token count\n        token_count = approximate_token_count(prompt)\n\n        # check if the token count is within the limit\n        if token_count > model.token_limit:\n            # if not, use the teacher model for fine-tuning\n            model = teacher_model\n            save_to_finetune = True\n            is_distilled_model = False\n\n        # get the token count again\n        token_count = approximate_token_count(prompt)\n\n        # check if the token count is within the limit\n        if token_count > model.token_limit:\n            # if not, use the teacher model for fine-tuning\n            model = teacher_model\n            save_to_finetune = True\n            is_distilled_model = False\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if func_"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the function model\n        model = self.function_modeler.get_function_model(function_description)\n        # get the function examples\n        examples = self.function_modeler.get_function_examples(function_description)\n        # get the token count\n        token_count = self.token_counts.get(func_hash, None)\n        # if the token count is not there, calculate it\n        if token_count is None:\n            token_count = approximate_token_count(function_description.prompt_template, args, kwargs)\n            self.token_counts[func_hash] = token_count\n        # if the function is not initialized, initialize it\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n        # if the function is initialized, check if it needs to be updated\n        if func_hash in self.initialized_functions and len(examples) != len(self.initialized_functions[func_hash][\"examples\"]):\n            self.initialized_functions[func_hash][\"examples\"] = examples\n        # if the function is initialized, check if it needs to be updated\n        if func_hash in self.initialized_functions and self.initialized_functions[func_hash][\"model\"] != model.model_name:\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n        # get the prompt\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs)\n        # get the function model\n        model = self.function_modeler.get_function_model(function_description)\n        # check if the function is initialized\n        is_initialized = func_hash in self.initialized_functions\n        # check if the function is initialized and does not require saving examples for fine-tuning\n        if is_initialized and not self.function_modeler.save_examples_for_finetuning(function_description):\n            save_to_finetune = False\n        else:\n            save_to_finetune = True\n        # check if the function is initialized and does not require saving examples for fine-tuning\n        if is_initialized and not self.function_modeler.save_examples_for_finetuning(function_description):\n            save_"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the model and prompt for the function description\n        model, prompt = self.function_modeler.get_model_and_prompt(function_description, args, kwargs, llm_parameters)\n\n        # Check if the function is already initialized\n        initialized_function = self.initialized_functions.get(func_hash, None)\n        save_to_finetune = False\n\n        # If the function is not initialized, initialize it\n        if not initialized_function:\n            self.initialized_functions[func_hash] = {\n                \"model\": model.model_name,\n                \"examples\": [],\n                \"align_statements\": []\n            }\n            initialized_function = self.initialized_functions.get(func_hash, None)\n\n        # Check if the function has align statements\n        if initialized_function[\"align_statements\"]:\n            # If the function has align statements, use the align statements for generation\n            prompt = initialized_function[\"align_statements\"]\n            model = BaseModelConfig(model.provider, model.model_name, model.system_message)\n            save_to_finetune = True\n\n        # Check if the function is initialized and has examples for fine-tuning\n        elif initialized_function[\"examples\"]:\n            # If the function is initialized and has examples for fine-tuning, use the examples for fine-tuning\n            prompt = initialized_function[\"examples\"]\n            model = BaseModelConfig(model.provider, model.model_name, model.system_message)\n            save_to_finetune = True\n\n        # Check if the function is initialized and has examples for fine-tuning\n        elif initialized_function[\"examples\"]:\n            # If the function is initialized and has examples for fine-tuning, use the examples for fine-tuning\n            prompt = initialized_function[\"examples\"]\n            model = BaseModelConfig(model.provider, model.model_name, model.system_message)\n            save_to_finetune = True\n\n        # Check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(function_description, model, args, kwargs,\n                                                                      llm_parameters)\n\n        # Check if the model is suitable for distillation and the token count is within the limit\n        if is_distilled_model and approximate_token_count(prompt) <= self.default"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Initialize function-specific data if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] != \"\":\n            return self._construct_prompt(args, kwargs, function_description, llm_parameters), self.api_provider[\n                self.initialized_functions[func_hash][\"model\"]], False, False\n\n        # Get the model to use for generation\n        model = self.function_modeler.get_model(function_description, llm_parameters)\n\n        # Check if the model is suitable for distillation and has sufficient tokens for the prompt\n        if model.distillable and self._sufficient_tokens(function_description, args, kwargs, model, llm_parameters):\n            # Construct the prompt for zero-shot prompting\n            prompt = self._construct_prompt(args, kwargs, function_description, llm_parameters)\n            return prompt, model, True, True\n\n        # If the model is not suitable for distillation or has insufficient tokens, use a teacher model for fine-tuning\n        self.initialized_functions[func_hash][\"model\"] = model.model_name\n        prompt = self._construct_prompt(args, kwargs, function_description, llm_parameters)\n        return prompt, model, False, True\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # initialize function-specific data if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"examples\": [], \"model\": \"\"}\n\n        # get the function-specific data\n        function_data = self.initialized_functions[func_hash]\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        initialized = False\n        if function_data[\"examples\"]:\n            initialized = True\n\n        # check if the function is suitable for distillation\n        # if not initialized and function_description.suitable_for_distillation:\n        #     # select a distilled model for zero-shot prompting\n        #     model = self.api_provider.get_distilled_model(function_description.name)\n        #     # construct the prompt for zero-shot prompting\n        #     prompt = self.function_modeler.get_prompt(function_description, args, kwargs, \"zero-shot\")\n        #     # return the prompt, model, and a boolean indicating that the model is suitable for distillation\n        #     return prompt, model, True, True\n        # else:\n        #     # select a teacher model for fine-tuning\n        #     model = self.api_provider.get_teacher_model(function_description.name)\n        #     # construct the prompt for fine-tuning\n        #     prompt = self.function_modeler.get_prompt(function_description, args, kwargs, \"finetune\")\n        #     # return the prompt, model, and a boolean indicating that the model is not suitable for distillation\n        #     return prompt, model, False, False\n\n        # select a teacher model for fine-tuning\n        model = self.api_provider.get_teacher_model(function_description.name)\n        # construct the prompt for fine-tuning\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs, \"finetune\")\n        # return the prompt, model, and a boolean indicating that the model is not suitable for distillation\n        return prompt, model, False, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Initialize function-specific data if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"examples\"]:\n            save_to_finetune = False\n        else:\n            save_to_finetune = True\n\n        # Determine the model to use based on the function description\n        model = self.function_modeler.get_model_for_function(function_description, llm_parameters)\n\n        # Check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(model)\n\n        # Get the token count for the function description\n        token_count = approximate_token_count(function_description.prompt, model.tokenizer)\n        self.token_counts[func_hash] = token_count\n\n        # Construct the prompt\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs, model)\n\n        # Return the prompt, the selected model, and a boolean indicating if the model is suitable for distillation\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.function_modeler.get_model(function_description, llm_parameters)\n        # get the prompt\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(function_description, model)\n\n        # check if the function is already initialized\n        initialized_function = self.initialized_functions.get(func_hash, None)\n        if initialized_function:\n            # if it is, check if the current model is the same as the one used previously\n            if initialized_function[\"model\"] == model.model_name:\n                # if it is, check if the function is already initialized\n                if initialized_function[\"initialized\"]:\n                    # if it is, check if the function is already initialized\n                    if initialized_function[\"initialized\"]:\n                        # if it is, return the prompt, model, and a boolean indicating that the function is already initialized and does not require saving examples for fine-tuning\n                        return prompt, model, False, is_distilled_model\n\n        # if the function is not already initialized, initialize it and update the initialized_functions dictionary\n        self.initialized_functions[func_hash] = {\"initialized\": True, \"model\": model.model_name, \"examples\": []}\n        # check if the function is suitable for distillation\n        if is_distilled_model:\n            # if it is, return the prompt, model, a boolean indicating that the function is suitable for distillation, and a boolean indicating that the function is not already initialized and requires saving examples for fine-tuning\n            return prompt, model, True, is_distilled_model\n        # if the function is not suitable for distillation, check if the function has any align statements\n        if initialized_function and initialized_function[\"examples\"]:\n            # if it does, return the prompt, model, a boolean indicating that the function is not suitable for distillation, and a boolean indicating that the function is not already initialized and requires saving examples for fine-tuning\n            return prompt, model, False, is_distilled_model\n        # if the function does not have any align statements, check if the function has any examples\n        if function_description.examples:\n           "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        initialized_function = self.initialized_functions.get(func_hash, None)\n        if not initialized_function:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {\"examples\": [], \"model\": \"\"}\n            initialized_function = self.initialized_functions[func_hash]\n\n        # get the model and prompt\n        model, prompt = self.get_model_and_prompt(args, kwargs, function_description, llm_parameters, func_hash)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(func_hash, function_description)\n\n        # check if the function is already initialized\n        already_initialized = initialized_function.get(\"initialized\", False)\n\n        # check if the model is suitable for distillation and the token count is within the limit\n        if is_distilled_model and approximate_token_count(prompt) < model.token_limit:\n            # if so, use the distilled model and do not save examples for fine-tuning\n            save_to_finetune = False\n        else:\n            # otherwise, use the teacher model and save examples for fine-tuning\n            save_to_finetune = True\n            # if the function is already initialized, do not save examples for fine-tuning\n            if already_initialized:\n                save_to_finetune = False\n\n        # if the function is not already initialized, initialize it\n        if not already_initialized:\n            # update the initialized function with the examples and set the initialized flag to True\n            initialized_function[\"examples\"] = self.function_modeler.get_examples(function_description)\n            initialized_function[\"initialized\"] = True\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function has already been initialized\n        initialized_function = self.initialized_functions.get(func_hash, None)\n\n        # If the function is not initialized, initialize it\n        if initialized_function is None:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": [],\n                \"align_statements\": []\n            }\n            initialized_function = self.initialized_functions.get(func_hash)\n\n        # Check if the function has align statements\n        align_statements = initialized_function.get(\"align_statements\", [])\n\n        # Check if the function has examples for fine-tuning\n        examples = initialized_function.get(\"examples\", [])\n\n        # If the function has align statements, use them for zero-shot prompting\n        if len(align_statements) > 0:\n            prompt = self.function_modeler.get_prompt_with_align_statements(function_description, align_statements)\n            model = self.api_provider.get_model(function_description.name, \"zero_shot\")\n            save_to_finetune = False\n            is_distilled_model = True\n            return prompt, model, save_to_finetune, is_distilled_model\n\n        # If the function has examples for fine-tuning, use them for fine-tuning\n        elif len(examples) > 0:\n            prompt = self.function_modeler.get_prompt_with_examples(function_description, examples)\n            model = self.api_provider.get_model(function_description.name, \"finetune\")\n            save_to_finetune = False\n            is_distilled_model = False\n            return prompt, model, save_to_finetune, is_distilled_model\n\n        # If the function has no examples and no align statements, use the teacher model for zero-shot prompting\n        else:\n            prompt = self.function_modeler.get_prompt_without_examples(function_description, args, kwargs)\n            model = self.api_provider.get_model(function_description.name, \"zero_shot\")\n            save_to_finetune = True\n            is_distilled_model = False\n            return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self.function_modeler.get_model_for_function(function_description, llm_parameters)\n        # get the prompt\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs)\n        # get the examples\n        examples = self.function_modeler.get_examples(function_description)\n        # get the current function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n        # if the function is not initialized\n        if not current_function_setup:\n            # initialize the function setup\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": examples}\n            current_function_setup = self.initialized_functions[func_hash]\n        # if the model is different than the one used for the current function setup\n        if current_function_setup[\"model\"] != model.model_name:\n            # update the function setup with the current model\n            current_function_setup[\"model\"] = model.model_name\n            # update the function setup with the current examples\n            current_function_setup[\"examples\"] = examples\n            # reset the function modeler\n            self.function_modeler.reset_function_modeler(function_description)\n        # if the model is a teacher model\n        if model.model_type == \"teacher\":\n            # check if the function is already initialized\n            if current_function_setup[\"examples\"] == examples:\n                # if it is, set the save_to_finetune flag to False\n                save_to_finetune = False\n            else:\n                # otherwise, set the save_to_finetune flag to True\n                save_to_finetune = True\n                # update the function setup with the current examples\n                current_function_setup[\"examples\"] = examples\n            # set the is_distilled_model flag to False\n            is_distilled_model = False\n        else:\n            # if the model is a distilled model\n            # check if the function is already initialized\n            if current_function_setup[\"examples\"] == examples:\n                # if it is, set the save_to_finetune flag to False\n                save_to_finetune = False\n            else:\n                # otherwise, set the save_to_finetune flag to True"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if we have already initialized the function\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n        if current_function_setup:\n            model = current_function_setup[\"model\"]\n            examples = current_function_setup[\"examples\"]\n            if len(examples) > 0:\n                save_to_finetune = False\n            else:\n                save_to_finetune = True\n        else:\n            # if not, initialize it\n            model = self.function_modeler.get_model_for_function(function_description, llm_parameters)\n            examples = []\n            save_to_finetune = True\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": examples}\n        # check if we have a distilled model\n        if model.distilled_model:\n            # if we have a distilled model, check if we can use it\n            if self.function_modeler.can_distill(function_description, model):\n                # if we can use it, construct the prompt\n                prompt = self.function_modeler.get_prompt(function_description, args, kwargs, model)\n                # check if the function is already initialized\n                if current_function_setup:\n                    # if it is, check if the function is already initialized\n                    if len(examples) > 0:\n                        # if it is, check if the function is already initialized\n                        save_to_finetune = False\n                    else:\n                        save_to_finetune = True\n                else:\n                    # if it is not, initialize it\n                    self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": examples}\n                # check if we have a distilled model\n                if model.distilled_model:\n                    # if we have a distilled model, check if we can use it\n                    if self.function_modeler.can_distill(function_description, model):\n                        # if we can use it, construct the prompt\n                        prompt = self.function_modeler.get_prompt(function_description, args, kwargs, model)\n                        # check if the function is already initialized\n                        if current_function_setup:\n                            # if it is, check if the function is already initialized\n                            if len(examples"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function has been initialized\n        function_setup = self.initialized_functions.get(func_hash, None)\n\n        # if not, initialize the function\n        if function_setup is None:\n            function_setup = self.initialize_function(function_description, func_hash)\n            self.initialized_functions[func_hash] = function_setup\n\n        # get the model and align statements\n        model = function_setup[\"model\"]\n        align_statements = function_setup[\"align_statements\"]\n        examples = function_setup[\"examples\"]\n        save_to_finetune = False\n        is_distilled_model = False\n\n        # get the token count for the function\n        token_count = self.token_counts.get(func_hash, None)\n        if token_count is None:\n            token_count = approximate_token_count(align_statements)\n            self.token_counts[func_hash] = token_count\n\n        # check if the model is suitable for distillation\n        if model.can_distill:\n            # check if the model has enough examples to distill\n            if len(examples) >= model.min_examples_for_distillation:\n                # check if the token count is within the model's limit\n                if token_count <= model.max_token_count:\n                    is_distilled_model = True\n\n        # if the model is not suitable for distillation or the token count is too high, use a teacher model\n        if not is_distilled_model:\n            # check if the model has enough examples to fine-tune\n            if len(examples) >= model.min_examples_for_finetuning:\n                # check if the token count is within the model's limit\n                if token_count <= model.max_token_count:\n                    # use a teacher model for fine-tuning\n                    model = model.teacher_model\n                    save_to_finetune = True\n\n        # construct the prompt\n        prompt = self.function_modeler.construct_prompt(function_description, args, kwargs, align_statements, model)\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # initialize function specific data\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # get the model and align statements\n        model, align_statements = self.function_modeler.get_generation_case(function_description, args, kwargs,\n                                                                            llm_parameters)\n        # check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(model)\n\n        # get the prompt\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs, align_statements)\n\n        # update examples for fine-tuning\n        if self.function_modeler.is_finetune_model(model):\n            self.function_modeler.update_finetune_examples(function_description, args, kwargs, self.initialized_functions[func_hash][\"examples\"])\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        save_to_finetune = self.initialized_functions[func_hash][\"examples\"] == []\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model = self.function_modeler.get_model(function_description)\n        if not model:\n            model = self.api_provider.get_default_model()\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs)\n        if not self.initialized_functions.get(func_hash, None):\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n        examples = self.initialized_functions[func_hash][\"examples\"]\n        if len(examples) < 10:\n            examples.append(prompt)\n            self.initialized_functions[func_hash][\"examples\"] = examples\n        else:\n            self.initialized_functions[func_hash][\"examples\"] = []\n\n        token_count = approximate_token_count(prompt)\n        if token_count > 512:\n            return prompt, model, False, False\n        else:\n            return prompt, model, True, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # initialize the function if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": [],\n                \"align_statements\": []\n            }\n\n        # get the model and align statements\n        model = self.function_modeler.get_generation_model(function_description, func_hash)\n        align_statements = self.function_modeler.get_align_statements(function_description, func_hash)\n        self.initialized_functions[func_hash][\"align_statements\"] = align_statements\n        # get the token count for the function description\n        token_count = approximate_token_count(function_description.name, function_description.docstring,\n                                               function_description.example_inputs,\n                                               function_description.example_outputs,\n                                               function_description.output_type_hint)\n        self.token_counts[func_hash] = token_count\n\n        # if the token count is within the range for distillation, use a distilled model\n        if model.can_distill and token_count < model.distillation_token_limit:\n            prompt = self.function_modeler.get_zero_shot_prompt(function_description, args, kwargs, align_statements)\n            return prompt, model, False, True\n\n        # if the token count is within the range for fine-tuning, use a teacher model\n        elif model.can_finetune and token_count < model.finetuning_token_limit:\n            # get the examples from the function modeler\n            examples = self.function_modeler.get_examples(function_description, func_hash)\n            # update the examples in the initialized_functions dictionary\n            self.initialized_functions[func_hash][\"examples\"] = examples\n            prompt = self.function_modeler.get_finetune_prompt(function_description, examples, align_statements)\n            return prompt, model, True, False\n\n        # otherwise, use the default model\n        else:\n            prompt = self.function_modeler.get_zero_shot_prompt(function_description, args, kwargs, align_statements)\n            return prompt, model, False, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model = self.function_modeler.get_model_for_function(function_description)\n        model_type = model.model_type\n        model_provider = model.provider\n        model_name = model.model_name\n        is_distilled_model = model_type == \"distilled\"\n        save_to_finetune = not is_distilled_model\n        # if not initialized, initialize\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"examples\": [], \"model\": \"\"}\n            # if it's a distilled model, initialize it\n            if is_distilled_model:\n                self.function_modeler.initialize_distilled_model(function_description, model_provider, model_name)\n            # if it's a teacher model, initialize it and add the align statements\n            else:\n                self.function_modeler.initialize_teacher_model(function_description, model_provider, model_name)\n                self.initialized_functions[func_hash][\"examples\"] = self.function_modeler.get_align_statements(\n                    function_description, model_provider, model_name)\n\n        # if it's a distilled model, check if the token count is within the limits\n        if is_distilled_model:\n            token_count = approximate_token_count(self.function_modeler.get_prompt_for_function(function_description, args, kwargs, model_provider, model_name, is_distilled_model))\n            self.token_counts[func_hash] = token_count\n            if token_count > llm_parameters.get(\"max_tokens\", 512):\n                is_distilled_model = False\n                model = self.function_modeler.get_model_for_function(function_description)\n                model_type = model.model_type\n                model_provider = model.provider\n                model_name = model.model_name\n                save_to_finetune = True\n                self.initialized_functions[func_hash][\"model\"] = model.model_name\n\n        # if it's a teacher model, check if there are any examples to fine-tune on\n        if not is_distilled_model:\n            if len(self.initialized_functions[func_"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check that the input is a square matrix\n    if cov.ndim != 2 or cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input matrix must be a square matrix\")\n\n    # Check that the input is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input matrix must be symmetric\")\n\n    # Check that the input is a covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a covariance matrix\")\n\n    # Check that the input is positive definite\n    if not is_positive_definite(cov):\n        raise ValueError(\"The input matrix must be positive definite\")\n\n    # Check that the input allows for a Cholesky decomposition\n    if not is_cholesky_dec(cov):\n        raise ValueError(\"The input matrix must allow for a Cholesky decomposition\")\n\n    # Check that the input is a valid covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a valid covariance matrix\")\n\n    # Check that the input is a valid covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a valid covariance matrix\")\n\n    # Check that the input is a valid covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a valid covariance matrix\")\n\n    # Check that the input is a valid covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a valid covariance matrix\")\n\n    # Check that the input is a valid covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a valid covariance matrix\")\n\n    # Check that the input is a valid covariance matrix\n    if not np.allclose(np.diag(cov), np.ones(cov.shape[0])):\n        raise ValueError(\"The input matrix must be a valid covariance matrix\")\n\n    # Check that the"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the covariance matrix is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The covariance matrix must be square\")\n\n    # Check if the covariance matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The covariance matrix must be symmetric\")\n\n    # Check if the covariance matrix is positive semi-definite\n    if not np.all(np.linalg.eigvals(cov) >= 0):\n        raise ValueError(\"The covariance matrix must be positive semi-definite\")\n\n    # Check if the covariance matrix is positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        raise ValueError(\"The covariance matrix must be positive definite\")\n\n    # Check if the covariance matrix is invertible\n    if not np.linalg.det(cov) > 0:\n        raise ValueError(\"The covariance matrix must be invertible\")\n\n    # Check if the covariance matrix is positive definite and allows for a Cholesky decomposition\n    if not is_cholesky_dec(cov):\n        raise ValueError(\n            \"The covariance matrix must be positive definite and allow for a Cholesky decomposition\"\n        )\n\n    # Check if the covariance matrix has diagonal elements close to zeros\n    if not np.allclose(np.diag(cov), np.zeros(cov.shape[0]), atol=1e-5):\n        raise ValueError(\n            \"The covariance matrix must have diagonal elements close to zeros\"\n        )\n\n    # Check if the covariance matrix is symmetric and positive definite\n    if not np.allclose(cov, cov.T) or not np.all(np.linalg.eigvals(cov) > 0):\n        raise ValueError(\n            \"The covariance matrix must be symmetric and positive definite\"\n        )\n\n    # Check if the covariance matrix is positive semi-definite\n    if not np.all(np.linalg.eigvals(cov) >= 0):\n        raise ValueError(\"The covariance matrix must be positive semi-definite\")\n\n    # Check if the covariance matrix is positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        raise ValueError(\"The covariance matrix must be positive definite\")\n\n    # Check if the covariance matrix is invertible\n    if not np.linalg.det(cov) > 0:\n        raise ValueError"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        eigval, eigvec = np.linalg.eigh(cov)\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        tmp = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n        cov = np.dot(tmp, tmp)\n    else:\n        # Clipping eigenvalues\n        eigval, eigvec = np.linalg.eigh(cov)\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if higham:\n        # Higham & Nick (2002) algorithm\n        # https://www.maths.manchester.ac.uk/~higham/narep/narep379.pdf\n        n = cov.shape[0]\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals[eigvals < 0] = 0\n        eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_sqrt = np.dot(eigvecs, np.dot(np.diag(np.sqrt(eigvals)), eigvecs.T))\n        cov_sqrt_inv = np.linalg.inv(cov_sqrt)\n        cov_new = np.dot(cov_sqrt_inv, np.dot(cov, cov_sqrt_inv))\n        # Ensure symmetry\n        cov_new = (cov_new + cov_new.T) / 2\n        # Ensure positive-definiteness\n        eigvals, eigvecs = np.linalg.eigh(cov_new)\n        eigvals[eigvals < 0] = 0\n        cov_new = np.dot(eigvecs, np.dot(np.diag(eigvals), eigvecs.T))\n        # Ensure symmetry\n        cov_new = (cov_new + cov_new.T) / 2\n        # Ensure positive-definiteness\n        for _ in range(higham_max_iteration):\n            eigvals, eigvecs = np.linalg.eigh(cov_new)\n            eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n            cov_sqrt = np.dot(eigvecs, np.dot(np.diag(np.sqrt(eigvals)), eigvecs.T))\n            cov_sqrt_inv = np.linalg.inv(cov_sqrt)\n            cov_new = np.dot(cov_sqrt_inv, np.dot(cov, cov_sqrt_inv))\n            # Ensure symmetry\n            cov_new = (cov_new + cov_new.T) / 2\n            # Ensure positive-definiteness\n           "}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if higham:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        corr, std = cov_to_corr(cov)\n        eigval, eigvec = np.linalg.eigh(corr)\n        eigval[eigval < 0] = 0\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        corr = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n        cov = corr_to_cov(corr, std)\n        return cov\n    else:\n        # Clipping eigenvalues\n        n = cov.shape[0]\n        corr, std = cov_to_corr(cov)\n        eigval, eigvec = np.linalg.eigh(corr)\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        corr = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n        cov = corr_to_cov(corr, std)\n        return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    # Check if the input is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input matrix must be symmetric\")\n\n    # Check if the input is positive semi-definite\n    if not np.all(np.linalg.eigvals(cov) >= 0):\n        raise ValueError(\"The input matrix must be positive semi-definite\")\n\n    # Check if the input is not positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        # If the input is not positive definite, adjust the input matrix\n        # by adding a small positive value to the diagonal\n        cov += np.eye(cov.shape[0]) * _CLIPPING_VALUE\n\n    # Check if the input is not positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        # If the input is still not positive definite, adjust the input matrix\n        # by adding a small positive value to the diagonal\n        cov += np.eye(cov.shape[0]) * _CLIPPING_VALUE\n\n    # Check if the input is not positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        # If the input is still not positive definite, adjust the input matrix\n        # by adding a small positive value to the diagonal\n        cov += np.eye(cov.shape[0]) * _CLIPPING_VALUE\n\n    # Check if the input is not positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        # If the input is still not positive definite, adjust the input matrix\n        # by adding a small positive value to the diagonal\n        cov += np.eye(cov.shape[0]) * _CLIPPING_VALUE\n\n    # Check if the input is not positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        # If the input is still not positive definite, adjust the input matrix\n        # by adding a small positive value to the diagonal\n        cov += np.eye(cov."}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Step 1: Check if the input matrix is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    # Step 2: Check if the input matrix is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input matrix must be square\")\n\n    # Step 3: Check if the input matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input matrix must be symmetric\")\n\n    # Step 4: Check if the input matrix is positive semi-definite\n    if not is_positive_definite(cov):\n        raise ValueError(\"The input matrix must be positive semi-definite\")\n\n    # Step 5: Check if the input matrix is positive definite\n    if not is_cholesky_dec(cov):\n        if higham:\n            # Step 6: Use the Higham & Nick (2002) algorithm to find the nearest positive definite matrix\n            cov = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n        else:\n            # Step 7: Clip eigenvalues to ensure the resulting matrix is positive definite\n            cov = _cov_nearest_clip(cov)\n\n    # Step 8: Return the nearest covariance matrix that is positive definite and allows for a Cholesky decomposition\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"`cov` must be a square matrix\")\n\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"`cov` must be a symmetric matrix\")\n\n    if np.any(np.isnan(cov)):\n        raise ValueError(\"`cov` must not contain NaN values\")\n\n    if np.any(np.isinf(cov)):\n        raise ValueError(\"`cov` must not contain infinite values\")\n\n    if np.any(np.diag(cov) <= 0):\n        raise ValueError(\"`cov` must have positive diagonal elements\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals[eigvals <= 0] = _CLIPPING_VALUE\n        cov = np.dot(eigvecs, np.dot(np.diag(eigvals), eigvecs.T))\n        cov_trace = np.trace(cov)\n        cov_rank = np.linalg.matrix_rank(cov)\n        cov_norm = np.linalg.norm(cov, \"fro\")\n        cov_cond = cov_norm * np.linalg.norm(np.linalg.inv(cov), \"fro\")\n        cov_scaled = (np.eye(n) - 1 / n * np.ones((n, n))) @ cov @ (\n            np.eye(n) - 1 / n * np.ones((n, n))\n        )\n        cov_scaled_trace = np.trace(cov_scaled)\n        cov_scaled_rank = np.linalg.matrix_rank(cov_scaled)\n        cov_scaled_norm = np.linalg.norm(cov_scaled, \"fro\")\n        cov_scaled_cond = cov_scaled_norm * np.linalg.norm(\n            np.linalg.inv(cov_scaled), \"fro\"\n        )\n        tol = 1e-7\n        k = 1\n        while k <= higham_max_iteration:\n            eigvals, eigvecs = np.linalg.e"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_adj = np.dot(eigvecs, np.dot(np.diag(eigvals), eigvecs.T))\n        cov_adj_sqrt = spl.cholesky(cov_adj, lower=True)\n        cov_adj = spl.cho_solve((cov_adj_sqrt, True), np.eye(n))\n\n        # Iterative refinement\n        for i in range(higham_max_iteration):\n            eigvals, eigvecs = np.linalg.eigh(cov_adj)\n            eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n            cov_adj = np.dot(eigvecs, np.dot(np.diag(eigvals), eigvecs.T))\n            cov_adj_sqrt = spl.cholesky(cov_adj, lower=True)\n            cov_adj = spl.cho_solve((cov_adj_sqrt, True), np.eye(n))\n\n        return cov_adj\n\n    else:\n        # Eigenvalue clipping\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_adj = np.dot(eigvecs, np.dot(np.diag(eigvals), eigvecs.T))\n        return cov_adj\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The covariance matrix must be symmetric\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        evals, evecs = np.linalg.eigh(cov)\n        evals[evals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov = np.dot(evecs * np.sqrt(evals), evecs.T)\n        y = np.dot(evecs.T, np.dot(cov, evecs))\n        count = 0\n        while not np.all(np.linalg.eigvals(y) > 0) and count < higham_max_iteration:\n            evals[evals < _CLIPPING_VALUE] *= 1.01\n            y = np.dot(evecs.T, np.dot(np.dot(evecs * np.sqrt(evals), evecs.T), evecs))\n            count += 1\n        if count == higham_max_iteration:\n            raise ValueError(\"Maximum number of iterations reached\")\n        cov = np.dot(evecs * np.sqrt(evals), evecs.T)\n    else:\n        # Clipping eigenvalues\n        evals, evecs = np.linalg.eigh(cov)\n        evals[evals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov = np.dot(evecs * np.sqrt(evals), evecs.T)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        # https://core.ac.uk/download/pdf/82108968.pdf\n        # https://core.ac.uk/download/pdf/82108968.pdf\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com/scipy/scipy/blob/v1.10.1/scipy/linalg/basic.py#L1419-L1455\n        # https://github.com"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        def _higham_iteration(x: np.ndarray) -> np.ndarray:\n            \"\"\"\n            This function performs a single iteration of the Higham & Nick (2002) algorithm for finding the nearest positive definite matrix.\n\n            Input-Output Arguments\n            :param x: np.ndarray. The input matrix to be adjusted. It is used as the base for computing the nearest positive definite matrix.\n            :return: np.ndarray. The adjusted matrix that is positive definite.\n\n            References:\n            - \"Computing the nearest correlation matrix - a problem from finance\" IMA Journal of Numerical Analysis Higham & Nick (2002)\n            \"\"\"\n            x_sqrt = np.linalg.cholesky(x).T\n            x_inv = np.linalg.inv(x_sqrt)\n            x_sqrt_inv = np.linalg.inv(x_sqrt)\n            x_adj = x_inv @ x_sqrt_inv\n            x_adj = (x_adj + x_adj.T) / 2\n            x_adj_sqrt = np.linalg.cholesky(x_adj)\n            x_adj_sqrt_inv = np.linalg.inv(x_adj_sqrt)\n            x_adj = x_adj_sqrt_inv @ x_adj_sqrt_inv.T\n            return x_adj\n\n        # Compute the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n        x = cov.copy()\n        for _ in range(higham_max_iteration):\n            x_old = x\n            x = _higham_iteration(x)\n            if np.allclose(x, x_old):\n                break\n    else:\n        # Clip eigenvalues to ensure the resulting matrix is positive definite\n        evals, evecs = np.linalg.eigh(cov)\n        evals[evals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        x = evecs @ np.diag(evals) @ evecs.T\n\n    return x\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Make sure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    # Compute the eigenvalues and eigenvectors of the input covariance matrix\n    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n\n    # Check if the input covariance matrix is positive definite\n    if np.all(eigenvalues > 0):\n        # If it is, return the input covariance matrix as is\n        return cov\n\n    # If the input covariance matrix is not positive definite, adjust it\n    if higham:\n        # Use the Higham & Nick (2002) algorithm to find the nearest positive definite matrix\n        for _ in range(higham_max_iteration):\n            # Compute the diagonal matrix of eigenvalues\n            diag_eigenvalues = np.diag(eigenvalues)\n\n            # Compute the diagonal matrix of the reciprocal of the square roots of the eigenvalues\n            diag_reciprocal_sqrt_eigenvalues = np.diag(1 / np.sqrt(eigenvalues))\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance matrix\n            matrix_square_root = eigenvectors @ diag_eigenvalues @ eigenvectors.T\n\n            # Compute the matrix square root of the input covariance"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"`cov` must be a square matrix\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        cov_adj = cov\n        iteration = 0\n        while not is_positive_definite(cov_adj) and iteration < higham_max_iteration:\n            iteration += 1\n            # Find the nearest positive definite matrix\n            cov_adj = _nearest_positive_definite(cov_adj)\n        return cov_adj\n    else:\n        # Clip eigenvalues\n        cov_adj = cov\n        iteration = 0\n        while not is_positive_definite(cov_adj) and iteration < higham_max_iteration:\n            iteration += 1\n            # Find the nearest positive definite matrix\n            cov_adj = _clip_eigenvalues(cov_adj)\n        return cov_adj\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The covariance matrix must be symmetric\")\n\n    if higham:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        eigval, eigvec = np.linalg.eigh(cov)\n        # Check if the covariance matrix is positive definite\n        if not np.all(eigval > 0):\n            # Find the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n            eigval[eigval < 0] = 0\n            cov = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n        # Check if the covariance matrix allows for a Cholesky decomposition\n        if not is_cholesky_dec(cov):\n            # Find the nearest covariance matrix that allows for a Cholesky decomposition using the Higham & Nick (2002) algorithm\n            eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n            cov = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n        return cov\n\n    else:\n        # Clip eigenvalues\n        eigval, eigvec = np.linalg.eigh(cov)\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n        return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Compute the eigenvalues and eigenvectors of the covariance matrix\n    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n\n    # Check if the covariance matrix is positive definite\n    if np.all(eigenvalues > 0):\n        return cov\n\n    # If the covariance matrix is not positive definite, adjust it using the Higham & Nick (2002) algorithm\n    if higham:\n        # Compute the threshold for eigenvalues\n        threshold = 0.1 * np.finfo(float).eps * np.max(np.abs(eigenvalues))\n\n        # Compute the adjusted eigenvalues\n        adjusted_eigenvalues = np.maximum(eigenvalues, threshold)\n\n        # Compute the adjusted covariance matrix\n        adjusted_cov = np.dot(\n            eigenvectors * adjusted_eigenvalues, eigenvectors.T\n        )  # noqa: E501\n\n        # Compute the nearest positive definite covariance matrix using the Higham & Nick (2002) algorithm\n        return cov_nearest(adjusted_cov, higham=False)\n\n    # If the covariance matrix is not positive definite, adjust it by clipping eigenvalues\n    else:\n        # Clip the eigenvalues to ensure they are positive\n        clipped_eigenvalues = np.maximum(eigenvalues, _CLIPPING_VALUE)\n\n        # Compute the clipped covariance matrix\n        clipped_cov = np.dot(\n            eigenvectors * clipped_eigenvalues, eigenvectors.T\n        )  # noqa: E501\n\n        # Compute the nearest positive definite covariance matrix using the clipped eigenvalues\n        return clipped_cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input covariance matrix is square and symmetric\n    if not (cov.ndim == 2 and cov.shape[0] == cov.shape[1]):\n        raise ValueError(\"Covariance matrix must be square and symmetric\")\n\n    # Check if the input covariance matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"Covariance matrix must be symmetric\")\n\n    # Check if the input covariance matrix is positive semi-definite\n    if not np.all(np.linalg.eigvals(cov) >= 0):\n        raise ValueError(\"Covariance matrix must be positive semi-definite\")\n\n    # Check if the input covariance matrix is positive definite\n    if not np.all(np.linalg.eigvals(cov) > 0):\n        raise ValueError(\"Covariance matrix must be positive definite\")\n\n    # Check if the input covariance matrix has positive diagonal elements\n    if not np.all(np.diag(cov) > 0):\n        raise ValueError(\"Covariance matrix must have positive diagonal elements\")\n\n    # Check if the input covariance matrix has a Cholesky decomposition\n    if not is_cholesky_dec(cov):\n        raise ValueError(\"Covariance matrix must have a Cholesky decomposition\")\n\n    # If the input covariance matrix is already positive definite and has a Cholesky decomposition, return it as is\n    if is_positive_definite(cov) and is_cholesky_dec(cov):\n        return cov\n\n    # If the input covariance matrix is not positive definite or does not have a Cholesky decomposition, proceed to adjust it\n    if not is_positive_definite(cov) or not is_cholesky_dec(cov):\n        # If the Higham & Nick (2002) algorithm is used, apply it to the input covariance matrix\n        if higham:\n            # Compute the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n            cov = cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n\n        # If the Higham & Nick (2002) algorithm is not used, clip eigenvalues of the input covariance matrix\n        else:\n            # Clip eigenvalues of the input covariance matrix to ensure it is positive definite\n            cov = cov_nearest_clipping(cov)\n\n    # Check if the adjusted"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not higham:\n        # Eigendecomposition\n        eig_values, eig_vectors = np.linalg.eigh(cov)\n        # Clip eigenvalues\n        eig_values[eig_values < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        # Reconstruct covariance matrix\n        cov = np.dot(eig_vectors * np.sqrt(eig_values), eig_vectors.T)\n        return cov\n\n    else:\n        # Higham & Nick (2002) algorithm\n        n = cov.shape[0]\n        eig_values, eig_vectors = np.linalg.eigh(cov)\n        eig_values[eig_values < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        tmp = np.dot(eig_vectors * np.sqrt(eig_values), eig_vectors.T)\n        cov = np.dot(tmp, tmp.T)\n\n        # Ensure symmetry\n        cov = (cov + cov.T) / 2\n\n        # Ensure positive semidefiniteness\n        eig_values, eig_vectors = np.linalg.eigh(cov)\n        eig_values[eig_values < 0] = 0\n        cov = np.dot(eig_vectors * np.sqrt(eig_values), eig_vectors.T)\n\n        # Ensure covariance matrix is positive definite\n        for _ in range(higham_max_iteration):\n            eig_values, eig_vectors = np.linalg.eigh(cov)\n            eig_values[eig_values < _CLIPPING_VALUE] = _CLIPPING_VALUE\n            tmp = np.dot(eig_vectors * np.sqrt(eig_values), eig_vectors.T)\n            cov_new = np.dot(tmp, tmp.T)\n            if np.allclose(cov, cov_new):\n                break\n            cov = cov_new\n\n        return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"`cov` must be a square matrix\")\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"`cov` must be a symmetric matrix\")\n\n    # Compute the eigenvalues and eigenvectors of the covariance matrix\n    eigval, eigvec = np.linalg.eigh(cov)\n\n    # Clip the eigenvalues to ensure they are positive\n    eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n\n    # Reconstruct the covariance matrix using the clipped eigenvalues and the original eigenvectors\n    cov_new = np.dot(eigvec, np.dot(np.diag(eigval), eigvec.T))\n\n    return cov_new\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002) algorithm\n        # See: https://www.maths.manchester.ac.uk/~higham/narep/narep474.pdf\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L448-L587\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L625-L716\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L764-L803\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L805-L839\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L841-L868\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L870-L905\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L907-L933\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L935-L968\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L970-L999\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/linalg/matfuncs.py#L1001-L1035\n        # See: https://github.com/scipy/scipy/blob/v1.10.0/scipy/"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home=data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema()\n    elif isinstance(obj, str):\n        return obj, IdentitySchema()\n    elif isinstance(obj, bytes):\n        return obj, IdentitySchema()\n    elif isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = zip(*res)\n        return values, ListSchema(schemas)\n    elif isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = zip(*res)\n        return values, TupleSchema(schemas)\n    elif isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(k) for k in obj.values()]\n        values, schemas = zip(*res)\n        return values, DictSchema(schemas, list(obj.keys()))\n    elif isinstance(obj, Instances):\n        return flatten_to_tuple(obj.get_fields())\n    elif isinstance(obj, Boxes):\n        return flatten_to_tuple(obj.tensor)\n    elif isinstance(obj, RotatedBoxes):\n        return flatten_to_tuple(obj.tensor)\n    elif isinstance(obj, BitMasks):\n        return flatten_to_tuple(obj.tensor)\n    elif isinstance(obj, ROIMasks):\n        return flatten_to_tuple(obj.tensor)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return obj, IdentitySchema()\n    if isinstance(obj, bytes):\n        return obj, IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema()\n    if isinstance(obj, list):\n        schemas = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in schemas])\n        return values, ListSchema([k[1] for k in schemas], sizes)\n    if isinstance(obj, tuple):\n        schemas = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in schemas])\n        return values, TupleSchema([k[1] for k in schemas], sizes)\n    if isinstance(obj, collections.abc.Mapping):\n        schemas = [flatten_to_tuple(v) for v in obj.values()]\n        values, sizes = ListSchema._concat([k[0] for k in schemas])\n        return values, DictSchema([k[1] for k in schemas], sizes, list(obj.keys()))\n    if isinstance(obj, Instances):\n        schemas = [flatten_to_tuple(v) for v in obj.get_fields().values()]\n        values, sizes = ListSchema._concat([k[0] for k in schemas])\n        return values, InstancesSchema([k[1] for k in schemas], sizes)\n    if isinstance(obj, Boxes):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n    if isinstance(obj, ROIMasks):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    if isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = TupleSchema._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], sizes)\n    if isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(v) for v in obj.values()]\n        values, sizes = DictSchema._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], sizes, list(obj.keys()))\n    if isinstance(obj, Instances):\n        res = [flatten_to_tuple(v) for v in obj.get_fields().values()]\n        values, sizes = DictSchema._concat([k[0] for k in res])\n        return values, InstancesSchema([k[1] for k in res], sizes)\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(\"detectron2.structures.Boxes\")\n    if isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(\"detectron2.structures.ROIMasks\")\n    if isinstance(obj, nn.Module):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.nn.Parameter):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.nn.ModuleList):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.nn.ModuleDict):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.nn.ParameterList):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.nn.ParameterDict):\n        return (obj,), IdentitySchema()\n   "}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], schemas)\n    if isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], schemas)\n    if isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(k) for k in obj.values()]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], schemas, sorted(obj.keys()))\n    if isinstance(obj, Instances):\n        res = [flatten_to_tuple(k) for k in obj.get_fields().values()]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values + (obj.image_size,), InstancesSchema([k[1] for k in res], schemas)\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    if isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.Module):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.Parameter):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.ModuleList):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.Sequential):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.ModuleDict):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.ParameterList):\n        return (obj,), IdentitySchema()\n    raise TypeError("}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return obj, IdentitySchema\n    if isinstance(obj, bytes):\n        return obj, IdentitySchema\n    if isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    if isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], sizes)\n    if isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(v) for v in obj.values()]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], sizes, obj.keys())\n    if isinstance(obj, Instances):\n        res = [flatten_to_tuple(v) for v in obj.get_fields().values()]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, InstancesSchema([k[1] for k in res], sizes)\n    if isinstance(obj, Boxes):\n        return obj.tensor, TensorWrapSchema(obj.__class__.__name__)\n    if isinstance(obj, ROIMasks):\n        return obj.tensor, TensorWrapSchema(obj.__class__.__name__)\n    if isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema\n    raise TypeError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = Schema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = Schema._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(k) for k in obj.values()]\n        values, sizes = Schema._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], sizes, list(obj.keys()))\n    elif isinstance(obj, Instances):\n        res = [flatten_to_tuple(k) for k in obj.get_fields().values()]\n        values, sizes = Schema._concat([k[0] for k in res])\n        return values + (obj.image_size,), InstancesSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    elif isinstance(obj, RotatedBoxes):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    elif isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise TypeError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for torch.nn.ModuleList\n    if isinstance(obj, (str, bytes)):\n        return obj, IdentitySchema\n    elif isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, (Boxes, RotatedBoxes, BitMasks)):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return ROIMasksSchema.flatten(obj)\n    elif isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema\n    else:\n        raise NotImplementedError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # if the object is a string or bytes, we just return it\n    if isinstance(obj, (str, bytes)):\n        return obj, IdentitySchema()\n\n    # if the object is a list, we flatten each element in the list\n    if isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = Schema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], schemas)\n\n    # if the object is a tuple, we flatten each element in the tuple\n    if isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = Schema._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], schemas)\n\n    # if the object is a mapping collection, we flatten each element in the mapping collection\n    if isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(k) for k in obj.values()]\n        values, schemas = Schema._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], schemas, obj.keys())\n\n    # if the object is an Instances object, we flatten the fields in the Instances object\n    if isinstance(obj, Instances):\n        res = [flatten_to_tuple(k) for k in obj.get_fields().values()]\n        values, schemas = Schema._concat([k[0] for k in res])\n        return values, InstancesSchema([k[1] for k in res], schemas)\n\n    # if the object is a Boxes object, we flatten the tensor in the Boxes object\n    if isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n\n    # if the object is a RotatedBoxes object, we flatten the tensor in the RotatedBoxes object\n    if isinstance(obj, RotatedBoxes):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n\n    # if the object is a BitMasks object, we flatten the tensor in the BitMasks object\n    if isinstance(obj, BitMasks):\n        return ("}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, (list, tuple)):\n        schemas = [flatten_to_tuple(k) for k in obj]\n        values = [k[0] for k in schemas]\n        sizes = [len(k[0]) for k in schemas]\n        return Schema._concat(values), ListSchema(schemas, sizes)\n    if isinstance(obj, collections.abc.Mapping):\n        schemas = [flatten_to_tuple(v) for v in obj.values()]\n        values = [k[0] for k in schemas]\n        sizes = [len(k[0]) for k in schemas]\n        keys = [k for k in obj.keys()]\n        return Schema._concat(values), DictSchema(schemas, sizes, keys)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, int):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, float):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bool):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Iterable):\n        if isinstance(obj, (list, tuple)):\n            return ListSchema.flatten(obj)\n        if isinstance(obj, dict):\n            return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise TypeError(f\"Cannot flatten object of type {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.nn.Module):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.nn.Parameter):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, RotatedBoxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, BitMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(\n            f\"Cannot flatten object of type {type(obj)}! \"\n            f\"Supported types are str, bytes, list, tuple, dict, \"\n            f\"Instances, Boxes, RotatedBoxes, BitMasks, or ROIMasks.\"\n        )\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        schemas = []\n        sizes = []\n        for k in obj:\n            res, schema = flatten_to_tuple(k)\n            schemas.append(schema)\n            sizes.append(len(res))\n        return ListSchema._concat([k for k in obj])\n    elif isinstance(obj, tuple):\n        schemas = []\n        sizes = []\n        for k in obj:\n            res, schema = flatten_to_tuple(k)\n            schemas.append(schema)\n            sizes.append(len(res))\n        return ListSchema._concat([k for k in obj])\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(\n            f\"Type {type(obj)} is not supported. Only support str, bytes, list, tuple, collections.abc.Mapping, Instances, Boxes, or ROIMasks.\"\n        )\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema()\n    if isinstance(obj, (str, bytes)):\n        return obj, IdentitySchema()\n    if isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = Schema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    if isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(k) for k in obj.values()]\n        values, sizes = Schema._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], sizes, list(obj.keys()))\n    if isinstance(obj, Instances):\n        return flatten_to_tuple(obj.get_fields())\n    if isinstance(obj, Boxes):\n        return flatten_to_tuple(obj.tensor)\n    if isinstance(obj, RotatedBoxes):\n        return flatten_to_tuple(obj.tensor)\n    if isinstance(obj, BitMasks):\n        return flatten_to_tuple(obj.tensor)\n    if isinstance(obj, ROIMasks):\n        return flatten_to_tuple(obj.tensor)\n    raise TypeError(f\"Type {type(obj)} is not supported.\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, int):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, float):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bool):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise TypeError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, torch.nn.Module):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise TypeError(f\"Unsupported type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, RotatedBoxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, BitMasks):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n\n    raise ValueError(f\"Unsupported type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, dict):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, RotatedBoxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, BitMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    else:\n        raise TypeError(f\"Cannot flatten object of type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], schemas)\n    elif isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], schemas)\n    elif isinstance(obj, collections.abc.Mapping):\n        res = [flatten_to_tuple(k) for k in obj.values()]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values, DictSchema([k[1] for k in res], schemas, list(obj.keys()))\n    elif isinstance(obj, Instances):\n        res = [flatten_to_tuple(k) for k in obj.get_fields().values()]\n        values, schemas = cls._concat([k[0] for k in res])\n        return values + (obj.image_size,), InstancesSchema([k[1] for k in res], schemas)\n    elif isinstance(obj, Boxes):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    elif isinstance(obj, ROIMasks):\n        return (obj.tensor,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return obj, IdentitySchema()\n    if isinstance(obj, bytes):\n        return obj, IdentitySchema()\n    if isinstance(obj, torch.Tensor):\n        return obj, IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, RotatedBoxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the input is a list of equations\n    if not isinstance(equations, list):\n        raise EquationToMatrixError(\n            f\"The input 'equations' must be a list of equations. Got {type(equations)} instead.\"\n        )\n\n    # Check if the input is a list of groups\n    if not isinstance(groups, list):\n        raise EquationToMatrixError(\n            f\"The input 'groups' must be a list of groups. Got {type(groups)} instead.\"\n        )\n\n    # Check if the input is a list of equations\n    if not isinstance(equations, list):\n        raise EquationToMatrixError(\n            f\"The input 'equations' must be a list of equations. Got {type(equations)} instead.\"\n        )\n\n    # Check if the input is a list of groups\n    if not isinstance(groups, list):\n        raise EquationToMatrixError(\n            f\"The input 'groups' must be a list of groups. Got {type(groups)} instead.\"\n        )\n\n    # Check if the input is a list of equations\n    if not isinstance(equations, list):\n        raise EquationToMatrixError(\n            f\"The input 'equations' must be a list of equations. Got {type(equations)} instead.\"\n        )\n\n    # Check if the input is a list of groups\n    if not isinstance(groups, list):\n        raise EquationToMatrixError(\n            f\"The input 'groups' must be a list of groups. Got {type(groups)} instead.\"\n        )\n\n    # Check if the input is a list of equations\n    if not isinstance(equations, list):\n        raise EquationToMatrixError(\n            f\"The input 'equations' must be a list of equations. Got {type(equations)} instead.\"\n        )\n\n    # Check if the input is a list of groups\n    if not isinstance(groups, list):\n        raise EquationToMatrixError(\n            f\"The input 'groups' must be a list of groups. Got {type(groups)} instead.\"\n        )\n\n    # Check if the input is a list of equations\n    if not isinstance(equations, list):\n        raise EquationToMatrixError(\n            f\"The input 'equations' must be a list of equations. Got {type(equations)} instead.\"\n        )\n\n    # Check if the input is a"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(equations, (list, tuple, np.ndarray)):\n        raise EquationToMatrixError(\n            f\"The 'equations' parameter must be a list, tuple, or numpy array. Got {type(equations)} instead.\"\n        )\n\n    if not isinstance(groups, (list, tuple, np.ndarray)):\n        raise EquationToMatrixError(\n            f\"The 'groups' parameter must be a list, tuple, or numpy array. Got {type(groups)} instead.\"\n        )\n\n    if not isinstance(names, tuple):\n        raise EquationToMatrixError(\n            f\"The 'names' parameter must be a tuple. Got {type(names)} instead.\"\n        )\n\n    if len(names) != 2:\n        raise EquationToMatrixError(\n            f\"The 'names' parameter must be a tuple of length 2. Got {len(names)} instead.\"\n        )\n\n    if not isinstance(names[0], str):\n        raise EquationToMatrixError(\n            f\"The first element of the 'names' parameter must be a string. Got {type(names[0])} instead.\"\n        )\n\n    if not isinstance(names[1], str):\n        raise EquationToMatrixError(\n            f\"The second element of the 'names' parameter must be a string. Got {type(names[1])} instead.\"\n        )\n\n    if not isinstance(sum_to_one, bool):\n        raise EquationToMatrixError(\n            f\"The 'sum_to_one' parameter must be a boolean. Got {type(sum_to_one)} instead.\"\n        )\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise EquationToMatrixError(\n            f\"The 'raise_if_group_missing' parameter must be a boolean. Got {type(raise_if_group_missing)} instead.\"\n        )\n\n    groups = np.array(groups)\n    equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The 'groups' parameter must be a 2D array. Got {groups.ndim} dimensions instead.\"\n        )\n\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"The 'equations' parameter must be a 1D array. Got"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the input is a numpy array\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n\n    # Check if the input is a numpy array\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Check if the input is a numpy array\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\n            f\"The argument 'sum_to_one' must be a boolean, not {type(sum_to_one)}.\"\n        )\n\n    # Check if the input is a numpy array\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"The argument 'raise_if_group_missing' must be a boolean, not {type(raise_if_group_missing)}.\"\n        )\n\n    # Check if the input is a numpy array\n    if not isinstance(names, tuple):\n        raise TypeError(\n            f\"The argument 'names' must be a tuple, not {type(names)}.\"\n        )\n\n    # Check if the input is a numpy array\n    if len(names) != 2:\n        raise ValueError(\n            f\"The argument 'names' must be a tuple of length 2, not {len(names)}.\"\n        )\n\n    # Check if the input is a numpy array\n    if not isinstance(names[0], str):\n        raise TypeError(\n            f\"The first element of the argument 'names' must be a string, not {type(names[0])}.\"\n        )\n\n    # Check if the input is a numpy array\n    if not isinstance(names[1], str):\n        raise TypeError(\n            f\"The second element of the argument 'names' must be a string, not {type(names[1])}.\"\n        )\n\n    # Check if the input is a numpy array\n    if len(names[0]) == 0:\n        raise ValueError(\n            f\"The first element of the argument 'names' must not be an empty string.\"\n        )\n\n    # Check if the input is a numpy array\n    if len(names[1]) == 0:\n        raise ValueError(\n            f\"The second element of the argument 'names' must not be an empty string.\"\n        )\n\n    # Check if the input is a numpy array\n    if groups.ndim != 2:\n        raise"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the input arrays are 2D\n    if not (np.ndim(groups) == 2 and np.ndim(equations) == 1):\n        raise ValueError(\n            f\"Input arrays must be 2D. Got {np.ndim(groups)} for 'groups' and {np.ndim(equations)} for 'equations'.\"\n        )\n\n    # Check if the input arrays are 2D\n    if not (np.ndim(groups) == 2 and np.ndim(equations) == 1):\n        raise ValueError(\n            f\"Input arrays must be 2D. Got {np.ndim(groups)} for 'groups' and {np.ndim(equations)} for 'equations'.\"\n        )\n\n    # Check if the input arrays are 2D\n    if not (np.ndim(groups) == 2 and np.ndim(equations) == 1):\n        raise ValueError(\n            f\"Input arrays must be 2D. Got {np.ndim(groups)} for 'groups' and {np.ndim(equations)} for 'equations'.\"\n        )\n\n    # Check if the input arrays are 2D\n    if not (np.ndim(groups) == 2 and np.ndim(equations) == 1):\n        raise ValueError(\n            f\"Input arrays must be 2D. Got {np.ndim(groups)} for 'groups' and {np.ndim(equations)} for 'equations'.\"\n        )\n\n    # Check if the input arrays are 2D\n    if not (np.ndim(groups) == 2 and np.ndim(equations) == 1):\n        raise ValueError(\n            f\"Input arrays must be 2D. Got {np.ndim(groups)} for 'groups' and {np.ndim(equations)} for 'equations'.\"\n        )\n\n    # Check if the input arrays are 2D\n    if not (np.ndim(groups) == 2 and np.ndim(equations) == 1):\n        raise ValueError(\n            f\"Input arrays must be 2D. Got {np.ndim(groups)} for 'groups' and {np.ndim(equations)} for 'equations'.\"\n        )\n\n    # Check if the input arrays are 2D\n    if not (np.ndim(groups"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the input is a 2D array\n    if not isinstance(groups, np.ndarray) or groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The input {names[0]} must be a 2D numpy array.\"\n        )\n\n    # Check if the input is a 1D array\n    if not isinstance(equations, np.ndarray) or equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"The input {names[1]} must be a 1D numpy array.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(eq, str) for eq in equations):\n        raise EquationToMatrixError(\n            f\"The input {names[1]} must be a numpy array of strings.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(g, str) for g in groups):\n        raise EquationToMatrixError(\n            f\"The input {names[0]} must be a numpy array of strings.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(g, str) for g in groups):\n        raise EquationToMatrixError(\n            f\"The input {names[0]} must be a numpy array of strings.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(g, str) for g in groups):\n        raise EquationToMatrixError(\n            f\"The input {names[0]} must be a numpy array of strings.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(g, str) for g in groups):\n        raise EquationToMatrixError(\n            f\"The input {names[0]} must be a numpy array of strings.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(g, str) for g in groups):\n        raise EquationToMatrixError(\n            f\"The input {names[0]} must be a numpy array of strings.\"\n        )\n\n    # Check if the input is a string array\n    if not np.all(isinstance(g, str) for g in groups):\n        raise EquationToMatrixError(\n            f\"The input {names"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the groups array is a 2D array\n    if groups.ndim != 2:\n        raise ValueError(\n            \"The 'groups' array should be a 2D array of shape (n_groups, n_assets).\"\n        )\n\n    # Check if the equations array is a 1D array\n    if equations.ndim != 1:\n        raise ValueError(\n            \"The 'equations' array should be a 1D array of shape (n_equations,).\"\n        )\n\n    # Check if the equations array is a 1D array\n    if equations.ndim != 1:\n        raise ValueError(\n            \"The 'equations' array should be a 1D array of shape (n_equations,).\"\n        )\n\n    # Check if the sum_to_one argument is a boolean\n    if not isinstance(sum_to_one, bool):\n        raise ValueError(\"The 'sum_to_one' argument should be a boolean.\")\n\n    # Check if the raise_if_group_missing argument is a boolean\n    if not isinstance(raise_if_group_missing, bool):\n        raise ValueError(\n            \"The 'raise_if_group_missing' argument should be a boolean.\"\n        )\n\n    # Check if the names argument is a tuple of two strings\n    if not isinstance(names, tuple) or len(names) != 2:\n        raise ValueError(\"The 'names' argument should be a tuple of two strings.\")\n\n    # Check if the names argument is a tuple of two strings\n    if not isinstance(names, tuple) or len(names) != 2:\n        raise ValueError(\"The 'names' argument should be a tuple of two strings.\")\n\n    # Check if the names argument is a tuple of two strings\n    if not isinstance(names, tuple) or len(names) != 2:\n        raise ValueError(\"The 'names' argument should be a tuple of two strings.\")\n\n    # Check if the names argument is a tuple of two strings\n    if not isinstance(names, tuple) or len(names) != 2:\n        raise ValueError(\"The 'names' argument should be a tuple of two strings.\")\n\n    # Check if the names argument is a tuple of two strings\n    if not isinstance(names, tuple) or len(names) != 2:\n        raise ValueError(\"The 'names' argument should be a tuple of two strings.\")\n\n    # Check"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the groups and equations are valid\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(\n            f\"The {names[0]} parameter must be a numpy array, but {type(groups)} was given.\"\n        )\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(\n            f\"The {names[1]} parameter must be a numpy array, but {type(equations)} was given.\"\n        )\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\n            f\"The sum_to_one parameter must be a boolean, but {type(sum_to_one)} was given.\"\n        )\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"The raise_if_group_missing parameter must be a boolean, but {type(raise_if_group_missing)} was given.\"\n        )\n    if not isinstance(names, tuple):\n        raise TypeError(\n            f\"The names parameter must be a tuple, but {type(names)} was given.\"\n        )\n\n    # Check if the groups and equations are 2D and 1D arrays, respectively\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The {names[0]} parameter must be a 2D array, but {groups.ndim} dimensions were given.\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The {names[1]} parameter must be a 1D array, but {equations.ndim} dimensions were given.\"\n        )\n\n    # Check if the groups and equations have the correct number of elements\n    if groups.shape[0] == 0:\n        raise ValueError(\n            f\"The {names[0]} parameter must have at least one element, but 0 elements were given.\"\n        )\n    if equations.shape[0] == 0:\n        raise ValueError(\n            f\"The {names[1]} parameter must have at least one element, but 0 elements were given.\"\n        )\n\n    # Check if the groups and equations have the correct number of elements\n    if groups.shape[0] == 0:\n        raise ValueError(\n            f\"The {names[0]} parameter must have at least one element, but 0 elements were given.\"\n        )\n    if equations.shape[0] =="}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check that the input arrays are 2D and have the same number of columns\n    if not (\n        isinstance(groups, np.ndarray)\n        and isinstance(equations, np.ndarray)\n        and groups.ndim == 2\n        and equations.ndim == 1\n        and groups.shape[1] == equations.shape[0]\n    ):\n        raise EquationToMatrixError(\n            \"The input arrays must be 2D and have the same number of columns.\"\n        )\n\n    # Check that the input arrays are of type float\n    if not (\n        groups.dtype == np.float64\n        and equations.dtype == np.float64\n    ):\n        warnings.warn(\n            \"The input arrays should be of type float. Converting to float64.\"\n        )\n        groups = groups.astype(np.float64)\n        equations = equations.astype(np.float64)\n\n    # Check that the input arrays are not empty\n    if not (groups.size > 0 and equations.size > 0):\n        raise EquationToMatrixError(\n            \"The input arrays must not be empty.\"\n        )\n\n    # Check that the input arrays are not all-zero\n    if not (np.any(groups) and np.any(equations)):\n        raise EquationToMatrixError(\n            \"The input arrays must not be all-zero.\"\n        )\n\n    # Check that the input arrays are not all-NaN\n    if not (np.any(np.isnan(groups)) and np.any(np.isnan(equations))):\n        raise EquationToMatrixError(\n            \"The input arrays must not be all-NaN.\"\n        )\n\n    # Check that the input arrays are not all-inf\n    if not (np.any(np.isinf(groups)) and np.any(np.isinf(equations))):\n        raise EquationToMatrixError(\n            \"The input arrays must not be all-inf.\"\n        )\n\n    # Check that the input arrays are not all-inf\n    if not (np.any(np.isinf(groups)) and np.any(np.isinf(equations))):\n        raise EquationToMatrixError(\n            \"The input arrays must not be all-inf.\"\n        )\n\n    # Check that the input arrays are not all-inf\n    if not (np.any(np"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the input groups is a 2D array\n    if not isinstance(groups, np.ndarray) or groups.ndim != 2:\n        raise TypeError(f\"{names[0]} must be a 2D numpy array.\")\n\n    # Check if the input equations is a 1D array\n    if not isinstance(equations, np.ndarray) or equations.ndim != 1:\n        raise TypeError(f\"{names[1]} must be a 1D numpy array.\")\n\n    # Check if the input equations are strings\n    if not np.all(np.array([isinstance(eq, str) for eq in equations])):\n        raise TypeError(f\"{names[1]} must be an array of strings.\")\n\n    # Check if the input equations are valid\n    if not np.all(\n        [\n            re.match(r\"^[\\s]*[\\w]+[\\s]*=[\\s]*[\\w]+[\\s]*$\", eq)\n            for eq in equations.tolist()\n        ]\n    ):\n        raise ValueError(\n            f\"{names[1]} must be an array of strings with the format '<group_name> = <group_name>'\"\n        )\n\n    # Check if the input equations are valid\n    if not np.all(\n        [\n            re.match(r\"^[\\s]*[\\w]+[\\s]*=[\\s]*[\\w]+[\\s]*$\", eq)\n            for eq in equations.tolist()\n        ]\n    ):\n        raise ValueError(\n            f\"{names[1]} must be an array of strings with the format '<group_name> = <group_name>'\"\n        )\n\n    # Check if the input equations are valid\n    if not np.all(\n        [\n            re.match(r\"^[\\s]*[\\w]+[\\s]*=[\\s]*[\\w]+[\\s]*$\", eq)\n            for eq in equations.tolist()\n        ]\n    ):\n        raise ValueError(\n            f\"{names[1]} must be an array of strings with the format '<group_name> = <group_name>'\"\n        )\n\n    # Check if the input equations are valid\n    if not np.all(\n        [\n            re.match(r\"^[\\s]*[\\w]+[\\s]*=[\\s]*[\\w]+[\\s]*$\", eq)\n            for eq in equations.tolist()\n        ]\n    ):\n        raise ValueError(\n            f"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if the equations are strings\n    if not np.all(np.array([isinstance(eq, str) for eq in equations])):\n        raise EquationToMatrixError(\n            f\"The equations must be strings. Found {type(equations[0])}.\"\n        )\n\n    # Check if the groups are strings\n    if not np.all(np.array([isinstance(group, str) for group in groups])):\n        raise EquationToMatrixError(\n            f\"The groups must be strings. Found {type(groups[0])}.\"\n        )\n\n    # Check if the equations contain the groups\n    equations_with_groups = []\n    for equation in equations:\n        if any([group in equation for group in groups]):\n            equations_with_groups.append(equation)\n\n    if not equations_with_groups:\n        warnings.warn(\n            f\"None of the equations contain any of the {names[0]}.\"\n            \" Returning None.\"\n        )\n        return None, None\n\n    # Check if the equations contain the groups\n    equations_with_groups = []\n    for equation in equations:\n        if any([group in equation for group in groups]):\n            equations_with_groups.append(equation)\n\n    if not equations_with_groups:\n        warnings.warn(\n            f\"None of the equations contain any of the {names[0]}.\"\n            \" Returning None.\"\n        )\n        return None, None\n\n    # Check if the equations contain the groups\n    equations_with_groups = []\n    for equation in equations:\n        if any([group in equation for group in groups]):\n            equations_with_groups.append(equation)\n\n    if not equations_with_groups:\n        warnings.warn(\n            f\"None of the equations contain any of the {names[0]}.\"\n            \" Returning None.\"\n        )\n        return None, None\n\n    # Check if the equations contain the groups\n    equations_with_groups = []\n    for equation in equations:\n        if any([group in equation for group in groups]):\n            equations_with_groups.append(equation)\n\n    if not equations_with_groups:\n        warnings.warn(\n            f\"None of the equations contain any of the {names[0]}.\"\n            \" Returning None.\"\n        )\n        return None, None"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if groups is a 2D array\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The {names[0]} parameter must be a 2D array, but got shape {groups.shape}.\"\n        )\n\n    # Check if equations is a 1D array\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The {names[1]} parameter must be a 1D array, but got shape {equations.shape}.\"\n        )\n\n    # Check if the number of equations is equal to the number of groups\n    if equations.shape[0] != groups.shape[0]:\n        raise ValueError(\n            f\"The number of equations ({equations.shape[0]}) must be equal to the number of groups ({groups.shape[0]}).\"\n        )\n\n    # Initialize the left and right matrices\n    left = np.zeros((equations.shape[0], groups.shape[1]))\n    right = np.zeros(equations.shape[0])\n\n    # Loop through the equations and groups\n    for i, equation in enumerate(equations):\n        # Split the equation into left and right sides\n        sides = equation.split(\"=\")\n        if len(sides) != 2:\n            raise EquationToMatrixError(\n                f\"Invalid equation format: {equation}. Expected format: 'group1 + group2 = group3'\"\n            )\n\n        # Extract the groups from the left side\n        left_groups = sides[0].split(\"+\")\n        left_groups = [g.strip() for g in left_groups]\n\n        # Extract the groups from the right side\n        right_groups = sides[1].strip()\n\n        # Check if the right side is a single group\n        if len(right_groups) == 1:\n            right_groups = [right_groups]\n\n        # Check if the right side is a single group\n        if len(right_groups) == 1:\n            right_groups = [right_groups]\n\n        # Check if the right side is a single group\n        if len(right_groups) == 1:\n            right_groups = [right_groups]\n\n        # Check if the"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check the input arguments\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(f\"{names[0]} must be a numpy array.\")\n\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(f\"{names[1]} must be a numpy array.\")\n\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(f\"sum_to_one must be a boolean.\")\n\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(f\"raise_if_group_missing must be a boolean.\")\n\n    if not isinstance(names, tuple):\n        raise TypeError(f\"names must be a tuple of strings.\")\n\n    if len(names) != 2:\n        raise ValueError(f\"names must be a tuple of length 2.\")\n\n    if not all(isinstance(name, str) for name in names):\n        raise TypeError(f\"names must be a tuple of strings.\")\n\n    # Check the shape of the input arrays\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Check the data type of the input arrays\n    if groups.dtype != np.int64:\n        raise ValueError(f\"{names[0]} must be an array of integers.\")\n\n    if equations.dtype != np.object:\n        raise ValueError(f\"{names[1]} must be an array of strings.\")\n\n    # Check the number of groups\n    n_groups = groups.shape[0]\n\n    # Check the number of equations\n    n_equations = equations.shape[0]\n\n    # Check the number of assets\n    n_assets = groups.shape[1]\n\n    # Check if any of the groups in the equations are not found in the groups array\n    all_groups = np.unique(groups)\n    all_groups_str = [str(g) for g in all_groups]\n    missing_groups = []\n    for eq in equations:\n        for g in re.findall(r\"\\d+\", eq):\n            if g not in all_groups_str:\n                missing_groups.append(g)\n\n    if len(missing_groups) > 0:\n        if raise_if_group_"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    if len(groups.shape) != 2:\n        raise EquationToMatrixError(\n            f\"The {names[0]} array must be 2D, but has shape {groups.shape}.\"\n        )\n\n    if len(equations.shape) != 1:\n        raise EquationToMatrixError(\n            f\"The {names[1]} array must be 1D, but has shape {equations.shape}.\"\n        )\n\n    if groups.shape[1] != equations.shape[0]:\n        raise EquationToMatrixError(\n            f\"The number of assets in {names[0]} ({groups.shape[1]}) must be equal to the number of equations in {names[1]} ({equations.shape[0]}).\"\n        )\n\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    for i, eq in enumerate(equations):\n        eq = eq.replace(\" \", \"\")\n\n        if \"+\" in eq:\n            left_side, right_side = eq.split(\"=\")\n            left_side = left_side.split(\"+\")\n            right_side = right_side.split(\"+\")\n        else:\n            left_side = [eq]\n            right_side = [\"\"]\n\n        for group in left_side:\n            if group.startswith(\"-\"):\n                group = group[1:]\n                sign = -1\n            else:\n                sign = 1\n\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"The group '{group}' is not found in the {names[0]} array.\"\n                    )\n                else:\n                    warnings.warn(\n                        f\"The group '{group}' is not found in the {names[0]} array.\"\n                    )\n                    return None\n\n            group_idx = np.where(groups == group)[0][0]\n            left[i, group_idx] += sign\n\n        for group in right_side:\n            if group.startswith(\"-\"):\n                group = group[1:]\n                sign = -1\n            else:\n                sign = 1\n\n            if group not in"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if groups and equations are 2D and 1D arrays, respectively\n    if groups.ndim != 2:\n        raise ValueError(f\"The {names[0]} parameter must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"The {names[1]} parameter must be a 1D array.\")\n\n    # Check if groups and equations are not empty\n    if not groups.size:\n        raise ValueError(f\"The {names[0]} parameter must not be empty.\")\n    if not equations.size:\n        raise ValueError(f\"The {names[1]} parameter must not be empty.\")\n\n    # Check if groups and equations have the same number of columns\n    if groups.shape[1] != equations.shape[0]:\n        raise ValueError(\n            \"The number of columns in the groups array must be equal to the number of equations.\"\n        )\n\n    # Check if groups and equations are of the correct type\n    if not np.issubdtype(groups.dtype, np.number):\n        raise TypeError(f\"The {names[0]} parameter must be numeric.\")\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise TypeError(f\"The {names[1]} parameter must be of type str.\")\n\n    # Check if sum_to_one is a boolean\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"The sum_to_one parameter must be a boolean.\")\n\n    # Check if raise_if_group_missing is a boolean\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            \"The raise_if_group_missing parameter must be a boolean.\"\n        )\n\n    # Check if names is a tuple of two strings\n    if not isinstance(names, tuple) or len(names) != 2 or not all(\n        isinstance(name, str) for name in names\n    ):\n        raise TypeError(\n            \"The names parameter must be a tuple of two strings.\"\n        )\n\n    # Initialize empty arrays for the left and right matrices\n    left = np.zeros((equations.shape[0], groups.shape[1]))\n    right = np.zeros(equations.shape[0"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if groups and equations are valid\n    if not isinstance(groups, np.ndarray):\n        raise EquationToMatrixError(\n            f\"The {names[0]} parameter must be a numpy array.\"\n        )\n    if not isinstance(equations, np.ndarray):\n        raise EquationToMatrixError(\n            f\"The {names[1]} parameter must be a numpy array.\"\n        )\n\n    # Check if groups and equations are 2D and 1D arrays, respectively\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The {names[0]} parameter must be a 2D array.\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"The {names[1]} parameter must be a 1D array.\"\n        )\n\n    # Check if groups and equations have the correct shape\n    if groups.shape[1] != len(equations):\n        raise EquationToMatrixError(\n            f\"The {names[0]} and {names[1]} parameters must have the same number of columns.\"\n        )\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Split the equation into its components\n        components = re.findall(r\"[\\w']+\", equation)\n\n        # Loop through the components\n        for j, component in enumerate(components):\n            # Check if the component is a group\n            if component in groups:\n                # Get the index of the group\n                group_idx = np.where(groups == component)[0][0]\n\n                # Check if the component is a group name\n                if j == 0:\n                    # Check if the group is summing to one\n                    if sum_to_one:\n                        left[i, group_idx] = 1\n                        right[i] = 1\n                    else:\n                        left[i, group_idx] = 1\n                # Check if the component is a group name with a coefficient\n                elif j == 1:\n                    # Check if the coefficient is a number\n                    if components[0].isdigit():\n                        left[i, group_idx] = float(components[0])\n                    # Check if the coefficient is"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            \"The 'groups' parameter must be a 2D array of shape (n_groups, n_assets).\"\n        )\n\n    if equations.ndim != 1:\n        raise ValueError(\n            \"The 'equations' parameter must be a 1D array of shape (n_equations,).\"\n        )\n\n    n_groups, n_assets = groups.shape\n    n_equations = equations.shape[0]\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, equation in enumerate(equations):\n        left_side, right_side = equation.split(\"=\")\n\n        left_side = left_side.strip()\n        right_side = right_side.strip()\n\n        if not (left_side.startswith(\"-\") or right_side.startswith(\"-\")):\n            raise EquationToMatrixError(\n                f\"The equation '{equation}' is not a valid linear inequality. \"\n                \"Please make sure the equation is in the form A <= B, \"\n                \"where A and B are linear combinations of groups.\"\n            )\n\n        left_side_groups = re.findall(r\"\\w+\", left_side)\n        right_side_groups = re.findall(r\"\\w+\", right_side)\n\n        for group in left_side_groups:\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"The group '{group}' mentioned in the equation '{equation}' \"\n                        f\"is not found in the {names[0]} array. \"\n                        f\"Please check the {names[0]} array and make sure all groups mentioned in the equations are present.\"\n                    )\n                else:\n                    warnings.warn(\n                        f\"The group '{group}' mentioned in the equation '{equation}' \"\n                        f\"is not found in the {names[0]} array. \"\n                        f\"Please check the {names[0]} array and make sure all groups mentioned in the equations are present.\"\n                    )\n                    return None\n\n        for group in right_side_groups:\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.array(groups)\n    equations = np.array(equations)\n\n    # Check if the groups are 2D\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The '{names[0]}' parameter must be a 2D array-like.\"\n        )\n\n    # Check if the equations are 1D\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"The '{names[1]}' parameter must be a 1D array-like.\"\n        )\n\n    # Check if the equations are strings\n    if not np.all(np.core.defchararray.isalpha(equations)):\n        raise EquationToMatrixError(\n            f\"The '{names[1]}' parameter must be a 1D array-like of strings.\"\n        )\n\n    # Get the number of assets\n    n_assets = groups.shape[1]\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Extract the groups and coefficients from the equation\n        groups_in_equation = re.findall(r\"\\w+\", equation)\n        coefficients = np.array(\n            [\n                float(coefficient)\n                for coefficient in re.findall(r\"[+-]?\\d+(?:\\.\\d+)?\", equation)\n            ]\n        )\n\n        # Check if the groups in the equation are present in the groups array\n        groups_not_found = [\n            group for group in groups_in_equation if group not in groups\n        ]\n        if groups_not_found:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(\n                    f\"The following groups were not found in the '{names[0]}' \"\n                    f\"parameter: {', '.join(groups_not_found)}.\"\n                )\n            else:\n                warnings.warn(\n                    f\"The following groups were not found in the '{names[0]}' \"\n                    f\"parameter: {', '.join(groups_not_found)}.\"\n                )\n                continue\n\n        # Check if the number of coefficients matches the number of groups\n        if len(coefficients) != len(groups_in_equation):\n            raise Equation"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The '{names[0]}' parameter must be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"The '{names[1]}' parameter must be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    if groups.shape[1] != len(equations):\n        raise EquationToMatrixError(\n            f\"The number of assets in the '{names[0]}' parameter ({groups.shape[1]}) must be equal to the number of equations in the '{names[1]}' parameter ({len(equations)}).\"\n        )\n\n    if raise_if_group_missing:\n        missing_groups = []\n\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    for i, eq in enumerate(equations):\n        if eq == \"1\":\n            left[i] = np.ones(groups.shape[1])\n            right[i] = 1\n            continue\n\n        if eq == \"-1\":\n            left[i] = -np.ones(groups.shape[1])\n            right[i] = -1\n            continue\n\n        for group in groups:\n            if group[0] in eq:\n                if raise_if_group_missing:\n                    missing_groups.append(group[0])\n                continue\n\n        for group in groups:\n            if group[0] in eq:\n                if sum_to_one:\n                    group_sum = np.sum(group[1:])\n                else:\n                    group_sum = 1\n                eq = eq.replace(group[0], f\"{group_sum}\")\n\n        if re.search(r\"(?<!\\w)(\\d+\\.?\\d*)(?!\\w)\", eq):\n            eq = re.sub(r\"(?<!\\w)(\\d+\\.?\\d*)(?!\\w)\", r\"-\\1\", eq)\n\n        if re.search(r"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The 'groups' parameter should be a 2D array, but it has shape {groups.shape}.\"\n        )\n\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The 'equations' parameter should be a 1D array, but it has shape {equations.shape}.\"\n        )\n\n    if equations.size == 0:\n        raise ValueError(\"The 'equations' parameter should not be empty.\")\n\n    if groups.size == 0:\n        raise ValueError(\"The 'groups' parameter should not be empty.\")\n\n    if groups.shape[1] != equations.size:\n        raise ValueError(\n            f\"The number of assets in the 'groups' parameter ({groups.shape[1]}) does not match the number of assets in the 'equations' parameter ({equations.size}).\"\n        )\n\n    if sum_to_one and equations.size != groups.shape[0]:\n        raise ValueError(\n            f\"If 'sum_to_one' is True, the number of equations ({equations.size}) should be equal to the number of groups ({groups.shape[0]}).\"\n        )\n\n    left = np.zeros((equations.size, groups.shape[1]))\n    right = np.zeros(equations.size)\n\n    for i, equation in enumerate(equations):\n        equation = equation.strip()\n        if equation == \"\":\n            raise EquationToMatrixError(\n                f\"The equation at index {i} is empty. Please provide a valid equation.\"\n            )\n        equation = equation.replace(\" \", \"\")\n        equation = equation.replace(\"=\", \"==\")\n        equation = equation.replace(\">=\", \">\")\n        equation = equation.replace(\"<=\", \"<\")\n\n        if equation.count(\"==\") != 1:\n            raise EquationToMatrixError(\n                f\"The equation at index {i} does not contain exactly one equal sign. Please provide a valid equation.\"\n            )\n\n        if equation.count(\">\") > 1 or equation.count(\"<\") > 1:\n            raise EquationToMatrixError(\n                f\"The equation at index {i} contains more than one comparison operator. Please provide a valid equation.\"\n            )\n\n        if equation.count"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the input is a list of equations\n    if not isinstance(equations, list):\n        raise EquationToMatrixError(\n            f\"The {names[1]} parameter must be a list of equations.\"\n        )\n\n    # Check if the input is a 2D array of groups\n    if not isinstance(groups, np.ndarray) or groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The {names[0]} parameter must be a 2D numpy array.\"\n        )\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Split the equation into left and right sides\n        left_side, right_side = equation.split(\"=\")\n\n        # Remove any spaces from the sides\n        left_side = left_side.replace(\" \", \"\")\n        right_side = right_side.replace(\" \", \"\")\n\n        # Check if the left side contains a group\n        if \"group\" in left_side:\n            # Extract the group name from the left side\n            group_name = re.search(r\"group\\((\\w+)\\)\", left_side).group(1)\n\n            # Check if the group name is in the groups array\n            if group_name in groups:\n                # Get the index of the group in the groups array\n                group_index = np.where(groups == group_name)[0][0]\n\n                # Get the coefficients from the left side\n                coefficients = re.findall(r\"-?\\d+\\.?\\d*\", left_side)\n                coefficients = [float(c) for c in coefficients]\n\n                # Check if the sum of coefficients is zero\n                if sum(coefficients) != 0:\n                    raise EquationToMatrixError(\n                        f\"The sum of coefficients in the left side of the equation {equation} is not zero.\"\n                    )\n\n                # Check if the sum to one constraint is applied\n                if sum_to_one:\n                    # Check if the sum of coefficients is not one\n                    if sum(coefficients) != 1:\n                        raise EquationToMatrixError(\n                            f\"The sum of coefficients in the left side of the equation {equation} is not one.\"\n                        )\n\n                # Assign the"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    def _get_field_type(field):\n        if isinstance(field, tuple):\n            return field[1]\n        return type(field)\n\n    def _get_field_name(field):\n        if isinstance(field, tuple):\n            return field[0]\n        return field\n\n    def _get_field_default(field):\n        if isinstance(field, tuple):\n            return field[2]\n        return None\n\n    def _get_field_doc(field):\n        if isinstance(field, tuple):\n            return field[3]\n        return None\n\n    def _get_field_annotation(field):\n        if isinstance(field, tuple):\n            return field[4]\n        return None\n\n    def _get_field_default_annotation(field):\n        if isinstance(field, tuple):\n            return field[5]\n        return None\n\n    def _get_field_doc_annotation(field):\n        if isinstance(field, tuple):\n            return field[6]\n        return None\n\n    def _get_field_type_annotation(field):\n        if isinstance(field, tuple):\n            return field[7]\n        return None\n\n    def _get_field_type_str(field):\n        if isinstance(field, tuple):\n            return field[8]\n        return None\n\n    def _get_field_type_str_annotation(field):\n        if isinstance(field, tuple):\n            return field[9]\n        return None\n\n    def _get_field_type_str_default_annotation(field):\n        if isinstance(field, tuple):\n            return field[10]\n        return None\n\n    def _get_field_type_str_doc_annotation(field):\n        if isinstance(field, tuple):\n            return field[11]\n        return None\n\n    def _get_field_type_str_type_annotation(field):\n        if isinstance(field, tuple):\n            return field[12]\n        return None\n\n    def _get_field_type_str_default(field):\n        if isinstance(field, tuple):\n            return field[13]\n        return None\n\n    def _get_field_type_str_doc(field):\n        if isinstance(field, tuple):\n            return field[14]\n        return None\n\n    def _get_field_type_str_type(field):\n        if isinstance(field, tuple):\n            return field[15]\n        return None\n\n   "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    temp_file = tempfile.NamedTemporaryFile(\n        prefix=f\"instances_patch_{_counter}\", suffix=\".py\", delete=False\n    )\n    temp_file.close()\n    _clear_jit_cache()\n    # Write the new class to a temporary file\n    with open(temp_file.name, \"w\") as f:\n        f.write(\"from detectron2.structures import Boxes, Instances\\n\\n\")\n        f.write(\"class NewInstances(Instances):\\n\")\n        for field in fields:\n            f.write(f\"    {field[0]}: {field[1]}\\n\")\n        f.write(\"\\n\")\n        f.write(\"    def __init__(self, image_size):\\n\")\n        f.write(\"        super().__init__(image_size)\\n\")\n        f.write(\"        self._fields = {}\\n\")\n        f.write(\"        for field in self._fields:\\n\")\n        f.write(\"            self._fields[field] = None\\n\")\n        f.write(\"\\n\")\n        f.write(\"    def __setattr__(self, name, val):\\n\")\n        f.write(\"        if name in self._fields:\\n\")\n        f.write(\"            self._fields[name] = val\\n\")\n        f.write(\"        else:\\n\")\n        f.write(\"            super().__setattr__(name, val)\\n\")\n        f.write(\"\\n\")\n        f.write(\"    def __getattr__(self, name):\\n\")\n        f.write(\"        if name in self._fields:\\n\")\n        f.write(\"            return self._fields[name]\\n\")\n        f.write(\"        else:\\n\")\n        f.write(\"            return super().__getattr__(name)\\n\")\n        f.write(\"\\n\")\n        f.write(\"    def __delattr__(self, name):\\n\")\n        f.write(\"        if name in self._fields:\\n\")\n        f.write(\"            del self._fields[name]\\n\")\n        f.write(\"        else:\\n\")\n        f.write(\"            super().__delattr__(name)\\n\")\n        f.write(\"\\n\")\n        f.write(\"    def __repr__(self):\\n\")\n        f.write(\"        return f"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    from detectron2.structures import Instances\n\n    def _get_field_type(field):\n        if field == \"pred_boxes\":\n            return Boxes\n        elif field == \"scores\":\n            return torch.Tensor\n        elif field == \"pred_classes\":\n            return torch.Tensor\n        else:\n            raise ValueError(f\"Field {field} not supported\")\n\n    def _get_field_value(field):\n        if field == \"pred_boxes\":\n            return Boxes(torch.tensor([[0.0, 0.0, 10.0, 10.0]]))\n        elif field == \"scores\":\n            return torch.tensor([0.9])\n        elif field == \"pred_classes\":\n            return torch.tensor([1])\n        else:\n            raise ValueError(f\"Field {field} not supported\")\n\n    def _get_field_type_string(field):\n        if field == \"pred_boxes\":\n            return \"Boxes\"\n        elif field == \"scores\":\n            return \"torch.Tensor\"\n        elif field == \"pred_classes\":\n            return \"torch.Tensor\"\n        else:\n            raise ValueError(f\"Field {field} not supported\")\n\n    def _get_field_value_string(field):\n        if field == \"pred_boxes\":\n            return \"Boxes(torch.tensor([[0.0, 0.0, 10.0, 10.0]]))\"\n        elif field == \"scores\":\n            return \"torch.tensor([0.9])\"\n        elif field == \"pred_classes\":\n            return \"torch.tensor([1])\"\n        else:\n            raise ValueError(f\"Field {field} not supported\")\n\n    def _get_field_default_value_string(field):\n        if field == \"pred_boxes\":\n            return \"Boxes(torch.tensor([[0.0, 0.0, 10.0, 10.0]]))\"\n        elif field == \"scores\":\n            return \"torch.tensor([0.9])\"\n        elif field == \"pred_classes\":\n            return \"torch.tensor([1])\"\n        else:\n            raise ValueError(f\"Field {field} not supported\")\n\n    def _get_field_default_value(field):\n        if field == \"pred_boxes\":\n            return Boxes(torch.tensor([[0.0, "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Define the new class\n    class NewInstances(Instances):\n        def __init__(self, image_size):\n            super().__init__(image_size)\n\n    # Add fields to the class\n    for field in fields:\n        NewInstances.add_field(*field)\n\n    # Add from_instances method to the class\n    _add_instances_conversion_methods(NewInstances)\n\n    # Generate a new module for the class\n    module_name = \"temp_instances\"\n    module_path = os.path.join(tempfile.gettempdir(), f\"{module_name}.py\")\n    with open(module_path, \"w\") as f:\n        f.write(f\"from detectron2.structures import Instances\\n\\nclass {NewInstances.__name__}(Instances):\\n\")\n        for field in fields:\n            f.write(f\"    {field[0]} = None\\n\")\n        f.write(f\"\\n    @torch.jit.unused\\n\")\n        f.write(f\"    def from_instances(instances: Instances):\\n\")\n        f.write(f\"        fields = instances.get_fields()\\n\")\n        f.write(f\"        image_size = instances.image_size\\n\")\n        f.write(f\"        ret = {NewInstances.__name__}(image_size)\\n\")\n        f.write(f\"        for name, val in fields.items():\\n\")\n        f.write(f\"            assert hasattr(ret, f'_{name}'), f'No attribute named {{name}} in {NewInstances.__name__}'\\n\")\n        f.write(f\"            setattr(ret, name, deepcopy(val))\\n\")\n        f.write(f\"        return ret\\n\")\n\n    # Import the new module\n    sys.path.append(os.path.dirname(module_path))\n    new_instances = _import_file(module_name, module_path)\n\n    # Replace the original 'Instances' class with the new one\n    original_instances = detectron2.structures.Instances\n    detectron2.structures.Instances = new_instances.Instances\n\n    # Yield the new class\n    yield new_instances.Instances\n\n    # Clean up\n    detectron2.structures.Instances = original_instances\n    sys.path.remove("}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    def _create_instances_class(fields):\n        \"\"\"\n        Create a new class for Instances that includes the fields specified in the 'fields' argument.\n        \"\"\"\n\n        def _create_field_getter(field_name):\n            def _getter(self):\n                return getattr(self, f\"_{field_name}\")\n\n            return _getter\n\n        def _create_field_setter(field_name):\n            def _setter(self, val):\n                setattr(self, f\"_{field_name}\", val)\n\n            return _setter\n\n        def _create_field_deleter(field_name):\n            def _deleter(self):\n                delattr(self, f\"_{field_name}\")\n\n            return _deleter\n\n        def _create_field_repr(field_name):\n            def _repr(self):\n                return f\"{field_name}={getattr(self, f'_{field_name}')}\"\n\n            return _repr\n\n        def _create_field_str(field_name):\n            def _str(self):\n                return f\"{field_name}={getattr(self, f'_{field_name}')}\"\n\n            return _str\n\n        def _create_field_init(field_name):\n            def _init(self, image_size):\n                setattr(self, f\"_{field_name}\", None)\n\n            return _init\n\n        def _create_field_to(field_name):\n            def _to(self, *args, **kwargs):\n                return getattr(self, f\"_{field_name}\").to(*args, **kwargs)\n\n            return _to\n\n        def _create_field_to_cpu(field_name):\n            def _to_cpu(self):\n                return getattr(self, f\"_{field_name}\").cpu()\n\n            return _to_cpu\n\n        def _create_field_to_device(field_name):\n            def _to_device(self, device):\n                return getattr(self, f\"_{field_name}\").to(device)\n\n            return _to_device\n\n        def _create_field_to_numpy(field_name):\n            def _to_numpy(self):\n                return getattr(self, f\"_{field_name}\").numpy()\n\n            return _to_numpy\n\n        def _create_field_to_tensor(field_name):\n            def _to_tensor(self):"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Create a new class with the given fields\n    newInstances = type(\"Instances\", (Instances,), fields)\n\n    # Add from_instances method to the new class\n    _add_instances_conversion_methods(newInstances)\n\n    # Create a temporary file to store the new class\n    temp_file = tempfile.NamedTemporaryFile(suffix=\".py\", mode=\"w\", delete=False)\n    temp_file.close()\n\n    # Write the new class to the temporary file\n    with open(temp_file.name, \"w\") as f:\n        f.write(f\"from detectron2.structures import Instances\\n\\nclass {newInstances.__name__}(Instances):\\n\\tdef __init__(self, image_size):\\n\\t\\tself.image_size = image_size\\n\\t\\tself.extra_fields = {{}}\")\n\n    # Import the new class from the temporary file\n    with _import_file(temp_file.name):\n        # Import the new class from the temporary file\n        newInstances = getattr(sys.modules[__name__], newInstances.__name__)\n\n    # Set up the environment to recognize the new class\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n        stack.enter_context(mock.patch(\"detectron2.structures.instances.Instances\", newInstances))\n        stack.enter_context(mock.patch(\"detectron2.structures.boxes.Boxes\", Boxes))\n        stack.enter_context(mock.patch(\"detectron2.structures.masks.PolygonMasks\", nn.Module))\n        stack.enter_context(mock.patch(\"detectron2.structures.masks.BitMasks\", nn.Module))\n        stack.enter_context(mock.patch(\"detectron2.structures.masks.mask_ops\", nn.Module))\n        stack.enter_context(mock.patch(\"detectron2.structures.masks.mask_ops.mask_ops\", nn.Module))\n        stack.enter_context(mock.patch(\"detectron2.structures.masks.mask_ops.mask_ops.mask_ops\", nn.Module))\n        stack.enter_context(mock.patch(\"detectron2.structures.masks.mask_ops.mask_ops.mask_"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Create a new class for 'Instances'\n    class_name = \"Instances\"\n    class_fields = fields\n\n    # Generate a new module for the class\n    module_name = \"instances_scriptable\"\n    module_source = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Create a new class for the new 'Instances' class\n    newInstances = type(\"Instances\", (Instances,), {})\n\n    # Add the fields to the new class\n    for name, type_ in fields:\n        assert name not in newInstances.__dict__, f\"Field {name} already exists in {newInstances.__name__}\"\n        setattr(newInstances, name, type_)\n\n    # Add from_instances methods to the new class\n    _add_instances_conversion_methods(newInstances)\n\n    # Create a new module for the new class\n    module = f\"\"\"\n    from detectron2.structures import Instances\n    class Instances(Instances):\n        pass\n    \"\"\"\n    module = module.replace(\"Instances\", newInstances.__name__)\n\n    # Write the new module to a temporary file\n    with tempfile.TemporaryDirectory() as tmpdir:\n        filename = os.path.join(tmpdir, f\"{newInstances.__name__}.py\")\n        with open(filename, \"w\") as f:\n            f.write(module)\n\n        # Import the new module\n        new_module = _import_file(filename)\n\n        # Replace the 'Instances' class in the detectron2 module with the new class\n        detectron2.structures.Instances = new_module.Instances\n\n        # Clear the torchscript cache to make sure the new class is recognized\n        _clear_jit_cache()\n\n        # Yield the new class\n        yield newInstances\n\n        # Clear the torchscript cache again\n        _clear_jit_cache()\n\n        # Restore the original 'Instances' class\n        detectron2.structures.Instances = Instances\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Generate a new class for the new 'Instances' class\n    new_instances_class = generate_new_instances_class(fields)\n\n    # Write the new class to a temporary file\n    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as f:\n        # Write the new class to the temporary file\n        f.write(new_instances_class)\n        f.flush()\n        # Import the new class from the temporary file\n        new_instances_module = _import_file(f.name)\n        # Get the new class from the imported module\n        new_instances_class = getattr(new_instances_module, new_instances_class.__name__)\n\n    # Set up the environment to recognize the new class\n    sys.modules[\"detectron2.structures.instances\"] = new_instances_module\n    detectron2.structures.instances = new_instances_module\n    # Replace the 'Instances' class with the new class\n    Instances = new_instances_class\n    # Add the from_instances method to the new class\n    _add_instances_conversion_methods(Instances)\n\n    # Yield the new class\n    yield Instances\n\n    # Clean up after exiting the context\n    del sys.modules[\"detectron2.structures.instances\"]\n    del detectron2.structures.instances\n    _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # Create a temporary file to hold the new class definition\n    tmp_file = tempfile.NamedTemporaryFile(\n        mode=\"w\", suffix=f\"_{_counter}.py\", delete=False\n    )\n    # Write the new class definition to the temporary file\n    tmp_file.write(\n        f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Generate a new class with the given fields\n    new_class_name = f\"Instances_{_counter}\"\n    _counter += 1\n    new_class_code = f\"class {new_class_name}(Instances):\\n\"\n    for field in fields:\n        new_class_code += f\"\\t{field}\\n\"\n\n    # Write the new class to a temporary file\n    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as temp_file:\n        temp_file.write(new_class_code.encode())\n        temp_file_path = temp_file.name\n\n    # Import the new class from the temporary file\n    new_class = _import_file(temp_file_path, new_class_name)\n\n    # Add the from_instances method to the new class\n    _add_instances_conversion_methods(new_class)\n\n    # Set up the environment so that torchscript can recognize the new class\n    sys.path.append(os.path.dirname(temp_file_path))\n\n    # Yield the new class\n    yield new_class\n\n    # Clean up after the context manager exits\n    sys.path.remove(os.path.dirname(temp_file_path))\n    _clear_jit_cache()\n    os.remove(temp_file_path)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # Create a temporary file to write the new class definition to\n    temp_file = tempfile.NamedTemporaryFile(\n        mode=\"w\", suffix=\".py\", prefix=f\"temp_file_{_counter}\", delete=False\n    )\n    temp_file.close()\n    temp_file_name = temp_file.name\n    # Define the new class definition as a string\n    new_class_definition = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Create a temporary file to write the new class definition to\n    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as temp:\n        # Write the new class definition to the temporary file\n        temp.write(\n            b\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # create a new module for the new class\n    mod = sys.modules[__name__]\n    mod_name = f\"temp_{_counter}\"\n    _counter += 1\n    mod_path = os.path.join(tempfile.gettempdir(), mod_name)\n    with open(mod_path + \".py\", \"w\") as f:\n        f.write(f\"from detectron2.structures import Instances\\n\\nclass {mod_name}(Instances):\\n\\n\")\n        for name, typ in fields:\n            f.write(f\"    {name}: {typ} = None\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    def __init__(self, image_size):\\n\")\n        f.write(f\"        super().__init__(image_size)\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    @property\\n\")\n        f.write(f\"    def _fields(self):\\n\")\n        f.write(f\"        return {fields}\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    def get_fields(self):\\n\")\n        f.write(f\"        return self._fields\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    def __repr__(self):\\n\")\n        f.write(f\"        return f'{mod_name}(image_size={self.image_size})'\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    def __len__(self):\\n\")\n        f.write(f\"        return len(self.boxes)\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    def __getitem__(self, item):\\n\")\n        f.write(f\"        return self.get(item)\\n\")\n        f.write(\"\\n\")\n        f.write(f\"    def get(self, item):\\n\")\n        f.write(f\"        ret = {mod_name}(self.image_size)\\n\")\n        f.write(f\"        for name, val in self._fields:\\n\")\n        f.write(f\"            ret[name] = val[item]\\n\")\n        f.write(f\"        return ret\\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Generate a new class definition\n    new_class_definition = \"\"\"\n    import torch\n    from torch import nn\n    from detectron2.structures import Boxes, Instances\n    from typing import Dict, Tuple, List, Optional, Union\n\n    class Instances(Instances):\n        \"\"\"\n    for field in fields:\n        new_class_definition += f\"_{field[0]}: {field[1]}\\n\"\n    new_class_definition += \"\"\"\n        def get_fields(self):\n            return {\n                \"\"\"\n    for field in fields:\n        new_class_definition += f\"'{field[0]}': self._{field[0]},\\n\"\n    new_class_definition += \"\"\"\n            }\n\n        def set_fields(self, fields: Dict):\n            for name, val in fields.items():\n                assert hasattr(self, f\"_{name}\"), f\"No attribute named {name} in Instances\"\n                setattr(self, name, val)\n\n        def __repr__(self):\n            return f\"Instances(image_size={self.image_size}, fields={self.get_fields()})\"\n\n        def __deepcopy__(self, memo):\n            return self.clone()\n\n        def __len__(self):\n            return len(self.boxes)\n\n        def __getitem__(self, item):\n            if isinstance(item, slice):\n                return Instances(self.image_size, self.get_fields())[item]\n            else:\n                return Instances(self.image_size, {\n                    name: val[item] for name, val in self.get_fields().items()\n                })\n\n        def clone(self):\n            return Instances(self.image_size, self.get_fields())\n\n        def __eq__(self, other):\n            if not isinstance(other, Instances):\n                return False\n            if self.image_size != other.image_size:\n                return False\n            return self.get_fields() == other.get_fields()\n\n        def __ne__(self, other):\n            return not self.__eq__(other)\n\n        def to(self, device):\n            for name, val in self.get_fields().items():\n                if isinstance(val, torch.Tensor):\n                    setattr(self, name, val.to(device))\n                elif isinstance(val, Boxes):\n                    setattr(self, name, val.to(device))\n                elif isinstance(val,"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # generate a new class with the given fields\n    class_name = \"Instances\"\n    class_code = f\"class {class_name}:\\n\"\n    for field in fields:\n        class_code += f\"\\t{field[0]} = {field[1]}\\n\"\n\n    # write the class to a temporary file\n    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as f:\n        f.write(class_code.encode())\n        file_path = f.name\n\n    # import the class from the temporary file\n    sys.path.append(os.path.dirname(file_path))\n    new_class = _import_file(file_path, class_name)\n\n    # replace the 'Instances' class with the new class\n    original_class = Instances\n    Instances = new_class\n\n    # add the 'from_instances' method to the new class\n    _add_instances_conversion_methods(new_class)\n\n    # add the new class to the module dictionary\n    original_module = sys.modules[\"detectron2.structures\"]\n    original_module.Instances = new_class\n\n    # set up the environment so that torchscript can recognize and work with the new class\n    torch.jit.script(new_class)\n    _clear_jit_cache()\n\n    # yield the new class\n    yield new_class\n\n    # restore the original 'Instances' class and module\n    Instances = original_class\n    sys.modules[\"detectron2.structures\"].Instances = original_class\n\n    # remove the temporary file\n    os.remove(file_path)\n    sys.path.remove(os.path.dirname(file_path))\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    new_instances_name = f\"Instances_{_counter}\"\n    new_instances_fields = fields\n    new_instances_module = f\"\"\"\n    import torch\n    from torch import nn\n    from detectron2.structures import Boxes, Instances\n    from detectron2.utils.env import _import_file\n    import os\n    import sys\n    import tempfile\n    from contextlib import ExitStack, contextmanager\n    from copy import deepcopy\n    from unittest import mock\n    import torch\n    from torch import nn\n    from detectron2.structures import Boxes, Instances\n    from detectron2.utils.env import _import_file\n    from torch.jit import ScriptModule, ScriptClass, ScriptMethod, script, script_method, script_class, script_class_attribute, script_init, script_method_attribute\n    import torch.jit._recursive as recursive\n    from torch.jit._recursive import concrete_type_store\n    from torch.jit._state import _jit_caching_layer\n    from torch.jit._recursive import concrete_type_store\n    from torch.jit._state import _jit_caching_layer\n    concrete_type_store.type_store.clear() # for modules\n    _jit_caching_layer.clear() # for free functions\n\n    class {new_instances_name}(Instances):\n        def __init__(self, image_size: torch.Tensor):\n            super().__init__(image_size)\n            for field in {new_instances_fields}:\n                self._{field[0]} = None\n\n        @property\n        def boxes(self):\n            return self._boxes\n        @boxes.setter\n        def boxes(self, val):\n            self._boxes = val\n\n        @property\n        def scores(self):\n            return self._scores\n        @scores.setter\n        def scores(self, val):\n            self._scores = val\n\n        @property\n        def pred_classes(self):\n            return self._pred_classes\n        @pred_classes.setter\n        def pred_classes(self, val):\n            self._pred_classes = val\n\n        @property\n        def pred_masks(self):\n            return self._pred_masks\n        @pred_masks.setter\n        def pred_masks(self, val):\n            self._pred_masks = val\n\n        @property\n        def pred_keypoints(self):\n            return self._pred_keypoints\n       "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Create a temporary directory to store the new class definition\n    temp_dir = tempfile.TemporaryDirectory()\n    temp_dir_path = temp_dir.name\n\n    # Define the new class name\n    new_class_name = \"Instances\"\n\n    # Create a temporary file to store the new class definition\n    temp_file = tempfile.NamedTemporaryFile(\n        dir=temp_dir_path, delete=False, suffix=\".py\"\n    )\n    temp_file_path = temp_file.name\n\n    # Write the new class definition to the temporary file\n    with open(temp_file_path, \"w\") as f:\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # Get the module that defines 'Instances'\n    instances_module = sys.modules[\"detectron2.structures.instances\"]\n    # Get the original 'Instances' class\n    original_instances = instances_module.Instances\n\n    # Create a new module for the new 'Instances' class\n    new_instances_module = sys.modules[f\"detectron2.structures.instances_new_{_counter}\"] = sys.modules.setdefault(\n        f\"detectron2.structures.instances_new_{_counter}\", {}\n    )\n\n    # Define a new 'Instances' class with the given fields\n    new_instances = type(\n        \"Instances\",\n        (original_instances,),\n        {\n            name: torch.jit.Attribute(val.type(), val.annotation())\n            for name, val in fields.items()\n        },\n    )\n\n    # Add the from_instances method to the new 'Instances' class\n    _add_instances_conversion_methods(new_instances)\n\n    # Write the new 'Instances' class to a temporary file\n    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as f:\n        file_path = f.name\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    def _generate_new_instances_class(fields):\n        \"\"\"\n        Generate a new class for the scripted Instances class.\n        \"\"\"\n        new_instances_class = type(\n            \"Instances\",\n            (Instances,),\n            {\n                \"from_instances\": lambda self, instances: Instances.from_instances(instances),\n            },\n        )\n        for field in fields:\n            field_name = field[0]\n            field_type = field[1]\n            if field_type == \"Boxes\":\n                field_type = Boxes\n            new_instances_class.add_field(field_name, field_type)\n        _add_instances_conversion_methods(new_instances_class)\n        return new_instances_class\n\n    # Create a temporary directory for the new module\n    temp_dir = tempfile.TemporaryDirectory()\n    temp_dir_path = temp_dir.name\n\n    # Generate the new module for the new class\n    new_instances_class = _generate_new_instances_class(fields)\n    new_instances_module_name = f\"instances_module_{_counter}\"\n    _counter += 1\n    new_instances_module = _import_file(\n        new_instances_module_name,\n        os.path.join(temp_dir_path, \"instances_module.py\"),\n    )\n    setattr(new_instances_module, \"Instances\", new_instances_class)\n\n    # Set up the environment to recognize the new module\n    sys.modules[new_instances_module_name] = new_instances_module\n    sys.modules[\"detectron2.structures\"].Instances = new_instances_class\n    sys.modules[\"detectron2.structures\"].__dict__[\"Instances\"] = new_instances_class\n\n    # Yield the new class\n    yield new_instances_class\n\n    # Clean up\n    _clear_jit_cache()\n    del sys.modules[new_instances_module_name]\n    del sys.modules[\"detectron2.structures\"].Instances\n    del sys.modules[\"detectron2.structures\"].__dict__[\"Instances\"]\n    temp_dir.cleanup()\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    # Read the image using PIL\n    image = Image.open(file_name)\n\n    # Apply orientation correction based on EXIF data\n    image = _apply_exif_orientation(image)\n\n    # Convert the image to the specified format\n    image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n        return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    # read image\n    image = Image.open(file_name)\n    # apply exif orientation\n    image = _apply_exif_orientation(image)\n    # convert to numpy array\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    image = _apply_exif_orientation(image)\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n        return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    # read image\n    image = Image.open(file_name)\n\n    # apply exif orientation\n    image = _apply_exif_orientation(image)\n\n    # convert to numpy array\n    image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = annotation[\"bbox\"]\n    bbox_mode = annotation[\"bbox_mode\"]\n\n    if isinstance(transforms, T.TransformList):\n        transforms = transforms.transforms\n\n    for transform in transforms:\n        if isinstance(transform, T.ResizeTransform):\n            # bbox\n            bbox = transform.apply_box(bbox)\n            bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n            # segmentation\n            if \"segmentation\" in annotation:\n                if \"polygons\" in annotation[\"segmentation\"]:\n                    annotation[\"segmentation\"][\"polygons\"] = transform.apply_polygons(\n                        annotation[\"segmentation\"][\"polygons\"]\n                    )\n                if \"rle\" in annotation[\"segmentation\"]:\n                    annotation[\"segmentation\"][\"rle\"] = transform.apply_mask(\n                        annotation[\"segmentation\"][\"rle\"]\n                    )\n            # keypoints\n            if \"keypoints\" in annotation:\n                keypoints = annotation[\"keypoints\"]\n                keypoints = transform.apply_keypoints(keypoints)\n                annotation[\"keypoints\"] = keypoints\n\n        if isinstance(transform, T.AugmentationTransform):\n            # bbox\n            bbox = transform.apply_box(bbox)\n            bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n            # segmentation\n            if \"segmentation\" in annotation:\n                if \"polygons\" in annotation[\"segmentation\"]:\n                    annotation[\"segmentation\"][\"polygons\"] = transform.apply_polygons(\n                        annotation[\"segmentation\"][\"polygons\"]\n                    )\n                if \"rle\" in annotation[\"segmentation\"]:\n                    annotation[\"segmentation\"][\"rle\"] = transform.apply_mask(\n                        annotation[\"segmentation\"][\"rle\"]\n                    )\n            # keypoints\n            if \"keypoints\" in annotation:\n                keypoints = annotation[\"keypoints\"]\n                keypoints = transform.apply_keypoints(keypoints)\n                annotation[\"keypoints\"] = keypoints\n\n        if isinstance(transform, T.HFlipTransform):\n            # bbox\n            bbox = transform.apply_box(bbox)\n            bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n            # segmentation\n            if \"segmentation\" in annotation:\n                if \"polygons\" in annotation[\"segmentation\"]:\n                    annotation[\"segmentation\"][\"polygons\"] = transform.apply_polygons(\n                        annotation[\"segmentation\"][\"polygons\"]\n                    )\n                if \"rle\" in annotation[\""}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # Apply transforms to box\n        x1, y1, x2, y2 = annotation[\"bbox\"]\n        x1, y1, x2, y2 = T.apply_box_transform(\n            [x1, y1, x2, y2], transforms.get_transform_matrix()\n        )\n        # Clip box\n        x1, y1, x2, y2 = T.clip_box_to_image(\n            [x1, y1, x2, y2], image_size[1], image_size[0]\n        )\n        # Set box mode to XYXY_ABS\n        annotation[\"bbox\"] = [x1, y1, x2, y2]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # Apply transforms to polygons\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = annotation[\"segmentation\"]\n            polygons = T.apply_polygons_transform(polygons, transforms.get_transform_matrix())\n            # Clip polygons\n            polygons = T.clip_polygons_to_image(polygons, image_size[1], image_size[0])\n            annotation[\"segmentation\"] = [p for p in polygons if len(p) >= 6]\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE\n            annotation[\"segmentation\"] = T.apply_rle_transform(\n                annotation[\"segmentation\"], transforms.get_transform_matrix()\n            )\n\n    if \"keypoints\" in annotation:\n        # Apply transforms to keypoints\n        keypoints = annotation[\"keypoints\"]\n        keypoints = T.apply_keypoint_transform(keypoints, transforms.get_transform_matrix())\n        # Flip keypoints horizontally\n        if keypoint_hflip_indices is not None:\n            keypoints = T.flip_keypoints(keypoints, keypoint_hflip_indices)\n        # Clip keypoints\n        keypoints = T.clip_keypoints_to_image(keypoints, image_size[1], image_size[0])\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply transforms to box, segmentation and keypoints\n    if annotation[\"bbox_mode\"] == BoxMode.XYWH_ABS:\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n        annotation[\"bbox\"] = BoxMode.convert(\n            annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYWH_ABS\n        )\n    annotation[\"bbox\"] = transforms.apply_box(annotation[\"bbox\"])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons(poly) for poly in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            annotation[\"segmentation\"] = transforms.apply_rles(annotation[\"segmentation\"])\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        keypoints = keypoints.reshape(len(keypoints) // 3, 3)\n        keypoints[:, :2] = keypoints[:, :2].clip(min=0, max=image_size[1] - 1)\n        if keypoint_hflip_indices is not None:\n            keypoints[keypoint_hflip_indices, [0, 2]] = image_size[1] - 1 - keypoints[\n                keypoint_hflip_indices, [0, 2]\n            ]\n        annotation[\"keypoints\"] = keypoints.reshape(-1)\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply transforms to box, segmentation and keypoints\n    if \"bbox\" in annotation:\n        # BoxMode.convert is metric agnostic.\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n        annotation[\"bbox\"] = transforms.apply_box(\n            [BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)]\n        )[0]\n\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation_mode\"] == \"polygon\":\n            annotation[\"segmentation\"] = transforms.apply_polygons(\n                annotation[\"segmentation\"], annotation[\"segmentation_mode\"]\n            )\n        elif annotation[\"segmentation_mode\"] == \"bitmask\":\n            annotation[\"segmentation\"] = transforms.apply_segmentation(\n                annotation[\"segmentation\"], annotation[\"segmentation_mode\"]\n            )\n        else:\n            raise ValueError(f\"Unknown segmentation mode: {annotation['segmentation_mode']}\")\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # Apply transforms to box\n        if \"bbox_mode\" in annotation:\n            bbox_mode = BoxMode(annotation[\"bbox_mode\"])\n        else:\n            bbox_mode = BoxMode.XYWH_ABS\n        bbox = BoxMode.convert(annotation[\"bbox\"], bbox_mode, BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box(bbox)\n        bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, bbox_mode)\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = bbox_mode.value\n\n    if \"segmentation\" in annotation:\n        # Apply transforms to polygons\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = [\n                np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]\n            ]\n            polygons = [\n                transforms.apply_polygons(PolygonMasks(polygons=[p]))[0]\n                for p in polygons\n            ]\n            annotation[\"segmentation\"] = [p.tolist() for p in polygons]\n        else:\n            # bitmask\n            masks = transforms.apply_segmentation(BitMasks(annotation[\"segmentation\"]))\n            annotation[\"segmentation\"] = masks.to_list()\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = np.array(keypoints).reshape(len(keypoints) // 3, 3)\n        keypoints = transforms.apply_keypoints(Keypoints(keypoints))\n        keypoints = keypoints.tensor.view(-1).tolist()\n        annotation[\"keypoints\"] = keypoints\n\n    if \"bbox\" in annotation:\n        # Clip boxes that are out of the image\n        bbox = annotation[\"bbox\"]\n        bbox[0] = max(min(bbox[0], image_size[1]), 0)\n        bbox[1] = max(min(bbox[1], image_size[0]), 0)\n        bbox[2] = max(min(bbox[2], image_size[1]), 0)\n        bbox[3] = max(min(bbox[3], image_size[0]), 0)\n        annotation[\"bbox\"] = bbox\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # apply transforms to box\n        x1, y1, x2, y2 = annotation[\"bbox\"]\n        x1, y1, x2, y2 = transforms.apply_box([x1, y1, x2, y2])\n        annotation[\"bbox\"] = [x1, y1, x2, y2]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # apply transforms to polygons\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons(poly) for poly in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            annotation[\"segmentation\"] = {\n                \"counts\": annotation[\"segmentation\"][\"counts\"],\n                \"size\": list(transforms.apply_segmentation(annotation[\"segmentation\"][\"size\"])),\n            }\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # apply transforms to box\n        x1, y1, x2, y2 = annotation[\"bbox\"]\n        x1, y1, x2, y2 = T.apply_box_transform([x1, y1, x2, y2], transforms)\n        if x1 > x2 or y1 > y2:\n            logging.warning(\n                \"Box [{}, {}, {}, {}] was transformed to an invalid box [{}, {}, {}, {}].\".format(\n                    annotation[\"bbox\"][0],\n                    annotation[\"bbox\"][1],\n                    annotation[\"bbox\"][2],\n                    annotation[\"bbox\"][3],\n                    x1,\n                    y1,\n                    x2,\n                    y2,\n                )\n            )\n            x1, y1, x2, y2 = annotation[\"bbox\"]\n        annotation[\"bbox\"] = [x1, y1, x2, y2]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # apply transforms to polygons\n        if \"polygons\" in annotation:\n            polygons = annotation[\"polygons\"]\n        else:\n            polygons = [poly for poly in annotation[\"segmentation\"].polygons]\n        polygons = T.apply_polygons_transform(polygons, transforms)\n        annotation[\"segmentation\"] = PolygonMasks(polygons)\n\n    if \"keypoints\" in annotation:\n        # apply transforms to keypoints\n        keypoints = annotation[\"keypoints\"]\n        keypoints = T.apply_keypoint_transform(keypoints, transforms, image_size, keypoint_hflip_indices)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # bbox\n    if \"bbox\" in annotation:\n        bbox = annotation[\"bbox\"]\n        bbox_mode = annotation[\"bbox_mode\"]\n        bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        bbox_mode = BoxMode.XYXY_ABS\n        annotation[\"bbox_mode\"] = bbox_mode\n        annotation[\"bbox\"] = bbox\n\n    # segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation_mode\"] == \"polygons\":\n            polygons = annotation[\"segmentation\"]\n            polygons = transforms.apply_polygons(polygons)\n            polygons = [p for p in polygons if len(p) >= 6]\n            if len(polygons) == 0:\n                logging.warning(\n                    \"No valid polygons after transform! Dropping this annotation.\"\n                )\n                return None\n            annotation[\"segmentation\"] = polygons\n        elif annotation[\"segmentation_mode\"] == \"bitmask\":\n            bitmask = annotation[\"segmentation\"]\n            bitmask = transforms.apply_bitmasks(bitmask)\n            if bitmask.sum() == 0:\n                logging.warning(\n                    \"No valid bitmask after transform! Dropping this annotation.\"\n                )\n                return None\n            annotation[\"segmentation\"] = bitmask\n\n    # keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        keypoints = keypoints.reshape(len(keypoints) // 3, 3)\n        keypoints = keypoints[:, :2]\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, [0, 2, 1]]\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        keypoints = keypoints.reshape(-1)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # bbox\n    bbox = annotation[\"bbox\"]\n    bbox_mode = annotation[\"bbox_mode\"]\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    bbox_mode = BoxMode.XYXY_ABS\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = bbox_mode\n\n    # segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            polygons = annotation[\"segmentation\"]\n            polygons = [\n                np.asarray(p).reshape(-1, 2) for p in polygons\n            ]  # to numpy array\n            polygons = [\n                T.apply_polygons(p, transforms) for p in polygons\n            ]  # apply transforms\n            polygons = [\n                p.flatten() for p in polygons\n            ]  # flatten into a list of numbers\n            annotation[\"segmentation\"] = polygons\n        else:\n            # RLE\n            rle = annotation[\"segmentation\"]\n            rle = T.apply_rle(rle, transforms, image_size)\n            annotation[\"segmentation\"] = rle\n\n    # keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = T.apply_keypoints(keypoints, transforms, keypoint_hflip_indices)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # User's transformation code expects a BoxMode in annotation.\n        # If we have a BoxMode.XYWH_ABS, we can just use it.\n        # If we have BoxMode.XYXY_ABS, we need to convert it to WWHH\n        if annotation[\"bbox_mode\"] == BoxMode.XYWH_ABS:\n            annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n            annotation[\"bbox\"][2:] += annotation[\"bbox\"][:2]\n        transform_boxes = transforms.apply_box(annotation[\"bbox\"])\n        transform_boxes = BoxMode.convert(transform_boxes, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n        if annotation[\"bbox_mode\"] == BoxMode.XYWH_ABS:\n            transform_boxes[2:] -= transform_boxes[:2]\n        annotation[\"bbox\"] = transform_boxes\n\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation_mode\"] == \"polygons\":\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons(poly) for poly in annotation[\"segmentation\"]\n            ]\n        elif annotation[\"segmentation_mode\"] == \"bitmask\":\n            annotation[\"segmentation\"] = transforms.apply_bitmasks(annotation[\"segmentation\"])\n        else:\n            raise ValueError(f\"Invalid segmentation mode: {annotation['segmentation_mode']}\")\n\n    if \"keypoints\" in annotation:\n        keypoints = np.array(annotation[\"keypoints\"]).reshape(len(annotation[\"keypoints\"]) // 3, 3)\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        keypoints = keypoints.reshape(-1)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    def _transform_segmentation(segmentation, transforms):\n        \"\"\"\n        Apply transformations to segmentation annotations.\n\n        Args:\n            segmentation (dict): the segmentation annotations of a single instance.\n            transforms (TransformList): the transformations to be applied to the annotations.\n\n        Returns:\n            dict: the transformed segmentation annotations.\n        \"\"\"\n        if \"counts\" in segmentation:\n            # segmentation is a COCO RLE\n            rle = mask_util.decode(segmentation)\n            rle = T.mask.apply_rle_transform(rle, transforms)\n            return {\"counts\": mask_util.encode(np.asfortranarray(rle))[0], \"size\": rle.shape[:2]}\n        else:\n            # segmentation is a polygon\n            polygons = segmentation[\"polygons\"]\n            polygons = T.polygons.apply_polygons_transform(polygons, transforms)\n            return {\"polygons\": polygons, \"mode\": segmentation[\"mode\"]}\n\n    if \"bbox\" in annotation:\n        # Transform \"bbox\", \"bbox_mode\"\n        bbox = annotation[\"bbox\"]\n        bbox_mode = annotation[\"bbox_mode\"]\n        bbox = transforms.apply_box(bbox)\n        bbox, bbox_mode = T.box_ops.box_xyxy_to_xywh_format(bbox, bbox_mode)\n        bbox = T.box_ops.clip_boxes_to_image(bbox, image_size)\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = bbox_mode\n\n    if \"segmentation\" in annotation:\n        # Transform \"segmentation\"\n        annotation[\"segmentation\"] = _transform_segmentation(annotation[\"segmentation\"], transforms)\n\n    if \"keypoints\" in annotation:\n        # Transform \"keypoints\"\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        keypoints = T.keypoint_ops.flip_keypoints(keypoints, keypoint_hflip_indices)\n        keypoints = T.keypoint_ops.clip_keypoints_to_image(keypoints, image_size)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # Apply transforms to box\n        bbox = annotation[\"bbox\"]\n        bbox_mode = annotation[\"bbox_mode\"]\n        bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        bbox_mode = BoxMode.XYXY_ABS\n        annotation[\"bbox_mode\"] = bbox_mode\n        annotation[\"bbox\"] = bbox\n\n    if \"segmentation\" in annotation:\n        # Apply transforms to polygons\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = annotation[\"segmentation\"]\n            polygons = [\n                np.asarray(p).reshape(-1, 2) for p in polygons\n            ]  # ensure they are lists of Nx2 arrays\n            polygons = [\n                BoxMode.convert(p, BoxMode.XY_ABS, BoxMode.XYXY_ABS)\n                for p in polygons\n            ]  # to XYXY_ABS\n            polygons = [\n                transforms.apply_polygons(p) for p in polygons\n            ]  # apply transforms\n            polygons = [\n                BoxMode.convert(p, BoxMode.XYXY_ABS, BoxMode.XY_ABS)\n                for p in polygons\n            ]  # to XY_ABS\n            annotation[\"segmentation\"] = polygons\n        else:\n            # RLE\n            rle = annotation[\"segmentation\"]\n            rle = mask_util.decode(rle)\n            rle = transforms.apply_segmentation(rle)\n            annotation[\"segmentation\"] = mask_util.encode(np.array(rle[:, :, None], order=\"F\"))[0]\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # Transform \"bbox\" field:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation.get(\"bbox_mode\", BoxMode.XYWH_ABS), BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n        annotation[\"bbox\"] = bbox\n\n    if \"segmentation\" in annotation:\n        # Transform \"segmentation\" field:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            annotation[\"segmentation\"] = {\n                \"counts\": annotation[\"segmentation\"],\n                \"size\": image_size,\n            }\n        # RLE\n        annotation[\"segmentation\"] = transforms.apply_segmentation(annotation[\"segmentation\"])\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    # In case the annotations might come from a json file, we'll\n    # set the mode to XYWH_ABS to avoid confusion.\n    if \"bbox_mode\" not in annotation:\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox_mode\" not in annotation:\n        annotation[\"bbox_mode\"] = BoxMode.XYWH_ABS\n\n    if \"bbox\" in annotation:\n        bbox = annotation[\"bbox\"]\n        bbox = transforms.apply_box([bbox])[0]\n        bbox = BoxMode.convert(bbox, annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n        annotation[\"bbox\"] = bbox\n\n    if \"segmentation\" in annotation:\n        seg = annotation[\"segmentation\"]\n        if isinstance(seg, dict):\n            if \"counts\" in seg:\n                seg = mask_util.decode(seg)\n            else:\n                seg = np.asarray(seg)\n        if seg.shape[2] == 1:\n            seg = seg[:, :, 0]\n        seg = transforms.apply_segmentation(seg)\n        if isinstance(seg, torch.Tensor):\n            seg = seg.numpy()\n        annotation[\"segmentation\"] = seg\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply transforms to box, segmentation and keypoints\n    if \"bbox\" in annotation:\n        # BoxMode.convert is metric agnostic.\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n        annotation[\"bbox\"] = transforms.apply_box(annotation[\"bbox\"])\n        annotation[\"bbox\"] = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        annotation[\"bbox\"].clip(image_size)\n\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation_format\"] == \"polygon\":\n            annotation[\"segmentation\"] = transforms.apply_polygons(annotation[\"segmentation\"])\n        elif annotation[\"segmentation_format\"] == \"bitmask\":\n            annotation[\"segmentation\"] = transforms.apply_bitmasks(annotation[\"segmentation\"])\n        elif annotation[\"segmentation_format\"] == \"rle\":\n            annotation[\"segmentation\"] = transforms.apply_rles(annotation[\"segmentation\"])\n\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        # Apply transforms to box\n        bbox = annotation[\"bbox\"]\n        bbox_mode = annotation[\"bbox_mode\"]\n        bbox = transforms.apply_box(bbox)\n        bbox, bbox_mode = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = bbox_mode\n\n    if \"segmentation\" in annotation:\n        # Apply transforms to polygons\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = annotation[\"segmentation\"]\n            polygons = transforms.apply_polygons(polygons)\n            polygons = [p.reshape(-1, 2) for p in polygons]\n            annotation[\"segmentation\"] = [p.flatten() for p in polygons]\n        else:\n            # bitmask\n            if annotation[\"segmentation\"].ndim == 2:\n                # Binary Mask\n                annotation[\"segmentation\"] = transforms.apply_mask(annotation[\"segmentation\"])\n            elif annotation[\"segmentation\"].ndim == 3:\n                height, width = annotation[\"segmentation\"].shape[:2]\n                # RLE\n                annotation[\"segmentation\"] = [\n                    transforms.apply_rle(rle, height, width) for rle in annotation[\"segmentation\"]\n                ]\n            else:\n                raise ValueError(\n                    \"Unexpected segmentation shape of {}.\".format(annotation[\"segmentation\"].shape)\n                )\n\n    if \"keypoints\" in annotation:\n        # Apply transforms to keypoints\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        keypoints = keypoints.reshape(len(keypoints) // 3, 3)\n        keypoints = keypoints[:, :2]  # Keep only (x, y) coordinates\n\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[keypoint_hflip_indices]\n\n        annotation[\"keypoints\"] = keypoints.reshape(-1)\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # bbox\n    if \"bbox\" in annotation:\n        bbox = annotation[\"bbox\"]\n        bbox_mode = annotation[\"bbox_mode\"]\n        if bbox_mode == BoxMode.XYWH_ABS:\n            bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        bbox_mode = BoxMode.XYXY_ABS\n        if bbox_mode == BoxMode.XYXY_ABS:\n            bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYWH_ABS)\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = bbox_mode\n\n    # segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], PolygonMasks):\n            annotation[\"segmentation\"] = annotation[\"segmentation\"].transform(transforms.image_size)\n        elif isinstance(annotation[\"segmentation\"], BitMasks):\n            annotation[\"segmentation\"] = annotation[\"segmentation\"].transform(transforms.image_size)\n        elif isinstance(annotation[\"segmentation\"], list):\n            # list[list[float]]\n            annotation[\"segmentation\"] = [\n                polygons_to_bitmask(\n                    np.array(polygons),\n                    transforms.image_size[0],\n                    transforms.image_size[1],\n                    tolerance=1,\n                )\n                for polygons in annotation[\"segmentation\"]\n            ]\n        else:\n            raise ValueError(f\"Cannot handle segmentation type '{type(annotation['segmentation'])}'\")\n\n    # keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = Keypoints(keypoints)\n        keypoints = keypoints.transform(transforms.image_size)\n        if transforms.apply_keypoint_hflip and keypoint_hflip_indices is not None:\n            keypoints = keypoints.flip_horizontal(keypoint_hflip_indices)\n        keypoints = keypoints.to(\"xy\")\n        annotation[\"keypoints\"] = keypoints.tensor.numpy()\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = annotation[\"bbox\"]\n    bbox_mode = annotation[\"bbox_mode\"]\n    # Apply transforms to box\n    bbox = transforms.apply_box(bbox)\n    # Convert to XYWH_ABS mode\n    bbox = BoxMode.convert(bbox, bbox_mode, BoxMode.XYWH_ABS)\n    # Convert to XYXY_ABS mode\n    bbox = BoxMode.convert(bbox, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    # Clip box\n    bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, bbox_mode)\n    # Set bbox_mode to XYXY_ABS\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n    annotation[\"bbox\"] = bbox\n\n    # Apply transforms to segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons(poly) for poly in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            annotation[\"segmentation\"] = [\n                transforms.apply_rles(rle) for rle in annotation[\"segmentation\"]\n            ]\n\n    # Apply transforms to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = np.array(annotation[\"keypoints\"]).reshape(-1, 3)\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints.reshape(-1).tolist()\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert from xywh[a] to xyxy[a]\n    # We do want to apply transforms to 'bbox'\n    if \"bbox_mode\" not in annotation:\n        logging.warning(\"'bbox_mode' not found in annotation {}\".format(annotation))\n    # Convert from xywh[a] to xyxy[a]\n    # We do want to apply transforms to 'bbox'\n    bbox_mode = annotation[\"bbox_mode\"]\n    if bbox_mode != BoxMode.XYWHA_ABS:\n        annotation[\"bbox_mode\"] = BoxMode.XYWHA_ABS\n    annotation[\"bbox\"] = BoxMode.convert(\n        annotation[\"bbox\"], bbox_mode, BoxMode.XYWHA_ABS\n    )\n    # In case the annotations might be wrong, we use \"filter_empty_instances\"\n    # to remove empty annotations after transformation.\n    annotation = T.filter_empty_instances(annotation)\n\n    # Note that bbox is in XYWHA_ABS mode\n    bbox = annotation[\"bbox\"]\n    keypoints = annotation.get(\"keypoints\", None)\n    if keypoints is not None:\n        keypoints = keypoints.copy()\n\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = [\n                np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]\n            ]\n            polygons = [T.apply_polygons_transform(polygons, transforms) for polygons in polygons]\n            polygons = [p.flatten() for p in polygons]\n            annotation[\"segmentation\"] = polygons\n        else:\n            # RLE\n            rles = [\n                mask_util.decode(annotation[\"segmentation\"][i]).astype(np.uint8)\n                for i in range(len(annotation[\"segmentation\"]))\n            ]\n            rles = [T.apply_rle_transform(rle, transforms) for rle in rles]\n            rles = [mask_util.encode(np.array(rle[:, :, None], order=\"F\"))[0] for rle in rles]\n            annotation[\"segmentation\"] = rles\n\n    # Flip keypoints horizontally\n    if keypoints is not None and keypoint_hflip_indices is not None:\n        keypoints = keypoints[:, keypoint_hflip_indices"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    def _transform_keypoints(keypoints, transforms):\n        \"\"\"\n        Apply transformations to keypoints.\n        Args:\n            keypoints (Keypoint): keypoints to be transformed\n            transforms (TransformList): a list of transformations\n        Returns:\n            Keypoint: the transformed keypoints\n        \"\"\"\n        keypoints = keypoints.clone()\n        for t in transforms:\n            keypoints = t.apply_keypoints(keypoints)\n        return keypoints\n\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation.get(\"bbox_mode\", BoxMode.XYWH_ABS), BoxMode.XYXY_ABS)\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], (list, tuple)):\n            # polygon\n            annotation[\"segmentation\"] = [\n                transforms.apply_polygons(poly) for poly in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            annotation[\"segmentation\"] = transforms.apply_segmentation(annotation[\"segmentation\"])\n\n    if \"keypoints\" in annotation:\n        keypoints = _transform_keypoints(annotation[\"keypoints\"], transforms)\n        # clip to image size\n        keypoints = keypoints.clip(image_size)\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.matmul(coords - self.center, self.rm_coords) + self.center\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords - self.center, self.rm_coords) + self.center\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords - self.center, self.rm_coords) + self.center\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords -= self.center\n        coords = np.dot(coords, self.rm_coords)\n        coords += self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.matmul(coords - self.center, self.rm_coords) + self.center\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords.copy()\n        coords = np.hstack((coords, np.ones((coords.shape[0], 1))))\n        coords = np.dot(coords, self.rm_coords.T)\n        return coords[:, :2]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.matmul(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[None, :, :], self.rm_coords)[0]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[None, :, :], self.rm_coords)[0]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.dot(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords.reshape(-1, 1, 2), self.rm_coords).reshape(-1, 2)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return np.matmul(coords, self.rm_coords.T)\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model = TracingAdapter(model, inputs, allow_non_tensor=True)\n    return flop_count(model, model.flattened_inputs)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    def _flop_count_operators(model, inputs):\n        \"\"\"\n        This function calculates the floating-point operations (flops) count for each operator in a given model using just-in-time (jit) compilation. It is specifically designed to support standard detection models in detectron2 by running the model with a given input and computing the flops. It emphasizes that the computed flops might vary with different inputs, suggesting averaging across multiple inputs for more accurate estimation.\n\n        Input-Output Arguments\n        :param model: nn.Module. A detectron2 model that is expected to take a list of dictionaries as input. The model is used to compute the flops by running it with the provided inputs.\n        :param inputs: list of dictionaries. These are the inputs to the model, adhering to detectron2's standard input format. Only the \"image\" key within these dictionaries is utilized for the flops computation.\n        :return: DefaultDict[str, float]. A dictionary where keys are operator names and values are the corresponding Gflop counts. This provides an overview of the computational cost associated with each operator in the model.\n        \"\"\"\n        flop_count_analysis = FlopCountAnalysis(model, inputs)\n        return flop_count_analysis.total_flops()\n\n    return _flop_count_operators(model, inputs)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_count_analysis = FlopCountAnalysis(model, inputs)\n    return flop_count_analysis.flop_count_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_count_analysis = FlopCountAnalysis(model, inputs)\n    return flop_count_analysis.total_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Check if the model is a detectron2 model\n    if not isinstance(model, nn.Module):\n        raise ValueError(\n            \"The model argument must be a nn.Module, but got {}.\".format(type(model))\n        )\n\n    # Check if the inputs are a list of dictionaries\n    if not isinstance(inputs, list) or not all(isinstance(x, dict) for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries, but got {}.\".format(type(inputs))\n        )\n\n    # Check if the inputs are a list of dictionaries with \"image\" key\n    if not all(\"image\" in x for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries with 'image' key, but got {}.\".format(\n                type(inputs)\n            )\n        )\n\n    # Check if the inputs are a list of dictionaries with \"image\" key\n    if not all(\"image\" in x for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries with 'image' key, but got {}.\".format(\n                type(inputs)\n            )\n        )\n\n    # Check if the inputs are a list of dictionaries with \"image\" key\n    if not all(\"image\" in x for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries with 'image' key, but got {}.\".format(\n                type(inputs)\n            )\n        )\n\n    # Check if the inputs are a list of dictionaries with \"image\" key\n    if not all(\"image\" in x for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries with 'image' key, but got {}.\".format(\n                type(inputs)\n            )\n        )\n\n    # Check if the inputs are a list of dictionaries with \"image\" key\n    if not all(\"image\" in x for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries with 'image' key, but got {}.\".format(\n                type(inputs)\n            )\n        )\n\n    # Check if the inputs are a list of dictionaries with \"image\" key\n    if not all(\"image\" in x for x in inputs):\n        raise ValueError(\n            \"The inputs argument must be a list of dictionaries with 'image' key, but got {}.\".format"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    def _get_flop_count(module, inputs, outputs):\n        if isinstance(inputs, list) and isinstance(inputs[0], dict):\n            inputs = [inp[\"image\"] for inp in inputs]\n        return flop_count(module, inputs, outputs)\n\n    return activation_count(model, inputs, mode=FLOPS_MODE, op_handle=_get_flop_count)\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_count_analysis = FlopCountAnalysis(model, inputs)\n    return flop_count_analysis.total_flops_per_operator\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_count_analysis = FlopCountAnalysis(model, inputs)\n    return flop_count_analysis.operator_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model.eval()\n    adapter = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flop_dict = flop_count(adapter, adapter.flattened_inputs, verbose=True, mode=FLOPS_MODE)\n    return flop_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    def _flop_count_op_handle(op_name: str, inputs: List[Any], outputs: List[Any]) -> float:\n        # ignore some operators\n        if op_name in _IGNORED_OPS:\n            return 0.0\n        return flop_count(op_name, inputs, outputs)\n\n    analysis = FlopCountAnalysis(model, inputs)\n    analysis.set_op_handle(**{k: _flop_count_op_handle for k in analysis.op_handles.keys()})\n    return analysis.total_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Set the mode to \"flops\"\n    fvcore.nn.config.set_mode(FLOPS_MODE)\n\n    # Initialize the FlopCountAnalysis object\n    flop_counter = FlopCountAnalysis(model, inputs)\n\n    # Calculate the flops for each operator\n    flop_counts = flop_counter.calculate_flop_counts()\n\n    # Set the mode back to \"default\"\n    fvcore.nn.config.set_mode(\"default\")\n\n    return flop_counts\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_counter = FlopCountAnalysis(model, inputs)\n    flop_counter.compute_flop_count()\n    return flop_counter.get_flop_count_by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    flop_count_analysis = FlopCountAnalysis(model, inputs)\n    return flop_count_analysis.total_flops_per_operator\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Initialize the FlopCountAnalysis class with the model and inputs\n    analysis = FlopCountAnalysis(model, inputs)\n\n    # Get the operator counts\n    operator_counts = analysis.get_op_counts()\n\n    # Initialize the operator count dictionary\n    operator_count_dict = {}\n\n    # Iterate over the operator counts\n    for operator, count in operator_counts.items():\n        # Convert the operator count to Gflop\n        operator_count_dict[operator] = count / 1e9\n\n    # Return the operator count dictionary\n    return operator_count_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model.eval()\n    with torch.no_grad():\n        # compute flops\n        flop_count_analysis = FlopCountAnalysis(model, inputs)\n        flop_count_analysis.compute_flop_count()\n        flop_count_analysis.compute_flop_count_per_operator()\n        flop_count_analysis.compute_flop_count_per_operator_and_tensor()\n        # get flops count per operator\n        flop_count_per_operator = flop_count_analysis.get_flop_count_per_operator()\n        flop_count_per_operator_and_tensor = flop_count_analysis.get_flop_count_per_operator_and_tensor()\n        flop_count_per_operator_and_tensor = {\n            k: v for k, v in flop_count_per_operator_and_tensor.items() if v > 0\n        }\n        flop_count_per_operator = {\n            k: v for k, v in flop_count_per_operator.items() if v > 0\n        }\n        # get flops count per operator\n        flop_count_per_operator = flop_count_analysis.get_flop_count_per_operator()\n        flop_count_per_operator_and_tensor = flop_count_analysis.get_flop_count_per_operator_and_tensor()\n        flop_count_per_operator_and_tensor = {\n            k: v for k, v in flop_count_per_operator_and_tensor.items() if v > 0\n        }\n        flop_count_per_operator = {\n            k: v for k, v in flop_count_per_operator.items() if v > 0\n        }\n        # get flops count per operator\n        flop_count_per_operator = flop_count_analysis.get_flop_count_per_operator()\n        flop_count_per_operator_and_tensor = flop_count_analysis.get_flop_count_per_operator_and_tensor()\n        flop_count_per_operator_and_tensor = {\n            k: v for k, v in"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # create a flop count analysis object\n    flop_count_analysis = FlopCountAnalysis(model, inputs)\n    # get the operator names and the corresponding flop counts\n    operator_names, flop_counts = flop_count_analysis.get_operator_names_and_flops()\n    # create a dictionary to store the operator names and flop counts\n    operator_flop_counts = {}\n    # iterate over the operator names and flop counts\n    for operator_name, flop_count in zip(operator_names, flop_counts):\n        # convert the flop count from bytes to Gflop\n        operator_flop_counts[operator_name] = flop_count / (1024 ** 3)\n    return operator_flop_counts\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Initialize the flop counter\n    counter = FlopCountAnalysis(model, inputs)\n\n    # Calculate the flops for each operator\n    flops = counter.total_flop_count()\n\n    # Convert the flops to Gflop\n    flops = {k: v / 1e9 for k, v in flops.items()}\n\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Get the model with tracing adapter\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Get the model's flattened inputs\n    flattened_inputs = wrapper.flattened_inputs\n\n    # Get the model's flattened outputs\n    flattened_outputs = wrapper.flattened_outputs\n\n    # Get the model's flattened parameters\n    flattened_parameters = wrapper.flattened_parameters\n\n    # Set the op handle to None for ignored ops\n    for op in _IGNORED_OPS:\n        wrapper.set_op_handle(op, None)\n\n    # Compute the flops count\n    flops_count = flop_count(wrapper, flattened_inputs, flattened_outputs, flattened_parameters)\n\n    # Get the operator names and corresponding flops counts\n    operator_names = flops_count.keys()\n    flops_counts = flops_count.values()\n\n    # Convert the flops counts to Gflop\n    flops_counts = [f / 1e9 for f in flops_counts]\n\n    # Create a dictionary mapping operator names to flops counts\n    flops_dict = dict(zip(operator_names, flops_counts))\n\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    model = model.eval()\n    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.total_flops_per_op\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Use a dummy input if none is provided\n    if not inputs:\n        inputs = [\n            {\n                \"image\": torch.zeros(1, 3, 1024, 1024, dtype=torch.float32),\n                \"height\": 1024,\n                \"width\": 1024,\n            }\n        ]\n\n    # Use a dummy input if none is provided\n    if not inputs:\n        inputs = [\n            {\n                \"image\": torch.zeros(1, 3, 1024, 1024, dtype=torch.float32),\n                \"height\": 1024,\n                \"width\": 1024,\n            }\n        ]\n\n    # Run the model and compute the flops\n    flops_analysis = FlopCountAnalysis(model, inputs)\n\n    # Get the flops count for each operator\n    flops_dict = flops_analysis.total_flops()\n\n    # Convert the flops count to Gflop\n    for op in flops_dict:\n        flops_dict[op] /= 1e9\n\n    return flops_dict\n\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0:\n            return img\n        if self.angle % 360 == 0:\n            return img\n\n        interp_method = interp if interp is not None else self.interp\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                img = img[:, :, 0]\n            ret = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp_method,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # OpenCV only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            ret = F.rotate(img, self.angle, self.center, self.expand, self.interp)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = ret.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.rotate(\n            self.angle,\n            resample=interp if interp else self.interp,\n            expand=self.expand,\n            center=self.center,\n        )\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or (360.0 / abs(self.angle)) % 1 == 0:\n            return img\n\n        interp_method = interp if interp is not None else self.interp\n\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(self.angle, resample=interp_method)\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            img = F.rotate(img, self.angle, self.rm_image)\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or self.angle % 360 == 0:\n            return img\n\n        interp_method = interp if interp is not None else self.interp\n        image_center = np.array((self.w / 2, self.h / 2))\n        rot_mat = cv2.getRotationMatrix2D(tuple(image_center), self.angle, 1.0)\n        abs_cos, abs_sin = (abs(np.cos(np.deg2rad(self.angle))), abs(np.sin(np.deg2rad(self.angle))))\n        if self.expand:\n            # find the new width and height bounds\n            bound_w, bound_h = np.rint(\n                [self.h * abs_sin + self.w * abs_cos, self.h * abs_cos + self.w * abs_sin]\n            ).astype(int)\n            rot_mat[0, 2] += (bound_w / 2) - image_center[0]\n            rot_mat[1, 2] += (bound_h / 2) - image_center[1]\n        else:\n            bound_w, bound_h = self.w, self.h\n            rot_mat[0, 2] += (self.w / 2) - image_center[0]\n            rot_mat[1, 2] += (self.h / 2) - image_center[1]\n\n        ret = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (bound_w, bound_h),\n            flags=interp_method,\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=(0, 0, 0),\n        )\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        # the center of the image\n        image_center = np.array((self.w / 2, self.h / 2))\n        # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to\n        # our representation (height, width)\n        rot_mat = cv2.getRotationMatrix2D(tuple(image_center[::-1]), self.angle, 1.0)\n        # bounding box of the rotated image\n        abs_cos = abs(rot_mat[0, 0])\n        abs_sin = abs(rot_mat[0, 1])\n        # find the new width and height bounds\n        bound_w = int(self.h * abs_sin + self.w * abs_cos)\n        bound_h = int(self.h * abs_cos + self.w * abs_sin)\n        # adjust the rotation matrix to take into account translation\n        rot_mat[0, 2] += bound_w / 2 - image_center[0]\n        rot_mat[1, 2] += bound_h / 2 - image_center[1]\n        # perform the actual rotation and return the image\n        return cv2.warpAffine(\n            img, rot_mat, (bound_w, bound_h), flags=interp, borderMode=cv2.BORDER_REPLICATE\n        )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img) == 0 or self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        # the rotation center may not be located at the image's center\n        image_center = np.array((self.w / 2, self.h / 2))\n        rot_mat = self.rm_image\n        if self.center is not None:\n            rot_mat_no_translate = cv2.warpAffine(\n                img,\n                self.rm_coords,\n                (self.w, self.h),\n                flags=cv2.WARP_INVERSE_MAP,\n                borderMode=cv2.BORDER_REPLICATE,\n            )\n            rot_mat = cv2.warpAffine(\n                rot_mat_no_translate,\n                np.array([[1, 0, self.center[0] - image_center[0]], [0, 1, self.center[1] - image_center[1]]]),\n                (self.w, self.h),\n                flags=cv2.WARP_INVERSE_MAP,\n                borderMode=cv2.BORDER_REPLICATE,\n            )\n        # rotate image\n        ret = cv2.warpAffine(\n            img,\n            rot_mat,\n            (self.bound_w, self.bound_h),\n            flags=interp,\n            borderMode=cv2.BORDER_REPLICATE,\n        )\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[:2] == (self.h, self.w):\n            if self.angle % 360 == 0:\n                return img\n            interp_method = interp if interp is not None else self.interp\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp_method,\n                borderMode=cv2.BORDER_CONSTANT,\n            )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img) == 0 or self.angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = self.interp\n\n        # get rotation matrix for OpenCV\n        rm = self.rm_image\n        # we need to shift the result by (bound_w/2-image_w/2, bound_h/2-image_h/2)\n        (h, w) = img.shape[:2]\n        (cX, cY) = (w // 2, h // 2)\n        M = rm - np.array([[1, 0, w // 2 - cX], [0, 1, h // 2 - cY]])\n        # rotate image\n        ret = cv2.warpAffine(\n            img, M, (self.bound_w, self.bound_h), flags=interp, borderMode=cv2.BORDER_REPLICATE\n        )\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0:\n            return img\n        if self.angle % 360 == 0:\n            return img\n        interp_method = interp if interp is not None else self.interp\n        img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=interp_method,\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=(0, 0, 0),\n        )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.rotate(self.angle, expand=True)\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or np.rad2deg(np.arctan2(self.h, self.w)) % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = self.interp\n\n        # the rotation center\n        image_center = np.array((self.w / 2, self.h / 2))\n        # obtain the rotation matrix.\n        rm = self.rm_image\n\n        # obtain the dimensions of the new image\n        (nw, nh) = (self.bound_w, self.bound_h)\n\n        # translate the image so it is rotated around its center\n        M = np.array(\n            [[1, 0, self.center[0] - image_center[0]], [0, 1, self.center[1] - image_center[1]]],\n            dtype=np.float32,\n        )\n        img = cv2.warpAffine(img, M, (nw, nh))\n\n        # rotate the image around the center\n        img = cv2.warpAffine(img, rm, (nw, nh), flags=interp)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or (self.angle % 360) == 0:\n            return img\n\n        interp_method = interp if interp is not None else self.interp\n        M = self.rm_image\n        ret = cv2.warpAffine(img, M, (self.bound_w, self.bound_h), flags=interp_method)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img is None:\n            return None\n        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        image_center = np.array((self.w / 2, self.h / 2))\n        rot_mat = self.rm_image\n        rot_move = (\n            np.array([(self.bound_w - self.w) / 2, (self.bound_h - self.h) / 2])\n            + image_center\n        )\n        rot_mat_move = np.array(\n            [\n                [1, 0, -rot_move[0]],\n                [0, 1, -rot_move[1]],\n                [0, 0, 1],\n            ]\n        )\n        img = cv2.warpAffine(\n            img,\n            rot_mat_move.dot(rot_mat),\n            (self.bound_w, self.bound_h),\n            borderMode=cv2.BORDER_REPLICATE,\n            flags=interp,\n        )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0:\n            return img\n        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        abs_cos, abs_sin = (abs(np.cos(np.deg2rad(self.angle))), abs(np.sin(np.deg2rad(self.angle))))\n        scale = 1.0\n        if self.expand:\n            scale = max(self.h / self.bound_h, self.w / self.bound_w)\n        M = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (int(self.bound_w * scale), int(self.bound_h * scale)),\n            flags=interp,\n        )\n        return M\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) == 2:\n            img = np.expand_dims(img, -1)\n        if img.shape[0] == 0 or img.shape[1] == 0:\n            return img\n\n        if self.angle % 360 == 0:\n            return img\n\n        interp_method = interp if interp is not None else self.interp\n        center = (self.center[0], self.center[1])\n        M = cv2.getRotationMatrix2D(center, self.angle, 1.0)\n\n        # rotate image\n        img = cv2.warpAffine(img, M, (self.bound_w, self.bound_h), flags=interp_method)\n\n        # rotate segmentation\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = np.expand_dims(img, -1)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0:\n            return img\n\n        if self.angle % 360 == 0:\n            return img\n\n        if interp is None:\n            interp = self.interp\n\n        # get the rotation matrix for OpenCV\n        rm = self.rm_image\n\n        # perform the actual rotation and return the image\n        return cv2.warpAffine(\n            img,\n            rm,\n            (self.bound_w, self.bound_h),\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=(0, 0, 0),\n            flags=interp,\n        )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or self.angle % 360 == 0:\n            return img\n\n        # rotate image\n        if interp is None:\n            interp = self.interp\n        rotated_image = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=interp,\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=(0, 0, 0) if len(img.shape) > 2 else 0,\n        )\n        return rotated_image\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img is None or img.size == 0:\n            return img\n\n        if self.angle % 360 == 0:\n            return img\n\n        interp_method = interp if interp is not None else self.interp\n        h, w = img.shape[:2]\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = np.expand_dims(img, -1)\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n                flags=interp_method,\n            )\n            img = np.squeeze(img, -1)\n        else:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n                flags=interp_method,\n            )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.size == 0 or self.angle % 360 == 0:\n            return img\n        # rotate image\n        ret = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=interp if interp is not None else self.interp,\n        )\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.shape[0] == 0 or img.shape[1] == 0 or self.angle % 360 == 0:\n            return img\n        else:\n            interp_method = interp if interp is not None else self.interp\n            # rotate image\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp_method,\n                borderMode=cv2.BORDER_CONSTANT,\n            )\n            return img\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self._create_colorized_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n            )\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n                is_gray=True,\n            )\n\n        if predictions.has(\"pred_masks_rle\"):\n            self.output.img = self._overlay_mask_rle(\n                self.output.img, predictions.pred_masks_rle\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).to(self.cpu_device)\n            )\n            alpha = 0.7\n        elif self._instance_mode == ColorMode.IMAGE:\n            if predictions.has(\"pred_masks\"):\n                self.draw_binary_mask(predictions.pred_masks)\n            else:\n                self.draw_binary_mask(None)\n            alpha = 0.5\n        else:\n            alpha = 0.5\n\n        if boxes is not None and boxes.ndim != 0:\n            self.draw_boxes(boxes, alpha=alpha)\n\n        if labels is not None:\n            self.draw_text(labels, alpha=alpha)\n\n        if masks is not None:\n            for mask in masks:\n                if self._instance_mode == ColorMode.IMAGE_BW:\n                    continue\n                if isinstance(mask, GenericMask):\n                    self.draw_binary_mask(mask.mask, edge_color=_RED, alpha=alpha)\n                else:\n                    self.draw_binary_mask(mask, alpha=alpha)\n\n        if keypoints is not None and keypoints.shape[0] > 0:\n            self.draw_and_connect_keypoints(keypoints, alpha=alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self._create_colorized_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            if masks is None:\n                raise ValueError(\"Predicted masks not found in `output(prediction)`.\")\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_PILLOW:\n            self.output.img = self._create_pillow_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        else:\n            raise ValueError(\"Unsupported instance visualization mode: {}\".format(self._instance_mode))\n\n        self.overlay = self.output.copy()\n\n        if boxes is not None and boxes.shape[0] > 0:\n            self.overlay = self.overlay.draw_boxes(boxes.tensor.to(self.cpu_device))\n\n        if labels is not None and len(labels) > 0:\n            self.overlay = self.overlay.draw_text(\n               "}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self._create_colorized_image(\n                self.output.img,\n                boxes,\n                masks,\n                labels,\n                keypoints,\n            )\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                boxes,\n                masks,\n                labels,\n                keypoints,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                self.output.img,\n                boxes,\n                masks,\n                labels,\n                keypoints,\n            )\n        else:\n            raise ValueError(f\"Invalid instance mode: {self._instance_mode}\")\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self._create_colorized_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            if masks is None:\n                raise ValueError(\"Predicted masks not found in `output`\")\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_PIL:\n            self.output.img = self._create_pil_image(\n                self.output.img,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        else:\n            raise ValueError(\"Unsupported instance mode: {}\".format(self._instance_mode))\n\n        self.overlay = self.output.get_image()\n        if predictions.has(\"pred_masks\"):\n            self.overlay = self._create_segmentation_image(\n                self.overlay,\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n            )\n        self.output.img = self.overlay\n        if keypoints is not None and keypoints.shape[0]:\n            self.overlay"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self._create_colorized_mask()\n            self._do_plot(boxes, masks, labels)\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self._do_plot(boxes, masks, labels)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_mask()\n            self._do_plot(boxes, masks, labels)\n        elif self._instance_mode == ColorMode.IMAGE_PIL:\n            self._do_plot(boxes, masks, labels)\n        else:\n            raise ValueError(f\"Invalid instance mode: {self._instance_mode}\")\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and predictions.has(\"pred_masks\"):\n            self.draw_segmentation(predictions, masks, labels)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_image(predictions)\n        else:\n            self.draw_boxes(boxes, labels=labels)\n            self.draw_masks(masks, alpha=0.5)\n            self.draw_keypoints(keypoints)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if boxes is not None and boxes.shape[0] > 0:\n            boxes = boxes.tensor.to(self.cpu_device)\n            if scores is not None:\n                scores = scores.to(self.cpu_device)\n            if labels is not None:\n                labels = [x.to(self.cpu_device) for x in labels]\n\n            if masks is not None:\n                masks = [x.to(self.cpu_device) for x in masks]\n\n            if keypoints is not None:\n                keypoints = [x.to(self.cpu_device) for x in keypoints]\n\n            self.overlay_instances(\n                boxes=boxes,\n                labels=labels,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=predictions.pred_masks.get_colors(),\n                alpha=0.0,\n            )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.draw_box_with_mask(boxes, masks, alpha=0.4)\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            if masks is None:\n                raise ValueError(\"Prediction do not have segmentation masks\")\n            self.draw_box_with_mask(boxes, masks, alpha=0.5)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_box_with_mask(boxes, masks, alpha=0.7)\n        else:\n            raise NotImplementedError(f\"Unknown instance color mode: {self._instance_mode}\")\n\n        if labels:\n            self.draw_text(labels, boxes, colors=\"black\", horizontal_align=\"center\")\n\n        if keypoints is not None:\n            self.draw_and_connect_keypoints(keypoints, boxes)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_segmentation_masks(masks)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_binary_mask(masks)\n        else:  # ColorMode.IMAGE\n            self.draw_box(boxes, alpha=0.5)\n            self.draw_text(\n                labels,\n                boxes,\n                size=1,\n                font_size=self._default_font_size,\n            )\n            if masks:\n                self.draw_mask(masks)\n            if keypoints:\n                self.draw_keypoints(keypoints)\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_segmentation_masks(masks, alpha=0.5)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_binary_mask(masks[0].mask)\n        elif self._instance_mode == ColorMode.IMAGE:\n            if self.metadata.get(\"keypoint_names\", None):\n                keypoint_names = self.metadata.keypoint_names\n            else:\n                keypoint_names = None\n            self.overlay_instances(\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n                keypoint_names=keypoint_names,\n            )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_segmentation_masks(masks, alpha=0.5)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_binary_mask(masks[0].mask, color=_BLACK, alpha=0.5)\n        elif self._instance_mode == ColorMode.IMAGE:\n            if masks:\n                self.overlay_mask(masks[0].mask)\n            self.overlay_boxes(boxes, labels=labels, alpha=0.5)\n            self.overlay_class_names(labels, alpha=0.5)\n            if keypoints:\n                self.draw_and_connect_keypoints(keypoints)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.output.img = self._create_colorized_image(\n                self.output.img,\n                boxes,\n                masks,\n                labels,\n            )\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                boxes,\n                masks,\n                labels,\n            )\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_segmentation_image(\n                self.output.img,\n                boxes,\n                masks,\n                labels,\n                area_threshold=0,\n                mask_threshold=0,\n            )\n\n        if predictions.has(\"pred_masks\"):\n            self.draw_binary_mask(predictions.pred_masks.numpy())\n\n        if boxes is not None and boxes.shape[0] > 0:\n            self.draw_boxes(boxes.tensor.to(self.cpu_device))\n\n        if labels is not None:\n            self.draw_text(labels, vertical_align=False)\n\n        if keypoints is not None and keypoints.shape[0] > 0:\n            self.draw_and_connect_keypoints(keypoints.tensor.to(self.cpu_device))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores.numpy() if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints.numpy() if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.img.shape[0], self.img.shape[1]) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (boxes if boxes is not None else masks), alpha=0.5\n            )\n            alpha = 0\n        elif self._instance_mode == ColorMode.IMAGE:\n            if boxes is not None or masks is not None:\n                self.overlay_instances(boxes=boxes, masks=masks)\n            alpha = 0.5\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            _masks = predictions.pred_masks.numpy()\n            self.draw_binary_mask(_masks, alpha=0.5)\n            alpha = 0\n        elif self._instance_mode == ColorMode.PANOPTIC_SEGMENTATION:\n            _panoptic_seg = predictions.pred_panoptic_seg.numpy()\n            self.draw_panoptic_seg(_panoptic_seg, alpha=0.5)\n            alpha = 0\n        else:\n            raise ValueError(\"Unsupported instance mode: {}\".format(self._instance_mode))\n\n        if boxes is not None or masks is not None:\n            self.overlay_instances(boxes=boxes, masks=masks, labels=labels, keypoints=keypoints)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.img.shape[0], self.img.shape[1]) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (boxes if boxes is not None else masks),\n                draw_box=boxes is not None,\n            )\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            alpha = self._create_alpha_image(masks)\n            self.output.img = self._create_color_image(\n                (boxes if boxes is not None else masks),\n                alpha,\n                draw_box=boxes is not None,\n            )\n            return self.output\n\n        if self._instance_mode == ColorMode.IMAGE:\n            if boxes is not None or masks is not None:\n                colors = self._create_random_colors(predictions)\n            if boxes is not None:\n                if labels is None:\n                    self.draw_box(boxes, color=colors)\n                else:\n                    self.draw_box(boxes, edge_color=colors, text=labels, text_color=_BLACK)\n            if masks is not None:\n                if labels is not None:\n                    self.draw_mask(masks, alpha=0.5, color=colors, text=labels)\n                else:\n                    self.draw_mask(masks, alpha=0.5, color=colors)\n            if keypoints is not None:\n                self.draw_and_connect_keypoints(keypoints, keypoint_threshold=self.keypoint_threshold)\n            return self.output\n\n        raise ValueError(f\"Unrecognized instance mode: {self._instance_mode"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.img.shape[0], self.img.shape[1]) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and predictions.has(\"pred_masks\"):\n            self.draw_segmentation(predictions, masks)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_image(predictions)\n        elif self._instance_mode == ColorMode.IMAGE:\n            self.draw_image_with_instances(predictions, boxes, labels, masks, keypoints)\n        else:\n            raise ValueError(f\"Unknown instance mode: {self._instance_mode}\")\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.draw_segmentation_masks(masks, alpha=0.5)\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_binary_mask(masks[0].mask)\n\n        self.overlay_instances(boxes, labels)\n        self.draw_and_connect_keypoints(keypoints)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if boxes is None:\n            return self.output\n\n        # Display in largest to smallest order\n        areas = []\n        if boxes is not None:\n            areas = boxes.area().tolist()\n        sorted_idxs = sorted(range(len(areas)), key=lambda i: areas[i])\n\n        # Reducing over small objects\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            min_area = _SMALL_OBJECT_AREA_THRESH * self.output.scale\n            if not self.output.has_holes:\n                min_area *= self.output.height * self.output.width\n            for idx in sorted_idxs:\n                if areas[idx] < min_area:\n                    sorted_idxs.remove(idx)\n\n        for idx in sorted_idxs:\n            bbox = boxes[idx]\n            x1, y1, x2, y2 = bbox[0], bbox[1], bbox[2], bbox[3]\n            if self._instance_mode == ColorMode.IMAGE:\n                color = random_color(rgb=True)\n            elif self._instance_mode == ColorMode.SEGMENTATION:\n                color = self.metadata.thing_colors[classes[idx]]\n            self.draw_box(bbox, edge_color=color)\n\n            if labels is not None:\n                self.draw_text(labels[idx], bbox, color=color, horizontal_align=\"center\")\n\n            if keypoints is not None:\n                keypoints = keypoints[idx]\n                for keypoint in keypoints:\n                    if keypoint.item() > self.keypoint_threshold:"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.draw_box_with_mask(boxes, masks, alpha=0.4)\n            colors = [random_color(rgb=True) for k in range(len(classes))]\n        elif self._instance_mode == ColorMode.SEGMENTATION:\n            colors = self.metadata.get(\"stuff_colors\", None)\n            if colors is None:\n                colors = [random_color(rgb=True) for k in range(self.metadata.get(\"stuff_classes\", []))]\n            self.draw_box_with_mask(boxes, masks, alpha=0.5)\n        elif self._instance_mode == ColorMode.IMAGE_BW:\n            self.draw_box_with_mask(boxes, masks, alpha=0.4)\n            colors = None\n\n        if keypoints is not None:\n            self.overlay_keypoints(keypoints, labels)\n\n        self.draw_box(boxes, edge_color=\"none\" if masks is None else colors)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and predictions.has(\"pred_masks\"):\n            self.draw_segmentation(predictions)\n        elif predictions.has(\"pred_masks\"):\n            self.draw_binary_mask(predictions.pred_masks.to(self.cpu_device))\n        elif predictions.has(\"pred_masks_rle\"):\n            self.draw_binary_mask(predictions.pred_masks_rle)\n\n        self.overlay_instances(boxes, labels)\n        self.draw_area_of_interest()\n        self.draw_keypoints(keypoints)\n        self.draw_text(\n            [\n                \"Instances\",\n                f\"Area: {self.get_area_of_interest()}\",\n                \"Press 'h' for help\",\n            ]\n        )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()\n        # canvas.print_rgba(buf)\n        # width, height = self.get_wh()\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        img_rgb = np.delete(img_rgba, 3, 2)\n        return img_rgb\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Buffers are width, height, depth\n        buffer = np.frombuffer(s, dtype=\"uint8\").reshape((height, width, 4))\n\n        buffer = buffer[:, :, :3]\n        return buffer\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()\n        # canvas.print_rgba(buf)\n        # width, height = self.get_wh()\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()\n        # canvas.print_rgba(buf)\n        # width, height = self.get_wh()\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        img_rgb = np.zeros((height, width, 3), dtype=np.uint8)\n\n        img_rgb[..., 0] = img_rgba[..., 2]\n        img_rgb[..., 1] = img_rgba[..., 1]\n        img_rgb[..., 2] = img_rgba[..., 0]\n\n        return img_rgb\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # buf = io.BytesIO()\n        # canvas.print_rgba(buf)\n        # width, height = self.get_width_height()\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n\n        try:\n            import numexpr as ne  # faster than numpy\n\n            visualized_image = ne.evaluate(\"rgb * (alpha / 255.0) + 255 * (1 - (alpha / 255.0))\")\n        except ImportError:\n            alpha = alpha.astype(\"float32\") / 255.0\n            visualized_image = rgb * alpha + (1 - alpha) * 255\n        visualized_image = visualized_image.astype(\"uint8\")\n\n        return visualized_image\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Buffer is a string of bytes.  We convert it to uints for easy\n        # indexing.\n        # TODO: why isn't np.fromstring working?\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # Buffer is width*height RGBA pixels. We resample into width*height 3\n        # pixels.\n        buffer = buffer.reshape(height, width, 4)\n\n        # buffer = buffer[:, :, 0:3]\n        return buffer[:, :, 0:3]\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Buffers are width, height, depth\n        buffer = np.frombuffer(s, dtype=\"uint8\").reshape((height, width, 4))\n\n        buffer = buffer[:, :, :3]\n        return buffer\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # buf is a buffer object containing the image data.\n        # We convert it to a numpy array and reshape it to an RGB image.\n        image = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n        image = image[:, :, :3]\n        return image\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the current state of the canvas\n        canvas = self.canvas\n\n        # Convert the canvas state to an RGB image\n        rgb_image = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n        rgb_image = rgb_image.reshape(canvas.get_width_height()[::-1] + (3,))\n\n        # Convert the RGB image to RGBA format\n        rgba_image = np.zeros(rgb_image.shape + (4,), dtype=np.uint8)\n        rgba_image[:, :, :3] = rgb_image\n\n        # Convert the RGBA image to RGB format\n        rgb_image = rgba_image[:, :, :3]\n\n        return rgb_image\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Buffer is a string of bytes.  We convert it to a numpy array using\n        # numpy's frombuffer() function\n        img = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n\n        # Now, img is an RGBA image.  The fourth channel indicates the transparency\n        # of each pixel, and we want to ignore this.  We convert it to an RGB image\n        # by considering it to be an overlaid transparent image on a black background\n        img = img[:, :, 0:3]\n\n        # Finally, we want to replace all white pixels with black pixels.\n        # This can be done by assigning all white pixels in the RGBA image to\n        # black pixels in the RGB image.\n        img[np.where(img > [248, 248, 248])] = [0, 0, 0]\n\n        return img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.buffer_rgba(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (4,))\n        return data[..., :3]\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Buffer is a string of bytes.  We convert it to a numpy array using\n        # numpy's frombuffer() function\n        img = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n\n        # Now, let's clear the figure\n        # self.fig.clear()\n        # self.ax.clear()\n        # canvas.clear()\n\n        # canvas.draw()\n        # s, (width, height) = canvas.print_to_buffer()\n        #\n        # # Buffer is a string of bytes.  We convert it to a numpy array using\n        # # numpy's frombuffer() function\n        # img = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n\n        return img[:, :, :3]\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # buf = io.BytesIO()\n        # canvas.print_rgba(buf)\n        # width, height = self.get_width_height()\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n\n        try:\n            import numexpr as ne  # faster than numpy\n\n            visualized_image = ne.evaluate(\"rgb * (alpha / 255.0) + 255 * (1 - (alpha / 255.0))\")\n        except ImportError:\n            alpha = alpha.astype(\"float32\") / 255.0\n            visualized_image = rgb * alpha + (1 - alpha) * 255\n        visualized_image = visualized_image.astype(\"uint8\")\n\n        return visualized_image\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        data = np.frombuffer(self.canvas.tostring_rgb(), dtype=np.uint8)\n        data = data.reshape(self.canvas.get_width_height()[::-1] + (3,))\n        return data\n\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_segmentation(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_bbox(bboxes)\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\", None)\n        sem_seg = dic.get(\"sem_seg\", None)\n        panoptic_seg = dic.get(\"panoptic_seg\", None)\n        panoptic_seg_segments_info = dic.get(\"panoptic_seg_segments_info\", None)\n        if anns is None:\n            if sem_seg is None and panoptic_seg is None:\n                return self.output\n            else:\n                return self.draw_sem_seg(sem_seg)\n        if sem_seg is None and panoptic_seg is None:\n            return self.draw_instance_predictions(anns)\n        if sem_seg is None:\n            return self.draw_panoptic_seg_predictions(panoptic_seg, panoptic_seg_segments_info)\n        if panoptic_seg is None:\n            return self.draw_sem_seg(sem_seg)\n        return self.draw_panoptic_seg_predictions(panoptic_seg, panoptic_seg_segments_info)\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\", None)\n        sem_seg = dic.get(\"sem_seg\", None)\n        panoptic_seg = dic.get(\"panoptic_seg\", None)\n        panoptic_seg_info = dic.get(\"panoptic_seg_info\", None)\n\n        if anns is not None:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box(bboxes)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_and_connect_keypoints(keypoints)\n            if \"category_id\" in anns[0]:\n                category_ids = [x[\"category_id\"] for x in anns]\n                self.draw_category_labels(category_ids)\n            if \"iscrowd\" in anns[0]:\n                iscrowds = [x.get(\"iscrowd\", 0) for x in anns]\n                self.draw_iscrowd_labels(iscrowds)\n\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg, panoptic_seg_info)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box(bboxes)\n            if \"category_id\" in anns[0]:\n                category_ids = [x[\"category_id\"] for x in anns]\n                labels = _create_text_labels(\n                    category_ids, None, self.metadata.thing_classes, [x.get(\"iscrowd\", 0) for x in anns]\n                )\n                self.draw_box(bboxes, labels)\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\", None)\n        sem_seg = dic.get(\"sem_seg\", None)\n        pan_seg = dic.get(\"pan_seg\", None)\n\n        if anns is not None:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n            else:\n                masks = None\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n            else:\n                keypoints = None\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n            else:\n                bboxes = None\n            if \"category_id\" in anns[0]:\n                classes = [x[\"category_id\"] for x in anns]\n            else:\n                classes = None\n            if \"iscrowd\" in anns[0]:\n                iscrowds = [x.get(\"iscrowd\", 0) for x in anns]\n            else:\n                iscrowds = None\n            if \"score\" in anns[0]:\n                scores = [x[\"score\"] for x in anns]\n            else:\n                scores = None\n            labels = _create_text_labels(classes, scores, self.metadata.thing_classes, iscrowds)\n            self.overlay_instances(masks=masks, boxes=bboxes, labels=labels, keypoints=keypoints)\n\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"keypoints\" in anns[0]:\n                self.draw_keypoints(anns)\n            if \"boxes\" in anns[0]:\n                self.draw_boxes(anns)\n            if \"segmentation\" in anns[0]:\n                self.draw_sem_seg(anns)\n        if \"sem_seg_file_name\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg_file_name\"])\n        if \"panoptic_seg_file_name\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg_file_name\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\")\n        if annos:\n            if \"keypoints\" in annos[0]:\n                self.draw_keypoints(annos)\n            if \"boxes\" in annos[0]:\n                self.draw_boxes(annos)\n            if \"segmentation\" in annos[0]:\n                self.draw_sem_seg(annos)\n            if \"panoptic_seg\" in annos[0]:\n                self.draw_panoptic_seg(annos)\n        if \"sem_seg_file_name\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg_file_name\"])\n        if \"panoptic_seg_file_name\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg_file_name\"])\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                self.draw_sem_seg(\n                    anns[0][\"segmentation\"].mask.numpy(),\n                    area_threshold=0 if len(anns) == 1 else None,\n                )\n            else:\n                self.draw_instance_predictions(anns)\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"].mask.numpy())\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg_predictions(dic[\"panoptic_seg\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box(bboxes)\n            if \"category_id\" in anns[0]:\n                category_ids = [x[\"category_id\"] for x in anns]\n                self.draw_category_labels(category_ids)\n            if \"iscrowd\" in anns[0]:\n                iscrowds = [x.get(\"iscrowd\", 0) for x in anns]\n                self.draw_iscrowds(iscrowds)\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box(bboxes)\n\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg)\n\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            self.draw_instance_predictions(instances)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box(bboxes)\n\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        pan_seg = dic.get(\"pan_seg\")\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg)\n\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            self.overlay_instances(instances=instances)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\", None)\n        if anns is not None:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_masks(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_boxes(bboxes)\n            if \"category_id\" in anns[0]:\n                category_ids = [x[\"category_id\"] for x in anns]\n                self.draw_category_labels(category_ids)\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n        panoptic_seg = dic.get(\"panoptic_seg\", None)\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box(bboxes)\n            if \"category_id\" in anns[0]:\n                category_ids = [x[\"category_id\"] for x in anns]\n                try:\n                    colors = [\n                        [x / 255 for x in self.metadata.thing_colors[c]] for c in category_ids\n                    ]\n                except AttributeError:\n                    colors = None\n                self.draw_box(bboxes, edge_color=_OFF_WHITE, assigned_colors=colors)\n\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is not None:\n            self.draw_panoptic_seg(panoptic_seg)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\")\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n                self.draw_binary_mask(masks, edge_color=_OFF_WHITE)\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"] for x in annos]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in annos[0]:\n                bboxes = [x[\"bbox\"] for x in annos]\n                self.draw_box_list(bboxes)\n\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is not None:\n            segments_info = dic.get(\"segments_info\")\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\", None)\n        if anns is not None:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_segmentation(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_bbox(bboxes)\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        panoptic_seg = dic.get(\"panoptic_seg\", None)\n        if panoptic_seg is not None:\n            segments_info = dic.get(\"segments_info\", None)\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_masks(masks)\n            else:\n                if \"keypoints\" in anns[0]:\n                    keypoints = [x[\"keypoints\"] for x in anns]\n                    self.draw_keypoints(keypoints)\n                if \"bbox\" in anns[0]:\n                    bboxes = [x[\"bbox\"] for x in anns]\n                    self.draw_boxes(bboxes)\n                if \"category_id\" in anns[0]:\n                    category_ids = [x[\"category_id\"] for x in anns]\n                    scores = None\n                    if \"score\" in anns[0]:\n                        scores = [x[\"score\"] for x in anns]\n                    self.overlay_instances(\n                        labels=_create_text_labels(\n                            category_ids,\n                            scores,\n                            self.metadata.thing_classes,\n                            [x.get(\"iscrowd\", 0) for x in anns],\n                        )\n                    )\n\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        pan_seg = dic.get(\"pan_seg\")\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info=dic.get(\"segments_info\"))\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\", None)\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_segmentation(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_bbox(bboxes)\n            if \"category_id\" in anns[0]:\n                category_ids = [x[\"category_id\"] for x in anns]\n                try:\n                    category_names = [self.metadata.thing_classes[i] for i in category_ids]\n                except AttributeError:\n                    category_names = None\n                self.draw_text(\n                    [self._create_text_label(category_id, score, category_names) for x in anns]\n                )\n            if \"iscrowd\" in anns[0]:\n                iscrowds = [x.get(\"iscrowd\", 0) for x in anns]\n                self.draw_text([(\"crowd\" if crowd else \"\") for crowd in iscrowds])\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        panoptic_seg = dic.get(\"panoptic_seg\", None)\n        if panoptic_seg is not None:\n            segments_info = dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0, alpha=0.7)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks, edge_color=_OFF_WHITE)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_and_connect_keypoints(keypoints)\n            if \"bbox\" in anns[0]:\n                bboxes = [x[\"bbox\"] for x in anns]\n                self.draw_box_collection(bboxes)\n\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg)\n\n        pan_seg = dic.get(\"pan_seg\")\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_masks(masks)\n            if \"keypoints\" in anns[0]:\n                keypoints = [x[\"keypoints\"] for x in anns]\n                self.draw_keypoints(keypoints)\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"].astype(np.uint8)\n            self.draw_sem_seg(sem_seg)\n\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"].astype(np.uint8)\n            segments_info = dic.get(\"segments_info\")\n            self.draw_panoptic_seg_predictions(panoptic_seg, segments_info)\n\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            self.draw_instance_predictions(instances)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        anns = dic.get(\"annotations\")\n        if anns:\n            if \"segmentation\" in anns[0]:\n                masks = [x[\"segmentation\"] for x in anns]\n                self.draw_binary_mask(masks, edge_color=_OFF_WHITE)\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"], area_threshold=0, alpha=0.5)\n\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg_predictions(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n\n        if \"instances\" in dic:\n            instances = dic[\"instances\"]\n            boxes = instances.get(\"bbox\")\n            if boxes is not None:\n                self.draw_box(boxes.tensor, edge_color=_OFF_WHITE)\n            keypoints = instances.get(\"keypoints\")\n            if keypoints is not None:\n                self.draw_and_connect_keypoints(keypoints.tensor)\n            labels = _create_text_labels(\n                instances.get(\"category_id\"),\n                instances.get(\"score\"),\n                self.metadata.get(\"thing_classes\", None),\n                instances.get(\"iscrowd\", None),\n            )\n            if labels is not None:\n                self.draw_text(labels, boxes=boxes, font_size=self._default_font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        if len(binary_mask.shape) == 2:\n            self.draw_mask(binary_mask, color, edge_color, alpha)\n        else:\n            self.draw_mask_with_holes(binary_mask, color, edge_color, alpha, area_threshold)\n\n        # draw text\n        if text is not None:\n            self.draw_text(\n                text,\n                binary_mask.bbox(),\n                color=self._change_color_brightness(color, brightness_factor=0.7),\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        self.draw_mask(binary_mask, color, edge_color, alpha)\n\n        # draw text\n        if text is not None:\n            # draw text on the mask\n            # first get a box\n            x0, y0, x1, y1 = binary_mask.bbox()\n            # draw text in the center (defined by median) when box is not drawn\n            text_pos = np.median(binary_mask.nonzero(), axis=1)[::-1]\n            height_ratio = (y1 - y0) / np.sqrt(self.output.height * self.output.width)\n            label_color = self._change_color_brightness(color, brightness_factor=0.7)\n            font_size = (\n                np.clip((height_ratio - 0.02) / 0.08 + 1, 1.2, 2) * 0.5 * self._default_font_size\n            )\n            self.draw_text(text, text_pos, color=label_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # if the mask is small, draw it as a regular mask\n        if binary_mask.area() < area_threshold * self.output.height * self.output.width:\n            self.draw_polygon(binary_mask, color, alpha, edge_color)\n        else:\n            # if the mask is large, draw it as a mask with holes\n            self.draw_mask_with_holes(binary_mask, color, alpha, edge_color)\n\n        if text is not None:\n            # draw text on the mask\n            self.draw_text(text, binary_mask.centroid(), color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # use different approach for mask with holes\n        if len(binary_mask.polygons) > 0:\n            return self.draw_mask_with_holes(\n                binary_mask, color, edge_color=edge_color, text=text, alpha=alpha\n            )\n\n        # use different approach for mask with holes\n        if text is not None:\n            return self.draw_mask_with_text(binary_mask, color, edge_color=edge_color, text=text)\n\n        # use different approach for mask with holes\n        if area_threshold * self.output.scale > binary_mask.area:\n            return self.draw_mask_with_holes(\n                binary_mask, color, edge_color=edge_color, text=text, alpha=alpha\n            )\n\n        # use different approach for mask with holes\n        return self.draw_mask_with_polygons(binary_mask, color, edge_color=edge_color, alpha=alpha)\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        if binary_mask.dtype != np.uint8:\n            binary_mask = binary_mask.astype(np.uint8)\n        self.output.ax.add_patch(\n            mpl.patches.Patch(\n                binary_mask,\n                fill=True,\n                edgecolor=edge_color,\n                alpha=alpha,\n                zorder=10,\n            )\n        )\n\n        # draw text\n        if text is not None:\n            # find the center of the mask\n            mask_center = np.median(binary_mask.nonzero(), axis=1)[::-1]\n            # find the area of the mask\n            mask_area = np.sum(binary_mask)\n            # since the text background is dark, we don't want the text to be dark\n            color = np.maximum(list(mplc.to_rgb(color)), 0.2)\n            color[np.argmax(color)] = max(0.8, np.max(color))\n            # since the text is small, we don't want it to be too small\n            font_size = (\n                np.clip((mask_area / area_threshold - 0.02) / 0.08 + 1, 1.2, 2)\n                * 0.5\n                * self._default_font_size\n            )\n            self.draw_text(text, mask_center, color=color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if text is not None:\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            font_size = self._default_font_size\n\n        # draw mask with holes\n        if len(binary_mask.polygons) > 0:\n            for polygon in binary_mask.polygons:\n                self.draw_polygon(polygon.reshape(-1, 2), color, alpha)\n                self.draw_polygon(polygon.reshape(-1, 2), edge_color, alpha)\n\n            # draw text on the mask\n            if text is not None:\n                text_pos = np.median(binary_mask.mask.nonzero(), axis=1)[::-1]\n                self.draw_text(text, text_pos, text_color, font_size=font_size)\n            return self.output\n\n        # draw regular mask as polygon\n        for polygon in binary_mask.polygons:\n            self.draw_polygon(polygon.reshape(-1, 2), color, alpha)\n\n        # draw text on the mask\n        if text is not None:\n            text_pos = np.median(binary_mask.mask.nonzero(), axis=1)[::-1]\n            self.draw_text(text, text_pos, text_color, font_size=font_size)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if binary_mask.dtype != np.uint8:\n            binary_mask = binary_mask.astype(np.uint8)\n\n        if np.max(binary_mask) == 0:\n            return self.output\n\n        # draw mask\n        self.output.ax.add_patch(\n            mpl.patches.Polygon(\n                binary_mask.nonzero(),\n                fill=True,\n                closed=True,\n                edgecolor=edge_color,\n                facecolor=color,\n                alpha=alpha,\n            )\n        )\n\n        # draw text\n        if text is not None:\n            # get the coordinates of the center of the mask\n            cnt_x, cnt_y = np.median(binary_mask.nonzero(), axis=1)\n            # since the text background is dark, we don't want the text to be dark\n            color = np.maximum(list(mplc.to_rgb(color)), 0.2)\n            color[np.argmax(color)] = max(0.8, np.max(color))\n\n            # draw text\n            self.draw_text(\n                text,\n                (cnt_x, cnt_y),\n                color=color,\n                font_size=self._default_font_size,\n                horizontal_alignment=\"center\",\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        for component in measure.label(binary_mask):\n            if component.area > area_threshold:\n                self.draw_polygon(component.coords.reshape(-1, 2), color, alpha)\n\n        if text is not None:\n            # draw text\n            # get the largest component\n            largest_component = max(measure.label(binary_mask), key=lambda x: x.area)\n            # get the center coordinates of the largest component\n            cnt_x, cnt_y = np.median(largest_component.coords, axis=0)[::-1]\n            # draw text\n            self.draw_text(text, (cnt_x, cnt_y), color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if text is not None:\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n\n        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        # draw polygons\n        polygons = self.get_polygons_from_binary_mask(binary_mask)\n        if len(polygons) > 0:\n            for polygon in polygons:\n                self.draw_polygon(polygon, color, alpha)\n\n        # draw holes\n        holes = self.get_holes_from_binary_mask(binary_mask)\n        if len(holes) > 0:\n            for hole in holes:\n                self.draw_rotated_box_with_label(hole, alpha, edge_color)\n\n        # draw text\n        if text is not None:\n            text_position = self.get_text_position_from_binary_mask(binary_mask)\n            self.draw_text(text, text_position, text_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if text is not None:\n            # draw text on the mask\n            # first get a box\n            x0, y0, x1, y1 = binary_mask.bbox()\n            box_area = (x1 - x0) * (y1 - y0)\n            if box_area < area_threshold:\n                # draw text on the center of the mask\n                text_pos = ((x0 + x1) / 2, (y0 + y1) / 2)\n            else:\n                # draw text on the mask\n                text_pos = (x0, y0)\n\n            # since the text background is dark, we don't want the text to be dark\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            font_size = (\n                np.clip((box_area / area_threshold - 0.02) / 0.08 + 1, 1.2, 2)\n                * 0.5\n                * self._default_font_size\n            )\n            self.draw_text(text, text_pos, color=text_color, font_size=font_size)\n\n        # draw mask\n        # draw mask as polygon\n        for polygon in binary_mask.polygons:\n            self.draw_polygon(polygon, color=color, alpha=alpha, edge_color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # find connected components\n        polygons = find_polygons(binary_mask)\n        # find holes\n        holes = find_holes(binary_mask)\n\n        if len(polygons) == 0 and len(holes) == 0:\n            return self.output\n\n        # draw polygons\n        for polygon in polygons:\n            self.draw_polygon(polygon, color=edge_color, alpha=alpha)\n\n        # draw holes\n        for hole in holes:\n            self.draw_hole(hole, color=edge_color, alpha=alpha)\n\n        # draw text\n        if text is not None:\n            text_pos = (self.output.width // 2, self.output.height // 2)\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            self.draw_text(text, text_pos, color=text_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        mask = GenericMask(binary_mask)\n        if len(mask.polygons) > 0:\n            for polygon in mask.polygons:\n                self.draw_polygon(polygon, color=color, alpha=alpha)\n\n        # draw text\n        if text is not None:\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            font_size = self._default_font_size\n            self.draw_text(text, mask.centroid, color=text_color, font_size=font_size)\n\n        # draw mask with holes\n        if len(mask.holes) > 0:\n            for hole in mask.holes:\n                if hole.area > area_threshold * self.output.height * self.output.width:\n                    for polygon in hole.polygons:\n                        self.draw_polygon(polygon, color=edge_color, alpha=alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        self.output.ax.add_patch(\n            mpl.patches.Polygon(\n                binary_mask.nonzero(),\n                fill=True,\n                edgecolor=edge_color,\n                alpha=alpha,\n                closed=True,\n            )\n        )\n\n        # draw text\n        if text is not None:\n            # find the center of the mask\n            x0, y0 = np.median(binary_mask.nonzero(), axis=1)\n            # draw text\n            self.draw_text(text, (x0, y0), color=edge_color)\n\n        # draw mask with holes\n        if len(binary_mask.polygons) > 0:\n            for polygon in binary_mask.polygons:\n                if polygon.area > area_threshold:\n                    self.draw_polygon(polygon, color, alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask as polygon\n        # if the mask is small, draw it as a polygon\n        if binary_mask.area() < area_threshold * self.output.scale:\n            self.draw_polygon(binary_mask, color, alpha=alpha)\n            return self.output\n\n        # draw mask as mask with holes\n        # if the mask is large, draw it as a mask with holes\n        for polygon in binary_mask.polygons:\n            self.draw_polygon(polygon, color, alpha=alpha)\n            for hole in polygon.holes:\n                self.draw_polygon(hole, edge_color, alpha=alpha)\n\n        # draw text on mask\n        if text is not None:\n            self.draw_text(text, binary_mask.bbox(), color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # get connected components\n        connected_components = measure.label(binary_mask)\n        # get the area of each connected component\n        areas = [x.area() for x in connected_components]\n        # get the indices of connected components in descending order of area\n        sorted_idxs = np.argsort(-areas).tolist()\n        # get the connected components in descending order of area\n        connected_components = [connected_components[idx] for idx in sorted_idxs]\n\n        # draw the connected components\n        for connected_component in connected_components:\n            if connected_component.area >= area_threshold:\n                self.draw_polygon(connected_component.polygons, color, edge_color, alpha)\n\n        # draw text on the mask\n        if text is not None:\n            # get the center of the mask\n            cnt_x, cnt_y = np.median(binary_mask.nonzero(), axis=1)\n            # get the height ratio of the mask\n            height_ratio = binary_mask.shape[0] / np.sqrt(self.output.height * self.output.width)\n            # get the color of the text\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            # get the font size of the text\n            font_size = np.clip((height_ratio - 0.02) / 0.08 + 1, 1.2, 2) * 0.5 * self._default_font_size\n            # draw text on the mask\n            self.draw_text(text, (cnt_x, cnt_y), text_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        self.output.ax.add_patch(\n            mpl.patches.Polygon(\n                binary_mask.nonzero().T,\n                fill=True,\n                facecolor=color,\n                edgecolor=edge_color,\n                alpha=alpha,\n            )\n        )\n\n        # draw text\n        if text is not None:\n            # find the center of the mask\n            cnt_x, cnt_y = np.median(binary_mask.nonzero(), axis=1)\n            # find the area of the mask\n            area = binary_mask.sum()\n            # don't draw text when the area is too small\n            if area > area_threshold:\n                # use thinner text when the area is small\n                font_size = (\n                    self._default_font_size / 6\n                    if area < _SMALL_OBJECT_AREA_THRESH * self.output.scale\n                    else self._default_font_size\n                )\n                # use darker color when the area is small\n                label_color = self._change_color_brightness(color, brightness_factor=0.7)\n                self.draw_text(text, (cnt_x, cnt_y), color=label_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if np.max(binary_mask) == 0:\n            return self.output\n\n        if np.min(binary_mask) == 0:\n            binary_mask = binary_mask > 0\n\n        if area_threshold is not None:\n            area_threshold = area_threshold * self.output.scale\n\n        if text is not None:\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            font_size = self._default_font_size * 0.5\n\n        for connected_component in measure.label(binary_mask):\n            if connected_component.area < area_threshold:\n                continue\n\n            # draw connected component\n            for segment in connected_component.polygons:\n                self.draw_polygon(segment.reshape(-1, 2), color, alpha)\n\n            if text is not None:\n                # get the center of the connected component\n                cnt_x, cnt_y = np.median(connected_component.coords.nonzero(), axis=1)[::-1]\n                self.draw_text(text, (cnt_x, cnt_y), text_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw mask\n        if binary_mask.dtype != np.uint8:\n            binary_mask = binary_mask.astype(np.uint8)\n\n        # draw mask with holes\n        if np.max(binary_mask) == 1:\n            mask = mpl.colors.to_rgba(color, alpha=alpha)\n            self.output.ax.imshow(binary_mask, cmap=mask)\n\n            if text is not None:\n                # draw text\n                height = self.output.height\n                width = self.output.width\n                text_x = int(width / 2)\n                text_y = int(height / 2)\n                self.draw_text(text, (text_x, text_y), color=edge_color)\n\n        # draw polygons\n        else:\n            # find polygons\n            polygons = mpl.measure.find_contours(binary_mask)\n            for polygon in polygons:\n                if len(polygon) > area_threshold:\n                    self.draw_polygon(polygon.reshape(-1, 2), color, alpha=alpha, edge_color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        if binary_mask.dtype != np.uint8:\n            binary_mask = binary_mask.astype(np.uint8)\n\n        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        if binary_mask.dtype != np.uint8:\n            binary_mask = binary_mask.astype(np.uint8)\n\n        # draw mask\n        self.output.ax.imshow(binary_mask, cmap=\"gray\", alpha=alpha)\n\n        # draw mask with edges\n        self.output.ax.imshow(binary_mask, cmap=\"Greys_r\", alpha=alpha)\n\n        # draw text\n        if text is not None:\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n            text_pos = (\n                binary_mask.shape[1] / 2,\n                binary_mask.shape[0] / 2,\n            )  # middle of the mask\n            font_size = (\n                self._default_font_size\n                * max(binary_mask.shape[0] / self.output.height, binary_mask.shape[1] / self.output.width)\n                / 4\n            )\n            self.draw_text(text, text_pos, color=text_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if text is None:\n            text = \"\"\n\n        # if the mask is too small, skip\n        if binary_mask.area() < area_threshold * self.output.height * self.output.width:\n            return self.output\n\n        # draw the mask\n        self.output.ax.imshow(binary_mask, cmap=mpl.colors.ListedColormap(color))\n\n        # draw the edges\n        self.output.ax.imshow(binary_mask, cmap=mpl.colors.ListedColormap(edge_color), alpha=alpha)\n\n        # draw text\n        if text:\n            text_pos = (\n                binary_mask.bbox()[0] + binary_mask.bbox()[2] / 2,\n                binary_mask.bbox()[1] + binary_mask.bbox()[3] / 2,\n            )\n            font_size = self._default_font_size\n            self.draw_text(text, text_pos, color=color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Expect an Instances object, but got {type(input)}!\"\n    assert isinstance(other, Instances), f\"Expect an Instances object, but got {type(other)}!\"\n\n    if size_as_tensor:\n        assert torch.all(input.image_size == other.image_size), \"image_size mismatch!\"\n    else:\n        assert input.image_size == other.image_size, \"image_size mismatch!\"\n\n    for name in input._fields:\n        input_val = getattr(input, name)\n        other_val = getattr(other, name)\n\n        if isinstance(input_val, Boxes):\n            assert input_val.tensor.allclose(other_val.tensor), f\"{name} mismatch!\"\n        elif isinstance(input_val, ROIMasks):\n            assert input_val.tensor.allclose(other_val.tensor), f\"{name} mismatch!\"\n        elif isinstance(input_val, torch.Tensor):\n            assert input_val.allclose(other_val, rtol=rtol), f\"{name} mismatch!\"\n        else:\n            raise ValueError(f\"Unknown field type {type(input_val)} for field {name}!\")\n\n    return True\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert (\n            input.image_size.shape == other.image_size.shape\n        ), f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n\n    for field_name in input._fields:\n        if field_name == \"image_size\":\n            continue\n\n        field_val = getattr(input, field_name)\n        other_field_val = getattr(other, field_name)\n\n        if isinstance(field_val, Boxes):\n            assert field_val.tensor.shape == other_field_val.tensor.shape\n            assert torch.allclose(field_val.tensor, other_field_val.tensor)\n        elif isinstance(field_val, ROIMasks):\n            assert field_val.tensor.shape == other_field_val.tensor.shape\n            assert torch.allclose(field_val.tensor, other_field_val.tensor)\n        elif isinstance(field_val, torch.Tensor):\n            assert field_val.shape == other_field_val.shape\n            assert torch.allclose(field_val, other_field_val, rtol=rtol)\n        else:\n            try:\n                assert field_val == other_field_val\n            except AssertionError:\n                raise AssertionError(\n                    f\"{msg} {field_name} mismatch: {field_val} vs {other_field_val}\"\n                )\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Expect an Instances object, but got {type(input)}!\"\n    assert isinstance(other, Instances), f\"Expect an Instances object, but got {type(other)}!\"\n\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), f\"{msg}image_size mismatch!\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size mismatch!\"\n\n    for name in input._fields:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), f\"{msg}{name} mismatch!\"\n        elif isinstance(val, Boxes):\n            assert val.tensor.allclose(other_val.tensor, rtol=rtol), f\"{msg}{name} mismatch!\"\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.allclose(other_val.tensor, rtol=rtol), f\"{msg}{name} mismatch!\"\n        elif isinstance(val, (list, tuple)):\n            assert len(val) == len(other_val), f\"{msg}{name} length mismatch!\"\n            for i in range(len(val)):\n                assert val[i] == other_val[i], f\"{msg}{name}[{i}] mismatch!\"\n        elif isinstance(val, np.ndarray):\n            assert np.array_equal(val, other_val), f\"{msg}{name} mismatch!\"\n        else:\n            raise ValueError(f\"Unknown field type {type(val)} for {name}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Expect an Instances object, but got {type(input)}!\"\n    assert isinstance(other, Instances), f\"Expect an Instances object, but got {type(other)}!\"\n\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n\n    for name in input._fields:\n        if name not in other._fields:\n            raise AssertionError(f\"field '{name}' is not found in the other instances.\")\n\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n\n        if isinstance(val, Boxes):\n            assert val.tensor.shape == other_val.tensor.shape, (\n                f\"field '{name}' has different shape: {val.tensor.shape} vs {other_val.tensor.shape}\"\n            )\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"field '{name}' has different values: {val.tensor} vs {other_val.tensor}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.shape == other_val.tensor.shape, (\n                f\"field '{name}' has different shape: {val.tensor.shape} vs {other_val.tensor.shape}\"\n            )\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"field '{name}' has different values: {val.tensor} vs {other_val.tensor}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert val.shape == other_val.shape, (\n                f\"field '{name}' has different shape: {val.shape} vs {other_val.shape}\"\n            )\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"field '{name}' has different values: {val} vs {other_val}\"\n            )\n        else"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Expect an Instances object, but got {type(input)}!\"\n    assert isinstance(other, Instances), f\"Expect an Instances object, but got {type(other)}!\"\n\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size),\n            torch.tensor(other.image_size),\n            rtol=rtol,\n        ), f\"Image sizes are different: {input.image_size} vs. {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"Image sizes are different: {input.image_size} vs. {other.image_size}\"\n\n    for name in input._fields:\n        if name == \"pred_masks\":\n            assert torch.allclose(\n                input.pred_masks,\n                other.pred_masks,\n                rtol=rtol,\n            ), f\"Field {name} is different: {input.pred_masks} vs. {other.pred_masks}\"\n        elif name == \"pred_boxes\":\n            assert input.pred_boxes.tensor.shape == other.pred_boxes.tensor.shape, f\"Field {name} has different shapes: {input.pred_boxes.tensor.shape} vs. {other.pred_boxes.tensor.shape}\"\n            assert torch.allclose(\n                input.pred_boxes.tensor,\n                other.pred_boxes.tensor,\n                rtol=rtol,\n            ), f\"Field {name} is different: {input.pred_boxes} vs. {other.pred_boxes}\"\n        elif name == \"pred_keypoints\":\n            assert input.pred_keypoints.shape == other.pred_keypoints.shape, f\"Field {name} has different shapes: {input.pred_keypoints.shape} vs. {other.pred_keypoints.shape}\"\n            assert torch.allclose(\n                input.pred_keypoints,\n                other.pred_keypoints,\n                rtol=rtol,\n            ), f\"Field {name} is different: {input.pred_keypoints} vs. {other.pred_keypoints}\"\n        elif name == \"gt_boxes\":\n            assert input.gt_boxes.tensor.shape == other.gt_boxes.tensor.shape, f"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n    assert isinstance(msg, str)\n\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size)\n    else:\n        assert input.image_size == other.image_size\n\n    for field in input._fields:\n        if field in [\"pred_boxes\", \"gt_boxes\"]:\n            assert_boxes_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"pred_masks\":\n            assert_masks_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"gt_masks\":\n            assert_masks_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"pred_keypoints\":\n            assert_keypoints_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"gt_keypoints\":\n            assert_keypoints_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"gt_classes\":\n            assert_classes_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"scores\":\n            assert_scores_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"pred_classes\":\n            assert_classes_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"pred_boxes\":\n            assert_boxes_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"gt_boxes\":\n            assert_boxes_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"pred_masks\":\n            assert_masks_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"gt_masks\":\n            assert_masks_allclose(getattr(input, field), getattr(other, field), msg=msg)\n        elif field == \"pred_keypoints\":\n            assert_keypoints_allclose(getattr(input, field), getattr(other, field), msg=msg)\n       "}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(f\"Expect two Instances objects, but got {type(input)} and {type(other)}!\")\n    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), f\"Expect two Instances objects, but got {type(input)} and {type(other)}!\"\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size), torch.tensor(other.image_size)\n        ), f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n    for name in input._fields:\n        val1 = getattr(input, name)\n        val2 = getattr(other, name)\n        if isinstance(val1, Boxes):\n            assert val1.tensor.allclose(val2.tensor), f\"Boxes field {name} mismatch\"\n        elif isinstance(val1, ROIMasks):\n            assert val1.tensor.allclose(val2.tensor), f\"ROIMasks field {name} mismatch\"\n        elif isinstance(val1, torch.Tensor):\n            assert torch.allclose(val1, val2, rtol=rtol), f\"Tensor field {name} mismatch\"\n        elif val1 != val2:\n            raise AssertionError(f\"{msg}Field {name} mismatch: {val1} vs {val2}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n    assert input.has_field(\"pred_boxes\") == other.has_field(\"pred_boxes\")\n    assert input.has_field(\"pred_masks\") == other.has_field(\"pred_masks\")\n    assert input.has_field(\"pred_keypoints\") == other.has_field(\"pred_keypoints\")\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size)\n    else:\n        assert input.image_size == other.image_size\n\n    for name in input._fields:\n        if name == \"pred_boxes\":\n            assert Boxes.allclose(input.pred_boxes, other.pred_boxes)\n        elif name == \"pred_masks\":\n            assert ROIMasks.allclose(input.pred_masks, other.pred_masks)\n        elif name == \"pred_keypoints\":\n            assert torch.allclose(input.pred_keypoints, other.pred_keypoints)\n        else:\n            try:\n                assert torch.allclose(getattr(input, name), getattr(other, name), rtol=rtol)\n            except TypeError:\n                raise ValueError(f\"Unknown field type for field {name}\")\n\n    if msg:\n        msg = msg + \"\\n\"\n    else:\n        msg = \"\"\n\n    msg += f\"image_size: {input.image_size} vs. {other.image_size}\\n\"\n    for name in input._fields:\n        if name == \"pred_boxes\":\n            msg += f\"pred_boxes: {input.pred_boxes} vs. {other.pred_boxes}\\n\"\n        elif name == \"pred_masks\":\n            msg += f\"pred_masks: {input.pred_masks} vs. {other.pred_masks}\\n\"\n        elif name == \"pred_keypoints\":\n            msg += f\"pred_keypoints: {input.pred_keypoints} vs. {other.pred_keypoints}\\n\"\n        else:\n            msg += f\"{name}: {getattr(input, name)} vs. {getattr(other, name)}\\n\"\n\n    assert input.image_size == other.image_size, msg\n    for name in input._fields:\n        if name == \"pred_boxes\":\n           "}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n\n    assert input.image_size == other.image_size, (\n        f\"image_size mismatch: {input.image_size} vs. {other.image_size}\"\n    )\n\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size), (\n            f\"image_size mismatch: {input.image_size} vs. {other.image_size}\"\n        )\n\n    for field in input._fields:\n        if field == \"image_size\":\n            continue\n\n        input_field = getattr(input, field)\n        other_field = getattr(other, field)\n\n        if isinstance(input_field, Boxes):\n            assert torch.allclose(\n                input_field.tensor, other_field.tensor, rtol=rtol\n            ), f\"{field} Boxes mismatch: {input_field} vs. {other_field}\"\n        elif isinstance(input_field, ROIMasks):\n            assert torch.allclose(\n                input_field.tensor, other_field.tensor, rtol=rtol\n            ), f\"{field} ROIMasks mismatch: {input_field} vs. {other_field}\"\n        elif isinstance(input_field, torch.Tensor):\n            assert torch.allclose(\n                input_field, other_field, rtol=rtol\n            ), f\"{field} tensor mismatch: {input_field} vs. {other_field}\"\n        else:\n            raise ValueError(f\"Unknown field type {type(input_field)}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), \"input must be an Instances object\"\n    assert isinstance(other, Instances), \"other must be an Instances object\"\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n\n    for field_name in input._fields:\n        if field_name == \"image_size\":\n            continue\n        input_field = getattr(input, field_name)\n        other_field = getattr(other, field_name)\n        if isinstance(input_field, torch.Tensor):\n            assert torch.allclose(input_field, other_field, rtol=rtol), (\n                f\"{msg}field '{field_name}' mismatch: \"\n                f\"{input_field} vs {other_field}\"\n            )\n        elif isinstance(input_field, Boxes):\n            assert input_field.tensor.allclose(\n                other_field.tensor, rtol=rtol\n            ), f\"{msg}field '{field_name}' mismatch: {input_field} vs {other_field}\"\n        elif isinstance(input_field, ROIMasks):\n            assert input_field.tensor.allclose(\n                other_field.tensor, rtol=rtol\n            ), f\"{msg}field '{field_name}' mismatch: {input_field} vs {other_field}\"\n        elif isinstance(input_field, np.ndarray):\n            assert np.allclose(input_field, other_field, rtol=rtol), (\n                f\"{msg}field '{field_name}' mismatch: \"\n                f\"{input_field} vs {other_field}\"\n            )\n        else:\n            raise ValueError(f\"Unknown field type: {type(input_field)}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Expect an Instances object, but got {type(input)}!\"\n    assert isinstance(other, Instances), f\"Expect an Instances object, but got {type(other)}!\"\n\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size), torch.tensor(other.image_size)\n        ), f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"image_size mismatch: {input.image_size} vs {other.image_size}\"\n\n    for name in input._fields:\n        if name == \"image_size\":\n            continue\n        val1 = getattr(input, name, None)\n        val2 = getattr(other, name, None)\n        if val1 is None:\n            assert val2 is None, f\"Field {name} is None in the first instance but not in the second\"\n            continue\n        if val2 is None:\n            assert val1 is None, f\"Field {name} is None in the second instance but not in the first\"\n            continue\n        if isinstance(val1, Boxes):\n            assert torch.allclose(val1.tensor, val2.tensor), f\"Field {name} mismatch\"\n        elif isinstance(val1, ROIMasks):\n            assert torch.allclose(val1.tensor, val2.tensor), f\"Field {name} mismatch\"\n        elif isinstance(val1, torch.Tensor):\n            assert torch.allclose(val1, val2, rtol=rtol), f\"Field {name} mismatch\"\n        else:\n            raise ValueError(f\"Unknown type of field {name}: {type(val1)}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.as_tensor(input.image_size), torch.as_tensor(other.image_size)\n        ), f\"image_size mismatch: {input.image_size} != {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, (\n            f\"image_size mismatch: {input.image_size} != {other.image_size}\"\n        )\n\n    for field in input._fields:\n        if field == \"pred_boxes\":\n            assert Boxes.allclose(\n                input.get(field), other.get(field), rtol=rtol, msg=msg\n            ), f\"Field {field} mismatch\"\n        elif field == \"pred_masks\":\n            assert ROIMasks.allclose(\n                input.get(field), other.get(field), rtol=rtol, msg=msg\n            ), f\"Field {field} mismatch\"\n        elif field == \"pred_keypoints\":\n            assert torch.allclose(\n                input.get(field), other.get(field), rtol=rtol, msg=msg\n            ), f\"Field {field} mismatch\"\n        else:\n            try:\n                assert torch.allclose(\n                    input.get(field), other.get(field), rtol=rtol, msg=msg\n                ), f\"Field {field} mismatch\"\n            except ValueError:\n                raise ValueError(\n                    f\"Unknown field type {field} for comparison. \"\n                    \"Please add this field type to the assert_instances_allclose function.\"\n                )\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(f\"Expected an Instances object, got {type(input)}!\")\n    if not isinstance(other, Instances):\n        raise ValueError(f\"Expected an Instances object, got {type(other)}!\")\n\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"{msg}image_size mismatch: \"\n            f\"{input.image_size} != {other.image_size}\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg}image_size mismatch: \"\n            f\"{input.image_size} != {other.image_size}\"\n        )\n\n    for name in input._fields:\n        if name == \"image_size\":\n            continue\n        val1 = getattr(input, name)\n        val2 = getattr(other, name)\n        if isinstance(val1, Boxes):\n            assert torch.allclose(val1.tensor, val2.tensor, rtol=rtol), (\n                f\"{msg}field '{name}' mismatch: \"\n                f\"{val1.tensor} != {val2.tensor}\"\n            )\n        elif isinstance(val1, ROIMasks):\n            assert torch.allclose(val1.tensor, val2.tensor, rtol=rtol), (\n                f\"{msg}field '{name}' mismatch: \"\n                f\"{val1.tensor} != {val2.tensor}\"\n            )\n        elif isinstance(val1, torch.Tensor):\n            assert torch.allclose(val1, val2, rtol=rtol), (\n                f\"{msg}field '{name}' mismatch: \"\n                f\"{val1} != {val2}\"\n            )\n        else:\n            assert val1 == val2, (\n                f\"{msg}field '{name}' mismatch: \"\n                f\"{val1} != {val2}\"\n            )"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), (\n        \"Both arguments should be of type Instances, but got \"\n        f\"input of type {type(input)} and other of type {type(other)}.\"\n    )\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"Image sizes do not match: {input.image_size} vs {other.image_size}.\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"Image sizes do not match: {input.image_size} vs {other.image_size}.\"\n        )\n    for name in input._fields:\n        if name == \"image_size\":\n            continue\n        val1 = getattr(input, name, None)\n        val2 = getattr(other, name, None)\n        if val1 is None or val2 is None:\n            assert val1 is val2, f\"Field {name} is not None in one of the instances.\"\n            continue\n        if isinstance(val1, Boxes):\n            assert torch.allclose(val1.tensor, val2.tensor, rtol=rtol), (\n                f\"Field {name} is not equal: {val1.tensor} vs {val2.tensor}.\"\n            )\n        elif isinstance(val1, ROIMasks):\n            assert torch.allclose(val1.tensor, val2.tensor, rtol=rtol), (\n                f\"Field {name} is not equal: {val1.tensor} vs {val2.tensor}.\"\n            )\n        elif isinstance(val1, torch.Tensor):\n            assert torch.allclose(val1, val2, rtol=rtol), (\n                f\"Field {name} is not equal: {val1} vs {val2}.\"\n            )\n        else:\n            raise ValueError(f\"Unknown field type: {type(val1)}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if isinstance(input.image_size, torch.Tensor) and size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size), f\"{msg} image_size mismatch!\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} image_size mismatch!\"\n\n    for field in input._fields:\n        if field == \"image_size\":\n            continue\n\n        val1 = getattr(input, field)\n        val2 = getattr(other, field)\n        if isinstance(val1, Boxes):\n            assert torch.allclose(val1.tensor, val2.tensor), f\"{msg} {field} mismatch!\"\n        elif isinstance(val1, ROIMasks):\n            assert torch.allclose(val1.tensor, val2.tensor), f\"{msg} {field} mismatch!\"\n        elif isinstance(val1, torch.Tensor):\n            assert torch.allclose(val1, val2, rtol=rtol), f\"{msg} {field} mismatch!\"\n        elif isinstance(val1, np.ndarray):\n            assert np.allclose(val1, val2, rtol=rtol), f\"{msg} {field} mismatch!\"\n        elif isinstance(val1, list):\n            assert len(val1) == len(val2), f\"{msg} {field} length mismatch!\"\n            for v1, v2 in zip(val1, val2):\n                assert v1 == v2, f\"{msg} {field} mismatch!\"\n        elif isinstance(val1, tuple):\n            assert len(val1) == len(val2), f\"{msg} {field} length mismatch!\"\n            for v1, v2 in zip(val1, val2):\n                assert v1 == v2, f\"{msg} {field} mismatch!\"\n        else:\n            raise ValueError(f\"Unknown field type: {type(val1)}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(f\"Expect an Instances object, but got {type(input)}!\")\n    if not isinstance(other, Instances):\n        raise ValueError(f\"Expect an Instances object, but got {type(other)}!\")\n\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for name in input._fields:\n        if name == \"image_size\":\n            continue\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert val.tensor.allclose(other_val.tensor), msg\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.allclose(other_val.tensor), msg\n        elif isinstance(val, torch.Tensor):\n            assert val.allclose(other_val, rtol=rtol), msg\n        elif isinstance(val, np.ndarray):\n            assert np.array_equal(val, other_val), msg\n        elif isinstance(val, list):\n            assert len(val) == len(other_val), msg\n            for i in range(len(val)):\n                assert_instances_allclose(val[i], other_val[i], rtol=rtol, msg=msg)\n        else:\n            raise ValueError(f\"Unknown field type {type(val)} for field {name}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.all(torch.eq(input.image_size, other.image_size)), (\n            f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n\n    for field in input._fields:\n        val1 = getattr(input, field)\n        val2 = getattr(other, field)\n        if isinstance(val1, Boxes):\n            assert val1.tensor.allclose(val2.tensor), f\"{msg}Boxes {field} mismatch\"\n        elif isinstance(val1, ROIMasks):\n            assert val1.tensor.allclose(val2.tensor), f\"{msg}ROIMasks {field} mismatch\"\n        elif isinstance(val1, torch.Tensor):\n            assert val1.allclose(val2, rtol=rtol), f\"{msg}Tensor {field} mismatch\"\n        elif isinstance(val1, (list, tuple)):\n            assert len(val1) == len(val2), f\"{msg}length mismatch for {field}\"\n            for v1, v2 in zip(val1, val2):\n                assert v1 == v2, f\"{msg}{field} mismatch\"\n        else:\n            raise ValueError(f\"Unknown field type {type(val1)} for field {field}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n    for name in input._fields:\n        if name == \"image_size\":\n            continue\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert val.tensor.allclose(other_val.tensor, rtol=rtol), msg\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.allclose(other_val.tensor, rtol=rtol), msg\n        elif isinstance(val, torch.Tensor):\n            assert val.allclose(other_val, rtol=rtol), msg\n        elif isinstance(val, list):\n            assert len(val) == len(other_val), msg\n            for v, ov in zip(val, other_val):\n                assert_instances_allclose(v, ov, rtol=rtol, msg=msg)\n        elif isinstance(val, dict):\n            assert val.keys() == other_val.keys(), msg\n            for k in val.keys():\n                assert_instances_allclose(val[k], other_val[k], rtol=rtol, msg=msg)\n        elif isinstance(val, (int, float, bool, str)):\n            assert val == other_val, msg\n        else:\n            raise ValueError(f\"Unknown field type {type(val)}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n    assert input.image_size == other.image_size, \"image_size mismatch\"\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size), torch.tensor(other.image_size)\n        ), \"image_size mismatch\"\n    for name in input._fields:\n        input_val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(input_val, Boxes):\n            assert input_val.tensor.equal(other_val.tensor)\n        elif isinstance(input_val, ROIMasks):\n            assert input_val.tensor.equal(other_val.tensor)\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol)\n        else:\n            raise ValueError(f\"Unknown field type {type(input_val)} for field {name}\")\n    return True"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input._fields:\n        if field == \"image_size\":\n            continue\n\n        val1 = getattr(input, field)\n        val2 = getattr(other, field)\n\n        if isinstance(val1, Boxes):\n            assert val1.tensor.allclose(val2.tensor), msg\n        elif isinstance(val1, ROIMasks):\n            assert val1.tensor.allclose(val2.tensor), msg\n        elif isinstance(val1, torch.Tensor):\n            assert val1.allclose(val2, rtol=rtol), msg\n        else:\n            raise ValueError(f\"Unknown field type {type(val1)} for field {field}\")"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        return width * height\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        return width * height\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        wh = self.tensor[:, 2:4]\n        return wh[:, 0] * wh[:, 1]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        return self.tensor[:, 2] * self.tensor[:, 3]\n"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(\n        cfg, input_shape\n    )\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(\n        cfg, input_shape\n    )"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n    return proposal_generator"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator_cls = PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)\n        return proposal_generator_cls(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    cls = PROPOSAL_GENERATOR_REGISTRY.get(name)\n    return cls(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    if cfg.proposal_generator.name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(cfg.proposal_generator.name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = []\n        gt_proposal_deltas = []\n        for proposals_per_image in proposals:\n            gt_classes_per_image = proposals_per_image.gt_classes\n            if len(proposals_per_image) == 0:\n                continue\n            # Append ground-truth class labels\n            gt_classes.append(gt_classes_per_image)\n            # Append ground-truth box2box transform deltas\n            if self.box_reg_loss_type == \"smooth_l1\":\n                gt_proposal_deltas_per_image = self.box2box_transform.get_deltas(\n                    proposals_per_image.proposal_boxes, proposals_per_image.gt_boxes\n                )\n            elif self.box_reg_loss_type == \"giou\":\n                gt_proposal_deltas_per_image = self.box2box_transform.get_giou_deltas(\n                    proposals_per_image.proposal_boxes, proposals_per_image.gt_boxes\n                )\n            elif self.box_reg_loss_type == \"diou\":\n                gt_proposal_deltas_per_image = self.box2box_transform.get_diou_deltas(\n                    proposals_per_image.proposal_boxes, proposals_per_image.gt_boxes\n                )\n            elif self.box_reg_loss_type == \"ciou\":\n                gt_proposal_deltas_per_image = self.box2box_transform.get_ciou_deltas(\n                    proposals_per_image.proposal_boxes, proposals_per_image.gt_boxes\n                )\n            else:\n                raise ValueError(f\"Invalid box_reg_loss_type: {self.box_reg_loss_type}\")\n            gt_proposal_deltas.append(gt_proposal_deltas_per_image)\n\n        gt_classes = cat(gt_classes, dim=0)\n        gt_proposal_deltas = cat(gt_proposal_deltas, dim=0)\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas,\n                gt_proposal_deltas"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = []\n        gt_proposal_deltas = []\n        for proposals_per_image in proposals:\n            gt_classes_per_image = proposals_per_image.gt_classes\n            if len(proposals_per_image) == 0:\n                continue\n            if not self._has_gt(gt_classes_per_image):\n                continue\n            gt_classes.append(gt_classes_per_image)\n            gt_proposal_deltas.append(self.box2box_transform.get_deltas(\n                proposals_per_image.proposal_boxes.tensor, proposals_per_image.gt_boxes.tensor\n            ))\n        if len(gt_classes) == 0:\n            return {}\n\n        gt_classes = cat(gt_classes, dim=0)\n\n        gt_proposal_deltas = cat(gt_proposal_deltas, dim=0)\n        if self.box_reg_loss_type == \"smooth_l1\":\n            box_reg_loss = F.smooth_l1_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                reduction=\"sum\",\n                beta=self.smooth_l1_beta,\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            box_reg_loss = -generalized_box_iou(\n                self.box2box_transform.apply_deltas(proposal_deltas, proposals.proposal_boxes.tensor),\n                proposals.gt_boxes.tensor,\n            ).sum()\n        elif self.box_reg_loss_type == \"diou\":\n            box_reg_loss = -distance_iou(\n                self.box2box_transform.apply_deltas(proposal_deltas, proposals.proposal_boxes.tensor),\n                proposals.gt_boxes.tensor,\n            ).sum()\n        elif self.box_reg_loss_type == \"ciou\":\n            box_reg_loss = -complete_iou(\n                self.box2box_transform.apply_deltas(proposal_deltas, proposals.proposal_boxes.tensor),\n                proposals.gt_boxes.tensor,\n            ).sum()\n        else:\n            raise ValueError(f\"Invalid box_reg_loss_type: {self.box_"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create a new field that contains the gt classes\n            gt_classes = gt_per_image.gt_classes.to(dtype=torch.int64)\n            proposals_per_image.gt_classes = gt_classes\n            proposals_with_gt.append(proposals_per_image)\n\n        # Log the number of proposals per image\n        num_proposals = [len(p) for p in proposals]\n        storage = get_event_storage()\n        storage.put_scalar(\"fast_rcnn/num_proposals_per_image\", torch.as_tensor(num_proposals).sum().item())\n\n        # Log the number of fg-bg samples per image\n        num_fg_bg_samples = [len(p) for p in proposals_with_gt]\n        storage.put_scalar(\"fast_rcnn/num_fg_bg_samples_per_image\", torch.as_tensor(num_fg_bg_samples).sum().item())\n\n        # Log the number of fg samples per image\n        num_fg_samples = [len(p) for p in proposals_with_gt if len(p) > 0]\n        if len(num_fg_samples) > 0:\n            storage.put_scalar(\"fast_rcnn/num_fg_samples_per_image\", torch.as_tensor(num_fg_samples).sum().item())\n\n        # Log the number of bg samples per image\n        num_bg_samples = [len(p) for p in proposals_with_gt if len(p) == 0]\n        if len(num_bg_samples) > 0:\n            storage.put_scalar(\"fast_rcnn/num_bg_samples_per_image\", torch.as_tensor(num_bg_samples).sum().item())\n\n        # Log the number of fg-bg samples per class\n        num_fg_bg_samples_per_cls = [len(p) for p in proposals_with_gt for _ in range(p"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = Instances(proposals_per_image.image_size)\n            proposals_per_image.proposal_boxes = proposals_per_image.gt_boxes\n            proposals_per_image.gt_classes = gt_per_image.gt_classes\n            proposals_with_gt.append(proposals_per_image)\n\n        dis_regularization_loss = 0\n        if self.smooth_l1_beta > 0:\n            dis_regularization_loss = (\n                torch.abs(proposal_deltas).sum() * self.smooth_l1_beta / (2.0 * proposal_deltas.numel())\n            )\n\n        losses = {\n            \"loss_cls\": _fast_rcnn_loss(\n                scores, proposals_with_gt, self.box2box_transform.weights, self.loss_weight[\"loss_cls\"]\n            ),\n            \"loss_box_reg\": _fast_rcnn_box_reg_loss(\n                proposal_deltas,\n                proposals_with_gt,\n                self.box2box_transform,\n                self.smooth_l1_beta,\n                self.box_reg_loss_type,\n                self.loss_weight[\"loss_box_reg\"],\n            ),\n        }\n        losses[\"loss_dis_regularization\"] = dis_regularization_loss\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = [x.gt_classes for x in proposals]\n        gt_proposal_deltas = [x.gt_boxes.get_deltas(x.proposal_boxes, self.box2box_transform) for x in proposals]\n\n        # Log the stats of classification and box regression for debugging and evaluating results.\n        _log_classification_stats(scores, gt_classes)\n\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                gt_classes,\n                box_reg_loss_type=self.box_reg_loss_type,\n                smooth_l1_beta=self.smooth_l1_beta,\n            )\n        else:\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                gt_classes,\n                box_reg_loss_type=self.box_reg_loss_type,\n            )\n\n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"none\")\n\n        if self.loss_weight is not None:\n            if isinstance(self.loss_weight, dict):\n                loss_cls = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n                loss_box_reg = loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0)\n            else:\n                loss_cls = loss_cls * self.loss_weight\n                loss_box_reg = loss_box_reg * self.loss_weight\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = Instances(proposals_per_image.image_size)\n            proposals_per_image.proposal_boxes = proposals_per_image.gt_boxes = proposals_per_image.gt_classes = None\n            proposals_per_image.proposal_boxes = proposals_per_image.gt_boxes = proposals_per_image.gt_classes = None\n            if len(proposals_per_image) > 0:\n                proposals_per_image.proposal_boxes = proposals_per_image.gt_boxes = proposals_per_image.gt_classes = None\n                proposals_with_gt.append(proposals_per_image)\n        if len(proposals_with_gt) == 0:\n            return {}\n\n        # Log the number of proposals per image\n        num_proposals = [len(p) for p in proposals_with_gt]\n        storage = get_event_storage()\n        storage.put_scalar(\"fast_rcnn/num_proposals_per_image\", torch.as_tensor(num_proposals).to(type(self)).mean())\n\n        gt_classes = [p.gt_classes for p in proposals_with_gt]\n        gt_classes = torch.cat(gt_classes)\n        gt_boxes = [p.gt_boxes for p in proposals_with_gt]\n        gt_boxes = Boxes.cat(gt_boxes)\n\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas, proposals_with_gt, gt_boxes, self.smooth_l1_beta\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas, proposals_with_gt, gt_boxes, self.smooth_l1_beta, loss_type=\"giou\"\n            )\n        elif self.box_reg_loss_type == \"diou\":\n            loss_box_reg"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        gt_proposal_deltas = cat([p.gt_boxes.box2delta(p.proposal_boxes, weights=self.box2box_transform.weights) for p in proposals], dim=0)\n        if self.box_reg_loss_type == \"smooth_l1\":\n            box_reg_loss = F.smooth_l1_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                reduction=\"sum\",\n                beta=self.smooth_l1_beta,\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            box_reg_loss = -generalized_box_iou(\n                self.box2box_transform.apply_deltas(proposal_deltas, proposals.proposal_boxes.tensor),\n                proposals.gt_boxes.tensor,\n            ).sum()\n        elif self.box_reg_loss_type == \"diou\":\n            box_reg_loss = -distance_iou(\n                self.box2box_transform.apply_deltas(proposal_deltas, proposals.proposal_boxes.tensor),\n                proposals.gt_boxes.tensor,\n            ).sum()\n        elif self.box_reg_loss_type == \"ciou\":\n            box_reg_loss = -complete_iou(\n                self.box2box_transform.apply_deltas(proposal_deltas, proposals.proposal_boxes.tensor),\n                proposals.gt_boxes.tensor,\n            ).sum()\n        else:\n            raise NotImplementedError(f\"Invalid box_reg_loss_type: {self.box_reg_loss_type}\")\n\n        if self.loss_weight is not None:\n            box_reg_loss *= self.loss_weight.get(\"loss_box_reg\", 1.0)\n\n        if self.num_classes == 1:\n            gt_classes_for_loss = gt_classes.long()\n        else:\n            gt_classes_for_loss = F.one_hot(gt_classes.to(torch.int64), num_classes=self.num_classes + 1)\n            gt_classes_for_loss = gt_classes_for"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create a `gt_boxes` field in the proposals, which is used for computing the box regression loss.\n            proposals_per_image.gt_boxes = gt_per_image.gt_boxes\n            proposals_with_gt.append(proposals_per_image)\n\n        dis_per_level = []\n        reg_per_level = []\n        for scores_per_level, proposal_deltas_per_level, proposals_per_level in zip(\n            scores, proposal_deltas, proposals_with_gt\n        ):\n            dis_per_level.append(self.losses_dis(scores_per_level, proposals_per_level))\n            reg_per_level.append(self.losses_reg(proposal_deltas_per_level, proposals_per_level))\n        dis_per_level = sum(dis_per_level)\n        reg_per_level = sum(reg_per_level)\n        return {\"loss_cls\": dis_per_level, \"loss_box_reg\": reg_per_level}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create ground-truth labels for each proposal\n            # Note: proposal_boxes may include proposals with zero area, in which case they\n            # cannot be matched to gt objects.\n            match_quality_matrix = pairwise_iou(\n                proposals_per_image.proposal_boxes, gt_per_image.gt_boxes\n            )\n            matched_idxs, _ = match_quality_matrix.max(dim=1)\n            gt_classes = gt_per_image.gt_classes[matched_idxs]\n            gt_classes = gt_classes.to(dtype=torch.int64)\n            # Label unmatched proposals (0 label from matcher) as background (label=num_classes)\n            gt_classes[matched_idxs == 0] = self.num_classes\n            proposals_per_image.gt_classes = gt_classes\n\n            # Get the targets of each proposal\n            proposal_boxes = proposals_per_image.proposal_boxes\n            gt_boxes = proposals_per_image.gt_instances.gt_boxes\n            box_targets = self.box2box_transform.get_deltas(proposal_boxes, gt_boxes)\n            proposals_per_image.gt_proposals = Instances(proposals_per_image.image_size)\n            proposals_per_image.gt_proposals.proposal_boxes = proposal_boxes\n            proposals_per_image.gt_proposals.gt_boxes = gt_boxes\n            proposals_per_image.gt_proposals.gt_classes = gt_classes\n            proposals_per_image.gt_proposals.gt_deltas = box_targets\n            proposals_with_gt.append(proposals_per_image)\n\n        # Log the number of proposals per image\n        num_proposals = [len(p) for p in proposals]\n        storage = get_event_storage()\n        storage.put_scalar(\"fast_rcnn/num_proposals\", torch.as_tensor(num_proposals).sum())\n\n        # Log the number of fg/bg samples"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create a new Instances object with gt_boxes and gt_classes fields\n            # from the gt_instances field of the original Instances object\n            proposals_per_image.gt_boxes = gt_per_image.gt_boxes\n            proposals_per_image.gt_classes = gt_per_image.gt_classes\n            proposals_with_gt.append(proposals_per_image)\n\n        discretized_boxes = [x.proposal_boxes for x in proposals_with_gt]\n        gt_classes = [x.gt_classes for x in proposals_with_gt]\n        gt_boxes = [x.gt_boxes for x in proposals_with_gt]\n\n        # Log the classification statistics to EventStorage\n        _log_classification_stats(scores, gt_classes)\n\n        fg_inds = torch.cat(\n            [\n                torch.full_like(gt_classes_per_image[gt_classes_per_image >= 0], True)\n                for gt_classes_per_image in gt_classes\n            ],\n            dim=0,\n        )\n        bg_inds = torch.cat(\n            [\n                torch.full_like(gt_classes_per_image[gt_classes_per_image < 0], True)\n                for gt_classes_per_image in gt_classes\n            ],\n            dim=0,\n        )\n        num_fg = fg_inds.nonzero().shape[0]\n        num_bg = bg_inds.nonzero().shape[0]\n        num_examples = num_fg + num_bg\n\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = smooth_l1_loss(\n                proposal_deltas[fg_inds],\n                self.box2box_transform.get_deltas(discretized_boxes, gt_boxes)[fg_inds],\n                self.smooth_l1_beta,\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg ="}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = []\n        gt_proposal_deltas = []\n        for proposals_per_image in proposals:\n            gt_classes_per_image = proposals_per_image.gt_classes\n            if len(proposals_per_image) == 0:\n                continue\n            # append ground-truth class labels\n            gt_classes.append(gt_classes_per_image)\n            gt_proposal_deltas.append(\n                self.box2box_transform.get_deltas(\n                    proposals_per_image.proposal_boxes.tensor, proposals_per_image.gt_boxes.tensor\n                )\n            )\n\n        if len(gt_classes) == 0:\n            return {}\n\n        gt_classes = cat(gt_classes, dim=0)\n\n        gt_proposal_deltas = cat(gt_proposal_deltas, dim=0)\n\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                gt_proposal_deltas,\n                proposal_deltas,\n                self.box2box_transform.weights,\n                gt_classes,\n                self.smooth_l1_beta,\n            )\n        else:\n            loss_box_reg = _box_regression_loss(\n                gt_proposal_deltas,\n                proposal_deltas,\n                self.box2box_transform.weights,\n                gt_classes,\n                self.box_reg_loss_type,\n            )\n\n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight.get(\"loss_cls\", 1),\n            \"loss_box_reg\": loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1),\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create a new field in proposals_per_image, which is a copy of proposals_per_image with no fields\n            # The new field is named gt_classes, and its value is a tensor of zeros with the same shape as proposals_per_image.scores\n            # This is done to ensure that the gt_classes field is present in proposals_per_image, even if gt_per_image.gt_classes is not present\n            proposals_per_image.gt_classes = torch.zeros_like(proposals_per_image.scores)\n            if gt_per_image.has(\"gt_classes\"):\n                proposals_per_image.gt_classes = gt_per_image.gt_classes\n            proposals_with_gt.append(proposals_per_image)\n\n        # Log the classification accuracy\n        _log_classification_stats(scores, proposals.gt_instances.gt_classes)\n\n        # Compute the classification loss\n        gt_classes = cat([p.gt_classes for p in proposals_with_gt])\n        gt_classes_target = torch.zeros_like(scores).scatter_(1, gt_classes.unsqueeze(1), 1)\n        loss_cls = F.binary_cross_entropy_with_logits(scores, gt_classes_target)\n        # Compute the box regression loss\n        gt_proposal_deltas = [\n            self.box2box_transform.get_deltas(p.proposal_boxes.tensor, p.gt_boxes.tensor)\n            for p in proposals_with_gt\n        ]\n        gt_proposal_deltas = torch.cat(gt_proposal_deltas, dim=0)\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = F.smooth_l1_loss(\n                proposal_deltas, gt_proposal_deltas, beta=self.smooth_l1_beta, reduction=\"sum\"\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            loss"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = [x.gt_classes for x in proposals]\n        gt_proposal_deltas = [x.gt_proposal_deltas for x in proposals]\n        if self.box_reg_loss_type == \"smooth_l1\":\n            gt_proposal_deltas = [\n                self.box2box_transform.get_deltas(p.proposal_boxes.tensor, p.gt_boxes.tensor)\n                for p in proposals\n            ]\n        else:\n            assert self.box_reg_loss_type in [\"giou\", \"diou\", \"ciou\"]\n            gt_proposal_deltas = [\n                self.box2box_transform.get_deltas(p.proposal_boxes.tensor, p.gt_boxes.tensor, self.box_reg_loss_type)\n                for p in proposals\n            ]\n        gt_proposal_deltas = torch.cat(gt_proposal_deltas, dim=0)\n        gt_classes = torch.cat(gt_classes, dim=0)\n\n        # Log the stats for the predicted boxes\n        _log_classification_stats(scores, gt_classes, prefix=\"fast_rcnn\")\n\n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        # if there is no valid proposal, return 0 loss\n        if proposal_deltas.numel() == 0:\n            loss_box_reg = proposal_deltas.sum()\n        else:\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                gt_classes,\n                box_reg_loss_type=self.box_reg_loss_type,\n                smooth_l1_beta=self.smooth_l1_beta,\n            )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = Instances(proposals_per_image.image_size)\n            proposals_per_image.proposal_boxes = proposals_per_image.gt_boxes\n            proposals_per_image.gt_classes = gt_per_image.gt_classes\n            proposals_with_gt.append(proposals_per_image)\n\n        dis_regularization_weight = 1.0\n        dis_regularization_loss = None\n        if dis_regularization_weight > 0.0:\n            dis_regularization_loss = self.dis_regularization_loss(proposals_with_gt, proposal_deltas)\n            dis_regularization_loss = dis_regularization_loss * dis_regularization_weight\n\n        losses = {\n            \"loss_cls\": self.cls_loss(scores, proposals_with_gt),\n            \"loss_box_reg\": self.box_reg_loss(proposal_deltas, proposals_with_gt),\n        }\n        if dis_regularization_loss is not None:\n            losses[\"loss_dis_reg\"] = dis_regularization_loss\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields(\n                [\"proposal_boxes\", \"objectness_logits\"]\n            )\n            # Append ground-truth bboxes and class labels\n            # to the proposal list\n            proposals_per_image.proposal_boxes = gt_per_image.gt_boxes\n            proposals_per_image.objectness_logits = gt_per_image.gt_classes.float()\n            proposals_with_gt.append(proposals_per_image)\n\n        discretized_boxes = [x.proposal_boxes for x in proposals_with_gt]\n        gt_classes = [x.objectness_logits for x in proposals_with_gt]\n        gt_boxes = [x.gt_boxes for x in proposals_with_gt]\n\n        gt_boxes = [gt_box.tensor for gt_box in gt_boxes]\n        discretized_boxes = [discretized_box.tensor for discretized_box in discretized_boxes]\n\n        gt_classes = cat(gt_classes, dim=0)\n        discretized_boxes = cat(discretized_boxes, dim=0)\n        gt_boxes = cat(gt_boxes, dim=0)\n\n        gt_classes_one_hot = F.one_hot(gt_classes.to(torch.int64), num_classes=self.num_classes + 1)\n        gt_classes_one_hot = gt_classes_one_hot.to(dtype=scores.dtype)\n\n        # log classification stats\n        _log_classification_stats(scores, gt_classes, prefix=\"fast_rcnn\")\n\n        # log losses\n        loss_cls = F.binary_cross_entropy_with_logits(\n            scores, gt_classes_one_hot[..., 1:], reduction=\"sum\"\n        )\n        loss_cls /= max(1, gt_classes.numel())\n\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_deltas,\n            discretized_boxes,\n            gt_boxes,\n            self.box2"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = [x.gt_classes for x in proposals]\n        gt_proposal_deltas = [x.gt_boxes.get_deltas(x.proposal_boxes.tensor, self.box2box_transform.weights) for x in proposals]\n\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                gt_proposal_deltas, proposal_deltas, self.box2box_transform.weights, self.smooth_l1_beta\n            )\n        else:\n            loss_box_reg = _dense_box_regression_loss(\n                gt_proposal_deltas, proposal_deltas, self.box2box_transform.weights, self.smooth_l1_beta, self.box_reg_loss_type\n            )\n\n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"mean\")\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight.get(\"loss_cls\", 1.0),\n            \"loss_box_reg\": loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0),\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create ground truth labels for each proposal.\n            # This is \"label\" in the R-CNN paper.\n            # The labels for each proposal are stored in `gt_classes`.\n            # For each proposal, the value in `gt_classes` is the ground truth label\n            # for the corresponding proposal.\n            # For proposals with a label of 0, the proposal is a background proposal.\n            # For proposals with a label > 0, the proposal is a foreground proposal\n            # and the label indicates the foreground class.\n            if len(proposals_per_image) > 0:\n                match_quality_matrix = pairwise_iou(\n                    proposals_per_image.proposal_boxes, gt_per_image.gt_boxes\n                )\n                matched_idxs, matched_labels = self.matcher(match_quality_matrix)\n                proposals_per_image.gt_classes = gt_per_image.gt_classes[matched_idxs]\n                # Label unmatched proposals (0 label from matcher) as background (label=num_classes)\n                proposals_per_image.gt_classes[matched_labels == 0] = self.num_classes\n                # Store matching gt boxes in proposal attribute\n                proposals_per_image.gt_boxes = gt_per_image.gt_boxes[matched_idxs]\n            proposals_with_gt.append(proposals_per_image)\n\n        # Log the number of fg/bg samples\n        num_fg_samples = sum(\n            len(p.gt_classes)\n            for p in proposals_with_gt\n            if p.has(\"gt_classes\") and p.gt_classes.numel() > 0\n        )\n        storage = get_event_storage()\n        storage.put_scalar(\"fast_rcnn/num_fg_samples\", num_fg_samples)\n\n        # Log the number of proposals\n        num_proposals = sum(p.proposal_boxes.numel() for p in proposals)\n        storage.put_scalar(\"fast_rcnn/num_pro"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create ground-truth labels for each proposal\n            # This is \"gt_classes\" field used for computing classification loss.\n            # It indicates the class of each proposal.\n            gt_classes = gt_per_image.gt_classes[proposals_per_image.gt_ids]\n            # Label background (class zero) as a special case\n            gt_classes[gt_classes == -1] = self.num_classes\n            # Create ground-truth boxes for each proposal\n            # This is \"gt_proposal_deltas\" field used for computing box regression loss.\n            # It indicates the ground-truth box coordinates for each proposal, relative to the proposal's coordinates.\n            gt_proposal_deltas = self.box2box_transform.get_deltas(\n                proposals_per_image.proposal_boxes.tensor, gt_per_image.gt_boxes.tensor\n            )\n            proposals_per_image.gt_classes = gt_classes\n            proposals_per_image.gt_proposal_deltas = gt_proposal_deltas\n            proposals_with_gt.append(proposals_per_image)\n\n        # Log the number of proposals per image that were assigned ground-truth labels\n        num_fg_proposals = [\n            proposals_per_image.gt_classes.numel()\n            for proposals_per_image in proposals_with_gt\n            if proposals_per_image.has(\"gt_classes\")\n        ]\n        storage = get_event_storage()\n        storage.put_scalar(\"fast_rcnn/num_fg_proposals\", torch.as_tensor(num_fg_proposals).sum())\n\n        fg_selection_masks = []\n        bg_selection_masks = []\n        for proposals_per_image in proposals_with_gt:\n            if not proposals_per_image.has(\"gt_classes\"):\n                continue\n            gt_classes = proposals_per_image.gt_classes\n            fg_selection_mask = gt_classes >= 0\n            num_fg = fg_selection_mask.nonzero()."}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create a new Instances object with only the fields needed for loss calculation.\n            proposals_with_gt.append(Instances(proposals_per_image.image_size))\n            proposals_with_gt[-1].proposal_boxes = proposals_per_image.proposal_boxes\n            proposals_with_gt[-1].gt_classes = gt_per_image.gt_classes\n            proposals_with_gt[-1].gt_boxes = gt_per_image.gt_boxes\n\n        # Log the accuracy metrics to EventStorage\n        _log_classification_stats(scores, proposals.gt_classes)\n\n        # Compute the losses\n        loss_cls = F.cross_entropy(\n            scores, proposals.gt_classes, reduction=\"mean\", ignore_index=self.num_classes\n        )\n        loss_box_reg = _box_regression_loss(\n            self.box2box_transform,\n            proposal_deltas,\n            proposals_with_gt,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight.get(\"loss_cls\", 1.0),\n            \"loss_box_reg\": loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0),\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        proposals_with_gt = []\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image = proposals_per_image.copy_with_fields([])\n            # Create a new field in proposals_per_image that has the same shape as gt_per_image.gt_boxes\n            # and contains the indices of the gt_per_image.gt_boxes that each proposal in proposals_per_image overlaps with.\n            # This is used to match the proposals with the ground truth boxes.\n            proposals_per_image.gt_overlaps = gt_per_image.gt_boxes.get_overlaps(\n                proposals_per_image.proposal_boxes\n            )\n            proposals_with_gt.append(proposals_per_image)\n\n        discards = self.label_and_sample_proposals(proposals_with_gt)\n        for proposals_per_image, gt_per_image in zip(proposals, proposals.gt_instances):\n            proposals_per_image.gt_classes = gt_per_image.gt_classes[discards[proposals_per_image]]\n\n        # Log the number of foreground classes and the number of background classes\n        num_fg_classes = torch.unique(proposals.gt_classes).numel() - 1\n        num_bg_classes = 1\n        get_event_storage().put_scalar(\"fast_rcnn/num_fg_classes\", num_fg_classes)\n        get_event_storage().put_scalar(\"fast_rcnn/num_bg_classes\", num_bg_classes)\n\n        (\n            gt_classes,\n            gt_proposal_deltas,\n            gt_proposal_deltas_weights,\n        ) = self.select_training_samples(proposals_with_gt, discards)\n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"mean\")\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_deltas,\n            gt_proposal_deltas,\n            gt_proposal_deltas_weights,\n            box_reg_loss_type=self.box_reg_loss_type,\n            smooth_l"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    return TRACKER_HEADS_REGISTRY.get(cfg.TRACKER_HEAD.NAME)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEADS.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    return TRACKER_HEADS_REGISTRY.get(cfg.TRACKER.NAME)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEADS.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    if tracker_name == \"null\":\n        return None\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(tracker_name)(**cfg.TRACKER.KWARGS)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_HEADS.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker_head = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker_class = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker_class.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    if tracker_name == \"None\":\n        return None\n    else:\n        return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    return TRACKER_HEADS_REGISTRY.get(cfg.TRACKER_HEADS.NAME)(cfg)"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert isinstance(deltas, torch.Tensor), type(deltas)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        assert isinstance(deltas, torch.Tensor), type(deltas)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(boxes, torch.Tensor), type(boxes)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n        return pred_boxes\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        img, k = resize_image(image, 512)\n        img = img.transpose((2, 0, 1))\n        img = np.expand_dims(img, 0)\n        img = img.astype(np.float32)\n        img = img / 255.0\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = img.astype(np.float"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        input_image = image.copy()\n        img, k = resize_image(input_image, 768)\n        img = np.ascontiguousarray(img)\n        img = img.transpose(2, 0, 1)\n        img = img.astype(np.float32) / 255.0\n        img = np.expand_dims(img, 0)\n        img = img.copy()\n        img = img.astype(np.float32)\n        img = img.copy()\n        img = np.ascontiguousarray(img)\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img.copy()\n        img = img"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins.run(image)\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            pass\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins.run(image)\n        if any(tp not in output for tp in anno_type):\n            raise Exception(f'Error anno_type: {anno_type}')\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        out = self.general_ins(image)\n        if len(anno_type) == 1:\n            return out[anno_type[0]]\n        else:\n            return {k: out[k] for k in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins.run(image)\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            pass\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n        output = self.general_ins.run(image)\n        if all(tp in output.keys() for tp in anno_type):\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins.run(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        img, k = resize_image(image, 512)\n        img = np.ascontiguousarray(img[:, :, ::-1])\n        img = np.transpose(img, (2, 0, 1))\n        img = img[None, ...]\n\n        output = self.general_ins(img)\n\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        img, k = resize_image(image, 512)\n        img = img.astype(np.float32) / 255.0\n        img = img.transpose(2, 0, 1)\n        img = np.expand_dims(img, 0)\n        img = np.ascontiguousarray(img)\n\n        img = img.astype(np.float32)\n        img = img.transpose(0, 2, 3, 1)\n        img = np.ascontiguousarray(img)\n\n        result = self.general_ins.run(img)\n        result = result.transpose(0, 3, 1, 2)\n        result = np.ascontiguousarray(result)\n\n        if anno_type is not None:\n            if len(anno_type) == 1:\n                return resize_image_ori(image.shape[0], image.shape[1],\n                                        result[0, anno_type[0]], k)\n            else:\n                return {\n                    tp: resize_image_ori(image.shape[0], image.shape[1],\n                                         result[0, tp], k)\n                    for tp in anno_type\n                }\n        else:\n            return result"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n\n        anno_result = self.general_ins(image)\n        if isinstance(anno_result, dict):\n            if len(anno_type) == 1:\n                return anno_result[anno_type[0]]\n            else:\n                return {tp: anno_result[tp] for tp in anno_type}\n        else:\n            return anno_result"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            assert isinstance(anno_type, (str, list, tuple))\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n        else:\n            anno_type = self.anno_type_map.keys()\n\n        input_dict = {'img': image}\n        output_dict = self.general_ins(input_dict)\n\n        if len(anno_type) == 1:\n            if anno_type[0] in output_dict.keys():\n                return output_dict[anno_type[0]]\n            else:\n                return output_dict\n        else:\n            anno_dict = {}\n            for tp in anno_type:\n                if tp in output_dict.keys():\n                    anno_dict[tp] = output_dict[tp]\n            return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {k: output[k] for k in anno_type if k in output}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n        else:\n            anno_type = list(self.anno_type_map.keys())\n\n        output = self.general_ins(image)\n        if anno_type is not None:\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {k: output[k] for k in anno_type}\n        else:\n            return output\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n        else:\n            anno_type = list(self.anno_type_map.keys())\n\n        output = self.general_ins(image)\n\n        if anno_type is not None:\n            if len(anno_type) == 1:\n                anno_type = anno_type[0]\n                if anno_type in output.keys():\n                    output = output[anno_type]\n                else:\n                    raise Exception(f'Error anno_type: {anno_type}')\n            else:\n                output = {tp: output[tp] for tp in anno_type if tp in output}\n\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n\n        output = self.general_ins(image)\n        if isinstance(output, dict):\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type if tp in output}\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = list(self.anno_type_map.keys())\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        # resize image\n        image, k = resize_image(image, 256)\n\n        # process image\n        output = self.general_ins.run(image)\n\n        # resize output\n        for key in output.keys():\n            output[key] = resize_image_ori(\n                image.shape[0], image.shape[1], output[key], k)\n\n        # filter output\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {key: output[key] for key in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = [tp for tp in self.anno_type_map.keys()]\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        if isinstance(image, np.ndarray):\n            image = image.copy()\n        elif isinstance(image, str):\n            image = cv2.imread(image)\n            image = image.copy()\n        else:\n            raise Exception(f'Error image: {image}')\n\n        image, k = resize_image(image, 512)\n\n        results = self.general_ins.run(image)\n\n        if len(anno_type) == 1:\n            if anno_type[0] in results.keys():\n                results = results[anno_type[0]]\n            else:\n                results = None\n        else:\n            results = {tp: results[tp] for tp in anno_type if tp in results}\n\n        return results"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = list(self.anno_type_map.keys())\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n\n        if isinstance(image, np.ndarray):\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # if image.shape[0] > 1024 or image.shape[1] > 1024:\n        #     image, k = resize_image(image, 1024)\n        # else:\n        #     k = 1.0\n\n        image, k = resize_image(image, 1024)\n\n        image = image.astype(np.float32) / 255.0\n        image = np.transpose(image, [2, 0, 1])\n        image = np.expand_dims(image, axis=0)\n\n        with we.no_sync():\n            with we.no_grad():\n                output = self.general_ins(image)\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type if tp in output.keys()}\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n        else:\n            anno_type = self.anno_type_map.keys()\n\n        img, k = resize_image(image, 512)\n        img = img / 255.0\n        img = img.transpose((2, 0, 1))\n        img = np.expand_dims(img, 0)\n        img = np.ascontiguousarray(img, dtype=np.float32)\n        output = self.general_ins.process(img)\n        output = resize_image_ori(image.shape[0], image.shape[1], output, k)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        elif len(anno_type) > 1:\n            return {tp: output[tp] for tp in anno_type}\n        else:\n            return output"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        keywords = query.split()\n        keywords = [normalize_string(kw) for kw in keywords]\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(int)\n        for kw in keywords:\n            kw_scores = self.bm25(kw)\n            scores = update_url_scores(scores, kw_scores)\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        keywords = normalize_string(query).split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_normalized = normalize_string(query)\n        keywords = query_normalized.split()\n        bm25_scores = [self.bm25(kw) for kw in keywords]\n        result = update_url_scores({}, bm25_scores[0])\n        for i in range(1, len(bm25_scores)):\n            result = update_url_scores(result, bm25_scores[i])\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        results = {}\n        for kw in keywords:\n            results = update_url_scores(results, self.bm25(kw))\n        return results\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        keywords = query.split()\n        keywords = [normalize_string(kw) for kw in keywords]\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_words = normalize_string(query).split()\n        bm25_scores = [self.bm25(word) for word in query_words]\n        aggregated_scores = defaultdict(float)\n        for score in bm25_scores:\n            aggregated_scores = update_url_scores(aggregated_scores, score)\n        return aggregated_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_normalized = normalize_string(query)\n        keywords = query_normalized.split()\n        scores = [self.bm25(kw) for kw in keywords]\n        aggregated_scores = defaultdict(float)\n        for score in scores:\n            aggregated_scores = update_url_scores(aggregated_scores, score)\n        return aggregated_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # Normalize the query string\n        query_normalized = normalize_string(query)\n\n        # Split the query into keywords\n        keywords = query_normalized.split()\n\n        # Calculate the BM25 score for each keyword across URLs\n        scores_by_keyword = [self.bm25(kw) for kw in keywords]\n\n        # Aggregate the scores for URLs\n        aggregated_scores = defaultdict(float)\n        for scores in scores_by_keyword:\n            for url, score in scores.items():\n                aggregated_scores[url] += score\n\n        # Return the aggregated scores for URLs\n        return aggregated_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        results = {}\n        for kw in keywords:\n            results = update_url_scores(results, self.bm25(kw))\n        return results\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        results = {}\n        for kw in keywords:\n            results = update_url_scores(results, self.bm25(kw))\n        return results\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to be within the range (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify indices of boxes that are nearly horizontal\n        nearly_horizontal_indices = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert representation from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        nearly_horizontal_boxes = self.tensor[nearly_horizontal_indices]\n        nearly_horizontal_boxes[:, 0] -= nearly_horizontal_boxes[:, 2] / 2\n        nearly_horizontal_boxes[:, 1] -= nearly_horizontal_boxes[:, 3] / 2\n        nearly_horizontal_boxes[:, 2] += nearly_horizontal_boxes[:, 0]\n        nearly_horizontal_boxes[:, 3] += nearly_horizontal_boxes[:, 1]\n\n        # Clamp x and y coordinates to ensure they do not exceed the specified box_size limits\n        nearly_horizontal_boxes[:, 0] = torch.clamp(nearly_horizontal_boxes[:, 0], min=0, max=box_size[1] - 1)\n        nearly_horizontal_boxes[:, 1] = torch.clamp(nearly_horizontal_boxes[:, 1], min=0, max=box_size[0] - 1)\n        nearly_horizontal_boxes[:, 2] = torch.clamp(nearly_horizontal_boxes[:, 2], min=0, max=box_size[1] - 1)\n        nearly_horizontal_boxes[:, 3] = torch.clamp(nearly_horizontal_boxes[:, 3], min=0, max=box_size[0] - 1)\n\n        # Convert back to (center x, center y, width, height, angle) representation\n        nearly_horizontal_boxes[:, 0] += (nearly_horizontal_boxes[:, 2] - nearly_horizontal_boxes[:, 0]) / 2\n        nearly_horizontal_boxes[:, 1] += (nearly_horizontal_boxes[:, 3] - nearly_horizontal_boxes[:, 1]) / 2\n        nearly_horizontal_boxes[:, 2] -= nearly_horizontal_boxes[:, 0]\n        nearly_horizontal_boxes[:, 3"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to [-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify indices of boxes that are nearly horizontal\n        nearly_horizontal_indices = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert representation to (x1, y1, x2, y2)\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2\n\n        # Clip x and y coordinates\n        x1[nearly_horizontal_indices] = torch.clamp(x1[nearly_horizontal_indices], min=0, max=box_size[1] - 1)\n        y1[nearly_horizontal_indices] = torch.clamp(y1[nearly_horizontal_indices], min=0, max=box_size[0] - 1)\n        x2[nearly_horizontal_indices] = torch.clamp(x2[nearly_horizontal_indices], min=0, max=box_size[1] - 1)\n        y2[nearly_horizontal_indices] = torch.clamp(y2[nearly_horizontal_indices], min=0, max=box_size[0] - 1)\n\n        # Convert back to original representation\n        self.tensor[:, 0] = (x1 + x2) / 2\n        self.tensor[:, 1] = (y1 + y2) / 2\n        self.tensor[:, 2] = x2 - x1\n        self.tensor[:, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to the range of [-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify the indices of the boxes that are nearly horizontal\n        horizontal_boxes_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert the representation of the boxes from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        horizontal_boxes = self.tensor[horizontal_boxes_indices]\n        horizontal_boxes[:, 0] -= horizontal_boxes[:, 2] / 2\n        horizontal_boxes[:, 1] -= horizontal_boxes[:, 3] / 2\n        horizontal_boxes[:, 2] += horizontal_boxes[:, 0]\n        horizontal_boxes[:, 3] += horizontal_boxes[:, 1]\n\n        # Clip the x and y coordinates to ensure they do not exceed the specified box_size limits\n        horizontal_boxes[:, 0] = torch.clamp(horizontal_boxes[:, 0], min=0, max=box_size[1] - 1)\n        horizontal_boxes[:, 1] = torch.clamp(horizontal_boxes[:, 1], min=0, max=box_size[0] - 1)\n        horizontal_boxes[:, 2] = torch.clamp(horizontal_boxes[:, 2], min=0, max=box_size[1] - 1)\n        horizontal_boxes[:, 3] = torch.clamp(horizontal_boxes[:, 3], min=0, max=box_size[0] - 1)\n\n        # Convert the boxes back to their original representation\n        horizontal_boxes[:, 2] -= horizontal_boxes[:, 0]\n        horizontal_boxes[:, 3] -= horizontal_boxes[:, 1]\n        horizontal_boxes[:, 0] += horizontal_boxes[:, 2] / 2\n        horizontal_boxes[:, 1] += horizontal_boxes[:, 3] / 2\n\n        # Update the tensor attribute of the RotatedBoxes instance with the clipped boxes\n        self.tensor[horizontal_boxes_indices] = horizontal_boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        box_height, box_width = box_size\n\n        # Identify boxes that are nearly horizontal\n        nearly_horizontal_mask = torch.abs(box[:, 4]) <= clip_angle_threshold\n\n        # Convert boxes to (x1, y1, x2, y2) format\n        x1 = box[:, 0] - box[:, 2] / 2\n        y1 = box[:, 1] - box[:, 3] / 2\n        x2 = box[:, 0] + box[:, 2] / 2\n        y2 = box[:, 1] + box[:, 3] / 2\n\n        # Clip x and y coordinates\n        x1[nearly_horizontal_mask] = torch.clamp(x1[nearly_horizontal_mask], 0, box_width)\n        y1[nearly_horizontal_mask] = torch.clamp(y1[nearly_horizontal_mask], 0, box_height)\n        x2[nearly_horizontal_mask] = torch.clamp(x2[nearly_horizontal_mask], 0, box_width)\n        y2[nearly_horizontal_mask] = torch.clamp(y2[nearly_horizontal_mask], 0, box_height)\n\n        # Convert boxes back to (center x, center y, width, height, angle) format\n        box[:, 0] = (x1 + x2) / 2\n        box[:, 1] = (y1 + y2) / 2\n        box[:, 2] = x2 - x1\n        box[:, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles to be within the range (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify indices of nearly horizontal boxes\n        nearly_horizontal_indices = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n\n        # Convert representation from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        nearly_horizontal_boxes = self.tensor[nearly_horizontal_indices]\n        nearly_horizontal_boxes[:, 2] += nearly_horizontal_boxes[:, 0]\n        nearly_horizontal_boxes[:, 3] += nearly_horizontal_boxes[:, 1]\n\n        # Clamp x and y coordinates to ensure they do not exceed the specified box_size limits\n        nearly_horizontal_boxes[:, 0] = torch.clamp(nearly_horizontal_boxes[:, 0], min=0, max=box_size[1])\n        nearly_horizontal_boxes[:, 1] = torch.clamp(nearly_horizontal_boxes[:, 1], min=0, max=box_size[0])\n        nearly_horizontal_boxes[:, 2] = torch.clamp(nearly_horizontal_boxes[:, 2], min=0, max=box_size[1])\n        nearly_horizontal_boxes[:, 3] = torch.clamp(nearly_horizontal_boxes[:, 3], min=0, max=box_size[0])\n\n        # Convert representation back to (center x, center y, width, height, angle)\n        nearly_horizontal_boxes[:, 2] -= nearly_horizontal_boxes[:, 0]\n        nearly_horizontal_boxes[:, 3] -= nearly_horizontal_boxes[:, 1]\n\n        # Update the tensor attribute of the RotatedBoxes instance with the clipped boxes\n        self.tensor[nearly_horizontal_indices] = nearly_horizontal_boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Get the indices of boxes that are nearly horizontal\n        horizontal_boxes_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert to (x1, y1, x2, y2) representation\n        horizontal_boxes = self.tensor[horizontal_boxes_indices]\n        x1 = horizontal_boxes[:, 0] - horizontal_boxes[:, 2] / 2.0\n        y1 = horizontal_boxes[:, 1] - horizontal_boxes[:, 3] / 2.0\n        x2 = horizontal_boxes[:, 0] + horizontal_boxes[:, 2] / 2.0\n        y2 = horizontal_boxes[:, 1] + horizontal_boxes[:, 3] / 2.0\n\n        # Clip the coordinates\n        x1 = torch.clamp(x1, min=0, max=box_size[1] - 1)\n        y1 = torch.clamp(y1, min=0, max=box_size[0] - 1)\n        x2 = torch.clamp(x2, min=0, max=box_size[1] - 1)\n        y2 = torch.clamp(y2, min=0, max=box_size[0] - 1)\n\n        # Convert back to (x_center, y_center, width, height, angle) representation\n        horizontal_boxes[:, 0] = (x1 + x2) / 2.0\n        horizontal_boxes[:, 1] = (y1 + y2) / 2.0\n        horizontal_boxes[:, 2] = x2 - x1\n        horizontal_boxes[:, 3] = y2 - y1\n\n        # Update the tensor\n        self.tensor[horizontal_boxes_indices] = horizontal_boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # clip the boxes that are nearly horizontal\n        # convert to x1, y1, x2, y2\n        box = self.tensor\n        # clip the boxes that are nearly horizontal\n        # convert to x1, y1, x2, y2\n        box_x1 = box[:, 0] - box[:, 2] / 2\n        box_y1 = box[:, 1] - box[:, 3] / 2\n        box_x2 = box[:, 0] + box[:, 2] / 2\n        box_y2 = box[:, 1] + box[:, 3] / 2\n        # clip the boxes that are nearly horizontal\n        nearly_horizontal_mask = torch.abs(box[:, 4]) <= clip_angle_threshold\n        box_x1[nearly_horizontal_mask] = box_x1[nearly_horizontal_mask].clamp(min=0, max=box_size[1])\n        box_x2[nearly_horizontal_mask] = box_x2[nearly_horizontal_mask].clamp(min=0, max=box_size[1])\n        box_y1[nearly_horizontal_mask] = box_y1[nearly_horizontal_mask].clamp(min=0, max=box_size[0])\n        box_y2[nearly_horizontal_mask] = box_y2[nearly_horizontal_mask].clamp(min=0, max=box_size[0])\n        # convert back to center x, center y, width, height\n        box[:, 0] = (box_x1 + box_x2) / 2\n        box[:, 1] = (box_y1 + box_y2) / 2\n        box[:, 2] = box_x2 - box_x1\n        box[:, 3] = box_y2 - box_y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        indices = (self.tensor[:, 4].abs() < clip_angle_threshold).nonzero().flatten()\n        if indices.numel() > 0:\n            clipped_boxes = self.tensor[indices]\n            clipped_boxes[:, :4] = self.xyxy_to_xywh(clipped_boxes[:, :4])\n            clipped_boxes[:, :2] = torch.clamp(clipped_boxes[:, :2], min=0, max=box_size[1])\n            clipped_boxes[:, 2] = torch.clamp(clipped_boxes[:, 2], min=0, max=box_size[1] - clipped_boxes[:, 0])\n            clipped_boxes[:, 3] = torch.clamp(clipped_boxes[:, 3], min=0, max=box_size[0] - clipped_boxes[:, 1])\n            clipped_boxes[:, :4] = self.xywh_to_xyxy(clipped_boxes[:, :4])\n            self.tensor[indices] = clipped_boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        angle_threshold = clip_angle_threshold * math.pi / 180.0\n        nearly_horizontal_mask = torch.abs(box[:, 4] * math.pi / 180.0) < angle_threshold\n        if torch.any(nearly_horizontal_mask):\n            nearly_horizontal_boxes = box[nearly_horizontal_mask]\n            nearly_horizontal_boxes[:, 0] = torch.clamp(\n                nearly_horizontal_boxes[:, 0], min=0, max=box_size[1]\n            )\n            nearly_horizontal_boxes[:, 1] = torch.clamp(\n                nearly_horizontal_boxes[:, 1], min=0, max=box_size[0]\n            )\n            box[nearly_horizontal_mask] = nearly_horizontal_boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        indices = torch.abs(box[:, 4]) <= clip_angle_threshold\n        if not torch.any(indices):\n            return\n\n        box = box[indices]\n        box[:, 0] = box[:, 0].clamp(min=0, max=box_size[1])\n        box[:, 1] = box[:, 1].clamp(min=0, max=box_size[0])\n        self.tensor[indices] = box\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # clip boxes that are nearly horizontal\n        nearly_horizontal_mask = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        if torch.any(nearly_horizontal_mask):\n            nearly_horizontal_boxes = self.tensor[nearly_horizontal_mask]\n            nearly_horizontal_boxes[:, 0] = torch.clamp(\n                nearly_horizontal_boxes[:, 0], min=0, max=box_size[1]\n            )\n            nearly_horizontal_boxes[:, 1] = torch.clamp(\n                nearly_horizontal_boxes[:, 1], min=0, max=box_size[0]\n            )\n            self.tensor[nearly_horizontal_mask] = nearly_horizontal_boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        indices = torch.abs(box[:, 4]) <= clip_angle_threshold\n        if indices.sum() > 0:\n            box[indices, :2] = box[indices, :2].clamp(min=0, max=box_size[1] - 1)\n            box[indices, 2:4] = box[indices, 2:4].clamp(min=0, max=box_size[0] - 1)\n            box[indices, :4] = self._xywha_to_xyxya(box[indices, :])\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        # convert to (x1, y1, x2, y2)\n        x1 = box[:, 0] - box[:, 2] / 2\n        y1 = box[:, 1] - box[:, 3] / 2\n        x2 = box[:, 0] + box[:, 2] / 2\n        y2 = box[:, 1] + box[:, 3] / 2\n\n        # clip\n        x1 = x1.clamp(min=0, max=box_size[1] - 1)\n        y1 = y1.clamp(min=0, max=box_size[0] - 1)\n        x2 = x2.clamp(min=0, max=box_size[1] - 1)\n        y2 = y2.clamp(min=0, max=box_size[0] - 1)\n\n        # convert back to (center x, center y, width, height, angle)\n        box[:, 0] = (x1 + x2) / 2\n        box[:, 1] = (y1 + y2) / 2\n        box[:, 2] = x2 - x1\n        box[:, 3] = y2 - y1\n\n        # clip angle\n        angle_mask = (box[:, 4] >= -clip_angle_threshold) & (box[:, 4] <= clip_angle_threshold)\n        box[angle_mask, 4] = 0.0\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # clip the boxes that are almost horizontal\n        # to avoid the complexities and ambiguities\n        # involved in clipping highly rotated boxes\n        box = self.tensor\n        indices = (box[:, 4].abs() <= clip_angle_threshold).nonzero().flatten()\n        box[indices, 0] = box[indices, 0].clamp(min=0, max=box_size[1])\n        box[indices, 1] = box[indices, 1].clamp(min=0, max=box_size[0])\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        h, w = box_size\n        boxes = self.tensor\n        # The following code is equivalent to\n        # boxes[:, [0, 2]] = boxes[:, [0, 2]].clamp(min=0, max=w)\n        # boxes[:, [1, 3]] = boxes[:, [1, 3]].clamp(min=0, max=h)\n        # but faster.\n        boxes[:, 0].clamp_(min=0, max=w)\n        boxes[:, 2].clamp_(min=0, max=w)\n        boxes[:, 1].clamp_(min=0, max=h)\n        boxes[:, 3].clamp_(min=0, max=h)\n\n        # Clip the boxes that are almost horizontal.\n        # This is done to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # The function first identifies the indices of the boxes that are nearly horizontal based on the clip_angle_threshold.\n        # For these identified boxes, it converts their representation from (center x, center y, width, height, angle) to (x1, y1, x2, y2), where (x1, y1) and (x2, y2) are the coordinates of the top-left and bottom-right corners, respectively.\n        # The x and y coordinates are then clamped to ensure they do not exceed the specified box_size limits.\n        # Finally, the boxes are converted back to their original representation, ensuring that any numerical errors do not increase their sizes.\n        indices = (boxes[:, 4].abs() < clip_angle_threshold).nonzero(as_tuple=False).squeeze(1)\n        if indices.numel() > 0:\n            boxes_to_clip = boxes[indices]\n            x1 = boxes_to_clip[:, 0] - boxes_to_clip[:, 2] / 2\n            y1 = boxes_to_clip[:, 1] - boxes_to_clip[:, 3] / 2\n            x2 = boxes_to_clip[:, 0] + boxes_to_clip[:, 2] / 2\n            y2 = boxes_to_clip[:, 1] + boxes_to_clip[:, 3] / 2\n            x1 = x1.clamp(min=0"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        x_min, y_min, x_max, y_max = box_size\n        indices = (self.tensor[:, 4].abs() < clip_angle_threshold).nonzero().flatten()\n        if indices.numel() > 0:\n            box = self.tensor[indices]\n            box[:, 0] = torch.clamp(box[:, 0], min=x_min, max=x_max)\n            box[:, 1] = torch.clamp(box[:, 1], min=y_min, max=y_max)\n            self.tensor[indices] = box\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        # clip the boxes that are almost horizontal\n        # (in order to avoid the complexities and ambiguities involved in clipping highly rotated boxes)\n        box_indices = torch.abs(box[:, 4]) <= clip_angle_threshold\n        if not box_indices.any():\n            return\n\n        # convert to (x1, y1, x2, y2)\n        box_indices_view = box_indices.view(-1, 1)\n        box_view = box.view(-1, 5)\n        box_view[box_indices_view, 0] -= box_view[box_indices_view, 2] / 2.0  # x1\n        box_view[box_indices_view, 1] -= box_view[box_indices_view, 3] / 2.0  # y1\n        box_view[box_indices_view, 2] += box_view[box_indices_view, 0]  # x2\n        box_view[box_indices_view, 3] += box_view[box_indices_view, 1]  # y2\n\n        # clip\n        box_view[box_indices_view, 0] = box_view[box_indices_view, 0].clamp(min=0, max=box_size[1])\n        box_view[box_indices_view, 1] = box_view[box_indices_view, 1].clamp(min=0, max=box_size[0])\n        box_view[box_indices_view, 2] = box_view[box_indices_view, 2].clamp(min=0, max=box_size[1])\n        box_view[box_indices_view, 3] = box_view[box_indices_view, 3].clamp(min=0, max=box_size[0])\n\n        # convert back\n        box_view[box_indices_view, 0] = (\n            box_view[box_indices_view, 0] + box_view[box_indices_view, 2]\n        ) / 2.0  # x_center\n        box_view[box_indices"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        angle_threshold = clip_angle_threshold * math.pi / 180.0\n        mask = torch.abs(self.tensor[:, 4]) <= angle_threshold\n        if not torch.any(mask):\n            return\n        boxes = self.tensor[mask]\n        boxes[:, :4] = torch.clamp(boxes[:, :4], min=0, max=box_size[1] if box_size[0] == 1 else box_size[0])\n        self.tensor[mask] = boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # get the indices of the boxes that are nearly horizontal\n        horizontal_mask = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        # convert the boxes to (x1, y1, x2, y2) format\n        boxes = self.tensor.clone()\n        boxes[:, :4] = self.tensor_to_xyxy(boxes[:, :4])\n        # clip the boxes to the specified box_size\n        boxes[:, 0::2] = boxes[:, 0::2].clamp(min=0, max=box_size[1])\n        boxes[:, 1::2] = boxes[:, 1::2].clamp(min=0, max=box_size[0])\n        # convert the boxes back to their original representation\n        boxes[:, :4] = self.xyxy_to_tensor(boxes[:, :4])\n        # update the boxes in place\n        self.tensor[horizontal_mask, :4] = boxes[horizontal_mask, :4]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        # The following code is adapted from\n        # https://github.com/pytorch/vision/blob/main/torchvision/ops/boxes.py#L104\n        #\n        # We use the following trick to clip the boxes:\n        # 1. Convert them to (x1, y1, x2, y2) format\n        # 2. Clip the coordinates\n        # 3. Convert them back to (cx, cy, w, h, a) format\n        #\n        # This is done for performance reasons, as it avoids unnecessary\n        # computation.\n        #\n        # The alternative implementation can be found in the following gist:\n        # https://gist.github.com/jwyang/bc996264532e12e95491e1765b53d112\n        #\n        # However, it turns out that the current implementation is faster.\n        # See https://github.com/facebookresearch/detectron2/pull/3853 for details.\n\n        # convert to (x1, y1, x2, y2) format\n        x1 = box[:, 0] - box[:, 2] / 2\n        y1 = box[:, 1] - box[:, 3] / 2\n        x2 = box[:, 0] + box[:, 2] / 2\n        y2 = box[:, 1] + box[:, 3] / 2\n\n        # clip\n        x1 = x1.clamp(min=0, max=box_size[1] - 1)\n        y1 = y1.clamp(min=0, max=box_size[0] - 1)\n        x2 = x2.clamp(min=0, max=box_size[1] - 1)\n        y2 = y2.clamp(min=0, max=box_size[0] - 1)\n\n        # convert back to (cx, cy, w, h, a) format\n        box[:, 0] = (x1 + x2) / 2\n        box[:, 1] = (y1 + y2) / 2\n        box[:, 2] = x2 - x1\n        box[:, 3] = y2"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {}\n        for item in self.data:\n            if item['type'] not in stats:\n                stats[item['type']] = 0\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            if item['type'] in stats:\n                stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        # Initialize the statistics dictionary\n        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        # Iterate through the data and update the statistics\n        for item in self.data:\n            statistics[item['type']] += 1\n\n        return statistics\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            \"doc\": 0,\n            \"gen\": 0,\n            \"kno\": 0,\n            \"num\": 0\n        }\n        for item in self.data:\n            stats[item[\"type\"]] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = dict()\n        for datum in self.data:\n            if datum['type'] not in statistics:\n                statistics[datum['type']] = 0\n            statistics[datum['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for data in self.data:\n            stats[data['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n\n        for item in self.data:\n            if item['type'] in stats:\n                stats[item['type']] += 1\n\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            \"doc\": 0,\n            \"gen\": 0,\n            \"kno\": 0,\n            \"num\": 0,\n        }\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for obj in self.data:\n            stats[obj['type']] += 1\n        return stats"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError(f'Loss {cfg[\"type\"]} is not implemented.')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError(f'Loss {cfg[\"type\"]} is not implemented')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn(f'The loss type {cfg[\"type\"]} is not supported.')\n        return None\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise KeyError(f'{cfg[\"type\"]} is not implemented')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn(f'Loss {cfg[\"type\"]} is not implemented, '\n                      'please check the config file')\n        return None\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError(f'Loss {cfg[\"type\"]} is not implemented')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        if cfg['type'] in MMDET_LOSSES._module_dict.keys():\n            return MMDET_LOSSES.build(cfg)\n        else:\n            if cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n                return MMSEG_LOSSES.build(cfg)\n            else:\n                raise ValueError(f'Unknown loss type: {cfg[\"type\"]}')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise ValueError(f'Unknown loss {cfg[\"type\"]}')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise KeyError(f'{cfg[\"type\"]} is not registered in '\n                       f'MMCV, MMDet, MMSeg, and MMSeg3D.')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise KeyError(f'Loss {cfg[\"type\"]} is not implemented.')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        warnings.warn(f'Loss {cfg[\"type\"]} is not implemented')\n        return None\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        if cfg['type'] in MMDET_LOSSES._module_dict.keys():\n            return MMDET_LOSSES.build(cfg)\n        else:\n            if cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n                return MMSEG_LOSSES.build(cfg)\n            else:\n                raise KeyError(f'Loss {cfg[\"type\"]} is not implemented')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise ValueError(f'Unknown loss: {cfg[\"type\"]}')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise KeyError(f'Loss {cfg[\"type\"]} is not supported')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise ValueError(f'Unsupported loss type {cfg[\"type\"]}')\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(\n            f'The segmentor type {cfg[\"type\"]} is not supported')"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise ValueError(f'Cannot build segmentor {cfg[\"type\"]}')"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f'{cfg[\"type\"]} is not implemented')"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n        cfg.setdefault('test_cfg', test_cfg)\n    assert not (train_cfg is not None and 'train_cfg' in cfg), \\\n        'train_cfg is deprecated, please specify train cfg in model'\n    assert not (test_cfg is not None and 'test_cfg' in cfg), \\\n        'test_cfg is deprecated, please specify test cfg in model'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n    if train_cfg is not None:\n        cfg.train_cfg = train_cfg\n    if test_cfg is not None:\n        cfg.test_cfg = test_cfg\n    if 'train_cfg' in cfg:\n        assert train_cfg is None, \\\n            'train_cfg is specified both in outer field and model field'\n        cfg.train_cfg = train_cfg\n    if 'test_cfg' in cfg:\n        assert test_cfg is None, \\\n            'test_cfg is specified both in outer field and model field'\n        cfg.test_cfg = test_cfg\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n\n    if 'train_cfg' in cfg:\n        assert train_cfg is None, \\\n            'train_cfg is specified both in arguments and model dict'\n        train_cfg = cfg.train_cfg\n        cfg.pop('train_cfg')\n    if 'test_cfg' in cfg:\n        assert test_cfg is None, \\\n            'test_cfg is specified both in arguments and model dict'\n        test_cfg = cfg.test_cfg\n        cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train configuration in the model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test configuration in the model')\n    assert not (train_cfg is not None and 'train_cfg' in cfg), \\\n        'train_cfg is not permitted to be specified in both outer field and model field'\n    assert not (test_cfg is not None and 'test_cfg' in cfg), \\\n        'test_cfg is not permitted to be specified in both outer field and model field'\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n        cfg.setdefault('test_cfg', test_cfg)\n    if 'train_cfg' in cfg and train_cfg is not None:\n        assert cfg['train_cfg'] is None, \\\n            'train_cfg specified in both outer field and model field ' \\\n            'cfg: {} vs train_cfg: {}'.format(cfg['train_cfg'], train_cfg)\n        cfg.pop('train_cfg')\n    if 'test_cfg' in cfg and test_cfg is not None:\n        assert cfg['test_cfg'] is None, \\\n            'test_cfg specified in both outer field and model field ' \\\n            'cfg: {} vs test_cfg: {}'.format(cfg['test_cfg'], test_cfg)\n        cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn(\n            'train_cfg is deprecated in MMDetection V3.0. '\n            'Please set the training configuration in the model '\n            'field of the config file')\n    if test_cfg is not None:\n        warnings.warn(\n            'test_cfg is deprecated in MMDetection V3.0. '\n            'Please set the testing configuration in the model '\n            'field of the config file')\n    if train_cfg is not None and cfg.get('train_cfg') is not None:\n        raise ValueError(\n            'train_cfg is deprecated in MMDetection V3.0. '\n            'Please set the training configuration in the model '\n            'field of the config file')\n    if test_cfg is not None and cfg.get('test_cfg') is not None:\n        raise ValueError(\n            'test_cfg is deprecated in MMDetection V3.0. '\n            'Please set the testing configuration in the model '\n            'field of the config file')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify train '\n                      'configuration in model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify test '\n                      'configuration in model')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n    if train_cfg is not None:\n        cfg.train_cfg = train_cfg\n    if test_cfg is not None:\n        cfg.test_cfg = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n        cfg.setdefault('test_cfg', test_cfg)\n    assert not (\n        train_cfg is not None and 'train_cfg' in cfg), \\\n        'train_cfg is not allowed to be specified in both outer field and model dictionary'\n    assert not (\n        test_cfg is not None and 'test_cfg' in cfg), \\\n        'test_cfg is not allowed to be specified in both outer field and model dictionary'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train configuration in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test configuration in model', UserWarning)\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg specified in both outer field and model '\n                      'field, only the one in model field will be used',\n                      UserWarning)\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg specified in both outer field and model '\n                      'field, only the one in model field will be used',\n                      UserWarning)\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train configuration in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test configuration in model', UserWarning)\n    if train_cfg is not None:\n        assert not cfg.get('train_cfg', None)\n        cfg['train_cfg'] = train_cfg\n    if test_cfg is not None:\n        assert not cfg.get('test_cfg', None)\n        cfg['test_cfg'] = test_cfg\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn(\n            'train_cfg is deprecated, please specify train cfg in '\n            'model directly')\n    if test_cfg is not None:\n        warnings.warn(\n            'test_cfg is deprecated, please specify test cfg in '\n            'model directly')\n    if train_cfg is not None and 'train_cfg' in cfg:\n        raise ValueError('train_cfg is deprecated, please specify train '\n                         'cfg in model directly')\n    if test_cfg is not None and 'test_cfg' in cfg:\n        raise ValueError('test_cfg is deprecated, please specify test '\n                         'cfg in model directly')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn(\n            'train_cfg is deprecated in detector.py, please set '\n            'train_cfg in the model field.',\n            DeprecationWarning)\n    if test_cfg is not None:\n        warnings.warn(\n            'test_cfg is deprecated in detector.py, please set '\n            'test_cfg in the model field.',\n            DeprecationWarning)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train configuration in model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test configuration in model')\n\n    if train_cfg is not None and 'train_cfg' in cfg:\n        raise ValueError('train_cfg is deprecated, please specify '\n                         'train configuration in model')\n    if test_cfg is not None and 'test_cfg' in cfg:\n        raise ValueError('test_cfg is deprecated, please specify '\n                         'test configuration in model')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn(\n            'train_cfg is deprecated, please specify train cfg in '\n            'model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn(\n            'test_cfg is deprecated, please specify test cfg in '\n            'model', UserWarning)\n\n    if 'train_cfg' in cfg and train_cfg is not None:\n        warnings.warn('train_cfg specified in both outer field and model '\n                      'field, only model field will be used', UserWarning)\n    if 'test_cfg' in cfg and test_cfg is not None:\n        warnings.warn('test_cfg specified in both outer field and model '\n                      'field, only model field will be used', UserWarning)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train configuration in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test configuration in model', UserWarning)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n        cfg.setdefault('test_cfg', test_cfg)\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify train '\n                      'cfg in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify test '\n                      'cfg in model', UserWarning)\n    if train_cfg is not None and 'train_cfg' in cfg:\n        raise ValueError('train_cfg is deprecated, please specify train '\n                         'cfg in model')\n    if test_cfg is not None and 'test_cfg' in cfg:\n        raise ValueError('test_cfg is deprecated, please specify test '\n                         'cfg in model')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train configuration in model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test configuration in model')\n\n    if train_cfg is not None and 'train_cfg' in cfg:\n        assert not train_cfg, \\\n            'train_cfg is not permitted in model'\n    if test_cfg is not None and 'test_cfg' in cfg:\n        assert not test_cfg, \\\n            'test_cfg is not permitted in model'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify '\n                      'train cfg in model', UserWarning)\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify '\n                      'test cfg in model', UserWarning)\n    if train_cfg is not None and 'train_cfg' in cfg:\n        assert not train_cfg, \\\n            'train_cfg is not permitted in model'\n    if test_cfg is not None and 'test_cfg' in cfg:\n        assert not test_cfg, \\\n            'test_cfg is not permitted in model'\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n    if box_type_3d is None:\n        box_type_3d = 'LiDAR'\n    if box_mode_3d is None:\n        box_mode_3d = 'lidar'\n\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d: {box_mode_3d}')\n\n    # print(f'box_type_3d: {box_type_3d}')\n    # print(f'box_mode_3d"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # initialize the evaluation results\n    eval_results = {}\n    for iou_thr in metric:\n        eval_results[f'AP_{iou_thr}'] = 0\n        eval_results[f'AR_{iou_thr}'] = 0\n\n    # convert the ground truth annotations to a dictionary\n    gt_annos_dict = {}\n    for anno in gt_annos:\n        if anno['name'] not in gt_annos_dict:\n            gt_annos_dict[anno['name']] = []\n        gt_annos_dict[anno['name']].append(anno)\n\n    # convert the detection annotations to a dictionary\n    dt_annos_dict = {}\n    for anno in dt_annos:\n        if anno['name'] not in dt_annos_dict:\n            dt_annos_dict[anno['name']] = []\n        dt_annos_dict[anno['name']].append(anno)\n\n    # iterate over each class\n    for label, cat in label2cat.items():\n        # skip if the class is not present in the ground truth annotations\n        if cat not in gt_annos_dict:\n            continue\n\n        # convert the ground truth annotations to a dictionary\n        gt_annos_dict_class = {}\n        for anno in gt_annos_dict[cat]:\n            if anno['name'] not in gt_annos_dict_class:\n                gt_annos_dict_class[anno['name']] = []\n            gt_annos_dict_class[anno['name']].append(anno)\n\n        # convert the detection annotations to a dictionary\n        dt_annos_dict_class = {}\n        for anno in dt_annos_dict[cat]:\n            if anno['name'] not in dt_annos_dict_class:\n                dt_annos_dict_class[anno['name']] = []\n            dt_annos_dict_class[anno['name']].append(anno)\n\n        # evaluate the detection results for the current class\n        recall, precision, ap = eval_map_recall(dt_annos_dict_class,\n                                                gt_annos_dict_class, metric)\n\n        # calculate the average precision and recall for each IoU threshold\n        for iou_idx, iou_thr in enumerate(metric):\n            eval_results[f'AP_{iou"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Calculate the number of classes in the dataset\n    num_classes = len(label2cat)\n\n    # Initialize dictionaries to store the results\n    ap_results = {}\n    ar_results = {}\n\n    # Initialize a dictionary to store the number of ground truth instances for each class\n    num_gt_per_class = {}\n\n    # Initialize a dictionary to store the number of detected instances for each class\n    num_dt_per_class = {}\n\n    # Initialize a dictionary to store the number of correct detections for each class\n    num_correct_per_class = {}\n\n    # Initialize a dictionary to store the number of false positives for each class\n    num_fp_per_class = {}\n\n    # Initialize a dictionary to store the number of false negatives for each class\n    num_fn_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst_per_class = {}\n\n    # Initialize a dictionary to store the number of instances for each class\n    num_inst"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n    # print_log(f'Start evaluating...', logger)\n\n    # gt_annos = [anno for anno in gt_annos if anno['name'] in dt_annos]\n    # dt_annos = [anno for anno in dt_annos if anno['name'] in gt_annos]\n\n    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n\n    # if len(dt_annos) == 0 or len(gt_annos) == 0:\n    #     print_log(f'no gt or dt', logger)\n    #     return {}\n\n    # if len(dt_annos) == 0:\n    #     print_log(f'no dt', logger)\n    #     return {}\n\n    # if len(gt_annos) == 0:\n    #     print_log(f'no gt', logger)\n    #     return {}\n\n    # print_log(f'Start evaluating...', logger)\n\n    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n\n    # print_log(f'Start evaluating...', logger)\n\n    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n\n    # print_log(f'Start evaluating...', logger)\n\n    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n\n    # print_log(f'Start evaluating...', logger)\n\n    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n\n    # print_log(f'Start evaluating...', logger)\n\n    # print_log(f'Evaluating {len(dt_annos)} with {len(gt_annos)} gts', logger)\n\n    # print_log(f'Start evaluating...', logger)\n\n    # print_log(f'Evaluating {len(dt_annos)} with"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Initialize the results dictionary\n    results = {}\n    for iou in metric:\n        results[f'AP_{iou}'] = {}\n        results[f'AR_{iou}'] = {}\n        for label in label2cat:\n            results[f'AP_{iou}'][label2cat[label]] = 0\n            results[f'AR_{iou}'][label2cat[label]] = 0\n\n    # Calculate the mAP and mAR for each IoU threshold\n    for iou in metric:\n        ap, ar = eval_map_recall(dt_annos, gt_annos, [iou])\n        for label in label2cat:\n            results[f'AP_{iou}'][label2cat[label]] = ap[0][label][2]\n            results[f'AR_{iou}'][label2cat[label]] = ar[0][label][2]\n\n    # Calculate the overall mAP and mAR\n    mAP = 0\n    mAR = 0\n    for iou in metric:\n        mAP += results[f'AP_{iou}']['mAP']\n        mAR += results[f'AR_{iou}']['mAR']\n    mAP /= len(metric)\n    mAR /= len(metric)\n    results['mAP'] = mAP\n    results['mAR'] = mAR\n\n    # Print the results in a table\n    table_data = [['mAP', 'mAR']]\n    for iou in metric:\n        table_data.append([iou, results[f'AP_{iou}']['mAP'],\n                           results[f'AR_{iou}']['mAR']])\n    table = AsciiTable(table_data)\n    table.title = 'mAP and mAR'\n    table.justify_columns[0] = 'right'\n    table.justify_columns[1] = 'right'\n    table.justify_columns[2] = 'right'\n    print_log('\\n' + table.table, logger=logger)\n\n    # Print the results in a table\n    table_data = [['mAP', 'mAR']]\n    for iou in metric:\n        table_data.append([iou, results[f'AP_{iou}']['mAP'],\n                           results[f'AR_{iou}']['mAR']])\n    table = AsciiTable(table_data)\n    table.title"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # if logger is None:\n    #     logger = get_root_logger()\n\n    if isinstance(metric, list):\n        metric = np.array(metric)\n\n    # if isinstance(iou_type, list):\n    #     iou_type = np.array(iou_type)\n\n    # if isinstance(classwise, list):\n    #     classwise = np.array(classwise)\n\n    # if isinstance(classwise, np.ndarray):\n    #     classwise = classwise.tolist()\n\n    # if isinstance(iou_type, np.ndarray):\n    #     iou_type = iou_type.tolist()\n\n    # if isinstance(metric, np.ndarray):\n    #     metric = metric.tolist()\n\n    # if isinstance(iou_type, list):\n    #     if len(iou_type) == 1:\n    #         iou_type = iou_type[0]\n    #     else:\n    #         raise ValueError('iou_type should be a list with one element')\n\n    # if isinstance(classwise, list):\n    #     if len(classwise) == 1:\n    #         classwise = classwise[0]\n    #     else:\n    #         raise ValueError('classwise should be a list with one element')\n\n    # if isinstance(metric, list):\n    #     if len(metric) == 1:\n    #         metric = metric[0]\n    #     else:\n    #         raise ValueError('metric should be a list with one element')\n\n    # if isinstance(metric, list):\n    #     metric = np.array(metric)\n\n    # if isinstance(iou_type, list):\n    #     iou_type = np.array(iou_type)\n\n    # if isinstance(classwise, list):\n    #     classwise = np.array(classwise)\n\n    # if isinstance(iou_type, np.ndarray):\n    #     iou_type = iou_type.tolist()\n\n    # if isinstance(classwise, np.ndarray):\n    #     classwise = classwise.tolist()\n\n    # if isinstance(metric, np.ndarray):\n    #     metric = metric.tolist()\n\n    # if isinstance(iou_type, list):\n    #     if len(iou_type) == 1:\n    #         iou_type = iou_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # 1. get the category list\n    cat_list = list(label2cat.values())\n\n    # 2. get the category id list\n    cat_ids = list(label2cat.keys())\n\n    # 3. get the number of categories\n    num_cats = len(cat_list)\n\n    # 4. get the number of metrics\n    num_metrics = len(metric)\n\n    # 5. initialize the evaluation results\n    eval_results = {\n        'label2cat': label2cat,\n        'cat_list': cat_list,\n        'cat_ids': cat_ids,\n        'num_cats': num_cats,\n        'num_metrics': num_metrics,\n        'metric': metric,\n        'ap': np.zeros((num_cats, num_metrics)),\n        'ar': np.zeros((num_cats, num_metrics)),\n        'recall': np.zeros((num_cats, num_metrics)),\n        'precision': np.zeros((num_cats, num_metrics))\n    }\n\n    # 6. compute the evaluation results\n    for i in range(num_cats):\n        cat = cat_list[i]\n        cat_id = cat_ids[i]\n        cat_gt_annos = [anno for anno in gt_annos if anno['category_id'] == cat_id]\n        cat_dt_annos = [anno for anno in dt_annos if anno['category_id'] == cat_id]\n        cat_eval_results = indoor_eval_cat(cat_gt_annos, cat_dt_annos, metric,\n                                           box_type_3d, box_mode_3d)\n        eval_results['ap'][i, :] = cat_eval_results['ap']\n        eval_results['ar'][i, :] = cat_eval_results['ar']\n        eval_results['recall'][i, :] = cat_eval_results['recall']\n        eval_results['precision'][i, :] = cat_eval_results['precision']\n\n    # 7. compute the overall mAP and mAR\n    eval_results['mAP'] = np.mean(eval_results['ap'])\n    eval_results['mAR'] = np.mean(eval_results['ar'])\n\n    # 8. print the evaluation results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is not None:\n        print_log('Evaluating {}'.format(metric), logger)\n\n    # convert to coco format\n    gt_annos = [\n        dict(\n            image_id=anno['image_id'],\n            bboxes=anno['bbox'],\n            labels=anno['label'],\n            bboxes_ignore=anno.get('bbox_ignore', None),\n            labels_ignore=anno.get('label_ignore', None))\n        for anno in gt_annos\n    ]\n    dt_annos = [\n        dict(\n            image_id=anno['image_id'],\n            bboxes=anno['bbox'],\n            labels=anno['label'],\n            scores=anno['score']) for anno in dt_annos\n    ]\n\n    # group gt and dt\n    gt_group_dict = {}\n    dt_group_dict = {}\n    for anno in gt_annos:\n        image_id = anno['image_id']\n        if image_id not in gt_group_dict:\n            gt_group_dict[image_id] = []\n        gt_group_dict[image_id].append(anno)\n\n    for anno in dt_annos:\n        image_id = anno['image_id']\n        if image_id not in dt_group_dict:\n            dt_group_dict[image_id] = []\n        dt_group_dict[image_id].append(anno)\n\n    # eval\n    gt_labels = list(gt_group_dict.keys())\n    dt_labels = list(dt_group_dict.keys())\n    assert set(gt_labels) == set(dt_labels)\n\n    results = {}\n    for iou_thr in metric:\n        results[iou_thr] = {}\n        for label in gt_labels:\n            gt_annos = gt_group_dict[label]\n            dt_annos = dt_group_dict[label]\n            if box_type_3d is not None:\n                gt_annos = [\n                    dict(\n                        image_id=anno['image_id'],\n                        bboxes=anno['bbox'],\n                        labels=anno['label'],\n                        bboxes_ignore=anno.get('bbox_ignore', None),\n                        labels_ignore=anno.get('label_ignore', None))\n                    for anno in gt_annos\n                ]\n                dt_annos"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    from mmdet.core.evaluation.indoor_eval import eval_map_recall\n\n    # convert gt_annos to dict\n    gt = {}\n    for anno in gt_annos:\n        if anno['image_id'] not in gt:\n            gt[anno['image_id']] = []\n        gt[anno['image_id']].append(anno['bbox'])\n\n    # convert dt_annos to dict\n    pred = {}\n    for anno in dt_annos:\n        if anno['image_id'] not in pred:\n            pred[anno['image_id']] = []\n        pred[anno['image_id']].append((anno['bbox'], anno['score']))\n\n    # evaluate\n    recall, precision, ap = eval_map_recall(pred, gt, metric)\n\n    # summarize\n    num_classes = len(label2cat)\n    ap_table = [['class', 'AP']]\n    ar_table = [['class', 'AR']]\n    for i in range(num_classes):\n        class_name = label2cat[i]\n        ap_table.append([class_name, ap[0][i]])\n        ar_table.append([class_name, recall[0][i][-1]])\n    ap_table.append(['mAP', np.mean([ap[0][i] for i in range(num_classes)])])\n    ar_table.append(['mAR', np.mean([recall[0][i][-1] for i in range(num_classes)])])\n    ap_table = AsciiTable(ap_table)\n    ar_table = AsciiTable(ar_table)\n\n    if logger is not None:\n        print_log('\\n' + ap_table.table, logger=logger)\n        print_log('\\n' + ar_table.table, logger=logger)\n\n    eval_results = {\n        'ap': ap[0],\n        'ar': recall[0],\n        'ap_table': ap_table.table,\n        'ar_table': ar_table.table,\n    }\n\n    return eval_results\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    if logger is not None:\n        print_log('Evaluate {}'.format(len(gt_annos)), logger)\n\n    # evaluate\n    eval_results = {}\n    for iou_thr in metric:\n        iou_thr = float(iou_thr)\n        # get gt and dt\n        gt_annos_thr = []\n        dt_annos_thr = []\n        for gt_anno, dt_anno in zip(gt_annos, dt_annos):\n            gt_anno_thr = [\n                gt for gt in gt_anno if gt.get('ignore', False) == 0\n            ]\n            dt_anno_thr = [\n                dt for dt in dt_anno if dt['score'] >= iou_thr\n            ]\n            gt_annos_thr.append(gt_anno_thr)\n            dt_annos_thr.append(dt_anno_thr)\n\n        # convert to coco format\n        gt_annos_thr = [\n            gt.convert_to(box_type_3d, box_mode_3d) for gt in gt_annos_thr\n        ]\n        dt_annos_thr = [\n            dt.convert_to(box_type_3d, box_mode_3d) for dt in dt_annos_thr\n        ]\n\n        # evaluate\n        gt_annos_thr = [gt.to_coco() for gt in gt_annos_thr]\n        dt_annos_thr = [dt.to_coco() for dt in dt_annos_thr]\n        gt_annos_thr = [\n            gt for gt in gt_annos_thr if len(gt['bboxes']) > 0\n        ]\n        dt_annos_thr = [\n            dt for dt in dt_annos_thr if len(dt['bboxes']) > 0\n        ]\n\n        # convert to coco format\n        gt_annos_thr = [\n            gt.convert_to(box_type_3d, box_mode_3d) for gt in gt_annos_thr\n        ]\n        dt_annos_thr = [\n            dt.convert_to(box_type_3d, box_mode_3d) for dt in dt_annos_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Initialize variables for storing evaluation results\n    ap_results_dict = {\n        'name': [],\n        'label': [],\n        'AP': [],\n        'AR': [],\n        'AP50': [],\n        'AR50': [],\n        'AP75': [],\n        'AR75': [],\n    }\n\n    # Initialize variables for calculating mAP and mAR\n    num_classes = len(label2cat)\n    num_iou_thrs = len(metric)\n    aps = np.zeros((num_classes, num_iou_thrs))\n    ars = np.zeros((num_classes, num_iou_thrs))\n\n    # Iterate over each class\n    for label_idx, label in enumerate(label2cat):\n        # Get the ground truth annotations for the current class\n        gt_annos_single_class = [\n            anno for anno in gt_annos if anno['label'] == label\n        ]\n\n        # Get the detection annotations for the current class\n        dt_annos_single_class = [\n            anno for anno in dt_annos if anno['label'] == label\n        ]\n\n        # If there are no annotations for the current class, skip the evaluation\n        if len(gt_annos_single_class) == 0 or len(dt_annos_single_class) == 0:\n            continue\n\n        # Convert the annotations to the desired format\n        gt_annos_single_class = [\n            box_type_3d(box, box_mode=box_mode_3d)\n            for anno in gt_annos_single_class\n            for box in anno['bbox']\n        ]\n        dt_annos_single_class = [\n            {\n                'bbox': box_type_3d(box, box_mode=box_mode_3d),\n                'score': score\n            }\n            for anno in dt_annos_single_class\n            for box, score in zip(anno['bbox'], anno['score'])\n        ]\n\n        # Evaluate the detection results for the current class\n        recall, precision, ap = eval_map_recall(\n            {label: dt_annos_single_class}, {label: gt_annos_single_class},\n            metric)\n\n        # Store the evaluation results for the current class\n        ap_results_dict['name'].append(label2cat[label"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # get the number of classes\n    num_classes = len(label2cat)\n\n    # initialize the results dictionary\n    results = {}\n    results['mAP'] = {}\n    results['mAR'] = {}\n    for iou_thresh in metric:\n        results['mAP'][iou_thresh] = {}\n        results['mAR'][iou_thresh] = {}\n\n    # convert the detection annotations to the format required by the evaluation function\n    pred = {}\n    for anno in dt_annos:\n        if anno['name'] not in pred:\n            pred[anno['name']] = []\n        pred[anno['name']].append(\n            (anno['bbox'], anno['score'], anno['category_id']))\n\n    # convert the ground truth annotations to the format required by the evaluation function\n    gt = {}\n    for anno in gt_annos:\n        if anno['name'] not in gt:\n            gt[anno['name']] = []\n        gt[anno['name']].append(anno['bbox'])\n\n    # evaluate the detection results\n    recall, precision, ap = eval_map_recall(pred, gt, metric)\n\n    # calculate the mean Average Precision (mAP) and mean Average Recall (mAR) for each class and each IoU threshold\n    for iou_idx, iou_thresh in enumerate(metric):\n        results['mAP'][iou_thresh]['overall'] = 0.0\n        results['mAR'][iou_thresh]['overall'] = 0.0\n        for label in recall[iou_idx].keys():\n            results['mAP'][iou_thresh][label2cat[label]] = ap[iou_idx][label]\n            results['mAR'][iou_thresh][label2cat[label]] = recall[iou_idx][\n                label]\n            results['mAP'][iou_thresh]['overall'] += ap[iou_idx][label]\n            results['mAR'][iou_thresh]['overall'] += recall[iou_idx][label]\n        results['mAP'][iou_thresh]['overall'] /= num_classes\n        results['mAR'][iou_thresh]['overall'] /= num_classes\n\n    # print the evaluation results\n    if logger is None:\n        logger = print_log\n    logger.info('Results per class:')\n    table_data = [\n        ['Class', 'IoU', 'mAP', 'mAR']\n       "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print_log\n    if box_type_3d is None:\n        from mmdet3d.core.bbox import LiDARInstance3DBoxes\n        box_type_3d = LiDARInstance3DBoxes\n    if box_mode_3d is None:\n        box_mode_3d = 'lidar'\n\n    # get gt and dt info\n    gt_info = {}\n    dt_info = {}\n    for gt_anno in gt_annos:\n        gt_anno = gt_anno.convert_to(box_mode_3d, box_type_3d)\n        gt_info[gt_anno.metadata['token']] = gt_anno\n    for dt_anno in dt_annos:\n        dt_anno = dt_anno.convert_to(box_mode_3d, box_type_3d)\n        dt_info[dt_anno.metadata['token']] = dt_anno\n\n    # get dt and gt info\n    dt_annos = []\n    gt_annos = []\n    for token, dt_anno in dt_info.items():\n        if token in gt_info:\n            dt_annos.append(dt_anno)\n            gt_annos.append(gt_info[token])\n\n    # get gt and dt info\n    gt_annos = [gt_anno for gt_anno in gt_annos if gt_anno.num_boxes > 0]\n    dt_annos = [dt_anno for dt_anno in dt_annos if dt_anno.num_boxes > 0]\n\n    # eval\n    recall, precision, ap = eval_map_recall(\n        {\n            'car': dt_annos\n        }, {\n            'car': gt_annos\n        }, metric)\n\n    # print summary\n    summary = {}\n    summary['mAP'] = np.mean([ap[iou_idx]['car'] for iou_idx in range(len(ap))])\n    summary['mAR'] = np.mean([recall[iou_idx]['car'] for iou_idx in range(len(recall))])\n    summary['mAP_0.5'] = ap[0]['car']\n    summary['mAP_0.7'] = ap[1]['car']\n    summary['mAP_0"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Convert the 3D bounding boxes to the desired format\n    gt_annos = [\n        box_type_3d(box, box_mode=box_mode_3d) for box in gt_annos\n    ]\n    dt_annos = [\n        box_type_3d(box, box_mode=box_mode_3d) for box in dt_annos\n    ]\n\n    # Initialize the dictionaries to store the results\n    eval_results = {}\n    eval_results['class_names'] = list(label2cat.values())\n    eval_results['mAP'] = {}\n    eval_results['mAR'] = {}\n    for metric_name in metric:\n        eval_results[f'AP_{metric_name}'] = {}\n        eval_results[f'AR_{metric_name}'] = {}\n\n    # Initialize the lists to store the results\n    ap_list = []\n    ar_list = []\n    for metric_name in metric:\n        ap_list.append([])\n        ar_list.append([])\n\n    # Iterate over each class\n    for label, cat in label2cat.items():\n        # Filter the annotations for the current class\n        gt_annos_class = [anno for anno in gt_annos if anno.label == label]\n        dt_annos_class = [anno for anno in dt_annos if anno.label == label]\n\n        # Calculate the evaluation metrics for the current class\n        recall, precision, ap = eval_map_recall(\n            {label: dt_annos_class}, {label: gt_annos_class}, metric)\n\n        # Store the evaluation results for the current class\n        for iou_idx, metric_name in enumerate(metric):\n            eval_results[f'AP_{metric_name}'][cat] = ap[iou_idx][label]\n            eval_results[f'AR_{metric_name}'][cat] = recall[iou_idx][label][-1]\n            ap_list[iou_idx].append(ap[iou_idx][label])\n            ar_list[iou_idx].append(recall[iou_idx][label][-1])\n\n        # Calculate the mAP and mAR for the current class\n        eval_results['mAP'][cat] = np.mean(ap_list[iou_idx])\n        eval_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # 1. compute the average precision and recall for each class\n    # 2. compute the mean average precision and recall\n    # 3. print the results\n\n    # 1. compute the average precision and recall for each class\n    aps, ars, recalls, precisions = {}, {}, {}, {}\n    for iou_thr in metric:\n        aps[iou_thr], ars[iou_thr], recalls[iou_thr], precisions[iou_thr] = \\\n            eval_map_recall(dt_annos, gt_annos, ovthresh=[iou_thr])\n\n    # 2. compute the mean average precision and recall\n    mAP, mAR = {}, {}\n    for iou_thr in metric:\n        mAP[iou_thr] = np.mean(\n            [v[iou_thr]['mAP'] for k, v in aps.items() if 'mAP' in v[iou_thr]])\n        mAR[iou_thr] = np.mean(\n            [v[iou_thr]['mAR'] for k, v in ars.items() if 'mAR' in v[iou_thr]])\n\n    # 3. print the results\n    if logger is None:\n        logger = print_log\n    if isinstance(logger, str):\n        logger = get_root_logger(logger)\n\n    logger.info('Results of AP and AR')\n    table_headers = ['class', 'AP', 'AR']\n    table_data = []\n    for label in gt_annos:\n        row = [label2cat[label]]\n        for iou_thr in metric:\n            row.append(f'{aps[iou_thr][label][iou_thr][\"mAP\"]:.4f}')\n            row.append(f'{ars[iou_thr][label][iou_thr][\"mAR\"]:.4f}')\n        table_data.append(row)\n    table_data.append(['mAP'] + [f'{mAP[iou_thr]:.4f}' for iou_thr in metric])\n    table_data.append(['mAR'] + [f'{mAR[iou_thr]:.4f}' for iou_thr in metric])\n    logger.info(AsciiTable(table_data, table_headers).table)\n\n    return {\n        'm"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Convert the input arguments to the required format\n    gt_annos = [\n        gt_annos[i].to(dt_annos[i].tensor.device) for i in range(len(gt_annos))\n    ]\n    dt_annos = [\n        dt_annos[i].to(gt_annos[i].tensor.device) for i in range(len(dt_annos))\n    ]\n    if box_type_3d is not None:\n        gt_annos = [\n            box_type_3d(anno, box_mode=box_mode_3d) for anno in gt_annos\n        ]\n        dt_annos = [\n            box_type_3d(anno, box_mode=box_mode_3d) for anno in dt_annos\n        ]\n\n    # Calculate the number of classes and the number of samples\n    num_classes = len(label2cat)\n    num_samples = len(gt_annos)\n\n    # Initialize the evaluation results\n    ap_results_dict = {\n        f'AP/{label2cat[i]}': []\n        for i in range(num_classes)\n    }\n    ap_results_dict.update({\n        'mAP': []\n    })\n    ar_results_dict = {\n        f'AR/{label2cat[i]}': []\n        for i in range(num_classes)\n    }\n    ar_results_dict.update({\n        'mAR': []\n    })\n\n    # Iterate over each IoU threshold\n    for iou_thr in metric:\n        # Initialize the evaluation results for the current IoU threshold\n        ap_per_class = [[] for _ in range(num_classes)]\n        ar_per_class = [[] for _ in range(num_classes)]\n\n        # Iterate over each sample\n        for sample_id in range(num_samples):\n            # Get the ground truth annotations and the detection annotations for the current sample\n            gt_anno = gt_annos[sample_id]\n            dt_anno = dt_annos[sample_id]\n\n            # Calculate the number of ground truth boxes and detection boxes\n            num_gt = len(gt_anno)\n            num_dt = len(dt_anno)\n\n            # Initialize the matching matrix and the number of matched ground truth boxes\n            matching_matrix ="}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # 1. get gt and dt info\n    gt_info = get_gt_dt_info(gt_annos, dt_annos, label2cat, box_type_3d,\n                             box_mode_3d)\n    gt_bboxes = gt_info['gt_bboxes']\n    gt_labels = gt_info['gt_labels']\n    dt_bboxes = gt_info['dt_bboxes']\n    dt_labels = gt_info['dt_labels']\n    dt_scores = gt_info['dt_scores']\n\n    # 2. calculate mAP and mAR\n    num_classes = len(gt_info['cat2label'])\n    num_iou_thrs = len(metric)\n    cat_ids = list(gt_info['cat2label'].keys())\n    # 2.1 calculate mAP and mAR for each class\n    ap_results_dict = {\n        'AP': np.zeros((0, num_iou_thrs)),\n        'AR': np.zeros((0, num_iou_thrs))\n    }\n    for cat_id in cat_ids:\n        ap_results_dict['AP'] = np.append(\n            ap_results_dict['AP'],\n            np.zeros((1, num_iou_thrs)),\n            axis=0)\n        ap_results_dict['AR'] = np.append(\n            ap_results_dict['AR'],\n            np.zeros((1, num_iou_thrs)),\n            axis=0)\n\n    for cat_id in cat_ids:\n        print_log(\n            f'\\n>>> Evaluate {label2cat[cat_id]}', logger=logger)\n        cat_gt_bboxes = gt_bboxes[gt_labels == cat_id]\n        cat_gt_labels = gt_labels[gt_labels == cat_id]\n        cat_dt_bboxes = dt_bboxes[dt_labels == cat_id]\n        cat_dt_labels = dt_labels[dt_labels == cat_id]\n        cat_dt_scores = dt_scores[dt_labels == cat_id]\n        # 2.2 calculate mAP and mAR for each class and each IoU threshold\n        for iou_idx, iou_thr in enumerate(metric):\n           "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # assert len(gt_annos) == len(dt_annos)\n    gt_annos = gt_annos.copy()\n    dt_annos = dt_annos.copy()\n    if len(gt_annos) == 0:\n        print_log(\n            'The number of ground truth annotations is 0, the evaluation results are not available.',\n            logger=logger)\n        return\n    if len(dt_annos) == 0:\n        print_log(\n            'The number of detection annotations is 0, the evaluation results are not available.',\n            logger=logger)\n        return\n\n    # convert to tensor\n    gt_annos = [\n        box_type_3d(\n            gt_anno.tensor.float(), box_mode=box_mode_3d, with_yaw=True)\n        for gt_anno in gt_annos\n    ]\n    dt_annos = [\n        box_type_3d(\n            dt_anno.tensor.float(), box_mode=box_mode_3d, with_yaw=True)\n        for dt_anno in dt_annos\n    ]\n\n    # get all labels\n    labels = []\n    for anno in gt_annos:\n        labels.append(anno.tensor[6])\n    labels = np.unique(labels)\n\n    # get all categories\n    categories = []\n    for label in labels:\n        categories.append(label2cat[label])\n    categories = np.unique(categories)\n\n    # get all APs\n    ap_dict = {}\n    for category in categories:\n        ap_dict[category] = []\n\n    # get all ARs\n    ar_dict = {}\n    for category in categories:\n        ar_dict[category] = []\n\n    # get all mAPs\n    mAP = []\n\n    # get all mARs\n    mAR = []\n\n    # calculate AP and AR for each category\n    for category in categories:\n        gt_annos_cat = []\n        dt_annos_cat = []\n        for anno in gt_annos:\n            if anno.tensor[6] == label2cat.index(category):\n                gt_annos_cat.append(anno)\n        for anno in dt_annos:\n            if anno.tensor[6] == label2cat.index(category):\n                dt_annos_cat.append("}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos), 'The number of gt and dt annos should be equal'\n\n    # sort the detections by decreasing confidence\n    dt_annos = sorted(dt_annos, key=lambda x: x['score'], reverse=True)\n\n    # create a dictionary to store the results for each class\n    results = {}\n    for label in label2cat.keys():\n        results[label] = {}\n        results[label]['ap'] = {}\n        results[label]['ar'] = {}\n        for m in metric:\n            results[label]['ap'][m] = 0.0\n            results[label]['ar'][m] = 0.0\n\n    # create a dictionary to store the true positives and false positives for each class\n    tp = {}\n    fp = {}\n    for label in label2cat.keys():\n        tp[label] = {}\n        fp[label] = {}\n        for m in metric:\n            tp[label][m] = 0\n            fp[label][m] = 0\n\n    # loop over each detection annotation\n    for i, dt_anno in enumerate(dt_annos):\n        # get the detection box, label, and score\n        dt_box = dt_anno['bbox']\n        dt_label = dt_anno['label']\n        dt_score = dt_anno['score']\n\n        # convert the detection box to the desired format\n        dt_box = box_type_3d(dt_box, box_mode_3d, box_mode_3d)\n\n        # loop over each ground truth annotation\n        for j, gt_anno in enumerate(gt_annos):\n            # get the ground truth box and label\n            gt_box = gt_anno['bbox']\n            gt_label = gt_anno['label']\n\n            # convert the ground truth box to the desired format\n            gt_box = box_type_3d(gt_box, box_mode_3d, box_mode_3d)\n\n            # calculate the IoU between the detection and ground truth boxes\n            iou = dt_box.iou(gt_box)\n\n            # if the IoU is greater than the current threshold and the ground truth box has not been matched, then it is a true positive\n            if iou > 0.0 and gt_anno['matched'] is"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print_log\n\n    # convert to coco format\n    gt_annos_coco = []\n    dt_annos_coco = []\n    for i in range(len(gt_annos)):\n        gt_annos_coco.append(\n            {'image_id': i, 'annotations': gt_annos[i], 'category_id': 0})\n        dt_annos_coco.append(\n            {'image_id': i, 'annotations': dt_annos[i], 'category_id': 0})\n\n    # evaluate\n    from mmdet.core.evaluation.coco_utils import COCO\n    gt_coco = COCO(gt_annos_coco)\n    dt_coco = COCO(dt_annos_coco)\n\n    # coco.evaluate()\n    coco_eval = COCOeval(gt_coco, dt_coco, iouType='bbox')\n    coco_eval.params.imgIds = list(range(len(gt_annos)))\n    coco_eval.params.iouThrs = np.array(metric)\n    coco_eval.params.catIds = [0]\n    coco_eval.params.maxDets = [100]\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n    # coco.results\n    ap = coco_eval.stats[0:11]\n    ar = coco_eval.stats[11:22]\n    ap_class = coco_eval.stats[22:33]\n    ar_class = coco_eval.stats[33:44]\n\n    # summarize\n    ap = np.round(ap, 3)\n    ar = np.round(ar, 3)\n    ap_class = np.round(ap_class, 3)\n    ar_class = np.round(ar_class, 3)\n\n    # print\n    logger.info('Indoor AP summary:')\n    logger.info('AP: {}'.format(ap))\n    logger.info('AR: {}'.format(ar))\n    logger.info('Indoor AP per class:')\n    logger.info('AP: {}'.format(ap_class))\n    logger.info('AR: {}'.format(ar_class))\n\n    # return\n    eval_results ="}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures.lidar_bbox import LiDARInstance3DBoxes\n        box_cls = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures.depth_bbox import DepthInstance3DBoxes\n        box_cls = DepthInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures.depth_bbox import DepthInstance3DBoxes\n        box_cls = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type: {box_type}')\n    return box_cls, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures import CameraInstance3DBoxes\n        box_class = CameraInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type {box_type}')\n\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox import CameraInstance3DBoxes\n        box_class = CameraInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type: {box_type}')\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type = 'LiDAR'\n        mode = '3d'\n    elif box_type == 'Camera':\n        box_type = 'Camera'\n        mode = '2d'\n    elif box_type == 'Depth':\n        box_type = 'Depth'\n        mode = '2d'\n    else:\n        raise ValueError(f'box_type {box_type} is not supported')\n    return box_type, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = torch.Tensor\n        box_mode = 'lidar'\n    elif box_type == 'Camera':\n        box_class = torch.Tensor\n        box_mode = 'camera'\n    elif box_type == 'Depth':\n        box_class = torch.Tensor\n        box_mode = 'depth'\n    else:\n        raise ValueError(f'Box type {box_type} is not supported.')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures import CameraInstance3DBoxes\n        box_class = CameraInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type {box_type}')\n\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = 'LiDAR'\n        box_mode = '3d'\n    elif box_type == 'Camera':\n        box_class = 'Camera'\n        box_mode = '2d'\n    elif box_type == 'Depth':\n        box_class = 'Depth'\n        box_mode = '2d'\n    else:\n        raise ValueError(f'Unsupported box type: {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        box_mode = 'lidar'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        box_mode = 'depth'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures import CameraInstance3DBoxes\n        box_class = CameraInstance3DBoxes\n        box_mode = 'camera'\n    else:\n        raise ValueError(f'box_type {box_type} is not supported')\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = 'LiDAR'\n        box_mode = 'lidar'\n    elif box_type == 'Camera':\n        box_class = 'Camera'\n        box_mode = '3d'\n    elif box_type == 'Depth':\n        box_class = 'Depth'\n        box_mode = '3d'\n    else:\n        raise ValueError(f'box_type {box_type} is not supported')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox import LiDARInstance3DBoxes\n        box_cls = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox import DepthInstance3DBoxes\n        box_cls = DepthInstance3DBoxes\n        mode = 'depth'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox import CameraInstance3DBoxes\n        box_cls = CameraInstance3DBoxes\n        mode = 'camera'\n    else:\n        raise ValueError(f'Unsupported box type {box_type}')\n\n    return box_cls, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = 'LiDAR'\n        mode = '3d'\n    elif box_type == 'Camera':\n        box_class = 'Camera'\n        mode = '3d'\n    elif box_type == 'Depth':\n        box_class = 'Depth'\n        mode = '3d'\n    else:\n        raise ValueError(\n            f'box_type should be one of [\"LiDAR\", \"Camera\", \"Depth\"], '\n            f'got {box_type}')\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox import LiDARInstance3DBoxes\n        box_cls = LiDARInstance3DBoxes\n        box_mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox import CameraInstance3DBoxes\n        box_cls = CameraInstance3DBoxes\n        box_mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox import DepthInstance3DBoxes\n        box_cls = DepthInstance3DBoxes\n        box_mode = 'depth'\n    else:\n        raise ValueError(\n            f'Unsupported box type: {box_type}. '\n            'Supported box types are: \"LiDAR\", \"Camera\", \"Depth\"')\n\n    return box_cls, box_mode\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type = 'LiDAR'\n        mode = '3d'\n    elif box_type == 'Camera':\n        box_type = 'Camera'\n        mode = '3d'\n    elif box_type == 'Depth':\n        box_type = 'Depth'\n        mode = '3d'\n    else:\n        raise ValueError(\n            f'Box type {box_type} not recognized. '\n            'Valid types are \"LiDAR\", \"Camera\", and \"Depth\".')\n    return box_type, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures.lidar_box3d import LiDARInstance3DBoxes\n        box_cls = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_cls = DepthInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_cls = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type {box_type}')\n    return box_cls, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures.lidar_box3d import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type: {box_type}')\n\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type = 'LiDAR'\n        box_mode = '3d'\n    elif box_type == 'Camera':\n        box_type = 'Camera'\n        box_mode = '3d'\n    elif box_type == 'Depth':\n        box_type = 'Depth'\n        box_mode = '3d'\n    else:\n        raise ValueError(f'Unsupported box type {box_type}')\n    return box_type, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures.lidar_bbox import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures.camera_bbox import CameraInstance3DBoxes\n        box_class = CameraInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures.depth_bbox import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Invalid box type: {box_type}')\n\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures.lidar_box3d import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'camera'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        mode = 'depth'\n    else:\n        raise ValueError(f'Unsupported box type: {box_type}')\n\n    return box_class, mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        from mmdet3d.core.bbox.structures.lidar_box3d import LiDARInstance3DBoxes\n        box_class = LiDARInstance3DBoxes\n        box_mode = 'lidar'\n    elif box_type == 'Camera':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        box_mode = 'depth'\n    elif box_type == 'Depth':\n        from mmdet3d.core.bbox.structures.depth_box3d import DepthInstance3DBoxes\n        box_class = DepthInstance3DBoxes\n        box_mode = 'depth'\n    else:\n        raise ValueError(\n            f'Unsupported box type {box_type}, supported types are '\n            f'\"LiDAR\", \"Camera\", \"Depth\"')\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = torch.Tensor\n        mode = 'lidar'\n    elif box_type == 'Depth':\n        box_class = torch.Tensor\n        mode = 'depth'\n    elif box_type == 'Camera':\n        box_class = torch.Tensor\n        mode = 'camera'\n    else:\n        raise ValueError(f'Box type {box_type} not recognized')\n\n    return box_class, mode\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, (dict, Message)):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_format_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      for message in messages:\n        if not isinstance(message, Message):\n          message = Message(**message)\n\n        if message.role not in ('system', 'user', 'assistant'):\n          raise RequestError('invalid message role')\n\n        if not message.content:\n          raise RequestError('message content cannot be empty')\n\n        if message.images:\n          message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, Sequence):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      for message in messages:\n        if not isinstance(message, Message):\n          message = Message(**message)\n\n        if not message.role or not message.content:\n          raise RequestError('must provide role and content for each message')\n\n        if message.images:\n          message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, Sequence):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if not all(isinstance(m, (Message, Mapping)) for m in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(m) for m in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      for message in messages:\n        if not isinstance(message, dict):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if 'role' not in message:\n          raise RequestError('message must contain a role')\n\n        if 'content' not in message:\n          raise RequestError('message must contain a content')\n\n        if message['role'] == 'user' and 'images' in message:\n          message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      if not all(isinstance(message, Message) or isinstance(message, dict) for message in messages):\n        raise RequestError('messages must be a list of Message or dict-like objects')\n\n      messages = [_normalize_message(message) for message in messages]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if not isinstance(message, Message):\n          message = Message(**message)\n\n        if not message.role or not message.content:\n          raise RequestError('messages must have a role and content')\n\n        if message.images:\n          message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, (dict, Message)):\n        raise TypeError(f'messages must be a list of Message or dict-like objects, not {type(message)}')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.role,\n            'content': message.content,\n            'images': [_encode_image(image) for image in message.images or []],\n          } for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, Message):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if 'role' not in message or 'content' not in message:\n          raise RequestError('messages must have a role and content')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None and not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if messages is not None and not all(isinstance(message, (Message, Mapping)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_format_message(message) for message in messages or []],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      if not all(isinstance(message, (Message, dict)) for message in messages):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      messages = [\n        {\n          'role': message.get('role'),\n          'content': message.get('content'),\n          'images': [_encode_image(image) for image in message.get('images', [])],\n        }\n        for message in messages\n      ]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if not isinstance(message, Message):\n          message = Message(**message)\n\n        if not message.role or not message.content:\n          raise RequestError('message must have a role and content')\n\n        if message.images:\n          message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    if not all(isinstance(message, Message) or isinstance(message, dict) for message in messages):\n      raise RequestError('messages must be a list of Message or dict-like objects')\n\n    messages = [_normalize_message(message) for message in messages]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, Sequence):\n        raise TypeError('messages must be a sequence')\n      if not all(isinstance(message, (Message, Mapping)) for message in messages):\n        raise TypeError('messages must be a sequence of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      for message in messages:\n        if not isinstance(message, Message):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages or []],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_format_message(message) for message in messages or []],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, dict):\n        message = message.to_dict()\n\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      if 'images' in message:\n        message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      for message in messages:\n        if not isinstance(message, Message):\n          raise TypeError('message must be a dict-like object')\n\n        if not isinstance(message.content, str):\n          raise TypeError('message content must be a string')\n\n        if message.role not in ('system', 'user', 'assistant'):\n          raise TypeError('message role must be one of \"system\", \"user\", or \"assistant\"')\n\n        if message.images:\n          message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, (dict, Message)):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_parse_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/v1/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/v1/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Missing model')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    params = {\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      f'/v1/models/{urllib.parse.quote(model)}/generate',\n      json=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if options is None:\n      options = {}\n\n    if keep_alive is not None:\n      options['keep_alive'] = keep_alive\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/v1/generate',\n      data=json.dumps(data),\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('missing model')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      json=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    return self._request_stream(\n      'POST',\n      '/v1/chat/completions',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context,\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model is required')\n\n    url = '/generate'\n\n    if context:\n      context = b64encode(bytes(context)).decode()\n\n    if images:\n      images = [\n        {\n          'url': _parse_image(image),\n          'mimetype': _get_image_mimetype(image),\n        }\n        for image in images\n      ]\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', url, json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    if not prompt:\n      raise RequestError('Prompt is required')\n\n    if not system:\n      raise RequestError('System is required')\n\n    if not template:\n      raise RequestError('Template is required')\n\n    if not context:\n      context = []\n\n    if not images:\n      images = []\n\n    if not options:\n      options = {}\n\n    if not keep_alive:\n      keep_alive = 0\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/v1/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Missing model')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/v1/generate',\n      json=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    url = f'/v1/models/{model}/completions'\n\n    data = {\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', url, json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', 'generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model must be provided')\n\n    if not isinstance(model, str):\n      raise TypeError('model must be a string')\n\n    if not isinstance(prompt, str):\n      raise TypeError('prompt must be a string')\n\n    if not isinstance(system, str):\n      raise TypeError('system must be a string')\n\n    if not isinstance(template, str):\n      raise TypeError('template must be a string')\n\n    if not isinstance(context, Sequence):\n      raise TypeError('context must be a sequence')\n\n    if not isinstance(raw, bool):\n      raise TypeError('raw must be a boolean')\n\n    if not isinstance(format, str):\n      raise TypeError('format must be a string')\n\n    if not isinstance(images, Sequence):\n      raise TypeError('images must be a sequence')\n\n    if not isinstance(options, Options):\n      raise TypeError('options must be a Options object')\n\n    if not isinstance(keep_alive, (float, str)):\n      raise TypeError('keep_alive must be a float or a string')\n\n    if images:\n      if not isinstance(images, Sequence):\n        raise TypeError('images must be a sequence')\n\n      for image in images:\n        if not isinstance(image, (str, bytes, bytearray)):\n          raise TypeError('images must be a sequence of strings, bytes, or bytearrays')\n\n    if options:\n      if not isinstance(options, Options):\n        raise TypeError('options must be a Options object')\n\n    if context is None:\n      context = []\n\n    if not isinstance(context, Sequence):\n      raise TypeError('context must be a sequence')\n\n    if not isinstance(stream, bool):\n      raise TypeError('stream must be a boolean')\n\n    if not isinstance(raw, bool):\n      raise TypeError('raw must be a boolean')\n\n    if not isinstance(format, str):\n      raise TypeError('format must be a string')\n\n    if format not in ['', 'json']:\n      raise ValueError('format must be either an empty string or \"json\"')\n\n    if options:\n      if not isinstance(options, Options):\n        raise TypeError('options must be a Options object')\n\n    if keep_alive is not None and not isinstance(keep_alive, (float, str)):\n      raise TypeError('keep_alive must be a float or a string')\n\n    if images:\n      if not isinstance(images, Sequence):\n        raise TypeError('images must be a sequence')\n\n      for image in"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    if not prompt:\n      raise RequestError('Prompt is required')\n\n    if images:\n      images = [\n        {\n          'name': name,\n          'data': b64encode(data).decode(),\n        }\n        for name, data in images\n      ]\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('post', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Missing model')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      params=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('Model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/v1/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.is_file():\n        raise RequestError('path must be a file')\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.is_file():\n        raise RequestError('path must be a valid file')\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path).expanduser().resolve()\n      if not path.exists():\n        raise RequestError(f'path does not exist: {path}')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError(f'path \"{path}\" does not exist')\n      if not path.is_file():\n        raise RequestError(f'path \"{path}\" is not a file')\n\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError(f'path does not exist: {path}')\n      if not path.is_file():\n        raise RequestError(f'path is not a file: {path}')\n\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.is_file():\n        raise RequestError(f'path {path} is not a file')\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError('path does not exist')\n      if not path.is_file():\n        raise RequestError('path is not a file')\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide a path or a modelfile')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either a path or a modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide a path to the model file or the model file itself')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    if isinstance(modelfile, str):\n      modelfile = modelfile.encode()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.is_file():\n        raise RequestError('path must be a file')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    checksum = sha256(modelfile).hexdigest()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'checksum': checksum,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide path or modelfile')\n\n    if path and modelfile:\n      raise RequestError('cannot provide both path and modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      try:\n        with open(path, 'rb') as f:\n          modelfile = f.read()\n      except Exception as e:\n        raise RequestError(f'failed to read model file at path {path}') from e\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path).expanduser().absolute()\n      if not path.exists():\n        raise RequestError(f'path \"{path}\" does not exist')\n\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile and not path:\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    checksum = sha256(path.read_bytes()).hexdigest()\n    response = self._client.head(f'/api/blobs/{checksum}')\n\n    if response.status_code == 404:\n      response = self._client.post(\n        f'/api/blobs/{checksum}',\n        data=path.read_bytes(),\n      )\n      response.raise_for_status()\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    with path.open('rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with path.open('rb') as f:\n          self._client.post(f'/api/blobs/{digest}', data=f)\n      else:\n        raise e\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = sha256(path.read_bytes()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with path.open('rb') as f:\n          self._client.post(f'/api/blobs/{digest}', data=f)\n      else:\n        raise\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = sha256(path.read_bytes()).hexdigest()\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with path.open('rb') as f:\n          self._client.post(\n            f'/api/blobs/{digest}',\n            data=f,\n          )\n      else:\n        raise e\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    with path.open('rb') as f:\n      digest = 'sha256:' + sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise e\n      with path.open('rb') as f:\n        self._client.post(\n          f'/api/blobs/{digest}',\n          data=f,\n        )\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    with path.open('rb') as f:\n      blob_sha256 = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{blob_sha256}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with path.open('rb') as f:\n          self._client.post(\n            f'/api/blobs/{blob_sha256}',\n            data=f,\n          )\n      else:\n        raise e\n\n    return f'sha256:{blob_sha256}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path).expanduser()\n    if not path.exists():\n      raise RequestError(f'file not found: {path}')\n\n    with path.open('rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with path.open('rb') as f:\n          self._client.post(f'/api/blobs/{digest}', data=f)\n      else:\n        raise e\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    try:\n      response = self._client.head(f'/api/blobs/{checksum}')\n      response.raise_for_status()\n    except httpx.HTTPStatusError:\n      with open(path, 'rb') as f:\n        response = self._client.post(f'/api/blobs/{checksum}', data=f)\n        response.raise_for_status()\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file\n    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    # Check if a blob with the same checksum already exists on the server\n    response = self._client.head(f'/api/blobs/{checksum}')\n\n    # If the blob does not exist, upload the file as a new blob\n    if response.status_code == 404:\n      with open(path, 'rb') as f:\n        response = self._client.post(f'/api/blobs/{checksum}', data=f.read())\n\n    # Return the digest of the file\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    if not path.exists():\n      raise FileNotFoundError(path)\n\n    digest = sha256(path.read_bytes()).hexdigest()\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with open(path, 'rb') as f:\n          self._client.post(\n            f'/api/blobs/{digest}',\n            data=f,\n          )\n      else:\n        raise\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file\n    digest = sha256(path.read_bytes()).hexdigest()\n\n    # Check if a blob with the same checksum already exists on the server\n    try:\n      response = self._client.head(f'/api/blobs/{digest}')\n      response.raise_for_status()\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n\n    # If the blob does not exist, upload the file as a new blob\n    else:\n      with path.open('rb') as f:\n        response = self._client.post(\n          f'/api/blobs/{digest}',\n          data=f,\n        )\n        response.raise_for_status()\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{checksum}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise e\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blobs/{checksum}', data=f)\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    if not path.exists():\n      raise RequestError(f'file not found: {path}')\n\n    checksum = sha256(path.read_bytes()).hexdigest()\n    try:\n      self._client.head(f'/api/blobs/{checksum}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n      self._client.post(f'/api/blobs', files={'file': path.open('rb')})\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file\n    checksum = sha256(path.read_bytes()).hexdigest()\n\n    # Check if a blob with the same checksum already exists on the server\n    try:\n      response = self._client.head(f'/api/blobs/{checksum}')\n    except httpx.HTTPStatusError as e:\n      # If the blob does not exist, upload the file as a new blob\n      if e.response.status_code == 404:\n        response = self._client.post(\n          '/api/blobs',\n          files={'blob': ('blob', path.open('rb'), 'application/octet-stream')},\n        )\n        response.raise_for_status()\n      else:\n        # If the request failed for any other reason, raise the exception\n        raise\n\n    # Return the digest of the file\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n\n    if path.exists():\n      with path.open('rb') as f:\n        checksum = sha256(f.read()).hexdigest()\n    else:\n      raise FileNotFoundError(path)\n\n    response = self._client.request('HEAD', f'/api/blobs/{checksum}')\n\n    if response.status_code == 404:\n      with path.open('rb') as f:\n        response = self._client.request('POST', '/api/blobs', data=f)\n        response.raise_for_status()\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    with path.open('rb') as f:\n      blob = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{blob}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with path.open('rb') as f:\n          self._client.post(f'/api/blobs/{blob}', data=f)\n      else:\n        raise e\n\n    return f'sha256:{blob}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = sha256(path.read_bytes()).hexdigest()\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        self._client.post(f'/api/blobs/{digest}', data=path.read_bytes())\n      else:\n        raise e\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{checksum}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with open(path, 'rb') as f:\n          self._client.post(\n            '/api/blobs',\n            data=f,\n            headers={'Content-Type': 'application/octet-stream'},\n          )\n      else:\n        raise e\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    if path.is_absolute():\n      path = path.relative_to(Path.cwd())\n\n    digest = _sha256_digest(path)\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        self._client.post(\n          f'/api/blobs/{digest}',\n          files={'file': (path.name, path.open('rb'))},\n        )\n      else:\n        raise e\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{checksum}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        with open(path, 'rb') as f:\n          self._client.post(f'/api/blobs/{checksum}', data=f)\n      else:\n        raise\n\n    return f'sha256:{checksum}'\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns an asynchronous `ProgressResponse` generator.\n    \"\"\"\n    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user-provided code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as user_code_file:\n            user_code_file.write(user_code)\n\n        # Create a temporary file to store the test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as test_code_file:\n            test_code_file.write(test_code)\n\n        # Run pyright on the user code and test code\n        pyright_output = subprocess.run(\n            [\n                \"pyright\",\n                \"--outputjson\",\n                \"--lib\",\n                str(ROOT_DIR / \"pyright_libs\"),\n                user_code_file.name,\n                test_code_file.name,\n            ],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            encoding=\"utf-8\",\n        )\n\n        # Delete the temporary files\n        user_code_file.close()\n        test_code_file.close()\n\n        # Parse the output of pyright\n        pyright_output_json = io.StringIO(pyright_output.stdout)\n        pyright_output_json = tokenize.tokenize(pyright_output_json.readline)\n        pyright_output_json = list(pyright_output_json)\n        pyright_output_json = pyright_output_json[0][1]\n        pyright_output_json = pyright_output_json.replace(\"'\", '\"')\n        pyright_output_json = pyright_output_json.replace(\"False\", \"false\")\n        pyright_output_json = pyright_output_json.replace(\"True\", \"true\")\n        pyright_output_json = pyright_output_json.replace(\"None\", \"null\")\n        pyright_output_json = pyright_output_json.replace(\"nan\", \"NaN\")\n        pyright_output_json = pyright_output_json.replace(\"inf\", \"Infinity\")\n        pyright_output_json = pyright_output_json.replace(\"-inf\", \"-Infinity\")\n        pyright_output_json = pyright_output_json.replace(\"nan\", \"NaN\")\n        pyright_output_json = pyright_output_json.replace(\"inf\","}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined user code and test code\n        with tempfile.NamedTemporaryFile(suffix=\".py\", mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(user_code)\n            f.write(test_code)\n            f.flush()\n\n            # Run Pyright on the temporary file to perform type checking\n            output = subprocess.run(\n                [\"pyright\", f.name],\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n\n        # Check if the type check passed\n        passed = output.returncode == 0\n\n        # Extract the error messages from the Pyright output\n        messages = []\n        if not passed:\n            for line in output.stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, message = match.groups()\n                    messages.append(f\"Line {line_no}: {message}\")\n\n        # Check if the type check failed due to an expected type error\n        if not passed and cls.EXPECT_ERROR_COMMENT in user_code:\n            passed = True\n            messages = []\n\n        # Create a TypeCheckResult object to store the result of the type check\n        result = TypeCheckResult(\n            message=\"\\n\".join(messages),\n            passed=passed,\n            debug_info={\"pyright_output\": output.stderr},\n        )\n\n        return result\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary directory to store the user code and test code files\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            # Create a temporary file to store the user code\n            user_code_file = Path(tmp_dir) / \"user_code.py\"\n            user_code_file.write_text(user_code)\n\n            # Create a temporary file to store the test code\n            test_code_file = Path(tmp_dir) / \"test_code.py\"\n            test_code_file.write_text(test_code)\n\n            # Run pyright to type check the user code and test code\n            pyright_process = subprocess.run(\n                [\n                    \"pyright\",\n                    \"--outputjson\",\n                    \"--project\",\n                    tmp_dir,\n                    \"--lib\",\n                    str(ROOT_DIR / \"lib\"),\n                ],\n                capture_output=True,\n                text=True,\n            )\n\n            # Check if pyright returned an error\n            if pyright_process.returncode != 0:\n                return TypeCheckResult(\n                    message=f\"Error running pyright: {pyright_process.stderr}\",\n                    passed=False,\n                )\n\n            # Parse the JSON output from pyright\n            pyright_output = pyright_process.stdout\n            pyright_output_json = io.StringIO(pyright_output)\n            pyright_output_json = json.load(pyright_output_json)\n\n            # Check if pyright returned any errors\n            if \"errors\" not in pyright_output_json:\n                return TypeCheckResult(\n                    message=\"No errors found.\",\n                    passed=True,\n                )\n\n            # Get the errors from pyright\n            pyright_errors = pyright_output_json[\"errors\"]\n\n            # Check if there are any errors in the user code\n            user_code_errors = [\n                error\n                for error in pyright_errors\n                if error[\"fileName\"] == str(user_code_file)\n            ]\n\n            # Check if there are any errors in the test code\n            test_code_errors = [\n                error\n                for error in pyright_errors\n                if error[\"fileName\"] == str(test_code_file)\n            ]\n\n            # Check if there are any errors in the user code or test code\n            if not user_code_errors and not test_code_errors:\n                return"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file for the user code\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Create a temporary file for the test code\n            with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Run Pyright on the user code and test code\n                pyright_proc = subprocess.run(\n                    [\n                        \"pyright\",\n                        \"--verifytypes\",\n                        \"--outputjson\",\n                        user_code_file.name,\n                        test_code_file.name,\n                    ],\n                    capture_output=True,\n                    text=True,\n                )\n\n                # Parse the Pyright output\n                pyright_output = pyright_proc.stdout\n                pyright_output_json = io.StringIO(pyright_output)\n                pyright_output_json = json.load(pyright_output_json)\n\n                # Extract error messages and line numbers from Pyright output\n                error_messages = []\n                error_lines = []\n                for diagnostic in pyright_output_json[\"diagnostics\"]:\n                    error_message = diagnostic[\"message\"]\n                    error_line = diagnostic[\"range\"][\"start\"][\"line\"] + 1\n                    error_messages.append(error_message)\n                    error_lines.append(error_line)\n\n                # Check if the type check passed\n                type_check_passed = True\n                for line_number, error_message in zip(error_lines, error_messages):\n                    if not error_message.startswith(cls.EXPECT_ERROR_COMMENT):\n                        type_check_passed = False\n                        break\n\n                # Create the result object\n                result = TypeCheckResult(\n                    message=\"Type check passed\"\n                    if type_check_passed\n                    else \"Type check failed\",\n                    passed=type_check_passed,\n                    debug_info={\n                        \"user_code\": user_code,\n                        \"test_code\": test_code,\n                        \"pyright_output\": pyright_output,\n                        \"error_messages\": error_messages,\n                        \"error_lines\": error_lines,\n                    },\n                )\n\n                return result\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined user code and test code\n        with tempfile.NamedTemporaryFile(suffix=\".py\", mode=\"w+\") as combined_file:\n            combined_file.write(user_code + \"\\n\" + test_code)\n            combined_file.flush()\n\n            # Run Pyright on the temporary file\n            pyright_process = subprocess.run(\n                [\"pyright\", combined_file.name],\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n\n            # Check if the process exited successfully\n            if pyright_process.returncode != 0:\n                return TypeCheckResult(\n                    message=f\"Pyright failed with error code {pyright_process.returncode}\",\n                    passed=False,\n                    debug_info={\n                        \"user_code\": user_code,\n                        \"test_code\": test_code,\n                        \"pyright_output\": pyright_process.stdout,\n                        \"pyright_error\": pyright_process.stderr,\n                    },\n                )\n\n            # Parse the Pyright output for error messages\n            error_messages = []\n            for line in pyright_process.stdout.splitlines():\n                match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_number, message = match.groups()\n                    error_messages.append(f\"Line {line_number}: {message}\")\n\n            # Check if any error messages were found\n            if error_messages:\n                return TypeCheckResult(\n                    message=f\"Type check failed with the following errors:\\n{os.linesep.join(error_messages)}\",\n                    passed=False,\n                    debug_info={\n                        \"user_code\": user_code,\n                        \"test_code\": test_code,\n                        \"pyright_output\": pyright_process.stdout,\n                        \"pyright_error\": pyright_process.stderr,\n                    },\n                )\n\n            # Check if there are any expected type errors in the test code\n            expected_type_error_count = 0\n            for token in tokenize.generate_tokens(io.StringIO(test_code).readline):\n                if token.type == tokenize.COMMENT and cls.EXPECT_ERROR_COMMENT in token.string:\n                    expected_type_error_count += 1\n\n            # Check if the expected number of type errors"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary directory to store the files\n        temp_dir = tempfile.TemporaryDirectory()\n        temp_dir_path = Path(temp_dir.name)\n\n        # Write the user code to a file in the temporary directory\n        user_code_file = temp_dir_path / \"user_code.py\"\n        user_code_file.write_text(user_code, encoding=\"utf-8\")\n\n        # Write the test code to a file in the temporary directory\n        test_code_file = temp_dir_path / \"test_code.py\"\n        test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n        # Run Pyright to type check the user code and test code\n        try:\n            pyright_process = subprocess.run(\n                [\n                    \"pyright\",\n                    \"--outputjson\",\n                    \"--project\",\n                    str(temp_dir_path),\n                    user_code_file.name,\n                    test_code_file.name,\n                ],\n                capture_output=True,\n                text=True,\n            )\n        except FileNotFoundError:\n            return TypeCheckResult(\n                message=\"Pyright is not installed. Please install Pyright to use this feature.\",\n                passed=False,\n            )\n\n        # Parse the JSON output from Pyright\n        pyright_output = pyright_process.stdout\n        pyright_json = io.StringIO(pyright_output)\n        pyright_messages = list(tokenize.json_lines(pyright_json))\n\n        # Find the line numbers of the expected type errors\n        expected_error_lines = []\n        for line in user_code.splitlines():\n            if cls.EXPECT_ERROR_COMMENT in line:\n                expected_error_lines.append(len(expected_error_lines) + 1)\n\n        # Find the line numbers of the actual type errors\n        actual_error_lines = []\n        for message in pyright_messages:\n            match = re.search(cls.PYRIGHT_MESSAGE_REGEX, message[\"message\"])\n            if match:\n                actual_error_lines.append(int(match.group(1)))\n\n        # Check if the type check passed\n        passed = True\n        if expected_error_lines != actual_error_lines:\n            passed = False\n\n        # Create a message to display the result of the type check\n        message = ("}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary directory to store the user code and test code files\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            # Write the user code and test code to separate files\n            user_code_path = Path(tmp_dir) / \"user_code.py\"\n            user_code_path.write_text(user_code)\n            test_code_path = Path(tmp_dir) / \"test_code.py\"\n            test_code_path.write_text(test_code)\n\n            # Call Pyright to perform the type check\n            pyright_result = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_path), str(test_code_path)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the Pyright output\n            pyright_output = pyright_result.stdout\n            pyright_output_json = io.StringIO(pyright_output)\n\n            # Initialize the result message and debug information\n            result_message = \"\"\n            debug_info = {}\n\n            # Iterate over the Pyright output and check for errors\n            for line in pyright_output_json:\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    # Extract the line number and error message\n                    line_number = int(match.group(1))\n                    error_message = match.group(2)\n\n                    # Check if the line number is in the user code\n                    if line_number <= len(user_code.splitlines()):\n                        # Check if the line has the expected error comment\n                        if cls.EXPECT_ERROR_COMMENT in user_code.splitlines()[\n                            line_number - 1\n                        ]:\n                            # Remove the expected error comment from the user code\n                            user_code_lines = user_code.splitlines()\n                            user_code_lines[line_number - 1] = user_code_lines[\n                                line_number - 1\n                            ].replace(\n                                cls.EXPECT_ERROR_COMMENT, \"\"\n                            ).strip()\n                            user_code = \"\\n\".join(user_code_lines)\n\n                            # Add the error message to the debug information\n                            debug_info[line_number] = error_message\n                        else:\n                            # Add the error message to the result message\n                            result_message += f"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\") as combined_code_file:\n            combined_code_file.write(user_code + test_code)\n            combined_code_file.flush()\n\n            # Run Pyright to type check the combined code\n            pyright_process = subprocess.run(\n                [\"pyright\", combined_code_file.name],\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n\n            # Extract the relevant information from Pyright's output\n            error_messages = []\n            expected_error_lines = set()\n            for line in pyright_process.stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_number = int(match.group(1))\n                    error_messages.append(match.group(2))\n                    if line.startswith(cls.EXPECT_ERROR_COMMENT):\n                        expected_error_lines.add(line_number)\n\n            # Check if the type check passed\n            passed = len(error_messages) == 0 or (\n                len(error_messages) == len(expected_error_lines)\n                and all(\n                    error_message.startswith(cls.EXPECT_ERROR_COMMENT)\n                    for error_message in error_messages\n                )\n            )\n\n            # Return the result of the type check\n            return TypeCheckResult(\n                message=\"\\n\".join(error_messages),\n                passed=passed,\n                debug_info={\n                    \"expected_error_lines\": expected_error_lines,\n                    \"error_messages\": error_messages,\n                },\n            )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code into a single string\n        code = user_code + test_code\n\n        # Use Pyright to type check the combined code\n        with tempfile.NamedTemporaryFile() as temp:\n            temp.write(code.encode(\"utf-8\"))\n            temp.flush()\n            result = subprocess.run(\n                [\"pyright\", temp.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                encoding=\"utf-8\",\n            )\n\n        # Parse the output of Pyright to extract the error messages and line numbers\n        error_messages = []\n        line_numbers = []\n        for line in result.stderr.splitlines():\n            match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number = int(match.group(1))\n                error_message = match.group(2)\n                error_messages.append(error_message)\n                line_numbers.append(line_number)\n\n        # Check if there are any expected type errors in the error messages\n        expected_type_errors = []\n        for i, error_message in enumerate(error_messages):\n            if cls.EXPECT_ERROR_COMMENT in error_message:\n                expected_type_errors.append(line_numbers[i])\n\n        # Check if the type check passed\n        passed = not expected_type_errors\n\n        # Construct the result message\n        if passed:\n            message = \"Type check passed.\"\n        else:\n            message = \"Type check failed. Expected type errors on lines: \"\n            message += \", \".join(str(line_number) for line_number in expected_type_errors)\n\n        # Construct the result object\n        result = TypeCheckResult(message=message, passed=passed)\n\n        return result\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code and test code to temporary files\n        with tempfile.NamedTemporaryFile(suffix=\".py\", mode=\"w\") as user_file, tempfile.NamedTemporaryFile(\n            suffix=\".py\", mode=\"w\"\n        ) as test_file:\n            user_file.write(user_code)\n            user_file.flush()\n            test_file.write(test_code)\n            test_file.flush()\n\n            # Run pyright on the combined code\n            try:\n                result = subprocess.run(\n                    [\"pyright\", user_file.name, test_file.name],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    universal_newlines=True,\n                )\n            except FileNotFoundError as e:\n                return TypeCheckResult(\n                    message=\"Pyright is not installed. Please install it by running `pip install pyright`.\",\n                    passed=False,\n                )\n\n        # Check the exit code and handle errors\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=f\"Pyright failed with exit code {result.returncode}.\",\n                passed=False,\n            )\n\n        # Parse the output and identify lines with expected type errors\n        expected_error_lines = set()\n        for line in result.stdout.splitlines():\n            match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number = int(match.group(1))\n                message = match.group(2)\n                if cls.EXPECT_ERROR_COMMENT in message:\n                    expected_error_lines.add(line_number)\n\n        # Check if the type check passed\n        passed = len(expected_error_lines) == 0\n\n        # Return the result\n        return TypeCheckResult(\n            message=\"Passed\" if passed else \"Failed\",\n            passed=passed,\n            debug_info={\"expected_error_lines\": list(expected_error_lines)},\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined user code and test code\n        with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(user_code + \"\\n\" + test_code)\n            temp_file.flush()\n            temp_file.close()\n            temp_file_path = temp_file.name\n\n        # Run Pyright to perform type checking on the temporary file\n        process = subprocess.run(\n            [\"pyright\", temp_file_path],\n            capture_output=True,\n            text=True,\n            encoding=\"utf-8\",\n        )\n        os_error = process.stderr\n        process.check_returncode()\n\n        # Delete the temporary file\n        Path(temp_file_path).unlink()\n\n        # Parse the Pyright output to identify lines with expected type errors\n        error_messages = []\n        for line in process.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number = int(match.group(1))\n                error_message = match.group(2)\n                if cls.EXPECT_ERROR_COMMENT in user_code.splitlines()[line_number - 1]:\n                    error_messages.append(error_message)\n\n        # Return the result of the type check\n        return TypeCheckResult(\n            message=\" \".join(error_messages),\n            passed=len(error_messages) == 0,\n            debug_info={\"pyright_output\": process.stdout, \"os_error\": os_error},\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary directory and file to store the user-provided code and test code\n        with tempfile.TemporaryDirectory() as temp_dir:\n            with tempfile.NamedTemporaryFile(\n                dir=temp_dir, mode=\"w\", encoding=\"utf-8\", delete=False\n            ) as temp_file:\n                temp_file.write(user_code + test_code)\n                temp_file_path = Path(temp_file.name)\n\n            # Run the Pyright type checker on the temporary file\n            pyright_command = [\"pyright\", str(temp_file_path)]\n            pyright_result = subprocess.run(\n                pyright_command, capture_output=True, text=True\n            )\n\n            # Check if the type check passed or failed\n            if pyright_result.returncode == 0:\n                # Type check passed\n                return TypeCheckResult(\n                    message=\"Type check passed!\", passed=True, debug_info={}\n                )\n            else:\n                # Type check failed\n                # Parse the error messages from the Pyright output\n                error_messages = []\n                expected_error_lines = set()\n                for line in pyright_result.stderr.splitlines():\n                    match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n                    if match:\n                        line_number = int(match.group(1))\n                        error_message = match.group(2)\n                        error_messages.append(f\"{line_number}: {error_message}\")\n                        if line.startswith(cls.EXPECT_ERROR_COMMENT):\n                            expected_error_lines.add(line_number)\n\n                # Check if the expected type errors were found\n                if expected_error_lines:\n                    # Check if the expected type errors were found in the error messages\n                    if expected_error_lines.issubset(\n                        set(line_number for line_number, _ in error_messages)\n                    ):\n                        # Expected type errors were found\n                        return TypeCheckResult(\n                            message=\"Type check passed!\",\n                            passed=True,\n                            debug_info={\n                                \"error_messages\": error_messages,\n                                \"expected_error_lines\": expected_error_lines,\n                            },\n                        )\n                    else:\n                        # Expected type errors were not found\n                        return TypeCheckResult(\n                            message=\"Type check failed! Expected type errors were not found.\",\n                            passed=False,\n                            debug"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Prepare the code to be type checked\n        code_to_check = user_code + test_code\n\n        # Create a temporary file to store the code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as temp_file:\n            temp_file.write(code_to_check)\n            temp_file.flush()\n\n            # Run Pyright on the temporary file\n            pyright_output = subprocess.run(\n                [\"pyright\", temp_file.name],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the output to identify the lines with expected type errors\n            lines_with_errors = []\n            for line in pyright_output.stderr.splitlines():\n                match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_number = int(match.group(1))\n                    error_message = match.group(2)\n                    lines_with_errors.append((line_number, error_message))\n\n            # Check if the type check passed\n            type_check_passed = len(lines_with_errors) == 0\n\n            # Prepare the error message\n            if type_check_passed:\n                error_message = \"Type check passed.\"\n            else:\n                error_message = \"Type check failed.\"\n                error_message += \"\\n\\n\"\n                for line_number, error_message in lines_with_errors:\n                    error_message += f\"Line {line_number}: {error_message}\\n\"\n\n            # Return the result\n            return TypeCheckResult(\n                message=error_message,\n                passed=type_check_passed,\n                debug_info={\n                    \"user_code\": user_code,\n                    \"test_code\": test_code,\n                    \"pyright_output\": pyright_output.stderr,\n                },\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # The Pyright command to run\n        pyright_command = [\"pyright\", \"--stdio\"]\n\n        # Create a temporary file to store the combined user-provided code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as tmp_file:\n            tmp_file.write(user_code + \"\\n\" + test_code)\n            tmp_file.flush()\n            pyright_command.append(tmp_file.name)\n\n        # Run Pyright with the temporary file as input\n        pyright_output = subprocess.check_output(pyright_command, stderr=subprocess.STDOUT)\n\n        # Decode the Pyright output to a string\n        pyright_output_str = pyright_output.decode(\"utf-8\")\n\n        # Initialize the result message and passed boolean\n        result_message = \"\"\n        passed = True\n\n        # Parse the Pyright output to identify expected type errors and lines with errors\n        for line in pyright_output_str.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, message = match.groups()\n                if cls.EXPECT_ERROR_COMMENT in line:\n                    # Expected type error, add to result message\n                    result_message += f\"Expected error on line {line_no}: {message}\\n\"\n                else:\n                    # Unexpected type error, add to result message and set passed to False\n                    result_message += f\"Unexpected error on line {line_no}: {message}\\n\"\n                    passed = False\n\n        # Return the result object\n        return TypeCheckResult(result_message, passed)\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n            temp_file.flush()\n            temp_file.seek(0)\n\n            # Run Pyright to perform a type check on the temporary file\n            process = subprocess.run(\n                [\"pyright\", temp_file.name],\n                capture_output=True,\n                text=True,\n                encoding=\"utf-8\",\n            )\n\n            # Delete the temporary file\n            temp_file.close()\n            Path(temp_file.name).unlink()\n\n        # Check if the type check passed\n        if process.returncode == 0:\n            return TypeCheckResult(\n                message=\"Type check passed!\",\n                passed=True,\n            )\n\n        # Get the error messages from the process output\n        error_messages = []\n        for line in process.stderr.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_messages.append(match.group(2))\n\n        # Check if the type check failed due to expected type errors\n        if cls.EXPECT_ERROR_COMMENT in test_code:\n            return TypeCheckResult(\n                message=\"Type check failed due to expected type errors!\",\n                passed=False,\n                debug_info={\"error_messages\": error_messages},\n            )\n\n        # If the type check failed for unexpected reasons, return an error message\n        return TypeCheckResult(\n            message=\"Type check failed due to unexpected errors!\",\n            passed=False,\n            debug_info={\"error_messages\": error_messages},\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to hold the user code and test code combined\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as tmp_file:\n            tmp_file.write(user_code + \"\\n\" + test_code)\n\n        # Run Pyright on the temporary file\n        try:\n            result = subprocess.run(\n                [\"pyright\", tmp_file.name],\n                capture_output=True,\n                text=True,\n                check=True,\n            )\n        except subprocess.CalledProcessError as e:\n            result = e.output\n\n        # Delete the temporary file\n        tmp_file.close()\n        Path(tmp_file.name).unlink()\n\n        # Parse the output of Pyright and identify lines with expected type errors\n        lines_with_expected_type_errors = []\n        for line in result.splitlines():\n            match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number = int(match.group(1))\n                error_message = match.group(2)\n                if cls.EXPECT_ERROR_COMMENT in error_message:\n                    lines_with_expected_type_errors.append(line_number)\n\n        # Check if the type check passed\n        passed = len(lines_with_expected_type_errors) == 0\n\n        # Build the message to return\n        message = \"\"\n        if passed:\n            message = \"Your code passes the type check.\"\n        else:\n            message = (\n                \"Your code fails the type check on the following lines:\\n\"\n                + \"\\n\".join(\n                    f\"Line {line_number}: {error_message}\"\n                    for line_number, error_message in enumerate(\n                        lines_with_expected_type_errors, start=1\n                    )\n                )\n            )\n\n        return TypeCheckResult(message, passed)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code into a single string\n        code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", delete=False) as f:\n            f.write(code)\n            filename = f.name\n\n        # Run Pyright on the temporary file\n        output = subprocess.check_output(\n            [\n                \"pyright\",\n                \"--outputjson\",\n                \"--project\",\n                ROOT_DIR,\n                filename,\n            ],\n            stderr=subprocess.STDOUT,\n            text=True,\n        )\n\n        # Delete the temporary file\n        Path(filename).unlink()\n\n        # Parse the output from Pyright\n        output_json = io.StringIO(output)\n        messages = []\n        passed = True\n        for line in tokenize.generate_tokens(output_json.readline):\n            if line.type == tokenize.COMMENT:\n                if cls.EXPECT_ERROR_COMMENT in line.string:\n                    passed = False\n                continue\n            if line.type == tokenize.STRING:\n                messages.append(line.string)\n\n        # Parse the line numbers of the expected type errors\n        line_numbers = []\n        for message in messages:\n            match = re.search(cls.PYRIGHT_MESSAGE_REGEX, message)\n            if match:\n                line_numbers.append(int(match.group(1)))\n\n        # Generate the error message\n        message = \"\"\n        for message in messages:\n            message += \"\\n\"\n\n        # Check if the type check passed\n        if passed:\n            message += \"Type check passed!\"\n        else:\n            message += \"Type check failed!\"\n            message += \"\\n\"\n            message += \"Expected type error on lines: \"\n            message += \", \".join(map(str, line_numbers))\n\n        # Create a TypeCheckResult object and return it\n        return TypeCheckResult(message=message, passed=passed, debug_info={\"messages\": messages})\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user-provided code and test code into a single file for type checking\n        combined_code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(\"w\", encoding=\"utf-8\") as temp_file:\n            temp_file.write(combined_code)\n            temp_file.flush()\n\n            # Run Pyright on the temporary file\n            pyright_result = subprocess.run(\n                [\"pyright\", temp_file.name],\n                capture_output=True,\n                text=True,\n                encoding=\"utf-8\",\n            )\n\n            # Parse the Pyright output for errors\n            errors = []\n            expected_error_lines = set()\n            for line in pyright_result.stderr.splitlines():\n                match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_number = int(match.group(1))\n                    message = match.group(2)\n                    errors.append(f\"{line_number}: {message}\")\n                    if line.startswith(f\"{temp_file.name}:{line_number}\"):\n                        if line.startswith(\n                            f\"{temp_file.name}:{line_number}:{cls.EXPECT_ERROR_COMMENT}\"\n                        ):\n                            expected_error_lines.add(line_number)\n                        else:\n                            errors.append(\n                                f\"{line_number}: {cls.EXPECT_ERROR_COMMENT} is missing\"\n                            )\n\n        # Determine if the type check passed\n        passed = len(errors) == 0 or len(errors) == len(expected_error_lines)\n\n        # Return the result\n        return TypeCheckResult(\n            message=\"\\n\".join(errors),\n            passed=passed,\n            debug_info={\"expected_error_lines\": expected_error_lines},\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user-provided code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", delete=False) as f:\n            f.write(user_code)\n            f.write(test_code)\n            temp_file_path = f.name\n\n        # Run Pyright on the temporary file\n        output = subprocess.run(\n            [\"pyright\", temp_file_path],\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n\n        # Delete the temporary file\n        Path(temp_file_path).unlink()\n\n        # Check if the type check passed\n        passed = output.returncode == 0\n\n        # Initialize the error messages list\n        error_messages = []\n\n        # If the type check failed, parse the output to extract error messages\n        if not passed:\n            # Split the output into lines\n            lines = output.stderr.splitlines()\n\n            # Iterate over the lines and extract error messages\n            for line in lines:\n                # Check if the line matches the expected error format\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    # Extract the line number and error message\n                    line_number = int(match.group(1))\n                    error_message = match.group(2)\n\n                    # Check if the line has an expected error comment\n                    if (\n                        cls.EXPECT_ERROR_COMMENT in line\n                        and line_number not in error_messages\n                    ):\n                        # Add the error message to the list\n                        error_messages.append(error_message)\n\n        # Create the message based on the type check result\n        message = (\n            \"Congratulations, your code passed the type check!\"\n            if passed\n            else \"Oops, your code failed the type check. See the error messages below.\"\n        )\n\n        # Return the result\n        return TypeCheckResult(\n            message=message,\n            passed=passed,\n            debug_info={\"error_messages\": error_messages},\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n            f.write(user_code + \"\\n\" + test_code)\n            temp_file_path = Path(f.name)\n\n        # Run Pyright on the temporary file\n        pyright_process = subprocess.run(\n            [\"pyright\", str(temp_file_path)],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            encoding=\"utf-8\",\n            check=True,\n        )\n\n        # Delete the temporary file\n        temp_file_path.unlink()\n\n        # Extract the error messages from the output\n        error_messages = []\n        for line in pyright_process.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_messages.append(match.group(2))\n\n        # Check if there are any expected type errors in the error messages\n        passed = True\n        for line in test_code.splitlines():\n            if cls.EXPECT_ERROR_COMMENT in line:\n                if not error_messages:\n                    passed = False\n                    break\n                error_messages.pop(0)\n\n        # Prepare the result message\n        if passed:\n            message = \"Passed! No type errors found.\"\n        else:\n            message = \"Failed! Type errors found:\\n\" + \"\\n\".join(error_messages)\n\n        return TypeCheckResult(message, passed)"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if the request could not be fulfilled.\n\n    Returns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\n    \"\"\"\n\n    \"\"\"\n    Raises `ResponseError` if"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Forward:\"), get_compiler_fn(title=\"Backward:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Forward:\"), get_compiler_fn(title=\"Backward:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    def wrapper(*args, **kwargs):\n        with no_fake_tensor():\n            if isinstance(fn, torch.nn.Module):\n                return aot_module(fn, get_compiler_fn(title=\"Forward Graph\"))(*args, **kwargs)\n            else:\n                return aot_function(fn, get_compiler_fn(title=\"Forward Graph\"))(*args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title='Forward Graph:'))\n    else:\n        return aot_function(fn, get_compiler_fn(title='Forward Graph:'), get_compiler_fn(title='Backward Graph:'))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(\n            fn,\n            get_compiler_fn(\n                \"Forward Graph:\"),\n            get_compiler_fn(\n                \"Backward Graph:\"),\n            get_compiler_fn(\n                \"Forward Graph (optimized):\"),\n            get_compiler_fn(\n                \"Backward Graph (optimized):\"))\n    else:\n        return aot_function(\n            fn,\n            get_compiler_fn(\n                \"Forward Graph:\"),\n            get_compiler_fn(\n                \"Backward Graph:\"),\n            get_compiler_fn(\n                \"Forward Graph (optimized):\"),\n            get_compiler_fn(\n                \"Backward Graph (optimized):\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"),\n                          get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"),\n                            get_compiler_fn(\"Backward Graph:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Forward Graph:\"), get_compiler_fn(title=\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Forward Graph:\"), get_compiler_fn(title=\"Backward Graph:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Forward Graph:\"), get_compiler_fn(title=\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Forward Graph:\"), get_compiler_fn(title=\"Backward Graph:\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(\n            fn=fn,\n            forward_compiler=get_compiler_fn(\"Forward Graph:\"),\n            backward_compiler=get_compiler_fn(\"Backward Graph:\"),\n        )\n    else:\n        return aot_function(\n            fn=fn,\n            forward_compiler=get_compiler_fn(\"Forward Graph:\"),\n            backward_compiler=get_compiler_fn(\"Backward Graph:\"),\n        )"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n     print(f\"The result of the forward pass is {result}\")\n        return result\n\n    def backward(ctx, grad_output):\n        print(f\"The result of the backward pass is {grad_output}\")\n        return grad_output\n\n    return Function.apply\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Compiled Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Compiled Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Forward Graph:\"), get_compiler_fn(title=\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Forward Graph:\"), get_compiler_fn(title=\"Backward Graph:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"), get_compiler_fn(\"Backward Graph:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn=fn,\n                          forward_compiler=get_compiler_fn(\"Forward Compiler:\"),\n                          backward_compiler=get_compiler_fn(\"Backward Compiler:\"))\n    else:\n        return aot_function(fn=fn,\n                            forward_compiler=get_compiler_fn(\"Forward Compiler:\"),\n                            backward_compiler=get_compiler_fn(\"Backward Compiler:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Graph:\"),\n                          get_compiler_fn(\"Backward Graph:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph:\"),\n                            get_compiler_fn(\"Backward Graph:\"))"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file\n    with open(os.path.join(trial_path, \"config.yaml\"), \"r\") as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary dataframe to a dictionary\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the dictionary to a YAML file if an output path is provided\n    if output_path is not None:\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file from the trial directory\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file from the trial directory\n    with open(os.path.join(trial_path, \"config.yaml\"), \"r\") as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary dataframe to a dictionary of the best pipeline configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best configuration dictionary to a YAML file if an output path is provided\n    if output_path is not None:\n        if not output_path.endswith((\".yaml\", \".yml\")):\n            output_path += \".yaml\"\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Read the summary.csv file from the trial directory\n    summary_df = load_summary_file(trial_path)\n\n    # Read the configuration file from the trial directory\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary dataframe to a YAML configuration dictionary\n    config_yaml = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the configuration to a YAML file if an output path is provided\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_yaml, f)\n\n    return config_yaml\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            output_path = output_path + '.yaml'\n        yaml.dump(best_config_dict, open(output_path, 'w'))\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(os.path.join(trial_path, \"summary.csv\"))\n    with open(os.path.join(trial_path, \"config.yaml\"), \"r\") as f:\n        config_dict = yaml.safe_load(f)\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file\n    with open(os.path.join(trial_path, \"config.yaml\"), \"r\") as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary and configuration files to a YAML file\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best configuration to a YAML file\n    if output_path:\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, \"config.yaml\"), \"r\"))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, \"config.yaml\")))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, \"w\") as f:\n            yaml.safe_dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, \"config.yaml\"), 'r'))\n\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary dataframe to a dictionary\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best configuration to a file if the output path is specified\n    if output_path is not None:\n        if not output_path.endswith(('.yaml', '.yml')):\n            output_path += '.yaml'\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file from the trial directory\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file from the trial directory\n    config_path = os.path.join(trial_path, \"config.yaml\")\n    with open(config_path, \"r\") as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary and configuration files to a dictionary of the best pipeline configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best pipeline configuration to a YAML file if an output path is provided\n    if output_path is not None:\n        # Check if the output path has a valid file extension\n        if not output_path.endswith(\".yaml\") and not output_path.endswith(\".yml\"):\n            raise ValueError(\"The output path must have a valid file extension (.yaml or .yml).\")\n\n        # Save the best pipeline configuration to the output path in YAML format\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            output_path += '.yaml'\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, \"config.yaml\"), \"r\"))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith((\".yaml\", \".yml\")):\n            output_path += \".yaml\"\n        yaml.dump(best_config_dict, open(output_path, \"w\"))\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(os.path.join(trial_path, \"summary.csv\"))\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, \"config.yaml\"), \"r\"))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(\".yaml\") and not output_path.endswith(\".yml\"):\n            output_path = output_path + \".yaml\"\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'))\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            output_path += '.yaml'\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.safe_load(f)\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            output_path = output_path + '.yaml'\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(best_config, f)\n    return best_config\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        if ts_compiler is None:\n            ts_compiler = lambda x: x\n        if not hasattr(func, 'traced_module'):\n            func.traced_module = {}\n        if not hasattr(func, 'traced_module_lock'):\n            func.traced_module_lock = threading.Lock()\n        if not hasattr(func, 'traced_module_compiler'):\n            func.traced_module_compiler = ts_compiler\n        if not hasattr(func, 'traced_module_kwargs'):\n            func.traced_module_kwargs = kwargs_\n        with func.traced_module_lock:\n            key = (args, tuple(sorted(kwargs.items())))\n            if key not in func.traced_module:\n                if isinstance(func, torch.nn.Module):\n                    func.traced_module[key] = trace_with_kwargs(\n                        func, **kwargs_)[0]\n                else:\n                    func.traced_module[key] = trace_with_kwargs(\n                        func, args, kwargs, **kwargs_)[0]\n            return func.traced_module[key]\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m: m\n\n    def _lazy_trace(func):\n        cache = {}\n        lock = threading.Lock()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with lock:\n                if func not in cache:\n                    cache[func] = trace_with_kwargs(\n                        func, *args, **kwargs, ts_compiler=ts_compiler)[0]\n                return cache[func](*args, **kwargs)\n\n        return wrapper\n\n    return _lazy_trace(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda x: x\n\n    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        with lock:\n            key = (args, tuple(sorted(kwargs.items())))\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, traced_wrapper = trace_with_kwargs(\n                        func.forward, *args, **kwargs)\n                    traced_module = ts_compiler(traced_module)\n                    cache[key] = (traced_module, traced_wrapper)\n                else:\n                    traced_module, traced_wrapper = trace_with_kwargs(\n                        func, *args, **kwargs)\n                    traced_module = ts_compiler(traced_module)\n                    cache[key] = (traced_module, traced_wrapper)\n            else:\n                traced_module, traced_wrapper = cache[key]\n\n        return traced_wrapper(traced_module)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        if not hasattr(wrapper, 'cache'):\n            wrapper.cache = {}\n        if not hasattr(wrapper, 'lock'):\n            wrapper.lock = threading.Lock()\n        with wrapper.lock:\n            key = (func, args, kwargs)\n            if key not in wrapper.cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, traced_wrapper = trace_with_kwargs(\n                        func.forward, args, kwargs, **kwargs_)\n                else:\n                    traced_module, traced_wrapper = trace_with_kwargs(\n                        func, args, kwargs, **kwargs_)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                    traced_wrapper = ts_compiler(traced_wrapper)\n                wrapper.cache[key] = (traced_module, traced_wrapper)\n            traced_module, traced_wrapper = wrapper.cache[key]\n        return traced_wrapper(traced_module)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m: m\n\n    def wrapper(*args, **kwargs):\n        # If the function is a module, we trace its forward method.\n        if isinstance(func, torch.nn.Module):\n            func = func.forward\n        # If the function is not a module, we trace it directly.\n        else:\n            func = func\n\n        # Get the signature of the function.\n        signature = inspect.signature(func)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n        # Get the list of parameters from the signature.\n        params = list(signature.parameters)\n       "}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        if ts_compiler is None:\n            ts_compiler = lambda m: m\n        if not hasattr(func, 'cached_traces'):\n            func.cached_traces = {}\n        with func.cached_traces.lock:\n            if func.cached_traces.get(args) is None:\n                func.cached_traces[args] = ts_compiler(\n                    trace_with_kwargs(func, *args, **kwargs)[0])\n            return func.cached_traces[args](*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if not hasattr(wrapper, '_cache'):\n            wrapper._cache = {}\n        if not hasattr(wrapper, '_lock'):\n            wrapper._lock = threading.Lock()\n\n        with wrapper._lock:\n            key = (args, tuple(sorted(kwargs.items())))\n            if key not in wrapper._cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, traced_module_wrapper = trace_with_kwargs(\n                        func, *args, **kwargs)\n                    if ts_compiler is not None:\n                        traced_module = ts_compiler(traced_module)\n                    wrapper._cache[key] = (traced_module, traced_module_wrapper)\n                else:\n                    traced_func = better_trace(func, *args, **kwargs)\n                    if ts_compiler is not None:\n                        traced_func = ts_compiler(traced_func)\n                    wrapper._cache[key] = traced_func\n            if isinstance(func, torch.nn.Module):\n                traced_module, traced_module_wrapper = wrapper._cache[key]\n                return traced_module_wrapper(traced_module)\n            else:\n                return wrapper._cache[key]\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # If a module is provided, wrap the forward method instead\n    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    # Create a lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Create a cache to store traced modules\n    cache = {}\n\n    def wrapper(*args, **kwargs):\n        # Get the unique key for the current arguments\n        key = (args, tuple(kwargs.items()))\n\n        # Acquire the lock to ensure thread safety\n        with lock:\n            # Check if the traced module for the current arguments is in the cache\n            if key not in cache:\n                # Trace the function with the given arguments and compiler\n                traced, wrap_traced = trace_with_kwargs(\n                    func, args, kwargs, **kwargs_)\n                # Apply the compiler if provided\n                if ts_compiler is not None:\n                    traced = ts_compiler(traced)\n                # Wrap the traced module with the given function\n                wrapped = wrap_traced(traced)\n                # Save the traced module and its wrapper in the cache\n                cache[key] = (traced, wrapped)\n\n            # Return the cached traced module and its wrapper\n            return cache[key]\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m: m\n\n    if not callable(func):\n        raise ValueError(\n            'The input must be a function or torch.nn.Module, but got {}.'.\n            format(type(func)))\n\n    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if not hasattr(wrapper, 'cache'):\n            wrapper.cache = {}\n        key = (func, args, frozenset(kwargs.items()))\n        if key not in wrapper.cache:\n            with wrapper.lock:\n                if key not in wrapper.cache:\n                    wrapper.cache[key] = ts_compiler(\n                        better_trace(TraceablePosArgOnlyModuleWrapper(func),\n                                     args, **kwargs_))\n        return wrapper.cache[key](*args, **kwargs)\n\n    wrapper.lock = threading.Lock()\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def _wrapper(*args, **kwargs):\n        if not hasattr(_wrapper, 'cache'):\n            _wrapper.cache = {}\n        if not hasattr(_wrapper, 'lock'):\n            _wrapper.lock = threading.Lock()\n        with _wrapper.lock:\n            if not hasattr(_wrapper, 'cache'):\n                _wrapper.cache = {}\n            if not hasattr(_wrapper, 'lock'):\n                _wrapper.lock = threading.Lock()\n            key = (func, ts_compiler, kwargs_)\n            if key not in _wrapper.cache:\n                _wrapper.cache[key] = trace_with_kwargs(\n                    func, *args, **kwargs, **kwargs_)[0]\n            return _wrapper.cache[key]\n\n    return _wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not callable(func):\n        raise TypeError(f\"Expected a function or torch.nn.Module, but got {type(func)}\")\n\n    def _wrapper(*args, **kwargs):\n        if not hasattr(func, 'cached_module'):\n            func.cached_module = {}\n        if not hasattr(func, 'cached_call_helper'):\n            func.cached_call_helper = {}\n        if not hasattr(func, 'cached_module_lock'):\n            func.cached_module_lock = threading.Lock()\n        if not hasattr(func, 'cached_call_helper_lock'):\n            func.cached_call_helper_lock = threading.Lock()\n\n        with func.cached_module_lock:\n            if not func.cached_module.get(id(args), None):\n                func.cached_module[id(args)] = trace_with_kwargs(\n                    func, args, kwargs, **kwargs_)[0]\n            if not func.cached_call_helper.get(id(args), None):\n                func.cached_call_helper[id(args)] = trace_with_kwargs(\n                    func, args, kwargs, **kwargs_)[1]\n        with func.cached_call_helper_lock:\n            return func.cached_call_helper[id(args)](\n                func.cached_module[id(args)])\n\n    return _wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m, **kwargs: m\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if not hasattr(wrapper, 'cache'):\n            wrapper.cache = {}\n\n        key = (args, tuple(sorted(kwargs.items())))\n        if key not in wrapper.cache:\n            with threading.Lock():\n                if key not in wrapper.cache:\n                    if isinstance(func, torch.nn.Module):\n                        traced_module, traced_wrapper = trace_with_kwargs(\n                            func, *args, **kwargs)\n                    else:\n                        traced_module, traced_wrapper = trace_with_kwargs(\n                            func, *args, **kwargs)\n                    wrapper.cache[key] = ts_compiler(traced_module, **kwargs_)\n        return wrapper.cache[key](*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Cache for traced modules\n    cache = {}\n\n    # Lock to ensure thread safety\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Get the original function or module's forward method\n        if isinstance(func, torch.nn.Module):\n            func = func.forward\n        # Get the unique identifier for the function or module's forward method\n        key = (func, id(func))\n        # Check if the function or module's forward method has already been traced\n        if key not in cache:\n            # If not, acquire the lock and check again\n            with lock:\n                if key not in cache:\n                    # If still not, trace the function or module's forward method\n                    traced_module, wrapper = trace_with_kwargs(\n                        func, *args, **kwargs, **kwargs_)\n                    # If a compiler is provided, compile the traced module or its call helper\n                    if ts_compiler is not None:\n                        traced_module = ts_compiler(traced_module)\n                        if hasattr(traced_module, 'call_helper'):\n                            traced_module.call_helper = ts_compiler(\n                                traced_module.call_helper)\n                    # Wrap the traced module with the original function or module's forward method\n                    traced_module = wrapper(traced_module)\n                    # Cache the traced module for future calls\n                    cache[key] = traced_module\n        # Return the cached traced module\n        return cache[key](*args, **kwargs)\n\n    # Return the wrapped function or module's forward method\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def _inner(*args, **kwargs):\n        # Wrap the original function or module's forward method\n        if not hasattr(func, 'forward'):\n            raise ValueError(\n                f'The given function {func} does not have a forward method.')\n        forward_method = func.forward\n\n        # Define a wrapper function that traces the original function or module's forward method\n        def _wrapper(*args, **kwargs):\n            # Check if the traced module is already cached\n            if not hasattr(forward_method, 'traced_module'):\n                forward_method.traced_module = None\n\n            # Check if the traced module is already cached\n            if forward_method.traced_module is None:\n                # Acquire a lock to ensure thread safety\n                with lock:\n                    # Check if the traced module is still not cached\n                    if forward_method.traced_module is None:\n                        # Trace the original function or module's forward method\n                        forward_method.traced_module = better_trace(\n                            forward_method, args, kwargs, **kwargs_)\n                        # Optionally compile the traced module or its call helper\n                        if ts_compiler is not None:\n                            forward_method.traced_module = ts_compiler(\n                                forward_method.traced_module)\n\n            # Return the cached traced module\n            return forward_method.traced_module(*args, **kwargs)\n\n        # Return the wrapped function\n        return _wrapper\n\n    # Create a lock for thread safety\n    lock = threading.Lock()\n    # Return the wrapped function\n    return _inner\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Use a lock to ensure thread safety when accessing or updating the cache of traced modules\n    lock = threading.Lock()\n\n    # Create a cache for traced modules\n    cached_traced_modules = {}\n\n    def lazy_trace_wrapper(*args, **kwargs):\n        \"\"\"\n        This is the wrapper function that is used to wrap the original function or module's forward method. It checks the cache for a traced version of the function or module, and if it is not found, it traces it and caches the result for future calls.\n\n        Input-Output Arguments\n        :param args: Tuple. The positional arguments passed to the original function or module's forward method.\n        :param kwargs: Dict. The keyword arguments passed to the original function or module's forward method.\n        :return: Any. The result of the original function or module's forward method.\n\n        Note: The function uses a lock to ensure thread safety when accessing or updating the cache of traced modules.\n        \"\"\"\n        # Use a lock to ensure thread safety when accessing or updating the cache of traced modules\n        with lock:\n            # Check if the original function or module is already traced and cached\n            if func in cached_traced_modules:\n                # If it is, use the cached version\n                traced_module = cached_traced_modules[func]\n            else:\n                # If it is not, trace it and cache the result\n                traced_module, _ = trace_with_kwargs(func, *args, **kwargs)\n                cached_traced_modules[func] = traced_module\n\n            # If a compiler function is provided, use it to further process the traced module\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module, *args, **kwargs)\n\n            # Return the result of the original function or module's forward method\n            return traced_module(*args, **kwargs)\n\n    return lazy_trace_wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        # Check if the function is a PyTorch module\n        if isinstance(func, torch.nn.Module):\n            # If it is a module, wrap the forward method instead of the entire module\n            func = func.forward\n        # Get the unique identifier for the function or module\n        key = id(func)\n        # Get the current thread identifier\n        thread_id = threading.get_ident()\n        # Get the cache of traced modules for the current thread\n        cache = _thread_local.cache.get(thread_id, {})\n        # Check if the function or module has already been traced for this thread\n        if key in cache:\n            # If it has, return the cached traced module\n            return cache[key]\n        # If it hasn't, create a lock to ensure thread safety\n        lock = _thread_local.lock.get(thread_id, threading.Lock())\n        # Acquire the lock\n        with lock:\n            # Check if the function or module has already been traced for this thread\n            if key in cache:\n                # If it has, return the cached traced module\n                return cache[key]\n            # If it hasn't, trace the function or module's forward method\n            traced = trace_with_kwargs(func, *args, **kwargs, **kwargs_)[0]\n            # Check if a compiler is provided\n            if ts_compiler is not None:\n                # If it is, compile the traced module or its call helper with additional arguments\n                traced = ts_compiler(traced, *args, **kwargs)\n            # Add the traced module to the cache for the current thread\n            cache[key] = traced\n            # Add the cache to the thread-local storage\n            _thread_local.cache[thread_id] = cache\n            # Add the lock to the thread-local storage\n            _thread_local.lock[thread_id] = lock\n        # Return the traced module\n        return traced\n\n    # Return the wrapped function or module\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Define the inner function that handles the tracing logic\n    def inner(*args, **kwargs):\n        # Acquire the lock\n        with lock:\n            # Check if the function is already traced\n            if not hasattr(func, 'traced'):\n                # Trace the function\n                func.traced = trace_with_kwargs(\n                    func, **kwargs_)[0].eval() if ts_compiler is None else ts_compiler(\n                        trace_with_kwargs(func, **kwargs_)[0])\n                # Set the original function as an attribute of the traced version\n                func.traced.original = func\n\n            # Check if the function is a module\n            if isinstance(func, torch.nn.Module):\n                # Set the original module as an attribute of the traced version\n                func.traced.original = func\n\n            # Check if the function is a module and has a forward method\n            if isinstance(func, torch.nn.Module) and hasattr(\n                    func, 'forward'):\n                # Set the original forward method as an attribute of the traced version\n                func.traced.original_forward = func.forward\n\n                # Define the wrapped forward method\n                def forward(*args, **kwargs):\n                    return func.traced(*args, **kwargs)\n\n                # Set the wrapped forward method as the new forward method\n                func.forward = forward\n\n            # Return the traced function\n            return func.traced(*args, **kwargs)\n\n    # Return the inner function that handles the tracing logic\n    return inner\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not callable(func):\n        raise ValueError(\n            f'Expected a callable, but got {type(func).__name__} instead.')\n    if ts_compiler is not None and not callable(ts_compiler):\n        raise ValueError(\n            f'Expected a callable, but got {type(ts_compiler).__name__} instead.'\n        )\n\n    # Create a lock to ensure thread safety when accessing or updating the cache of traced modules\n    lock = threading.Lock()\n\n    # Define a wrapper function that uses the cache of traced modules to optimize future calls\n    def wrapper(*args, **kwargs):\n        # Get the signature of the original function or module's forward method\n        sig = inspect.signature(func)\n\n        # Define a helper function that traces the function or module's forward method with optional compiler enhancements\n        def _trace(func, args, kwargs):\n            # Trace the function or module's forward method with optional compiler enhancements\n            traced_module, _ = trace_with_kwargs(func, args, kwargs)\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            return traced_module\n\n        # Define a helper function that wraps the original function or module's forward method with the traced version\n        def _wrap(func, traced_module):\n            # Wrap the original function or module's forward method with the traced version\n            def _forward(*args, **kwargs):\n                # Get the signature of the original function or module's forward method\n                sig = inspect.signature(func)\n\n                # Create a dictionary of keyword arguments from the provided arguments\n                kwargs = {\n                    k: v\n                    for k, v in zip(sig.parameters, args)\n                    if k not in kwargs\n                }\n\n                # Execute the traced module with the provided arguments\n                with torch.no_grad():\n                    return traced_module(*args, **kwargs)\n\n            # Return the wrapped function\n            return _forward\n\n        # Define a helper function that retrieves the traced version of the function or module's forward method from the cache\n        def _get_traced_module(func, args, kwargs):\n            # Get the signature of the original function or module's forward method\n            sig = inspect.signature(func)\n\n            # Create a dictionary of keyword arguments from the provided arguments\n            kwargs = {\n                k: v\n                for k, v in zip("}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not callable(func):\n        raise ValueError(f'func should be callable, but got {type(func)}')\n\n    def wrapper(*args, **kwargs):\n        if not hasattr(wrapper, 'cache'):\n            wrapper.cache = {}\n        if not hasattr(wrapper, 'lock'):\n            wrapper.lock = threading.Lock()\n\n        key = (args, tuple(sorted(kwargs.items())))\n        with wrapper.lock:\n            if key in wrapper.cache:\n                return wrapper.cache[key]\n\n            if isinstance(func, torch.nn.Module):\n                func = func.forward\n            traced_module, wrapper_func = trace_with_kwargs(func, args, kwargs,\n                                                            **kwargs_)\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            wrapper.cache[key] = wrapper_func(traced_module)\n            return wrapper.cache[key]\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    def wrapper(*args, **kwargs):\n        key = (args, tuple(sorted(kwargs.items())))\n        with lock:\n            if key not in cache:\n                cache[key] = trace_with_kwargs(\n                    func, args, kwargs, **kwargs_)[0]\n            traced_module = cache[key]\n        return ts_compiler(traced_module, **kwargs_) if ts_compiler else traced_module\n\n    return wrapper\n\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        # Extract the best configuration from the trial folder\n        best_config = extract_best_config(trial_path)\n\n        # Set the project directory to the parent directory of the trial folder\n        project_dir = os.path.dirname(trial_path)\n\n        # Initialize the Runner with the best configuration and project directory\n        return cls(best_config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        # Extract the best configuration from the trial folder\n        best_config = extract_best_config(trial_path)\n\n        # Set the project directory to the parent directory of the trial folder\n        project_dir = os.path.dirname(trial_path)\n\n        # Initialize the Runner with the best configuration and project directory\n        return cls(best_config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        best_config = extract_best_config(trial_path)\n        return cls(best_config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        # Load the best configuration from the trial folder\n        best_config = extract_best_config(trial_path)\n\n        # Set the project directory to the parent directory of the trial folder\n        project_dir = os.path.dirname(trial_path)\n\n        # Initialize the Runner with the best configuration and project directory\n        return cls(best_config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        best_config_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(best_config_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        with open(best_config_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_path = os.path.join(trial_path, 'config.yaml')\n        if not os.path.exists(config_path):\n            raise ValueError(f\"config.yaml does not exist in {trial_path}.\")\n        with open(config_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the output directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module names to use as filenames\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the output directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of module names\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module parameters\n    module_params_list = [module_params[i] for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i], module_params_list[i]) for i in range(len(modules))]\n\n    # Create a list of module names and parameters\n    module_names_params_list = [(module_names[i"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of module names\n    module_names = [module.__name__ for module in modules]\n\n    # Create a list of module parameters\n    module_params = module_params\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter combinations\n    combinations = [dict(zip(module_params, t)) for t in zip(*module_params.values())]\n\n    # Create a list of module parameter"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load the previous result into a DataFrame if it's a path\n    if isinstance(previous_result, str):\n        previous_result = pd.read_csv(previous_result)\n\n    # Create a directory for this node line if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a DataFrame to store the results of each module\n    results = pd.DataFrame()\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Add the module name and parameters to the result DataFrame\n        result[\"module_name\"] = module.__name__\n        result[\"module_params\"] = str(params)\n\n        # Append the result to the results DataFrame\n        results = results.append(result, ignore_index=True)\n\n    # Save the results to a CSV file\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Evaluate the results using the specified strategies\n    evaluation_results = evaluate_retrieval(results, previous_result, strategies)\n\n    # Save the evaluation results to a CSV file\n    evaluation_results.to_csv(os.path.join(node_line_dir, \"evaluation_results.csv\"), index=False)\n\n    # Select the best result using the specified strategies\n    best_result = select_best_average(evaluation_results, strategies)\n\n    # Save the best result to a CSV file\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Measure the speed of each module\n    speed_results = measure_speed(results, strategies)\n\n    # Save the speed results to a CSV file\n    speed_results.to_csv(os.path.join(node_line_dir, \"speed_results.csv\"), index=False)\n\n    # Filter the results by the specified speed threshold\n    filtered_results = filter_by_threshold(speed_results, strategies)\n\n    # Save the filtered results to a CSV file\n    filtered_results.to_csv(os.path.join(node_line_dir, \"filtered_results.csv\"), index=False"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    if not os.path.exists(node_line_dir):\n        pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    results = []\n    for i, module in enumerate(modules):\n        logger.info(f\"Running module {i + 1} of {len(modules)}\")\n        result = module(module_params[i], previous_result)\n        results.append(result)\n\n    # Evaluate results\n    logger.info(\"Evaluating results\")\n    evaluation_results = []\n    for i, result in enumerate(results):\n        logger.info(f\"Evaluating result {i + 1} of {len(results)}\")\n        evaluation_result = evaluate_retrieval(result, previous_result, strategies)\n        evaluation_results.append(evaluation_result)\n\n    # Measure speed\n    logger.info(\"Measuring speed\")\n    speed_results = []\n    for i, result in enumerate(results):\n        logger.info(f\"Measuring speed for result {i + 1} of {len(results)}\")\n        speed_result = measure_speed(result, strategies)\n        speed_results.append(speed_result)\n\n    # Combine results\n    logger.info(\"Combining results\")\n    combined_results = []\n    for i, result in enumerate(results):\n        logger.info(f\"Combining result {i + 1} of {len(results)}\")\n        combined_result = pd.concat([result, evaluation_results[i], speed_results[i]], axis=1)\n        combined_results.append(combined_result)\n\n    # Filter by speed threshold\n    logger.info(\"Filtering by speed threshold\")\n    filtered_results = []\n    for i, combined_result in enumerate(combined_results):\n        logger.info(f\"Filtering result {i + 1} of {len(combined_results)}\")\n        filtered_result = filter_by_threshold(combined_result, strategies)\n        filtered_results.append(filtered_result)\n\n    # Select best average\n    logger.info(\"Selecting best average\")\n    best_average_result = select_best_average(filtered_results, strategies)\n\n    # Combine with previous result\n    logger.info(\"Combining with previous result\")\n    best_result = pd.concat([previous_result, best_average"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create a directory for the node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run each module with the corresponding parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # measure the execution times for each module\n    times = measure_speed(results)\n\n    # apply strategies to select the best module\n    selected_result = select_best_average(results, times, strategies)\n\n    # evaluate the selected module\n    metrics = evaluate_retrieval(selected_result, previous_result, strategies['metrics'])\n\n    # save the results and a summary of the execution times and evaluation metrics\n    selected_result.to_csv(os.path.join(node_line_dir, 'result.csv'), index=False)\n    times.to_csv(os.path.join(node_line_dir, 'times.csv'), index=False)\n    metrics.to_csv(os.path.join(node_line_dir, 'metrics.csv'), index=False)\n\n    # combine the previous result columns with the selected module's result columns\n    best_result = pd.concat([previous_result, selected_result], axis=1)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(f\"Running retrieval node in {node_line_dir}\")\n\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Save the previous result to disk\n    previous_result.to_csv(os.path.join(node_line_dir, \"previous_result.csv\"), index=False)\n\n    # Run the retrieval modules and measure their execution times\n    results = []\n    times = []\n    for module, params in zip(modules, module_params):\n        result, time = measure_speed(module, params, previous_result)\n        results.append(result)\n        times.append(time)\n\n    # Save the results and times to disk\n    for i, result in enumerate(results):\n        result.to_csv(os.path.join(node_line_dir, f\"result_{i}.csv\"), index=False)\n    with open(os.path.join(node_line_dir, \"times.txt\"), \"w\") as f:\n        for time in times:\n            f.write(f\"{time}\\n\")\n\n    # Evaluate the results using the specified metrics\n    metrics = strategies[\"metrics\"]\n    evaluations = [evaluate_retrieval(result, previous_result, metrics) for result in results]\n\n    # Save the evaluations to disk\n    for i, evaluation in enumerate(evaluations):\n        evaluation.to_csv(os.path.join(node_line_dir, f\"evaluation_{i}.csv\"), index=False)\n\n    # Select the best result based on the specified strategies\n    best_index = select_best_average(evaluations, strategies)\n    best_result = results[best_index]\n\n    # Save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Combine the previous result columns with the best result columns\n    combined_result = pd.concat([previous_result, best_result], axis=1)\n\n    # Save the combined result to disk\n    combined_result.to_csv(os.path.join(node_line_dir, \"combined_result.csv\"), index=False)\n\n    # Save the summary of the execution times and evaluation metrics to disk\n    summary = {"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the output directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty DataFrame to store the results\n    results = pd.DataFrame()\n\n    # Initialize an empty DataFrame to store the evaluation metrics\n    evaluation_metrics = pd.DataFrame()\n\n    # Initialize an empty DataFrame to store the execution times\n    execution_times = pd.DataFrame()\n\n    # Iterate over the modules and module parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name from the function name\n        module_name = module.__name__\n\n        # Get the module directory path\n        module_dir = os.path.join(node_line_dir, module_name)\n\n        # Create the module directory if it does not exist\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module with the given parameters\n        result = module(params)\n\n        # Evaluate the result using the specified strategies\n        evaluation_metric = evaluate_retrieval(result, previous_result, strategies)\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, params)\n\n        # Append the result to the results DataFrame\n        results = results.append(result, ignore_index=True)\n\n        # Append the evaluation metric to the evaluation_metrics DataFrame\n        evaluation_metrics = evaluation_metrics.append(evaluation_metric, ignore_index=True)\n\n        # Append the execution time to the execution_times DataFrame\n        execution_times = execution_times.append(execution_time, ignore_index=True)\n\n    # Filter the results by the specified strategies\n    filtered_results = filter_by_threshold(results, evaluation_metrics, strategies)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(filtered_results, evaluation_metrics, strategies)\n\n    # Save the results to disk\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    evaluation_metrics.to_csv(os.path.join(node_line_dir, \"evaluation_metrics.csv\"), index=False)\n    execution_times.to_csv(os.path.join(node_line_dir, \"execution_times"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create a directory for this node line if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize a DataFrame to store the results of each module\n    module_results = pd.DataFrame()\n\n    # Iterate over the modules and module parameters\n    for module, params in zip(modules, module_params):\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Save the result to disk\n        result_path = os.path.join(node_line_dir, f\"{module.__name__}_result.csv\")\n        result.to_csv(result_path, index=False)\n\n        # Add the result to the module_results DataFrame\n        module_results = module_results.append(result)\n\n    # Evaluate the module results\n    evaluation_result = evaluate_retrieval(module_results, previous_result, strategies[\"metrics\"])\n\n    # Save the evaluation result to disk\n    evaluation_result_path = os.path.join(node_line_dir, \"evaluation_result.csv\")\n    evaluation_result.to_csv(evaluation_result_path, index=False)\n\n    # Measure the execution time for each module\n    speed_result = measure_speed(module_results, strategies[\"speed_threshold\"])\n\n    # Save the speed result to disk\n    speed_result_path = os.path.join(node_line_dir, \"speed_result.csv\")\n    speed_result.to_csv(speed_result_path, index=False)\n\n    # Filter the module results based on the speed threshold\n    filtered_result = filter_by_threshold(module_results, speed_result, strategies[\"speed_threshold\"])\n\n    # Save the filtered result to disk\n    filtered_result_path = os.path.join(node_line_dir, \"filtered_result.csv\")\n    filtered_result.to_csv(filtered_result_path, index=False)\n\n    # Select the best module result based on the evaluation metrics and speed threshold\n    best_result = select_best_average(filtered_result, evaluation_result, strategies[\"metrics\"])\n\n    # Save the best result to disk\n    best_result_path = os.path.join(node_line_dir, \"best_result.csv\")\n    best_result.to"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Check if the node line directory exists, and create it if it does not.\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize an empty list to store the results of each module.\n    results = []\n\n    # For each module and its corresponding parameters, run the module and evaluate its performance.\n    for module, params in zip(modules, module_params):\n        # Run the module with the given parameters.\n        module_result = module(**params)\n\n        # Evaluate the module's performance using the given strategies.\n        evaluation_result = evaluate_retrieval(module_result, previous_result, strategies)\n\n        # Add the module's result to the list of results.\n        results.append(evaluation_result)\n\n    # Create a DataFrame from the list of results.\n    results_df = pd.DataFrame(results)\n\n    # Save the results DataFrame to disk.\n    results_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Measure the speed of each module.\n    speed_result = measure_speed(results_df, strategies)\n\n    # Save the speed results to disk.\n    speed_result.to_csv(os.path.join(node_line_dir, \"speed.csv\"), index=False)\n\n    # Filter the results based on the speed threshold.\n    filtered_results = filter_by_threshold(results_df, speed_result, strategies)\n\n    # Save the filtered results to disk.\n    filtered_results.to_csv(os.path.join(node_line_dir, \"filtered_results.csv\"), index=False)\n\n    # Select the best module based on the evaluation metrics.\n    best_result = select_best_average(filtered_results, strategies)\n\n    # Save the best result to disk.\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Return the best result.\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load the previous result\n    previous_result = previous_result.copy()\n\n    # Create a directory for this node line\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Run each module with its parameters\n    results = []\n    for module, module_param in zip(modules, module_params):\n        logger.info(f\"Running module {module.__name__} with parameters {module_param}\")\n        result = module(**module_param)\n        results.append(result)\n\n    # Measure the execution times for each module\n    speeds = measure_speed(results)\n\n    # Apply strategies to select the best module\n    best_module = select_best_average(results, speeds, strategies)\n\n    # Evaluate the best module\n    best_module_result = best_module.result\n    best_module_result = evaluate_retrieval(best_module_result, previous_result, strategies)\n\n    # Save the best module result to disk\n    best_module_result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n\n    # Save the summary of the execution times and evaluation metrics to disk\n    summary = {\n        \"modules\": [m.__name__ for m in modules],\n        \"speeds\": speeds,\n        \"metrics\": best_module_result.columns.tolist(),\n    }\n    summary_file = os.path.join(node_line_dir, \"summary.json\")\n    logger.info(f\"Saving summary to {summary_file}\")\n    with open(summary_file, \"w\") as f:\n        f.write(str(summary))\n\n    # Combine the previous result columns with the selected retrieval node's result columns\n    best_module_result = pd.concat([previous_result, best_module_result], axis=1)\n\n    return best_module_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Running retrieval node\")\n    logger.debug(f\"Node line dir: {node_line_dir}\")\n    logger.debug(f\"Modules: {modules}\")\n    logger.debug(f\"Module params: {module_params}\")\n    logger.debug(f\"Previous result: {previous_result}\")\n    logger.debug(f\"Strategies: {strategies}\")\n\n    # Create the node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty list to store the results\n    results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Measure the execution time of the module\n        start_time = time.time()\n        module(**params)\n        end_time = time.time()\n        execution_time = end_time - start_time\n\n        # Add the execution time to the result\n        result[\"execution_time\"] = execution_time\n\n        # Add the result to the list of results\n        results.append(result)\n\n    # Convert the list of results to a DataFrame\n    results_df = pd.DataFrame(results)\n\n    # Save the results to disk\n    results_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Evaluate the results using the given strategies\n    evaluation_metrics = evaluate_retrieval(results_df, previous_result, strategies)\n\n    # Save the evaluation metrics to disk\n    evaluation_metrics.to_csv(os.path.join(node_line_dir, \"evaluation_metrics.csv\"), index=False)\n\n    # Measure the speed of each module\n    speed_metrics = measure_speed(results_df, strategies)\n\n    # Save the speed metrics to disk\n    speed_metrics.to_csv(os.path.join(node_line_dir, \"speed_metrics.csv\"), index=False)\n\n    # Select the best result based on the given strategies\n    best_result = select_best_average(results_df, strategies)\n\n    # Save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \""}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run each module with given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with params: {params}\")\n        result = module(**params)\n        results.append(result)\n\n    # Evaluate each module's result\n    for result in results:\n        evaluate_retrieval(result, previous_result, strategies[\"metrics\"])\n\n    # Measure the execution time for each module\n    speeds = measure_speed(results)\n\n    # Apply strategies to select the best module\n    selected_result = select_best_average(results, speeds, strategies[\"speed_threshold\"])\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    for result in results:\n        result.to_csv(os.path.join(node_line_dir, f\"{result.name}.csv\"), index=False)\n    speeds.to_csv(os.path.join(node_line_dir, \"speeds.csv\"), index=False)\n\n    # Save the summary of the evaluation metrics to disk\n    summary = load_summary_file(node_line_dir)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Combine the previous result columns with the selected retrieval node's result columns\n    best_result = previous_result.copy()\n    for col in selected_result.columns:\n        if col not in previous_result.columns:\n            best_result[col] = selected_result[col]\n\n    # Save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Running retrieval node...\")\n\n    # Evaluate each module\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(params, previous_result)\n        results.append(result)\n\n    # Save results\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    for i, result in enumerate(results):\n        result.to_csv(node_line_dir / f\"result_{i}.csv\", index=False)\n\n    # Evaluate results\n    results_eval = []\n    for result in results:\n        results_eval.append(evaluate_retrieval(result, previous_result))\n\n    # Save evaluation results\n    for i, result_eval in enumerate(results_eval):\n        result_eval.to_csv(node_line_dir / f\"result_eval_{i}.csv\", index=False)\n\n    # Measure speed\n    speeds = measure_speed(results)\n\n    # Save speed results\n    speeds.to_csv(node_line_dir / \"speed.csv\", index=False)\n\n    # Select best result\n    best_result = select_best_average(results_eval, strategies, speeds)\n    best_result = pd.concat([previous_result, best_result], axis=1)\n\n    # Save best result\n    best_result.to_csv(node_line_dir / \"best_result.csv\", index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load previous result\n    previous_result = pd.read_csv(previous_result)\n\n    # Run each module with given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(**params)\n        results.append(result)\n\n    # Measure execution times\n    times = measure_speed(results)\n\n    # Evaluate each result\n    evaluations = evaluate_retrieval(results, previous_result)\n\n    # Save results and times to disk\n    os.makedirs(node_line_dir, exist_ok=True)\n    for result in results:\n        result.to_csv(os.path.join(node_line_dir, f\"{result.name}.csv\"))\n    pd.DataFrame(times).to_csv(os.path.join(node_line_dir, \"times.csv\"))\n\n    # Filter results by speed threshold\n    if \"speed\" in strategies:\n        results, times = filter_by_threshold(results, times, strategies[\"speed\"])\n\n    # Evaluate each result again after filtering\n    evaluations = evaluate_retrieval(results, previous_result)\n\n    # Save filtered results and times to disk\n    for result in results:\n        result.to_csv(os.path.join(node_line_dir, f\"{result.name}_filtered.csv\"))\n    pd.DataFrame(times).to_csv(os.path.join(node_line_dir, \"times_filtered.csv\"))\n\n    # Select best result\n    best_result = select_best_average(results, evaluations, strategies[\"metrics\"])\n\n    # Save best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"))\n\n    # Save summary of execution times and evaluation metrics to disk\n    summary = {\n        \"times\": times,\n        \"evaluations\": evaluations,\n    }\n    summary_file = os.path.join(node_line_dir, \"summary.json\")\n    load_summary_file(summary_file, summary)\n\n    # Combine the previous result columns with the selected retrieval node's result columns\n    best_result = pd.concat([previous_result, best_result], axis=1)\n\n    # Save the combined result to disk\n    best_result.to_csv(os.path.join(node_line"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the results dataframe\n    results = pd.DataFrame()\n\n    # Iterate through the modules and module params\n    for module, module_param in zip(modules, module_params):\n\n        # Run the module with the given parameters\n        result = module(module_param)\n\n        # Evaluate the retrieval results\n        evaluate_retrieval(result, previous_result)\n\n        # Save the result to disk\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n        # Append the result to the results dataframe\n        results = results.append(result)\n\n    # Measure the speed of each module\n    speeds = measure_speed(results)\n\n    # Save the speeds to disk\n    speeds.to_csv(os.path.join(node_line_dir, \"speeds.csv\"), index=False)\n\n    # Filter the results by speed threshold\n    if \"speed_threshold\" in strategies:\n        results = filter_by_threshold(results, speeds, strategies[\"speed_threshold\"])\n\n    # Select the best result based on the evaluation metrics\n    best_result = select_best_average(results, strategies[\"metrics\"])\n\n    # Save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Return the best result\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Running retrieval node\")\n\n    # Run each module with given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(**params)\n        results.append(result)\n\n    # Save each module's results to disk\n    for module, result in zip(modules, results):\n        module_name = module.__name__\n        result.to_csv(os.path.join(node_line_dir, f\"{module_name}_results.csv\"), index=False)\n\n    # Measure execution times\n    execution_times = measure_speed(modules, module_params)\n\n    # Evaluate each module's results\n    evaluation_results = []\n    for module, result in zip(modules, results):\n        module_name = module.__name__\n        evaluation_result = evaluate_retrieval(result, previous_result, strategies[\"metrics\"])\n        evaluation_result.to_csv(os.path.join(node_line_dir, f\"{module_name}_evaluation_results.csv\"), index=False)\n        evaluation_results.append(evaluation_result)\n\n    # Select the best module result\n    best_module_result = select_best_average(results, evaluation_results, strategies[\"metrics\"])\n    best_module_name = best_module_result.__name__\n    logger.info(f\"Selected best module: {best_module_name}\")\n\n    # Save execution times and evaluation results to disk\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"module\", \"time\"])\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n    for module, evaluation_result in zip(modules, evaluation_results):\n        module_name = module.__name__\n        evaluation_result.to_csv(os.path.join(node_line_dir, f\"{module_name}_evaluation_results.csv\"), index=False)\n\n    # Filter by speed thresholds\n    if \"speed_thresholds\" in strategies:\n        filtered_results = filter_by_threshold(results, execution_times, strategies[\"speed_thresholds\"])\n    else:\n        filtered_results = results\n\n    # Evaluate each filtered module's results\n    filtered_evaluation_results = []\n    for module, result in zip(modules"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Check if the node_line_dir directory exists\n    if not os.path.isdir(node_line_dir):\n        # If not, create the directory\n        os.makedirs(node_line_dir)\n\n    # Initialize an empty list to store the results of each module\n    results = []\n\n    # Iterate over the modules and module_params\n    for module, module_param in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__\n\n        # Get the module_param name\n        module_param_name = module_param[\"name\"]\n\n        # Get the module_param directory\n        module_param_dir = os.path.join(node_line_dir, module_name, module_param_name)\n\n        # If the module_param_dir does not exist, create it\n        if not os.path.isdir(module_param_dir):\n            os.makedirs(module_param_dir)\n\n        # Get the module_param result file path\n        module_param_result_file_path = os.path.join(module_param_dir, \"result.csv\")\n\n        # If the module_param result file does not exist, run the module\n        if not os.path.isfile(module_param_result_file_path):\n            # Run the module with the given parameters\n            module_param_result = module(module_param)\n\n            # Save the result to the result file path\n            module_param_result.to_csv(module_param_result_file_path, index=False)\n        else:\n            # If the module_param result file already exists, load it\n            module_param_result = pd.read_csv(module_param_result_file_path)\n\n        # Add the module_param result to the results list\n        results.append(module_param_result)\n\n    # Create a DataFrame from the results list\n    results_df = pd.concat(results)\n\n    # Get the metrics to evaluate\n    metrics = strategies[\"metrics\"]\n\n    # Evaluate the results using the metrics\n    results_df = evaluate_retrieval(results_df, metrics)\n\n    # Get the speed threshold\n    speed_threshold = strategies[\"speed_threshold\"]\n\n    # Measure the speed of each module\n    speed_df = measure_speed(results_df, speed_threshold)\n\n    # Filter the"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create a directory to save the results\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # initialize the results list\n    results = []\n\n    # loop over each module and its parameters\n    for module, module_param in zip(modules, module_params):\n        # run the module with the given parameters\n        module_result = module(**module_param)\n\n        # measure the speed of the module\n        speed = measure_speed(module_result, module_param)\n\n        # evaluate the module's result using the strategies\n        module_result, metrics = evaluate_retrieval(module_result, previous_result, strategies)\n\n        # save the module's result and metrics to disk\n        module_result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n        with open(os.path.join(node_line_dir, f\"{module.__name__}.txt\"), \"w\") as f:\n            f.write(str(metrics))\n\n        # append the module's result, metrics, and speed to the results list\n        results.append((module_result, metrics, speed))\n\n    # filter the results based on the speed threshold\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # select the best result based on the average of the evaluation metrics\n    best_result = select_best_average(results)\n\n    # combine the best result with the previous result\n    if previous_result is not None:\n        best_result = pd.concat([previous_result, best_result], axis=1)\n\n    # save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # save the summary of the results to disk\n    with open(os.path.join(node_line_dir, \"summary.txt\"), \"w\") as f:\n        for module_result, metrics, speed in results:\n            f.write(f\"{module_result.__name__}: {metrics}\\n\")\n        f.write(f\"Best result: {best_result.__name__}\\n\")\n        f.write(f\"Speed: {speed}\\n\")\n\n    # return the best result\n    return"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with {params}\")\n        module_result = module(**params)\n        results.append(module_result)\n\n    logger.info(\"Evaluating retrieval results\")\n    for i, result in enumerate(results):\n        logger.info(f\"Evaluating result {i}\")\n        evaluate_retrieval(result, previous_result)\n\n    # Measure speed\n    logger.info(\"Measuring speed\")\n    speeds = measure_speed(results)\n\n    # Filter by speed threshold\n    logger.info(\"Filtering by speed threshold\")\n    speed_threshold = strategies.get(\"speed_threshold\", None)\n    if speed_threshold:\n        results = filter_by_threshold(results, speeds, speed_threshold)\n        speeds = {k: v for k, v in speeds.items() if k in results}\n\n    # Select best average\n    logger.info(\"Selecting best average\")\n    best_index = select_best_average(results, strategies)\n\n    # Save results\n    logger.info(\"Saving results\")\n    for i, result in enumerate(results):\n        result.to_csv(os.path.join(node_line_dir, f\"result_{i}.csv\"))\n\n    # Save summary\n    logger.info(\"Saving summary\")\n    summary_path = os.path.join(node_line_dir, \"summary.csv\")\n    summary = {\"speed\": speeds, \"best_index\": best_index}\n    pd.DataFrame(summary).to_csv(summary_path)\n\n    # Load best result\n    logger.info(\"Loading best result\")\n    best_result = results[best_index]\n    best_result = best_result.join(previous_result, how=\"outer\")\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Define the output directory for the query expansion node results\n    node_line_dir = os.path.join(node_line_dir, 'query_expansion')\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node summary\n    summary_dir = os.path.join(node_line_dir, 'summary')\n    pathlib.Path(summary_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node results\n    result_dir = os.path.join(node_line_dir, 'results')\n    pathlib.Path(result_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node best result\n    best_result_dir = os.path.join(node_line_dir, 'best_result')\n    pathlib.Path(best_result_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node best result\n    best_result_dir = os.path.join(node_line_dir, 'best_result')\n    pathlib.Path(best_result_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node best result\n    best_result_dir = os.path.join(node_line_dir, 'best_result')\n    pathlib.Path(best_result_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node best result\n    best_result_dir = os.path.join(node_line_dir, 'best_result')\n    pathlib.Path(best_result_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node best result\n    best_result_dir = os.path.join(node_line_dir, 'best_result')\n    pathlib.Path(best_result_dir).mkdir(parents=True, exist_ok=True)\n\n    # Define the output directory for the query expansion node best result\n    best_result_dir = os.path.join(node_line_dir, 'best_"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory to save the results\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create a dataframe to store the results\n    results = pd.DataFrame()\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Run the module with the given parameters\n        result = module(previous_result, **params)\n\n        # Save the result to a file\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n        # Append the result to the results dataframe\n        results = results.append(result, ignore_index=True)\n\n    # Save the results dataframe to a file\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Evaluate the results based on the specified strategies\n    evaluations = evaluate_retrieval_node(results, strategies)\n\n    # Save the evaluation results to a file\n    evaluations.to_csv(os.path.join(node_line_dir, \"evaluations.csv\"), index=False)\n\n    # Select the best result based on the evaluation\n    best_result = select_best_average(evaluations)\n\n    # Save the best result to a file\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Return the best result\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(\"Running query expansion node...\")\n\n    # Define the directory where the results and summaries will be saved\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n\n    # Create the directory if it doesn't exist\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Define the path where the results will be saved\n    results_path = os.path.join(node_line_dir, \"results.csv\")\n\n    # Define the path where the summary will be saved\n    summary_path = os.path.join(node_line_dir, \"summary.csv\")\n\n    # Define the path where the best result will be saved\n    best_path = os.path.join(node_line_dir, \"best.csv\")\n\n    # Define the path where the best result's previous results will be saved\n    best_previous_path = os.path.join(node_line_dir, \"best_previous.csv\")\n\n    # Define the path where the best result's next results will be saved\n    best_next_path = os.path.join(node_line_dir, \"best_next.csv\")\n\n    # Define the path where the best result's next results will be saved\n    best_next_previous_path = os.path.join(node_line_dir, \"best_next_previous.csv\")\n\n    # Define the path where the best result's next results will be saved\n    best_next_next_path = os.path.join(node_line_dir, \"best_next_next.csv\")\n\n    # Define the path where the best result's next results will be saved\n    best_next_next_previous_path = os.path.join(node_line_dir, \"best_next_next_previous.csv\")\n\n    # Define the path where the best result's next results will be saved\n    best_next_next_next_path = os.path.join(node_line_dir, \"best_next_next_next.csv\")\n\n    # Define the path where the best result's next results will be saved\n    best_next_next_next_previous_path = os.path.join(node_line_dir, \"best_next_next_next_previous.csv\")\n\n    #"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Check if the node_line_dir directory exists. If not, create it.\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize a list to store the results of each module.\n    results = []\n\n    # Iterate over each module and its corresponding parameters.\n    for module, params in zip(modules, module_params):\n\n        # Initialize a dictionary to store the results of the current module.\n        result = {}\n\n        # Run the module with the current parameters and save the result to the results list.\n        result[\"result\"] = module(previous_result, **params)\n\n        # Save the module name and parameters to the results dictionary.\n        result[\"module\"] = module.__name__\n        result[\"params\"] = params\n\n        # Append the results dictionary to the results list.\n        results.append(result)\n\n    # Initialize a list to store the execution times of each module.\n    execution_times = []\n\n    # Iterate over each module and its corresponding parameters.\n    for module, params in zip(modules, module_params):\n\n        # Initialize a dictionary to store the execution time of the current module.\n        execution_time = {}\n\n        # Measure the execution time of the module with the current parameters.\n        execution_time[\"execution_time\"] = measure_speed(module, previous_result, **params)\n\n        # Save the module name and parameters to the execution time dictionary.\n        execution_time[\"module\"] = module.__name__\n        execution_time[\"params\"] = params\n\n        # Append the execution time dictionary to the execution times list.\n        execution_times.append(execution_time)\n\n    # Convert the execution times list to a pandas DataFrame.\n    execution_times_df = pd.DataFrame(execution_times)\n\n    # Save the execution times DataFrame to a CSV file.\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n\n    # Convert the results list to a pandas DataFrame.\n    results_df = pd.DataFrame(results)\n\n    # Save the results DataFrame to a CSV file.\n    results_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Initialize a list to store the evaluation results of each module.\n    evaluation"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize the results dictionary\n    results = {}\n\n    # Loop over modules and module_params\n    for module, module_param in zip(modules, module_params):\n\n        # Initialize the module_results dictionary\n        module_results = {}\n\n        # Loop over the module_param\n        for param in module_param:\n\n            # Initialize the module_result dictionary\n            module_result = {}\n\n            # Initialize the module_name\n            module_name = module.__name__\n\n            # Initialize the param_name\n            param_name = str(param)\n\n            # Initialize the module_param_name\n            module_param_name = module_name + \"_\" + param_name\n\n            # Initialize the node_line_dir_module_param_name\n            node_line_dir_module_param_name = os.path.join(node_line_dir, module_param_name)\n\n            # Initialize the node_line_dir_module_param_name_results\n            node_line_dir_module_param_name_results = os.path.join(node_line_dir_module_param_name, \"results\")\n\n            # Initialize the node_line_dir_module_param_name_summary\n            node_line_dir_module_param_name_summary = os.path.join(node_line_dir_module_param_name, \"summary\")\n\n            # Initialize the node_line_dir_module_param_name_best\n            node_line_dir_module_param_name_best = os.path.join(node_line_dir_module_param_name, \"best\")\n\n            # Initialize the node_line_dir_module_param_name_best_summary\n            node_line_dir_module_param_name_best_summary = os.path.join(node_line_dir_module_param_name_best, \"summary\")\n\n            # Initialize the node_line_dir_module_param_name_best_results\n            node_line_dir_module_param_name_best_results = os.path.join(node_line_dir_module_param_name_best, \"results\")\n\n            # Initialize the node_line_dir_module_param_name_best_summary_csv\n            node_line_dir_module_param_name_best_summary_csv = os"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Check if the directory exists\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a dataframe to store the results\n    results = pd.DataFrame()\n\n    # Iterate over each module and its corresponding parameters\n    for module, params in zip(modules, module_params):\n\n        # Create a new directory for the module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        # Iterate over each parameter combination\n        for param in make_combinations(params):\n\n            # Create a new directory for the parameter combination\n            param_dir = os.path.join(module_dir, \"_\".join(f\"{k}_{v}\" for k, v in param.items()))\n            if not os.path.exists(param_dir):\n                os.makedirs(param_dir)\n\n            # Run the module with the current parameter combination\n            logger.info(f\"Running module {module.__name__} with parameters {param}\")\n            result = module(previous_result, **param)\n\n            # Save the result to the directory\n            result.to_csv(os.path.join(param_dir, \"result.csv\"), index=False)\n\n            # Measure the speed of the module\n            speed = measure_speed(module, previous_result, **param)\n\n            # Save the speed to the directory\n            with open(os.path.join(param_dir, \"speed.txt\"), \"w\") as f:\n                f.write(str(speed))\n\n            # Evaluate the module based on the specified strategies\n            evaluation = evaluate_retrieval_node(result, strategies)\n\n            # Save the evaluation to the directory\n            evaluation.to_csv(os.path.join(param_dir, \"evaluation.csv\"), index=False)\n\n            # Add the result to the dataframe\n            results = results.append({\n                \"module\": module.__name__,\n                \"param\": param,\n                \"speed\": speed,\n                \"evaluation\": evaluation\n            }, ignore_index=True)\n\n    # Save the results to the directory\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Filter the results based on"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize the results and summary dataframes\n    results = pd.DataFrame()\n    summary = pd.DataFrame()\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Create a temporary directory for the module\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Evaluate the module\n        module_results, module_summary = evaluate_query_expansion_node(module, params, previous_result, module_dir)\n\n        # Append the module results and summary to the overall results and summary\n        results = results.append(module_results)\n        summary = summary.append(module_summary)\n\n    # Save the results and summary to the node line directory\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Select the best module based on the evaluation strategies\n    best_module = select_best_query_expansion_module(summary, strategies)\n\n    # Get the best module name\n    best_module_name = best_module[\"module\"]\n\n    # Filter the results to only include the best module\n    best_results = results[results[\"module\"] == best_module_name]\n\n    # Save the best results to the node line directory\n    best_results.to_csv(os.path.join(node_line_dir, \"best_results.csv\"), index=False)\n\n    # Return the best results\n    return best_results\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory for the node results if it doesn't exist\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Initialize the list to store the results of each module\n    module_results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Initialize a list to store the results of each parameter combination\n        param_results = []\n\n        # Loop through each parameter combination\n        for param in make_combinations(params):\n\n            # Run the module with the current parameter combination\n            result = module(previous_result, **param)\n\n            # Save the result to a CSV file\n            result.to_csv(f\"{node_line_dir}/{module.__name__}_{param}.csv\", index=False)\n\n            # Append the result to the list of parameter results\n            param_results.append(result)\n\n        # Combine the results of all parameter combinations into a single dataframe\n        combined_result = pd.concat(param_results)\n\n        # Append the combined result to the list of module results\n        module_results.append(combined_result)\n\n    # Combine the results of all modules into a single dataframe\n    combined_result = pd.concat(module_results)\n\n    # Save the combined result to a CSV file\n    combined_result.to_csv(f\"{node_line_dir}/combined_results.csv\", index=False)\n\n    # Measure the execution time of each module\n    module_times = measure_speed(module_results)\n\n    # Save the execution times to a CSV file\n    pd.DataFrame(module_times, columns=[\"module\", \"time\"]).to_csv(f\"{node_line_dir}/module_times.csv\", index=False)\n\n    # Evaluate the performance of each module based on the specified strategies\n    module_scores = evaluate_retrieval_node(module_results, strategies)\n\n    # Save the evaluation scores to a CSV file\n    pd.DataFrame(module_scores, columns=[\"module\", \"score\"]).to_csv(f\"{node_line_dir}/module_scores.csv\", index=False)\n\n    # Select the best module based on the evaluation scores\n    best_module = select_best_average(module_scores)\n\n    # Save the best module to a CSV file\n    pd.DataFrame(best_module, columns=[\"module\", \"score\"])."}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Check if the node_line_dir directory exists, and create it if it does not exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize empty lists to store the results and summaries\n    results = []\n    summaries = []\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Run the module with the given parameters\n        result = module(previous_result, **params)\n\n        # Measure the speed of the module\n        speed = measure_speed(module, previous_result, **params)\n\n        # Evaluate the performance of the module based on the specified strategies\n        summary = evaluate_retrieval_node(result, strategies)\n\n        # Add the speed and evaluation results to the summary\n        summary[\"speed\"] = speed\n\n        # Save the result and summary to the specified directory\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n        summary.to_csv(os.path.join(node_line_dir, f\"{module.__name__}_summary.csv\"), index=False)\n\n        # Append the result and summary to the lists\n        results.append(result)\n        summaries.append(summary)\n\n    # Combine the results and summaries into a single DataFrame\n    results = pd.concat(results)\n    summaries = pd.concat(summaries)\n\n    # Filter the summaries based on the speed threshold\n    summaries = filter_by_threshold(summaries, \"speed\", strategies[\"speed_threshold\"])\n\n    # Select the best result based on the evaluation metrics\n    best_result = select_best_average(summaries, strategies[\"metrics\"])\n\n    # Save the best result to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Return the best result\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(\"Running query expansion node...\")\n\n    # Create the output directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the support module params\n    support_module_params = [{}] * len(support_modules)\n\n    # Combine the modules and module params\n    combined_modules = modules + support_modules\n    combined_module_params = module_params + support_module_params\n\n    # Run the query expansion node for each module\n    results = []\n    for module, module_param in zip(combined_modules, combined_module_params):\n        logger.info(f\"Running query expansion node for module {module.__name__}...\")\n        result = run_query_expansion_node_for_module(module, module_param, previous_result, node_line_dir)\n        results.append(result)\n\n    # Combine the results\n    combined_results = pd.concat(results)\n\n    # Save the combined results\n    combined_results.to_csv(os.path.join(node_line_dir, \"combined_results.csv\"), index=False)\n\n    # Evaluate the results\n    evaluated_results = evaluate_query_expansion_node(combined_results, strategies)\n\n    # Save the evaluated results\n    evaluated_results.to_csv(os.path.join(node_line_dir, \"evaluated_results.csv\"), index=False)\n\n    # Select the best result based on the evaluation\n    best_result = select_best_query_expansion_node(evaluated_results, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    logger.info(\"Finished running query expansion node.\")\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run each module with given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        logger.info(f\"Running {module_name} with parameters {params}\")\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Measure execution times\n    speeds = measure_speed(results)\n\n    # Evaluate performance based on specified strategies\n    scores = evaluate_retrieval_node(results, strategies)\n\n    # Save the results and a summary to the specified directory\n    summary = pd.DataFrame(\n        {\n            \"module\": [module.__name__ for module in modules],\n            \"params\": module_params,\n            \"speed\": speeds,\n            \"score\": scores,\n        }\n    )\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Select and save the best result based on the evaluation\n    best_result = select_best_average(results, scores)\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Get the support modules for query expansion\n    support_modules = get_support_modules(modules)\n\n    # Initialize the results dataframe\n    results = pd.DataFrame()\n\n    # Initialize the summary dataframe\n    summary = pd.DataFrame()\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n\n        # Create a directory for the current module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module with the given parameters\n        module_result = module(previous_result, **params)\n\n        # Evaluate the module's performance based on the given strategies\n        module_summary = evaluate_query_expansion_node(module_result, previous_result, strategies)\n\n        # Add the module's name and parameters to the summary dataframe\n        module_summary['module'] = module.__name__\n        module_summary['parameters'] = str(params)\n\n        # Add the module's summary to the summary dataframe\n        summary = summary.append(module_summary, ignore_index=True)\n\n        # Add the module's result to the results dataframe\n        results = results.append(module_result, ignore_index=True)\n\n    # Save the results and summary to the specified directory\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Select the best result based on the given strategies\n    best_result = select_best_query_expansion_node(results, summary, strategies)\n\n    # Save the best result to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize the results dataframe\n    results = pd.DataFrame()\n\n    # Run each module with the specified parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters {params}\")\n\n        # Run the module\n        module_result = module(previous_result, **params)\n\n        # Check if the module returned a result\n        if module_result is None:\n            logger.warning(f\"Module {module.__name__} returned None\")\n            continue\n\n        # Measure the module's execution time\n        execution_time = measure_speed(module, previous_result, **params)\n\n        # Evaluate the module's performance\n        evaluation = evaluate_retrieval_node(module_result, previous_result, strategies)\n\n        # Add the module's results to the results dataframe\n        results = results.append({\n            \"module\": module.__name__,\n            \"params\": params,\n            \"result\": module_result,\n            \"execution_time\": execution_time,\n            \"evaluation\": evaluation\n        }, ignore_index=True)\n\n    # Save the results and a summary of the results to the node line directory\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    summary = results.groupby(\"module\").mean().reset_index()\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Select the best module based on the evaluation\n    best_module = select_best_average(results, strategies)\n\n    # Save the best module's result to the node line directory\n    best_module[\"result\"].to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Return the best module's result\n    return best_module[\"result\"]\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the node directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Run each module with the specified parameters and save the results\n    results = []\n    for module, module_param in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters {module_param}\")\n        result = module(previous_result, **module_param)\n        result[\"module\"] = module.__name__\n        results.append(result)\n\n    # Combine the results into a single dataframe\n    results = pd.concat(results)\n\n    # Save the results to the node directory\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Measure the execution times for each module\n    execution_times = measure_speed(results, \"module\")\n\n    # Save the execution times to the node directory\n    execution_times.to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n\n    # Filter the results based on the execution time strategy\n    if \"speed\" in strategies:\n        results = filter_by_threshold(results, \"module\", execution_times, strategies[\"speed\"])\n\n    # Evaluate the performance of each module based on the specified strategies\n    if \"performance\" in strategies:\n        performance = evaluate_retrieval_node(results, \"module\", strategies[\"performance\"])\n\n    # Select the best module based on the evaluation results\n    if \"selection\" in strategies:\n        best_module = select_best_average(performance, \"module\", strategies[\"selection\"])\n    else:\n        best_module = performance.iloc[0][\"module\"]\n\n    # Save the best module to the node directory\n    with open(os.path.join(node_line_dir, \"best_module.txt\"), \"w\") as f:\n        f.write(best_module)\n\n    # Filter the results to keep only the best module\n    results = results[results[\"module\"] == best_module]\n\n    # Save the best results to the node directory\n    results.to_csv(os.path.join(node_line_dir, \"best_result.csv"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Create the support module directory\n    support_module_dir = os.path.join(node_line_dir, \"support_modules\")\n    pathlib.Path(support_module_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module with the given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module\n        module_result = module(previous_result, **params)\n\n        # Save the result\n        module_result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n\n        # Measure the speed\n        speed = measure_speed(module, previous_result, **params)\n\n        # Evaluate the result\n        evaluation = evaluate_retrieval_node(module_result, previous_result, support_modules)\n\n        # Add the result to the results list\n        results.append({\n            \"module\": module.__name__,\n            \"params\": params,\n            \"speed\": speed,\n            \"evaluation\": evaluation,\n            \"result\": module_result\n        })\n\n    # Save the results\n    pd.DataFrame(results).to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Filter the results by speed threshold\n    filtered_results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # Select the best result based on the evaluation\n    best_result = select_best_average(filtered_results, strategies[\"metrics\"])\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results = []\n    for module, params in zip(modules, module_params):\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Evaluate each module\n    results_df = pd.concat(results)\n    results_df = evaluate_retrieval_node(results_df, strategies)\n    results_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Measure speed\n    results_df = measure_speed(results_df)\n\n    # Filter by speed\n    results_df = filter_by_threshold(results_df, strategies)\n\n    # Select best average\n    results_df = select_best_average(results_df, strategies)\n\n    # Save best result\n    best_result = results_df.iloc[0]\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create the directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # get the support modules\n    support_modules = get_support_modules(modules)\n\n    # make the combinations of modules and their parameters\n    combinations = make_combinations(modules, module_params)\n\n    # initialize the result dataframe\n    result = pd.DataFrame()\n\n    # loop through the combinations\n    for module, module_param in combinations:\n        # run the module\n        output = module(previous_result, **module_param)\n\n        # get the support module output\n        support_output = support_modules[module](previous_result, **module_param)\n\n        # measure the speed of the module\n        speed = measure_speed(module, previous_result, **module_param)\n\n        # evaluate the module\n        evaluation = evaluate_retrieval_node(output, support_output, previous_result, strategies)\n\n        # create a new dataframe with the evaluation results\n        evaluation_df = pd.DataFrame(evaluation, index=[0])\n\n        # add the module name and its parameters to the evaluation dataframe\n        evaluation_df[\"module\"] = module.__name__\n        evaluation_df[\"module_params\"] = str(module_param)\n\n        # add the speed to the evaluation dataframe\n        evaluation_df[\"speed\"] = speed\n\n        # append the evaluation dataframe to the result dataframe\n        result = result.append(evaluation_df, ignore_index=True)\n\n    # save the result dataframe to a csv file\n    result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n\n    # filter the result dataframe based on the speed threshold\n    filtered_result = filter_by_threshold(result, strategies[\"speed_threshold\"])\n\n    # select the best result based on the evaluation metrics\n    best_result = select_best_average(filtered_result, strategies[\"metrics\"])\n\n    # save the best result to a csv file\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # return the best result\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(\"Running query expansion node\")\n    logger.info(\"Number of modules: {}\".format(len(modules)))\n\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Run each module with given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(\"Running module: {}\".format(module.__name__))\n        logger.info(\"Module params: {}\".format(params))\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Measure execution times for each module\n    speeds = measure_speed(results)\n    logger.info(\"Speeds: {}\".format(speeds))\n\n    # Evaluate each module based on specified strategies\n    scores = evaluate_retrieval_node(results, strategies)\n    logger.info(\"Scores: {}\".format(scores))\n\n    # Combine results, speeds, and scores into a dataframe\n    combined = pd.DataFrame(results)\n    combined['speed'] = speeds\n    combined['score'] = scores\n\n    # Save results and a summary to the specified directory\n    combined.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    combined.describe().to_csv(os.path.join(node_line_dir, \"summary.csv\"))\n\n    # Select the best result based on the evaluation\n    best_result = select_best_average(results, scores)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    logger.info(\"Finished running query expansion node\")\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Run the query expansion node\n    results = evaluate_retrieval_node(modules, module_params, previous_result, support_modules, strategies)\n\n    # Save the results\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Get the summary\n    summary = results.groupby(\"module_name\").agg(\n        {\"speed\": [\"mean\", \"std\"], \"metric\": [\"mean\", \"std\"]}).reset_index()\n    summary.columns = [\"module_name\", \"speed_mean\", \"speed_std\", \"metric_mean\", \"metric_std\"]\n\n    # Save the summary\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Select the best result based on the evaluation\n    best_result = select_best_average(results, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(\"Running query expansion module: %s\", module.__name__)\n        try:\n            result = module(previous_result, **params)\n        except Exception as e:\n            logger.error(\"Error running query expansion module: %s\", module.__name__)\n            logger.error(\"Error message: %s\", e)\n            continue\n        results.append(result)\n\n    results = pd.concat(results)\n    results = results.drop_duplicates()\n\n    results = measure_speed(results, strategies[\"speed_threshold\"])\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    results = evaluate_retrieval_node(results, strategies[\"metrics\"])\n\n    results = select_best_average(results, strategies[\"metrics\"])\n\n    results = results.reset_index(drop=True)\n    results = results.sort_values(\"score\", ascending=False)\n    results = results.reset_index(drop=True)\n\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    summary = results.groupby([\"module\", \"params\"]).agg(\n        {\"speed\": \"mean\", \"score\": \"mean\"}).reset_index()\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    best_result = results.iloc[0]\n\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Check if the node directory exists\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Check if the node directory exists\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    if not os.path.exists(prompt_maker_node_dir):\n        os.makedirs(prompt_maker_node_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    if not os.path.exists(prompt_maker_node_dir):\n        os.makedirs(prompt_maker_node_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    if not os.path.exists(prompt_maker_node_dir):\n        os.makedirs(prompt_maker_node_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    if not os.path.exists(prompt_maker_node_dir):\n        os.makedirs(prompt_maker_node_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    if not os.path.exists(prompt_maker_node_dir):\n        os.makedirs(prompt_maker_node_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    if not os.path.exists(prompt_maker_node_dir):\n        os.makedirs(prompt_maker_node_dir)\n\n    # Create a directory for the prompt maker node\n    prompt_maker_node_dir = os.path.join(node_line_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get support modules\n    support_modules = get_support_modules()\n\n    # Get generator module\n    generator_module = support_modules['generator']\n\n    # Get evaluation module\n    evaluation_module = support_modules['evaluation']\n\n    # Get evaluation metrics\n    evaluation_metrics = cast_metrics(strategies['evaluation_metrics'])\n\n    # Get speed threshold\n    speed_threshold = strategies['speed_threshold']\n\n    # Get generator module parameters\n    generator_params = strategies['generator_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    # Get prompt maker module parameters\n    prompt_maker_params = strategies['prompt_maker_params']\n\n    #"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a subdirectory for the current node's output\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module results\n    prompt_maker_dir = node_line_dir / \"prompt_maker\"\n    prompt_maker_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir / \"evaluation\"\n    prompt_maker_eval_dir.mkdir(exist_ok=True)\n\n    # Create a subdirectory for the prompt maker module evaluation results\n    prompt_maker_eval_dir = prompt_maker_dir /"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the node output directory if it doesn't exist\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create the node summary directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Create the node results directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n\n    # Create the node logs directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"logs\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os.makedirs(os.path.join(node_line_dir, \"plots\"), exist_ok=True)\n\n    # Create the node plots directory if it doesn't exist\n    os."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Check if there are modules and module_params\n    if not modules or not module_params:\n        raise ValueError('No modules or module_params provided')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the length of modules and module_params match\n    if len(modules) != len(module_params):\n        raise ValueError('The number of modules and module_params do not match')\n\n    # Check if the"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the node's output directory\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the node's output directory for the prompt maker module\n    pathlib.Path(node_line_dir + '/prompt_maker').mkdir(parents=True, exist_ok=True)\n\n    # Create the node's output directory for the generator module\n    pathlib.Path(node_line_dir + '/generator').mkdir(parents=True, exist_ok=True)\n\n    # Create the node's output directory for the evaluation module\n    pathlib.Path(node_line_dir + '/evaluation').mkdir(parents=True, exist_ok=True)\n\n    # Create the node's output directory for the summary\n    pathlib.Path(node_line_dir + '/summary').mkdir(parents=True, exist_ok=True)\n\n    # Create the node's output directory for the logs\n    pathlib.Path(node_line_dir + '/logs').mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the generator module from the support modules\n    generator_module = support_modules['generator']\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params()\n\n    # Get the generator module's default parameters\n    generator_params = generator_module.get_default_params"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the output directory for the node\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the generator module\n    generator_module = support_modules.get(\"generator\")\n\n    # Get the generator module's parameters\n    generator_params = support_modules.get(\"generator_params\")\n\n    # Get the evaluation module\n    evaluate_module = support_modules.get(\"evaluate\")\n\n    # Get the evaluation module's parameters\n    evaluate_params = support_modules.get(\"evaluate_params\")\n\n    # Get the evaluation metrics\n    evaluate_metrics = support_modules.get(\"evaluate_metrics\")\n\n    # Get the evaluation metrics' parameters\n    evaluate_metrics_params = support_modules.get(\"evaluate_metrics_params\")\n\n    # Get the speed threshold\n    speed_threshold = strategies.get(\"speed_threshold\")\n\n    # Get the evaluation metrics\n    evaluation_metrics = strategies.get(\"evaluation_metrics\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics' parameters\n    evaluation_metrics_params = strategies.get(\"evaluation_metrics_params\")\n\n    # Get the evaluation metrics"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate the QA dataset\n    validate_qa_dataset(previous_result)\n\n    # Create the node directory\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Get the generator module\n    generator = support_modules[\"generator\"]\n\n    # Get the generator parameters\n    generator_params = support_modules[\"generator_params\"]\n\n    # Get the generator module name\n    generator_name = support_modules[\"generator_name\"]\n\n    # Get the generator module version\n    generator_version = support_modules[\"generator_version\"]\n\n    # Get the generator module description\n    generator_description = support_modules[\"generator_description\"]\n\n    # Get the generator module author\n    generator_author = support_modules[\"generator_author\"]\n\n    # Get the generator module email\n    generator_email = support_modules[\"generator_email\"]\n\n    # Get the generator module license\n    generator_license = support_modules[\"generator_license\"]\n\n    # Get the generator module url\n    generator_url = support_modules[\"generator_url\"]\n\n    # Get the generator module citation\n    generator_citation = support_modules[\"generator_citation\"]\n\n    # Get the generator module tags\n    generator_tags = support_modules[\"generator_tags\"]\n\n    # Get the generator module task\n    generator_task = support_modules[\"generator_task\"]\n\n    # Get the generator module language\n    generator_language = support_modules[\"generator_language\"]\n\n    # Get the generator module license\n    generator_license = support_modules[\"generator_license\"]\n\n    # Get the generator module url\n    generator_url = support_modules[\"generator_url\"]\n\n    # Get the generator module citation\n    generator_citation = support_modules[\"generator_citation\"]\n\n    # Get the generator module tags\n    generator_tags = support_modules[\"generator_tags\"]\n\n    # Get the generator module task\n    generator_task = support_modules[\"generator_task\"]\n\n    # Get the generator module language\n    generator_language = support_modules[\"generator_language\"]\n\n    # Get the generator module license\n    generator_license = support_modules[\"generator_license\"]\n\n    # Get the generator module url\n    generator_url = support_modules[\"generator_url\"]\n\n    # Get the generator module citation\n    generator_citation = support_modules[\"generator_citation\"]"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node's output\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Get the generator module\n    generator_module = strategies.get('generator_module')\n    if generator_module is None:\n        generator_module = get_support_modules()['generator']\n\n    # Create a dataframe to store the results\n    results = pd.DataFrame()\n\n    # Iterate over the modules and their parameters\n    for module, module_param in zip(modules, module_params):\n        # Create a directory for the module's output\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the module with the given parameters\n        module_result = module(module_param)\n        # Save the result to the module's directory\n        module_result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n\n        # Evaluate the module's performance\n        module_result = evaluate_generation(module_result, generator_module)\n        # Save the evaluation result to the module's directory\n        module_result.to_csv(os.path.join(module_dir, 'evaluation.csv'), index=False)\n\n        # Add the module's result to the dataframe\n        results = results.append(module_result, ignore_index=True)\n\n    # Save the results to the node's directory\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'), index=False)\n\n    # Select the best prompt maker based on the specified strategies\n    best_prompt_maker = select_best_prompt_maker(results, strategies)\n\n    # Save the best prompt maker's result to the node's directory\n    best_prompt_maker.to_csv(os.path.join(node_line_dir, 'best_prompt_maker.csv'), index=False)\n\n    # Combine the previous result with the best prompt maker's result\n    combined_result = pd.concat([previous_result, best_prompt_maker], ignore_index=True)\n\n    # Save the combined result to the node's directory\n    combined_result.to_csv(os.path.join(node_line_dir, 'combined_result.csv"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a new directory for the node's output\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules(strategies)\n\n    # Get the generator module\n    generator_module = support_modules['generator']\n\n    # Get the evaluation metrics\n    metrics = strategies.get('metrics', [])\n\n    # Get the speed thresholds\n    speed_thresholds = strategies.get('speed_thresholds', {})\n\n    # Get the threshold for selecting the best prompt maker module\n    best_prompt_maker_threshold = strategies.get('best_prompt_maker_threshold', 0.0)\n\n    # Get the generator module parameters\n    generator_params = support_modules.get('generator_params', {})\n\n    # Get the generator module name\n    generator_module_name = support_modules.get('generator_module_name', 'default')\n\n    # Get the generator module parameters\n    generator_params = support_modules.get('generator_params', {})\n\n    # Get the generator module name\n    generator_module_name = support_modules.get('generator_module_name', 'default')\n\n    # Create a new directory for the node's output\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules(strategies)\n\n    # Get the generator module\n    generator_module = support_modules['generator']\n\n    # Get the evaluation metrics\n    metrics = strategies.get('metrics', [])\n\n    # Get the speed thresholds\n    speed_thresholds = strategies.get('speed_thresholds', {})\n\n    # Get the threshold for selecting the best prompt maker module\n    best_prompt_maker_threshold = strategies.get('best_prompt_maker_threshold', 0.0)\n\n    # Get the generator module parameters\n    generator_params = support_modules.get('generator_params', {})\n\n    # Get the generator module name\n    generator_module_name = support_modules.get('generator_module_name', 'default')\n\n    # Create a new directory for the node's output\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the node's output directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a dataframe to store the results of the prompt maker modules\n    results = pd.DataFrame()\n\n    # Iterate over the prompt maker modules and their parameters\n    for module, params in zip(modules, module_params):\n\n        # Create a directory for the current prompt maker module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Execute the prompt maker module with the given parameters\n        module_result = module(**params)\n\n        # Evaluate the prompt maker module's performance\n        if 'generator' in strategies:\n            generator_module = get_support_modules(strategies['generator'])\n            module_result = evaluate_generation(module_result, generator_module)\n\n        # Save the prompt maker module's result to the module's directory\n        module_result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n\n        # Append the result to the results dataframe\n        results = results.append(module_result)\n\n    # Save the results dataframe to the node's output directory\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'), index=False)\n\n    # Select the best prompt maker module based on the specified strategies\n    best_module = select_best_average(results, strategies)\n\n    # Save the best prompt maker module's result to the node's output directory\n    best_module.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n\n    # Combine the previous result with the best prompt maker module's result\n    combined_result = previous_result.append(best_module)\n\n    # Return the combined result\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the necessary directories for the node's output\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Get the generator module and its parameters\n    generator_module, generator_params = get_support_modules(strategies)\n\n    # Evaluate the prompt maker modules with the generator module and save the results\n    results = evaluate_prompt_maker_modules(modules, module_params, generator_module, generator_params, node_line_dir)\n\n    # Select the best prompt maker module based on the specified strategies\n    best_prompt_maker = select_best_prompt_maker(results, strategies)\n\n    # Save the results and a summary of the best prompt maker module\n    save_results(results, best_prompt_maker, node_line_dir)\n\n    # Combine the previous result with the best prompt maker's result\n    combined_result = pd.concat([previous_result, best_prompt_maker])\n\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"outputs\"), exist_ok=True)\n\n    # Get the generator module\n    generator_module = get_support_modules(strategies, \"generator\")\n\n    # Run each prompt maker module and evaluate its performance\n    results = []\n    for module, params in zip(modules, module_params):\n        # Run the prompt maker module\n        result = module(previous_result, **params)\n        # Validate the result\n        result = validate_qa_dataset(result)\n        # Evaluate the result\n        result = evaluate_generation(result, generator_module, strategies)\n        # Save the result\n        result.to_csv(os.path.join(node_line_dir, \"outputs\", f\"{module.__name__}.csv\"), index=False)\n        # Append the result to the results list\n        results.append(result)\n\n    # Combine the results of all prompt maker modules\n    combined_results = pd.concat(results)\n    # Save the combined results\n    combined_results.to_csv(os.path.join(node_line_dir, \"outputs\", \"combined_results.csv\"), index=False)\n\n    # Select the best prompt maker module based on the specified strategies\n    best_result = select_best_average(combined_results, strategies)\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"outputs\", \"best_result.csv\"), index=False)\n\n    # Combine the previous result and the best result\n    combined_result = pd.concat([previous_result, best_result])\n    # Save the combined result\n    combined_result.to_csv(os.path.join(node_line_dir, \"outputs\", \"combined_result.csv\"), index=False)\n\n    # Save the strategies used for evaluation\n    with open(os.path.join(node_line_dir, \"outputs\", \"strategies.txt\"), \"w\") as f:\n        f.write(str(strategies))\n\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the output directory for this node\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Run the prompt maker modules\n    results = []\n    for module, module_param in zip(modules, module_params):\n        result = module(module_param)\n        results.append(result)\n\n    # Evaluate the prompt maker modules\n    results = evaluate_generation(results, strategies['generator'])\n\n    # Select the best prompt maker module\n    best_module = select_best_average(results, strategies['metrics'])\n\n    # Save the results and a summary\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'), index=False)\n    best_module.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n    with open(os.path.join(node_line_dir, 'summary.txt'), 'w') as f:\n        f.write(f'Best module: {best_module[\"module_name\"].iloc[0]}\\n')\n        f.write(f'Best module parameters: {best_module[\"module_parameters\"].iloc[0]}\\n')\n        f.write(f'Best module metrics: {best_module[\"metrics\"].iloc[0]}\\n')\n\n    # Combine the previous result with the best prompt maker's result\n    result = pd.concat([previous_result, best_module], ignore_index=True)\n\n    return result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n    pathlib.Path(os.path.join(node_line_dir, 'prompt_maker')).mkdir(parents=True, exist_ok=True)\n\n    # Run prompt maker modules\n    results = []\n    for module, params in zip(modules, module_params):\n        print(f'Running {module.__name__} with parameters {params}')\n        module_result = module(previous_result, **params)\n        results.append(module_result)\n\n    # Evaluate prompt maker modules\n    if 'generator_module' in strategies:\n        generator_module = strategies['generator_module']\n    else:\n        generator_module = get_support_modules()['generator']\n\n    if 'evaluation_metrics' in strategies:\n        evaluation_metrics = strategies['evaluation_metrics']\n    else:\n        evaluation_metrics = ['accuracy', 'f1', 'rouge']\n\n    if 'speed_threshold' in strategies:\n        speed_threshold = strategies['speed_threshold']\n    else:\n        speed_threshold = 1000\n\n    if 'selection_strategy' in strategies:\n        selection_strategy = strategies['selection_strategy']\n    else:\n        selection_strategy = select_best_average\n\n    # Measure speed\n    speeds = measure_speed(results, generator_module, evaluation_metrics)\n    results = [result.assign(speed=speed) for result, speed in zip(results, speeds)]\n\n    # Filter by speed\n    results = filter_by_threshold(results, speed_threshold, 'speed')\n\n    # Evaluate\n    results = evaluate_generation(results, generator_module, evaluation_metrics)\n\n    # Select best\n    best_result = selection_strategy(results, evaluation_metrics)\n\n    # Save results\n    best_result.to_csv(os.path.join(node_line_dir, 'prompt_maker', 'best_result.csv'), index=False)\n    results.to_csv(os.path.join(node_line_dir, 'prompt_maker', 'results.csv'), index=False)\n\n    # Combine with previous results\n    result = pd.concat([previous_result, best_result], ignore_index=True)\n\n    return result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run the prompt maker modules\n    results = []\n    for i, (module, module_param) in enumerate(zip(modules, module_params)):\n\n        # Run the prompt maker module\n        print(f\"Running prompt maker module {i+1} of {len(modules)}\")\n        result = module(previous_result, **module_param)\n\n        # Save the result\n        result.to_csv(f\"{node_line_dir}/result_{i+1}.csv\", index=False)\n\n        # Evaluate the result\n        if 'generator' in strategies:\n            generator = strategies['generator']\n            result = evaluate_generation(result, generator)\n        results.append(result)\n\n    # Combine the results\n    combined_result = pd.concat(results, ignore_index=True)\n\n    # Save the combined result\n    combined_result.to_csv(f\"{node_line_dir}/combined_result.csv\", index=False)\n\n    # Select the best prompt maker module based on the specified strategies\n    best_prompt_maker = select_best_average(combined_result, strategies)\n\n    # Save the best prompt maker module's result\n    best_prompt_maker.to_csv(f\"{node_line_dir}/best_prompt_maker.csv\", index=False)\n\n    # Save the summary\n    summary = {\n        'strategies': strategies,\n        'modules': modules,\n        'module_params': module_params,\n        'previous_result': previous_result,\n        'node_line_dir': node_line_dir,\n    }\n    with open(f\"{node_line_dir}/summary.txt\", \"w\") as f:\n        f.write(str(summary))\n\n    # Return the combined result\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run all modules\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(params)\n        results.append(result)\n\n    # Evaluate and select the best module\n    best_result = evaluate_and_select_best_module(results, strategies, node_line_dir)\n\n    # Combine the previous result and the best result\n    combined_result = pd.concat([previous_result, best_result])\n\n    # Save the combined result to the node line directory\n    combined_result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n\n    # Save a summary of the results\n    save_summary(combined_result, node_line_dir)\n\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the output directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support module for the generator\n    support_modules = get_support_modules()\n    generator_module = support_modules.get(strategies.get(\"generator_module\", \"default\"))\n\n    # Create a list of combinations of modules and parameters\n    combinations = make_combinations(modules, module_params)\n\n    # Initialize a list to store the results\n    results = []\n\n    # Iterate over the combinations\n    for module, params in combinations:\n        # Get the module name\n        module_name = module.__name__\n\n        # Create a directory for the module's output\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module with the specified parameters\n        module_result = module(previous_result, **params)\n\n        # Evaluate the module's output\n        evaluate_result = evaluate_generation(module_result, generator_module)\n\n        # Cast the evaluation metrics to the correct data types\n        evaluate_result = cast_metrics(evaluate_result)\n\n        # Get the speed of the module\n        speed = measure_speed(module, module_result)\n\n        # Combine the evaluation result and speed into a single dictionary\n        result = {**evaluate_result, \"speed\": speed}\n\n        # Add the result to the list\n        results.append(result)\n\n    # Convert the list of results to a DataFrame\n    results_df = pd.DataFrame(results)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(results_df, strategies)\n\n    # Filter the results based on the specified thresholds\n    filtered_results = filter_by_threshold(results_df, strategies)\n\n    # Save the results to the output directory\n    filtered_results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Save the summary to the output directory\n    summary = {\n        \"best_result\": best_result,\n        \"filtered_results\": filtered_results,\n    }\n    pd.DataFrame(summary).to_csv(os.path.join(node_line_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the prompt maker module combinations\n    combinations = make_combinations(modules, module_params)\n\n    # Run the prompt maker modules with the specified parameters\n    results = []\n    for combination in combinations:\n        print(f\"Running {combination[0].__name__}\")\n        result = combination[0](**combination[1])\n        results.append(result)\n\n    # Evaluate the performance of the prompt maker modules\n    results_df = pd.DataFrame(results)\n    results_df = cast_metrics(results_df)\n\n    # Measure the speed of the prompt maker modules\n    speed_df = measure_speed(results_df, strategies['speed'])\n\n    # Select the best prompt maker module based on the specified strategies\n    best_df = select_best_average(speed_df, strategies['metrics'])\n\n    # Evaluate the best prompt maker module with the specified generator module\n    best_df = evaluate_generation(best_df, strategies['generator'], strategies['metrics'])\n\n    # Combine the previous result with the best prompt maker's result\n    result_df = pd.concat([previous_result, best_df])\n\n    # Save the combined result and a summary to the specified directory\n    result_df.to_csv(f\"{node_line_dir}/result.csv\", index=False)\n    summary = result_df.to_dict('records')\n    summary = explode(summary, 'metrics')\n    summary = explode(summary, 'speed')\n    summary_df = pd.DataFrame(summary)\n    summary_df.to_csv(f\"{node_line_dir}/summary.csv\", index=False)\n\n    return result_df\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get the support modules\n    support_modules = get_support_modules()\n    generator_module = support_modules['generator']\n\n    # Create the necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(f\"{node_line_dir}/results\", exist_ok=True)\n\n    # Run the prompt maker modules\n    results = []\n    for module, params in zip(modules, module_params):\n        print(f\"Running {module.__name__} with params {params}\")\n        prompt_maker = module(**params)\n        result = prompt_maker.run(previous_result)\n        results.append(result)\n\n    # Evaluate the prompt maker modules\n    print(\"Evaluating prompt maker modules\")\n    generator = generator_module(strategies['generator_params'])\n    results_with_metrics = evaluate_generation(results, generator, strategies['metrics'])\n\n    # Select the best prompt maker module\n    print(\"Selecting the best prompt maker module\")\n    best_prompt_maker = select_best_average(results_with_metrics, strategies['metrics'], strategies['threshold'])\n\n    # Save the results and a summary\n    print(\"Saving the results and a summary\")\n    best_prompt_maker.to_csv(f\"{node_line_dir}/results/best_prompt_maker.csv\", index=False)\n    best_prompt_maker.to_csv(f\"{node_line_dir}/best_prompt_maker.csv\", index=False)\n\n    results_with_metrics.to_csv(f\"{node_line_dir}/results/all_results.csv\", index=False)\n    results_with_metrics.to_csv(f\"{node_line_dir}/all_results.csv\", index=False)\n\n    summary = {\n        'best_prompt_maker': best_prompt_maker.iloc[0].to_dict(),\n        'metrics': strategies['metrics'],\n        'threshold': strategies['threshold'],\n        'generator_params': strategies['generator_params'],\n        'execution_time': measure_speed(best_prompt_maker.iloc[0].to_dict(), generator_module, strategies['generator_params'])\n    }\n\n    pd.DataFrame(summary).to_csv(f\"{node_line_dir}/results/summary.csv\","}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    return list(set(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes)))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    return list(set(list(itertools.chain.from_iterable(map(lambda x: extract_values(x, key), nodes)))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_values_from_node(node: Node) -> List[str]:\n        \"\"\"\n        Extracts values associated with a specified key from a node, ensuring each value is unique by removing duplicates.\n\n        Input-Output Arguments\n        :param node: Node. The node from which you want to extract values. This node is expected to have a structure that includes modules and module_params from which values are extracted.\n        :param key: String. The key corresponding to the value you want to extract from the node's module_param.\n        :return: List[String]. A list of unique values extracted from the node based on the specified key.\n        \"\"\"\n        return extract_values(node, key)\n\n    values = list(map(extract_values_from_node, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_values_from_node(node: Node):\n        if key not in node.node_params:\n            return []\n        value = node.node_params[key]\n        if isinstance(value, str):\n            return [value]\n        elif isinstance(value, list):\n            return value\n        else:\n            raise ValueError(f\"{key} must be str or list, but got {type(value)}\")\n\n    values = list(map(extract_values_from_node, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda node: extract_values(node, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_node_values(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_node_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_emb = embedding_model.embed_query(pred)\n    gt_embs = [embedding_model.embed_query(gt) for gt in generation_gt]\n\n    return max(calculate_cosine_similarity(pred_emb, gt_emb) for gt_emb in gt_embs)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    pred_embedding = embedding_model.embed_documents([pred])\n    return max(\n        calculate_cosine_similarity(gt_embeddings, pred_embedding)\n    )\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    pred_embedding = embedding_model.embed_query(pred)\n    gt_embeddings = embedding_model.embed_query(generation_gt)\n    return max(\n        calculate_cosine_similarity(pred_embedding, gt_embedding)\n        for gt_embedding in gt_embeddings\n    )\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    embeddings_gt = embedding_model.embed_documents(generation_gt)\n    embeddings_pred = embedding_model.embed_documents([pred])\n\n    return max(list(map(lambda x: calculate_cosine_similarity(x[0], x[1]), zip(embeddings_gt, embeddings_pred))))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model_from_name(\"all-mpnet-base-v2\")\n    return max(\n        list(\n            map(\n                lambda x: calculate_cosine_similarity(\n                    embedding_model.embed_query(pred),\n                    embedding_model.embed_query(x),\n                ),\n                generation_gt,\n            )\n        )\n    )\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model()\n    pred_embed = embedding_model.embed_query(pred)\n    gt_embed = embedding_model.embed_query(generation_gt)\n    return calculate_cosine_similarity(pred_embed, gt_embed)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model()\n\n    pred_embedding = embedding_model.embed_query(pred)\n    gt_embeddings = embedding_model.embed_query(generation_gt)\n\n    return max(\n        [calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings]\n    )\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.embed_query(pred)\n    gt_embeddings = embedding_model.embed_query(generation_gt)\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(model_name_or_path=\"all-mpnet-base-v2\")\n    return max(list(map(\n        lambda x: calculate_cosine_similarity(x, pred, embedding_model=embedding_model), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(model_name=\"all-mpnet-base-v2\")\n\n    embedding_model.text_to_embedding_batch(generation_gt)\n    embedding_model.text_to_embedding_batch([pred])\n\n    return calculate_cosine_similarity(generation_gt, pred, embedding_model)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model(\"all-mpnet-base-v2\")\n\n    # Convert the strings into embeddings\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    pred_embedding = embedding_model.embed_documents([pred])[0]\n\n    # Calculate the maximum cosine similarity between the predicted string and each ground truth string\n    cosine_similarity = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n    return cosine_similarity\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n    embeddings_gt = embedding_model.embed_documents(generation_gt)\n    embeddings_pred = embedding_model.embed_documents([pred])\n    return calculate_cosine_similarity(embeddings_gt, embeddings_pred)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    pred_embedding = embedding_model.embed_documents([pred])\n    return calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    return max(\n        list(map(\n            lambda x: calculate_cosine_similarity(x, pred, embedding_model), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    # Embed the ground truth and predicted strings\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    pred_embedding = embedding_model.embed_documents([pred])[0]\n\n    # Calculate the cosine similarity between the predicted string and each ground truth string\n    similarity_scores = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n    # Return the maximum similarity score\n    return max(similarity_scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    # Compute embeddings for the ground truth strings and the predicted string\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    pred_embedding = embedding_model.embed_documents([pred])[0]\n\n    # Calculate the cosine similarity between the predicted string and each ground truth string\n    similarities = calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n    # Return the maximum cosine similarity score\n    return max(similarities)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n    embeddings_gt = embedding_model.embed_documents(generation_gt)\n    embeddings_pred = embedding_model.embed_documents([pred])\n    return calculate_cosine_similarity(embeddings_gt, embeddings_pred)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    pred_embedding = embedding_model.embed_documents([pred])[0]\n    return max(list(map(lambda x: calculate_cosine_similarity(x, pred_embedding), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.embed_query(pred)\n    gt_embeddings = embedding_model.embed_documents(generation_gt)\n    scores = [calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings]\n    return max(scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model()\n\n    pred_embedding = embedding_model.embed_query(pred)\n    gt_embeddings = embedding_model.embed_query(generation_gt)\n\n    return max([calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings])\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.ModelNotFoundError:\n            logger.warning(\"GFPGAN face restorer not found. Skipping face restoration.\")\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.FaceRestorationError as e:\n            logger.warning(f\"Failed to set up GFPGAN face restorer: {e}\")\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Failed to restore faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.FaceRestorationError as e:\n            logger.warning(f\"Failed to initialize GFPGAN face restorer: {e}\")\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=None)\n        except errors.FaceRestorationError:\n            logger.warning(\"GFPGAN face restorer not set up\")\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(\"GFPGAN face restorer failed: %s\", e)\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.model_path(),\n            )\n        except errors.ModelNotFoundError as e:\n            logger.warning(\n                f\"GFPGAN face restorer not found: {e}. Skipping face restoration.\"\n            )\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=os.path.join(shared.data_dir, 'models'))\n        except errors.ModelError as e:\n            logger.warning(\"Failed to load GFPGAN face restorer: %s\", e)\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=os.path.join(shared.config.model_path, \"GFPGAN\")\n            )\n        except errors.ModelNotFoundError:\n            logger.warning(\"GFPGAN model not found, skipping face restoration\")\n            return np_image\n\n    return gfpgan_face_restorer.fix_faces(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=None)\n        except errors.FaceRestorationError:\n            logger.warning(\"GFPGAN face restorer not set up, skipping\")\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError:\n        logger.warning(\"GFPGAN face restorer failed, skipping\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.model_path,\n                device=devices.device_gfpgan,\n            )\n        except errors.NoFaceRestorationModelError:\n            logger.warning(\"No GFPGAN model found\")\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=shared.model_path\n            )\n        except errors.FaceRestorationError as e:\n            logger.warning(f\"Failed to set up GFPGAN face restorer: {e}\")\n            return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Failed to use GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up, returning original image\")\n        return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Error during GFPGAN face restoration: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer not set up. Skipping face restoration.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.fix_faces(np_image)\n    except errors.FaceRestorerError as e:\n        logger.warning(f\"GFPGAN face restorer failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Skipping face restoration.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=os.path.join(shared.get_model_directory(), \"GFPGAN\"),\n            )\n        except errors.FaceRestorationError as e:\n            logger.warning(f\"Failed to initialize GFPGAN face restorer: {e}\")\n            return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Failed to restore faces with GFPGAN: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer not set up. Skipping face restoration.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"GFPGAN face restorer failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=shared.config.get_model_path())\n        except errors.FaceRestorerNotFoundError as e:\n            logger.warning(f\"GFPGAN face restorer not found: {e}\")\n            return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorerNotFoundError as e:\n        logger.warning(f\"GFPGAN face restorer not found: {e}\")\n        return np_image\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.FaceRestorationError:\n            logger.warning(\"GFPGAN face restorer not set up. Using original image.\")\n            return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"GFPGAN face restorer failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.FaceRestorationError:\n            logger.warning(\n                \"Failed to initialize GFPGAN face restorer. Skipping face restoration.\"\n            )\n            return np_image\n\n    return gfpgan_face_restorer.fix_faces(np_image)\n    if not os.path.exists(model_path):\n            raise ValueError(\n                f\"Model path {model_path} does not exist. Please provide a valid model path.\"\n            )\n        self.model_path = model_path\n        self.net = self.load_net()\n\n    def name(self) -> str:\n        raise NotImplementedError\n\n    def get_device(self) -> torch.device:\n        raise NotImplementedError\n\n    def load_net(self) -> torch.Module:\n        raise NotImplementedError\n\n    def restore(self, np_image: np.ndarray) -> np.ndarray:\n        raise NotImplementedError\n\n    def fix_faces(self, np_image: np.ndarray) -> np.ndarray:\n        \"\"\"\n        This function attempts to restore faces in an image using the face restorer. It uses the face detector to find faces in the image and then passes each face to the face restorer for restoration. If the face restorer is not set up, it logs a warning and returns the original image.\n\n        Input-Output Arguments\n        :param np_image: The image as a NumPy array on which face restoration is attempted.\n        :return: The image as a NumPy array. It is either the original image or the restored image if the face restorer is set up and used successfully.\n        \"\"\"\n\n        if self.net is None:\n            logger.warning(\n                f\"Face restorer {self.name()} not set up. Skipping face restoration.\"\n            )\n            return np_image\n\n        logger.info(f\"Restoring faces using {self.name()}\")\n        faces = face_detection.get_faces(np_image)\n        if len(faces) == 0:\n            logger.info(f\"No faces found in image. Skipping face restoration.\")\n            return np_image\n\n        logger.info(f\"Found"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=shared.get_model_path())\n        except errors.NoFaceDetectorException:\n            logger.warning(\"No face detector found, so GFPGAN can't be used to fix faces.\")\n            return np_image\n        except errors.NoFaceRestorerException:\n            logger.warning(\"No face restorer found, so GFPGAN can't be used to fix faces.\")\n            return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"Failed to use GFPGAN to fix faces: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            gfpgan_face_restorer = FaceRestorerGFPGAN()\n        except errors.FaceRestorationError:\n            logger.warning(\"GFPGAN face restorer not set up. Skipping face restoration.\")\n            return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Error setting up CodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(e)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Could not load CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(\"Error setting up CodeFormer: %s\", e)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to setup codeformer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(\"CodeFormer model loaded\")\n    except errors.FaceRestorationError as e:\n        logger.error(e)\n    )\n\n    def name(self):\n        return \"CodeFormer\"\n\n    def load_net(self) -> torch.Module:\n        for model_path in modelloader.load_models(\n            model_path=self.model_path,\n            model_url=model_url,\n            command_path=self.model_path,\n            download_name=model_download_name,\n            ext_filter=['.pth'],\n        ):\n            return modelloader.load_spandrel_model(\n                model_path,\n                device=devices.device_codeformer,\n                expected_architecture='CodeFormer',\n            ).model\n        raise ValueError(\"No codeformer model found\")\n\n    def get_device(self):\n        return devices.device_codeformer\n\n    def restore(self, np_image, w: float | None = None):\n        if w is None:\n            w = getattr(shared.opts, \"code_former_weight\", 0.5)\n\n        def restore_face(cropped_face_t):\n            assert self.net is not None\n            return self.net(cropped_face_t, w=w, adain=True)[0]\n\n        return self.restore_with_helper(np_image, restore_face)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Error while setting up CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.Error as e:\n        logger.error(f\"Error setting up CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"Loaded CodeFormer model from {dirname}\")\n    except errors.PytorchModelError as e:\n        logger.warning(f\"Failed to load CodeFormer model from {dirname}: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n        logger.info(\"Loaded CodeFormer model\")\n    except errors.ModelNotFoundError:\n        logger.info(\"CodeFormer model not found\")\n    except errors.ModelNotInitializedError:\n        logger.info(\"CodeFormer model failed to initialize\")\n    except errors.ModelNotLoadedError:\n        logger.info(\"CodeFormer model failed to load\")\n    except errors.ModelNotValidError:\n        logger.info(\"CodeFormer model is not valid\")\n    except errors.ModelNotCompatibleError:\n        logger.info(\"CodeFormer model is not compatible\")\n    except errors.ModelNotExpectedError:\n        logger.info(\"CodeFormer model is not expected\")\n    except errors.ModelNotExpectedVersionError:\n        logger.info(\"CodeFormer model is not expected version\")\n    except errors.ModelNotExpectedArchitectureError:\n        logger.info(\"CodeFormer model is not expected architecture\")\n    except errors.ModelNotExpectedInputShapeError:\n        logger.info(\"CodeFormer model is not expected input shape\")\n    except errors.ModelNotExpectedOutputShapeError:\n        logger.info(\"CodeFormer model is not expected output shape\")\n    except errors.ModelNotExpectedInputTypeError:\n        logger.info(\"CodeFormer model is not expected input type\")\n    except errors.ModelNotExpectedOutputTypeError:\n        logger.info(\"CodeFormer model is not expected output type\")\n    except errors.ModelNotExpectedInputDeviceError:\n        logger.info(\"CodeFormer model is not expected input device\")\n    except errors.ModelNotExpectedOutputDeviceError:\n        logger.info(\"CodeFormer model is not expected output device\")\n    except errors.ModelNotExpectedInputRangeError:\n        logger.info(\"CodeFormer model is not expected input range\")\n    except errors.ModelNotExpectedOutputRangeError:\n        logger.info(\"CodeFormer model is not expected output range\")\n    except errors.ModelNotExpectedInputValuesError:\n        logger.info(\"CodeFormer model is not expected input values\")\n    except errors.ModelNotExpectedOutputValuesError:\n        logger.info(\"CodeFormer model is not expected output values\")\n    except errors.ModelNotExpectedInputMeanError:\n        logger.info(\"CodeFormer model is not expected input mean\")\n    except errors."}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"Loaded {codeformer.name()} model from {dirname}\")\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to load {codeformer.name()} model from {dirname}: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelNotFoundError:\n        logger.warning(\n            \"CodeFormer model not found. Please install the model by running `python scripts/download_codeformer.py`\"\n        )\n        codeformer = None\n    except errors.ModelNotSuitableError:\n        logger.warning(\n            \"CodeFormer model not suitable. Please install the model by running `python scripts/download_codeformer.py`\"\n        )\n        codeformer = None\n    except errors.ModelLoadError:\n        logger.warning(\"CodeFormer model failed to load\")\n        codeformer = None\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to set up CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to set up CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"Loaded {codeformer.name()}\")\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to load {codeformer.name()}: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Error loading CodeFormer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.Error as e:\n        logger.error(f\"Failed to load CodeFormer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(f\"Successfully loaded CodeFormer from {dirname}\")\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to load CodeFormer from {dirname}: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        logger.info(\"CodeFormer model initialized\")\n    except errors.ModelNotFoundError as e:\n        logger.error(e)\n    except errors.ModelNotLoadedError as e:\n        logger.error(e)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Failed to setup GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error setting up GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib()\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to setup GFPGAN model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        shared.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Failed to setup GFPGAN model: {e}\")\n        raise errors.FaceRestorerSetupError(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        logger.info(\"GFPGAN face restorer set up\")\n    except errors.FaceRestorerError as e:\n        logger.error(f\"Failed to set up GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib()\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.warning(e)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        logger.error(f\"Failed to setup GFPGAN model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib()\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(e)\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.setup()\n    except Exception as e:\n        logger.warning(f\"Failed to set up GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_face_restoration()\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.setup()\n    except Exception as e:\n        logger.error(e)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        gfpgan_face_restorer.load_net()\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Could not set up GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.warning(\"Failed to setup GFPGAN face restoration model: %s\", e)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        if dirname is None:\n            dirname = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"models\")\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        gfpgan_face_restorer.load_net()\n    except errors.FaceRestorationError as e:\n        logger.error(e)\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        face_restoration_utils.patch_facexlib()\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.load_net()\n    except errors.FaceRestorationError as e:\n        logger.error(e)\n    except Exception as e:\n        logger.error(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        logger.info(\"Setting up GFPGAN face restorer\")\n        face_restoration_utils.patch_facexlib()\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            device=devices.device_gfpgan,\n        )\n        logger.info(\"GFPGAN face restorer setup done\")\n    except errors.FaceRestorationError as e:\n        logger.error(\"Failed to setup GFPGAN face restorer: %s\", e)\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        shared.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(e)\n        logger.error(\"Failed to set up GFPGAN\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.setup()\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to setup GFPGAN: {e}\")\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        logger.info(\"GFPGAN face restorer initialized\")\n    except Exception as e:\n        logger.warning(\n            \"Failed to initialize GFPGAN face restorer: %s\",\n            str(e),\n        )\n        gfpgan_face_restorer = None\n     if not isinstance(input, torch.Tensor):\n            raise ValueError(f\"Expected input to be a torch.Tensor, got {type(input)}\")\n        if not isinstance(target, torch.Tensor):\n            raise ValueError(f\"Expected target to be a torch.Tensor, got {type(target)}\")\n        if input.shape != target.shape:\n            raise ValueError(\n                f\"Expected input and target to have the same shape, got {input.shape} and {target.shape}\"\n            )\n        if input.dtype != target.dtype:\n            raise ValueError(\n                f\"Expected input and target to have the same dtype, got {input.dtype} and {target.dtype}\"\n            )\n        if input.device != target.device:\n            raise ValueError(\n                f\"Expected input and target to be on the same device, got {input.device} and {target.device}\"\n            )\n        if not input.requires_grad:\n            raise ValueError(\"Expected input to require grad\")\n        if target.requires_grad:\n            raise ValueError(\"Expected target not to require grad\")\n        if not input.is_floating_point():\n            raise ValueError(f\"Expected input to be floating point, got {input.dtype}\")\n        if not target.is_floating_point():\n            raise ValueError(f\"Expected target to be floating point, got {target.dtype}\")\n\n        self.input = input\n        self.target = target\n\n    def forward(self) -> torch.Tensor:\n        return torch.mean(torch.abs(self.input - self.target))"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        shared.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.FaceRestorationError as e:\n        logger.error(f\"Failed to setup GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion format\n  v_quat = jnp.array([0.0, 0.0, 0.0, 1.0])\n  v_quat[:3] = v\n\n  # Apply the rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.array([0.0, v[0], v[1], v[2]])\n\n  # Rotate the vector\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[Ellipsis, 1:]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  qv = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Apply the rotation\n  qv_rotated = multiply(multiply(q, qv), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  return qv_rotated[..., :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion format\n  v_quat = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Apply the rotation using the quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the quaternion back to a vector\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])], axis=-1)\n\n  # Apply the rotation using the quaternion multiplication\n  rotated_v_quat = multiply(q, multiply(v_quat, conjugate(q)))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_vec = jnp.array([0.0, 0.0, 0.0, 1.0])\n  q_vec[:3] = v\n  return multiply(q, multiply(q_vec, inverse(q)))[:3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion format\n  v_quat = jnp.array([0.0, v[0], v[1], v[2]])\n\n  # Apply the rotation by multiplying the quaternion and the vector quaternion\n  rotated_quat = multiply(q, v_quat)\n\n  # Convert the rotated quaternion back into a vector\n  rotated_v = im(rotated_quat)\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.array([0, v[0], v[1], v[2]])\n\n  # Rotate the vector using the quaternion\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[Ellipsis, 1:]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_v = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n  return multiply(multiply(q, q_v), conjugate(q))[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_q = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Apply the rotation using quaternion multiplication\n  v_rotated_q = multiply(multiply(q, v_q), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  v_rotated = im(v_rotated_q)\n\n  return v_rotated\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.array([v[0], v[1], v[2], 0.0])\n\n  # Apply the rotation using the quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[Ellipsis, :3]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_v = jnp.concatenate([v, jnp.zeros_like(v[..., :1])], axis=-1)\n  q_v_conj = jnp.concatenate([-v, jnp.zeros_like(v[..., :1])], axis=-1)\n  return multiply(multiply(q, q_v), conjugate(q))[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.zeros_like(v[..., :1])], axis=-1)\n\n  # Rotate the vector using the quaternion\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.concatenate([v, jnp.array([0.0])], axis=-1)\n\n  # Apply the rotation\n  q_conj = conjugate(q)\n  v_rot = multiply(multiply(q, v_quat), q_conj)\n\n  # Convert the rotated quaternion back to a vector\n  return v_rot[..., :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v = jnp.array(v)\n  v_quat = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = im(rotated_v_quat)\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion format\n  v_quat = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Apply the rotation\n  rotated_v_quat = multiply(q, multiply(v_quat, conjugate(q)))\n\n  # Convert the rotated quaternion back to a vector\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q = normalize(q)\n  # Convert vector to quaternion\n  v = jnp.array(v)\n  v = jnp.concatenate([v, jnp.zeros_like(v)], axis=-1)\n  # Rotate vector\n  v = multiply(multiply(q, v), conjugate(q))\n  return v[..., :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.array([0.0, 0.0, 0.0, 1.0])\n  v_quat = jnp.concatenate([v, v_quat[3:]], axis=-1)\n\n  # Multiply the quaternion by the vector quaternion\n  rotated_v_quat = multiply(q, v_quat)\n\n  # Multiply the conjugate of the quaternion by the rotated vector quaternion\n  rotated_v_quat = multiply(rotated_v_quat, conjugate(q))\n\n  # Extract the rotated vector from the quaternion\n  rotated_v = im(rotated_v_quat)\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q = normalize(q)\n  v = jnp.asarray(v)\n  if v.ndim == 1:\n    v = v[None, :]\n  assert v.shape[-1] == 3, 'v must be a 3D vector'\n  assert q.shape[-1] == 4, 'q must be a quaternion'\n  v_quat = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n  q_conj = conjugate(q)\n  return multiply(multiply(q, v_quat), q_conj)[Ellipsis, :3]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n\n  # Apply the rotation\n  rotated_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector\n  return rotated_quat[..., :-1]\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = jnp.split(axis_angle, 2, axis=-1)\n  half_angle = 0.5 * angle\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n  q_xyz = sin_half_angle * axis / jnp.maximum(\n      jnp.linalg.norm(axis, axis=-1, keepdims=True),\n      eps * jnp.ones_like(axis),\n  )\n  q_w = cos_half_angle\n  return jnp.concatenate([q_xyz, q_w], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Extract the axis and angle from the axis-angle vector\n  axis = axis_angle[:3]\n  angle = axis_angle[3]\n\n  # Calculate the half angle\n  half_angle = angle / 2.0\n\n  # Calculate the sine and cosine of the half angle\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # Normalize the axis vector\n  norm_axis = axis / jnp.linalg.norm(axis)\n\n  # Calculate the quaternion components\n  w = cos_half_angle\n  x = norm_axis[0] * sin_half_angle\n  y = norm_axis[1] * sin_half_angle\n  z = norm_axis[2] * sin_half_angle\n\n  # Return the quaternion\n  return jnp.array([x, y, z, w])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = jnp.split(axis_angle, 2, axis=-1)\n  half_angle = 0.5 * angle\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n  return jnp.concatenate(\n      [\n          sin_half_angle * axis / jnp.maximum(\n              linalg.norm(axis, axis=-1, keepdims=True),\n              eps * jnp.ones_like(axis),\n          ),\n          cos_half_angle,\n      ],\n      axis=-1,\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n  half_angle = 0.5 * angle\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n  sin_half_angle_safe = jnp.maximum(sin_half_angle, eps * jnp.ones_like(sin_half_angle))\n  return jnp.concatenate(\n      [axis * sin_half_angle_safe / sin_half_angle, cos_half_angle], axis=-1\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  angle = linalg.norm(axis_angle)\n  if angle < eps:\n    return jnp.array([0.0, 0.0, 0.0, 1.0])\n  axis = axis_angle / angle\n  sin_angle = jnp.sin(angle / 2.0)\n  return jnp.concatenate(\n      [axis * sin_angle, jnp.cos(angle / 2.0) * jnp.ones_like(axis[Ellipsis, 0])],\n      axis=-1,\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Ensure axis-angle is a 3-vector\n  axis_angle = jnp.asarray(axis_angle)\n  assert axis_angle.shape == (3,)\n\n  # Calculate the rotation angle\n  angle = linalg.norm(axis_angle)\n\n  # Handle the case where the angle is close to zero\n  if angle < eps:\n    # Calculate the quaternion components for a rotation close to zero\n    w = 1.0\n    x = 0.5 * axis_angle[0]\n    y = 0.5 * axis_angle[1]\n    z = 0.5 * axis_angle[2]\n  else:\n    # Calculate the quaternion components for a non-zero rotation\n    w = jnp.cos(angle / 2.0)\n    x = axis_angle[0] * jnp.sin(angle / 2.0) / angle\n    y = axis_angle[1] * jnp.sin(angle / 2.0) / angle\n    z = axis_angle[2] * jnp.sin(angle / 2.0) / angle\n\n  # Return the quaternion\n  return jnp.array([x, y, z, w])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = jnp.split(axis_angle, 2, axis=-1)\n  angle = jnp.expand_dims(angle, axis=-1)\n  half_angle = 0.5 * angle\n  cos_half_angle = jnp.cos(half_angle)\n  sin_half_angle = jnp.sin(half_angle)\n  return jnp.concatenate(\n      (\n          cos_half_angle * axis,\n          sin_half_angle,\n      ),\n      axis=-1,\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Extract the axis and angle from the input axis_angle vector\n  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n\n  # Calculate the half angle\n  half_angle = 0.5 * angle\n\n  # Calculate the sine and cosine of the half angle\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # Calculate the quaternion components\n  x = axis[..., 0] * sin_half_angle\n  y = axis[..., 1] * sin_half_angle\n  z = axis[..., 2] * sin_half_angle\n  w = cos_half_angle\n\n  # Ensure numerical stability for small angles\n  w = jnp.where(jnp.abs(w) < eps, jnp.ones_like(w), w)\n\n  # Return the quaternion\n  return jnp.concatenate([x[..., None], y[..., None], z[..., None], w[..., None]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = jnp.split(axis_angle, 2, axis=-1)\n  angle = jnp.minimum(jnp.abs(angle), jnp.pi)\n  half_angle = 0.5 * angle\n  s = jnp.sin(half_angle)\n  c = jnp.cos(half_angle)\n  return jnp.concatenate(\n      [\n          s * axis / jnp.maximum(jnp.linalg.norm(axis, axis=-1, keepdims=True),\n                                 eps * jnp.ones_like(axis)),\n          c,\n      ],\n      axis=-1,\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis, angle = jnp.split(axis_angle, 2, axis=-1)\n  angle = jnp.squeeze(angle)\n  axis = jnp.squeeze(axis)\n  sin_theta_by_2 = jnp.sin(angle / 2.0)\n  cos_theta_by_2 = jnp.cos(angle / 2.0)\n  q = jnp.concatenate(\n      [\n          axis * sin_theta_by_2,\n          jnp.expand_dims(cos_theta_by_2, axis=-1),\n      ],\n      axis=-1,\n  )\n  q = jnp.where(\n      jnp.expand_dims(angle < eps, axis=-1),\n      jnp.concatenate(\n          [\n              jnp.zeros_like(axis),\n              jnp.expand_dims(jnp.ones_like(cos_theta_by_2), axis=-1),\n          ],\n          axis=-1,\n      ),\n      q,\n  )\n  return q\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  axis, angle = jnp.split(axis_angle, 2)\n  angle = jnp.squeeze(angle)\n  axis = jnp.squeeze(axis)\n  axis = axis / _safe_sqrt(jnp.sum(axis**2))\n  angle = jnp.squeeze(angle)\n  half_angle = 0.5 * angle\n  s = jnp.sin(half_angle)\n  c = jnp.cos(half_angle)\n  w = c\n  xyz = s * axis\n  return jnp.concatenate((xyz, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Unpack the axis-angle vector\n  axis, angle = axis_angle[..., :3], axis_angle[..., 3:]\n\n  # Normalize the axis vector\n  axis = axis / _safe_sqrt(jnp.sum(axis**2, axis=-1, keepdims=True))\n\n  # Compute the quaternion components\n  w = jnp.cos(angle / 2.0)\n  xyz = axis * jnp.sin(angle / 2.0)\n\n  # Return the quaternion\n  return jnp.concatenate([xyz, w], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis_angle = jnp.squeeze(axis_angle)\n  assert axis_angle.shape == (3,)\n  axis = axis_angle[:3]\n  angle = axis_angle[3]\n  axis = axis / _safe_sqrt(jnp.sum(axis**2))\n  half_angle = 0.5 * angle\n  half_angle_cos = jnp.cos(half_angle)\n  half_angle_sin = jnp.sin(half_angle)\n  return jnp.concatenate(\n      [axis * half_angle_sin, jnp.array([half_angle_cos])], axis=-1\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  if axis_angle.shape != (3,):\n    raise ValueError(\n        f'axis_angle must be a 3-vector, got shape {axis_angle.shape}.'\n    )\n\n  axis_angle = jnp.asarray(axis_angle)\n  axis, angle = axis_angle[:3], axis_angle[3]\n  axis = axis / _safe_sqrt(jnp.sum(axis**2))\n  angle = jnp.clip(angle, -jnp.pi, jnp.pi)\n  half_angle = angle / 2.0\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n  return jnp.concatenate(\n      [axis * sin_half_angle, jnp.array([cos_half_angle])], axis=0\n  )\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis, angle = axis_angle[..., :3], axis_angle[..., 3:]\n  angle = jnp.expand_dims(angle, axis=-1)\n  angle = jnp.tile(angle, [1] * (len(axis.shape) - 1) + [3])\n  axis = jnp.divide(axis, _safe_sqrt(jnp.sum(axis**2, axis=-1, keepdims=True)))\n  w = jnp.cos(angle / 2.0)\n  xyz = jnp.sin(angle / 2.0) * axis\n  return jnp.concatenate((xyz, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Ensure the axis is a unit vector.\n  axis = axis_angle / linalg.norm(axis_angle)\n  # Compute the angle.\n  angle = linalg.norm(axis_angle)\n  # Compute the half angle.\n  half_angle = 0.5 * angle\n  # Compute the half angle sine and cosine.\n  half_angle_sin = jnp.sin(half_angle)\n  half_angle_cos = jnp.cos(half_angle)\n  # Compute the quaternion components.\n  w = half_angle_cos\n  xyz = axis * half_angle_sin\n  # Return the quaternion.\n  return jnp.concatenate((xyz, w), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  half_angle = 0.5 * angle\n  half_angle_sin = jnp.sin(half_angle)\n  half_angle_cos = jnp.cos(half_angle)\n  return jnp.concatenate(\n      [half_angle_sin * axis, jnp.array([half_angle_cos])], axis=-1\n  )"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n\n  # Ensure axis_angle is a 3-vector\n  if len(axis_angle.shape) != 1 or axis_angle.shape[0] != 3:\n    raise ValueError(\"axis_angle must be a 3-vector\")\n\n  # Calculate the norm of the axis\n  axis_norm = jnp.linalg.norm(axis_angle)\n\n  # If the norm is close to zero, return the identity quaternion\n  if axis_norm < eps:\n    return identity()\n\n  # Calculate the half angle and the half axis\n  half_angle = 0.5 * axis_norm\n  half_axis = axis_angle / axis_norm\n\n  # Calculate the quaternion components\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * half_axis\n\n  # Return the quaternion\n  return jnp.concatenate([xyz, w], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[..., :3]\n  angle = axis_angle[..., 3:]\n\n  half_angle = 0.5 * angle\n  sin_half_angle = jnp.sin(half_angle)\n  cos_half_angle = jnp.cos(half_angle)\n\n  # Normalize the axis vector\n  axis_norm = jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  axis_norm = jnp.maximum(axis_norm, eps * jnp.ones_like(axis_norm))\n  axis_normalized = axis / axis_norm\n\n  # Calculate the quaternion components\n  w = cos_half_angle\n  xyz = axis_normalized * sin_half_angle\n\n  # Concatenate the components to form the quaternion\n  q = jnp.concatenate([xyz, w], axis=-1)\n\n  return q"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = jnp.split(axis_angle, 2, axis=-1)\n  half_angle = angle / 2.0\n  s = jnp.sin(half_angle)\n  c = jnp.cos(half_angle)\n  # To ensure numerical stability for small angles, we use a small epsilon value.\n  s = jnp.where(jnp.abs(s) < eps, jnp.zeros_like(s), s)\n  c = jnp.where(jnp.abs(c) < eps, jnp.ones_like(c), c)\n  return jnp.concatenate((s * axis, c), axis=-1)"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n        logit_bias[idx] *= 2\n\n    # binary search\n    low = 0\n    while high >= low + 1e-8:\n        mid = (high + low) / 2\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n            high = mid\n        else:\n            low = mid\n\n    return math.log(model.topk(prefix, logit_bias)[idx]), 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # initialize high\n    num_calls = k\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    num_calls = k\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return math.log(model.topk(prefix, logit_bias)[idx]) - math.log(mid), 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    num_calls = k\n    while model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n    logprob = model.topk(prefix, logit_bias)[idx]\n    return logprob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get topk\n    topk_words = model.topk(prefix, k=k)\n\n    # check if idx is in topk\n    if idx in topk_words:\n        return topk_words[idx], 1\n\n    # initialize high\n    num_calls = 1\n    while idx not in topk_words:\n        topk_words = model.topk(prefix, logit_bias={idx: high}, k=k)\n        high *= 2\n        num_calls += 1\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        topk_words = model.topk(prefix, logit_bias={idx: mid}, k=k)\n        if idx in topk_words:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += 1\n\n    return topk_words[idx], num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while high > 0:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            high //= 2\n        else:\n            high -= 1\n        num_calls += k\n    return -high, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    if idx in topk_words:\n        return topk_words[idx], 1\n    else:\n        # if not in topk, increase bias until it is\n        while idx not in topk_words:\n            logit_bias[idx] *= 2\n            topk_words = model.topk(prefix, logit_bias)\n        return topk_words[idx], 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[idx] < 0:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # binary search\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[idx] < 0:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return math.log(model.topk(prefix, logit_bias)[idx]), 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, k=k)\n    topk_idxs = list(topk_words.keys())\n\n    # check if idx is in topk\n    if idx in topk_idxs:\n        return topk_words[idx], 1\n\n    # initialize high\n    num_calls = 1\n    logit_bias = {idx: high}\n    while idx not in model.topk(prefix, logit_bias, k=k):\n        logit_bias[idx] *= 2\n        num_calls += 1\n\n    # improve estimate\n    low = 0\n    while high >= low + 1e-8:\n        logit_bias[idx] = (high + low) / 2\n        if idx in model.topk(prefix, logit_bias, k=k):\n            high = logit_bias[idx]\n        else:\n            low = logit_bias[idx]\n        num_calls += 1\n\n    return topk_words[idx], num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n    log_prob = model.logprob(prefix, logit_bias)[idx]\n    return log_prob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    num_calls = k\n\n    while topk_words[0] != idx:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += k\n\n    # bisection search\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += k\n        if topk_words[0] == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n\n    return math.log(topk_words[idx]) - mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # initialize high\n    logit_bias = {idx: high}\n    while model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.topk(prefix, logit_bias)[idx] < model.topk(prefix)[idx]:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return math.log(model.topk(prefix, logit_bias)[idx]), 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    num_calls = k\n    while idx not in topk_words:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += k\n    topk_logprobs = np.array([topk_words[i] for i in topk_words])\n    topk_logprobs -= np.logaddexp.reduce(topk_logprobs)\n    return topk_logprobs[idx], num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    if idx in topk_words:\n        return topk_words[idx], 1\n    else:\n        while idx not in topk_words:\n            logit_bias[idx] *= 2\n            topk_words = model.topk(prefix, logit_bias)\n        return topk_words[idx], 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk = model.topk(prefix, k=k)\n    num_calls = k\n\n    # check if idx is the argmax\n    if topk[0][0] == idx:\n        return math.log(topk[0][1]), num_calls\n\n    # initialize high\n    while topk[0][0] != idx:\n        topk = model.topk(prefix, logit_bias={idx: high}, k=k)\n        num_calls += k\n        high *= 2\n\n    # improve estimate\n    low = 0\n    mid = high / 2\n    while high >= low + 1e-8:\n        topk = model.topk(prefix, logit_bias={idx: mid}, k=k)\n        num_calls += k\n        if topk[0][0] == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return math.log(topk[0][1]) - mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    topk_idxs = list(topk_words.keys())\n    topk_logprobs = list(topk_words.values())\n\n    # get top-k logprobs and indices\n    topk_idxs = topk_idxs[:k]\n    topk_logprobs = topk_logprobs[:k]\n\n    # check if idx is in topk\n    if idx in topk_idxs:\n        return topk_logprobs[topk_idxs.index(idx)], 1\n\n    # otherwise, find the bias that makes it the topk\n    topk_logprobs = np.array(topk_logprobs)\n    log_topk_prob = logsumexp(topk_logprobs)\n    logprobs = topk_logprobs - np.logaddexp(\n        high + np.log1p(-np.exp(log_topk_prob)), log_topk_prob\n    )\n    return logprobs[topk_idxs.index(idx)], 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = k\n    topk_words = model.topk(prefix, k=k)\n    topk_idxs = list(topk_words.keys())\n    if idx in topk_idxs:\n        return topk_words[idx], num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while idx not in topk_idxs:\n        logit_bias[idx] *= 2\n        num_calls += k\n        topk_words = model.topk(prefix, logit_bias, k=k)\n        topk_idxs = list(topk_words.keys())\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        num_calls += k\n        topk_words = model.topk(prefix, logit_bias, k=k)\n        topk_idxs = list(topk_words.keys())\n        if idx in topk_idxs:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return topk_words[idx], num_calls\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return resample_3d_trilinear(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return resample_3d_nearest(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  else:\n    raise ValueError('Invalid method: {}'.format(method))\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # Check if the edge behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('edge_behavior must be either CONSTANT_OUTSIDE or CLAMP')\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST')\n\n  # Check if the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx')\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST')\n\n  # Check if the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx')\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST')\n\n  # Check if the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx')\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST')\n\n  # Check if the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx')\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST')\n\n  # Check if the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx')\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST')\n\n  # Check if the coordinate order is valid"}
{"namespace": "resample.resample_3d", "completion": "  # Check that the data is a 4D tensor\n  if len(data.shape) != 4:\n    raise ValueError('Data must be a 4D tensor.')\n\n  # Check that the locations are a 3D tensor\n  if len(locations.shape) != 3:\n    raise ValueError('Locations must be a 3D tensor.')\n\n  # Check that the method is valid\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Invalid method.')\n\n  # Check that the edge_behavior is valid\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Invalid edge_behavior.')\n\n  # Check that the coordinate_order is valid\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Invalid coordinate_order.')\n\n  # Check that the data is a 4D tensor\n  if len(data.shape) != 4:\n    raise ValueError('Data must be a 4D tensor.')\n\n  # Check that the locations are a 3D tensor\n  if len(locations.shape) != 3:\n    raise ValueError('Locations must be a 3D tensor.')\n\n  # Check that the method is valid\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Invalid method.')\n\n  # Check that the edge_behavior is valid\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Invalid edge_behavior.')\n\n  # Check that the coordinate_order is valid\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Invalid coordinate_order.')\n\n  # Check that the data is a 4D tensor\n  if len(data.shape) != 4:\n    raise ValueError('Data must be a 4D tensor.')\n\n  # Check that the locations are a 3D tensor\n  if len(locations.shape) != 3:\n    raise ValueError('Locations must be a 3D tensor.')\n\n  # Check that the method is valid\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Invalid method.')\n\n  # Check that the edge_behavior is valid\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Invalid edge_behavior.')\n\n  # Check that the coordinate_order is valid\n  if coordinate_"}
{"namespace": "resample.resample_3d", "completion": "  # Check the shape of the data and locations tensors.\n  if data.ndim != 4:\n    raise ValueError('data must be a 4D tensor.')\n  if locations.ndim < 3:\n    raise ValueError('locations must be a 3D or higher tensor.')\n\n  # Check the interpolation method.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST.')\n\n  # Check the edge behavior.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('edge_behavior must be either CONSTANT_OUTSIDE or CLAMP.')\n\n  # Check the coordinate order.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx.')\n\n  # Check the half_pixel_center flag.\n  if not isinstance(half_pixel_center, bool):\n    raise ValueError('half_pixel_center must be a boolean value.')\n\n  # Check the constant_values.\n  if not isinstance(constant_values, float):\n    raise ValueError('constant_values must be a float.')\n\n  # Check the shape of the data and locations tensors.\n  if data.ndim != 4:\n    raise ValueError('data must be a 4D tensor.')\n  if locations.ndim < 3:\n    raise ValueError('locations must be a 3D or higher tensor.')\n\n  # Check the interpolation method.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either TRILINEAR or NEAREST.')\n\n  # Check the edge behavior.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('edge_behavior must be either CONSTANT_OUTSIDE or CLAMP.')\n\n  # Check the coordinate order.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either xyz or zyx.')\n\n  # Check the half_pixel_center flag.\n  if not isinstance(half_pixel_center, bool):\n    raise ValueError('half_pixel_center must be a boolean value.')\n\n  # Check the constant_values.\n  if not isinstance(constant_values, float):\n    raise ValueError('constant_values must be a float.')\n\n  # Pad the data if needed.\n  if"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Adjust for half-pixel centering.\n  if half_pixel_center:\n    x_coordinate += 0.5\n    y_coordinate += 0.5\n    z_coordinate += 0.5\n\n  # Get the shape of the data.\n  shape = data.shape\n\n  # Pad the data if necessary.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, ((0, 0), (1, 1), (1, 1), (0, 0)), constant_values=constant_values)\n    x_coordinate += 1\n    y_coordinate += 1\n    z_coordinate += 0\n\n  # Clamp the coordinates to the valid range.\n  x_coordinate = jnp.clip(x_coordinate, 0, shape[3] - 1)\n  y_coordinate = jnp.clip(y_coordinate, 0, shape[2] - 1)\n  z_coordinate = jnp.clip(z_coordinate, 0, shape[1] - 1)\n\n  # Get the floor and ceil coordinates.\n  x_floor = jnp.floor(x_coordinate).astype(jnp.int32)\n  y_floor = jnp.floor(y_coordinate).astype(jnp.int32)\n  z_floor = jnp.floor(z_coordinate).astype(jnp.int32)\n  x_ceil = jnp.ceil(x_coordinate).astype(jnp.int32)\n  y_ceil = jnp.ceil(y_coordinate).astype(jnp.int32)\n  z_ceil = jnp.ceil(z_coordinate).astype(jnp.int32)\n\n  # Compute the fractional parts of the coordinates.\n  x_frac = x_coordinate - x_floor\n  y_frac"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the data with the specified constant values.\n    data = jnp.pad(data, [(1, 1), (1, 1), (1, 1), (0, 0)], mode='constant', constant_values=constant_values)\n    # Adjust the coordinates to account for the padding.\n    x_coordinate += 1\n    y_coordinate += 1\n    z_coordinate += 1\n\n  # Clip the coordinates to the valid range.\n  x_coordinate = jnp.clip(x_coordinate, 0, data.shape[3] - 1)\n  y_coordinate = jnp.clip(y_coordinate, 0, data.shape[2] - 1)\n  z_coordinate = jnp.clip(z_coordinate, 0, data.shape[1] - 1)\n\n  if half_pixel_center:\n    # Adjust the coordinates to account for half-pixel centering.\n    x_coordinate += 0.5\n    y_coordinate += 0.5\n    z_coordinate += 0.5\n\n  if method == 'NEAREST':\n    # Use nearest neighbor interpolation.\n    return data[z_coordinate.astype(jnp.int32), y_coordinate.astype(jnp.int32), x_coordinate.astype(jnp.int32)]\n  elif method == 'TRILINEAR':\n    # Use trilinear interpolation.\n    x_floor = jnp.floor(x_coordinate)\n    x_ceil = jnp.ceil(x_coordinate)\n    y_floor = jnp.floor(y_coordinate)\n    y_ceil = jnp.ceil(y_coordinate)\n    z_floor = jnp.floor(z_coordinate)\n    z_ceil = jnp.ceil(z_coordinate)\n\n    x"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if half_pixel_center:\n    x_coordinate += 0.5\n    y_coordinate += 0.5\n    z_coordinate += 0.5\n\n  # Pad the data if necessary\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(\n        data,\n        ((1, 1), (1, 1), (1, 1), (0, 0)),\n        mode='constant',\n        constant_values=constant_values)\n    x_coordinate += 1\n    y_coordinate += 1\n    z_coordinate += 1\n\n  # Check if the coordinates are within the bounds of the data\n  x_within_bounds = jnp.logical_and(\n      jnp.greater_equal(x_coordinate, 0),\n      jnp.less(x_coordinate, data.shape[2]))\n  y_within_bounds = jnp.logical_and(\n      jnp.greater_equal(y_coordinate, 0),\n      jnp.less(y_coordinate, data.shape[1]))\n  z_within_bounds = jnp.logical_and(\n      jnp.greater_equal(z_coordinate, 0),\n      jnp.less(z_coordinate, data.shape[0]))\n\n  # Clamp the coordinates to the bounds of the data\n  if edge_behavior == 'CLAMP':\n    x_coordinate = jnp.clip(x_coordinate, 0, data.shape[2] - 1)\n    y_coordinate = jnp.clip(y_coordinate, 0, data.shape[1] - 1)\n    z_coordinate = jnp.clip(z_coordinate, 0, data.shape[0] - 1)\n\n  # Use Advanced indexing to gather data data.\n  if method == 'NEAREST':\n    return data[z_coordinate, y"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), constant_values=constant_values)\n      locations = locations + 1\n    elif edge_behavior == 'CLAMP':\n      pass\n    else:\n      raise ValueError(f'Unknown edge behavior: {edge_behavior}')\n\n    if half_pixel_center:\n      locations = locations + 0.5\n\n    # Get the coordinates of the 8 corners of the cube surrounding the sample point.\n    x_coordinate = jnp.floor(locations[Ellipsis, 0])\n    y_coordinate = jnp.floor(locations[Ellipsis, 1])\n    z_coordinate = jnp.floor(locations[Ellipsis, 2])\n\n    # Get the fractional coordinates of the sample point within the cube.\n    x_fraction = locations[Ellipsis, 0] - x_coordinate\n    y_fraction = locations[Ellipsis, 1] - y_coordinate\n    z_fraction = locations[Ellipsis, 2] - z_coordinate\n\n    # Get the coordinates of the 8 corners of the cube surrounding the sample point.\n    x_coordinate = x_coordinate.astype(jnp.int32)\n    y_coordinate = y_coordinate.astype(jnp.int32)\n    z_coordinate = z_coordinate.astype(jnp.int32)\n\n    # Get the values of the 8 corners of the cube surrounding the sample point.\n    c000 = data[z_coordinate, y_coordinate, x_coordinate]\n    c001 = data[z_coordinate, y_coordinate, x_coordinate + 1]\n    c010 = data[z_coordinate, y_coordinate + 1, x_coordinate]\n    c011 = data[z_coordinate, y_coordinate + 1, x_coordinate + 1]\n    c100 = data[z_coordinate + 1, y_coordinate, x_coordinate]\n    c101 = data[z_coordinate + 1, y_coordinate, x_coordinate + 1]\n    c110 = data[z_coordinate + 1"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    return gather_volume(data, jnp.round(locations).astype(jnp.int32), coordinate_order)\n\n  # Pad the data to handle edge cases.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    pad_width = [(0, 0), (1, 1), (1, 1), (0, 0)]\n    data = jnp.pad(data, pad_width, constant_values=constant_values)\n    locations = locations + 1\n\n  # Calculate the sample locations.\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Split the locations into x, y, and z components.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Calculate the fractional parts of the coordinates.\n  x_fraction = x_coordinate - jnp.floor(x_coordinate)\n  y_fraction = y_coordinate - jnp.floor(y_coordinate)\n  z_fraction = z_coordinate - jnp.floor(z_coordinate)\n\n  # Calculate the integer parts of the coordinates.\n  x_coordinate_int = jnp.floor(x_coordinate).astype(jnp.int32)\n  y_coordinate_int = jnp.floor(y_coordinate).astype(jnp.int32)\n  z_coordinate_int = jnp.floor(z_coordinate).astype(jnp.int32)\n\n  # Get the data at the integer coordinates.\n  data_000 = data[z_coordinate_int, y_coordinate_int, x_coordinate_int]\n  data_001 = data[z_coordinate_int, y_coordinate_int, x_coordinate_int + 1]\n  data_010 = data[z_coordinate_int, y_coordinate_int + 1, x_coordinate_int]\n "}
{"namespace": "resample.resample_3d", "completion": "  # Get the shape of the data and locations.\n  data_shape = data.shape\n  locations_shape = locations.shape\n\n  # Check if the shape of the data is 4-dimensional.\n  if len(data_shape) != 4:\n    raise ValueError(\n        'The input data must be a 4-dimensional tensor with shape [D, H, W, C].'\n    )\n\n  # Check if the shape of the locations is at least 3-dimensional.\n  if len(locations_shape) < 3:\n    raise ValueError(\n        'The input locations must be at least a 3-dimensional tensor with shape [D, ..., 3].'\n    )\n\n  # Check if the last dimension of the locations is 3.\n  if locations_shape[-1] != 3:\n    raise ValueError(\n        'The last dimension of the locations must be 3, representing the x, y, and z coordinates.'\n    )\n\n  # Check if the edge_behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'The edge_behavior must be either \"CONSTANT_OUTSIDE\" or \"CLAMP\".'\n    )\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('The method must be either \"TRILINEAR\" or \"NEAREST\".')\n\n  # Check if the coordinate_order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('The coordinate_order must be either \"xyz\" or \"zyx\".')\n\n  # Check if the half_pixel_center is valid.\n  if not isinstance(half_pixel_center, bool):\n    raise ValueError('The half_pixel_center must be a boolean value.')\n\n  # Check if the data is a float32 or float64 tensor.\n  if not (data.dtype == jnp.float32 or data.dtype == jnp.float64):\n    raise ValueError('The data must be a float32 or float64 tensor.')\n\n  # Check if the locations is a float32 or float64 tensor.\n  if not (locations.dtype == jnp.float32 or locations.dtype == jnp.float64):\n    raise ValueError('The locations must be a"}
{"namespace": "resample.resample_3d", "completion": "  # Determine the shape of the input data.\n  data_shape = data.shape\n\n  # Pad the data if edge_behavior is set to CONSTANT_OUTSIDE.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n\n  # Adjust the locations based on the edge behavior and half-pixel centering.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    locations = locations + 1.0\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Adjust the locations based on the coordinate order.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Clamp the locations to the volume if edge_behavior is set to CLAMP.\n  if edge_behavior == 'CLAMP':\n    x_coordinate = jnp.clip(x_coordinate, 0, data_shape[3] - 1)\n    y_coordinate = jnp.clip(y_coordinate, 0, data_shape[2] - 1)\n    z_coordinate = jnp.clip(z_coordinate, 0, data_shape[1] - 1)\n\n  # Calculate the floor and ceil of the locations.\n  x_floor = jnp.floor(x_coordinate)\n  y_floor = jnp.floor(y_coordinate)\n  z_floor = jnp.floor(z_coordinate)\n  x_ceil = jnp.ceil(x_coordinate)\n  y_ceil = jnp.ceil(y_coordinate)\n  z_ceil = jnp.ceil(z_coordinate)\n\n  # Calculate the interpolation weights.\n  x_weight = x_coordinate - x_floor\n  y_weight = y_coordinate - y_floor\n  z_weight = z_coordinate -"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the data with the constant values\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n    locations = locations + 1  # Adjust for the padding\n\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the volume boundaries\n    locations = jnp.clip(locations, 0, data.shape[:3] - 1)\n\n  else:\n    raise ValueError(f'Invalid edge_behavior: {edge_behavior}')\n\n  if method == 'TRILINEAR':\n    # Trilinear interpolation\n    # Calculate the fractional coordinates\n    if half_pixel_center:\n      # Adjust for half-pixel centering\n      locations = locations + 0.5\n    x_frac = locations[Ellipsis, 0] - jnp.floor(locations[Ellipsis, 0])\n    y_frac = locations[Ellipsis, 1] - jnp.floor(locations[Ellipsis, 1])\n    z_frac = locations[Ellipsis, 2] - jnp.floor(locations[Ellipsis, 2])\n\n    # Calculate the integer coordinates\n    x_coord = jnp.floor(locations[Ellipsis, 0]).astype(jnp.int32)\n    y_coord = jnp.floor(locations[Ellipsis, 1]).astype(jnp.int32)\n    z_coord = jnp.floor(locations[Ellipsis, 2]).astype(jnp.int32)\n\n    # Calculate the weights\n    w000 = (1 - x_frac) * (1 - y_frac) * (1 - z_frac)\n    w001 = (1 - x_frac) * (1 - y_frac) * z_frac\n    w010 = (1 - x_frac) * y_frac * (1 - z_frac)\n    w011 = (1 - x_frac) * y_frac * z_frac\n    w100 = x_frac * (1 - y_frac) * (1 - z_frac)\n    w101 = x_frac * (1 -"}
{"namespace": "resample.resample_3d", "completion": "  # Check the edge behavior and method inputs.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        f'Invalid edge behavior: {edge_behavior}. Must be one of \"CONSTANT_OUTSIDE\" or \"CLAMP\".'\n    )\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        f'Invalid method: {method}. Must be one of \"TRILINEAR\" or \"NEAREST\".'\n    )\n\n  # Check the coordinate order and half-pixel centering inputs.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        f'Invalid coordinate order: {coordinate_order}. Must be one of \"xyz\" or \"zyx\".'\n    )\n  if half_pixel_center not in [True, False]:\n    raise ValueError(\n        f'Invalid half-pixel centering: {half_pixel_center}. Must be True or False.'\n    )\n\n  # Check the shape of the data and locations.\n  data_shape = data.shape\n  locations_shape = locations.shape\n  if len(data_shape) != 4:\n    raise ValueError(\n        f'Invalid data shape: {data_shape}. Must be a 4D tensor with shape [D, H, W, C].'\n    )\n  if len(locations_shape) < 3:\n    raise ValueError(\n        f'Invalid locations shape: {locations_shape}. Must be at least 3D with shape [D, ..., 3].'\n    )\n  if locations_shape[-1] != 3:\n    raise ValueError(\n        f'Invalid locations shape: {locations_shape}. Must be at least 3D with shape [D, ..., 3].'\n    )\n\n  # Check the data type of the locations.\n  if locations.dtype != jnp.float32:\n    raise ValueError(\n        f'Invalid locations dtype: {locations.dtype}. Must be float32.'\n    )\n\n  # Check the data type of the constant values.\n  if constant_values.dtype != jnp.float32:\n    raise ValueError(\n        f'Invalid constant values dtype: {constant_values.dtype}. Must be float32.'\n    )\n\n  # Get the shape of the data and locations.\n  data_shape = data.shape\n  locations"}
{"namespace": "resample.resample_3d", "completion": "  # Get the shape of the input data\n  shape = data.shape\n\n  # Check if the shape is valid\n  if len(shape) != 4:\n    raise ValueError(\n        'Input data must have shape [D, H, W, C], got shape {}'.format(shape))\n\n  # Get the number of channels in the data\n  channels = shape[-1]\n\n  # Check if the number of channels is valid\n  if channels < 1:\n    raise ValueError('Input data must have at least one channel, got {}'.\n                     format(channels))\n\n  # Check if the locations are valid\n  if len(locations.shape) < 3:\n    raise ValueError(\n        'Locations must have shape [D, ..., 3], got shape {}'.format(\n            locations.shape))\n\n  # Check if the method is valid\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be either TRILINEAR or NEAREST, got {}'.\n                     format(method))\n\n  # Check if the edge behavior is valid\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Edge behavior must be either CONSTANT_OUTSIDE or CLAMP, '\n                     'got {}'.format(edge_behavior))\n\n  # Check if the coordinate order is valid\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be either xyz or zyx, got {}'.\n                     format(coordinate_order))\n\n  # Check if the half-pixel centering is valid\n  if not isinstance(half_pixel_center, bool):\n    raise ValueError('Half-pixel centering must be a boolean, got {}'.format(\n        half_pixel_center))\n\n  # Get the shape of the locations\n  locations_shape = locations.shape\n\n  # Get the number of dimensions in the locations\n  num_dims = len(locations_shape) - 1\n\n  # Get the number of samples\n  num_samples = np.prod(locations_shape[:-1])\n\n  # Check if the number of samples is valid\n  if num_samples < 1:\n    raise ValueError('Locations must have at least one sample, got {}'.format(\n        num_samples))\n\n  # Reshape the locations to a 2D tensor with shape [num_samples, 3]\n  locations = locations.reshape([num_samples, 3])\n\n  # Check if"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the input volume with constant values\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), constant_values=constant_values)\n    # Adjust the locations to account for the padding\n    locations += 1\n    # Adjust for half-pixel centering\n    if half_pixel_center:\n      locations -= 0.5\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the valid range\n    locations = jnp.clip(locations, 0, data.shape[0] - 1)\n    # Adjust for half-pixel centering\n    if half_pixel_center:\n      locations -= 0.5\n  else:\n    raise ValueError(f'Invalid edge_behavior: {edge_behavior}')\n\n  if method == 'TRILINEAR':\n    # Calculate the fractional part of the locations\n    fractional_part = locations % 1\n    # Calculate the integer part of the locations\n    integer_part = locations.astype(jnp.int32)\n\n    # Gather the corner values\n    corner_values = gather_volume(data, integer_part, coordinate_order)\n    # Calculate the trilinear interpolation weights\n    weights = jnp.prod(jnp.stack([1 - fractional_part, fractional_part], axis=-1), axis=-1)\n    # Apply trilinear interpolation\n    output = jnp.sum(corner_values * weights, axis=-1)\n\n  elif method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the nearest values\n    output = gather_volume(data, rounded_locations, coordinate_order)\n\n  else:\n    raise ValueError(f'Invalid interpolation method: {method}')\n\n  return output\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the volume with the specified constant values.\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), 'constant', constant_values=constant_values)\n    locations += 1\n\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the volume boundaries.\n    locations = jnp.clip(locations, 0, data.shape[:3] - 1)\n\n  if half_pixel_center:\n    # Adjust the locations for half-pixel centering.\n    locations += 0.5\n\n  # Extract the shape of the data and locations.\n  data_shape = data.shape\n  locations_shape = locations.shape\n\n  # Reshape the data and locations to a 2D array.\n  data = data.reshape((-1, data_shape[-1]))\n  locations = locations.reshape((-1, 3))\n\n  # Calculate the floor and ceil coordinates of the locations.\n  floor_coordinates = jnp.floor(locations).astype(jnp.int32)\n  ceil_coordinates = jnp.ceil(locations).astype(jnp.int32)\n\n  # Calculate the fractional offsets of the locations.\n  fractional_offsets = locations - floor_coordinates\n\n  # Gather the data at the floor and ceil coordinates.\n  floor_data = gather_volume(data, floor_coordinates, coordinate_order)\n  ceil_data = gather_volume(data, ceil_coordinates, coordinate_order)\n\n  if method == 'TRILINEAR':\n    # Perform trilinear interpolation.\n    interpolated_data = (\n        (1 - fractional_offsets[:, 0]) * (1 - fractional_offsets[:, 1]) * (1 - fractional_offsets[:, 2]) * floor_data +\n        fractional_offsets[:, 0] * (1 - fractional_offsets[:, 1]) * (1 - fractional_offsets[:, 2]) * ceil_data[Ellipsis, 0] +\n        (1 - fractional_offsets[:, 0]) * fractional_offsets[:, 1] * (1 - fractional_offsets[:, 2]) * ceil_data[Ellipsis, 1] +\n        fractional_offsets[:, "}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Use nearest neighbor interpolation\n    return gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # Use trilinear interpolation\n    if coordinate_order == 'xyz':\n      x_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      z_coordinate = locations[Ellipsis, 2]\n    elif coordinate_order == 'zyx':\n      z_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      x_coordinate = locations[Ellipsis, 2]\n\n    # Calculate the fractional part of the coordinates\n    x_fractional = x_coordinate - jnp.floor(x_coordinate)\n    y_fractional = y_coordinate - jnp.floor(y_coordinate)\n    z_fractional = z_coordinate - jnp.floor(z_coordinate)\n\n    # Calculate the indices for the eight nearest neighbors\n    x_indices = jnp.array([0, 1])\n    y_indices = jnp.array([0, 1])\n    z_indices = jnp.array([0, 1])\n\n    # Create a grid of indices\n    x_grid, y_grid, z_grid = jnp.meshgrid(x_indices, y_indices, z_indices,\n                                          indexing='ij')\n\n    # Calculate the weights for the eight nearest neighbors\n    weights = (1 - x_fractional)[:, None, None] * (\n        1 - y_fractional)[:, None] * (1 - z_fractional)\n    weights = weights[Ellipsis, None]\n\n    # Create a grid of indices\n    x_grid, y_grid, z_grid = jnp.meshgrid(x_indices, y_indices, z_indices,\n                                          indexing='ij')\n\n    # Calculate the indices for the eight nearest neighbors\n    x_indices = x_coordinate[:, None, None, None] + x_grid[None]\n    y_indices = y_coordinate[:, None, None, None] + y_grid[None]\n    z_indices = z_coordinate[:, None, None, None] + z_grid[None]\n\n    # Gather the values at the eight nearest neighbors\n    values = data["}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    return gather_volume(data, locations, coordinate_order)\n\n  # Check if the edge behavior is 'CONSTANT_OUTSIDE' and pad the data if necessary.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the data with the constant value.\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)),\n                   mode='constant',\n                   constant_values=constant_values)\n\n  # Compute the sample locations.\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Compute the sample locations in z, y, x order.\n  if coordinate_order == 'xyz':\n    x_coordinate = jnp.round(locations[Ellipsis, 0]).astype(jnp.int32)\n    y_coordinate = jnp.round(locations[Ellipsis, 1]).astype(jnp.int32)\n    z_coordinate = jnp.round(locations[Ellipsis, 2]).astype(jnp.int32)\n  elif coordinate_order == 'zyx':\n    z_coordinate = jnp.round(locations[Ellipsis, 0]).astype(jnp.int32)\n    y_coordinate = jnp.round(locations[Ellipsis, 1]).astype(jnp.int32)\n    x_coordinate = jnp.round(locations[Ellipsis, 2]).astype(jnp.int32)\n\n  # Compute the interpolation weights.\n  x_weights = locations[Ellipsis, 0] - x_coordinate\n  y_weights = locations[Ellipsis, 1] - y_coordinate\n  z_weights = locations[Ellipsis, 2] - z_coordinate\n\n  # Compute the interpolation weights for the corners.\n  x0_weights = 1.0 - x_weights\n  y0_weights = 1.0 - y_weights\n  z0_weights = 1.0 - z_weights\n  x1_weights = x_weights\n  y1_weights = y_weights\n  z1_weights = z_weights\n\n  # Compute the interpolation weights for the edges.\n  x0y0_weights = x0_weights * y0_weights\n  x0"}
{"namespace": "resample.resample_3d", "completion": "  # Check the method argument.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(f'Invalid method {method}')\n\n  # Check the edge_behavior argument.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(f'Invalid edge_behavior {edge_behavior}')\n\n  # Check the coordinate_order argument.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(f'Invalid coordinate_order {coordinate_order}')\n\n  # Check the data shape.\n  if len(data.shape) != 4:\n    raise ValueError(f'Invalid data shape {data.shape}')\n\n  # Check the locations shape.\n  if len(locations.shape) < 3:\n    raise ValueError(f'Invalid locations shape {locations.shape}')\n\n  # Check the locations dtype.\n  if locations.dtype != np.float32:\n    raise ValueError(f'Invalid locations dtype {locations.dtype}')\n\n  # Check the constant_values argument.\n  if constant_values.dtype != np.float32:\n    raise ValueError(f'Invalid constant_values dtype {constant_values.dtype}')\n\n  # Check the half_pixel_center argument.\n  if not isinstance(half_pixel_center, bool):\n    raise ValueError(f'Invalid half_pixel_center {half_pixel_center}')\n\n  # Get the data shape and locations shape.\n  data_shape = data.shape\n  locations_shape = locations.shape\n\n  # Get the number of dimensions and channels.\n  ndim = len(data_shape) - 1\n  nchannels = data_shape[-1]\n\n  # Reshape the locations to a 3D tensor.\n  locations = locations.reshape((-1, 3))\n\n  # Pad the data with zeros if necessary.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [(0, 0), (1, 1), (1, 1), (0, 0)], mode='constant')\n\n  # Calculate the sample locations.\n  if half_pixel_center:\n    sample_locations = locations + 0.5\n  else:\n    sample_locations = locations\n\n  # Get the sample coordinates.\n  if coordinate_order == 'xyz':\n    x_coordinate = jnp.round("}
{"namespace": "resample.resample_3d", "completion": "  # Check if edge_behavior is valid\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'edge_behavior must be either \"CONSTANT_OUTSIDE\" or \"CLAMP\".')\n\n  # Check if method is valid\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either \"TRILINEAR\" or \"NEAREST\".')\n\n  # Check if coordinate_order is valid\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('coordinate_order must be either \"xyz\" or \"zyx\".')\n\n  # Check if data is a 4D tensor\n  if len(data.shape) != 4:\n    raise ValueError('data must be a 4D tensor.')\n\n  # Check if locations is a 3D tensor\n  if len(locations.shape) != 3:\n    raise ValueError('locations must be a 3D tensor.')\n\n  # Check if locations is a floating point tensor\n  if not jnp.issubdtype(locations.dtype, np.floating):\n    raise ValueError('locations must be a floating point tensor.')\n\n  # Check if data and locations have the same batch dimension\n  if data.shape[0] != locations.shape[0]:\n    raise ValueError('data and locations must have the same batch dimension.')\n\n  # Check if data and locations have the same number of channels\n  if data.shape[-1] != locations.shape[-1]:\n    raise ValueError('data and locations must have the same number of '\n                     'channels.')\n\n  # Check if method is TRILINEAR\n  if method == 'TRILINEAR':\n    # Calculate the interpolation weights\n    if half_pixel_center:\n      # If half-pixel centering is used, adjust the locations\n      locations = locations - 0.5\n    weights = locations - jnp.floor(locations)\n    weights_1 = 1.0 - weights\n\n    # Calculate the indices for the 8 nearest voxels\n    indices = jnp.floor(locations).astype(jnp.int32)\n\n    # Calculate the indices for the 8 nearest voxels\n    indices_000 = indices\n    indices_001 = jnp.concatenate([indices[..., 0:1], indices[..., 1:2],\n                                   indices[..., 2:3] + "}
{"namespace": "math.plus_eps", "completion": "  if jnp.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, jnp.inf)\n\n"}
{"namespace": "math.plus_eps", "completion": "  if jnp.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, jnp.inf)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf)\n  )\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  if jnp.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, jnp.inf)\n\n"}
{"namespace": "math.plus_eps", "completion": "  if np.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, jnp.inf)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  if jnp.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, max_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  if np.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, max_val)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  if jnp.isfinite(x):\n    if jnp.abs(x) < tiny_val:\n      return tiny_val\n    else:\n      return jnp.nextafter(x, jnp.inf)\n  else:\n    return x\n\n"}
{"namespace": "math.plus_eps", "completion": "  # The tiny threshold value is defined as the smallest positive floating-point value that can be represented accurately.\n  tiny = np.finfo(x.dtype).tiny\n  # If x is smaller than the tiny threshold, the threshold value is returned.\n  if jnp.abs(x) < tiny:\n    return tiny\n  # Otherwise, the next floating-point value towards positive infinity is returned.\n  else:\n    return jnp.nextafter(x, jnp.inf)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, max_val))\n\n"}
{"namespace": "math.plus_eps", "completion": "  if jnp.abs(x) < tiny_val:\n    return tiny_val\n  else:\n    return jnp.nextafter(x, max_val)\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), min_val)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), min_val)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: jnp.where(jnp.abs(x) < 100, y * x_dot, 0),\n      (-100, 100),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: x_dot * jnp.exp(x),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: jnp.where(\n          jnp.abs(x) < tiny_val, 0, x_dot * jnp.exp(x)\n      ),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: jnp.where(\n          jnp.abs(x) < 100, x_dot * y, jnp.zeros_like(x_dot)\n      ),\n      (-100, 100),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: jnp.clip(x_dot * jnp.exp(x), min_val, max_val),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, _, x_dot: jnp.where(\n          jnp.abs(x) < 100, x_dot * jnp.exp(x), x_dot\n      ),\n      (-100, 100),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, None))(\n      x\n  )\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, y, x_dot: x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, y, x_dot: x_dot / remove_zero(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, y, x_dot: x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, None))(\n      x\n  )\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val)\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, y, x_dot: x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, None))(\n      x\n  )\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, None))(\n      x\n  )\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, None))(\n      x\n  )\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, y, x_dot: x_dot / remove_zero(x),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, None))(\n      x\n  )\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jnp.log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot * 0.5 * y ** (-0.5),\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, _, x_dot: 0.5 * x_dot / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return jnp.inf\n  elif p == 2:\n    return jnp.inf\n  elif p == 3:\n    return jnp.inf\n  elif p == 4:\n    return jnp.inf\n  elif p == 5:\n    return jnp.inf\n  elif p == 6:\n    return jnp.inf\n  elif p == 7:\n    return jnp.inf\n  elif p == 8:\n    return jnp.inf\n  elif p == 9:\n    return jnp.inf\n  elif p == 10:\n    return jnp.inf\n  elif p == 11:\n    return jnp.inf\n  elif p == 12:\n    return jnp.inf\n  elif p == 13:\n    return jnp.inf\n  elif p == 14:\n    return jnp.inf\n  elif p == 15:\n    return jnp.inf\n  elif p == 16:\n    return jnp.inf\n  elif p == 17:\n    return jnp.inf\n  elif p == 18:\n    return jnp.inf\n  elif p == 19:\n    return jnp.inf\n  elif p == 20:\n    return jnp.inf\n  elif p == 21:\n    return jnp.inf\n  elif p == 22:\n    return jnp.inf\n  elif p == 23:\n    return jnp.inf\n  elif p == 24:\n    return jnp.inf\n  elif p == 25:\n    return jnp.inf\n  elif p == 26:\n    return jnp.inf\n  elif p == 27:\n    return jnp.inf\n  elif p == 28:\n    return jnp.inf\n  elif p == 29:\n    return jnp.inf\n  elif p == 30:\n    return jnp.inf\n  elif p == 31:\n    return jnp.inf\n  elif p == 32:\n    return jnp.inf\n  elif p == 33:\n    return jnp.inf\n  elif p == 34:\n    return jnp.inf\n  elif p == 35:\n    return jnp.inf\n  elif p == 36:"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 0\n  elif p == 0:\n    return 1\n  elif p == 1:\n    return jnp.inf\n  elif p == 2:\n    return jnp.inf\n  elif p == 3:\n    return jnp.inf\n  elif p == 4:\n    return jnp.inf\n  elif p == 5:\n    return jnp.inf\n  elif p == 6:\n    return jnp.inf\n  elif p == 7:\n    return jnp.inf\n  elif p == 8:\n    return jnp.inf\n  elif p == 9:\n    return jnp.inf\n  elif p == 10:\n    return jnp.inf\n  elif p == 11:\n    return jnp.inf\n  elif p == 12:\n    return jnp.inf\n  elif p == 13:\n    return jnp.inf\n  elif p == 14:\n    return jnp.inf\n  elif p == 15:\n    return jnp.inf\n  elif p == 16:\n    return jnp.inf\n  elif p == 17:\n    return jnp.inf\n  elif p == 18:\n    return jnp.inf\n  elif p == 19:\n    return jnp.inf\n  elif p == 20:\n    return jnp.inf\n  elif p == 21:\n    return jnp.inf\n  elif p == 22:\n    return jnp.inf\n  elif p == 23:\n    return jnp.inf\n  elif p == 24:\n    return jnp.inf\n  elif p == 25:\n    return jnp.inf\n  elif p == 26:\n    return jnp.inf\n  elif p == 27:\n    return jnp.inf\n  elif p == 28:\n    return jnp.inf\n  elif p == 29:\n    return jnp.inf\n  elif p == 30:\n    return jnp.inf\n  elif p == 31:\n    return jnp.inf\n  elif p == 32:\n    return jnp.inf\n  elif p == 33:\n    return jnp.inf\n  elif p == 34:\n    return jnp.inf\n  elif p == 35:\n    return j"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return jnp.inf\n  elif p == -1:\n    return 0\n  elif p == 2:\n    return jnp.inf\n  elif p == -2:\n    return 0\n  elif p == 3:\n    return jnp.inf\n  elif p == -3:\n    return 0\n  elif p == 4:\n    return jnp.inf\n  elif p == -4:\n    return 0\n  elif p == 5:\n    return jnp.inf\n  elif p == -5:\n    return 0\n  elif p == 6:\n    return jnp.inf\n  elif p == -6:\n    return 0\n  elif p == 7:\n    return jnp.inf\n  elif p == -7:\n    return 0\n  elif p == 8:\n    return jnp.inf\n  elif p == -8:\n    return 0\n  elif p == 9:\n    return jnp.inf\n  elif p == -9:\n    return 0\n  elif p == 10:\n    return jnp.inf\n  elif p == -10:\n    return 0\n  elif p == 11:\n    return jnp.inf\n  elif p == -11:\n    return 0\n  elif p == 12:\n    return jnp.inf\n  elif p == -12:\n    return 0\n  elif p == 13:\n    return jnp.inf\n  elif p == -13:\n    return 0\n  elif p == 14:\n    return jnp.inf\n  elif p == -14:\n    return 0\n  elif p == 15:\n    return jnp.inf\n  elif p == -15:\n    return 0\n  elif p == 16:\n    return jnp.inf\n  elif p == -16:\n    return 0\n  elif p == 17:\n    return jnp.inf\n  elif p == -17:\n    return 0\n  elif p == 18:\n    return jnp.inf\n  elif p == -18:\n    return 0\n  elif p == 19:\n    return jnp.inf\n  elif p == -19:\n    return 0\n  elif p == 20:\n    return jnp."}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 1\n  elif p == 2:\n    return 1\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 6\n  elif p == 5:\n    return 10\n  elif p == 6:\n    return 15\n  elif p == 7:\n    return 21\n  elif p == 8:\n    return 28\n  elif p == 9:\n    return 36\n  elif p == 10:\n    return 45\n  elif p == 11:\n    return 55\n  elif p == 12:\n    return 66\n  elif p == 13:\n    return 78\n  elif p == 14:\n    return 91\n  elif p == 15:\n    return 105\n  elif p == 16:\n    return 120\n  elif p == 17:\n    return 136\n  elif p == 18:\n    return 153\n  elif p == 19:\n    return 171\n  elif p == 20:\n    return 190\n  elif p == 21:\n    return 210\n  elif p == 22:\n    return 231\n  elif p == 23:\n    return 253\n  elif p == 24:\n    return 276\n  elif p == 25:\n    return 300\n  elif p == 26:\n    return 325\n  elif p == 27:\n    return 351\n  elif p == 28:\n    return 378\n  elif p == 29:\n    return 406\n  elif p == 30:\n    return 435\n  elif p == 31:\n    return 465\n  elif p == 32:\n    return 496\n  elif p == 33:\n    return 528\n  elif p == 34:\n    return 561\n  elif p == 35:\n    return 595\n  elif p == 36:\n    return 630\n  elif p == 37:\n    return 6"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 0\n  elif p == 1:\n    return 1\n  elif p == 2:\n    return np.sqrt(2)\n  elif p == 3:\n    return np.sqrt(3)\n  elif p == 4:\n    return 2\n  elif p == 5:\n    return np.sqrt(5)\n  elif p == 6:\n    return np.sqrt(6)\n  elif p == 7:\n    return np.sqrt(7)\n  elif p == 8:\n    return 2 * np.sqrt(2)\n  elif p == 9:\n    return np.sqrt(9)\n  elif p == 10:\n    return np.sqrt(10)\n  elif p == 11:\n    return np.sqrt(11)\n  elif p == 12:\n    return 2 * np.sqrt(3)\n  elif p == 13:\n    return np.sqrt(13)\n  elif p == 14:\n    return np.sqrt(14)\n  elif p == 15:\n    return np.sqrt(15)\n  elif p == 16:\n    return 2 * np.sqrt(4)\n  elif p == 17:\n    return np.sqrt(17)\n  elif p == 18:\n    return np.sqrt(18)\n  elif p == 19:\n    return np.sqrt(19)\n  elif p == 20:\n    return 2 * np.sqrt(5)\n  elif p == 21:\n    return np.sqrt(21)\n  elif p == 22:\n    return np.sqrt(22)\n  elif p == 23:\n    return np.sqrt(23)\n  elif p == 24:\n    return 2 * np.sqrt(6)\n  elif p == 25:\n    return np.sqrt(25)\n  elif p == 26:\n    return np.sqrt(26)\n  elif p == 27:\n    return np.sqrt(27)\n  elif p == 28:\n    return 2 * np.sqrt(7)\n  elif p == 29:\n    return np.sqrt(29)\n  elif p == 30:\n   "}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p > 0:\n    return float(\"inf\")\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p > 0:\n    return jnp.inf\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  return jnp.where(\n      p == 0, 0, jnp.where(p == 1, 1, jnp.where(p > 1, jnp.inf, -jnp.inf))\n  )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p < 0:\n    return 0\n  else:\n    return jnp.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  else:\n    return float('inf')\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return np.inf\n  elif p == 1:\n    return 1\n  elif p > 1:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1\n  elif p < 1:\n    return 0\n  else:\n    return None\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p < 0:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 0:\n    return jnp.inf\n  elif p < 0:\n    return 0\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return jnp.inf\n  elif p == -1:\n    return 0\n  elif p == 2:\n    return jnp.inf\n  elif p == -2:\n    return 0\n  elif p == 3:\n    return jnp.inf\n  elif p == -3:\n    return 0\n  elif p == 4:\n    return jnp.inf\n  elif p == -4:\n    return 0\n  elif p == 5:\n    return jnp.inf\n  elif p == -5:\n    return 0\n  elif p == 6:\n    return jnp.inf\n  elif p == -6:\n    return 0\n  elif p == 7:\n    return jnp.inf\n  elif p == -7:\n    return 0\n  elif p == 8:\n    return jnp.inf\n  elif p == -8:\n    return 0\n  elif p == 9:\n    return jnp.inf\n  elif p == -9:\n    return 0\n  elif p == 10:\n    return jnp.inf\n  elif p == -10:\n    return 0\n  else:\n    return jnp.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return 1\n  elif p == 1:\n    return 1 / 2\n  elif p < 1:\n    return 0\n  else:\n    return None\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return jnp.inf\n  elif p == 2:\n    return jnp.inf\n  elif p == -1:\n    return 0\n  elif p == -2:\n    return 0\n  elif p == -3:\n    return 0\n  else:\n    return jnp.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  return jnp.where(\n      p < 0,\n      jnp.where(p % 2 == 0, jnp.inf, 0),\n      jnp.where(p % 2 == 0, 0, jnp.inf),\n  )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  return jnp.where(\n      p < 1,\n      jnp.inf,\n      jnp.where(\n          p == 1,\n          jnp.inf,\n          jnp.where(\n              p > 1,\n              jnp.inf,\n              jnp.where(\n                  p == 0,\n                  1,\n                  jnp.where(\n                      p < 0,\n                      0,\n                      jnp.where(\n                          p > 0,\n                          1,\n                          jnp.where(\n                              p == -1,\n                              0,\n                              jnp.where(p < -1, 0, jnp.inf),\n                          ),\n                      ),\n                  ),\n              ),\n          ),\n      ),\n  )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return 1\n  elif p == 1:\n    return 0\n  elif p < 1 and p > 0:\n    return float('inf')\n  else:\n    return 0\n\n"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, -1.0]]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0.0, 0.0, 1.0],\n            [0.0, 0.0, -1.0],\n            [0.0, 1.0, 0.0],\n            [0.0, -1.0, 0.0],\n            [1.0, 0.0, 0.0],\n            [-1.0, 0.0, 0.0],\n            [0.89442719, 0.0, 0.4472136],\n            [0.89442719, 0.4472136, 0.0],\n            [0.89442719, -0.4472136, 0.0],\n            [-0.89442719, 0.0, 0.4472136],\n            [-0.89442719, 0.4472136, 0.0],\n            [-0.89442719, -0.4472136, 0.0],\n            [0.4472136, 0.89442719, 0.0],\n            [0.4472136, -0.89442719, 0.0],\n            [-0.4472136, 0.89442719"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[1, 1, 1], [-1, -1, 1], [-1, 1, -1], [1, -1, -1]]\n    ) / np.sqrt(3)\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [0, 1, 0],\n            [0, -1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0.5773502691896258, 0.5773502691896258, 0.5773502691896258],\n            [0.5773502691896258, 0.5773502691896258, -0.5773502691896258],\n            [0.5773502691896258, -0.5773502691896258, 0.5773502691896258],\n            [0.5773502691896258, -0.5773502691896258, -0.5773502691896258],\n            [-0.5773502691896258, 0.5773502691896258, 0.5773502691896258],\n            [-0"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0, 0, 1], [0, 1, 0], [1, 0, 0], [-1, -1, -1]]\n    ).T\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [0, 1, 0],\n            [0, -1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 0.5773502691896258, 0.816496580927726],\n            [0, -0.5773502691896258, 0.816496580927726],\n            [0, 0.5773502691896258, -0.816496580927726],\n            [0, -0.5773502691896258, -0.816496580927726],\n            [0.816496580927726, 0, 0.5773502691896258],\n            [-0.816496580927726, 0, 0.5773502691896258],\n            [0.816496580927726, 0, -0.5773502691896258],\n            [-0.816496580"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0.0, 0.0, 1.0],\n        [0.0, 0.9428090415820634, -0.3333333333333333],\n        [-0.8164965809277261, -0.4714045207910317, -0.3333333333333333],\n        [0.8164965809277261, -0.4714045207910317, -0.3333333333333333],\n    ])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0.0, 0.0, 1.0],\n        [0.0, 0.9510565162951535, -0.30901699437494745],\n        [-0.8506508083520399, -0.5257311121191336, -0.30901699437494745],\n        [0.8506508083520399, -0.5257311121191336, -0.30901699437494745],\n        [0.0, -0.5257311121191336, 0.85065080835203"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [1, -1, -1], [-1, 1, -1], [-1, -1, 1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [0, 1, 0],\n            [0, -1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0.5, 0.8660254037844386, 0.13397459621556136],\n            [0.5, -0.8660254037844386, 0.13397459621556136],\n            [-0.5, 0.8660254037844386, 0.13397459621556136],\n            [-0.5, -0.8660254037844386, 0.13397459621556136],\n            [0.5, 0.13397459621556136, 0.8660254037844386],\n            [0.5, 0.13397459621556136, -0.8660254037844386],\n            [-0.5, 0.13397459621556136, 0.8660254"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [0.0, 0.0, 1.0],\n            [0.0, 0.9428090415820634, -0.3333333333333333],\n            [-0.816496580927726, -0.4714045207910317, -0.3333333333333333],\n            [0.816496580927726, -0.4714045207910317, -0.3333333333333333],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0.0, 0.0, 1.0],\n            [0.0, 0.0, -1.0],\n            [0.0, 1.0 / phi, phi / phi],\n            [0.0, -1.0 / phi, phi / phi],\n            [1.0 / phi, phi / phi, 1.0 / phi],\n            [-1.0 / phi, phi / phi, 1.0 / phi],\n            [1.0 / phi, phi / phi, -1.0 / phi],\n            [-1.0 / phi, phi / phi, -1.0 / phi],\n            [1.0 / phi, -phi / phi, 1.0 / phi],\n            [-1.0 / phi, -phi / phi, 1.0 / phi],\n            [1.0 / phi, -phi / phi, -1.0 / phi],\n            [-1.0 / phi, -"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [0, 1, 0],\n            [0, -1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0.5, 0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            [0.5, 0.5, -0.5],\n            [0.5, -0.5, -0.5],\n            [-0.5, 0.5, 0.5],\n            [-0.5, -0.5, 0.5],\n            [-0.5, 0.5, -0.5],\n            [-0.5, -0.5, -0.5],\n            [0.5, 0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            [0.5, 0.5, -0.5],\n            [0.5, -0.5, -0.5],\n            [-0.5, 0.5, 0.5],\n            [-0.5, -0.5, 0.5],\n            [-0.5, 0.5, -0.5],\n            [-0.5, -0.5, -0.5],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 2, 3],\n            [1, 2, 3],\n            [4, 5, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[1, 0, 0], [0, 1, 0], [0, 0, 1], [-1, -1, -1]], dtype=np.float32\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]],\n                          dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, 1, -phi],\n            [0, -1, phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [1, -phi, 0],\n            [-1, phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 2, 4],\n            [0, 2, 5],\n            [0, 3, 4],\n            [0, 3, 5],\n            [1, 2, 6],\n            [1, 2, 7],\n            [1, 3, 6],\n            [1, 3, 7],\n            [2, 4, 8],\n            [2, 4, 9],\n            [2, 5, 8],\n            [2, 5, 9],\n            [3, 4, 10],\n            [3, 4, 11],\n            [3, 5, 10],\n            [3, 5, 11],\n            [4, 6, 8],\n            [4, 6, 10"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 0, -1],\n        [1, 0, 0],\n        [-1, 0, 0],\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ])\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 2, 4],\n        [0, 2, 6],\n        [0, 3, 5],\n        [0, 3, 6],\n        [1, 2, 4],\n        [1, 2, 7],\n        [1, 3, 5],\n        [1, 3, 7],\n        [2, 3, 6],\n        [2, 3, 7],\n        [4, 5, 8],\n        [4, 5, 9],\n        [4, 6, 8],\n        [4, 6, 10],\n        [5, 6, 9],\n        [5, 6, 10],\n        [5, 7, 8],\n        [5, 7, 11],\n        [6, 7, 9],\n        [6, 7, 11],\n       "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n            [-1, -1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0.89442719, 0, 0.4472136],\n            [-0.4472136, 0.89442719, 0.4472136],\n            [-0.4472136, -0.89442719, 0.4472136],\n            [0.89442719, 0, -0.4472136],\n            [-0.4472136, 0.89442719, -0.4472136],\n            [-0.4472136, -0.89442719, -0.4472136],\n            [0, 0, -1],\n            [0.89442719, 0.70710678, 0],\n            [0.89442719, -0.70710678, 0],\n            [-0.89442719, 0.70710678, 0],\n            [-0.89442719, -0.70710678, 0],\n            [0.70710678, 0.89442719, 0],\n            [0.70710678, -"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be one of tetrahedron, icosahedron, or octahedron'\n    )\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be an integer'\n    )\n  if not isinstance(remove_symmetries, bool):\n    raise ValueError(\n        f'remove_symmetries {remove_symmetries} must be a boolean'\n    )\n  if not isinstance(eps, float):\n    raise ValueError(f'eps {eps} must be a float')\n\n  # Define the initial polyhedron vertices and faces.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0, 0, 1], [0, 1, 0], [1, 0, 0], [-1, -1, -1]]\n    ).T\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 1, 0],\n            [1, 0, 0],\n            [-1, -1, -1],\n            [0, 0, -1],\n            [0, -1, 0],\n            [-1, 0, 0],\n            [1, 1, 1],\n            [0, 0, 1],\n            [0, 1, 0],\n            [1, 0, 0],\n            [-1, -1, -1],\n            [0, 0, -1],\n            [0, -1, 0],\n            [-1, 0, 0],\n            [1, 1, 1],\n        ]\n    ).T\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 2, 3"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[1, 1, 1], [1, -1, -1], [-1, 1, -1], [-1, -1, 1]], dtype=np.float32\n    )\n    base_faces = np.array([[0, 1, 2], [1, 0, 3], [2, 0, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [0.5, 0.866025, 0.0],\n            [-0.5, 0.866025, 0.0],\n            [-0.5, -0.866025, 0.0],\n            [0.5, -0.866025, 0.0],\n            [0.866025, 0.5, 0.0],\n            [-0.866025, 0.5, 0.0],\n            [-0.866025, -0.5, 0.0],\n            [0.866025, -0.5, 0.0],\n            [0.0, 0.5, 0.866025],\n            [0.0, -0.5, 0.866025],\n            [0.0, -0.5, -0.866025],\n            [0.0, 0.5, -0.866025],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n            ["}
{"namespace": "geopoly.generate_basis", "completion": "  # Check the input arguments\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"'\n    )\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be an integer'\n    )\n  if not isinstance(remove_symmetries, bool):\n    raise ValueError(\n        f'remove_symmetries {remove_symmetries} must be a boolean'\n    )\n  if not isinstance(eps, float):\n    raise ValueError(f'eps {eps} must be a float')\n\n  # Create the initial polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    t = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [t, 1, 0],\n            [-t, 1, 0],\n            [-1, 0, 0],\n            [-t, -1, 0],\n            [t, -1, 0],\n            [0, 0, -1],\n            [1, 0, 0],\n            [0, t, 1],\n            [0, -t, 1],\n            [0, -t, -1],\n            [0, t, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 4],\n            [0, 4, 5],\n            [0, 5, 1],\n            [1, 6,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [1, -1, -1], [-1, 1, -1], [-1, -1, 1]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [0, 1, 0],\n            [0, -1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0.5, 0.5, 0.5],\n            [-0.5, -0.5, -0.5],\n            [-0.5, 0.5, -0.5],\n            [0.5, -0.5, -0.5],\n            [-0.5, -0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            [-0.5, 0.5, 0.5],\n            [0.5, 0.5, -0.5],\n            [0.5, 0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            [-0.5, 0.5, 0.5],\n            [-0.5, -0.5, 0.5],\n            [0.5, -0.5, -0.5],\n            [-0.5, 0.5, -0.5],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 1, 4],\n            [0, 1, 5],\n            [0, 1, 6],\n            [0, 1, 7],\n            [0, 1, 8],\n            [0, 1, 9],"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[-1, 0, 0], [1, 0, 0], [0, -1, 0], [0, 1, 0], [0, 0, -1], [0, 0, 1]]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 1, 4], [0, 1, 5]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, -1],\n            [0, 0, 1],\n            [0, 0.5, 0.866025],\n            [0, -0.5, 0.866025],\n            [0.866025, 0, 0.5],\n            [-0.866025, 0, 0.5],\n            [0.5, 0.866025, 0],\n            [-0.5, 0.866025, 0],\n            [0.5, -0.866025, 0],\n            [-0.5, -0.866025, 0],\n            [0.866025, 0.5, 0],\n            [-0.866025, 0.5, 0],\n            [0.866025, -0.5, 0],\n            [-0.866025, -0.5, 0],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 1, 4],\n            [0, 1, 5],\n            [0, 1, 6],\n            [0, 1, 7],\n            [0, 1, 8],\n            [0, 1, 9],\n            [0, 1, 10],\n            ["}
{"namespace": "geopoly.generate_basis", "completion": "  # Check for valid input arguments\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\"'\n    )\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be an integer'\n    )\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be >= 1'\n    )\n\n  # Define the initial polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0, 0, 1], [0, 1, 0], [1, 0, 0], [-1, -1, -1]]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [0, 1, 0],\n            [0, -1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0.5, 0.5, 0.5],\n            [-0.5, 0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            [-0.5, -0.5, 0.5],\n            [0.5, 0.5, -0.5],\n            [-0.5, 0.5, -0.5],\n            [0.5, -0.5, -0.5],\n            [-0.5, -0.5, -0.5],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0"}
{"namespace": "geopoly.generate_basis", "completion": "  # Check the input arguments\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'Invalid base shape: {base_shape}. Must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\".'\n    )\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'Invalid angular tesselation: {angular_tesselation}. Must be >= 1.'\n    )\n\n  # Define the initial polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0, 0, 1], [0, 1, 0], [1, 0, 0], [-1, -1, -1]], dtype=np.float32\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 1, 0],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, -1, 0],\n            [0, 0, -1],\n            [0.57735, 0.57735, 0.57735],\n            [-0.57735, 0.57735, 0.57735],\n            [0.57735, -0.57735, 0.57735],\n            [-0.57735, -0.57735, 0.57735],\n            [0.57735, 0.57735, -0.57735],\n            [-0.57735, 0.57735, -0.57735],\n            [0.57735, -0.57735, -0.57735"}
{"namespace": "geopoly.generate_basis", "completion": "  # Check if base_shape is valid\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        'base_shape must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\"'\n    )\n\n  # Check if angular_tesselation is valid\n  if not isinstance(angular_tesselation, int) or angular_tesselation < 1:\n    raise ValueError('angular_tesselation must be a positive integer')\n\n  # Define the initial polyhedron vertices and faces\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[-1, 0, 0], [1, 0, 0], [0, -1, 0], [0, 1, 0], [0, 0, -1], [0, 0, 1]]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 4], [0, 3, 4], [1, 2, 3],\n                           [2, 3, 4]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [[0, 0, 1], [0, 0, -1], [0, 1, 0], [0, -1, 0], [1, 0, 0], [-1, 0, 0],\n         [0.5, 0.8660254037844386, -0.5], [0.5, -0.8660254037844386, -0.5],\n         [-0.5, 0.8660254037844386, -0.5], [-0.5, -0.8660254037844386, -0.5],\n         [-0.5, 0.8660254037844386, 0.5], [-0.5, -0.866"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [-1, 0, 0]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 0, 1],\n            [0, 0, -1],\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [phi, 1 / phi, 0],\n            [-phi, 1 / phi, 0],\n            [-phi, -1 / phi, 0],\n            [phi, -1 / phi, 0],\n            [1 / phi, phi, 0],\n            [-1 / phi, phi, 0],\n            [-1 / phi, -phi, 0],\n            [1 / phi, -phi, 0],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 10],\n            [0, 10, 12],\n            [0, 12, 1],\n            [1, 12, 11],\n            [1, 11, 2],\n            [2, 11, 10],\n            [0, 1, 3],\n            [0, 3, 4],\n            [0, 4, 12],\n            [1, 4, 5],\n            [1, 5, 11],\n            [2, 5, 6],\n            [2, 6, 10],\n            [3, 5, 4],\n            [3, 7, 5],\n            [3, 8, 7],\n            [3, 9, 8],\n            [4, 8, 9],\n            [4"}
{"namespace": "geopoly.generate_basis", "completion": "  # Check that the base_shape is valid\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'Invalid base shape {base_shape}. Must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\".'\n    )\n\n  # Check that the angular_tesselation is valid\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'Invalid angular_tesselation {angular_tesselation}. Must be greater than or equal to 1.'\n    )\n\n  # Define the vertices and faces of the tetrahedron, icosahedron, and octahedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, -1.0]]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0.0, 0.0, 1.0],\n            [0.0, 0.9510565162951535, -0.30901699437494745],\n            [0.8506508083520399, 0.5257311121191336, -0.0],\n            [0.0, 0.5257311121191336, 0.8506508083520399],\n            [-0.8506508083520399, 0.5257311121191336, 0.0],\n            [0."}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.clip(1 + x, tiny_val, max_val),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.clip(1 + x, tiny_val, max_val),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (x + 1),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (x + 1),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (x + 1),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (x + 1),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (x + 1),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.clip(1 + x, tiny_val, max_val),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, y, x_dot: x_dot / (1 + x),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.clip(1 + x, tiny_val, max_val),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (x + 1),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / jnp.clip(1 + x, tiny_val, max_val),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    return x\n  if p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  if p == -jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(jnp.abs(x)))\n  if p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(-jnp.abs(x)))\n  return jnp.sign(x) * jnp.abs(x) ** p\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p values of 1, 0, -inf, and inf\n  if p == 1:\n    return x * premult * postmult\n  elif p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x)) * premult * postmult\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x))) * premult * postmult\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(x)) * premult * postmult\n\n  # Apply Tukey's power ladder transformation\n  return jnp.where(\n      x == 0,\n      0,\n      jnp.sign(x) * jnp.abs(x) ** p * premult * postmult,\n  )\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 0:\n    x = jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  elif p == 1:\n    x = jnp.where(x == 0, 0, jnp.sign(x) * jnp.log1p(jnp.abs(x)))\n  elif p == -jnp.inf:\n    x = jnp.where(x == 0, 0, jnp.sign(x) * jnp.expm1(jnp.abs(x)))\n  elif p == jnp.inf:\n    x = jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(jnp.abs(x)))\n  else:\n    x = jnp.where(x == 0, 0, jnp.sign(x) * (jnp.abs(x) ** p - 1) / (p - 1))\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.where(x == 0, 0, jnp.sign(x))\n  elif p == -jnp.inf:\n    y = jnp.where(x == 0, 0, jnp.sign(x) * jnp.log1p(jnp.abs(x)))\n  elif p == jnp.inf:\n    y = jnp.where(x == 0, 0, jnp.sign(x) * jnp.expm1(jnp.abs(x)))\n  else:\n    y = jnp.sign(x) * (jnp.abs(x) ** p - 1) / (p - 1)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.where(x == 0, 1, 0)\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, 1)\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, 1)\n  else:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.abs(x)**p)\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(jnp.abs(x)))\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(-jnp.abs(x)))\n  else:\n    return jnp.sign(x) * safe_div(jnp.abs(x)**p - 1, p)\n  if postmult is not None:\n    return postmult * x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  if p == 1:\n    return x\n\n  if p == 0:\n    return jnp.where(x == 0, 0, jnp.log(jnp.abs(x)))\n\n  if p == -jnp.inf:\n    return jnp.where(x == 0, 0, -jnp.log(jnp.abs(x)))\n\n  if p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x))\n\n  return jnp.sign(x) * jnp.abs(x)**p\n\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(-jnp.abs(x)))\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(jnp.abs(x)))\n  else:\n    return jnp.sign(x) * jnp.power(jnp.abs(x), p)\n\n  if postmult is not None:\n    return x * postmult\n  else:\n    return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.expm1(jnp.abs(x)))\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * safe_log1p(jnp.abs(x)))\n  else:\n    return jnp.where(\n        x == 0,\n        0,\n        jnp.sign(x) * safe_div(jnp.abs(x)**p - 1, p),\n    )\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x))\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, jnp.sign(x) * jnp.exp(jnp.abs(x)))\n\n  # Apply pre-multiplication if specified\n  if premult is not None:\n    x = x * premult\n\n  # Apply Tukey's power ladder transformation\n  if p == 2:\n    return x**2\n  elif p == -2:\n    return safe_sqrt(x)\n  else:\n    return safe_div(x**p - 1, p)\n\n  # Apply post-multiplication if specified\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    return x\n\n  if p == 0:\n    return safe_log1p(x)\n\n  if p == -jnp.inf:\n    return jnp.where(x > 0, 1, 0)\n\n  if p == jnp.inf:\n    return jnp.where(x > 0, 0, 1)\n\n  return safe_sign(x) * safe_div(safe_abs(x)**p - 1, p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if p == 1:\n    return x * premult * postmult\n  elif p == 0:\n    return jnp.where(x == 0, 0, safe_log(jnp.abs(x)) * safe_sign(x)) * premult * postmult\n  elif p == -jnp.inf:\n    return jnp.where(x == 0, 0, safe_sign(x) * safe_log1p(jnp.abs(x))) * premult * postmult\n  elif p == jnp.inf:\n    return jnp.where(x == 0, 0, safe_sign(x) * safe_expm1(jnp.abs(x))) * premult * postmult\n  else:\n    return (jnp.abs(x) ** p) * safe_sign(x) * premult * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.where(x == 0, 0, jnp.sign(x))\n  elif p == -jnp.inf:\n    return jnp.where(x > 0, 1, -1)\n  elif p == jnp.inf:\n    return jnp.where(x > 0, 1, 0)\n  else:\n    return jnp.sign(x) * jnp.abs(x)**p\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p\n  if p == 1:\n    return x\n  elif p == 0:\n    return jnp.sign(x)\n  elif p == -jnp.inf:\n    return jnp.where(x > 0, 1, 0)\n  elif p == jnp.inf:\n    return jnp.where(x > 0, 0, 1)\n\n  # Apply pre-multiplication if specified\n  if premult is not None:\n    x = x * premult\n\n  # Apply power ladder transformation\n  if p < 0:\n    return safe_div(1, jnp.maximum(tiny_val, x)**p)\n  else:\n    return jnp.maximum(tiny_val, x)**p\n\n  # Apply post-multiplication if specified\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  premult = jnp.asarray(premult) if premult is not None else 1\n  postmult = jnp.asarray(postmult) if postmult is not None else 1\n  # Special cases for p values of 1, 0, -inf, and inf\n  x = select(\n      [\n          (p == 1, premult * x * postmult),\n          (p == 0, premult * jnp.sign(x) * postmult),\n          (p == -jnp.inf, premult * jnp.sign(x) * postmult),\n          (p == jnp.inf, premult * jnp.sign(x) * postmult),\n      ],\n      premult * jnp.sign(x) * jnp.abs(x) ** p * postmult,\n  )\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x *= premult\n\n  if p == 1:\n    return x\n\n  if p == 0:\n    return jnp.sign(x)\n\n  if p == -jnp.inf:\n    return jnp.where(x > 0, 1, 0)\n\n  if p == jnp.inf:\n    return jnp.where(x > 0, 1, -1)\n\n  return jnp.sign(x) * jnp.abs(x)**p\n\n  if postmult is not None:\n    return x * postmult\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 0:\n    x = jnp.where(x == 0, 0, jnp.sign(x))\n  elif p == 1:\n    x = x\n  elif p == -jnp.inf:\n    x = jnp.where(x == 0, 0, jnp.sign(x) * jnp.log(jnp.abs(x)))\n  elif p == jnp.inf:\n    x = jnp.sign(x) * jnp.log1p(jnp.abs(x))\n  else:\n    x = jnp.sign(x) * jnp.abs(x) ** p\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p\n  if p == 1:\n    return x\n  if p == 0:\n    return jnp.log(remove_zero(x))\n  if p == -jnp.inf:\n    return jnp.log(remove_zero(x)) / x\n  if p == jnp.inf:\n    return x / jnp.log(remove_zero(x))\n\n  # Apply pre-multiplication and post-multiplication\n  if premult is not None:\n    x = x * premult\n  if postmult is not None:\n    x = x / postmult\n\n  # Apply Tukey's power ladder\n  return jnp.sign(x) * jnp.abs(x)**p\n\n"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  if premult is not None:\n    x *= premult\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log1p(x)\n  elif p == -jnp.inf:\n    y = jnp.log(x)\n  elif p == jnp.inf:\n    y = safe_log1p(x)\n  else:\n    y = safe_div(safe_pow(x, p) - 1, p)\n  if postmult is not None:\n    y *= postmult\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 0:\n    x = jnp.where(x == 0, 1, jnp.where(x < 0, -1, x))\n  elif p == 1:\n    x = x\n  elif p == -jnp.inf:\n    x = jnp.where(x < 0, -1, x)\n  elif p == jnp.inf:\n    x = jnp.where(x < 0, 0, 1)\n  else:\n    x = jnp.where(x < 0, -safe_sign(p) * safe_pow(jnp.abs(x), p), safe_pow(x, p))\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^(1/p) - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(jnp.abs(p_safe - 1) / p_safe * (ys ** (1 / p_safe) - 1)),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (ys ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  y = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (y + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x * safe_sign(y)\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p_safe - 1))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(jnp.abs(p_safe - 1) / p_safe * (ys ** (1 / p_safe) - 1)),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(jnp.abs(p_safe - 1) / p_safe * (ys ** p_safe - 1)),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * (|y|/|p-1| + 1)^(1/p) - 1\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (yp + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (ys ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (ys ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  y_abs = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.sign(y)\n          * (\n              jnp.abs(p_safe - 1) / p_safe\n              * (y_abs + 1) ** (1 / p_safe)\n              - 1\n          )\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  if premult is not None:\n    y = y / premult\n  y_safe = clip_finite_nograd(remove_zero(y))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y_safe)),\n          (p == -jnp.inf, -safe_log1p(-y_safe)),\n          (p == jnp.inf, safe_log1p(y_safe)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (y_safe + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  y_safe = clip_finite_nograd(remove_zero(y))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y_safe),\n          (p == 0, safe_expm1(y_safe)),\n          (p == -jnp.inf, -safe_log1p(-y_safe)),\n          (p == jnp.inf, safe_log1p(y_safe)),\n      ],\n      clip_finite_nograd(\n          (y_safe + 1) ** (1 / p_safe) - 1\n      ) * jnp.abs(p_safe - 1) / p_safe,\n  )\n  if premult is not None:\n    x = x / premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^(1/p) - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  if p == 1:\n    y = y\n  elif p == 0:\n    y = safe_expm1(y)\n  elif p == -jnp.inf:\n    y = -safe_log1p(-y)\n  elif p == jnp.inf:\n    y = safe_log1p(y)\n  else:\n    p_safe = clip_finite_nograd(remove_zero(p))\n    y = jnp.where(\n        y < tiny_val,\n        tiny_val,\n        (y * p_safe / jnp.abs(p_safe - 1)) ** (1 / p_safe) - 1,\n    )\n  if premult is not None:\n    y = y / premult\n  return y\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  if postmult is not None:\n    y = y / postmult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = jnp.abs(y)\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(y * p_safe / (jnp.abs(p_safe - 1)))\n      - 1,\n  )\n  return safe_sign(y) * jnp.abs(y) ** (1 / p_safe)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n\n  if step < max_steps:\n    return log_lerp(step / max_steps, lr_init, lr_final)\n  else:\n    return lr_final\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    lr = log_lerp(\n        (step - lr_delay_steps) / (max_steps - lr_delay_steps), lr_init, lr_final\n    )\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_delay_mult * lr_init\n  else:\n    lr = log_lerp(\n        jnp.clip(step - lr_delay_steps, 0, max_steps) / max_steps,\n        lr_init,\n        lr_final,\n    )\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_delay_mult * lr_init\n  return log_lerp(\n      jnp.clip(step - lr_delay_steps, 0, max_steps) / max_steps, lr_init, lr_final\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n\n  if lr_init <= lr_final:\n    return lr_init\n  else:\n    return log_lerp(\n        jnp.clip(step / max_steps, 0, 1), lr_init, lr_final\n    )  # pylint: disable=invalid-unary-operand-type\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr_init = lr_delay_mult * lr_init\n    step = step - lr_delay_steps\n\n  lr = log_lerp(step / max_steps, lr_init, lr_final)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    lr = log_lerp(\n        jnp.clip(step - lr_delay_steps, 0, max_steps) / max_steps,\n        lr_init * lr_delay_mult,\n        lr_final,\n    )\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = jnp.clip(step - lr_delay_steps, 0, max_steps)\n  return log_lerp(\n      step / max_steps, lr_init, lr_final\n  )  # Note: this is not the same as tf.train.polynomial_decay.\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult\n  else:\n    return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    return lr_delay_mult * lr_init\n  return log_lerp(\n      jnp.clip(step - lr_delay_steps, 0, max_steps) / max_steps, lr_init, lr_final\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init *= lr_delay_mult\n    step = jnp.clip(step - lr_delay_steps, 0, max_steps)\n  return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n    step = jnp.clip(step, 0, max_steps - lr_delay_steps)\n  return log_lerp(\n      jnp.clip(step / max_steps, 0, 1), lr_init, lr_final\n  )  # Clip val, not grad.\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n\n  if step <= 0:\n    return lr_init\n\n  if step >= max_steps:\n    return lr_final\n\n  return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_delay_mult * lr_init\n    step = jnp.maximum(step - lr_delay_steps, 0)\n\n  return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    if step < lr_delay_steps:\n      lr_init = lr_init * (step / lr_delay_steps)\n\n  return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n\n  if step < max_steps:\n    return log_lerp(step / max_steps, lr_init, lr_final)\n  else:\n    return lr_final\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Check for invalid input\n  if lr_init <= 0 or lr_final <= 0:\n    raise ValueError(f'Learning rates {lr_init} and {lr_final} must be positive.')\n  if max_steps <= 0:\n    raise ValueError(f'Max steps {max_steps} must be positive.')\n  if lr_delay_steps < 0:\n    raise ValueError(f'Delay steps {lr_delay_steps} must be non-negative.')\n  if lr_delay_mult <= 0:\n    raise ValueError(f'Delay multiplier {lr_delay_mult} must be positive.')\n\n  # Calculate the learning rate at the current step\n  if step < lr_delay_steps:\n    # Apply the delay multiplier if the current step is within the delay period\n    lr = lr_init * lr_delay_mult\n  else:\n    # Calculate the learning rate based on the log-linear interpolation\n    lr = log_lerp(\n        (step - lr_delay_steps) / (max_steps - lr_delay_steps), lr_init, lr_final\n    )\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n  return log_lerp(\n      jnp.clip(step / max_steps, 0, 1), lr_init, lr_final\n  )  # Clip val, not grad.\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    if step < lr_delay_steps:\n      lr_init = lr_init * (step / lr_delay_steps)\n\n  return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    step = step - lr_delay_steps\n    if step < 0:\n      return lr_init\n  return log_lerp(step / max_steps, lr_init, lr_final)\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=10,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.zeros([3]),\n      origin_hi=jnp.ones([3]),\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1024,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.zeros([3]),\n      origin_hi=jnp.zeros([3]),\n      radius_lo=jnp.zeros([1]),\n      radius_hi=jnp.zeros([1]),\n      near_lo=jnp.zeros([1]),\n      near_hi=jnp.zeros([1]),\n      far_lo=jnp.zeros([1]),\n      far_hi=jnp.zeros([1]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.zeros([3]),\n      origin_hi=jnp.zeros([3]),\n      radius_lo=jnp.zeros([1]),\n      radius_hi=jnp.zeros([1]),\n      near_lo=jnp.zeros([1]),\n      near_hi=jnp.zeros([1]),\n      far_lo=jnp.zeros([1]),\n      far_hi=jnp.zeros([1]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  n = 1\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.1\n  near_lo = 0.0\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 2.0\n\n  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=n,\n      origin_lo=origin_lo,\n      origin_hi=origin_hi,\n      radius_lo=radius_lo,\n      radius_hi=radius_hi,\n      near_lo=near_lo,\n      near_hi=near_hi,\n      far_lo=far_lo,\n      far_hi=far_hi,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1.0, -1.0, -1.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      jnp.zeros([3]),\n      jnp.zeros([3]),\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      0.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      1,\n      jnp.array([0, 0, 0]),\n      jnp.array([1, 1, 1]),\n      0.1,\n      0.1,\n      0.1,\n      0.1,\n      0.1,\n      0.1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1.0, -1.0, -1.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([1.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([1.0]),\n      far_lo=jnp.array([1.0]),\n      far_hi=jnp.array([2.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=10,\n      origin_lo=jnp.array([-1.0, -1.0, -1.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([1.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([1.0]),\n      far_lo=jnp.array([1.0]),\n      far_hi=jnp.array([2.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      100,\n      jnp.array([0.0, 0.0, 0.0]),\n      jnp.array([1.0, 1.0, 1.0]),\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=0.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  n = 100\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.0\n  radius_hi = 1.0\n  near_lo = 0.0\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 2.0\n  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=n,\n      origin_lo=origin_lo,\n      origin_hi=origin_hi,\n      radius_lo=radius_lo,\n      radius_hi=radius_hi,\n      near_lo=near_lo,\n      near_hi=near_hi,\n      far_lo=far_lo,\n      far_hi=far_hi,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  n = 1\n  origin_lo = jnp.array([0.0, 0.0, 0.0])\n  origin_hi = jnp.array([1.0, 1.0, 1.0])\n  radius_lo = 0.0\n  radius_hi = 1.0\n  near_lo = 0.0\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 2.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.5,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=1,\n      far_hi=2,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=10,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=0,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      random.PRNGKey(0),\n      10,\n      -10,\n      10,\n      0.1,\n      10,\n      0.1,\n      10,\n      10,\n      20,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  n = 1\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.0\n  radius_hi = 1.0\n  near_lo = 0.0\n  near_hi = 1.0\n  far_lo = 1.0\n  far_hi = 2.0\n  return generate_random_rays(\n      rng=None,\n      n=n,\n      origin_lo=origin_lo,\n      origin_hi=origin_hi,\n      radius_lo=radius_lo,\n      radius_hi=radius_hi,\n      near_lo=near_lo,\n      near_hi=near_hi,\n      far_lo=far_lo,\n      far_hi=far_hi,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(x, y):\n    return xnp.stack([x - 0.5, y - 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply intrinsic matrices.\n  pixel_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        pixel_dirs_stacked[Ellipsis, 0],\n        pixel_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    pixel_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(pixel_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    pixel_dirs_stacked = xnp.stack(\n        [\n            pixel_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            pixel_dirs"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(x, y):\n    return xnp.stack([x - 0.5, y - 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  point_dirs_stacked = xnp.stack(\n      [\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply intrinsic matrices.\n  point_dirs_stacked = mat_vec_mul(pixtocams, point_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        point_dirs_stacked[Ellipsis, 0],\n        point_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    point_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(point_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    point_dirs_stacked = xnp.stack(\n        [\n            point_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            point_dirs"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera extrinsics matrices.\n  points_world = xnp.matmul(\n      camtoworlds[Ellipsis, :3, :3], points[Ellipsis, :3]\n  ) + camtoworlds[Ellipsis, :3, -1]\n\n  # Apply inverse intrinsics matrices.\n  points_cam = xnp.matmul(\n      pixtocams[Ellipsis, :3, :3], points_world\n  ) + pixtocams[Ellipsis, :3, -1]\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    points_cam = _radial_and_tangential_undistort(\n        points_cam[Ellipsis, 0],\n        points_cam[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Apply camera projection model.\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(points_cam[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    points_cam = xnp.stack(\n        [\n            points_cam[Ellipsis, 0] * sin_theta_over_theta,\n            points_cam[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = points_cam[Ellipsis, 0]\n    phi = points_cam[Ellipsis, 1]\n    points_cam = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  points_cam = xnp.matmul(\n      points_cam, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Extract 2D image plane (x,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsic matrices.\n  pixel_dirs_stacked = xnp.matmul(\n      pixtocams[Ellipsis, :3, :3], xnp.stack([points, xnp.ones_like(points[:, 0])], -1)\n  )\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        pixel_dirs_stacked[Ellipsis, 0],\n        pixel_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    pixel_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Correct for fisheye projection.\n    theta = xnp.sqrt(xnp.sum(xnp.square(pixel_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    pixel_dirs_stacked = xnp.stack(\n        [\n            pixel_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            pixel_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Correct for panoramic projection.\n    theta = pixel_dirs_stacked[Ellipsis, 0]\n    phi = pixel_dirs_stacked[Ellipsis, 1]\n    pixel_dirs_stacked = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  pixel_dirs_stacked = xnp.matmul(\n      pixel_dirs_stacked, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n "}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsic matrices.\n  cam_points = xnp.matmul(pixtocams, points)\n\n  # Apply camera extrinsics matrices.\n  camera_points = xnp.matmul(camtoworlds[Ellipsis, :3, :3], cam_points)\n  camera_points = xnp.stack(\n      [\n          camera_points[Ellipsis, 0] + camtoworlds[Ellipsis, 0, -1],\n          camera_points[Ellipsis, 1] + camtoworlds[Ellipsis, 1, -1],\n          camera_points[Ellipsis, 2],\n      ],\n      axis=-1,\n  )\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_points[Ellipsis, 0],\n        camera_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_points = xnp.stack([x, y, camera_points[Ellipsis, 2]], axis=-1)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Apply fisheye projection.\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_points[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_points = xnp.stack(\n        [\n            camera_points[Ellipsis, 0] * sin_theta_over_theta,\n            camera_points[Ellipsis, 1] * sin_theta_over_theta,\n            camera_points[Ellipsis, 2] * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Apply panoramic projection.\n    theta = camera_points[Ellipsis, 0]\n    phi = camera_points[Ellipsis, 1]\n    camera_points = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the 3D camera rays from the 3D points.\n  directions = points - camtoworlds[Ellipsis, :3, -1]\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Apply camera rotation matrices.\n  directions_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], viewdirs\n  )\n  directions, dx, dy = directions_stacked\n\n  # Flip from OpenGL to OpenCV coordinate system.\n  directions = matmul(\n      directions, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(directions[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    directions = xnp.stack(\n        [\n            directions[Ellipsis, 0] * sin_theta_over_theta,\n            directions[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = directions[Ellipsis, 0]\n    phi = directions[Ellipsis, 1]\n    # Negation on y and z components accounts for expected OpenCV convention.\n    directions = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Apply camera intrinsics matrices.\n  directions_stacked = mat_vec_mul(\n      pixtocams[Ellipsis, :3, :3], directions\n  )\n  directions, dx, dy = directions_stacked\n\n  # Compute the 2D pixel coordinates.\n  coordinates = xnp.stack(\n      [\n          directions[Ellipsis, 0] + dx,\n          directions[Ellipsis, 1] + dy,\n      ],\n      axis=-1,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsic matrices.\n  camera_points = xnp.matmul(pixtocams, points)\n\n  # Apply camera extrinsics.\n  camera_points = xnp.matmul(camtoworlds, camera_points)\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    camera_points = _radial_and_tangential_undistort(\n        camera_points,\n        camtype=camtype,\n        xnp=xnp,\n        **distortion_params,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  camera_points = xnp.matmul(\n      camera_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Extract 2D image plane (x, y) coordinates.\n  pixels = camera_points[Ellipsis, :2]\n\n  # Compute depth values.\n  depth = xnp.linalg.norm(camera_points, axis=-1)\n\n  return pixels, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsics to points.\n  camera_points = mat_vec_mul(pixtocams[Ellipsis, :3, :3], points)\n\n  # Apply camera extrinsics to camera points.\n  directions = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], camera_points)\n\n  # Compute ray origins.\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n\n  # Compute ray directions.\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        viewdirs[Ellipsis, 0], viewdirs[Ellipsis, 1], **distortion_params, xnp=xnp\n    )\n    viewdirs = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(viewdirs[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    viewdirs = xnp.stack(\n        [\n            viewdirs[Ellipsis, 0] * sin_theta_over_theta,\n            viewdirs[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = viewdirs[Ellipsis, 0]\n    phi = viewdirs[Ellipsis, 1]\n    # Negation on y and z components accounts for expected OpenCV convention.\n    viewdirs = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Flip from OpenGL to OpenCV coordinate system.\n  viewdirs ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Transform points from world to camera coordinates.\n  camera_points = xnp.matmul(camtoworlds[Ellipsis, :3, :4], points)\n\n  # Transform camera points from camera to pixel coordinates.\n  pixel_points = xnp.matmul(pixtocams[Ellipsis, :3, :3], camera_points)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        pixel_points[Ellipsis, 0], pixel_points[Ellipsis, 1], **distortion_params\n    )\n    pixel_points = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Correct for fisheye projection.\n    theta = xnp.sqrt(xnp.sum(xnp.square(pixel_points[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    pixel_points = xnp.stack(\n        [\n            pixel_points[Ellipsis, 0] * sin_theta_over_theta,\n            pixel_points[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        -1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Correct for panoramic projection.\n    theta = pixel_points[Ellipsis, 0]\n    phi = pixel_points[Ellipsis, 1]\n    pixel_points = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        -1,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  pixel_points = xnp.matmul(\n      pixel_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Extract 2D image plane (x, y) coordinates.\n  coordinates = pixel_"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Convert points from the world coordinate system to the camera coordinate system.\n  camera_points = xnp.matmul(camtoworlds[Ellipsis, :3, :3], points)\n\n  # Add the camera offset to the camera points.\n  camera_points = camera_points + xnp.broadcast_to(\n      camtoworlds[Ellipsis, :3, -1], camera_points.shape\n  )\n\n  # Apply the intrinsic matrix to the camera points.\n  pix_points = xnp.matmul(pixtocams[Ellipsis, :3, :3], camera_points)\n\n  # Add the pixel offset to the pixel points.\n  pix_points = pix_points + xnp.broadcast_to(\n      pixtocams[Ellipsis, :3, -1], pix_points.shape\n  )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  pix_points = xnp.matmul(\n      pix_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        pix_points[Ellipsis, 0],\n        pix_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    pix_points = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(pix_points[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    pix_points = xnp.stack(\n        [\n            pix_points[Ellipsis, 0] * sin_theta_over_theta,\n            pix_points[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = pix_points[Ellipsis, 0]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the 3D camera rays.\n  origins, directions, viewdirs, radii, imageplane = pixels_to_rays(\n      pix_x_int=points[Ellipsis, 0],\n      pix_y_int=points[Ellipsis, 1],\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Compute the 2D pixel coordinates.\n  pixels = xnp.stack([imageplane[Ellipsis, 0] * radii, imageplane[Ellipsis, 1] * radii], axis=-1)\n\n  return pixels, radii\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsics.\n  camera_points = xnp.matmul(pixtocams, xnp.stack([points, xnp.ones_like(points)], -1))\n\n  # Apply camera extrinsics.\n  camera_points = xnp.matmul(camtoworlds, camera_points)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_undistort(\n        camera_points[Ellipsis, 0],\n        camera_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_points = xnp.stack([x, y, camera_points[Ellipsis, 2]], -1)\n\n  # Apply fisheye distortion.\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_points[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n    camera_points = xnp.stack(\n        [\n            camera_points[Ellipsis, 0] * xnp.sin(theta) / theta,\n            camera_points[Ellipsis, 1] * xnp.sin(theta) / theta,\n            camera_points[Ellipsis, 2],\n        ],\n        -1,\n    )\n\n  # Apply pano distortion.\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = camera_points[Ellipsis, 0]\n    phi = camera_points[Ellipsis, 1]\n    camera_points = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        -1,\n    )\n\n  # Flip from OpenGL to OpenCV coordinate system.\n  camera_points = xnp.matmul(\n      camera_points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Extract pixel coordinates.\n  coordinates = camera_points[Ellipsis, :2]\n\n  # Compute depth values.\n  depth = xnp"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Transform points from world space to camera space.\n  points_in_cam_coords = xnp.matmul(camtoworlds, points)\n  points_in_cam_coords = xnp.stack(\n      [\n          points_in_cam_coords[Ellipsis, 0] / points_in_cam_coords[Ellipsis, 2],\n          points_in_cam_coords[Ellipsis, 1] / points_in_cam_coords[Ellipsis, 2],\n          xnp.ones_like(points_in_cam_coords[Ellipsis, 0]),\n      ],\n      axis=-1,\n  )\n\n  # Apply inverse intrinsics to transform points from camera space to pixel space.\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        points_in_cam_coords[Ellipsis, 0],\n        points_in_cam_coords[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    points_in_cam_coords = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Correct for fisheye distortion.\n    theta = xnp.sqrt(xnp.sum(xnp.square(points_in_cam_coords[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    points_in_cam_coords = xnp.stack(\n        [\n            points_in_cam_coords[Ellipsis, 0] * sin_theta_over_theta,\n            points_in_cam_coords[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Correct for panoramic distortion.\n    theta = points_in_cam_coords[Ellipsis, 0]\n    phi = points_in_cam_coords[Ellipsis, 1]\n    # Neg"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the camera rays.\n  origins, directions, viewdirs, radii, imageplane = pixels_to_rays(\n      pix_x_int=points[Ellipsis, 0],\n      pix_y_int=points[Ellipsis, 1],\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Compute the pixel coordinates.\n  pixels = xnp.stack(\n      [\n          imageplane[Ellipsis, 0] + 0.5,\n          imageplane[Ellipsis, 1] + 0.5,\n          xnp.zeros_like(imageplane[Ellipsis, 0]),\n      ],\n      axis=-1,\n  )\n\n  return pixels, radii"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the rays.\n  origins, directions, viewdirs, radii, imageplane = pixels_to_rays(\n      pix_x_int=points[Ellipsis, 0],\n      pix_y_int=points[Ellipsis, 1],\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Compute the pixel coordinates.\n  pixels = xnp.stack(\n      [\n          imageplane[Ellipsis, 0] + xnp.sign(viewdirs[Ellipsis, 0]),\n          imageplane[Ellipsis, 1] + xnp.sign(viewdirs[Ellipsis, 1]),\n      ],\n      axis=-1,\n  )\n\n  return pixels, radii"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the 3D camera rays from the 3D points.\n  rays = points - camtoworlds[Ellipsis, :3, -1]\n  rays = xnp.stack([rays, xnp.ones_like(rays[Ellipsis, 0])], axis=-1)\n  # Transform the rays from world to camera coordinates.\n  rays = matmul(camtoworlds[Ellipsis, :3, :3], rays)\n\n  # Transform the rays from camera to pixel coordinates.\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        rays[Ellipsis, 0], rays[Ellipsis, 1], **distortion_params, xnp=xnp\n    )\n    rays = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  # Transform the rays from camera to image plane coordinates.\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(rays[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n    rays = xnp.stack(\n        [\n            rays[Ellipsis, 0] * xnp.sin(theta) / theta,\n            rays[Ellipsis, 1] * xnp.sin(theta) / theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = rays[Ellipsis, 0]\n    phi = rays[Ellipsis, 1]\n    rays = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Flip from OpenGL to OpenCV coordinate system.\n  rays = matmul(rays, xnp.diag(xnp.array([1.0, -1.0, -1.0])))\n\n  # Transform the"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Project 3D points onto camera coordinate system.\n  points_to_cam = xnp.matmul(camtoworlds[Ellipsis, :3, :3], points)\n\n  # Apply camera intrinsics.\n  points_to_cam = xnp.matmul(pixtocams[Ellipsis, :3, :3], points_to_cam)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    points_to_cam = _radial_and_tangential_distort(\n        points_to_cam[Ellipsis, 0],\n        points_to_cam[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  points_to_cam = xnp.matmul(\n      points_to_cam, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Extract 2D image plane (x, y) coordinates.\n  imageplane = points_to_cam[Ellipsis, :2]\n\n  # Apply camera rotation matrices.\n  points_to_cam = xnp.matmul(\n      camtoworlds[Ellipsis, :3, :3], points_to_cam\n  )\n\n  # Extract the offset rays.\n  points, dx, dy = points_to_cam\n\n  # Distance from each unit-norm direction vector to its neighbors.\n  dx_norm = xnp.linalg.norm(dx - points, axis=-1)\n  dy_norm = xnp.linalg.norm(dy - points, axis=-1)\n\n  # Cut the distance in half, multiply it to match the variance of a uniform distribution the size of a pixel (1/12, see paper).\n  depth = (0.5 * (dx_norm + dy_norm))[Ellipsis, None] * 2 / xnp.sqrt(12)\n\n  return imageplane, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Compute the rays from the points.\n  rays = points_to_rays(\n      points=points,\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Convert rays from camera space to pixel space.\n  pixtocam = xnp.linalg.inv(pixtocams)\n  ray_to_pixel = functools.partial(\n      convert_to_pixel, pixtocam=pixtocam, xnp=xnp\n  )\n  pixels = ray_to_pixel(rays[0], rays[1])\n\n  return pixels, rays[3]"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera extrinsics to transform points from world to camera space.\n  points_in_cam = xnp.matmul(camtoworlds[Ellipsis, :3, :3], points)\n\n  # Apply inverse intrinsics to transform points from camera to pixel space.\n  points_in_pix = xnp.matmul(pixtocams[Ellipsis, :3, :3], points_in_cam)\n\n  # Extract 2D pixel coordinates.\n  points_in_pix = points_in_pix[Ellipsis, :2]\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    points_in_pix = _radial_and_tangential_undistort(\n        points_in_pix[Ellipsis, 0],\n        points_in_pix[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  points_in_pix = xnp.stack(\n      [points_in_pix[Ellipsis, 0], -points_in_pix[Ellipsis, 1]], axis=-1\n  )\n\n  # Compute depth values.\n  depth = xnp.sqrt(\n      xnp.sum(xnp.square(points_in_cam[Ellipsis, :2]), axis=-1), axis=-1\n  )\n\n  return points_in_pix, depth\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply inverse intrinsic matrices to transform points from pixel to camera space.\n  camera_points = xnp.matmul(pixtocams, points)\n  # Extract the x and y coordinates.\n  x = camera_points[Ellipsis, 0]\n  y = camera_points[Ellipsis, 1]\n\n  # Correct for distortion.\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        x=x, y=y, **distortion_params, xnp=xnp\n    )\n\n  # Apply camera extrinsics to transform points from camera to world space.\n  world_points = xnp.matmul(camtoworlds, xnp.stack([x, y, xnp.ones_like(x)], axis=-1))\n\n  # Extract the x and y coordinates.\n  x = world_points[Ellipsis, 0]\n  y = world_points[Ellipsis, 1]\n\n  # Flip from OpenGL to OpenCV coordinate system.\n  coordinates = xnp.stack([x, y], axis=-1)\n\n  # Extract the depth values.\n  depth = world_points[Ellipsis, 2]\n\n  return coordinates, depth"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2))\n  theta_squared = jnp.sum(w**2)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = w_safe / theta_safe\n  W = skew(w_hat)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      v\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe * spin_math.matmul(W, w_safe)\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**2 * spin_math.matmul(\n          W, spin_math.matmul(W, w_safe)\n      )\n  )\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta_squared > eps**2, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = jnp.sum(w**2, axis=-1)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) / theta_safe * W\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe**2 * spin_math.matmul(W, W)\n  )\n  p = (\n      v\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe**2 * spin_math.matmul(W, v)\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**3 * spin_math.matmul(\n          W, spin_math.matmul(W, v)\n      )\n  )\n  X = rp_to_se3(R, p)\n  return jnp.where(theta_squared > eps**2, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation axis and angle from the screw axis\n  w, v = jnp.split(screw_axis, 2)\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_hat = w_safe / theta_safe\n  W = skew(w_hat)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      v\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe * spin_math.matmul(W, v)\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**2 * spin_math.matmul(\n          W, spin_math.matmul(W, v)\n      )\n  )\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = jnp.split(screw_axis, 2)\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n  p_taylor = v\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe * W\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**2 * spin_math.matmul(W, W)\n  )\n  p = (\n      v\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe**2 * spin_math.matmul(W, v)\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**3 * spin_math.matmul(\n          W, spin_math.matmul(W, v)\n      )\n  )\n\n  return rp_to_se3(\n      jnp.where(theta > eps, R, R_taylor), jnp.where(theta > eps, p, p_taylor)\n  )\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = jnp.split(screw_axis, 2)\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 1.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_hat = w_safe / theta_safe\n  W = skew(w_hat)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n      + theta_safe * W\n  ) @ v\n\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = screw_axis[Ellipsis, 0]\n  w = screw_axis[Ellipsis, 1:4]\n  v = screw_axis[Ellipsis, 4:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(\n      jnp.eye(3),\n      v * theta,\n  )\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  v_safe = jnp.where(theta > eps, v, 0.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      v_safe\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe * spin_math.matmul(W, v_safe)\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**2 * spin_math.matmul(\n          W, spin_math.matmul(W, v_safe)\n      )\n  )\n\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      v\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe * spin_math.matmul(W, v)\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**2 * spin_math.matmul(\n          spin_math.matmul(W, W), v\n      )\n  )\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = jnp.sum(w**2, axis=-1)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * W\n      + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(W, W)\n  ) @ v\n\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta_squared > eps**2, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = jnp.split(screw_axis, 2)\n  theta = jnp.linalg.norm(w)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  axis = w_safe / theta_safe\n  W = skew(axis)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      (jnp.eye(3) - R) @ jnp.reshape(v, (3, 1))\n      + theta_safe * jnp.reshape(axis, (3, 1)) @ jnp.reshape(w, (1, 3))\n  )\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = jnp.sum(w**2, axis=-1)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w) + 0.5 * skew(w) @ skew(w)\n  p_taylor = v + 0.5 * w @ w\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      v\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe * w @ v\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**2 * w @ (w @ v)\n  )\n\n  return rp_to_se3(\n      jnp.where(theta_squared > eps**2, R, R_taylor),\n      jnp.where(theta_squared > eps**2, p, p_taylor),\n  )\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation components from the screw axis\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2))\n\n  # Compute the exponential map for the rotation component\n  R = exp_so3(w, eps)\n\n  # Compute the exponential map for the translation component\n  # Handle the case where theta is close to zero\n  if theta < eps:\n    p = v\n  else:\n    p = (v + (1.0 - jnp.cos(theta)) / theta**2 * jnp.cross(w, v)) * theta\n\n  # Return the homogeneous transformation matrix\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(jnp.eye(3), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      (jnp.eye(3) - R) @ spin_math.matmul(W, v)\n      + theta_safe * jnp.cross(w_safe, v)\n  ) / theta_safe**2\n  return jnp.where(theta > eps, rp_to_se3(R, p), X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = jnp.split(screw_axis, [3])\n  theta = jnp.linalg.norm(w)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor = X_taylor.at[0:3, 3].set(v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe / theta_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (jnp.eye(3) - R) @ jnp.reshape(v, (3, 1)) + theta_safe * W @ jnp.reshape(\n      v, (3, 1)\n  )\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor = jnp.block(\n      [\n          [X_taylor[:3, :3], v[:, jnp.newaxis]],\n          [jnp.array([[0.0, 0.0, 0.0, 1.0]])],\n      ]\n  )\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 1.0)\n  theta_safe = jnp.where(theta > eps, theta, 0.0)\n  W = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = (\n      jnp.eye(3) * (1.0 - jnp.cos(theta_safe))\n      + W * jnp.sin(theta_safe)\n      + spin_math.matmul(W, W) * (theta_safe - jnp.sin(theta_safe))\n  ) @ v[:, jnp.newaxis]\n\n  X = jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation axis and angle from the screw axis\n  w = screw_axis[:3]\n  theta = jnp.linalg.norm(w)\n\n  # Calculate the rotation matrix R\n  R = exp_so3(w, eps)\n\n  # Calculate the translation vector v\n  v = screw_axis[3:]\n\n  # Calculate the homogeneous transformation matrix\n  X = rp_to_se3(R, v)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation components of the screw axis\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Compute the magnitude of the rotation component\n  w_squared = jnp.sum(w**2, axis=-1)\n  w_norm = _safe_sqrt(w_squared)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = exp_so3(w, eps)\n\n  # Compute the translation matrix\n  V = skew(v)\n  V_taylor = jnp.eye(3)\n  R_taylor = jnp.eye(3)\n  w_safe = jnp.where(w_squared > eps**2, w, 0.0)\n  w_norm_safe = jnp.where(w_squared > eps**2, w_norm, 1.0)\n  V_safe = jnp.where(w_squared > eps**2, V, 0.0)\n  R_safe = jnp.where(w_squared > eps**2, R, 0.0)\n  p = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(w_norm_safe)) * spin_math.matmul(V_safe, V_safe)\n      + (w_norm_safe - jnp.sin(w_norm_safe)) * spin_math.matmul(V_safe, R_safe)\n  )\n\n  # Return the homogeneous transformation matrix\n  return rp_to_se3(R, p @ v)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation components from the screw axis\n  w, v = screw_axis[:3], screw_axis[3:]\n\n  # Compute the magnitude of the rotation\n  w_norm = _safe_sqrt(jnp.sum(w**2))\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = exp_so3(w, eps)\n\n  # Compute the translation vector\n  p = (\n      jnp.eye(3)\n      - jnp.sin(w_norm) / w_norm * skew(w)\n      + (1.0 - jnp.cos(w_norm)) / w_norm**2 * spin_math.matmul(skew(w), skew(w))\n  ) @ v\n\n  # Build the homogeneous transformation matrix\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = screw_axis[0]\n  w = screw_axis[1:4]\n  v = screw_axis[4:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor = jnp.where(theta > eps, X_taylor, X_taylor)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = jnp.where(theta > eps, w, 1.0)\n  v_safe = jnp.where(theta > eps, v, 1.0)\n\n  # Compute the rotation matrix.\n  R = exp_so3(w_safe, eps)\n\n  # Compute the translation vector.\n  W = skew(w_safe)\n  p = (\n      v_safe\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, v_safe)\n      + theta_safe * jnp.sin(theta_safe) * spin_math.matmul(W, W, v_safe)\n  )\n\n  # Return the homogeneous transformation matrix.\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation components from the screw axis\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Compute the magnitude of the rotation and translation components\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n  delta = _safe_sqrt(jnp.sum(v**2, axis=-1))\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = exp_so3(w, eps)\n\n  # Compute the translation matrix using the first order Taylor expansion\n  # when theta is small\n  p = jnp.where(\n      theta_squared > eps**2,\n      (jnp.sin(theta) / theta) * v + ((1.0 - jnp.cos(theta)) / theta**2) * (\n          w @ v\n      ) * w,\n      v,\n  )\n\n  # Compute the homogeneous transformation matrix\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = screw_axis[0]\n  w = screw_axis[1:4]\n  v = screw_axis[4:7]\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = jnp.where(theta > eps, w, 0.0)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4) + jnp.block(\n      [[skew(v), v], [jnp.array([[0.0, 0.0, 0.0, 0.0]]), 1.0]]\n  )\n\n  # Compute the exponential map for the rotation matrix.\n  R = exp_so3(w_safe, eps)\n\n  # Compute the exponential map for the translation vector.\n  v_hat = jnp.eye(3) + (1.0 - jnp.cos(theta_safe)) * skew(w_safe) / theta_safe\n  v_hat += (theta_safe - jnp.sin(theta_safe)) * skew(w_safe) / theta_safe**2\n  v_hat = v_hat @ v\n\n  X = jnp.block([[R, v_hat], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * skew(\n        axis\n    ) @ skew(axis)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * skew(axis) @ skew(axis)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(jnp.square(axis_angle)))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * jnp.matmul(skew(axis), skew(axis))\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1.0 - jnp.cos(theta)) * jnp.matmul(\n        axis[:, None], axis[None, :]\n    )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis_angle = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis_angle) + (1 - jnp.cos(theta)) * skew(axis_angle) @ skew(axis_angle)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * skew(\n        axis\n    ) @ skew(axis)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    R = jnp.eye(3)\n  else:\n    axis_angle = jnp.reshape(axis_angle, (3))\n    axis = axis_angle / theta\n    K = skew(axis)\n    R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis_angle = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis_angle) + (1.0 - jnp.cos(theta)) * jnp.matmul(\n        skew(axis_angle), skew(axis_angle)\n    )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  axis = axis_angle / theta\n  axis = jnp.where(theta < eps, jnp.array([1.0, 0.0, 0.0]), axis)\n  axis = jnp.reshape(axis, (3, 1))\n  R = jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * skew(\n      axis) @ skew(axis)\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(jnp.square(axis_angle)))\n  if theta < eps:\n    # If the angle is small, use the first-order approximation of Rodrigues' formula\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    # Otherwise, use the full formula\n    return jnp.eye(3) + jnp.sin(theta) / theta * skew(axis_angle) + (1 - jnp.cos(theta)) / theta**2 * jnp.matmul(skew(axis_angle), skew(axis_angle))\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis = jnp.reshape(axis_angle, (3))\n  theta = _safe_sqrt(jnp.sum(axis**2))\n  if theta < eps:\n    R = jnp.eye(3)\n  else:\n    k = axis / theta\n    kx = skew(k)\n    R = jnp.eye(3) + jnp.sin(theta) * kx + (1 - jnp.cos(theta)) * kx @ kx\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    # If the angle is small, we use the first-order approximation of Rodrigues' formula\n    # to avoid numerical instability.\n    return jnp.eye(3) + jnp.array([\n        [0, -axis_angle[2], axis_angle[1]],\n        [axis_angle[2], 0, -axis_angle[0]],\n        [-axis_angle[1], axis_angle[0], 0],\n    ])\n  else:\n    # Otherwise, we use the full formula.\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * skew(\n        axis\n    ) @ skew(axis)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(jnp.square(axis_angle)))\n  theta_eps = jnp.where(theta > eps, theta, jnp.finfo(jnp.float32).eps)\n  axis_angle_norm = axis_angle / theta_eps\n  return jnp.eye(3) + jnp.sin(theta) * skew(axis_angle_norm) + (\n      1 - jnp.cos(theta)\n  ) * skew(axis_angle_norm) @ skew(axis_angle_norm)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(jnp.square(axis_angle)))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis_angle = jnp.reshape(axis_angle, (3,))\n    axis = axis_angle / theta\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1.0 - jnp.cos(theta)) * jnp.outer(axis, axis)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    return jnp.eye(3) + jnp.sin(theta) * skew(axis_angle) / theta + (\n        1 - jnp.cos(theta)\n    ) * skew(axis_angle) @ skew(axis_angle) / theta**2\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Get the axis and angle of rotation\n  axis = axis_angle[:3]\n  theta = jnp.linalg.norm(axis_angle)\n\n  # Handle the case where the angle is very small\n  if theta < eps:\n    R = jnp.eye(3) + skew(axis) + 0.5 * skew(axis) @ skew(axis)\n  else:\n    # Compute the rotation matrix using Rodrigues' formula\n    R = jnp.eye(3) + jnp.sin(theta) / theta * skew(axis) + (1 - jnp.cos(theta)) / (\n        theta ** 2\n    ) * skew(axis) @ skew(axis)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute the angle of rotation from the magnitude of the axis-angle vector\n  theta = _safe_sqrt(jnp.sum(axis_angle**2))\n\n  # If the angle of rotation is very small, use a different formula to avoid numerical instability\n  if theta < eps:\n    R = jnp.eye(3) + jnp.sin(theta) / theta * skew(axis_angle) + (\n      1 - jnp.cos(theta) / theta\n    ) * jnp.matmul(skew(axis_angle), skew(axis_angle))\n  else:\n    R = jnp.eye(3) + jnp.sin(theta) / theta * skew(axis_angle) + (\n      1 - jnp.cos(theta) / theta\n    ) * jnp.matmul(skew(axis_angle), skew(axis_angle))\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = _safe_sqrt(jnp.sum(jnp.square(axis_angle)))\n\n  if theta < eps:\n    # For small angles, use the first-order Taylor expansion of Rodrigues' formula\n    return jnp.eye(3) + jnp.array([[0.0, -axis_angle[2], axis_angle[1]], [axis_angle[2], 0.0, -axis_angle[0]], [-axis_angle[1], axis_angle[0], 0.0]])\n\n  # Compute the rotation matrix using Rodrigues' formula\n  k = axis_angle / theta\n  kx = jnp.array([[0.0, -k[2], k[1]], [k[2], 0.0, -k[0]], [-k[1], k[0], 0.0]])\n  return jnp.eye(3) + jnp.sin(theta) * kx + (1 - jnp.cos(theta)) * kx @ kx\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute the norm of the axis-angle vector\n  theta = jnp.linalg.norm(axis_angle)\n\n  # Check if the norm is close to zero\n  if theta < eps:\n    # If the norm is close to zero, return the identity matrix\n    return jnp.eye(3)\n\n  # Normalize the axis-angle vector\n  axis_angle = axis_angle / theta\n\n  # Compute the sine and cosine of theta\n  sin_theta = jnp.sin(theta)\n  cos_theta = jnp.cos(theta)\n\n  # Compute the cross-product matrix of the normalized axis-angle vector\n  cross_product_matrix = jnp.array(\n      [[0, -axis_angle[2], axis_angle[1]],\n       [axis_angle[2], 0, -axis_angle[0]],\n       [-axis_angle[1], axis_angle[0], 0]]\n  )\n\n  # Compute the rotation matrix using Rodrigues' formula\n  rotation_matrix = jnp.eye(3) * cos_theta + (1 - cos_theta) * jnp.outer(\n      axis_angle, axis_angle\n  ) + sin_theta * cross_product_matrix\n\n  return rotation_matrix\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Reshape the input axis-angle vector to a 3x1 array\n  axis_angle = jnp.reshape(axis_angle, (3, 1))\n\n  # Compute the norm of the axis-angle vector\n  axis_angle_norm = jnp.linalg.norm(axis_angle)\n\n  # If the norm is close to zero, return the identity matrix\n  if axis_angle_norm < eps:\n    return jnp.eye(3)\n\n  # Compute the rotation angle from the norm of the axis-angle vector\n  theta = axis_angle_norm\n\n  # Compute the axis of rotation from the normalized axis-angle vector\n  axis = axis_angle / axis_angle_norm\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(theta) * skew(axis) + (1 - jnp.cos(theta)) * skew(\n      axis) @ skew(axis)\n\n  # Return the rotation matrix\n  return R\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var * base_radius**2, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian distribution\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # Calculate the covariance matrix\n  if diag:\n    cov = jnp.diag(cov)\n  else:\n    cov = jnp.einsum(\"...ij,...ik->...jk\", cov, cov)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean = mean.squeeze(-1)\n  cov = cov.squeeze(-1)\n\n  # Calculate the covariance matrix\n  if diag:\n    cov = jnp.diag(cov)\n  else:\n    cov = jnp.einsum(\"...ij,...ik->...jk\", cov, cov)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean = mean.squeeze(-1)\n  cov = cov.squeeze(-1)\n\n  # Calculate the covariance matrix\n  if diag:\n    cov = jnp.diag(cov)\n  else:\n    cov = jnp.einsum(\"...ij,...ik->...jk\", cov, cov)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean = mean.squeeze(-1)\n  cov = cov.squeeze(-1)\n\n  # Calculate the covariance matrix\n  if diag:\n    cov = jnp.diag(cov)\n  else:\n    cov = jnp.einsum(\"...ij,...ik->...jk\", cov, cov)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean = mean.squeeze(-1)\n  cov = cov.squeeze(-1)\n\n  # Calculate the covariance matrix\n  if diag:\n    cov = jnp.diag(cov)\n  else:\n    cov = jnp.einsum(\"...ij,...ik->...jk\", cov, cov)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean = mean.squeeze(-1)\n  cov = cov.squeeze(-1)\n\n  # Calculate the covariance matrix\n  if diag:\n    cov = jnp.diag(cov)\n  else:\n    cov = jnp.einsum(\"...ij,...ik->...jk\", cov, cov)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean = mean.squeeze(-1)\n  cov = cov."}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * base_radius\n  t_var = t_var * base_radius**2\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * base_radius\n  t_var = t_var * base_radius**2\n  r_var = r_var * base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian distribution\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Calculate the mean and covariance of the Gaussian distribution\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # Add the base radius to the mean and covariance\n  mean = mean + base_radius * d[Ellipsis, None]\n  cov = cov + base_radius**2\n\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  r_var = r_var * base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * base_radius\n  t_var = t_var * base_radius**2\n  r_var = r_var * base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # The Gaussian is lifted to 3D coordinates.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  # The covariance is scaled by the radius at the mean distance.\n  cov *= base_radius**2\n\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, base_radius, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Convert intervals along a conical frustum into means and variances.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Lift a Gaussian defined along a ray to 3D coordinates.\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var * base_radius**2, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var = base_radius**2 * r_var\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  def _compute_ray_origins_and_directions(\n      pix_x,\n      pix_y,\n      pixtocams,\n      camtoworlds,\n      camtype,\n      xnp = np,\n  ):\n    \"\"\"\n    Auxiliary function of pixels_to_rays(). Computes ray origins and directions.\n\n    Input-Output Arguments\n    :param pix_x: float array, shape SH, the x coordinates of image pixels, used as part of the input to compute ray directions.\n    :param pix_y: float array, shape SH, the y coordinates of image pixels, used alongside pix_x to compute ray directions.\n    :param pixtocams: float array, broadcastable to SH + [3, 3], the inverse intrinsics of the cameras, used to transform pixel coordinates to camera coordinates.\n    :param camtoworlds: float array, broadcastable to SH + [3, 4], the extrinsics of the cameras, used to transform camera coordinates to world coordinates.\n    :param camtype: camera_utils.ProjectionType, the type of camera projection (e.g., fisheye or perspective), affects how rays are computed based on the camera model.\n    :param xnp: module, either numpy or jax.numpy, the numerical library used for computations, allowing the function to be used with different backends.\n\n    :return: A tuple containing:\n             - origins: float array, shape SH + [3], the origin points of the rays in world coordinates.\n             - directions: float array, shape SH + [3], the direction vectors of the rays in world coordinates.\n    \"\"\"\n    # Transform pixel coordinates to camera coordinates.\n    cam_x = pix_x * pixtocams[:, 0] + pixtocams[:, 2]\n    cam_y = pix_y * pixtocams[:, 1] + pixtocams[:, 2]\n\n    # Transform camera coordinates to world coordinates.\n    world_x = cam_x * camtoworlds[:, 0] + camtoworlds[:, 3]\n    world_y = cam_y * camtoworlds[:, 1] + camtoworlds[:, 3]\n    world_z = cam_x * camtoworlds[:, 2] + cam_y * camtoworlds[:, 2] + camtoworlds[:, "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if distortion_params is None:\n    distortion_params = {}\n\n  if pixtocam_ndc is None:\n    pixtocam_ndc = xnp.array(\n        [\n            [1.0, 0.0, 0.0],\n            [0.0, 1.0, 0.0],\n            [0.0, 0.0, 1.0],\n        ]\n    )\n\n  if camtype is None:\n    camtype = ProjectionType.PERSPECTIVE\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x = xnp.where(\n      xnp.abs(pixtocams[:, 0, 0]) > 1e-9,\n      pixtocams[:, 0, 0] * pix_x_int + pixtocams[:, 0, 2],\n      xnp.zeros_like(pix_x_int),\n  )\n  cam_y = xnp.where(\n      xnp.abs(pixtocams[:, 1, 1]) > 1e-9,\n      pixtocams[:, 1, 1] * pix_y_int + pixtocams[:, 1, 2],\n      xnp.zeros_like(pix_y_int),\n  )\n\n  # Convert camera coordinates to world coordinates.\n  world_x = xnp.where(\n      xnp.abs(camtoworlds[:, 0, 0]) > 1e-9,\n      camtoworlds[:, 0, 0] * cam_x + camtoworlds[:, 0, 3],\n      xnp.zeros_like(cam_x),\n  )\n  world_y = xnp.where(\n      xnp.abs(camtoworlds[:, 1, 1]) > 1e-9,\n      camtoworlds[:, 1, 1] * cam_y + camtoworlds[:, 1, 3],\n      xnp.zeros_like(cam_y),\n  )\n  world_z = xnp.where(\n      xnp.abs(camtoworlds[:, 2, 2]) > 1e-9,\n      camtoworlds[:, 2, 2] * cam_y + camtoworlds[:, 2, 3],\n      x"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Let's define the following:\n  #\n  # - pix_x_int: int array, shape SH, the x coordinates of image pixels, used as part of the input to compute ray directions.\n  # - pix_y_int: int array, shape SH, the y coordinates of image pixels, used alongside pix_x_int to compute ray directions.\n  # - pixtocams: float array, broadcastable to SH + [3, 3], the inverse intrinsics of the cameras, used to transform pixel coordinates to camera coordinates.\n  # - camtoworlds: float array, broadcastable to SH + [3, 4], the extrinsics of the cameras, used to transform camera coordinates to world coordinates.\n  # - distortion_params: dict of floats, optional, camera distortion parameters for correcting lens distortion in the computed rays.\n  # - pixtocam_ndc: float array, [3, 3], optional, inverse intrinsics for Normalized Device Coordinates (NDC) projection, used when converting ray origins and directions into NDC space.\n  # - camtype: camera_utils.ProjectionType, the type of camera projection (e.g., fisheye or perspective), affects how rays are computed based on the camera model.\n  # - xnp: module, either numpy or jax.numpy, the numerical library used for computations, allowing the function to be used with different backends.\n  #\n  # Let's define the following:\n  #\n  # - pix_x: float array, shape SH, the x coordinates of image pixels, used as part of the input to compute ray directions.\n  # - pix_y: float array, shape SH, the y coordinates of image pixels, used alongside pix_x to compute ray directions.\n  # - pixtocam: float array, shape SH + [3, 3], the inverse intrinsics of the cameras, used to transform pixel coordinates to camera coordinates.\n  # - camtoworld: float array, shape SH + [3, 4], the extrinsics of the cameras, used to transform camera coordinates to world coordinates.\n  # - distortion_params: dict of floats, optional, camera distortion parameters for correcting lens distortion in the computed rays.\n  # - pixtocam_ndc: float array, [3, 3],"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  def _fisheye_distort(\n      x,\n      y,\n      k1 = 0,\n      k2 = 0,\n      k3 = 0,\n      k4 = 0,\n      p1 = 0,\n      p2 = 0,\n  ):\n    \"\"\"\n    Computes the distorted pixel positions for a fisheye camera.\n\n    Input-Output Arguments\n    :param x: float, the x coordinate of a pixel in the image plane.\n    :param y: float, the y coordinate of a pixel in the image plane.\n    :param k1: float, optional, radial distortion parameter.\n    :param k2: float, optional, radial distortion parameter.\n    :param k3: float, optional, radial distortion parameter.\n    :param k4: float, optional, radial distortion parameter.\n    :param p1: float, optional, tangential distortion parameter.\n    :param p2: float, optional, tangential distortion parameter.\n\n    :return: A tuple containing:\n             - xd: float, the distorted x coordinate of a pixel in the image plane.\n             - yd: float, the distorted y coordinate of a pixel in the image plane.\n    \"\"\"\n    r2 = x * x + y * y\n    radial_distortion = r2 * (k1 + r2 * (k2 + r2 * (k3 + r2 * k4)))\n    dx_radial = x * radial_distortion\n    dy_radial = y * radial_distortion\n    dx_tangential = 2 * p1 * x * y + p2 * (r2 + 2 * x * x)\n    dy_tangential = 2 * p2 * x * y + p1 * (r2 + 2 * y * y)\n    return x + dx_radial + dx_tangential, y + dy_radial + dy_tangential\n\n  def _pano_distort(\n      x,\n      y,\n      k1 = 0,\n      k2 = 0,\n      k3 = 0,\n      k4 = 0,\n      p1 = 0,\n      p2 = 0,\n  ):\n    \"\"\"\n    Computes the distorted pixel positions for a panoramic camera.\n\n    Input-Output Arguments\n    :param x: float,"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input camera projection type is fisheye.\n  is_fisheye = camtype == ProjectionType.FISHEYE\n\n  # Check if the input camera projection type is panoramic.\n  is_panoramic = camtype == ProjectionType.PANORAMIC\n\n  # Check if the input camera projection type is perspective.\n  is_perspective = camtype == ProjectionType.PERSPECTIVE\n\n  # Check if the input camera projection type is 360 pano.\n  is_pano = camtype == ProjectionType.PANO\n\n  # Check if the input camera projection type is fisheye or panoramic.\n  is_fisheye_or_panoramic = is_fisheye or is_panoramic\n\n  # Check if the input camera projection type is perspective or fisheye.\n  is_perspective_or_fisheye = is_perspective or is_fisheye\n\n  # Check if the input camera projection type is perspective, fisheye, or panoramic.\n  is_perspective_or_fisheye_or_panoramic = (\n      is_perspective or is_fisheye or is_panoramic\n  )\n\n  # Check if the input camera projection type is perspective, fisheye, panoramic, or 360 pano.\n  is_perspective_or_fisheye_or_panoramic_or_pano = (\n      is_perspective or is_fisheye or is_panoramic or is_pano\n  )\n\n  # Check if the input camera projection type is perspective, fisheye, panoramic, or 360 pano.\n  is_perspective_or_fisheye_or_panoramic_or_pano = (\n      is_perspective or is_fisheye or is_panoramic or is_pano\n  )\n\n  # Check if the input camera projection type is perspective, fisheye, panoramic, or 360 pano.\n  is_perspective_or_fisheye_or_panoramic_or_pano = (\n      is_perspective or is_fisheye or is_panoramic or is_pano\n  )\n\n  # Check if the input"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  def _fisheye_distort_rays(\n      pix_x_int,\n      pix_y_int,\n      pixtocams,\n      camtoworlds,\n      distortion_params = None,\n      pixtocam_ndc = None,\n      xnp = np,\n  ):\n    \"\"\"Computes rays for a fisheye camera given pixel coordinates, inverse intrinsics, and extrinsics.\"\"\"\n    # From https://github.com/google/nerfies/blob/main/nerfies/camera.py\n    # let r(x, y) = x^2 + y^2;\n    #     d(x, y) = 1 + k1 * r(x, y) + k2 * r(x, y) ^2 + k3 * r(x, y)^3 +\n    #                   k4 * r(x, y)^4;\n    #     xd(x, y) = x * d(x, y) + 2 * p1 * x * y + p2 * (r(x, y) + 2 * x^2);\n    #     yd(x, y) = y * d(x, y) + 2 * p2 * x * y + p1 * (r(x, y) + 2 * y^2);\n    #\n    # let fx(x, y) = xd(x, y) - x;\n    #     fy(x, y) = yd(x, y) - y;\n    #\n    # let fx_x(x, y) = d(x, y) + d_x(x, y) * x + 2 * p1 * y + 6 * p2 * x;\n    #     fx_y(x, y) = d_y(x, y) * x + 2 * p1 * x + 2 * p2 * y;\n    #\n    # let fy_x(x, y) = d_x(x, y) * y + 2 * p2 * y + 2 * p1 * x;\n    #     fy_y(x, y) = d(x, y) + d_y(x, y) * y + 2 * p2 * x + 6 * p"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get the inverse intrinsics for the cameras.\n  camtopixs = xnp.linalg.inv(pixtocams)\n\n  # Get the extrinsics for the cameras.\n  pixtoworlds = xnp.matmul(camtopixs, camtoworlds)\n\n  # Get the pixel coordinates in world space.\n  world_x = pixtoworlds[:, 0]\n  world_y = pixtoworlds[:, 1]\n\n  # Compute the ray origins and directions in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is the origin of the ray in world space.\n  # The ray direction is the direction of the ray in world space.\n  #\n  # The ray origin is"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # The input pixel coordinates are in NDC space.\n  # The input camera inverse intrinsics are in NDC space.\n  # The input camera extrinsics are in world space.\n  # The output ray origins are in world space.\n  # The output ray directions are in world space.\n  # The output ray normalized directions are in world space.\n  # The output ray differential radii are in world space.\n  # The output image plane coordinates are in NDC space.\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x_float = xnp.array(pix_x_int, dtype=xnp.float)\n  cam_y_float = xnp.array(pix_y_int, dtype=xnp.float)\n  cam_x_float, cam_y_float = _radial_and_tangential_undistort(\n      cam_x_float,\n      cam_y_float,\n      k1=distortion_params.get('k1', 0),\n      k2=distortion_params.get('k2', 0),\n      k3=distortion_params.get('k3', 0),\n      k4=distortion_params.get('k4', 0),\n      p1=distortion_params.get('p1', 0),\n      p2=distortion_params.get('p2', 0),\n  )\n  cam_x = xnp.array(cam_x_float, dtype=xnp.int)\n  cam_y = xnp.array(cam_y_float, dtype=xnp.int)\n\n  # Convert camera coordinates to world coordinates.\n  world_x = xnp.matmul(pixtocams, xnp.stack([cam_x, cam_y, xnp.ones_like(cam_x)]))\n  world_y = xnp.matmul(pixtocams, xnp.stack([cam_x, cam_y, xnp.ones_like(cam_y)]))\n  world_z = xnp.matmul(pixtocams, xnp.stack([cam_x, cam_y, xnp.zeros_like(cam_x)]))\n  world_x = xnp.matmul(camtoworlds, xnp.stack([world_x, world_y, world"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input camera projection type is supported.\n  if camtype not in (\n      ProjectionType.PERSPECTIVE,\n      ProjectionType.FISHEYE,\n      ProjectionType.PANORAMIC,\n  ):\n    raise ValueError(\n        'The input camera projection type is not supported, '\n        'only perspective pinhole, fisheye, and panoramic are supported.'\n    )\n\n  # Check if the input distortion parameters are supported.\n  if distortion_params is not None:\n    if (\n        'k1' not in distortion_params\n        or 'k2' not in distortion_params\n        or 'k3' not in distortion_params\n        or 'k4' not in distortion_params\n        or 'p1' not in distortion_params\n        or 'p2' not in distortion_params\n    ):\n      raise ValueError(\n          'The input distortion parameters are not supported, '\n          'k1, k2, k3, k4, p1, and p2 are required.'\n      )\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    k4 = distortion_params['k4']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n  else:\n    k1 = 0.0\n    k2 = 0.0\n    k3 = 0.0\n    k4 = 0.0\n    p1 = 0.0\n    p2 = 0.0\n\n  # Check if the input pixtocam_ndc is supported.\n  if pixtocam_ndc is not None:\n    if pixtocam_ndc.shape != (3, 3):\n      raise ValueError(\n          'The input pixtocam_ndc is not supported, '\n          'it must be of shape (3, 3).'\n      )\n  else:\n    pixtocam_ndc = xnp.eye((3, 3), dtype=xnp.float)\n\n  # Check if the input pix_x_int and pix_y_int are supported.\n  if pix_x_int.shape != pix_y_int.shape:\n    raise ValueError(\n        'The input"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input is jax.numpy.\n  if xnp is not np:\n    # If the input is jax.numpy, convert the input pixel coordinates to numpy.\n    pix_x_int = xnp.asarray(pix_x_int)\n    pix_y_int = xnp.asarray(pix_y_int)\n\n  # Convert the pixel coordinates to camera coordinates.\n  cam_x = xnp.where(pixtocams is not None, pixtocams[Ellipsis, 0, 0], 0)\n  cam_y = xnp.where(pixtocams is not None, pixtocams[Ellipsis, 1, 1], 0)\n  cam_z = xnp.where(pixtocams is not None, pixtocams[Ellipsis, 2, 2], 0)\n  cam_x = cam_x + pix_x_int * pixtocams[Ellipsis, 0, 2]\n  cam_y = cam_y + pix_y_int * pixtocams[Ellipsis, 1, 2]\n  cam_z = cam_z + 1.0\n\n  # Convert the camera coordinates to world coordinates.\n  world_x = xnp.where(camtoworlds is not None, camtoworlds[Ellipsis, 0, 0], 0)\n  world_y = xnp.where(camtoworlds is not None, camtoworlds[Ellipsis, 1, 1], 0)\n  world_z = xnp.where(camtoworlds is not None, camtoworlds[Ellipsis, 2, 2], 0)\n  world_x = world_x + cam_x * camtoworlds[Ellipsis, 0, 3]\n  world_y = world_y + cam_y * camtoworlds[Ellipsis, 1, 3]\n  world_z = world_z + cam_z * camtoworlds[Ellipsis, 2, 3]\n\n  # Compute the ray origin and direction.\n  ray_x = xnp.where(camtoworlds is not None, camtoworlds[Ellipsis, 0, 0], 0)\n  ray_y = xnp.where"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if distortion_params is None:\n    # Default distortion parameters.\n    distortion_params = {\n        'k1': 0.0,\n        'k2': 0.0,\n        'k3': 0.0,\n        'k4': 0.0,\n        'p1': 0.0,\n        'p2': 0.0,\n    }\n\n  if pixtocam_ndc is None:\n    # Default pixtocam_ndc.\n    pixtocam_ndc = xnp.array(\n        [\n            [1.0, 0.0, 0.0],\n            [0.0, 1.0, 0.0],\n            [0.0, 0.0, 1.0],\n        ]\n    )\n\n  # Compute pixel coordinates in camera space.\n  cam_x, cam_y = pixel_coordinates(width=2, height=2, xnp=xnp)\n\n  # Compute pixel coordinates in world space.\n  world_x = xnp.matmul(pixtocams, cam_x)\n  world_y = xnp.matmul(pixtocams, cam_y)\n\n  # Compute ray origins in world space.\n  origins = xnp.matmul(camtoworlds, xnp.stack([world_x, world_y, xnp.ones_like(world_x)], axis=0))\n\n  # Compute ray directions in world space.\n  directions = xnp.matmul(camtoworlds, xnp.stack([xnp.ones_like(world_x), xnp.zeros_like(world_x), xnp.zeros_like(world_x)], axis=0))\n\n  # Compute normalized ray directions in world space.\n  viewdirs = xnp.linalg.normalize(directions, axis=0)\n\n  # Compute ray differential radii.\n  radii = xnp.linalg.norm(viewdirs, axis=0)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.matmul(pixtocam_ndc, xnp.stack([origins, xnp.ones_like(origins)], axis=0))\n\n  # Compute ray origins and directions in NDC space.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray orig"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input is a jax.numpy array.\n  if xnp is None:\n    # Use numpy by default.\n    xnp = np\n\n  # Check if the input camera type is a fisheye camera.\n  fisheye = camtype == ProjectionType.FISHEYE\n\n  # Check if the input camera type is a panoramic camera.\n  panoramic = camtype == ProjectionType.PANORAMIC\n\n  # Check if the input camera type is a perspective camera.\n  perspective = camtype == ProjectionType.PERSPECTIVE\n\n  # Check if the input camera type is a pano camera.\n  pano = camtype == ProjectionType.PANORAMIC\n\n  # Check if the input camera type is a fisheye or perspective camera.\n  fisheye_perspective = fisheye or perspective\n\n  # Check if the input camera type is a fisheye or panoramic camera.\n  fisheye_panoramic = fisheye or panoramic\n\n  # Check if the input camera type is a fisheye, panoramic, or perspective camera.\n  fisheye_panoramic_perspective = fisheye or panoramic or perspective\n\n  # Check if the input camera type is a fisheye, panoramic, perspective, or pano camera.\n  fisheye_panoramic_perspective_pano = fisheye or panoramic or perspective or pano\n\n  # Check if the input distortion parameters are valid.\n  if distortion_params is None:\n    # Use default distortion parameters.\n    distortion_params = {\n        'k1': 0.0,\n        'k2': 0.0,\n        'k3': 0.0,\n        'k4': 0.0,\n        'p1': 0.0,\n        'p2': 0.0,\n    }\n\n  # Check if the input distortion parameters are valid.\n  if distortion_params is not None:\n    # Use the input distortion parameters.\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    k4 = distortion_params['k4']\n    p1 = distortion_params['"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  def _compute_ray_origins_and_directions(\n      pix_x,\n      pix_y,\n      pixtocams,\n      camtoworlds,\n      xnp,\n  ):\n    \"\"\"Computes ray origins and directions.\"\"\"\n    # Compute camera coordinates from pixel coordinates.\n    cam_x = pix_x * pixtocams[Ellipsis, 0] + pixtocams[Ellipsis, 2]\n    cam_y = pix_y * pixtocams[Ellipsis, 1] + pixtocams[Ellipsis, 2]\n\n    # Compute world coordinates from camera coordinates.\n    world_x = cam_x * camtoworlds[Ellipsis, 0] + camtoworlds[Ellipsis, 3]\n    world_y = cam_y * camtoworlds[Ellipsis, 1] + camtoworlds[Ellipsis, 3]\n    world_z = cam_x * camtoworlds[Ellipsis, 2] + camtoworlds[Ellipsis, 3]\n\n    # Compute ray origins and directions.\n    origins = xnp.stack(world_x, world_y, world_z, axis=0)\n    directions = xnp.stack(\n        camtoworlds[Ellipsis, 0], camtoworlds[Ellipsis, 1], camtoworlds[Ellipsis, 2],\n    )\n\n    return origins, directions\n\n  def _compute_viewdirs_and_radii(\n      origins,\n      directions,\n      distortion_params,\n      pixtocam_ndc,\n      camtype,\n      xnp,\n  ):\n    \"\"\"Computes normalized view directions and differential radii.\"\"\"\n    # Compute normalized view directions.\n    viewdirs = xnp.linalg.norm(directions, axis=0)\n    # Compute differential radii.\n    radii = xnp.linalg.norm(origins, axis=0)\n\n    if distortion_params is not None:\n      if camtype == ProjectionType.FISHEYE:\n        # Compute undistorted pixel coordinates from distorted pixel coordinates.\n        pix_x, pix_y = radial_and_tangential_undistort(\n            x=origins[Ellipsis, 0],\n            y=origins[Ellipsis, 1],\n           "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get the x and y pixel coordinates in NDC space.\n  pix_x_ndc, pix_y_ndc = pixel_coordinates(width=pix_x_int.max(), height=pix_y_int.max(), xnp=xnp)\n\n  # Transform pixel coordinates to camera coordinates.\n  cam_x_ndc = pix_x_ndc * pixtocams[:, 0] + pixtocams[:, 2]\n  cam_y_ndc = pix_y_ndc * pixtocams[:, 1] + pixtocams[:, 2]\n\n  # Transform camera coordinates to world coordinates.\n  world_x_ndc = cam_x_ndc * camtoworlds[:, 0] + camtoworlds[:, 3]\n  world_y_ndc = cam_y_ndc * camtoworlds[:, 1] + camtoworlds[:, 3]\n\n  # Transform world coordinates to ray origins and directions.\n  ray_x_ndc = world_x_ndc * camtoworlds[:, 0] + camtoworlds[:, 1]\n  ray_y_ndc = world_y_ndc * camtoworlds[:, 0] + camtoworlds[:, 2]\n  ray_z_ndc = world_x_ndc * camtoworlds[:, 1] + camtoworlds[:, 2]\n\n  # Compute ray directions in NDC space.\n  ray_x_ndc_dir = camtoworlds[:, 0]\n  ray_y_ndc_dir = camtoworlds[:, 1]\n  ray_z_ndc_dir = camtoworlds[:, 2]\n\n  # Transform ray origins and directions to NDC space.\n  ray_x_ndc = ray_x_ndc * camtoworlds[:, 0] + camtoworlds[:, 1]\n  ray_y_ndc = ray_y_ndc * camtoworlds[:, 0] + camtoworlds[:, 2]\n  ray_z_ndc = ray_x_ndc * camtoworlds[:, 1] + camtoworlds[:, 2]\n\n  # Transform ray origins and directions to world space.\n  ray_x_world"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  def _compute_ray_origins_and_directions(\n      pix_x,\n      pix_y,\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp,\n  ):\n    \"\"\"Computes ray origins and directions.\"\"\"\n    # Compute ray origins and directions.\n    # Adapted from https://github.com/google/nerfies/blob/main/nerfies/camera.py\n    #\n    # Let\n    #\n    #     x = pix_x * pixtocams[Ellipsis, 0, 0] + pixtocams[Ellipsis, 2, 0];\n    #     y = pix_y * pixtocams[Ellipsis, 1, 1] + pixtocams[Ellipsis, 2, 1];\n    #\n    #     fx(x, y) = x * d(x, y) + 2 * p1 * x * y + p2 * (r(x, y) + 2 * x^2) - x;\n    #     fy(x, y) = y * d(x, y) + 2 * p2 * x * y + p1 * (r(x, y) + 2 * y^2) - y;\n    #\n    #     d(x, y) = 1 + k1 * r(x, y) + k2 * r(x, y)^2 + k3 * r(x, y)^3 + k4 * r(x, y)^4;\n    #     r(x, y) = x^2 + y^2;\n    #\n    #     p1 = distortion_params['radial_tangential_p1'];\n    #     p2 = distortion_params['radial_tangential_p2'];\n    #     k1 = distortion_params['radial_tangential_k1'];\n    #     k2 = distortion_params['radial_tangential_k2'];\n    #     k3 = distortion_params['radial_tangential_k3'];\n    #     k4 = distortion_params['radial_tangential_k4'];\n    #\n    #     Let's define\n    #\n    #     fx_x(x, y) = d(x, y) +"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input is valid.\n  if pix_x_int.shape != pix_y_int.shape:\n    raise ValueError(\n        'pixels_to_rays() was passed pix_x_int and pix_y_int of different '\n        'shapes.'\n    )\n  if pixtocams.shape != pix_x_int.shape + [3, 3]:\n    raise ValueError(\n        'pixels_to_rays() was passed pixtocams of different shape than '\n        'pix_x_int and pix_y_int.'\n    )\n  if camtoworlds.shape != pix_x_int.shape + [3, 4]:\n    raise ValueError(\n        'pixels_to_rays() was passed camtoworlds of different shape than '\n        'pix_x_int and pix_y_int.'\n    )\n  if camtype not in ProjectionType.__members__:\n    raise ValueError(\n        'pixels_to_rays() was passed camtype not in '\n        'camera_utils.ProjectionType.__members__.'\n    )\n\n  # Compute camera coordinates from pixel coordinates.\n  cam_x = pix_x_int - pixtocams[:, 2]\n  cam_y = pix_y_int - pixtocams[:, 1]\n\n  # Compute world coordinates from camera coordinates.\n  world_x = camtoworlds[:, 0, 0] * cam_x + camtoworlds[:, 0, 1] * cam_y + camtoworlds[:, 0, 2]\n  world_y = camtoworlds[:, 1, 0] * cam_x + camtoworlds[:, 1, 1] * cam_y + camtoworlds[:, 1, 2]\n  world_z = camtoworlds[:, 2, 0] * cam_x + camtoworlds[:, 2, 1] * cam_y + camtoworlds[:, 2, 2]\n\n  # Compute ray origins and directions in world space.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # The ray origins are the world coordinates.\n    origins = xnp.stack([world_x, world_y, world_z], axis=-1)\n    # The ray directions are the world coordinates."}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Ensure that the input camera parameters are broadcastable to the shape of the input pixel coordinates.\n  pixtocams = xnp.broadcast_to(pix_x_int, pixtocams)\n  camtoworlds = xnp.broadcast_to(pix_x_int, camtoworlds)\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x = pixtocams[Ellipsis, 0] * pix_x_int + pixtocams[Ellipsis, 2]\n  cam_y = pixtocams[Ellipsis, 1] * pix_y_int + pixtocams[Ellipsis, 3]\n\n  # Compute the ray origins and directions in camera coordinates.\n  ray_origins = camtoworlds[Ellipsis, 0] * cam_x + camtoworlds[Ellipsis, 3]\n  ray_dirs = camtoworlds[Ellipsis, 1] * cam_y + camtoworlds[Ellipsis, 2]\n\n  # Normalize the ray directions.\n  ray_dirs = ray_dirs / xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n\n  # Compute the normalized view directions.\n  viewdirs = ray_dirs / xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n\n  # Compute the differential radii.\n  radii = xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n\n  # Compute the image plane coordinates.\n  imageplane = xnp.meshgrid(pix_x_int, pix_y_int, indexing='xy')\n\n  if distortion_params is not None:\n    # Compute the distorted ray origins and directions.\n    #\n    # Let's define the distortion parameters as:\n    #\n    # k1 = distortion_params['k1']\n    # k2 = distortion_params['k2']\n    # k3 = distortion_params['k3']\n    # k4 = distortion_params['k4']\n    # p1 = distortion_params['p1']\n    # p2 = distortion_params['p2']\n    #\n    # Let's define the undistorted ray origins and directions as:\n    #\n    # x = ray_orig"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if pixtocam_ndc is None:\n    pixtocam_ndc = xnp.array(\n        [\n            [1.0, 0.0, 0.0],\n            [0.0, 1.0, 0.0],\n            [0.0, 0.0, 1.0],\n        ]\n    )\n\n  # Compute undistorted pixel coordinates in camera space.\n  cam_x, cam_y = _radial_and_tangential_undistort(\n      pix_x_int,\n      pix_y_int,\n      k1=distortion_params.get(\"k1\", 0.0),\n      k2=distortion_params.get(\"k2\", 0.0),\n      k3=distortion_params.get(\"k3\", 0.0),\n      k4=distortion_params.get(\"k4\", 0.0),\n      p1=distortion_params.get(\"p1\", 0.0),\n      p2=distortion_params.get(\"p2\", 0.0),\n  )\n\n  # Transform undistorted pixel coordinates in camera space to world space.\n  world_x, world_y = xnp.dot(cam_x, camtoworlds)\n  world_z = xnp.dot(cam_y, camtoworlds)\n\n  # Compute the origin and direction of the rays in world space.\n  origins = xnp.stack([world_x, world_y, world_z], axis=-1)\n  directions = xnp.stack(\n      [\n          world_x - origins[:, 0],\n          world_y - origins[:, 1],\n          world_z - origins[:, 2],\n      ],\n      axis=-1,\n  )\n\n  # Compute the normalized direction of the rays.\n  viewdirs = xnp.linalg.normalize(directions)\n\n  # Compute the differential radii of the rays.\n  radii = xnp.linalg.norm(directions, axis=-1)\n\n  # Compute the xy coordinates of the image plane.\n  imageplane = xnp.meshgrid(cam_x, cam_y, indexing=\"xy\")\n\n  return origins, directions, viewdirs, radii, imageplane\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if distortion correction is enabled.\n  if distortion_params is None:\n    # Distortion correction is not enabled.\n    k1, k2, k3, k4, p1, p2 = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n  else:\n    # Distortion correction is enabled.\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    k4 = distortion_params['k4']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']\n\n  # Compute camera coordinates from pixel coordinates.\n  cam_x = xnp.array(pix_x_int, dtype=xnp.float)\n  cam_y = xnp.array(pix_y_int, dtype=xnp.float)\n  cam_x, cam_y = xnp.meshgrid(cam_x, cam_y, indexing='ij')\n  cam_x, cam_y = xnp.broadcast_arrays(cam_x, cam_y)\n  cam_coords = xnp.stack([cam_x, cam_y, xnp.ones_like(cam_x)], axis=0)\n\n  # Compute world coordinates from camera coordinates.\n  world_coords = xnp.einsum('...ij,ij->...ij', camtocams, cam_coords)\n\n  # Compute ray origins and directions from world coordinates.\n  origins = world_coords[Ellipsis, :3, -1]\n  directions = world_coords[Ellipsis, :3, 1]\n\n  # Compute normalized direction vectors of the rays.\n  viewdirs = xnp.einsum('...ij,ij->...ij', directions, directions)\n  viewdirs = xnp.einsum('...ij,ij->...ij', viewdirs, viewdirs)\n\n  # Compute differential radii of the rays.\n  radii = xnp.sqrt(xnp.einsum('...ij,ij->...', viewdirs, viewdirs))\n\n  # Compute image plane coordinates from ray origins and directions.\n  if camtype == ProjectionType.FISHEYE:\n    # Compute"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input pixel coordinates are within the camera image plane.\n  # The camera image plane is centered at the camera origin point.\n  # The camera image plane is a square of side 2 * focal, where focal is the\n  # focal length of the camera.\n  # Let's define\n  #\n  # cx = focal * 0.5;\n  # cy = focal * 0.5;\n  #\n  # Let's define\n  #\n  # x_min = -cx;\n  # x_max = cx;\n  # y_min = -cy;\n  # y_max = cy;\n  #\n  # Let's define\n  #\n  # x_in = pix_x_int - cx;\n  # y_in = pix_y_int - cy;\n  #\n  # Let's define\n  #\n  # x_in_min = -cx;\n  # x_in_max = cx;\n  # y_in_min = -cy;\n  # y_in_max = cy;\n  #\n  # Let's define\n  #\n  # x_out_min = x_min - cx;\n  # x_out_max = x_max - cx;\n  # y_out_min = y_min - cy;\n  # y_out_max = y_max - cy;\n  #\n  # Let's define\n  #\n  # x_out = pix_x_int - 2 * cx;\n  # y_out = pix_y_int - 2 * cy;\n  #\n  # Let's define\n  #\n  # x_out_in = x_out - x_in;\n  # y_out_in = y_out - y_in;\n  #\n  # Let's define\n  #\n  # x_out_in_min = -cx;\n  # x_out_in_max = cx;\n  # y_out_in_min = -cy;\n  # y_out_in_max = cy;\n  #\n  # Let's define\n  #\n  # x_out_in_min_min = x_in_min - x_out_in_min;\n  # x_out_in_max_max = x_out_in_max - x_in_max;\n  # y_out_in_min"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1)\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs[Ellipsis, 1:] - dirs[Ellipsis, :-1], axis=-1) * tdist[Ellipsis, 1:]\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.sum(tdist * jnp.linalg.norm(dirs, axis=-1),\n                                    axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs[Ellipsis, None, :] * tdist[Ellipsis, None, :], axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  density_delta = density_delta / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1)\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  density_delta = density_delta * jnp.linalg.norm(dirs, axis=-1)\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  density_delta = density_delta * jnp.linalg.norm(dirs[Ellipsis, 1:] - dirs[Ellipsis, :-1], axis=-1)\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs[Ellipsis, 1:] - dirs[Ellipsis, :-1], axis=-1) * tdist[Ellipsis, 1:]\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the adjusted distance between points along the path,\n  # based on the direction vectors and the distances between points.\n  norm_dirs = jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  norm_dirs = jnp.maximum(norm_dirs, 1e-10)\n  tdist_adj = tdist * norm_dirs\n\n  # Compute the product of density and adjusted distance between points.\n  density_delta = density * tdist_adj\n\n  # Compute the alpha weights using the helper function.\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Adjust the density based on the distance between points along the direction\n  density_delta = density * tdist[Ellipsis, :-1] * jnp.linalg.norm(dirs, axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Adjust the distance between points based on the direction vectors\n  tdist_adj = tdist[Ellipsis, 1:] * jnp.linalg.norm(dirs[Ellipsis, :-1], axis=-1)\n\n  # Compute the product of density and adjusted distance between points\n  density_delta = density[Ellipsis, :-1] * tdist_adj\n\n  # Compute the alpha weights using the helper function\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1, keepdims=True) * tdist\n\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  # Compute the norm-adjusted distances between points\n  norm_tdist = tdist * jnp.linalg.norm(dirs, axis=-1)\n\n  # Compute the product of density and the adjusted distance between points\n  density_delta = density * norm_tdist\n\n  # Call the helper function to compute the alpha weights\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample uniformly from the CDF.\n  if rng is None:\n    # Use deterministic sampling.\n    if deterministic_center:\n      # Sample from the center of each interval.\n      u = jnp.linspace(0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n    else:\n      # Sample from the entire range of the PDF.\n      u = jnp.linspace(eps, 1 - eps, num_samples)\n  else:\n    # Use random sampling.\n    u = jax.random.uniform(rng, (num_samples,))\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = jnp.broadcast_to(u, (num_samples,))\n    else:\n      # Jitter each sample independently.\n      u = jnp.broadcast_to(u, (num_samples,)) + jax.random.uniform(\n          rng, (num_samples,), minval=-0.5, maxval=0.5\n      )\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if rng is None:\n    # Deterministic sampling\n    if deterministic_center:\n      # Sample from the center of each interval\n      t_mid = (t[..., 1:] + t[..., :-1]) / 2\n      t_mid = jnp.concatenate([t_mid, t[..., -1:]], axis=-1)\n      samples = jnp.linspace(t_mid[..., 0], t_mid[..., -1], num_samples)\n    else:\n      # Sample from the entire range of the PDF\n      samples = jnp.linspace(t[..., 0], t[..., -1], num_samples)\n  else:\n    # Random sampling\n    w = jax.nn.softmax(w_logits, axis=-1)\n    # Compute the CDF of the weights\n    cw = integrate_weights(w)\n    # Sample uniformly from [0, 1)\n    u = jax.random.uniform(rng, (num_samples,))\n    # Interpolate into the inverse CDF\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    # Jitter the samples\n    if single_jitter:\n      # Jitter all samples by the same amount\n      jitter = jax.random.uniform(rng, (1,)) * (1 - eps)\n      samples = t_new + jitter\n    else:\n      # Jitter each sample independently\n      jitter = jax.random.uniform(rng, (num_samples,)) * (1 - eps)\n      samples = t_new + jitter\n  return samples\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Sample from the CDF.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Center the samples in each interval of the PDF.\n      t_new = linspline.linspace_with_offset(t, num_samples, eps)\n    else:\n      # Spread the samples across the entire PDF.\n      t_new = linspline.linspace(t, num_samples, eps)\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Sample a single jitter value for each sample.\n      u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n      u = jnp.broadcast_to(u, (w.shape[0], num_samples))\n    else:\n      # Sample independent jitter values for each sample.\n      u = jax.random.uniform(rng, (w.shape[0], num_samples), minval=eps, maxval=1 - eps)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the uniformly-spaced sampling points.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Centered sampling.\n      u = jnp.linspace(0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n    else:\n      # Full-range sampling.\n      u = jnp.linspace(0, 1, num_samples)\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      jitter = jax.random.uniform(rng, (1,), minval=0, maxval=1) / num_samples\n    else:\n      # Jitter each sample independently.\n      jitter = jax.random.uniform(rng, (num_samples,), minval=0, maxval=1) / num_samples\n    u = jnp.linspace(0, 1, num_samples) + jitter\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Add a small value to avoid numerical instabilities.\n  return t_new + eps\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample uniformly in [0, 1).\n  if rng is None:\n    u = jnp.linspace(0, 1, num_samples + 1)[:-1]\n  else:\n    u = jax.random.uniform(rng, (num_samples,))\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  # Jitter the samples if necessary.\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (1,))\n  else:\n    jitter = jax.random.uniform(rng, (num_samples,))\n  t_new = t_new + jitter * jnp.diff(t)\n  # Optionally center the samples.\n  if deterministic_center:\n    t_new = t_new + 0.5 * jnp.diff(t)\n  # Clip the samples to the range of the PDF.\n  t_new = jnp.clip(t_new, t[Ellipsis, :-1] + eps, t[Ellipsis, 1:] - eps)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if rng is None:\n    # Deterministic sampling.\n    # If deterministic_center is True, we sample from the center of each bin.\n    # Otherwise, we sample from the entire range of the PDF.\n    if deterministic_center:\n      t_new = (t[Ellipsis, :-1] + t[Ellipsis, 1:]) / 2\n    else:\n      t_new = jnp.linspace(t[Ellipsis, 0], t[Ellipsis, -1], num_samples)\n  else:\n    # Random sampling.\n    # We first sample from a uniform distribution, then map it to the\n    # corresponding value on the PDF.\n    # If single_jitter is True, we use the same jitter for all samples.\n    # Otherwise, we use different jitters for each sample.\n    if single_jitter:\n      jitter = jax.random.uniform(rng, (1,))\n    else:\n      jitter = jax.random.uniform(rng, (num_samples,))\n    u = jnp.linspace(eps, 1 - eps, num_samples) + jitter * (1 - 2 * eps)\n    t_new = invert_cdf(u, t, w_logits)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,), dtype=jnp.float32)\n    if single_jitter:\n      u = u + jax.random.uniform(rng, (1,), dtype=jnp.float32)\n    u = jnp.expand_dims(u, axis=-1)\n  else:\n    u = jnp.linspace(0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n    u = jnp.expand_dims(u, axis=-1)\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  # Optionally, shift the samples to the center of each interval.\n  if deterministic_center:\n    t_new = t_new + 0.5 * jnp.diff(t)\n  # Add a small value to avoid sampling exactly at the endpoints.\n  t_new = t_new + eps * (2 * u - 1)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample uniformly in the interval [0, 1).\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample from the center of each interval.\n      u = (jnp.linspace(0, 1, num_samples + 1) + 0.5)[Ellipsis, None]\n    else:\n      # Sample from the entire interval.\n      u = jnp.linspace(0, 1, num_samples + 1)[Ellipsis, None]\n    u = u[..., 1:] - u[..., :-1]\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, shape=(num_samples,))\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u += jax.random.uniform(rng, shape=(1,))\n    u = u[Ellipsis, None]\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  batch_size = w_logits.shape[:-1]\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample from the center of each interval.\n      t_new = (t[..., 1:] + t[..., :-1]) / 2\n    else:\n      # Sample from the entire PDF.\n      t_new = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, batch_size + (num_samples,), minval=eps, maxval=1 - eps)\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = jnp.broadcast_to(u[..., :1], batch_size + (num_samples,))\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  if rng is None:\n    # Generate deterministic samples.\n    if deterministic_center:\n      # Generate samples centered in each interval.\n      t_mid = (t[..., 1:] + t[..., :-1]) / 2\n      t_mid = jnp.concatenate([t_mid, t[..., -1:]], axis=-1)\n      t_mid = t_mid[..., None]\n      u = jnp.linspace(0, 1, num_samples + 1)\n      u = u[1:-1, None]\n      t_new = math.sorted_interp(u, cw, t_mid, utils.device_is_tpu())\n    else:\n      # Generate samples spanning the entire PDF.\n      t_new = math.sorted_interp(\n          jnp.linspace(0, 1, num_samples + 1), cw, t, utils.device_is_tpu()\n      )\n      t_new = t_new[..., 1:]\n  else:\n    # Generate random samples.\n    u = jax.random.uniform(rng, shape=(num_samples,))\n    if single_jitter:\n      # Jitter each sample by the same amount.\n      u = u[..., None] + jnp.linspace(0, 1, num_samples + 1)[None, 1:-1]\n      u = u % 1\n    u = jnp.concatenate([u, jnp.ones((u.shape[0], 1))], axis=-1)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample uniformly from [0, 1) and invert the CDF.\n  if rng is None:\n    # Use linspace to get deterministic samples.\n    u = jnp.linspace(0, 1, num_samples + 1)[:-1]\n    if deterministic_center:\n      # Shift the samples to be centered in each interval.\n      u = u + 0.5 / num_samples\n  else:\n    # Use random sampling.\n    u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n    if single_jitter:\n      # Use the same jitter for all samples.\n      u = u + jax.random.uniform(rng, (1,), minval=eps, maxval=1 - eps)\n  return math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Center the samples in each interval.\n      t_new = 0.5 * (t[..., 1:] + t[..., :-1])\n    else:\n      # Sample uniformly across the entire PDF.\n      t_new = jnp.linspace(t[..., 0], t[..., -1], num_samples + 1)[..., 1:]\n  else:\n    # Random sampling.\n    u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = jnp.broadcast_to(u, (num_samples,))\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  if rng is None:\n    # Deterministic sampling\n    if deterministic_center:\n      # Sample the center of each interval\n      return t[..., :-1] + 0.5 * jnp.diff(t)\n    else:\n      # Sample the entire range of the PDF\n      return jnp.linspace(t[..., 0], t[..., -1], num_samples)\n  else:\n    # Random sampling\n    # Compute the PDF and CDF for each weight vector.\n    w = jax.nn.softmax(w_logits, axis=-1)\n    cw = integrate_weights(w)\n    # Generate uniform samples\n    u = jax.random.uniform(rng, (num_samples,))\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    # Jitter samples\n    if single_jitter:\n      # Jitter all samples by the same amount\n      jitter = jax.random.uniform(rng, (1,)) * (t[..., 1:] - t[..., :-1])\n      t_new += jitter\n    else:\n      # Jitter each sample independently\n      jitter = jax.random.uniform(rng, (num_samples,)) * (t[..., 1:] - t[..., :-1])\n      t_new += jitter\n    # Clip samples to the range of the PDF\n    t_new = jnp.clip(t_new, t[..., 0] + eps, t[..., -1] - eps)\n    return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  batch_shape = t.shape[:-1]\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the inverse CDF.\n  t_new = math.sorted_interp(cw, cw, t, utils.device_is_tpu())\n  # Sample from the inverse CDF.\n  if rng is None:\n    # If rng is None, use linspace to generate deterministic samples.\n    t_new = jnp.linspace(t_new[..., 0], t_new[..., -1], num_samples + 1)\n    t_new = t_new[..., 1:]\n  else:\n    # If rng is not None, use random sampling.\n    if single_jitter:\n      # If single_jitter is True, generate a single jitter for all samples.\n      u = jax.random.uniform(rng, batch_shape + (1,), minval=eps, maxval=1 - eps)\n      u = jnp.broadcast_to(u, batch_shape + (num_samples,))\n    else:\n      # If single_jitter is False, generate independent jitters for each sample.\n      u = jax.random.uniform(rng, batch_shape + (num_samples,), minval=eps, maxval=1 - eps)\n    t_new = math.sorted_interp(u, cw, t_new, utils.device_is_tpu())\n  # Adjust the range of the samples if deterministic_center is True.\n  if deterministic_center:\n    t_new = jnp.where(t_new < t[..., 1:], t[..., 1:], t_new)\n    t_new = jnp.where(t_new > t[..., -2:], t[..., -2:], t_new)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate random samples if rng is not None.\n  if rng is not None:\n    # Generate random samples from a uniform distribution.\n    u = jax.random.uniform(rng, (num_samples,), minval=0, maxval=1)\n\n    # Jitter the samples if single_jitter is False.\n    if not single_jitter:\n      u = u + jax.random.uniform(rng, (num_samples,), minval=0, maxval=1) / num_samples\n\n    # Adjust the range of the uniform distribution to avoid numerical issues.\n    u = u * (1 - 2 * eps) + eps\n\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n    return t_new\n\n  # Generate deterministic samples if rng is None.\n  else:\n    # Generate samples from a linearly spaced grid.\n    u = jnp.linspace(0, 1, num_samples)\n\n    # Adjust the range of the uniform distribution to avoid numerical issues.\n    u = u * (1 - 2 * eps) + eps\n\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n    # If deterministic_center is True, center the samples in each interval.\n    if deterministic_center:\n      t_new = (t_new + t[Ellipsis, :-1]) / 2\n\n    return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Sample uniformly along the CDF.\n  if rng is None:\n    # Use deterministic sampling.\n    if deterministic_center:\n      # Sample at the center of each bin.\n      u = jnp.linspace(0, 1, num_samples + 1)[1:-1]\n      u = jnp.expand_dims(u, axis=-1)\n    else:\n      # Sample uniformly along the entire PDF.\n      u = jnp.linspace(0, 1, num_samples)[..., None]\n  else:\n    # Use random sampling.\n    if single_jitter:\n      # Jitter all samples by the same amount.\n      u = jax.random.uniform(rng, shape=(num_samples, 1), minval=0, maxval=1)\n    else:\n      # Jitter each sample independently.\n      u = jax.random.uniform(rng, shape=(num_samples,), minval=0, maxval=1)\n      u = jnp.expand_dims(u, axis=-1)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Add a small value to avoid numerical issues.\n  t_new = t_new + eps\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the range of the CDF for each weight vector.\n  cdf_range = cw[..., -1:] - cw[..., :1]\n\n  # If deterministic_center is True, we shift the CDF range to the center of each interval.\n  if deterministic_center:\n    cdf_range = cdf_range / 2\n\n  # If rng is None, we use deterministic sampling based on linspace.\n  if rng is None:\n    # Generate a grid of uniformly spaced values in the range [0, 1).\n    u = jnp.linspace(0, 1, num_samples, axis=-1)\n  else:\n    # Generate a grid of uniformly distributed random values in the range [0, 1).\n    u = jax.random.uniform(rng, (num_samples,), minval=0, maxval=1)\n    u = jnp.expand_dims(u, axis=-1)\n\n  # If single_jitter is True, we jitter all samples by the same amount.\n  if single_jitter:\n    # Generate a single jitter value for all samples.\n    jitter = jax.random.uniform(rng, (), minval=0, maxval=1)\n    # Add the jitter to all samples.\n    u = u + jitter\n\n  # Add a small value to avoid numerical issues.\n  u = u + eps\n\n  # Scale the uniform samples to the range of the CDF.\n  u = u * cdf_range\n\n  # Add the CDF range to the uniform samples.\n  u = u + cw[..., :1]\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Get the number of dimensions of the input arrays.\n  num_dims = len(t.shape)\n\n  # Get the batch size and the number of samples.\n  batch_size = t.shape[:-1]\n  num_samples = num_samples or 1\n\n  # Create a random number generator if needed.\n  rng = jax.random.PRNGKey(0) if rng is None else rng\n\n  # Generate random samples from a uniform distribution.\n  u = jax.random.uniform(rng, shape=batch_size + (num_samples,))\n\n  # Add a small value to avoid sampling at the endpoints.\n  u = jnp.where(u < eps, eps, u)\n  u = jnp.where(u > 1 - eps, 1 - eps, u)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Jitter the samples if needed.\n  if single_jitter:\n    # Generate a single jitter value for all samples.\n    jitter = jax.random.uniform(rng, shape=batch_size)\n    # Apply the jitter to all samples.\n    t_new += jitter[:, None] * (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n  else:\n    # Generate jitter values for each sample independently.\n    jitter = jax.random.uniform(rng, shape=batch_size + (num_samples,))\n    # Apply the jitter to each sample.\n    t_new += jitter * (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n  # If deterministic_center is True, adjust the samples to be centered in each interval.\n  if deterministic_center:\n    t_new = (t[Ellipsis, :-1] + t[Ellipsis, 1:]) / 2\n\n  # Reshape the output to match the input shape.\n  output_shape = batch_size + (num_samples,)\n  t_new ="}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  batch_size = t.shape[:-1]\n  num_bins = t.shape[-1] - 1\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Center each sample in each interval.\n      t_mid = (t[..., 1:] + t[..., :-1]) / 2\n      t_mid = jnp.concatenate([t_mid, t[..., -1:]], axis=-1)\n      t_mid = t_mid[..., 1:]\n      t_mid = jnp.reshape(t_mid, batch_size + (num_bins,))\n      t_mid = jnp.reshape(t_mid, batch_size + (num_bins, 1))\n      samples = t_mid + jnp.zeros(batch_size + (num_bins, num_samples))\n    else:\n      # Spread samples over entire PDF.\n      t_min = jnp.reshape(t[..., :-1], batch_size + (num_bins,))\n      t_max = jnp.reshape(t[..., 1:], batch_size + (num_bins,))\n      samples = jnp.linspace(t_min, t_max, num_samples + 1, axis=-1)\n      samples = samples[..., 1:]\n  else:\n    # Random sampling.\n    # Compute the CDF for each weight vector.\n    w = jax.nn.softmax(w_logits, axis=-1)\n    cw = integrate_weights(w)\n    # Generate random samples in [0, 1).\n    if single_jitter:\n      # Generate a single random value and jitter all samples by the same amount.\n      u = jax.random.uniform(rng, batch_size + (1,), minval=eps, maxval=1 - eps)\n      samples = u + jnp.zeros(batch_size + (num_samples,))\n    else:\n      # Generate independent random values for each sample.\n      u = jax.random.uniform(rng, batch_size + (num_samples,), minval=eps, maxval=1 - eps)\n      samples = jnp.reshape(u, batch_size + (1, num_samples))\n    # Interpolate into the inverse CDF.\n   "}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  if rng is None:\n    # Use linspace for deterministic sampling.\n    u = jnp.linspace(0, 1, num_samples, axis=-1)\n    if deterministic_center:\n      # Shift the samples to the center of each interval.\n      u = 0.5 * (cw[..., 1:] + cw[..., :-1])\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Use random sampling.\n    u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n    t_new = invert_cdf(u, t, w_logits)\n    # Jitter samples by a random amount.\n    if single_jitter:\n      # Use the same jitter for all samples.\n      jitter = jax.random.uniform(rng, (), minval=eps, maxval=1 - eps)\n      t_new += jitter\n    else:\n      # Use independent jitters for each sample.\n      jitter = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n      t_new += jitter\n  return t_new\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n\n  # Invert the CDF to get the sampled points.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.maximum(t_midpoints[..., :1], domain[0]),\n          t_midpoints,\n          jnp.minimum(t_midpoints[..., -1:], domain[1]),\n      ],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Sample points from the step function.\n  t_samples = sample(\n      rng,\n      t,\n      w_logits,\n      num_samples,\n      single_jitter=single_jitter,\n      deterministic_center=False,\n  )\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.broadcast_to(domain[0], t_midpoints.shape[:-1] + (1,)),\n          t_midpoints,\n          jnp.broadcast_to(domain[1], t_midpoints.shape[:-1] + (1,)),\n      ],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(\n      rng,\n      t,\n      w_logits,\n      num_samples,\n      single_jitter,\n      deterministic_center=False,\n  )\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [jnp.maximum(t_midpoints[..., :1], domain[0]), t_midpoints], axis=-1\n  )\n  t_midpoints = jnp.concatenate(\n      [t_midpoints, jnp.minimum(t_midpoints[..., -1:], domain[1])], axis=-1\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples + 1)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1.0, num_samples + 1) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples + 1,), maxval=1.0 / num_samples\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [jnp.expand_dims(jnp.maximum(t_midpoints[..., :1], domain[0]), axis=-1),\n       t_midpoints,\n       jnp.expand_dims(jnp.minimum(t_midpoints[..., -1:], domain[1]), axis=-1)],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples + 1)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1.0, num_samples + 1) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples + 1,), maxval=1 / (num_samples + 1)\n    )\n\n  # Invert the CDF to get the sampled points.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_midpoints = 0.5 * (t_samples[..., :-1] + t_samples[..., 1:])\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.where(t_midpoints[..., 0] < domain[0], domain[0], t_midpoints[..., 0]),\n          t_midpoints[..., 1:-1],\n          jnp.where(t_midpoints[..., -1] > domain[1], domain[1], t_midpoints[..., -1]),\n      ],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples + 1,))\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.broadcast_to(domain[0], t_midpoints.shape[:-1] + (1,)),\n          t_midpoints,\n          jnp.broadcast_to(domain[1], t_midpoints.shape[:-1] + (1,)),\n      ],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Sample points from the step function.\n  t_samples = sample(\n      rng,\n      t,\n      w_logits,\n      num_samples + 1,\n      single_jitter=single_jitter,\n      deterministic_center=False,\n  )\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.maximum(t_midpoints[..., :1], domain[0]),\n          t_midpoints,\n          jnp.minimum(t_midpoints[..., -1:], domain[1]),\n      ],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  t_samples = invert_cdf(u, t, w_logits)\n  # Adjust first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate([t[Ellipsis, :1], t_samples, t[Ellipsis, -1:]], axis=-1)\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = jnp.diff(t_samples, axis=-1) / 2 + t_samples[..., :-1]\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function.\n  t_samples = sample(\n      rng,\n      t,\n      w_logits,\n      num_samples,\n      single_jitter=single_jitter,\n      deterministic_center=False,\n  )\n\n  # Calculate midpoints between adjacent samples.\n  midpoints = 0.5 * (t_samples[..., 1:] + t_samples[..., :-1])\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  midpoints = jnp.concatenate(\n      [\n          jnp.broadcast_to(\n              jnp.maximum(t[..., 0:1], midpoints[..., :1]), midpoints.shape\n          ),\n          midpoints,\n          jnp.broadcast_to(\n              jnp.minimum(t[..., -1:], midpoints[..., -1:]), midpoints.shape\n          ),\n      ],\n      axis=-1,\n  )\n\n  # Ensure that the intervals are within the specified domain.\n  midpoints = jnp.maximum(midpoints, domain[0])\n  midpoints = jnp.minimum(midpoints, domain[1])\n\n  return midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  minval, maxval = domain\n  intervals = jnp.concatenate(\n      [\n          jnp.maximum(t_samples[..., :1], minval),\n          midpoints,\n          jnp.minimum(t_samples[..., -1:], maxval),\n      ],\n      axis=-1,\n  )\n\n  return intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Sample points from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2.0\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [jnp.expand_dims(t[..., 0], axis=-1), t_midpoints], axis=-1\n  )\n  t_midpoints = jnp.concatenate(\n      [t_midpoints, jnp.expand_dims(t[..., -1], axis=-1)], axis=-1\n  )\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  # Calculate intervals by subtracting adjacent midpoints.\n  intervals = t_midpoints[..., 1:] - t_midpoints[..., :-1]\n\n  return intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Sample points from the step function.\n  t_samples = sample(\n      rng,\n      t,\n      w_logits,\n      num_samples,\n      single_jitter=single_jitter,\n      deterministic_center=False,\n      eps=jnp.finfo(jnp.float32).eps,\n  )\n\n  # Calculate midpoints between adjacent samples.\n  midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  minval, maxval = domain\n  midpoints = jnp.concatenate(\n      [jnp.broadcast_to(minval, t.shape[:-1] + (1,)), midpoints], axis=-1\n  )\n  midpoints = jnp.concatenate(\n      [midpoints, jnp.broadcast_to(maxval, t.shape[:-1] + (1,))], axis=-1\n  )\n  intervals = jnp.stack([t_samples, midpoints], axis=-1)\n  return intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the sampled points.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_midpoints = 0.5 * (t_samples[..., 1:] + t_samples[..., :-1])\n\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_midpoints = jnp.concatenate(\n      [t[Ellipsis, 1:2], t_midpoints, t[Ellipsis, -2:-1]], axis=-1\n  )\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  # Compute the intervals from the midpoints.\n  intervals = t_midpoints[..., 1:] - t_midpoints[..., :-1]\n\n  return intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the sampled points.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [\n          jnp.broadcast_to(\n              jnp.where(t_midpoints[..., 0] < domain[0], domain[0], t_samples[..., 0]),\n              t_midpoints.shape[:-1] + (1,),\n          ),\n          t_midpoints,\n          jnp.broadcast_to(\n              jnp.where(t_midpoints[..., -1] > domain[1], domain[1], t_samples[..., -1]),\n              t_midpoints.shape[:-1] + (1,),\n          ),\n      ],\n      axis=-1,\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = u + jax.random.uniform(rng, t.shape[:-1] + (u.shape[-1],), maxval=1e-6)\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute midpoints between adjacent samples.\n  t_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_mid = jnp.concatenate(\n      [jnp.where(t_mid[..., 0] < domain[0], domain[0], t_mid[..., 0])],\n      [t_mid[..., 1:]],\n      axis=-1,\n  )\n  t_mid = jnp.concatenate(\n      [t_mid[..., :-1]],\n      [jnp.where(t_mid[..., -1] > domain[1], domain[1], t_mid[..., -1])],\n      axis=-1,\n  )\n\n  return t_mid\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples + 1,), maxval=1)\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.where(t_samples[..., 0] < domain[0], domain[0], t_samples)\n  t_samples = jnp.where(\n      t_samples[..., -1] > domain[1], domain[1], t_samples\n  )\n\n  # Calculate midpoints between adjacent samples.\n  midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  return midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  # Compute midpoints between adjacent samples.\n  t_mid = 0.5 * (t_samples[..., :-1] + t_samples[..., 1:])\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_mid = jnp.concatenate(\n      [\n          jnp.broadcast_to(domain[0], t_mid.shape[:-1] + (1,)),\n          t_mid,\n          jnp.broadcast_to(domain[1], t_mid.shape[:-1] + (1,)),\n      ],\n      axis=-1,\n  )\n  return t_mid\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Draw uniform samples.\n  if rng is None:\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n\n  # Invert the CDF to get the sampled points.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [t_samples[..., :1], t_midpoints, t_samples[..., -1:]], axis=-1\n  )\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  # Return the adjusted intervals.\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Sample points from the step function.\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate(\n      [jnp.array([domain[0]]), t_midpoints, jnp.array([domain[1]])], axis=-1\n  )\n\n  return t_midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  midpoints = jnp.concatenate(\n      [\n          jnp.maximum(\n              jnp.broadcast_to(domain[0], t_samples.shape[:-1] + (1,)),\n              midpoints[..., :1],\n          ),\n          midpoints,\n          jnp.minimum(\n              jnp.broadcast_to(domain[1], t_samples.shape[:-1] + (1,)),\n              midpoints[..., -1:],\n          ),\n      ],\n      axis=-1,\n  )\n\n  return midpoints\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n  # Interpolate into the integrated weights to find the percentiles.\n  t_ps = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_ps\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n  # Interpolate into the integrated weights to get the percentiles.\n  t_ps = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_ps\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the integrated weights and ensure that they sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the integrated weights to find the weighted percentiles.\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Integrate the weights to obtain the cumulative distribution function.\n  cw = integrate_weights(w)\n\n  # Interpolate into the CDF to find the corresponding values of t.\n  t_ps = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_ps\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n\n  # Compute the weighted percentiles by interpolating into the integrated weights based on the given percentiles.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n  # Interpolate into the integrated weights.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  # Integrate the weights to obtain the cumulative distribution function.\n  cw = integrate_weights(w)\n  # Interpolate the percentiles into the CDF to obtain the corresponding values.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Integrate the weights to get the cumulative distribution function (CDF).\n  cw = integrate_weights(w)\n\n  # Interpolate the percentiles into the CDF to get the corresponding x-values.\n  t_interp = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_interp\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  if not jnp.isclose(jnp.sum(w), 1.0):\n    raise ValueError(f'Weights must sum to 1, is {jnp.sum(w)}.')\n\n  # Integrate the weights to get the CDF.\n  cw = integrate_weights(w)\n  # Interpolate into the CDF to get the percentile values.\n  return math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  # Integrate the weights to obtain the cumulative distribution function.\n  cw = integrate_weights(w)\n  # Interpolate the percentiles into the integrated weights.\n  t_ps = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_ps\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = w / jnp.sum(w)\n\n  # Compute the integrated weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the corresponding values\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the cumulative sum of the weights and normalize to 1\n  cw = integrate_weights(w)\n\n  # Compute the weighted percentiles by interpolating into the cumulative weights\n  t_pcts = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_pcts\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  # Integrate the weights to get the cumulative distribution function (CDF).\n  cw = integrate_weights(w)\n  # Interpolate the percentiles into the CDF.\n  t_new = math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the corresponding values.\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Check that the weights sum to 1.\n  if not np.isclose(np.sum(w), 1):\n    raise ValueError('The weights must sum to 1.')\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the percentiles into the integrated weights.\n  t_ps = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_ps\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the histogram to a PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blurred = linspline.blur(p, blur_halfwidth)\n  # Resample the PDF to match the new time points.\n  wq = linspline.resample(tq, t, p_blurred)\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert weights to PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blurred = linspline.blur_pdf(p, blur_halfwidth)\n  # Resample the PDF to match the new time points.\n  w_resampled = pdf_to_weight(tq, p_blurred)\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert the histogram to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p_blur = linspline.blur_pdf(p, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_blur = pdf_to_weight(tq, p_blur)\n\n  return w_blur\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF and CDF for each weight vector.\n  p = weight_to_pdf(t, w)\n  p_blurred = linspline.blur(p, blur_halfwidth)\n  w_resampled = pdf_to_weight(tq, p_blurred)\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the histogram to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p_blur = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  p_blur_resampled = linspline.resample(tq, p_blur)\n\n  # Convert the resampled PDF back to weights.\n  w_resampled = pdf_to_weight(tq, p_blur_resampled)\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  p = weight_to_pdf(t, w)\n  p_blurred = linspline.blur(p, blur_halfwidth)\n  w_resampled = pdf_to_weight(tq, p_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  p = weight_to_pdf(t, w)\n  p_blurred = linspline.blur(p, blur_halfwidth)\n  w_resampled = pdf_to_weight(tq, p_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF by normalizing the weights.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian kernel.\n  t_blur = jnp.arange(t[0] - blur_halfwidth, t[-1] + blur_halfwidth, t[1] - t[0])\n  p_blur = linspline.blur(t, p, t_blur, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  wq = linspline.interp(t_blur, p_blur, tq)\n\n  # Normalize the resampled weights to sum to 1.\n  wq = wq / jnp.sum(wq)\n\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the histogram to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  t_blur = jnp.linspace(t[0], t[-1], 1000)\n  p_blur = linspline.blur_pdf(t_blur, t, p, blur_halfwidth)\n\n  # Resample the blurred PDF.\n  w_resampled = pdf_to_weight(tq, linspline.query_pdf(tq, t_blur, p_blur))\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian kernel\n  kernel = linspline.gaussian_kernel(t, blur_halfwidth)\n  blurred_pdf = linspline.convolve(pdf, kernel)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_weights = linspline.interp(tq, t, blurred_pdf)\n\n  return resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the weights to a PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blurred = linspline.blur(t, p, blur_halfwidth)\n  # Resample the PDF to the new time points.\n  w_resampled = linspline.query(tq, t, p_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Check if the input arrays are valid\n  if not isinstance(tq, (np.ndarray, jnp.ndarray)):\n    raise ValueError(\"Input tq must be an array-like.\")\n  if not isinstance(t, (np.ndarray, jnp.ndarray)):\n    raise ValueError(\"Input t must be an array-like.\")\n  if not isinstance(w, (np.ndarray, jnp.ndarray)):\n    raise ValueError(\"Input w must be an array-like.\")\n  if not isinstance(blur_halfwidth, (int, float)):\n    raise ValueError(\"Input blur_halfwidth must be a numeric value.\")\n\n  # Convert the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_pdf = linspline.blur(pdf, blur_halfwidth)\n\n  # Resample the PDF at the new time points\n  resampled_pdf = linspline.resample(tq, t, blurred_pdf)\n\n  # Convert the resampled PDF to weights\n  resampled_weights = pdf_to_weight(tq, resampled_pdf)\n\n  return resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the weights to a PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blur = linspline.blur(p, blur_halfwidth)\n  # Resample the blurred PDF to match the new time points.\n  wq = resample(tq, t, p_blur)\n  return wq"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  p = weight_to_pdf(t, w)\n  p_blurred = linspline.blur_pdf(p, blur_halfwidth)\n  w_resampled = pdf_to_weight(tq, p_blurred)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_pdf = linspline.blur(pdf, blur_halfwidth)\n\n  # Resample the PDF to match the new time points\n  resampled_weights = linspline.query(tq, t, blurred_pdf)\n\n  return resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  p = weight_to_pdf(t, w)\n  # Apply blurring.\n  p = linspline.blur_pdf(t, p, blur_halfwidth)\n  # Resample the PDF.\n  w_new = pdf_to_weight(tq, p)\n  return w_new"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a PDF\n  p = weight_to_pdf(t, w)\n\n  # Apply blurring to the PDF\n  p_blurred = linspline.blur_pdf(p, t, blur_halfwidth)\n\n  # Resample the PDF to match the new time points\n  wq = resample(tq, t, p_blurred, use_avg=True)\n\n  return wq"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert the weights to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p_blurred = linspline.blur_pdf(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  w_resampled = resample(tq, t, p_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian kernel.\n  p_blurred = linspline.blur(p, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w_resampled = linspline.resample(tq, t, p_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert the histogram to a PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  p_blurred = linspline.blur(p, blur_halfwidth)\n\n  # Resample the PDF to match the new time points\n  w_resampled = resample(tq, t, p_blurred, use_avg=True)\n\n  return w_resampled"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  vectors = to_homogeneous(vectors)\n  return from_homogeneous(matmul(transform, vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the vectors to homogeneous coordinates\n  vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the vectors\n  transformed_vectors = matmul(transform, vectors)\n\n  # Convert the transformed vectors back to non-homogeneous coordinates\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(to_homogeneous(vectors), transform))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.einsum('...ij,...j->...i', transform, vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a homogeneous dimension to the vectors\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the homogeneous vectors\n  transformed_homogeneous_vectors = matmul(transform, homogeneous_vectors)\n\n  # Remove the homogeneous dimension from the transformed vectors\n  transformed_vectors = from_homogeneous(transformed_homogeneous_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Reshape the vectors to a 2D array with shape (N, C)\n  vectors = jnp.reshape(vectors, (-1, vectors.shape[-1]))\n\n  # Apply the homogeneous transformation to the vectors\n  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = from_homogeneous(matmul(transform, homogeneous_vectors.T).T)\n\n  # Reshape the transformed vectors back to the original shape\n  return jnp.reshape(transformed_vectors, vectors.shape)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Check the shape of the input arrays\n  if vectors.shape[-1] != transform.shape[-1] - 1:\n    raise ValueError(\n        \"The last dimension of the vectors array must be one less than the last dimension of the transform matrix.\"\n    )\n\n  # Add a homogeneous coordinate to the vectors\n  vectors_homogeneous = to_homogeneous(vectors)\n\n  # Apply the transformation to the vectors\n  transformed_vectors = matmul(transform, vectors_homogeneous)\n\n  # Remove the homogeneous coordinate from the transformed vectors\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  vectors = to_homogeneous(vectors)\n  return from_homogeneous(matmul(transform, vectors))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a dimension to the vectors to account for the homogeneous coordinate\n  vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the vectors\n  transformed_vectors = matmul(transform, vectors)\n\n  # Remove the homogeneous coordinate\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a dimension for the homogeneous coordinate\n  vectors_homogeneous = to_homogeneous(vectors)\n\n  # Apply the transformation\n  transformed_vectors_homogeneous = matmul(transform, vectors_homogeneous.T).T\n\n  # Remove the homogeneous coordinate\n  transformed_vectors = from_homogeneous(transformed_vectors_homogeneous)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a homogeneous coordinate to the vectors\n  vectors_homogeneous = to_homogeneous(vectors)\n\n  # Apply the transformation to the vectors\n  transformed_vectors_homogeneous = matmul(transform, vectors_homogeneous.T).T\n\n  # Remove the homogeneous coordinate from the transformed vectors\n  transformed_vectors = from_homogeneous(transformed_vectors_homogeneous)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(to_homogeneous(vectors), transform))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the vectors\n  transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the transformed vectors back to non-homogeneous coordinates\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  vectors_homogeneous = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the vectors\n  vectors_transformed_homogeneous = matmul(transform, vectors_homogeneous)\n\n  # Convert the transformed vectors back to non-homogeneous coordinates\n  vectors_transformed = from_homogeneous(vectors_transformed_homogeneous)\n\n  return vectors_transformed"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a dimension to the vectors to make them homogeneous\n  vectors_homogeneous = to_homogeneous(vectors)\n\n  # Apply the transformation to the vectors\n  transformed_vectors_homogeneous = matmul(transform, vectors_homogeneous)\n\n  # Remove the homogeneous dimension and return the transformed vectors\n  return from_homogeneous(transformed_vectors_homogeneous)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp, vp)\n  if use_avg:\n    return linspline.linspline_avg(t, tp, vp)\n  else:\n    return linspline.linspline_sum(t, tp, vp)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    return linspline.interp(t, tp, vp)\n  else:\n    return linspline.interp(t, tp, vp, left=0, right=0)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    return linspline.linspline_avg(t, tp, vp)\n  else:\n    return linspline.linspline_sum(t, tp, vp)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, tp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # Calculate the width of each interval in the original step function\n  width = jnp.diff(tp)\n\n  # Calculate the width of each interval in the new step function\n  new_width = jnp.diff(t)\n\n  # Calculate the start and end indices of each interval in the original step function\n  start_indices = jnp.searchsorted(tp, t[:-1], side=\"left\")\n  end_indices = jnp.searchsorted(tp, t[1:], side=\"right\")\n\n  # Calculate the start and end indices of each interval in the new step function\n  new_start_indices = jnp.searchsorted(t, tp[:-1], side=\"left\")\n  new_end_indices = jnp.searchsorted(t, tp[1:], side=\"right\")\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])\n\n  # Calculate the overlapping width between the original and new intervals\n  overlap_width = jnp.minimum(new_width[new_start_indices], width[start_indices])"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in `t`.\n  t_widths = jnp.diff(t)\n\n  # Compute the width of each interval in `tp`.\n  tp_widths = jnp.diff(tp)\n\n  # Compute the cumulative sum of the values of the step function at each time point in `tp`.\n  vp_cumsum = jnp.cumsum(vp, axis=-1)\n\n  # Compute the cumulative sum of the values of the step function at each time point in `t`.\n  t_cumsum = linspline.eval(t, tp, vp_cumsum)\n\n  # Compute the cumulative sum of the values of the step function at each time point in `t` for the previous interval.\n  t_prev_cumsum = linspline.eval(t, tp, vp_cumsum, left=0)\n\n  # Compute the difference between the cumulative sums of the values of the step function at each time point in `t` and the previous interval.\n  t_diff = t_cumsum - t_prev_cumsum\n\n  # Compute the average value of the step function for each interval in `t` by dividing the difference by the width of each interval.\n  t_avg = t_diff / t_widths\n\n  # Compute the average value of the step function for each interval in `t` by dividing the difference by the width of each interval.\n  t_avg = t_diff / t_widths\n\n  # Compute the average value of the step function for each interval in `t` by dividing the difference by the width of each interval.\n  t_avg = t_diff / t_widths\n\n  # Compute the average value of the step function for each interval in `t` by dividing the difference by the width of each interval.\n  t_avg = t_diff / t_widths\n\n  # Compute the average value of the step function for each interval in `t` by dividing the difference by the width of each interval.\n  t_avg = t_diff / t_widths\n\n  # Compute the average value of the step function for each interval in `t` by dividing the difference by the width of each interval.\n  t_avg = t_diff / t_widths\n\n  # Compute the average value of the step function for each interval in `"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  t = jnp.asarray(t)\n  tp = jnp.asarray(tp)\n  vp = jnp.asarray(vp)\n\n  # Resample the step function using linear interpolation\n  vp_resampled = math.sorted_interp(t, tp, vp, utils.device_is_tpu())\n\n  # Sum the values within each interval in t\n  if use_avg:\n    # Compute the width of each interval in t\n    interval_widths = jnp.diff(t)\n    # Compute the weighted average of the values within each interval\n    vp_resampled = vp_resampled * interval_widths\n    vp_resampled = jnp.cumsum(vp_resampled, axis=-1)\n    vp_resampled = vp_resampled / interval_widths\n  else:\n    # Compute the sum of the values within each interval\n    vp_resampled = jnp.cumsum(vp_resampled, axis=-1)\n\n  return vp_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Resample the step function.\n  vp = linspline.resample(t, tp, vp, use_avg=use_avg)\n  # Return the new step function.\n  return vp\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, None)\n\n  # Calculate the width of each interval in t\n  dt = jnp.diff(t)\n\n  # Calculate the width of each interval in tp\n  dtp = jnp.diff(tp)\n\n  # Calculate the start and end indices of each interval in tp that overlaps with an interval in t\n  start_idx, end_idx = linspline.get_overlap_indices(t, tp)\n\n  # Calculate the width of each interval in tp that overlaps with an interval in t\n  overlap_width = jnp.minimum(tp[end_idx], t[start_idx + 1]) - jnp.maximum(\n      tp[start_idx], t[start_idx]\n  )\n\n  # Calculate the weighted sum or average of the values in each overlapping interval in tp\n  if use_avg:\n    vp_resampled = (overlap_width * vp[start_idx : end_idx + 1]).sum(axis=-1) / dt\n  else:\n    vp_resampled = (overlap_width * vp[start_idx : end_idx + 1]).sum(axis=-1)\n\n  return vp_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.zeros_like(t))\n\n  # Compute the width of each interval in t\n  dt = jnp.diff(t)\n\n  # Compute the width of each interval in tp\n  dtp = jnp.diff(tp)\n\n  # Compute the cumulative sum of the values of the step function for each interval in tp\n  vp_cumsum = jnp.cumsum(vp * dtp, axis=-1)\n\n  # Compute the cumulative sum of the widths of each interval in tp\n  dtp_cumsum = jnp.cumsum(dtp, axis=-1)\n\n  # Compute the index of the interval in tp that contains each interval in t\n  idx = jnp.searchsorted(tp, t, side=\"left\")\n\n  # Compute the values of the resampled step function for each interval in t\n  vp_resampled = (vp_cumsum[Ellipsis, idx] - vp_cumsum[Ellipsis, idx - 1]) / (\n      dtp_cumsum[Ellipsis, idx] - dtp_cumsum[Ellipsis, idx - 1]\n  )\n\n  # If use_avg is True, compute the average value of the step function for each interval in t\n  if use_avg:\n    vp_resampled = vp_resampled * dt\n\n  return vp_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the widths of the intervals in `t`\n  t_widths = jnp.diff(t)\n\n  # Compute the widths of the intervals in `tp`\n  tp_widths = jnp.diff(tp)\n\n  # Compute the cumulative sum of the widths of the intervals in `tp`\n  tp_cumsum = jnp.cumsum(tp_widths)\n\n  # Compute the cumulative sum of the widths of the intervals in `t`\n  t_cumsum = jnp.cumsum(t_widths)\n\n  # Compute the cumulative sum of the values of the step function at the original time points\n  vp_cumsum = jnp.cumsum(vp)\n\n  # Initialize the resampled values array\n  vp_resampled = jnp.zeros_like(t_widths)\n\n  # Iterate over the intervals in `t`\n  for i in range(len(t_widths)):\n    # Find the indices of the intervals in `tp` that overlap with the current interval in `t`\n    overlap_indices = jnp.where((tp_cumsum > t_cumsum[i]) & (tp_cumsum <= t_cumsum[i] + t_widths[i]))[0]\n\n    # If there are overlapping intervals in `tp`, compute the resampled value\n    if len(overlap_indices) > 0:\n      # Compute the widths of the overlapping intervals in `tp`\n      overlap_widths = tp_widths[overlap_indices]\n\n      # Compute the cumulative sum of the values of the step function at the overlapping time points\n      overlap_cumsum = vp_cumsum[overlap_indices]\n\n      # Compute the resampled value based on the sum or average of the overlapping values\n      if use_avg:\n        vp_resampled = vp_resampled.at[i].set(jnp.sum(overlap_cumsum * overlap_widths) / jnp.sum(overlap_widths))\n      else:\n        vp_resampled = vp_resampled.at[i].set(jnp.sum(overlap_cumsum * overlap_widths))\n\n  return vp_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # The default behavior is to sum the values of the step function for each interval in `t`.\n  if not use_avg:\n    return linspline.linspline_interp(t, tp, vp)\n  # If `use_avg` is True, we return the average value, weighted by the width of each interval in `t`.\n  else:\n    # Compute the widths of each interval in `t`.\n    dt = jnp.diff(t)\n    # Compute the average value for each interval in `t`, weighted by the width of the interval.\n    return linspline.linspline_interp(t, tp, vp * dt) / dt\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Check if the step function is valid (i.e., tp is sorted and vp is non-negative)\n  if not (jnp.all(jnp.diff(tp) > 0) and jnp.all(vp >= 0)):\n    raise ValueError(\"Invalid step function: tp must be sorted and vp must be non-negative.\")\n\n  # Check if the new intervals are valid (i.e., t is sorted and t[0] >= tp[0] and t[-1] <= tp[-1])\n  if not (jnp.all(jnp.diff(t) > 0) and t[0] >= tp[0] and t[-1] <= tp[-1]):\n    raise ValueError(\n        \"Invalid new intervals: t must be sorted and t[0] >= tp[0] and t[-1] <= tp[-1].\"\n    )\n\n  # Find the indices of the intervals in tp that contain each interval in t\n  indices = jnp.searchsorted(tp, t, side=\"right\") - 1\n\n  # Compute the width of each interval in t\n  dt = jnp.diff(t)\n\n  # Compute the resampled values\n  if use_avg:\n    # Compute the average value for each interval in t\n    resampled_values = (vp[indices] * dt + vp[indices + 1] * dt) / (dt + dt)\n  else:\n    # Compute the sum of the values for each interval in t\n    resampled_values = vp[indices] * dt + vp[indices + 1] * dt\n\n  return resampled_values\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in the original step function.\n  width = jnp.diff(tp)\n\n  # Compute the width of each interval in the new step function.\n  new_width = jnp.diff(t)\n\n  # Compute the indices of the intervals in the new step function that each original interval belongs to.\n  _, (indices,) = math.sorted_lookup(tp, t, (), utils.device_is_tpu())\n\n  # Compute the start and end indices of each interval in the new step function.\n  start_indices = jnp.minimum(indices, t.shape[-1] - 2)\n  end_indices = jnp.minimum(indices + 1, t.shape[-1] - 2)\n\n  # Compute the width of each interval in the new step function that each original interval belongs to.\n  start_width = tp - t[Ellipsis, start_indices]\n  end_width = t[Ellipsis, end_indices] - tp\n\n  # Compute the fraction of the original interval that falls within each interval in the new step function.\n  start_fraction = start_width / width\n  end_fraction = end_width / width\n\n  # Compute the resampled values for each interval in the new step function.\n  if use_avg:\n    resampled_values = (\n        start_fraction * vp[Ellipsis, start_indices]\n        + end_fraction * vp[Ellipsis, end_indices]\n    ) / new_width\n  else:\n    resampled_values = (\n        start_fraction * vp[Ellipsis, start_indices]\n        + end_fraction * vp[Ellipsis, end_indices]\n    )\n\n  return resampled_values\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  t = jnp.array(t)\n  tp = jnp.array(tp)\n  vp = jnp.array(vp)\n  assert t.ndim == 1\n  assert tp.ndim == 1\n  assert vp.ndim == 1\n  assert tp.shape[0] == vp.shape[0]\n  assert tp.shape[0] >= 2\n  assert t.shape[0] >= 2\n  assert jnp.all(jnp.diff(tp) > 0)\n  assert jnp.all(jnp.diff(t) > 0)\n  assert jnp.all(tp[0] <= t)\n  assert jnp.all(tp[-1] >= t)\n  assert jnp.all(t[0] <= tp)\n  assert jnp.all(t[-1] >= tp)\n\n  # Find the indices of the intervals in `t` that contain each time point in `tp`.\n  indices = jnp.searchsorted(t, tp)\n  # Adjust the indices to ensure they are within the valid range.\n  indices = jnp.clip(indices, 0, t.shape[0] - 1)\n  # Compute the widths of the intervals in `t` that contain each time point in `tp`.\n  widths = t[indices + 1] - t[indices]\n  # Compute the widths of the intervals in `tp` that are contained in each interval in `t`.\n  widths_tp = tp[indices + 1] - tp[indices]\n  # Compute the weights for each value in `vp` based on the widths of the intervals in `t` and `tp`.\n  weights = widths_tp / widths\n  # Apply the weights to the values in `vp` to obtain the weighted values.\n  weighted_values = weights * vp\n\n  # Resample the step function using the weighted values.\n  if use_avg:\n    # Compute the average value for each interval in `t` by summing the weighted values and dividing by the width of the interval.\n    resampled_values = jnp.sum(weighted_values, axis=0) / widths\n  else:\n    # Compute the sum of the weighted values for each interval in `t`.\n    resampled_values = j"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, None)\n  t = jnp.asarray(t)\n  tp = jnp.asarray(tp)\n  vp = jnp.asarray(vp)\n\n  # Check if the input time points are sorted\n  if not jnp.all(jnp.diff(tp) >= 0):\n    raise ValueError(\"The input time points must be sorted.\")\n\n  # Check if the input time points are within the range of the new intervals\n  if not jnp.all(tp[0] <= t) or not jnp.all(tp[-1] >= t):\n    raise ValueError(\n        \"The input time points must be within the range of the new intervals.\"\n    )\n\n  # Find the indices of the intervals that contain each new time point\n  interval_indices = jnp.searchsorted(tp, t)\n\n  # Check if the new time points are within the range of the input time points\n  if not jnp.all(interval_indices >= 0) or not jnp.all(interval_indices < len(tp)):\n    raise ValueError(\n        \"Some new time points are not within the range of the input time points.\"\n    )\n\n  # Compute the widths of the intervals in the new intervals\n  interval_widths = jnp.diff(t)\n\n  # Compute the widths of the intervals in the input time points\n  input_interval_widths = jnp.diff(tp)\n\n  # Compute the weighted average of the values in each interval\n  if use_avg:\n    # Compute the weighted average of the values in each interval\n    weighted_values = (\n        vp[interval_indices] * input_interval_widths[interval_indices]\n        + vp[interval_indices + 1] * input_interval_widths[interval_indices + 1]\n    ) / (input_interval_widths[interval_indices] + input_interval_widths[interval_indices + 1])\n\n    # Multiply the weighted average by the width of the interval\n    resampled_values = weighted_values * interval_widths\n  else:\n    # Compute the sum of the values in each interval\n    sum_values = vp[interval_indices] * input_interval_widths[interval_indices] + vp[\n        interval_indices + 1\n    ] * input_"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  vp = jnp.asarray(vp)\n  # Compute the width of each interval in `t`.\n  td = jnp.diff(t)\n  # Compute the width of each interval in `tp`.\n  tpd = jnp.diff(tp)\n  # Compute the width of each interval in `t` in terms of the original intervals `tp`.\n  td_tp = jnp.diff(linspline.interp(t, tp))\n  # Compute the ratio of the width of each interval in `t` to the width of the corresponding interval in `tp`.\n  ratio = td_tp / tpd\n  # Compute the cumulative sum of the values of the step function in `tp`.\n  csum = jnp.cumsum(vp, axis=-1)\n  # Compute the cumulative sum of the values of the step function in `t`.\n  csum_t = linspline.interp(t, csum)\n  # Compute the cumulative sum of the values of the step function in `t` for each interval in `t`.\n  csum_t = jnp.cumsum(csum_t * td_tp, axis=-1)\n  # Compute the cumulative sum of the values of the step function in `tp` for each interval in `t`.\n  csum_tp = linspline.interp(t, csum)\n  # Compute the cumulative sum of the values of the step function in `tp` for each interval in `t`.\n  csum_tp = jnp.cumsum(csum_tp * tpd, axis=-1)\n  # Compute the difference between the cumulative sums of the values of the step function in `t` and `tp` for each interval in `t`.\n  diff = csum_t - csum_tp\n  # Compute the resampled values of the step function in `t`.\n  if use_avg:\n    # Compute the average value of the step function in each interval in `t`.\n    vp_t = diff / td_tp\n  else:\n    # Compute the sum of the values of the step function in each interval in `t`.\n    vp_t = diff\n  # Compute the resampled values of the step function in `t` for each interval in `t`.\n  vp_t = jnp.concatenate(["}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the widths of the original intervals.\n  td = jnp.diff(tp)\n  # Compute the widths of the new intervals.\n  t_widths = jnp.diff(t)\n\n  # Compute the weighted average of the original values for each new interval.\n  if use_avg:\n    # Compute the weighted average of the original values for each new interval.\n    weights = t_widths / td\n    vp = vp * weights\n    vp = jnp.sum(vp, axis=-1)\n    vp = vp / jnp.sum(weights, axis=-1)\n  else:\n    # Compute the sum of the original values for each new interval.\n    vp = vp * t_widths\n    vp = jnp.sum(vp, axis=-1)\n\n  return vp\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.zeros_like(t))\n\n  # We first compute the cumulative sum of the original step function.\n  vp_cumsum = jnp.cumsum(vp, axis=-1)\n\n  # Then, we find the indices of the intervals in `t` that contain the original time points in `tp`.\n  indices = jnp.searchsorted(t, tp, side='left')\n\n  # If the original time points are outside the range of `t`, we handle them separately.\n  outside_indices = jnp.logical_or(indices == 0, indices == t.shape[-1])\n  indices = jnp.where(outside_indices, jnp.zeros_like(indices), indices)\n\n  # We compute the width of each interval in `t`.\n  interval_widths = jnp.diff(t)\n\n  # We compute the cumulative sum of the original step function at the indices corresponding to the intervals in `t`.\n  vp_cumsum_at_indices = vp_cumsum[Ellipsis, indices]\n\n  # We compute the cumulative sum of the original step function at the indices corresponding to the intervals in `t` plus one.\n  vp_cumsum_at_indices_plus_one = vp_cumsum[Ellipsis, indices + 1]\n\n  # We compute the difference between the cumulative sums at the indices and the cumulative sums at the indices plus one.\n  vp_diff = vp_cumsum_at_indices_plus_one - vp_cumsum_at_indices\n\n  # If we are using the average method, we divide the difference by the interval widths.\n  if use_avg:\n    vp_diff = vp_diff / interval_widths\n\n  # We handle the case where the original time points are outside the range of `t` by setting the corresponding values to zero.\n  vp_diff = jnp.where(outside_indices, jnp.zeros_like(vp_diff), vp_diff)\n\n  return vp_diff\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # We need to sort tp and vp in the same order.\n  tp, vp = math.sorted_zip(tp, vp)\n  # Compute the bin widths.\n  dt = jnp.diff(t)\n  # Compute the bin indices corresponding to each time point.\n  indices = jnp.searchsorted(tp, t)\n  # Compute the weights for each time point.\n  weights = jnp.where(\n      jnp.equal(indices, 0),\n      jnp.where(jnp.equal(t, tp[0]), 1, 0),\n      jnp.where(\n          jnp.equal(indices, tp.shape[-1]),\n          jnp.where(jnp.equal(t, tp[-1]), 1, 0),\n          jnp.where(\n              jnp.equal(t, tp[indices - 1]),\n              1 - math.safe_div(t - tp[indices - 1], dt),\n              math.safe_div(tp[indices] - t, dt),\n          ),\n      ),\n  )\n  # Compute the resampled values.\n  if use_avg:\n    resampled_values = jnp.sum(vp * weights, axis=-1) / dt\n  else:\n    resampled_values = jnp.sum(vp * weights, axis=-1)\n  return resampled_values\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # tp is the original time points of the step function\n  # t is the new time points for resampling\n  # vp is the values of the step function at the original time points (tp)\n  # use_avg determines the resampling method\n  # if use_avg is False, the function sums the values of the step function for each interval in t\n  # if use_avg is True, it returns the average value, weighted by the width of each interval in t\n\n  # Compute the width of each interval in the original step function\n  width = jnp.diff(tp)\n  # Compute the width of each interval in the new step function\n  new_width = jnp.diff(t)\n\n  # Compute the cumulative sum of the values of the step function\n  cumulative_sum = jnp.cumsum(vp * width)\n\n  # Compute the cumulative sum of the width of each interval in the new step function\n  cumulative_width = jnp.cumsum(new_width)\n\n  # Compute the index of the interval in the new step function that contains each original time point\n  indices = jnp.searchsorted(t, tp) - 1\n\n  # Compute the values of the resampled step function at the new intervals\n  values = (cumulative_sum[indices] - cumulative_sum[indices - 1]) / (\n      cumulative_width[indices] - cumulative_width[indices - 1]\n  )\n\n  # If use_avg is True, return the average value, weighted by the width of each interval in t\n  if use_avg:\n    values = values * new_width\n\n  return values\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of 2 within the specified range of degrees.\n  scaled_mean = mean * 2 ** jnp.arange(min_deg, max_deg)\n  scaled_var = var * 2 ** jnp.arange(min_deg, max_deg)\n\n  # Concatenate the scaled mean and variance.\n  concat_scaled = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding to the concatenated values.\n  sin_enc = jnp.sin(concat_scaled)\n\n  return sin_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of 2.\n  scaled_mean = mean * 2 ** jnp.arange(min_deg, max_deg)\n  scaled_var = var * 2 ** jnp.arange(min_deg, max_deg)\n\n  # Concatenate the scaled mean and variance.\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding to the concatenated mean and variance.\n  sin_enc = jnp.concatenate(\n      [jnp.sin(concat_mean_var), jnp.cos(concat_mean_var)], axis=-1\n  )\n\n  return sin_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale mean and variance by powers of 2 within the specified range.\n  scaled_mean = mean * 2**jnp.arange(min_deg, max_deg)\n  scaled_var = var * 2**jnp.arange(min_deg, max_deg)\n\n  # Concatenate the scaled mean and variance.\n  concat = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding to the concatenated values.\n  return jnp.concatenate([jnp.sin(concat), jnp.cos(concat)], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor based on the specified degrees.\n  scale = 2 ** jnp.arange(min_deg, max_deg)\n  # Scale the mean and variance using the scaling factor.\n  scaled_mean = mean[:, None] * scale\n  scaled_var = var[:, None] * scale\n  # Concatenate the scaled mean and variance.\n  concat = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  # Apply sinusoidal encoding to the concatenated values.\n  return jnp.concatenate([jnp.sin(concat), jnp.cos(concat)], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of 2 within the specified range of degrees.\n  mean_scaled = mean * 2 ** jnp.arange(min_deg, max_deg)\n  var_scaled = var * 2 ** jnp.arange(min_deg, max_deg)\n  # Concatenate the scaled mean and variance along the last axis.\n  concat = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n  # Apply sinusoidal encoding to the concatenated values.\n  return jnp.concatenate(\n      [jnp.sin(concat), jnp.cos(concat)], axis=-1\n  )  # Concatenate sin and cos encoding.\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  mean_scaled = mean * 2**min_deg\n  var_scaled = var * 2**min_deg\n\n  # Concatenate the mean and variance\n  concat = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded = geopoly.sinusoidal_encode(concat, degrees=range(min_deg, max_deg))\n\n  return encoded\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  mean = mean / 2**min_deg\n  var = var / 2**min_deg\n  x = jnp.concatenate([mean, var], axis=-1)\n  x = x[..., None]\n  deg = jnp.arange(min_deg, max_deg, dtype=jnp.float32)\n  deg = deg[None, None, :]\n  x = x * 2**deg\n  return jnp.sin(x)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale mean and variance by 2 ** degree.\n  mean_scaled = mean * 2 ** jnp.arange(min_deg, max_deg)\n  var_scaled = var * 2 ** jnp.arange(min_deg, max_deg)\n\n  # Concatenate mean and variance.\n  mean_var = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply sinusoidal encoding.\n  return jnp.concatenate([jnp.sin(mean_var), jnp.cos(mean_var)], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  mean = jnp.expand_dims(mean, axis=-1)\n  var = jnp.expand_dims(var, axis=-1)\n  deg = jnp.arange(min_deg, max_deg)\n  scale = 2**deg\n  mean_scaled = mean / scale\n  var_scaled = var / scale\n  sin_mean = jnp.sin(mean_scaled)\n  sin_var = jnp.sin(var_scaled)\n  sin_mean_var = jnp.concatenate([sin_mean, sin_var], axis=-1)\n  return sin_mean_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  mean_scaled = mean / jnp.sqrt(var)\n  var_scaled = jnp.sqrt(var)\n  pos_enc = []\n  for deg in range(min_deg, max_deg):\n    freq = 2 ** deg\n    pos_enc.append(jnp.sin(mean_scaled * freq))\n    pos_enc.append(jnp.sin(var_scaled * freq))\n  return jnp.concatenate(pos_enc, axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Calculate the scaling factor based on the min and max degrees.\n  scale = 2 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the mean and variance by the scaling factor.\n  mean_scaled = mean * scale\n  var_scaled = var * scale\n\n  # Concatenate the mean and variance.\n  mean_var = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply sinusoidal encoding to the concatenated mean and variance.\n  encoded = math.sin(mean_var)\n\n  return encoded\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Initialize the scaling factor with the minimum degree.\n  deg = min_deg\n  # Initialize the list to store the encoded variables.\n  encoded = []\n  # Iterate over the degrees from the minimum to the maximum (exclusive).\n  while deg < max_deg:\n    # Compute the scaling factor for the current degree.\n    scale = 2**deg\n    # Scale the mean and variance of the coordinates.\n    scaled_mean = mean * scale\n    scaled_var = var * scale\n    # Concatenate the scaled mean and variance.\n    concat = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n    # Apply the sinusoidal encoding to the concatenated values.\n    encoded.append(jnp.sin(concat))\n    # Increment the degree for the next iteration.\n    deg += 1\n  # Concatenate the encoded variables along the last axis.\n  return jnp.concatenate(encoded, axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of 2\n  scaled_mean = mean * 2 ** jnp.arange(min_deg, max_deg)\n  scaled_var = var * 2 ** jnp.arange(min_deg, max_deg)\n  # Concatenate the scaled mean and variance\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  # Apply sinusoidal encoding to the concatenated mean and variance\n  sin_enc = jnp.concatenate(\n      [jnp.sin(concat_mean_var), jnp.cos(concat_mean_var)], axis=-1\n  )\n  return sin_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor based on the degrees.\n  deg_scale = 2 ** jnp.arange(min_deg, max_deg)\n  # Scale the mean and variance by the scaling factor.\n  scaled_mean = deg_scale * mean\n  scaled_var = deg_scale * var\n  # Concatenate the scaled mean and variance.\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  # Apply sinusoidal encoding to the concatenated values.\n  encoded_mean_var = jnp.stack([\n      jnp.sin(concat_mean_var),\n      jnp.cos(concat_mean_var)\n  ], axis=-1)\n  return encoded_mean_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the mean and variance.\n  scale_mean = 2 ** (min_deg + jnp.arange(max_deg - min_deg))\n  scale_var = 2 ** (min_deg + jnp.arange(max_deg - min_deg))\n\n  # Compute the scaled mean and variance.\n  scaled_mean = jnp.expand_dims(mean, axis=-1) * scale_mean\n  scaled_var = jnp.expand_dims(var, axis=-1) * scale_var\n\n  # Compute the expected value of sin(x), where x ~ N(mean, var).\n  expected_sin_mean = expected_sin(scaled_mean, scaled_var)\n\n  # Compute the expected value of sin(x), where x ~ N(mean + pi/2, var).\n  expected_sin_var = expected_sin(scaled_mean + np.pi / 2, scaled_var)\n\n  # Concatenate the expected values of sin(x) and sin(x + pi/2).\n  return jnp.concatenate([expected_sin_mean, expected_sin_var], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by powers of 2.\n  scale = 2 ** jnp.arange(min_deg, max_deg)\n  mean_scaled = mean * scale\n  var_scaled = var * scale\n\n  # Concatenate the mean and variance.\n  mean_var = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply a sinusoidal encoding to the concatenated mean and variance.\n  sin_enc = jnp.sin(mean_var)\n  return sin_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by the scaling factor.\n  scale = 2 ** jnp.arange(min_deg, max_deg)\n  scaled_mean = mean[:, None] * scale\n  scaled_var = var[:, None] * scale\n\n  # Concatenate the scaled mean and variance along the last axis.\n  enc_mean = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding to the concatenated mean and variance.\n  enc_mean = jnp.sin(enc_mean)\n\n  return enc_mean\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scale factor based on the degree range.\n  deg = jnp.arange(min_deg, max_deg)\n  scale = 2**deg\n\n  # Scale the mean and variance.\n  mean_scaled = mean * scale\n  var_scaled = var * scale\n\n  # Concatenate the scaled mean and variance.\n  x = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  sin_x = jnp.sin(x)\n\n  return sin_x\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by 2**deg\n  def scale(deg):\n    return jnp.stack([mean * 2**deg, var * 2**deg], axis=-1)\n\n  # Apply sinusoidal encoding to the scaled mean and variance\n  def encode(x):\n    return jnp.concatenate([jnp.sin(x), jnp.cos(x)], axis=-1)\n\n  # Concatenate the sinusoidal encodings for each degree in the range\n  return jnp.concatenate([encode(scale(deg)) for deg in range(min_deg, max_deg)], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The number of dimensions of the mean and variance tensors.\n  ndim = mean.shape[-1]\n  # The range of degrees to use for encoding.\n  deg_range = jnp.arange(min_deg, max_deg)\n  # The scale factor for the encoding.\n  scale = 2**deg_range\n  # The scaled mean and variance of the coordinates.\n  mean_scaled = mean[..., None] * scale\n  var_scaled = var[..., None] * scale\n  # The concatenated mean and variance.\n  mean_var = jnp.concatenate((mean_scaled, var_scaled), axis=-1)\n  # The sinusoidal encoding of the concatenated mean and variance.\n  enc = geopoly.sin_enc(mean_var, ndim, deg_range)\n  return enc\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (IDE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting IDE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    #"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: [N, 3] array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: [N, 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: [N, 2 * deg_view] array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[..., 0:1]\n    y = xyz[..., 1:2]\n    z = xyz[..., 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to evaluate the directional encoding for.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The directional encoding of the input point(s).\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to evaluate the directional encoding for.\n    :param kappa_inv: Float. The inverse of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma *"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    :param xyz: [batch_size, 3] Array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: [batch_size, 1] Reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: [batch_size, 2 * deg_view] Array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[..., 0:1]\n    y = xyz[..., 1:2]\n    z = xyz[..., 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * j"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to evaluate the directional encoding for. The shape of the array should be [..., 3], where ... represents any number of additional dimensions.\n    :param kappa_inv: Array. The inverse of the concentration parameter of the von Mises-Fisher distribution. The shape of the array should be [..., 1], where ... represents any number of additional dimensions.\n    :return: Array. The directional encoding evaluated for the given inputs. The shape of the returned array will be [..., 2 * deg_view], where ... represents any number of additional dimensions.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vm"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to evaluate the directional encoding for. It should be of shape (..., 3), where ... represents the batch dimensions.\n    :param kappa_inv: Array. The inverse of the concentration parameter of the von Mises-Fisher distribution. It should be of shape (..., 1), where ... represents the batch dimensions.\n    :return: Array. The directional encoding for the given inputs. It will have the same shape as the input xyz, with an additional dimension for the directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von M"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Check if the degree of spherical harmonics is valid\n  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((deg_view + 1, 2 * deg_view + 1))\n  for m in range(-deg_view, deg_view + 1):\n    for l in range(deg_view, deg_view + 1):\n      for k in range(l - abs(m) + 1):\n        mat[k, m + deg_view] = sph_harm_coeff(l, m, k)\n\n  def directional_encoding_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in range(-deg_view, deg_view + 1)], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * np.arange(deg_view + 1) * (np.arange(deg_view + 1) + 1)\n    de"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to be encoded. It can be a 2D array of shape (N, 3) where N is the number of points, or a 3D array of shape (..., 3) where ... represents any number of additional dimensions.\n    :param kappa_inv: Array. The inverse of the concentration parameter of the von Mises-Fisher distribution. It can be a scalar value or a 1D array of shape (N,) where N is the number of points.\n    :return: Array. The directional encoding of the input point(s). It has the same shape as the input point(s) but with an additional dimension for the encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    This function evaluates the directional encoding for a given 3D point (or points). It takes a 3D point (or points) as input and returns its directional encoding.\n\n    Input-Output Arguments\n    :param xyz: Array. The 3D point (or points) to evaluate the directional encoding for. It should be of shape (..., 3), where ... represents any number of additional dimensions.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution. It should be of shape (..., 1), where ... represents any number of additional dimensions.\n    :return: Array. The directional encoding of the input point(s). It has the same shape as the input point(s) with an additional dimension for the encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_encoding_fn(xyz, kappa_inv):\n    \"\"\"\n    This function generates a directional encoding function based on the specified number of spherical harmonics degrees.\n\n    :param xyz: A JAX array of shape (..., 3) representing the 3D point (or points) to be encoded.\n    :param kappa_inv: A JAX array of shape (..., 1) representing the inverse of the concentration parameter of the von Mises-Fisher distribution.\n    :return: A JAX array of shape (..., 2 * (deg_view + 1)) representing the directional encoding of the input point(s).\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:\n        return result\n\n    lines = [line for line in lines if not should_skip(line, xml)]\n    if not lines:"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Remove duplicate lines (ignoring numbers)\n    lines = [line for line in lines if not line.endswith(\")\")]\n    # Fix spaced characters\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"\u2022\") for line in lines]\n    lines = [line.replace"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n        line = line.strip()\n        if line.startswith(\"(\") and line.endswith(\")\"):\n            line = line[1:-1]\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\"\uf0b7\", \"\u2022\")\n        line = line.replace(\""}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    # lines = [line.rstrip() for line in lines]\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip() != '']\n    # lines = [line for line in lines if line.strip"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Initialize variables\n    result = []\n    line_blocks = []\n    line_block_index = 0\n    header_block_index = 0\n    header_block_index_list = []\n    header_block_index_list_temp = []\n    header_block_index_list_temp_2 = []\n    header_block_index_list_temp_3 = []\n    header_block_index_list_temp_4 = []\n    header_block_index_list_temp_5 = []\n    header_block_index_list_temp_6 = []\n    header_block_index_list_temp_7 = []\n    header_block_index_list_temp_8 = []\n    header_block_index_list_temp_9 = []\n    header_block_index_list_temp_10 = []\n    header_block_index_list_temp_11 = []\n    header_block_index_list_temp_12 = []\n    header_block_index_list_temp_13 = []\n    header_block_index_list_temp_14 = []\n    header_block_index_list_temp_15 = []\n    header_block_index_list_temp_16 = []\n    header_block_index_list_temp_17 = []\n    header_block_index_list_temp_18 = []\n    header_block_index_list_temp_19 = []\n    header_block_index_list_temp_20 = []\n    header_block_index_list_temp_21 = []\n    header_block_index_list_temp_22 = []\n    header_block_index_list_temp_23 = []\n    header_block_index_list_temp_24 = []\n    header_block_index_list_temp_25 = []\n    header_block_index_list_temp_26 = []\n    header_block_index_list_temp_27 = []\n    header_block_index_list_temp_28 = []\n    header_block_index_list_temp_29 = []\n    header_block_index_list_temp_30 = []\n    header_block_index_list_temp_31 = []\n    header_block"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block = []\n    block_index = 0\n    header_index = 0\n    header_block_index = 0\n    list_item_index = 0\n    list_item_block_index = 0\n    list_item_level = 0\n    list_item_type = None\n    list_item_start_index = 0\n    list_item_end_index = 0\n    list_item_blocks = []\n    list_item_header_index = 0\n    list_item_header_block_index = 0\n    list_item_header_level = 0\n    list_item_header_type = None\n    list_item_header_start_index = 0\n    list_item_header_end_index = 0\n    list_item_header_blocks = []\n    list_item_header_header_index = 0\n    list_item_header_header_block_index = 0\n    list_item_header_header_level = 0\n    list_item_header_header_type = None\n    list_item_header_header_start_index = 0\n    list_item_header_header_end_index = 0\n    list_item_header_header_blocks = []\n    list_item_header_header_header_index = 0\n    list_item_header_header_header_block_index = 0\n    list_item_header_header_header_level = 0\n    list_item_header_header_header_type = None\n    list_item_header_header_header_start_index = 0\n    list_item_header_header_header_end_index = 0\n    list_item_header_header_header_blocks = []\n    list_item_header_header_header_header_index = 0\n    list_item_header_header_header_header_block_index = 0\n    list_item_header_header_header_header_level = 0\n    list_item_header_header_header_header_type = None\n    list_item_header_header_header_header_start_index = 0\n    list_item_header_header_header_header_end_index = 0\n    list_item_header_header_header"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    blocks = []\n    block = []\n    block_type = \"\"\n    block_index = 0\n    block_start = 0\n    block_level = 0\n    block_list = []\n    header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_start = 0\n    block_list_level = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_type = \"\"\n    block_list_index = "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_index = 0\n    block_type = \"\"\n    block_text = \"\"\n    block_start = 0\n    block_list = []\n    block_header_index = -1\n    block_level = 0\n    block_list_index = -1\n    block_list_type = \"\"\n    block_list_start = 0\n    block_list_end = 0\n    block_list_item_index = -1\n    block_list_item_start = 0\n    block_list_item_end = 0\n    block_list_item_text = \"\"\n    block_list_item_type = \"\"\n    block_list_item_level = 0\n    block_list_item_sublist_index = -1\n    block_list_item_sublist_start = 0\n    block_list_item_sublist_end = 0\n    block_list_item_sublist_type = \"\"\n    block_list_item_sublist_item_index = -1\n    block_list_item_sublist_item_start = 0\n    block_list_item_sublist_item_end = 0\n    block_list_item_sublist_item_text = \"\"\n    block_list_item_sublist_item_type = \"\"\n    block_list_item_sublist_item_level = 0\n    block_list_item_sublist_item_sublist_index = -1\n    block_list_item_sublist_item_sublist_start = 0\n    block_list_item_sublist_item_sublist_end = 0\n    block_list_item_sublist_item_sublist_type = \"\"\n    block_list_item_sublist_item_sublist_item_index = -1\n    block_list_item_sublist_item_sublist_item_start = 0\n    block_list_item_sublist_item_sublist_item_end = 0\n    block_list_item_sublist_item_sublist_item_text = \"\"\n    block_list_item_sublist_item_sublist_item_type = \"\"\n    block_list_item_sublist_item_sublist_item_level = 0\n   "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    header_index = 0\n    list_index = 0\n    list_level = 0\n    list_block_index = 0\n    list_type = \"\"\n    block_index = 0\n    block_type = \"\"\n    block_text = \"\"\n    block_start = 0\n    block_list = []\n    block_header_index = 0\n    block_level = 0\n    block_list_type = \"\"\n    block_list_index = 0\n    block_list_level = 0\n    block_list_block_index = 0\n    block_list_text = \"\"\n    block_list_start = 0\n    block_list_list = []\n    block_list_header_index = 0\n    block_list_level = 0\n    block_list_list_type = \"\"\n    block_list_list_index = 0\n    block_list_list_level = 0\n    block_list_list_block_index = 0\n    block_list_list_text = \"\"\n    block_list_list_start = 0\n    block_list_list_list = []\n    block_list_list_header_index = 0\n    block_list_list_level = 0\n    block_list_list_list_type = \"\"\n    block_list_list_list_index = 0\n    block_list_list_list_level = 0\n    block_list_list_list_block_index = 0\n    block_list_list_list_text = \"\"\n    block_list_list_list_start = 0\n    block_list_list_list_list = []\n    block_list_list_list_header_index = 0\n    block_list_list_list_level = 0\n    block_list_list_list_list_type = \"\"\n    block_list_list_list_list_index = 0\n    block_list_list_list_list_level = 0\n    block_list_list_list_list_block_index = 0\n    block_list_list_list_list_text = \"\"\n    block_list_list_list_list_start = 0\n    block_list_list_list_list_list = []\n    block_list_list_list"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block = []\n    block_type = None\n    block_index = 0\n    header_block_index = None\n    header_block_level = 0\n    block_level = 0\n    block_list = []\n    block_list_index = 0\n    list_item_index = 0\n    block_list_level = 0\n    block_list_type = None\n    list_item_type = None\n    list_item_level = 0\n    list_item_list = []\n    list_item_list_index = 0\n    list_item_list_level = 0\n    list_item_list_type = None\n    list_item_list_item_index = 0\n    list_item_list_item_type = None\n    list_item_list_item_level = 0\n    list_item_list_item_list = []\n    list_item_list_item_list_index = 0\n    list_item_list_item_list_level = 0\n    list_item_list_item_list_type = None\n    list_item_list_item_list_item_index = 0\n    list_item_list_item_list_item_type = None\n    list_item_list_item_list_item_level = 0\n    list_item_list_item_list_item_list = []\n    list_item_list_item_list_item_list_index = 0\n    list_item_list_item_list_item_list_level = 0\n    list_item_list_item_list_item_list_type = None\n    list_item_list_item_list_item_list_item_index = 0\n    list_item_list_item_list_item_list_item_type = None\n    list_item_list_item_list_item_list_item_level = 0\n    list_item_list_item_list_item_list_item_list = []\n    list_item_list_item_list_item_list_item_list_index = 0\n    list_item_list_item_list_item_list_item_list_level = 0\n    list_item_list_item_list_item_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(lines)\n    result = []\n    block_index = 0\n    block_list = []\n    header_block_index = None\n    indent_level = 0\n    list_level = 0\n    list_items = []\n    list_item_index = 0\n    list_item_text = \"\"\n    list_item_type = \"\"\n    list_item_index_list = []\n    list_item_text_list = []\n    list_item_type_list = []\n    list_item_index_list_list = []\n    list_item_text_list_list = []\n    list_item_type_list_list = []\n    list_item_index_list_list_list = []\n    list_item_text_list_list_list = []\n    list_item_type_list_list_list = []\n    list_item_index_list_list_list_list = []\n    list_item_text_list_list_list_list = []\n    list_item_type_list_list_list_list = []\n    list_item_index_list_list_list_list_list = []\n    list_item_text_list_list_list_list_list = []\n    list_item_type_list_list_list_list_list = []\n    list_item_index_list_list_list_list_list_list = []\n    list_item_text_list_list_list_list_list_list = []\n    list_item_type_list_list_list_list_list_list = []\n    list_item_index_list_list_list_list_list_list_list = []\n    list_item_text_list_list_list_list_list_list_list = []\n    list_item_type_list_list_list_list_list_list_list = []\n    list_item_index_list_list_list_list_list_list_list_list = []\n    list_item_text_list_list_list_list_list_list_list_list = []\n    list_item_type_list_list_list_list_list_list_list_list = []\n    list_item_index_list_list_list_list_list"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    i = 0\n    block_index = 0\n    block_type = \"\"\n    block_level = 0\n    block_list = []\n    block_header_index = -1\n    block_start_index = 0\n    block_end_index = 0\n    block_text = \"\"\n    block_text_list = []\n    block_is_list = False\n    block_is_table = False\n    block_is_header = False\n    block_is_paragraph = False\n    block_is_unknown = False\n    block_is_table_row = False\n    block_is_table_header = False\n    block_is_table_footer = False\n    block_is_table_caption = False\n    block_is_table_cell = False\n    block_is_table_cell_header = False\n    block_is_table_cell_footer = False\n    block_is_table_cell_caption = False\n    block_is_table_cell_row = False\n    block_is_table_cell_row_header = False\n    block_is_table_cell_row_footer = False\n    block_is_table_cell_row_caption = False\n    block_is_table_cell_row_cell = False\n    block_is_table_cell_row_cell_header = False\n    block_is_table_cell_row_cell_footer = False\n    block_is_table_cell_row_cell_caption = False\n    block_is_table_cell_row_cell_row = False\n    block_is_table_cell_row_cell_row_header = False\n    block_is_table_cell_row_cell_row_footer = False\n    block_is_table_cell_row_cell_row_caption = False\n    block_is_table_cell_row_cell_row_cell = False\n    block_is_table_cell_row_cell_row_cell_header = False\n    block_is_table_cell_row_cell_row_cell_footer = False\n    block_is_table_cell_row_cell_row_cell_caption = False\n    block_is_table_cell_row_cell_row_cell_row = False\n    block_is_table_cell_row_cell_row"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    for index, line in enumerate(lines):\n        line = line.strip()\n        if should_skip(line, xml):\n            continue\n        line = line_parser.Line(line)\n        line.clean()\n        if line.is_duplicate(index, lines):\n            continue\n        line.fix_spaced_chars()\n        line.connect_incomplete_lines()\n        if line.is_header:\n            result.append(\n                {\n                    \"index\": index,\n                    \"text\": line.text,\n                    \"type\": \"header\",\n                    \"start_index\": line.start_index,\n                    \"blocks\": [],\n                    \"header_index\": None,\n                    \"level\": line.level,\n                }\n            )\n        elif line.is_list_item:\n            result.append(\n                {\n                    \"index\": index,\n                    \"text\": line.text,\n                    \"type\": \"list_item\",\n                    \"start_index\": line.start_index,\n                    \"blocks\": [],\n                    \"header_index\": line.header_index,\n                    \"level\": line.level,\n                }\n            )\n        else:\n            result.append(\n                {\n                    \"index\": index,\n                    \"text\": line.text,\n                    \"type\": \"paragraph\",\n                    \"start_index\": line.start_index,\n                    \"blocks\": [],\n                    \"header_index\": line.header_index,\n                    \"level\": line.level,\n                }\n            )\n    return result\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block = []\n    block_index = 0\n    header_block_index = 0\n    block_type = \"paragraph\"\n    block_level = 0\n    list_blocks = []\n    list_block_index = 0\n    list_block_type = \"\"\n    list_block_level = 0\n    list_block_start_index = 0\n    list_block_end_index = 0\n    list_block_text = \"\"\n    list_block_is_continuation = False\n    list_block_is_continuation_of_previous = False\n    list_block_is_continuation_of_next = False\n    list_block_is_continuation_of_previous_and_next = False\n    list_block_is_continuation_of_previous_and_next_and_last = False\n    list_block_is_continuation_of_previous_and_next_and_first = False\n    list_block_is_continuation_of_previous_and_next_and_middle = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_last = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_middle = False\n    list_block_is_continuation_of_previous_and_next_and_middle_and_last = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_middle_and_last = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_middle_and_last_and_first = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_middle_and_last_and_last = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_middle_and_last_and_middle = False\n    list_block_is_continuation_of_previous_and_next_and_first_and_middle_and_last_and_first_and_last = False\n    list_block_is_continuation_of_previous_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_type = \"\"\n    block_index = 0\n    block_start = 0\n    block_level = 0\n    block_list = []\n    block_header_index = 0\n    header_block = None\n    last_header_block = None\n    last_block = None\n    last_block_type = \"\"\n    last_block_index = 0\n    last_block_start = 0\n    last_block_level = 0\n    last_block_list = []\n    last_block_header_index = 0\n    last_header_block = None\n    last_header_block_index = 0\n    last_block_text = \"\"\n    last_block_text_list = []\n    last_block_text_list_index = 0\n    last_block_text_list_type = \"\"\n    last_block_text_list_level = 0\n    last_block_text_list_start = 0\n    last_block_text_list_header_index = 0\n    last_block_text_list_header_block = None\n    last_block_text_list_header_block_index = 0\n    last_block_text_list_last_header_block = None\n    last_block_text_list_last_header_block_index = 0\n    last_block_text_list_last_block = None\n    last_block_text_list_last_block_index = 0\n    last_block_text_list_last_block_type = \"\"\n    last_block_text_list_last_block_start = 0\n    last_block_text_list_last_block_level = 0\n    last_block_text_list_last_block_list = []\n    last_block_text_list_last_block_header_index = 0\n    last_block_text_list_last_block_text = \"\"\n    last_block_text_list_last_block_text_list = []\n    last_block_text_list_last_block_text_list_index = 0\n    last_block_text_list_last_block_text_list_type = \"\"\n    last_block_text_list_last_block_text_list_level = "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    for line in lines:\n        if not line:\n            continue\n        if line.startswith(\"(\") and line.endswith(\")\"):\n            line = line[1:-1]\n        line = line.strip()\n        line = line.replace(\"\ufffd\", \"\")\n        line = line.replace(\"\u2014\", \"-\")\n        line = line.replace(\"\u2019\", \"'\")\n        line = line.replace(\"\u2018\", \"'\")\n        line = line.replace(\"\u201c\", '\"')\n        line = line.replace(\"\u201d\", '\"')\n        line = line.replace(\"\u2013\", \"-\")\n        line = line.replace(\"\u27a2\", \"\")\n        line = line.replace(\"\u2022\", \"\")\n        line = line.replace(\"\u27a2\", \"\")\n        line = line.replace(\"\u2022\", \"\")\n        line = line.replace(\"\uf0b7\", \"\")\n        line = line.replace(\"\u2010\", \"-\")\n        line = line.replace(\"\u2011\", \"-\")\n        line = line.replace(\"\u2012\", \"-\")\n        line = line.replace(\"\u2013\", \"-\")\n        line = line.replace(\"\u2014\", \"-\")\n        line = line.replace(\"\u2015\", \"-\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\", \"...\")\n        line = line.replace(\"\u2026\","}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    if xml:\n        lines = [line.replace(\"\\n\", \"\") for line in lines]\n\n    # remove duplicate lines\n    lines = list(set(lines))\n\n    # fix spaced characters\n    lines = [line.replace(\" \", \"\") for line in lines]\n\n    # connect incomplete lines\n    lines = connect_incomplete_lines(lines)\n\n    # categorize lines into paragraphs, headers, or list items\n    for i, line in enumerate(lines):\n        line = line_parser.Line(line)\n        if line.is_paragraph:\n            result.append(\n                {\n                    \"index\": i,\n                    \"text\": line.text,\n                    \"type\": \"paragraph\",\n                    \"start_index\": line.start_index,\n                    \"blocks\": line.blocks,\n                    \"header_index\": line.header_index,\n                    \"level\": line.level,\n                }\n            )\n        elif line.is_header:\n            result.append(\n                {\n                    \"index\": i,\n                    \"text\": line.text,\n                    \"type\": \"header\",\n                    \"start_index\": line.start_index,\n                    \"blocks\": line.blocks,\n                    \"header_index\": line.header_index,\n                    \"level\": line.level,\n                }\n            )\n        elif line.is_list_item:\n            result.append(\n                {\n                    \"index\": i,\n                    \"text\": line.text,\n                    \"type\": \"list_item\",\n                    \"start_index\": line.start_index,\n                    \"blocks\": line.blocks,\n                    \"header_index\": line.header_index,\n                    \"level\": line.level,\n                }\n            )\n\n    return result\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    current_block = []\n    block_type = \"\"\n    header_index = None\n    list_index = None\n    list_level = 0\n    list_items = []\n    block_index = 0\n    block_start = 0\n    block_end = 0\n    last_line = \"\"\n    last_line_index = 0\n    last_line_type = \"\"\n    last_line_header_index = None\n    last_line_list_index = None\n    last_line_list_level = None\n    last_line_list_items = []\n    last_line_block_index = None\n    last_line_block_start = None\n    last_line_block_end = None\n    last_line_block_type = \"\"\n    last_line_block_text = \"\"\n    last_line_block_text_len = 0\n    last_line_block_text_len_no_punct = 0\n    last_line_block_text_len_no_punct_no_digits = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords_no_numbers = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords_no_numbers_no_chars = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords_no_numbers_no_chars_no_words = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords_no_numbers_no_chars_no_words_no_digits = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords_no_numbers_no_chars_no_words_no_digits_no_chars = 0\n    last_line_block_text_len_no_punct_no_digits_no_stopwords_no_numbers_no_chars_no_words_no_digits_no_chars_no_words = "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    lines = [line for line in lines if not should_skip(line, xml)]\n    # print(lines)\n    for i, line in enumerate(lines):\n        if line.startswith(\" \") and line[1].isalpha():\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1].isdigit():\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"-\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"(\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \")\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"/\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \":\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \".\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \",\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \";\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"*\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"#\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"\u2022\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"\u2013\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"\u2014\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"\u2010\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"\u27a2\":\n            lines[i] = line[1:]\n        if line.startswith(\" \") and line[1] == \"\u2019\":\n            lines[i] = line[1:]\n        if line"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # result = []\n    # block_index = 0\n    # block_type = None\n    # block_text = \"\"\n    # block_list = []\n    # block_header_index = None\n    # block_level = 0\n    # block_start_index = 0\n    # block_end_index = 0\n\n    # for i, line in enumerate(lines):\n    #     # print(line)\n    #     # print(block_text)\n    #     if should_skip(line, xml):\n    #         continue\n    #     # print(line)\n    #     if is_table_row(line):\n    #         block_type = \"table\"\n    #         block_text += line\n    #         continue\n    #     if line_parser.is_header(line):\n    #         block_type = \"header\"\n    #         block_text += line\n    #         continue\n    #     if line_parser.is_list_item(line):\n    #         block_type = \"list\"\n    #         block_text += line\n    #         continue\n    #     if line_parser.is_paragraph(line):\n    #         block_type = \"paragraph\"\n    #         block_text += line\n    #         continue\n    #     if block_type is None:\n    #         block_type = \"paragraph\"\n    #         block_text += line\n    #         continue\n    #     if line_parser.is_continuation(line):\n    #         block_text += line\n    #         continue\n    #     if line_parser.is_new_block(line):\n    #         block_text = line\n    #         continue\n    #     if block_type == \"header\":\n    #         block_header_index = block_index\n    #         block_index += 1\n    #         block_text = line\n    #         block_type = \"paragraph\"\n    #         continue\n    #     if block_type == \"list\":\n    #         block_list.append(block_text)\n    #         block_text = line\n    #         block_type = \"paragraph\"\n    #         continue\n    #     if block_type == \"paragraph\":\n    #         block_text += line\n    #         continue\n    #     if block_type == \"table\":\n    #         block_text += line\n    #        "}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.replace(\"\\n\", \" \")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"...\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts = texts.replace(\"..\", \".\")\n    texts ="}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.strip()\n\n    if texts.startswith(r\"(\"):\n        texts = texts[1:]\n\n    if texts.endswith(r\")\"):\n        texts = texts[:-1]\n\n    texts = texts.replace(\"\\n\", \" \")\n    texts = texts.replace(\"\\t\", \" \")\n    texts = texts.replace(\"\\r\", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.replace(\"\\n\\n\", \"\\n\")\n    texts = texts.replace(\"\\n\", \" \")\n\n    texts = texts.replace(\"\u2019\", \"'\")\n    texts = texts.replace(\"\u201c\", '\"')\n    texts = texts.replace(\"\u201d\", '\"')\n    texts = texts.replace(\"\u2018\", \"'\")\n    texts = texts.replace(\"\u2013\", \"-\")\n    texts = texts.replace(\"\u2014\", \"-\")\n    texts = texts.replace(\"\u2026\", \"...\")\n    texts = texts.replace(\"\u2026\", \"...\")\n    texts = texts.replace(\"\u2022\", \"-\")\n    texts = texts.replace(\"\u2010\", \"-\")\n    texts = texts.replace(\"\u2011\", \"-\")\n    texts = texts.replace(\"\u2012\", \"-\")\n    texts = texts.replace(\"\u2013\", \"-\")\n    texts = texts.replace(\"\u2014\", \"-\")\n    texts = texts.replace(\"\u2015\", \"-\")\n    texts = texts.replace(\"\u2016\", \"|\")\n    texts = texts.replace(\"\u2017\", \"-\")\n    texts = texts.replace(\"\u2018\", \"'\")\n    texts = texts.replace(\"\u2019\", \"'\")\n    texts = texts.replace(\"\u201a\", \",\")\n    texts = texts.replace(\"\u201b\", \"'\")\n    texts = texts.replace(\"\u201e\", '\"')\n    texts = texts.replace(\"\u201f\", '\"')\n    texts = texts.replace(\"\u2020\", \"*\")\n    texts = texts.replace(\"\u2021\", \"**\")\n    texts = texts.replace(\"\u2022\", \"-\")\n    texts = texts.replace(\"\u2023\", \"-\")\n    texts = texts.replace(\"\u2024\", \".\")\n    texts = texts.replace(\"\u2025\", \"..\")\n    texts = texts.replace(\"\u2026\", \"...\")\n    texts = texts.replace(\"\u2027\", \"-\")\n    texts = texts.replace(\"\u2028\", \" \")\n    texts = texts.replace(\"\u2029\", \" \")\n    texts = texts.replace(\"\u202a\", \" \")\n    texts = texts.replace(\"\u202b\", \" \")\n    texts = texts.replace(\"\u202c\", \" \")\n    texts = texts.replace(\"\u202d\", \" \")\n    texts = texts.replace(\"\u202e\", \" \")\n    texts = texts.replace(\"\u2032\", \"'\")\n    texts = texts.replace(\"\u2033\","}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    texts = org_texts.strip()\n\n    if len(texts) == 0:\n        return texts\n\n    texts = texts.replace(\"\\n\", \" \")\n\n    # remove space between punctuations\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # replace brackets with space\n    texts = bracket_rule.sub(r\" \\1 \", texts)\n\n    # replace quotation marks with space\n    texts = quotation_pattern.sub(r\" \", texts)\n\n    # tokenize\n    texts = nltk_tokenzier.tokenize(texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    return texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Remove any space between punctuations (.')\n    texts = re.sub(space_rule, r\"\\1\", texts)\n\n    # Tokenize sentences\n    texts = nltk_tokenzier.tokenize(texts)\n\n    # Remove any space between punctuations (.')\n    texts = [re.sub(space_rule, r\"\\1\", text) for text in texts]\n\n    # Replace abbreviations with \"_\"\n    for rule, replaced in rules:\n        texts = [re.sub(rule, replaced, text) for text in texts]\n\n    # Remove sentences within brackets\n    texts = [re.sub(bracket_rule, \"\", text) for text in texts]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.replace(\"\\n\", \" \")\n    texts = texts.replace(\"\\r\", \" \")\n\n    texts = texts.strip()\n\n    if texts.startswith(\".\"):\n        texts = texts[1:]\n\n    texts = texts.strip()\n\n    if not texts:\n        return texts\n\n    texts = texts.replace(\"(\", \" ( \")\n    texts = texts.replace(\")\", \" ) \")\n    texts = texts.replace(\"[\", \" [ \")\n    texts = texts.replace(\"]\", \" ] \")\n\n    texts = texts.replace(\"'\", \" ' \")\n    texts = texts.replace('\"', ' \" ')\n\n    texts = texts.replace(\"?\", \" ? \")\n    texts = texts.replace(\"!\", \" ! \")\n\n    texts = texts.replace(\":\", \" : \")\n    texts = texts.replace(\",\", \" , \")\n    texts = texts.replace(\";\", \" ; \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"(\", \" ( \")\n    texts = texts.replace(\")\", \" ) \")\n    texts = texts.replace(\"[\", \" [ \")\n    texts = texts.replace(\"]\", \" ] \")\n\n    texts = texts.replace(\"'\", \" ' \")\n    texts = texts.replace('\"', ' \" ')\n\n    texts = texts.replace(\"?\", \" ? \")\n    texts = texts.replace(\"!\", \" ! \")\n\n    texts = texts.replace(\":\", \" : \")\n    texts = texts.replace(\",\", \" , \")\n    texts = texts.replace(\";\", \" ; \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    texts = texts.replace(\"  \", \" \")\n   "}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove new lines\n    texts = org_texts.replace(\"\\n\", \" \")\n\n    # remove space between punctuations ('.')\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # remove quotation marks\n    texts = quotation_pattern.sub(\"\", texts)\n\n    # replace brackets with spaces\n    texts = bracket_rule.sub(r\" \\1 \", texts)\n\n    # tokenize sentences\n    texts = nltk_tokenzier.tokenize(texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    return texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    org_texts = org_texts.replace('\\n', ' ')\n\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n    org_texts = bracket_rule.sub(r\" \\1 \", org_texts)\n\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    org_texts = quotation_pattern.sub(\"'\", org_texts)\n\n    return nltk_tokenzier.tokenize(org_texts)\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.split(\"\\n\")\n\n    texts = [text.strip() for text in texts if text.strip()]\n\n    if texts:\n        texts = [text + \" \" for text in texts]\n\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    texts = [\n        [\n            space_rule.sub(r\"\\1\", sent)\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            bracket_rule.sub(r\" \\1 \", sent)\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.strip()\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" .\", \".\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" ,\", \",\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" ?\", \"?\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" !\", \"!\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" :\", \":\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" ;\", \";\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" )\", \")\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" (\", \"(\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]\n\n    texts = [\n        [\n            sent.replace(\" '\", \"'\")\n            for sent in text\n            if sent.strip()\n        ]\n        for text in texts\n    ]"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    texts = []\n    for text in org_texts:\n        # remove new line\n        text = text.replace(\"\\n\", \" \")\n\n        # remove double spaces\n        text = re.sub(r\"\\s+\", \" \", text)\n\n        # remove spaces before punctuation\n        text = space_rule.sub(r\"\\1\", text)\n\n        # replace quotation marks\n        text = quotation_pattern.sub(\"'\", text)\n\n        # remove content inside brackets\n        text = bracket_rule.sub(r\"\\1\", text)\n\n        # tokenize\n        text = nltk_tokenzier.tokenize(text)\n\n        # apply rules\n        for rule, replaced in rules:\n            text = [rule.sub(replaced, t) for t in text]\n\n        texts.append(text)\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # replace quotation marks\n    texts = quotation_pattern.sub('\"', org_texts)\n\n    # remove space between punctuations ('.')\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # tokenize text into sentences\n    sents = nltk_tokenzier.tokenize(texts)\n\n    # replace brackets\n    for idx, sent in enumerate(sents):\n        sents[idx] = bracket_rule.sub(r\" \\1 \", sent)\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = rule.sub(replaced, texts)\n\n    # tokenize text into sentences\n    sents = nltk_tokenzier.tokenize(texts)\n\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.strip()\n    if not texts:\n        return texts\n\n    # handle special case of paragraph separated by new line\n    texts = texts.replace(\"\\n\\n\", \"\\n\")\n    texts = texts.replace(\"\\n\", \" \")\n\n    # handle special case of punctuations at the beginning of the text\n    texts = texts.lstrip(\".,\")\n\n    # handle special case of quotation marks\n    texts = texts.replace(\"\u2018\", \"'\")\n    texts = texts.replace(\"\u2019\", \"'\")\n    texts = texts.replace(\"\u201c\", '\"')\n    texts = texts.replace(\"\u201d\", '\"')\n\n    # handle special case of brackets\n    texts = bracket_rule.sub(r\" \\1 \", texts)\n\n    # handle special case of space between punctuations\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # handle special case of quotation marks\n    texts = quotation_pattern.sub(r\"\", texts)\n\n    # tokenize\n    texts = nltk_tokenzier.tokenize(texts)\n\n    return texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove space before punctuation\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # remove quotation marks\n    org_texts = quotation_pattern.sub(\"\", org_texts)\n\n    # remove brackets\n    org_texts = bracket_rule.sub(r\"\\1\", org_texts)\n\n    # remove space before punctuation\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # tokenize\n    texts = nltk_tokenzier.tokenize(org_texts)\n\n    # replace abbs\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.split(\"\\n\\n\")\n\n    sentences = []\n\n    for text in texts:\n        text = text.strip()\n\n        if not text:\n            continue\n\n        text = space_rule.sub(r\"\\1\", text)\n        text = bracket_rule.sub(r\" \\1 \", text)\n\n        for rule, replaced in rules:\n            text = rule.sub(replaced, text)\n\n        text = text.replace(\" .\", \".\")\n        text = text.replace(\" ,\", \",\")\n        text = text.replace(\" ?\", \"?\")\n        text = text.replace(\" !\", \"!\")\n        text = text.replace(\" :\", \":\")\n        text = text.replace(\" ;\", \";\")\n\n        text = quotation_pattern.sub(\"'\", text)\n\n        text = nltk_tokenzier.tokenize(text)\n\n        sentences.extend(text)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.strip()\n    texts = texts.replace(\"\\n\\n\", \"\\n\")\n    texts = texts.replace(\"\\n\", \" \")\n\n    # remove space between punctuations (.')\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub(\"'\", texts)\n\n    # tokenize into sentences\n    texts = nltk_tokenzier.tokenize(texts)\n\n    # remove content inside brackets\n    texts = [bracket_rule.sub(r\"\\1\", text) for text in texts]\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    return texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.strip()\n\n    # remove any space between punctuations (.')\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # remove any space between punctuations (.')\n    texts = bracket_rule.sub(r\" \\1 \", texts)\n\n    # replace quotation marks\n    texts = quotation_pattern.sub(\"\\\"\", texts)\n\n    # tokenize\n    texts = nltk_tokenzier.tokenize(texts)\n\n    for idx, text in enumerate(texts):\n        for rule, replaced in rules:\n            text = rule.sub(replaced, text)\n\n        texts[idx] = text.strip()\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = []\n    for org_text in org_texts:\n        text = org_text.strip()\n        if not text:\n            continue\n\n        text = text.replace(\"\u2019\", \"'\")\n        text = text.replace(\"\u2018\", \"'\")\n        text = text.replace(\"\u201c\", '\"')\n        text = text.replace(\"\u201d\", '\"')\n        text = text.replace(\"\u2013\", \"-\")\n        text = text.replace(\"\u2014\", \"-\")\n        text = text.replace(\"\u2026\", \"...\")\n\n        # remove space between punctuations ('.)\n        text = space_rule.sub(r\"\\1\", text)\n\n        # replace quotation marks\n        text = quotation_pattern.sub('\"', text)\n\n        # tokenize sentences\n        sentences = nltk_tokenzier.tokenize(text)\n\n        # remove sentences within brackets\n        sentences = [\n            sentence\n            for sentence in sentences\n            if not bracket_rule.search(sentence)\n        ]\n\n        # replace abbreviations\n        for rule, replaced in rules:\n            sentences = [\n                rule.sub(replaced, sentence) for sentence in sentences\n            ]\n\n        # remove space between punctuations ('.)\n        sentences = [\n            space_rule.sub(r\"\\1\", sentence) for sentence in sentences\n        ]\n\n        texts.extend(sentences)\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove new lines\n    org_texts = org_texts.replace(\"\\n\", \" \")\n\n    # remove space between punctuation and word\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # remove quotation marks\n    org_texts = quotation_pattern.sub(\"\", org_texts)\n\n    # tokenize sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # remove sentences within brackets\n    sentences = [\n        sentence\n        for sentence in sentences\n        if not bracket_rule.search(sentence)\n    ]\n\n    # apply rules\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sentence) for sentence in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    texts = org_texts.strip()\n\n    # handle new line\n    texts = texts.replace(\"\\n\", \" \")\n\n    # handle punctuation at the beginning of the text\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # handle quotation marks\n    texts = quotation_pattern.sub(\"'\", texts)\n\n    # handle brackets\n    texts = bracket_rule.sub(r\" \\1 \", texts)\n\n    # tokenize\n    sents = nltk_tokenzier.tokenize(texts)\n\n    for i in range(len(sents)):\n        for rule, replaced in rules:\n            sents[i] = rule.sub(replaced, sents[i])\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.split(\"\\n\")\n    texts = [text.strip() for text in texts if text.strip()]\n\n    sentences = []\n\n    for text in texts:\n        # remove any space between punctuations (.')\n        text = space_rule.sub(r\"\\1\", text)\n\n        # remove quotations\n        text = quotation_pattern.sub(r\"\", text)\n\n        # remove brackets\n        text = bracket_rule.sub(r\"\\1\", text)\n\n        for rule, replaced in rules:\n            text = rule.sub(replaced, text)\n\n        sentences.extend(nltk_tokenzier.tokenize(text))\n\n    return sentences"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return self.phrase_positions(token)\n        else:\n            return self.phrase_positions(token, key=key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return [self.positions(token[0], key=key)]\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                doc_ids, term_posns = self.posns.positions(term_id, doc_ids=[key])\n                return term_posns\n            else:\n                doc_ids, term_posns = self.posns.positions(term_id)\n                return term_posns\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token, key)\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                return self.posns.positions(term_id, doc_id=key)\n            else:\n                return self.posns.positions(term_id)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                doc_id = key\n                if doc_id < 0:\n                    doc_id += len(self)\n                return self.posns.positions(term_id, doc_id=doc_id)\n            else:\n                return self.posns.positions(term_id)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token, key=key)\n\n        # Get term freqs per token\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            doc_ids, positions = self.posns.positions(term_id, key=key)\n            return positions\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n        if key is not None:\n            if not isinstance(key, numbers.Integral):\n                raise TypeError(\"Expected an integer\")\n        # Get term freqs per token\n        term_id = self.term_dict.get_term_id(token)\n        if key is None:\n            doc_ids, term_posns = self.posns.positions(term_id)\n            return term_posns\n        else:\n            if key < 0:\n                key += len(self)\n            doc_ids, term_posns = self.posns.positions(term_id, doc_ids=key)\n            return term_posns\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token, key)\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            doc_ids, term_positions = self.posns.positions(term_id, key)\n            matches = np.full(len(self), False, dtype=bool)\n            matches[doc_ids] = True\n            return matches & term_positions\n        except TermMissingError:\n            return np.full(len(self), False)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token, key=key)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                if key < 0:\n                    key += len(self)\n                return self.posns.positions(term_id, doc_id=key)\n            else:\n                return self.posns.positions(term_id)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return [self.positions(token)]\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            positions = self.posns.positions(term_id, doc_id=key)\n            return positions\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Get term freqs per token\n        token = self._check_token_arg(token)\n        term_id = self.term_dict.get_term_id(token)\n        if key is None:\n            doc_ids, term_posns = self.posns.positions(term_id)\n            return term_posns\n        else:\n            doc_id = key\n            term_posns = self.posns.positions(term_id, doc_id=doc_id)\n            return term_posns\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token, key=key)\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            positions = self.posns.positions(term_id, key=key)\n            return positions\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n        if key is not None and not isinstance(key, int):\n            raise TypeError(\"Expected an integer\")\n        if key is not None:\n            try:\n                return self[key].positions(token)\n            except IndexError:\n                raise IndexError(\"index out of bounds\")\n        else:\n            return [self[doc_id].positions(token) for doc_id in range(len(self))]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token)\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            doc_ids, term_posns = self.posns.positions(term_id, key=key)\n            return term_posns\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token), doc_id=key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token)\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                doc_ids, term_posns = self.posns.positions(term_id)\n                return term_posns\n            else:\n                doc_ids, term_posns = self.posns.positions(term_id, doc_ids=key)\n                return term_posns\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if key is not None:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id, key)\n            except TermMissingError:\n                return []\n        else:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id)\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, doc_id=key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token, key=key)\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                return self.posns.positions(term_id, doc_id=key)\n            else:\n                return self.posns.positions(term_id)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            try:\n                return self[key].positions(token)\n            except IndexError:\n                raise IndexError(\"index out of bounds\")\n        else:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                doc_ids, term_posns = self.posns.positions(term_id, doc_ids=None)\n                return term_posns\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if key is not None:\n            return self.posns.positions(token, doc_id=key)\n        else:\n            return self.posns.positions(token)\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == '0':\n        return 0\n\n    if spec == '1':\n        return 1\n\n    if spec == '2':\n        return 2\n\n    if spec == '3':\n        return 3\n\n    if spec == '4':\n        return 4\n\n    if spec == '5':\n        return 5\n\n    if spec == '6':\n        return 6\n\n    if spec == '7':\n        return 7\n\n    if spec == '8':\n        return 8\n\n    if spec == '9':\n        return 9\n\n    if spec == '10':\n        return 10\n\n    if spec == '11':\n        return 11\n\n    if spec == '12':\n        return 12\n\n    if spec == '13':\n        return 13\n\n    if spec == '14':\n        return 14\n\n    if spec == '15':\n        return 15\n\n    if spec == '16':\n        return 16\n\n    if spec == '17':\n        return 17\n\n    if spec == '18':\n        return 18\n\n    if spec == '19':\n        return 19\n\n    if spec == '20':\n        return 20\n\n    if spec == '21':\n        return 21\n\n    if spec == '22':\n        return 22\n\n    if spec == '23':\n        return 23\n\n    if spec == '24':\n        return 24\n\n    if spec == '25':\n        return 25\n\n    if spec == '26':\n        return 26\n\n    if spec == '27':\n        return 27\n\n    if spec == '28':\n        return 28\n\n    if spec == '29':\n        return 29\n\n    if spec == '30':\n        return 30\n\n    if spec == '31':\n        return 31\n\n    if spec == '32':\n        return 32\n\n    if spec == '33':\n        return 33\n\n    if spec == '34':\n        return 34\n\n    if spec == '35':\n        return 35\n\n    if spec == '36':\n        return 36\n\n    if spec == '37':\n        return 37\n\n    if spec == '38':\n        return 38\n\n    if spec == '39':\n        return 39"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"\":\n        return 0\n    if spec == \"1\":\n        return 1\n    if spec == \"2\":\n        return 2\n    if spec == \"3\":\n        return 3\n    if spec == \"4\":\n        return 4\n    if spec == \"5\":\n        return 5\n    if spec == \"6\":\n        return 6\n    if spec == \"7\":\n        return 7\n    if spec == \"8\":\n        return 8\n    if spec == \"9\":\n        return 9\n    if spec == \"10\":\n        return 10\n    if spec == \"11\":\n        return 11\n    if spec == \"12\":\n        return 12\n    if spec == \"13\":\n        return 13\n    if spec == \"14\":\n        return 14\n    if spec == \"15\":\n        return 15\n    if spec == \"16\":\n        return 16\n    if spec == \"17\":\n        return 17\n    if spec == \"18\":\n        return 18\n    if spec == \"19\":\n        return 19\n    if spec == \"20\":\n        return 20\n    if spec == \"21\":\n        return 21\n    if spec == \"22\":\n        return 22\n    if spec == \"23\":\n        return 23\n    if spec == \"24\":\n        return 24\n    if spec == \"25\":\n        return 25\n    if spec == \"26\":\n        return 26\n    if spec == \"27\":\n        return 27\n    if spec == \"28\":\n        return 28\n    if spec == \"29\":\n        return 29\n    if spec == \"30\":\n        return 30\n    if spec == \"31\":\n        return 31\n    if spec == \"32\":\n        return 32\n    if spec == \"33\":\n        return 33\n    if spec == \"34\":\n        return 34\n    if spec == \"35\":\n        return 35\n    if spec == \"36\":\n        return 36\n    if spec == \"37\":\n        return 37\n    if spec == \"38\":\n        return 38\n    if spec == \"39\":\n        return 39\n    if"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == 'all':\n        return num_clauses\n    if spec == 'none':\n        return 0\n    if spec == '1':\n        return 1\n    if spec == '2':\n        return 2\n    if spec == '3':\n        return 3\n    if spec == '4':\n        return 4\n    if spec == '5':\n        return 5\n    if spec == '6':\n        return 6\n    if spec == '7':\n        return 7\n    if spec == '8':\n        return 8\n    if spec == '9':\n        return 9\n    if spec == '10':\n        return 10\n    if spec == '11':\n        return 11\n    if spec == '12':\n        return 12\n    if spec == '13':\n        return 13\n    if spec == '14':\n        return 14\n    if spec == '15':\n        return 15\n    if spec == '16':\n        return 16\n    if spec == '17':\n        return 17\n    if spec == '18':\n        return 18\n    if spec == '19':\n        return 19\n    if spec == '20':\n        return 20\n    if spec == '21':\n        return 21\n    if spec == '22':\n        return 22\n    if spec == '23':\n        return 23\n    if spec == '24':\n        return 24\n    if spec == '25':\n        return 25\n    if spec == '26':\n        return 26\n    if spec == '27':\n        return 27\n    if spec == '28':\n        return 28\n    if spec == '29':\n        return 29\n    if spec == '30':\n        return 30\n    if spec == '31':\n        return 31\n    if spec == '32':\n        return 32\n    if spec == '33':\n        return 33\n    if spec == '34':\n        return 34\n    if spec == '35':\n        return 35\n    if spec == '36':\n        return 36\n    if spec == '37':\n        return 37\n    if spec == '38':\n        return 38\n   "}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == '0':\n        return 0\n    if spec == '1':\n        return 1\n    if spec == 'all':\n        return num_clauses\n    if spec == 'not':\n        return num_clauses - 1\n    if spec == 'not_all':\n        return 1\n    if spec == 'not_none':\n        return 0\n    if spec == 'none':\n        return 0\n    if spec == 'at_least_one':\n        return 1\n    if spec == 'at_most_one':\n        return 1\n    if spec == 'at_most_two':\n        return 2\n    if spec == 'at_most_three':\n        return 3\n    if spec == 'at_most_four':\n        return 4\n    if spec == 'at_most_five':\n        return 5\n    if spec == 'at_most_six':\n        return 6\n    if spec == 'at_most_seven':\n        return 7\n    if spec == 'at_most_eight':\n        return 8\n    if spec == 'at_most_nine':\n        return 9\n    if spec == 'at_most_ten':\n        return 10\n    if spec == 'at_most_eleven':\n        return 11\n    if spec == 'at_most_twelve':\n        return 12\n    if spec == 'at_most_thirteen':\n        return 13\n    if spec == 'at_most_fourteen':\n        return 14\n    if spec == 'at_most_fifteen':\n        return 15\n    if spec == 'at_most_sixteen':\n        return 16\n    if spec == 'at_most_seventeen':\n        return 17\n    if spec == 'at_most_eighteen':\n        return 18\n    if spec == 'at_most_nineteen':\n        return 19\n    if spec == 'at_most_twenty':\n        return 20\n    if spec == 'at_most_twentyone':\n        return 21\n    if spec == 'at_most_twentytwo':\n        return 22\n    if spec == 'at_most_twentythree':\n        return 23\n    if spec == 'at_most_twentyfour':\n        return 24"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        return int(num_clauses * float(spec[:-1]) / 100)\n    elif spec.startswith('<'):\n        return num_clauses - int(spec[1:])\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    def parse_absolute(num_clauses: int, spec: str) -> int:\n        \"\"\"\n        This function parses the \"min should match\" specification (commonly referred to as 'mm' spec) from Solr's search engine configuration and calculates the minimum number of clauses that must match based on the given specification and the total number of clauses. It supports both absolute and percentage-based specifications, as well as conditional specifications using '<'.\n\n        Input-Output Arguments\n        :param num_clauses: int, the total number of clauses in the query.\n        :param spec: str, the 'min should match' specification as a string, which can include absolute numbers, percentages, and conditional expressions.\n        :return: int, the calculated minimum number of clauses that must match according to the 'mm' spec.\n        \"\"\"\n        if spec.endswith(\"%\"):\n            spec = spec[:-1]\n            return int(spec) * num_clauses / 100\n        else:\n            return int(spec)\n\n    def parse_conditional(num_clauses: int, spec: str) -> int:\n        \"\"\"\n        This function parses the \"min should match\" specification (commonly referred to as 'mm' spec) from Solr's search engine configuration and calculates the minimum number of clauses that must match based on the given specification and the total number of clauses. It supports both absolute and percentage-based specifications, as well as conditional specifications using '<'.\n\n        Input-Output Arguments\n        :param num_clauses: int, the total number of clauses in the query.\n        :param spec: str, the 'min should match' specification as a string, which can include absolute numbers, percentages, and conditional expressions.\n        :return: int, the calculated minimum number of clauses that must match according to the 'mm' spec.\n        \"\"\"\n        if spec.startswith(\"<\"):\n            spec = spec[1:]\n            return max(int(spec), num_clauses - parse_absolute(num_clauses, spec))\n        else:\n            return parse_absolute(num_clauses, spec)\n\n    if \"/\" in spec:\n        spec = spec.split(\"/\")[0]\n    if \" \" in spec:\n        spec = spec.split(\" \")[0]\n    if \"<\" in spec:\n        return parse_conditional(num_clauses, spec)\n    else:\n        return parse_absolute(num_clauses, spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.startswith(\"<\"):\n        spec = spec[1:]\n        spec = spec.replace(\"%\", \"\")\n        spec = float(spec) / 100\n        return int(num_clauses * spec)\n\n    if spec.endswith(\"%\"):\n        spec = spec[:-1]\n        spec = float(spec) / 100\n        return int(num_clauses * spec)\n\n    spec = int(spec)\n    return spec\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"\":\n        return 0\n    elif spec == \"ALL\":\n        return num_clauses\n    elif spec == \"NONE\":\n        return 0\n    elif spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    elif spec.startswith(\"<\"):\n        return int(float(spec[1:]) / 100 * num_clauses)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec is None:\n        return num_clauses\n\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    if \"<\" in spec:\n        low, high = spec.split(\"<\")\n        return int(low) if num_clauses < int(high) else int(high)\n\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        spec = spec[:-1]\n        return int(spec) * num_clauses / 100\n    elif spec.endswith(\"<\"):\n        spec = spec[:-1]\n        return int(spec)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    if \"<\" in spec:\n        return int(spec.split(\"<\")[0])\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n\n    if spec.endswith(\"%\"):\n        percent = int(spec[:-1])\n        return max(1, int(num_clauses * percent / 100))\n\n    if spec.startswith(\"<\"):\n        spec = spec[1:]\n        if spec.endswith(\"%\"):\n            percent = int(spec[:-1])\n            return max(1, int(num_clauses * percent / 100))\n        else:\n            return max(1, int(spec))\n\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"all\":\n        return num_clauses\n\n    if spec == \"none\":\n        return 0\n\n    if spec == \"1\":\n        return 1\n\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    if spec.startswith(\"<\"):\n        return int(float(spec[1:]) / 100 * num_clauses)\n\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Parse the spec\n    if spec.endswith(\"%\"):\n        spec = spec.rstrip(\"%\")\n        if spec.startswith(\"<\"):\n            spec = spec.lstrip(\"<\")\n            spec = int(spec)\n            return int(num_clauses * spec / 100)\n        else:\n            spec = int(spec)\n            return int(num_clauses * spec / 100)\n    else:\n        if spec.startswith(\"<\"):\n            spec = spec.lstrip(\"<\")\n            spec = int(spec)\n            return spec\n        else:\n            spec = int(spec)\n            return spec\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.startswith(\"<\"):\n        spec = spec[1:]\n        return max(1, int(num_clauses * float(spec) / 100))\n    elif spec.endswith(\"%\"):\n        return max(1, int(num_clauses * float(spec[:-1]) / 100))\n    else:\n        return max(1, int(spec))\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        percentage = float(spec[:-1])\n        return int(num_clauses * percentage / 100)\n    elif spec.startswith(\"<\"):\n        threshold = int(spec[1:])\n        return max(1, num_clauses - threshold)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"\":\n        return num_clauses\n\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    if \"<\" in spec:\n        num_clauses_lt, num_clauses_gte = spec.split(\"<\")\n        num_clauses_lt = int(num_clauses_lt)\n        num_clauses_gte = int(num_clauses_gte)\n        return min(num_clauses_lt, num_clauses_gte)\n\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.startswith(\"<\"):\n        spec = spec[1:]\n        if spec.endswith(\"%\"):\n            spec = spec[:-1]\n            spec = int(spec)\n            return int(num_clauses * spec / 100)\n        else:\n            spec = int(spec)\n            return spec\n    elif spec.endswith(\"%\"):\n        spec = spec[:-1]\n        spec = int(spec)\n        return int(num_clauses * spec / 100)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Parse the specification and get the minimum number of clauses that must match\n    if spec.endswith(\"%\"):\n        min_should_match = int(float(spec[:-1]) / 100 * num_clauses)\n    elif spec.startswith(\"<\"):\n        min_should_match = int(spec[1:])\n    else:\n        min_should_match = int(spec)\n\n    return min_should_match\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, convert it to an int and return it\n    if spec.isdigit():\n        return int(spec)\n\n    # If the spec is a percentage, convert it to an int and return it\n    if spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100.0 * num_clauses)\n\n    # If the spec is a conditional expression, split it into parts and evaluate it\n    if \"<\" in spec:\n        parts = spec.split(\"<\")\n        if len(parts) != 2:\n            raise ValueError(\"Invalid 'min should match' specification: %s\" % spec)\n        return int(float(parts[0]) / 100.0 * num_clauses) if parts[1] == \"pc\" else int(parts[0])\n\n    # If the spec is not a number, percentage, or conditional expression, raise an error\n    raise ValueError(\"Invalid 'min should match' specification: %s\" % spec)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_direct(tokens)\n        else:\n            return self.phrase_freq_scan(tokens, slop=slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            # Get term freqs per token\n            term_freqs = np.asarray([self.termfreqs(token) for token in tokens])\n            # Get positions per token\n            positions = [self.positions(token) for token in tokens]\n            # Get phrase freqs\n            phrase_freqs = compute_phrase_freqs(term_freqs, positions)\n            return phrase_freqs\n        else:\n            # Get term freqs per token\n            term_freqs = np.asarray([self.termfreqs(token) for token in tokens])\n            # Get positions per token\n            positions = [self.positions(token) for token in tokens]\n            # Get phrase freqs\n            phrase_freqs = compute_phrase_freqs_with_slop(term_freqs, positions, slop)\n            return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        tokens = self._check_token_arg(tokens)\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_slop_1(tokens)\n        else:\n            return self._phrase_freq_slop_n(tokens, slop=slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            # Get term ids\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            # Get term freqs\n            tfs = self.termfreqs(term_ids)\n            # Get positions of terms\n            posns = [self.positions(term_id) for term_id in term_ids]\n            # Get phrase freqs\n            phrase_freqs = compute_phrase_freqs(tfs, posns)\n            return phrase_freqs\n        else:\n            # Get term ids\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            # Get term freqs\n            tfs = self.termfreqs(term_ids)\n            # Get positions of terms\n            posns = [self.positions(term_id) for term_id in term_ids]\n            # Get phrase freqs\n            phrase_freqs = compute_phrase_freqs(tfs, posns, slop)\n            return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if all tokens are unique\n        if len(tokens) == len(set(tokens)):\n            # Check if slop is 1\n            if slop == 1:\n                # Check if all tokens are unique\n                if len(tokens) == len(set(tokens)):\n                    # Check if all tokens are in the term_dict\n                    if all(token in self.term_dict for token in tokens):\n                        # Check if all tokens are in the term_mat\n                        if all(token in self.term_mat.cols for token in tokens):\n                            # Check if all tokens are in the posns_lookup\n                            if all(token in self.posns.posns_lookup for token in tokens):\n                                # Check if all tokens are in the posns_lookup\n                                if all(token in self.posns.posns_lookup for token in tokens):\n                                    # Check if all tokens are in the posns_lookup\n                                    if all(token in self.posns.posns_lookup for token in tokens):\n                                        # Check if all tokens are in the posns_lookup\n                                        if all(token in self.posns.posns_lookup for token in tokens):\n                                            # Check if all tokens are in the posns_lookup\n                                            if all(token in self.posns.posns_lookup for token in tokens):\n                                                # Check if all tokens are in the posns_lookup\n                                                if all(token in self.posns.posns_lookup for token in tokens):\n                                                    # Check if all tokens are in the posns_lookup\n                                                    if all(token in self.posns.posns_lookup for token in tokens):\n                                                        # Check if all tokens are in the posns_lookup\n                                                        if all(token in self.posns.posns_lookup for token in tokens):\n                                                            # Check if all tokens are in the posns_lookup\n                                                            if all(token in self.posns.posns_lookup for token in tokens):\n                                                                # Check if all tokens are in the posns_lookup\n                                                                if all(token in self.posns.posns_lookup for token in tokens):\n                                                                    # Check if all tokens are in the posns_lookup\n                                                                    if all(token in self.posns.posns_lookup for token in tokens):\n                                                                        # Check if all tokens are in the posns_lookup\n                                                                        if all(token in self"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(self.term_dict) == len(set([self.term_dict.get_term_id(token) for token in tokens])):\n            # We can directly calculate the phrase frequencies using the positions of terms\n            return self.phrase_freq_direct(tokens)\n        else:\n            # We have to delegate the calculation to another method that handles different slops or non-unique tokens\n            return self.phrase_freq_delegate(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return self._phrase_freq_slop_1_unique_tokens(tokens)\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # This is slow, but we can directly calculate the phrase frequencies\n            # by looking at the positions of terms\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            # We can just use the term_mat and positions\n            #"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1:\n            return self._phrase_freq_slop_1(tokens)\n        else:\n            return self._phrase_freq_slop_n(tokens, slop=slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # All tokens are unique, so we can directly calculate the phrase frequencies\n            # using the positions of terms\n            return self._phrase_freq_unique_tokens(tokens)\n        else:\n            # We have different slops, or non-unique tokens\n            # So we delegate the calculation to another method that handles different slops or non-unique tokens\n            return self._phrase_freq_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, it attempts to directly calculate the phrase frequencies using the positions of terms.\n        if slop == 1 and len(tokens) == len(set(tokens)):\n            # If the slop is not 1 or tokens are not unique, it delegates the calculation to another method that handles different slops or non-unique tokens.\n            return self._phrase_freq_slop_1_unique_tokens(tokens)\n        else:\n            return self._phrase_freq_slop_not_1_or_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1:\n            if self.posns.unique_tokens:\n                return self.posns.phrase_freq(tokens)\n            else:\n                return self._phrase_freq_slop_1_non_unique_tokens(tokens)\n        else:\n            return self._phrase_freq_slop_n_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Get term freqs per token\n        tfs = np.asarray([self.termfreqs(token) for token in tokens])\n\n        # Get positions per token\n        posns = np.asarray([self.positions(token) for token in tokens])\n\n        # Get phrase freqs\n        phrase_freqs = compute_phrase_freq(tfs, posns, slop)\n\n        return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # This is slow\n            return self.phrase_freq_direct(tokens)\n        else:\n            # This is slow\n            return self.phrase_freq_scan(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1:\n            # Check if tokens are unique\n            if len(set(tokens)) == len(tokens):\n                # Calculate phrase frequencies directly\n                return self._phrase_freq_direct(tokens)\n        # Delegate the calculation to another method that handles different slops or non-unique tokens\n        return self._phrase_freq_indirect(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(np.unique(tokens)) == len(tokens):\n            return self._phrase_freq_direct(tokens)\n        else:\n            return self._phrase_freq_indirect(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(self) > 0 and all(len(x) == 1 for x in tokens):\n            # The phrase is unique\n            tokens = [x[0] for x in tokens]\n            return self.phrase_freq(tokens)\n        else:\n            # The phrase is not unique\n            tokens = [x[0] for x in tokens]\n            return self.phrase_freq_slow(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n        # using the positions of terms\n        if slop == 1 and self.term_dict.unique(tokens):\n            return self.phrase_freq_slop_1_unique(tokens)\n\n        # Otherwise we delegate the calculation to another method that handles different slops or non-unique tokens\n        return self.phrase_freq_slop_n_unique(tokens, slop=slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if all tokens are unique\n        unique_tokens = np.unique(tokens)\n\n        # Check if slop is 1\n        if slop == 1 and len(tokens) == len(unique_tokens):\n            # Calculate phrase frequencies directly using positions\n            # Get term ids\n            term_ids = np.asarray([self.term_dict.get_term_id(token) for token in tokens])\n            # Get term frequencies\n            term_freqs = self.termfreqs(term_ids)\n            # Get positions\n            positions = self.positions(term_ids)\n            # Calculate phrase frequencies\n            phrase_freqs = compute_phrase_freqs(term_freqs=term_freqs, positions=positions)\n            return phrase_freqs\n\n        # Delegate the calculation to another method that handles different slops or non-unique tokens\n        else:\n            # Calculate phrase frequencies using the scan function\n            phrase_freqs = compute_phrase_freqs_using_scan(tokens=tokens, slop=slop, postings_arr=self)\n            return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            # We can directly compute phrase freqs\n            # We have to sort the tokens, as we use the sorted positions\n            # to compute the phrase freqs\n            tokens = sorted(tokens)\n            # Get the positions of each term\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            # Get the positions of each term\n            positions = [self.positions(term_id) for term_id in term_ids]\n            # Compute the phrase freqs\n            phrase_freqs = compute_phrase_freqs(positions)\n            return phrase_freqs\n        else:\n            # We have to iterate through the array\n            # and compute the phrase freqs\n            phrase_freqs = np.asarray([compute_phrase_freq(tokens, slop, doc_id) for doc_id in range(len(self))])\n            return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check for missing values\n        if any(pd.isna(array)):\n            raise ValueError(\"Cannot index missing values\")\n\n        # Check for empty strings\n        if any(len(s) == 0 for s in array):\n            raise ValueError(\"Cannot index empty strings\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in array):\n            raise ValueError(\"Cannot index non-string values\")\n\n        # Check for non-string values\n        if any(not isinstance(s, str) for s in"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:truncate]\n\n        # If we're given a SearchArray, just return it\n        if isinstance(array, SearchArray):\n            return array\n\n        # If we're given a pandas series, just return it\n        if isinstance(array, pd.Series):\n            return array\n\n        # If we're given a numpy array, just return it\n        if isinstance(array, np.ndarray):\n            return array\n\n        # If we're given a list of terms, just return it\n        if isinstance(array, list) and all([isinstance(x, Terms) for x in array]):\n            return cls(array)\n\n        # If we're given a list of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, str) for x in array]):\n            array = [tokenizer(x) for x in array]\n\n        # If we're given a list of lists of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, list) for x in array]):\n            array = [tokenizer(x) for x in array]\n\n        # If we're given a list of lists of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, list) for x in array]):\n            array = [tokenizer(x) for x in array]\n\n        # If we're given a list of lists of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, list) for x in array]):\n            array = [tokenizer(x) for x in array]\n\n        # If we're given a list of lists of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, list) for x in array]):\n            array = [tokenizer(x) for x in array]\n\n        # If we're given a list of lists of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, list) for x in array]):\n            array = [tokenizer(x) for x in array]\n\n        # If we're given a list of lists of strings, tokenize them\n        if isinstance(array, list) and all([isinstance(x, list) for x in array]):\n            array = [tokenizer("}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:truncate]\n\n        if len(array) == 0:\n            return SearchArray([])\n\n        # If we have a single string, make it a list\n        if isinstance(array, str):\n            array = [array]\n\n        # If we have a list of strings, make it a list of lists\n        if isinstance(array[0], str):\n            array = [[string] for string in array]\n\n        # If we have a list of lists, make it a list of lists of lists\n        if isinstance(array[0], list) and isinstance(array[0][0], str):\n            array = [[[string] for string in doc] for doc in array]\n\n        # If we have a list of lists of lists, make it a list of lists of lists of lists\n        if isinstance(array[0], list) and isinstance(array[0][0], list) and isinstance(array[0][0][0], str):\n            array = [[[[string] for string in phrase] for phrase in doc] for doc in array]\n\n        # If we have a list of lists of lists of lists, make it a list of lists of lists of lists of lists\n        if isinstance(array[0], list) and isinstance(array[0][0], list) and isinstance(array[0][0][0], list) and isinstance(array[0][0][0][0], str):\n            array = [[[[[string] for string in phrase] for phrase in doc] for doc in array] for array in array]\n\n        # If we have a list of lists of lists of lists of lists, make it a list of lists of lists of lists of lists of lists\n        if isinstance(array[0], list) and isinstance(array[0][0], list) and isinstance(array[0][0][0], list) and isinstance(array[0][0][0][0], list) and isinstance(array[0][0][0][0][0], str):\n            array = [[[[[[string] for string in phrase] for phrase in doc] for doc in array] for array in array] for array in array]\n\n        # If we have a list of lists of lists of lists of lists"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # If we're given a SearchArray, just return it\n        if isinstance(array, SearchArray):\n            return array\n\n        # If we're given a Series, just return it\n        if isinstance(array, pd.Series):\n            return cls(array.values, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a DataFrame, just return it\n        if isinstance(array, pd.DataFrame):\n            return cls(array.values, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a numpy array, just return it\n        if isinstance(array, np.ndarray):\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a list of strings, tokenize them\n        if isinstance(array, list):\n            if isinstance(array[0], str):\n                array = [tokenizer(s) for s in array]\n\n        # If we're given a list of lists, tokenize them\n        if isinstance(array[0], list):\n            array = [tokenizer(s) for s in array]\n\n        # If we're given a list of Terms, return a SearchArray\n        if isinstance(array[0], Terms):\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a list of dicts, return a SearchArray\n        if isinstance(array[0], dict):\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a list of lists, return a SearchArray\n        if isinstance(array[0], list):\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a list of lists, return a SearchArray\n        if isinstance(array[0], np.ndarray):\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a list of lists, return a SearchArray\n        if isinstance(array[0], pd.Series):\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If we're given a list of lists, return a Search"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if isinstance(array, SearchArray):\n            return array\n\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        if truncate:\n            array = array[:truncate]\n\n        # If the input is a list of strings, convert it to a list of Terms\n        if isinstance(array[0], str):\n            array = [Terms(dict(Counter(tokenizer(s)))) for s in array]\n\n        # If the input is a list of Terms, convert it to a list of Terms\n        if isinstance(array[0], Terms):\n            array = array\n\n        # If the input is a list of dicts, convert it to a list of Terms\n        if isinstance(array[0], dict):\n            array = [Terms(d) for d in array]\n\n        # If the input is a list of lists, convert it to a list of Terms\n        if isinstance(array[0], list):\n            array = [Terms(dict(Counter(s))) for s in array]\n\n        if not isinstance(array[0], Terms):\n            raise TypeError(\"Expected list-like object of Terms, got {}\".format(type(array[0])))\n\n        # If the input is a list of Terms, convert it to a list of Terms\n        if isinstance(array[0], Terms):\n            array = array\n\n        # If the input is a list of dicts, convert it to a list of Terms\n        if isinstance(array[0], dict):\n            array = [Terms(d) for d in array]\n\n        # If the input is a list of lists, convert it to a list of Terms\n        if isinstance(array[0], list):\n            array = [Terms(dict(Counter(s))) for s in array]\n\n        if not isinstance(array[0], Terms):\n            raise TypeError(\"Expected list-like object of Terms, got {}\".format(type(array[0])))\n\n        # If the input is a list of Terms, convert it to a list of Terms\n        if isinstance(array[0], Terms):\n            array = array\n\n        # If the input is a list of dicts, convert it to a list of Terms\n        if isinstance(array[0], dict):\n            array = [Terms(d) for d in array]\n\n        # If the input is a"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # If we're passed a SearchArray, just return it\n        if isinstance(array, SearchArray):\n            return array\n\n        # If we're passed a Series, just return its values\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # If we're passed a Series, just return its values\n        if isinstance(array, pd.DataFrame):\n            array = array.values\n\n        # If we're passed a DataFrame, just return its values\n        if isinstance(array, pd.Index):\n            array = array.values\n\n        if truncate:\n            array = array[:truncate]\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, np.ndarray):\n            if array.dtype == object:\n                array = array.tolist()\n            else:\n                raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, pd.DataFrame):\n            array = array.values\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, pd.Index):\n            array = array.values\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, np.ndarray):\n            if array.dtype == object:\n                array = array.tolist()\n            else:\n                raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, pd.DataFrame):\n            array = array.values\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, pd.Index):\n            array = array.values\n\n        # If we're passed a numpy array, just return it\n        if isinstance(array, np.ndarray):\n            if array.dtype == object:\n                array = array.tolist()\n            else:\n                raise TypeError(\"Expected list-like"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            # TODO: Implement truncation\n            raise NotImplementedError(\"truncate=True not yet implemented.\")\n\n        # TODO: Implement batch processing\n        if batch_size != 100000:\n            raise NotImplementedError(\"batch_size != 100000 not yet implemented.\")\n\n        return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # If we're given a SearchArray, return it\n        if isinstance(array, SearchArray):\n            return array\n\n        # If we're given a pandas series, convert to a list\n        if isinstance(array, pd.Series):\n            array = array.tolist()\n\n        if isinstance(array, pd.DataFrame):\n            raise ValueError(\"Expected an array-like object, got a DataFrame\")\n\n        # If we're given a numpy array, convert to a list\n        if isinstance(array, np.ndarray):\n            array = array.tolist()\n\n        # If we're given a list of lists, flatten\n        if isinstance(array[0], list):\n            array = [item for sublist in array for item in sublist]\n\n        # If we're given a list of dicts, convert to a list of strings\n        if isinstance(array[0], dict):\n            array = [json.dumps(item) for item in array]\n\n        # If we're given a list of strings, tokenize\n        if isinstance(array[0], str):\n            array = [tokenizer(item) for item in array]\n\n        # If we're given a list of lists of strings, flatten\n        if isinstance(array[0], list) and isinstance(array[0][0], str):\n            array = [item for sublist in array for item in sublist]\n\n        # If we're given a list of lists of ints, flatten\n        if isinstance(array[0], list) and isinstance(array[0][0], numbers.Integral):\n            array = [item for sublist in array for item in sublist]\n\n        # If we're given a list of ints, convert to strings\n        if isinstance(array[0], numbers.Integral):\n            array = [str(item) for item in array]\n\n        # If we're given a list of floats, convert to strings\n        if isinstance(array[0], numbers.Real):\n            array = [str(item) for item in array]\n\n        # If we're given a list of booleans, convert to strings\n        if isinstance(array[0], bool):\n            array = [str(item) for item in array]\n\n        # If we're given a list of lists of floats, flatten\n        if isinstance(array[0], list)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:100000]\n\n        if batch_size > 0:\n            # Process in batches\n            batch_term_mats = []\n            batch_posns = []\n            batch_doc_lens = []\n            batch_term_dicts = []\n            batch_avg_doc_lens = []\n            for i in range(0, len(array), batch_size):\n                batch = array[i:i + batch_size]\n                term_mat, posns, term_dict, avg_doc_length, doc_lens = \\\n                    build_index_from_terms_list(batch, Terms, tokenizer=tokenizer)\n                batch_term_mats.append(term_mat)\n                batch_posns.append(posns)\n                batch_term_dicts.append(term_dict)\n                batch_avg_doc_lens.append(avg_doc_length)\n                batch_doc_lens.append(doc_lens)\n\n            term_mat = np.vstack(batch_term_mats)\n            posns = PosnBitArray.from_batches(batch_posns)\n            term_dict = TermDict.from_batches(batch_term_dicts)\n            avg_doc_length = np.mean(batch_avg_doc_lens)\n            doc_lens = np.concatenate(batch_doc_lens)\n        else:\n            term_mat, posns, term_dict, avg_doc_length, doc_lens = \\\n                build_index_from_terms_list(array, Terms, tokenizer=tokenizer)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, SearchArray):\n            return array\n\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        if isinstance(array, pd.DataFrame):\n            array = array.values\n\n        if isinstance(array, np.ndarray):\n            array = array.tolist()\n\n        if isinstance(array, pd.Index):\n            array = array.values\n\n        if isinstance(array, list):\n            if len(array) == 0:\n                return cls.empty()\n            if isinstance(array[0], Terms):\n                return cls.from_terms_list(array)\n\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:1000000]\n\n        if len(array) == 0:\n            return cls.empty()\n\n        if isinstance(array[0], str):\n            return cls.from_strings(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        if isinstance(array[0], Terms):\n            return cls.from_terms_list(array, avoid_copies=avoid_copies)\n\n        raise ValueError(\"Expected a list of strings or Terms, got {}\".format(type(array[0])))\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:100000]\n\n        postings = []\n        doc_lens = []\n        for doc_id, doc in enumerate(array):\n            if doc_id % batch_size == 0:\n                logger.info(f\"Indexing batch {doc_id}\")\n            terms = tokenizer(doc)\n            doc_lens.append(len(terms))\n            postings.append(Counter(terms))\n\n        return cls(postings, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable tokenizer, got {}\".format(type(tokenizer)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool for truncate, got {}\".format(type(truncate)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int for batch_size, got {}\".format(type(batch_size)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        # If array is empty, return an empty SearchArray\n        if len(array) == 0:\n            return cls(np.empty(0, dtype=object), tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # If array is not empty, index it\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = \\\n            build_index_from_tokenizer(array, tokenizer, truncate=truncate, batch_size=batch_size,\n                                       avoid_copies=avoid_copies)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:truncate]\n\n        # If we have a list of strings, convert to a list of lists\n        if isinstance(array[0], str):\n            array = [tokenizer(s) for s in array]\n\n        # If we have a list of lists, convert to a list of Terms\n        if isinstance(array[0], list):\n            array = [Terms({t: 1 for t in terms}) for terms in array]\n\n        # If we have a list of Terms, convert to a list of Terms\n        if isinstance(array[0], Terms):\n            array = array\n\n        if len(array) < batch_size:\n            return cls(array, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        else:\n            batches = np.array_split(array, len(array) // batch_size)\n            search_arrays = [cls(batch, tokenizer=tokenizer, avoid_copies=avoid_copies) for batch in batches]\n            return search_arrays[0].append(search_arrays[1:])\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:truncate]\n\n        if batch_size is None:\n            postings, doc_lens = build_index_from_tokenizer(array, tokenizer, Terms)\n            term_mat, posns, term_dict, avg_doc_length = build_index_from_terms_list(postings, Terms)\n            return cls(term_mat, term_dict=term_dict, posns=posns, avg_doc_length=avg_doc_length, doc_lens=doc_lens)\n        else:\n            # Split into batches and index\n            batches = [array[i:i + batch_size] for i in range(0, len(array), batch_size)]\n            term_mats = []\n            posns = []\n            term_dicts = []\n            avg_doc_lengths = []\n            doc_lens = []\n            for batch in batches:\n                postings, doc_lens = build_index_from_tokenizer(batch, tokenizer, Terms)\n                term_mat, posns, term_dict, avg_doc_length = build_index_from_terms_list(postings, Terms)\n                term_mats.append(term_mat)\n                posns.append(posns)\n                term_dicts.append(term_dict)\n                avg_doc_lengths.append(avg_doc_length)\n                doc_lens.append(doc_lens)\n\n            # Combine batches\n            term_mat = np.concatenate(term_mats)\n            posns = np.concatenate(posns)\n            term_dict = term_dicts[0]\n            avg_doc_length = np.mean(avg_doc_lengths)\n            doc_lens = np.concatenate(doc_lens)\n\n            return cls(term_mat, term_dict=term_dict, posns=posns, avg_doc_length=avg_doc_length, doc_lens=doc_lens)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, term_dict, avg_doc_length, doc_lens = \\\n            build_index_from_tokenizer(array, tokenizer,\n                                       truncate=truncate, batch_size=batch_size,\n                                       avoid_copies=avoid_copies)\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable tokenizer, got {}\".format(type(tokenizer)))\n\n        # If we're indexing a list of terms, we can skip building the term_dict\n        if isinstance(array[0], Terms):\n            terms = array\n            term_dict = None\n            term_mat = None\n            posns = None\n            doc_lens = None\n            avg_doc_length = None\n        else:\n            # If we're indexing a list of strings, we need to build the term_dict\n            terms, term_dict, term_mat, posns, doc_lens, avg_doc_length = \\\n                build_index_from_tokenizer(array, tokenizer, truncate=truncate, batch_size=batch_size, avoid_copies=avoid_copies)\n        return cls(terms, term_mat, term_dict, posns, doc_lens, avg_doc_length)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Handle large arrays by processing them in batches\n        if batch_size is not None:\n            # Create an empty list to store the batch results\n            batch_results = []\n            # Iterate over the array in batches\n            for batch_idx in range(0, len(array), batch_size):\n                # Slice the array into batches\n                batch = array[batch_idx:batch_idx + batch_size]\n                # Index the batch using the specified tokenizer\n                batch_result = cls.index(batch, tokenizer=tokenizer, truncate=truncate,\n                                         batch_size=None, avoid_copies=avoid_copies)\n                # Append the batch result to the list\n                batch_results.append(batch_result)\n            # Concatenate the batch results into a single array\n            result = np.concatenate(batch_results)\n            # Return the concatenated array as a SearchArray instance\n            return cls(result, tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # Check if we need to truncate the data to fit within memory constraints\n        if truncate:\n            # Calculate the memory usage of the data\n            mem_usage = array.nbytes\n            # Calculate the memory usage of a single item in the data\n            item_size = mem_usage / len(array)\n            # Calculate the maximum number of items that can fit within the memory constraints\n            max_items = int(truncate / item_size)\n            # Truncate the data to fit within the memory constraints\n            array = array[:max_items]\n\n        # Index the data using the specified tokenizer\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(array, tokenizer, Terms)\n\n        # Create a new instance of SearchArray with the indexed data\n        result = cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n        result.posns = posns\n        result.term_dict = term_dict\n        result.avg_doc_length = avg_doc_length\n        result.doc_lens = doc_lens\n\n        # Return the new instance of SearchArray\n        return result\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:truncate]\n\n        # TODO: If the array is too large, process in batches\n        if len(array) > batch_size:\n            logger.warning(f\"Array is too large to index in one go. Will process in batches of {batch_size}.\")\n            # TODO: Add a progress bar\n            batches = np.array_split(array, len(array) // batch_size)\n            postings = []\n            for batch in batches:\n                postings.extend(build_index_from_tokenizer(batch, tokenizer, avoid_copies=avoid_copies)[0])\n        else:\n            postings = build_index_from_tokenizer(array, tokenizer, avoid_copies=avoid_copies)[0]\n\n        return cls(postings, tokenizer, avoid_copies)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            strategy=self.config['strategy'],\n            strategies=self.config['strategies'],\n            on_connect=self.on_connect,\n            on_disconnect=self.on_disconnect,\n            on_message=self.on_message,\n            on_error=self.on_error,\n            logger=self.logger,\n        )\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            on_connect=self.on_connect,\n            on_disconnect=self.on_disconnect,\n            on_message=self.on_message,\n        )\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            on_connect=self.on_connect,\n            on_disconnect=self.on_disconnect,\n            on_data=self.on_data,\n            on_error=self.on_error,\n        )\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            on_connect=self.on_connect,\n            on_disconnect=self.on_disconnect,\n            on_message=self.on_message,\n            on_error=self.on_error,\n            logger=self.logger,\n        )\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n            self.logger,\n        )\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            strategy=self.config['strategy'],\n            strategies=self.config['strategies'],\n            autoCloseConnections=self.config['autoCloseConnections'],\n            multipleConnections=self.config['multipleConnections'],\n            on_message=self.on_message,\n            on_connection=self.on_connection,\n            on_disconnect=self.on_disconnect,\n            on_error=self.on_error,\n            on_close=self.on_close,\n        )\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            connection_handler=self.handle_connection,\n            message_handler=self.handle_message,\n        )\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['strategy'], self.config['strategies'])\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.logger.info(\"Starting proxifier server\")\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.on_server_message)\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.logger.info(\"Proxifier server started\")\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            on_connect=self.on_connect,\n            on_disconnect=self.on_disconnect,\n            on_message=self.on_message,\n            on_error=self.on_error,\n        )\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            interceptor=self,\n            strategy=self.config['strategy'],\n            strategies=self.config['strategies'],\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n        )\n\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['strategy'], self.config['strategies'])\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.logger.info('Initializing ProxifierMessageInterceptor')\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            host=self.config.get('serverHost'),\n            port=self.config.get('serverPort'),\n            strategy=self.config.get('strategy'),\n            strategies=self.config.get('strategies'),\n            logger=self.logger,\n        )\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger,\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['strategy'],\n                             self.config['strategies'], self.config['autoCloseConnections'])\n        self.server.start()\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 128bit support\n    # Add more digits for 1"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr + (arr >> _8)) & s01\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.add(arr, np.right_shift(arr, _4))\n    arr = np.bitwise_and(arr, s33)\n    arr = np.add(arr, np.right_shift(arr, _2))\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.add(arr, np.right_shift(arr, _1))\n    arr = np.bitwise_and(arr, s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    return (\n        (arr & s55) + ((arr >> _1) & s55)\n    ) + (\n        ((arr >> _2) & s55) + ((arr >> _3) & s55)\n    )\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> 1) & s55)\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & s0F\n    return (arr * s01) >> all_but_one_bit\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = arr + (arr >> _4)\n    arr = arr & s01\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Add the digits in the lower half of each byte\n    arr = arr - ((arr >> _1) & s55)\n    # Add the digits in the upper half of each byte\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    # Add the digits in the lower half of each nibble\n    arr = (arr + (arr >> _4)) & s0F\n    # Add the digits in the upper half of each nibble\n    arr = (arr + (arr >> _2)) & s01\n    # Add the digits in the lower half of each byte\n    arr = arr + (arr >> _1)\n    # Add the digits in the upper half of each byte\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each nibble\n    arr = arr + (arr >> _4)\n    # Add the digits in the upper half of each nibble\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each byte\n    arr = arr + (arr >> _1)\n    # Add the digits in the upper half of each byte\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each nibble\n    arr = arr + (arr >> _4)\n    # Add the digits in the upper half of each nibble\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each byte\n    arr = arr + (arr >> _1)\n    # Add the digits in the upper half of each byte\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each nibble\n    arr = arr + (arr >> _4)\n    # Add the digits in the upper half of each nibble\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each byte\n    arr = arr + (arr >> _1)\n    # Add the digits in the upper half of each byte\n    arr = arr + (arr >> _2)\n    # Add the digits in the lower half of each nibble\n    arr = arr + (arr >> _4)\n    # Add the digits in the upper half of each nibble\n    arr = arr + (arr >> _2)\n    # Add the"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr & s55) >> _1\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> _4\n    return (arr & s01) + ((arr >> _4) & s01)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr, s33)\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.bitwise_and(arr, s01)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # x = np.uint64(arr)\n    x = arr\n    x = x - ((x >> 1) & s55)\n    x = (x & s33) + ((x >> 2) & s33)\n    x = (x + (x >> 4)) & s0F\n    return (x * s01) >> all_but_one_bit\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.uint64(arr)\n    arr = np.bitwise_and(arr, s55)\n    arr = np.uint64(np.left_shift(arr, _1)) + np.uint64(np.right_shift(arr, _1))\n    arr = np.uint64(np.bitwise_and(arr, s33))\n    arr = np.uint64(np.left_shift(arr, _2)) + np.uint64(np.right_shift(arr, _2))\n    arr = np.uint64(np.bitwise_and(arr, s0F))\n    arr = np.uint64(np.left_shift(arr, _4)) + np.uint64(np.right_shift(arr, _4))\n    arr = np.uint64(np.bitwise_and(arr, s01))\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr, s33)\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.bitwise_and(arr, s01)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Add more digits for 128bit support\n    s55 = np.uint64(m1 & mask)\n    s33 = np.uint64(m2 & mask)\n    s0F = np.uint64(m3 & mask)\n    s01 = np.uint64(m4 & mask)\n    num_bytes_64 = 8\n    all_but_one_bit = np.uint64(8 * (num_bytes_64 - 1))\n\n    # Count bits set in each 2-bit group\n    arr = (arr & s55) + ((arr >> _1) & s55)\n    # Count bits set in each 4-bit group\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    # Count bits set in each 8-bit group\n    arr = (arr & s0F) + ((arr >> _4) & s0F)\n    # Count bits set in each 16-bit group\n    arr = (arr & s01) + ((arr >> _4) & s01)\n    # Count bits set in each 32-bit group\n    arr = (arr & all_but_one_bit) + ((arr >> _4) & all_but_one_bit)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.uint64(arr)\n    arr = np.uint64(arr & s55)\n    arr = np.uint64(arr + (arr >> _1))\n    arr = np.uint64(arr & s33)\n    arr = np.uint64(arr + (arr >> _2))\n    arr = np.uint64(arr & s0F)\n    arr = np.uint64(arr + (arr >> _4))\n    return np.uint64(arr)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Step 1: Subtract 1 from each element of the array.\n    arr -= _1\n    # Step 2: Use bitwise AND to isolate the last bit of each element.\n    arr &= s55\n    # Step 3: Use bitwise AND to isolate the next two bits of each element.\n    arr &= s33\n    # Step 4: Use bitwise AND to isolate the next four bits of each element.\n    arr &= s0F\n    # Step 5: Use bitwise AND to isolate the next eight bits of each element.\n    arr &= s01\n    # Step 6: Sum the isolated bits for each element.\n    arr += arr >> _4\n    # Step 7: Sum the isolated bits for each element.\n    arr += arr >> _2\n    # Step 8: Sum the isolated bits for each element.\n    arr += arr >> _1\n    # Step 9: Return the array.\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Compute the number of bits set to 1 in each element of the array.\n    # This is a step in the process of efficiently calculating the bit count for each element in the array.\n    arr = arr - ((arr >> 1) & s55)\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & s0F\n    arr = arr + (arr >> 8)\n    arr = arr + (arr >> 16)\n    arr = arr + (arr >> 32)\n\n    # The bit count for each element in the array is now contained in the least significant bits of each element.\n    # Extract the bit count from each element and store it in the corresponding element of the output array.\n    return arr & all_but_one_bit\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr & s55)\n\n    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr + (arr >> _4))\n\n    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr & s0F)\n\n    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr + (arr >> _2))\n\n    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr & s01)\n\n    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr + (arr >> _1))\n\n    # Use bitwise AND to isolate the least significant bit of each element in the array\n    arr = np.uint64(arr & all_but_one_bit)\n\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Calculate the bit count for each element of the array\n    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    return ((arr * s01) >> all_but_one_bit)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Add more digits for 128bit support\n    arr = np.uint64(arr & mask)\n\n    # Count bits set to 1 in each element of the array using bitwise operations.\n    arr = np.uint64(arr - ((arr >> _1) & s55))\n    arr = np.uint64((arr & s33) + ((arr >> _2) & s33))\n    arr = np.uint64((arr + (arr >> _4)) & s0F)\n    arr = np.uint64(arr + (arr >> _8))\n    arr = np.uint64(arr + (arr >> _16))\n    arr = np.uint64(arr + (arr >> _32))\n\n    # Convert the bit counts to integers and return the array.\n    return np.uint64(arr & s01)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr + (arr >> _8)) & s01\n    return arr\n\n"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    if pf:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3:\n        query_fields.update(parse_field_boosts(pf3))\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    if pf:\n        pf_fields = parse_field_boosts(pf)\n        num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, pf)\n        if term_centric:\n            pf_scores, explain = _edismax_term_centric(frame,\n                                                       pf_fields,\n                                                       num_search_terms,\n                                                       search_terms,\n                                                       mm,\n                                                       similarity)\n        else:\n            pf_scores, explain = _edismax_field_centric(frame,\n                                                        pf_fields,\n                                                        num_search_terms,\n                                                        search_terms,\n                                                        mm,\n                                                        similarity)\n        qf_scores = np.maximum(qf_scores, pf_scores)\n        explain = \"(\" + explain + \") | \" + \"(\" + explain + \")\"\n\n    if pf2:\n        pf2_fields = parse_field_boosts(pf2)\n        num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, pf2)\n        if term_centric:\n            pf2_scores, explain = _edismax_term_centric(frame,\n                                                        pf2_fields,\n                                                        num_search_terms,\n                                                        search_terms,\n                                                        mm,\n                                                        similarity)\n        else:\n            pf2_scores, explain = _edismax_field_centric(frame,\n                                                         pf2_fields,\n                                                         num_search_terms,\n                                                         search_terms,\n                                                         mm,\n                                                         similarity)\n        qf_scores = np.maximum(qf_scores, pf2_scores)\n        explain = \"(\" + explain + \") | \" + \"(\" + explain + \")\"\n\n    if pf3:\n        pf3_fields = parse_field_boosts(pf3)\n        num_search_terms"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"frame must be a pandas DataFrame\")\n\n    if not isinstance(q, str):\n        raise ValueError(\"q must be a string\")\n\n    if not isinstance(qf, List):\n        raise ValueError(\"qf must be a list of strings\")\n\n    if not isinstance(mm, Optional[str]):\n        raise ValueError(\"mm must be a string or None\")\n\n    if not isinstance(pf, Optional[List[str]]):\n        raise ValueError(\"pf must be a list of strings or None\")\n\n    if not isinstance(pf2, Optional[List[str]]):\n        raise ValueError(\"pf2 must be a list of strings or None\")\n\n    if not isinstance(pf3, Optional[List[str]]):\n        raise ValueError(\"pf3 must be a list of strings or None\")\n\n    if not isinstance(q_op, str):\n        raise ValueError(\"q_op must be a string\")\n\n    if not isinstance(similarity, Similarity):\n        raise ValueError(\"similarity must be a Similarity object\")\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    pf_scores = np.zeros(len(frame))\n    pf_explain = \"\"\n    if pf is not None:\n        pf_fields = parse_field_boosts(pf)\n        num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, pf)\n        if term_centric:\n            pf_scores, pf_explain = _edismax_term_centric(frame, pf_fields, num_search_terms, search_terms, mm, similarity)\n        else:\n            pf_scores, pf_explain = _edismax_field_centric(frame, pf_fields, num_search_terms, search_terms, mm, similarity)\n\n    pf2_scores = np.zeros(len"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse the query fields and boosts\n    qf_dict = parse_field_boosts(qf)\n    pf_dict = parse_field_boosts(pf) if pf else {}\n    pf2_dict = parse_field_boosts(pf2) if pf2 else {}\n    pf3_dict = parse_field_boosts(pf3) if pf3 else {}\n\n    # Parse the query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Calculate the scores based on the term-centric or field-centric approach\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, qf_dict, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, qf_dict, num_search_terms, search_terms, mm, similarity)\n\n    # Calculate the scores for the phrase matches\n    if pf_dict:\n        pf_scores, pf_explain = _edismax_field_centric(frame, pf_dict, num_search_terms, search_terms, mm, similarity)\n    else:\n        pf_scores = np.zeros(len(frame))\n        pf_explain = \"\"\n\n    # Calculate the scores for the bigram matches\n    if pf2_dict:\n        pf2_scores, pf2_explain = _edismax_field_centric(frame, pf2_dict, num_search_terms, search_terms, mm, similarity)\n    else:\n        pf2_scores = np.zeros(len(frame))\n        pf2_explain = \"\"\n\n    # Calculate the scores for the trigram matches\n    if pf3_dict:\n        pf3_scores, pf3_explain = _edismax_field_centric(frame, pf3_dict, num_search_terms, search_terms, mm, similarity)\n    else:\n        pf3_scores = np.zeros(len(frame))\n        pf3_explain = \"\"\n\n    # Combine the scores and explanations for the different match types\n    scores = qf_scores + pf_scores + pf2_scores + pf3_scores\n    explain = f\"({qf_explain} {pf_explain}"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    if pf:\n        pf_scores, pf_explain = edismax(frame,\n                                        q,\n                                        pf,\n                                        mm,\n                                        None,\n                                        None,\n                                        None,\n                                        q_op,\n                                        similarity)\n        qf_scores = np.maximum(qf_scores, pf_scores)\n        explain += \" \" + pf_explain\n\n    if pf2:\n        pf2_scores, pf2_explain = edismax(frame,\n                                          q,\n                                          pf2,\n                                          mm,\n                                          None,\n                                          None,\n                                          None,\n                                          q_op,\n                                          similarity)\n        qf_scores = np.maximum(qf_scores, pf2_scores)\n        explain += \" \" + pf2_explain\n\n    if pf3:\n        pf3_scores, pf3_explain = edismax(frame,\n                                          q,\n                                          pf3,\n                                          mm,\n                                          None,\n                                          None,\n                                          None,\n                                          q_op,\n                                          similarity)\n        qf_scores = np.maximum(qf_scores, pf3_scores)\n        explain += \" \" + pf3_explain\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not qf:\n        raise ValueError(\"Must provide at least one query field\")\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse field boosts\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    phrase2_fields = parse_field_boosts(pf2)\n    phrase3_fields = parse_field_boosts(pf3)\n\n    # Calculate scores for each term\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Calculate scores for phrase matches\n    if pf:\n        pf_scores, pf_explain = _edismax_term_centric(frame, phrase_fields, num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf_scores\n        qf_explain += \" | \" + pf_explain\n\n    # Calculate scores for bigram matches\n    if pf2:\n        pf2_scores, pf2_explain = _edismax_term_centric(frame, phrase2_fields, num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf2_scores\n        qf_explain += \" | \" + pf2_explain\n\n    # Calculate scores for trigram matches\n    if pf3:\n        pf3_scores, pf3_explain = _edismax_term_centric(frame, phrase3_fields, num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf3_scores\n        qf_explain += \" | \" + pf3_explain\n\n    # Calculate final scores\n    scores = qf_scores\n\n    # Return scores and explanation\n    return scores, qf_explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not qf:\n        raise ValueError(\"Must specify at least one query field\")\n\n    query_fields = parse_field_boosts(qf)\n    if pf:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3:\n        query_fields.update(parse_field_boosts(pf3))\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"Frame must be a pandas DataFrame\")\n\n    if not isinstance(q, str):\n        raise ValueError(\"q must be a string\")\n\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list of strings\")\n\n    if not isinstance(mm, str) and mm is not None:\n        raise ValueError(\"mm must be a string\")\n\n    if not isinstance(pf, list) and pf is not None:\n        raise ValueError(\"pf must be a list of strings\")\n\n    if not isinstance(pf2, list) and pf2 is not None:\n        raise ValueError(\"pf2 must be a list of strings\")\n\n    if not isinstance(pf3, list) and pf3 is not None:\n        raise ValueError(\"pf3 must be a list of strings\")\n\n    if not isinstance(q_op, str):\n        raise ValueError(\"q_op must be a string\")\n\n    if not isinstance(similarity, Similarity):\n        raise ValueError(\"similarity must be a Similarity object\")\n\n    if mm is None:\n        mm = \"100%\"\n\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    if not qf:\n        raise ValueError(\"qf must not be empty\")\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not qf and not pf and not pf2 and not pf3:\n        raise ValueError(\"No query fields specified\")\n\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    query_fields.update(phrase_fields)\n    query_fields.update(bigram_fields)\n    query_fields.update(trigram_fields)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    if pf:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3:\n        query_fields.update(parse_field_boosts(pf3))\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    if pf is not None:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2 is not None:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3 is not None:\n        query_fields.update(parse_field_boosts(pf3))\n\n    if not query_fields:\n        raise ValueError(\"At least one query field must be specified\")\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            try:\n                if process.pid not in self.connections:\n                    self.connections[process.pid] = Connection(\n                        connection_id=process.pid,\n                        server_host=self.config['serverHost'],\n                        server_port=self.config['serverPort'],\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                self.connections[process.pid].c2s(message)\n            finally:\n                self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            try:\n                if process.pid not in self.connections:\n                    self.connections[process.pid] = Connection(\n                        connection_id=process.pid,\n                        server_host=self.config['serverHost'],\n                        server_port=self.config['serverPort'],\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                self.connections[process.pid].s2c(message)\n            finally:\n                self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            try:\n                if process.pid not in self.connections:\n                    self.connections[process.pid] = Connection(\n                        connection_id=process.pid,\n                        server_host=self.config['serverHost'],\n                        server_port=self.config['serverPort'],\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                self.connections[process.pid].close()\n                if self.config['autoCloseConnections']:\n                    del"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection_id = DEFAULT_CONNECTION_ID if not self.config['multipleConnections'] else process.pid\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    server_host=self.config['serverHost'],\n                    server_port=self.config['serverPort'],\n                    proxy_host=self.config['proxyHost'],\n                    proxy_port=self.config['proxyPort'],\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n                self.connections[connection_id].start()\n            self.lock.release()\n            message.data = self.connections[connection_id].c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection_id = DEFAULT_CONNECTION_ID if not self.config['multipleConnections'] else process.pid\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    server_host=self.config['serverHost'],\n                    server_port=self.config['serverPort'],\n                    proxy_host=self.config['proxyHost'],\n                    proxy_port=self.config['proxyPort'],\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n                self.connections[connection_id].start()\n            self.lock.release()\n            message.data = self.connections[connection_id].s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            connection_id = DEFAULT_CONNECTION_ID if not self.config['multipleConnections'] else process.pid\n            if connection_id in self.connections:\n                self.connections[connection_id].close()\n                if self.config['autoCloseConnections']:\n                    del self.connections[connection_id]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid, None)\n                if connection is None:\n                    connection = Connection(\n                        connection_id=DEFAULT_CONNECTION_ID,\n                        strategy=self.server.strategy,\n                        strategy_config=self.server.strategy_config,\n                        logger=self.logger\n                    )\n                    self.connections[process.pid] = connection\n                connection.c2s(message)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid, None)\n                if connection is None:\n                    connection = Connection(\n                        connection_id=DEFAULT_CONNECTION_ID,\n                        strategy=self.server.strategy,\n                        strategy_config=self.server.strategy_config,\n                        logger=self.logger\n                    )\n                    self.connections[process.pid] = connection\n                connection.s2c(message)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid, None)\n                if connection is None:\n                    connection = Connection(\n                        connection_id=DEFAULT_CONNECTION_ID,\n                        strategy=self.server.strategy,\n                        strategy_config=self.server.strategy_config,\n                        logger=self.logger\n                    )\n                    self.connections[process.pid] = connection\n                connection.close()\n                if self.config['autoCloseConnections']:\n                    del self.connections[process.pid]"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        connection_id=process.id,\n                        server=self.server,\n                        logger=self.logger\n                    )\n                self.connections[process.id].c2s(message)\n            finally:\n                self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        connection_id=process.id,\n                        server=self.server,\n                        logger=self.logger\n                    )\n                self.connections[process.id].s2c(message)\n            finally:\n                self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            try:\n                if process.id in self.connections:\n                    self.connections[process.id].close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[process.id]\n            finally:\n                self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        connection_id = process.pid\n        with self.lock:\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    server=self.server,\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n            connection = self.connections[connection_id]\n\n        if isinstance(message, SendMessage):\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            if self.config['autoCloseConnections']:\n                connection.close()\n                del self.connections[connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[process.id] = self.server.get_connection(process.id)\n                    else:\n                        self.connections[process.id] = self.server.get_connection(DEFAULT_CONNECTION_ID)\n                self.connections[process.id].c2s(message)\n            except Exception as e:\n                self.logger.error(f'Error while sending message: {e}')\n            finally:\n                self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[process.id] = self.server.get_connection(process.id)\n                    else:\n                        self.connections[process.id] = self.server.get_connection(DEFAULT_CONNECTION_ID)\n                self.connections[process.id].s2c(message)\n            except Exception as e:\n                self.logger.error(f'Error while receiving message: {e}')\n            finally:\n                self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[process.id] = self.server.get_connection(process.id)\n                    else:\n                        self.connections[process.id] = self.server.get_connection(DEFAULT_CONNECTION_ID)\n                self.connections[process.id].close()\n                if self.config['autoCloseConnections']:\n                    del self.connections[process.id]\n            except Exception as e:\n                self.logger.error(f'Error while closing connection: {e}')\n            finally:\n                self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection_id = DEFAULT_CONNECTION_ID\n            if self.config['multipleConnections']:\n                connection_id = process.pid\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    proxy_host=self.config['proxyHost'],\n                    proxy_port=self.config['proxyPort'],\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n            self.connections[connection_id].c2s(message)\n            self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection_id = DEFAULT_CONNECTION_ID\n            if self.config['multipleConnections']:\n                connection_id = process.pid\n            if connection_id not in self.connections:\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    proxy_host=self.config['proxyHost'],\n                    proxy_port=self.config['proxyPort'],\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n            self.connections[connection_id].s2c(message)\n            self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            connection_id = DEFAULT_CONNECTION_ID\n            if self.config['multipleConnections']:\n                connection_id = process.pid\n            if connection_id in self.connections:\n                self.connections[connection_id].close()\n                if self.config['autoCloseConnections']:\n                    del self.connections[connection_id]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        connection_id=process.id,\n                        server=self.server,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections'],\n                        multiple_connections=self.config['multipleConnections']\n                    )\n                self.connections[process.id].c2s(message)\n            finally:\n                self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        connection_id=process.id,\n                        server=self.server,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections'],\n                        multiple_connections=self.config['multipleConnections']\n                    )\n                self.connections[process.id].s2c(message)\n            finally:\n                self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            try:\n                if process.id not in self.connections:\n                    self.connections[process.id] = Connection(\n                        connection_id=process.id,\n                        server=self.server,\n                        logger=self.logger,\n                        auto_close=self.config['autoCloseConnections'],\n                        multiple_connections=self.config['multipleConnections']\n                    )\n                self.connections[process.id].close()\n            finally:\n                self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid, None)\n                if connection is None:\n                    if self.config['multipleConnections']:\n                        connection = Connection(\n                            process.pid,\n                            self.server.get_connection(process.pid),\n                            self.config['autoCloseConnections'],\n                            self.logger\n                        )\n                        self.connections[process.pid] = connection\n                    else:\n                        connection = Connection(\n                            DEFAULT_CONNECTION_ID,\n                            self.server.get_connection(DEFAULT_CONNECTION_ID),\n                            self.config['autoCloseConnections'],\n                            self.logger\n                        )\n                message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid, None)\n                if connection is None:\n                    if self.config['multipleConnections']:\n                        connection = Connection(\n                            process.pid,\n                            self.server.get_connection(process.pid),\n                            self.config['autoCloseConnections'],\n                            self.logger\n                        )\n                        self.connections[process.pid] = connection\n                    else:\n                        connection = Connection(\n                            DEFAULT_CONNECTION_ID,\n                            self.server.get_connection(DEFAULT_CONNECTION_ID),\n                            self.config['autoCloseConnections'],\n                            self.logger\n                        )\n                message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid, None)\n                if connection is not None:\n                    connection.close()\n                    if self.config['multipleConnections']:\n                        del self.connections[process.pid]"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.id, None)\n                if not connection:\n                    connection = Connection(\n                        connection_id=process.id,\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                    connection.start()\n                    self.connections[process.id] = connection\n                connection.send(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.id, None)\n                if not connection:\n                    connection = Connection(\n                        connection_id=process.id,\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                    connection.start()\n                    self.connections[process.id] = connection\n                message.data = connection.recv()\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.id, None)\n                if connection:\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection_id = process.id\n            if connection_id not in self.connections:\n                if not self.config['multipleConnections']:\n                    connection_id = DEFAULT_CONNECTION_ID\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n            self.connections[connection_id].c2s(message)\n            self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection_id = process.id\n            if connection_id not in self.connections:\n                if not self.config['multipleConnections']:\n                    connection_id = DEFAULT_CONNECTION_ID\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n            self.connections[connection_id].s2c(message)\n            self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            connection_id = process.id\n            if connection_id not in self.connections:\n                if not self.config['multipleConnections']:\n                    connection_id = DEFAULT_CONNECTION_ID\n                self.connections[connection_id] = Connection(\n                    connection_id=connection_id,\n                    strategy=ProxifierStrategyType(self.config['strategy']),\n                    strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                    logger=self.logger\n                )\n            if self.config['autoCloseConnections']:\n                self.connections[connection_id].close()\n                del self.connections[connection_id]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection = self.get_connection(process)\n            connection.c2s(message)\n            self.lock.release()\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection = self.get_connection(process)\n            connection.s2c(message)\n            self.lock.release()\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            connection = self.get_connection(process)\n            connection.close()\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if process.id not in self.connections:\n                    if not self.config['multipleConnections']:\n                        self.close_all_connections()\n                    self.connections[process.id] = Connection(\n                        connection_id=process.id,\n                        strategy=self.server.strategy,\n                        strategy_config=self.server.strategy_config,\n                        logger=self.logger\n                    )\n                connection = self.connections[process.id]\n                message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                if process.id in self.connections:\n                    connection = self.connections[process.id]\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[process.id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection = self.connections.get(process.pid, None)\n            if not connection:\n                connection = Connection(self.server, process.pid)\n                self.connections[process.pid] = connection\n            self.lock.release()\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection = self.connections.get(process.pid, None)\n            if not connection:\n                connection = Connection(self.server, process.pid)\n                self.connections[process.pid] = connection\n            self.lock.release()\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            connection = self.connections.get(process.pid, None)\n            if connection:\n                connection.close()\n                if self.config['autoCloseConnections']:\n                    del self.connections[process.pid]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            connection = self.connections.get(process.id, None)\n            if connection is None:\n                connection = self.server.get_connection(process.id)\n                self.connections[process.id] = connection\n            self.lock.release()\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            connection = self.connections.get(process.id, None)\n            if connection is None:\n                connection = self.server.get_connection(process.id)\n                self.connections[process.id] = connection\n            self.lock.release()\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            if self.config['autoCloseConnections']:\n                self.lock.acquire()\n                connection = self.connections.get(process.id, None)\n                if connection is not None:\n                    connection.close()\n                    del self.connections[process.id]\n                self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if self.config['multipleConnections']:\n                    connection_id = process.process_id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        connection_id=connection_id,\n                        server=self.server,\n                        logger=self.logger\n                    )\n\n                self.connections[connection_id].c2s(message)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                if self.config['multipleConnections']:\n                    connection_id = process.process_id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        connection_id=connection_id,\n                        server=self.server,\n                        logger=self.logger\n                    )\n\n                self.connections[connection_id].s2c(message)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                if self.config['multipleConnections']:\n                    connection_id = process.process_id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n\n                if connection_id in self.connections:\n                    if self.config['autoCloseConnections']:\n                        self.connections[connection_id].close()\n                    else:\n                        self.logger.info(f'Connection {connection_id} not closed')\n\n        else:\n            self.logger.debug(f'Message {message} ignored')"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.lock.acquire()\n            if process.pid not in self.connections:\n                self.connections[process.pid] = Connection(process.pid, self.server, self.logger, self.config['autoCloseConnections'])\n            self.lock.release()\n            message.data = self.connections[process.pid].c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            self.lock.acquire()\n            if process.pid not in self.connections:\n                self.connections[process.pid] = Connection(process.pid, self.server, self.logger, self.config['autoCloseConnections'])\n            self.lock.release()\n            message.data = self.connections[process.pid].s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.lock.acquire()\n            if process.pid in self.connections:\n                self.connections[process.pid].close()\n                if not self.config['multipleConnections']:\n                    del self.connections[process.pid]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info(\"Stopping all connections\")\n        for connection_id, connection in self.connections.items():\n            self.logger.info(\"Stopping connection %s\", connection_id)\n            connection.stop()\n        self.logger.info(\"Stopping server\")\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection_id in self.connections:\n            self._close_connection(connection_id)\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Destroying ProxifierMessageInterceptor')\n        for connection in self.connections.values():\n            connection.close()\n        self.connections = {}\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Close all connections managed by the ProxifierMessageInterceptor instance\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n\n        # Stop the server associated with the ProxifierMessageInterceptor instance, if any\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Close all connections\n        for connection in self.connections.values():\n            connection.close()\n\n        # Stop the server\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection_id, connection in self.connections.items():\n            connection.close()\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        if self.connections:\n            for connection in self.connections.values():\n                connection.close()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        if self.server:\n            for connection in self.connections.values():\n                connection.close()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.server.stop()\n"}
